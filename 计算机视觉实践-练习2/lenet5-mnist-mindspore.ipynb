{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2554b851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.589.321 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.591.282 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.592.279 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.595.299 [mindspore\\dataset\\core\\validator_helpers.py:744] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.597.268 [mindspore\\dataset\\core\\validator_helpers.py:744] 'TypeCast' from mindspore.dataset.transforms.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'TypeCast' from mindspore.dataset.transforms instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting Training ==========\n",
      "epoch: 1 step: 1, loss is 2.3175418376922607\n",
      "epoch: 1 step: 2, loss is 2.2908544540405273\n",
      "epoch: 1 step: 3, loss is 2.2934257984161377\n",
      "epoch: 1 step: 4, loss is 2.294602155685425\n",
      "epoch: 1 step: 5, loss is 2.30145263671875\n",
      "epoch: 1 step: 6, loss is 2.302452802658081\n",
      "epoch: 1 step: 7, loss is 2.297163963317871\n",
      "epoch: 1 step: 8, loss is 2.302682876586914\n",
      "epoch: 1 step: 9, loss is 2.290586471557617\n",
      "epoch: 1 step: 10, loss is 2.294130802154541\n",
      "epoch: 1 step: 11, loss is 2.2916743755340576\n",
      "epoch: 1 step: 12, loss is 2.288522481918335\n",
      "epoch: 1 step: 13, loss is 2.2780914306640625\n",
      "epoch: 1 step: 14, loss is 2.2650272846221924\n",
      "epoch: 1 step: 15, loss is 2.2725777626037598\n",
      "epoch: 1 step: 16, loss is 2.28691029548645\n",
      "epoch: 1 step: 17, loss is 2.2750027179718018\n",
      "epoch: 1 step: 18, loss is 2.2607781887054443\n",
      "epoch: 1 step: 19, loss is 2.254864454269409\n",
      "epoch: 1 step: 20, loss is 2.241610527038574\n",
      "epoch: 1 step: 21, loss is 2.293060541152954\n",
      "epoch: 1 step: 22, loss is 2.3006386756896973\n",
      "epoch: 1 step: 23, loss is 2.2277445793151855\n",
      "epoch: 1 step: 24, loss is 2.2507224082946777\n",
      "epoch: 1 step: 25, loss is 2.26584529876709\n",
      "epoch: 1 step: 26, loss is 2.207688570022583\n",
      "epoch: 1 step: 27, loss is 2.246142864227295\n",
      "epoch: 1 step: 28, loss is 2.1804263591766357\n",
      "epoch: 1 step: 29, loss is 2.205709934234619\n",
      "epoch: 1 step: 30, loss is 2.182378053665161\n",
      "epoch: 1 step: 31, loss is 2.1874959468841553\n",
      "epoch: 1 step: 32, loss is 2.1799676418304443\n",
      "epoch: 1 step: 33, loss is 2.1516172885894775\n",
      "epoch: 1 step: 34, loss is 2.1759090423583984\n",
      "epoch: 1 step: 35, loss is 2.091303586959839\n",
      "epoch: 1 step: 36, loss is 2.0355770587921143\n",
      "epoch: 1 step: 37, loss is 2.031902551651001\n",
      "epoch: 1 step: 38, loss is 2.1715197563171387\n",
      "epoch: 1 step: 39, loss is 2.0977978706359863\n",
      "epoch: 1 step: 40, loss is 1.847468376159668\n",
      "epoch: 1 step: 41, loss is 1.9373332262039185\n",
      "epoch: 1 step: 42, loss is 1.7957099676132202\n",
      "epoch: 1 step: 43, loss is 1.6619372367858887\n",
      "epoch: 1 step: 44, loss is 1.7876548767089844\n",
      "epoch: 1 step: 45, loss is 1.4743096828460693\n",
      "epoch: 1 step: 46, loss is 1.3926582336425781\n",
      "epoch: 1 step: 47, loss is 1.644524335861206\n",
      "epoch: 1 step: 48, loss is 1.5712941884994507\n",
      "epoch: 1 step: 49, loss is 1.4531804323196411\n",
      "epoch: 1 step: 50, loss is 1.4712989330291748\n",
      "epoch: 1 step: 51, loss is 1.5175998210906982\n",
      "epoch: 1 step: 52, loss is 1.0682088136672974\n",
      "epoch: 1 step: 53, loss is 1.2217460870742798\n",
      "epoch: 1 step: 54, loss is 1.404093623161316\n",
      "epoch: 1 step: 55, loss is 1.1594278812408447\n",
      "epoch: 1 step: 56, loss is 2.0518457889556885\n",
      "epoch: 1 step: 57, loss is 1.2329230308532715\n",
      "epoch: 1 step: 58, loss is 1.3202353715896606\n",
      "epoch: 1 step: 59, loss is 1.4918452501296997\n",
      "epoch: 1 step: 60, loss is 1.5973533391952515\n",
      "epoch: 1 step: 61, loss is 1.2983890771865845\n",
      "epoch: 1 step: 62, loss is 1.6098568439483643\n",
      "epoch: 1 step: 63, loss is 1.0366758108139038\n",
      "epoch: 1 step: 64, loss is 1.334513545036316\n",
      "epoch: 1 step: 65, loss is 1.1339484453201294\n",
      "epoch: 1 step: 66, loss is 1.006945013999939\n",
      "epoch: 1 step: 67, loss is 1.2731263637542725\n",
      "epoch: 1 step: 68, loss is 0.8735068440437317\n",
      "epoch: 1 step: 69, loss is 0.9313348531723022\n",
      "epoch: 1 step: 70, loss is 0.9026170969009399\n",
      "epoch: 1 step: 71, loss is 0.9875935316085815\n",
      "epoch: 1 step: 72, loss is 0.6135706305503845\n",
      "epoch: 1 step: 73, loss is 0.8015072345733643\n",
      "epoch: 1 step: 74, loss is 0.9319887757301331\n",
      "epoch: 1 step: 75, loss is 0.7010061740875244\n",
      "epoch: 1 step: 76, loss is 0.6858168244361877\n",
      "epoch: 1 step: 77, loss is 0.7580164670944214\n",
      "epoch: 1 step: 78, loss is 0.8264782428741455\n",
      "epoch: 1 step: 79, loss is 0.7353325486183167\n",
      "epoch: 1 step: 80, loss is 0.974868893623352\n",
      "epoch: 1 step: 81, loss is 0.546840250492096\n",
      "epoch: 1 step: 82, loss is 0.6174237728118896\n",
      "epoch: 1 step: 83, loss is 0.5456783175468445\n",
      "epoch: 1 step: 84, loss is 1.0396517515182495\n",
      "epoch: 1 step: 85, loss is 0.8463142514228821\n",
      "epoch: 1 step: 86, loss is 0.8029271364212036\n",
      "epoch: 1 step: 87, loss is 0.3161952495574951\n",
      "epoch: 1 step: 88, loss is 0.920139729976654\n",
      "epoch: 1 step: 89, loss is 1.0269814729690552\n",
      "epoch: 1 step: 90, loss is 0.7351927757263184\n",
      "epoch: 1 step: 91, loss is 1.3856700658798218\n",
      "epoch: 1 step: 92, loss is 0.6388897895812988\n",
      "epoch: 1 step: 93, loss is 0.8796858787536621\n",
      "epoch: 1 step: 94, loss is 0.4826388359069824\n",
      "epoch: 1 step: 95, loss is 0.9781092405319214\n",
      "epoch: 1 step: 96, loss is 0.5574085712432861\n",
      "epoch: 1 step: 97, loss is 0.7047361731529236\n",
      "epoch: 1 step: 98, loss is 0.7510011792182922\n",
      "epoch: 1 step: 99, loss is 0.5397630929946899\n",
      "epoch: 1 step: 100, loss is 0.6118126511573792\n",
      "epoch: 1 step: 101, loss is 0.606071412563324\n",
      "epoch: 1 step: 102, loss is 0.4720498323440552\n",
      "epoch: 1 step: 103, loss is 0.7547380328178406\n",
      "epoch: 1 step: 104, loss is 0.5720964670181274\n",
      "epoch: 1 step: 105, loss is 0.3202435076236725\n",
      "epoch: 1 step: 106, loss is 0.2983555495738983\n",
      "epoch: 1 step: 107, loss is 0.7801538705825806\n",
      "epoch: 1 step: 108, loss is 0.4524952173233032\n",
      "epoch: 1 step: 109, loss is 0.7267738580703735\n",
      "epoch: 1 step: 110, loss is 0.7566455602645874\n",
      "epoch: 1 step: 111, loss is 0.716666579246521\n",
      "epoch: 1 step: 112, loss is 0.9082701206207275\n",
      "epoch: 1 step: 113, loss is 0.559441328048706\n",
      "epoch: 1 step: 114, loss is 0.5823757648468018\n",
      "epoch: 1 step: 115, loss is 0.4405117928981781\n",
      "epoch: 1 step: 116, loss is 0.5618816614151001\n",
      "epoch: 1 step: 117, loss is 0.5875471830368042\n",
      "epoch: 1 step: 118, loss is 0.622036337852478\n",
      "epoch: 1 step: 119, loss is 0.5784927010536194\n",
      "epoch: 1 step: 120, loss is 0.20969541370868683\n",
      "epoch: 1 step: 121, loss is 0.5863214731216431\n",
      "epoch: 1 step: 122, loss is 0.44111964106559753\n",
      "epoch: 1 step: 123, loss is 0.38225844502449036\n",
      "epoch: 1 step: 124, loss is 0.3960413634777069\n",
      "epoch: 1 step: 125, loss is 0.3975468873977661\n",
      "epoch: 1 step: 126, loss is 0.18171431124210358\n",
      "epoch: 1 step: 127, loss is 0.293552428483963\n",
      "epoch: 1 step: 128, loss is 0.7025222778320312\n",
      "epoch: 1 step: 129, loss is 0.370598167181015\n",
      "epoch: 1 step: 130, loss is 0.3170435428619385\n",
      "epoch: 1 step: 131, loss is 0.873563289642334\n",
      "epoch: 1 step: 132, loss is 0.37950456142425537\n",
      "epoch: 1 step: 133, loss is 0.3277991712093353\n",
      "epoch: 1 step: 134, loss is 0.28230705857276917\n",
      "epoch: 1 step: 135, loss is 0.29792216420173645\n",
      "epoch: 1 step: 136, loss is 0.18513689935207367\n",
      "epoch: 1 step: 137, loss is 0.11702938377857208\n",
      "epoch: 1 step: 138, loss is 0.11354537308216095\n",
      "epoch: 1 step: 139, loss is 0.2570441961288452\n",
      "epoch: 1 step: 140, loss is 0.4532487094402313\n",
      "epoch: 1 step: 141, loss is 0.5412837862968445\n",
      "epoch: 1 step: 142, loss is 0.5205171704292297\n",
      "epoch: 1 step: 143, loss is 0.1027718037366867\n",
      "epoch: 1 step: 144, loss is 0.34402406215667725\n",
      "epoch: 1 step: 145, loss is 0.7105377316474915\n",
      "epoch: 1 step: 146, loss is 0.24150781333446503\n",
      "epoch: 1 step: 147, loss is 0.3553943932056427\n",
      "epoch: 1 step: 148, loss is 0.46727991104125977\n",
      "epoch: 1 step: 149, loss is 0.2971290349960327\n",
      "epoch: 1 step: 150, loss is 0.30821970105171204\n",
      "epoch: 1 step: 151, loss is 0.4525424838066101\n",
      "epoch: 1 step: 152, loss is 0.3927713930606842\n",
      "epoch: 1 step: 153, loss is 0.3601992428302765\n",
      "epoch: 1 step: 154, loss is 0.22618833184242249\n",
      "epoch: 1 step: 155, loss is 0.47138354182243347\n",
      "epoch: 1 step: 156, loss is 0.20612512528896332\n",
      "epoch: 1 step: 157, loss is 0.442126989364624\n",
      "epoch: 1 step: 158, loss is 0.3348536193370819\n",
      "epoch: 1 step: 159, loss is 0.7171785235404968\n",
      "epoch: 1 step: 160, loss is 0.2680074870586395\n",
      "epoch: 1 step: 161, loss is 0.8051742911338806\n",
      "epoch: 1 step: 162, loss is 0.5005913376808167\n",
      "epoch: 1 step: 163, loss is 0.9733699560165405\n",
      "epoch: 1 step: 164, loss is 0.32516637444496155\n",
      "epoch: 1 step: 165, loss is 0.3360372483730316\n",
      "epoch: 1 step: 166, loss is 0.35474327206611633\n",
      "epoch: 1 step: 167, loss is 0.40739211440086365\n",
      "epoch: 1 step: 168, loss is 0.47661685943603516\n",
      "epoch: 1 step: 169, loss is 0.23857131600379944\n",
      "epoch: 1 step: 170, loss is 0.49369001388549805\n",
      "epoch: 1 step: 171, loss is 0.3707466423511505\n",
      "epoch: 1 step: 172, loss is 0.23667852580547333\n",
      "epoch: 1 step: 173, loss is 0.411373108625412\n",
      "epoch: 1 step: 174, loss is 0.31618836522102356\n",
      "epoch: 1 step: 175, loss is 0.4210568070411682\n",
      "epoch: 1 step: 176, loss is 0.4050482213497162\n",
      "epoch: 1 step: 177, loss is 0.29479700326919556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 178, loss is 0.3171994090080261\n",
      "epoch: 1 step: 179, loss is 0.19484888017177582\n",
      "epoch: 1 step: 180, loss is 0.12460707128047943\n",
      "epoch: 1 step: 181, loss is 0.3381057381629944\n",
      "epoch: 1 step: 182, loss is 0.44577330350875854\n",
      "epoch: 1 step: 183, loss is 0.3857579529285431\n",
      "epoch: 1 step: 184, loss is 0.4843492805957794\n",
      "epoch: 1 step: 185, loss is 0.21111765503883362\n",
      "epoch: 1 step: 186, loss is 0.13970337808132172\n",
      "epoch: 1 step: 187, loss is 0.271420955657959\n",
      "epoch: 1 step: 188, loss is 0.38114622235298157\n",
      "epoch: 1 step: 189, loss is 0.0730481743812561\n",
      "epoch: 1 step: 190, loss is 0.5099272727966309\n",
      "epoch: 1 step: 191, loss is 0.06591972708702087\n",
      "epoch: 1 step: 192, loss is 0.182000532746315\n",
      "epoch: 1 step: 193, loss is 0.19786794483661652\n",
      "epoch: 1 step: 194, loss is 0.16851435601711273\n",
      "epoch: 1 step: 195, loss is 0.3402138948440552\n",
      "epoch: 1 step: 196, loss is 0.38784852623939514\n",
      "epoch: 1 step: 197, loss is 0.5421263575553894\n",
      "epoch: 1 step: 198, loss is 0.22906368970870972\n",
      "epoch: 1 step: 199, loss is 0.22416695952415466\n",
      "epoch: 1 step: 200, loss is 0.18304072320461273\n",
      "epoch: 1 step: 201, loss is 0.4095975458621979\n",
      "epoch: 1 step: 202, loss is 0.3281824588775635\n",
      "epoch: 1 step: 203, loss is 0.1683480590581894\n",
      "epoch: 1 step: 204, loss is 0.35704511404037476\n",
      "epoch: 1 step: 205, loss is 0.5798599123954773\n",
      "epoch: 1 step: 206, loss is 0.07350669801235199\n",
      "epoch: 1 step: 207, loss is 0.24320757389068604\n",
      "epoch: 1 step: 208, loss is 0.5102852582931519\n",
      "epoch: 1 step: 209, loss is 0.35682353377342224\n",
      "epoch: 1 step: 210, loss is 0.30482518672943115\n",
      "epoch: 1 step: 211, loss is 0.08668193966150284\n",
      "epoch: 1 step: 212, loss is 0.1311597228050232\n",
      "epoch: 1 step: 213, loss is 0.08385451883077621\n",
      "epoch: 1 step: 214, loss is 0.4436822235584259\n",
      "epoch: 1 step: 215, loss is 0.26842281222343445\n",
      "epoch: 1 step: 216, loss is 0.1369004249572754\n",
      "epoch: 1 step: 217, loss is 0.41025981307029724\n",
      "epoch: 1 step: 218, loss is 0.11679280549287796\n",
      "epoch: 1 step: 219, loss is 0.31639963388442993\n",
      "epoch: 1 step: 220, loss is 0.16945526003837585\n",
      "epoch: 1 step: 221, loss is 0.1688651293516159\n",
      "epoch: 1 step: 222, loss is 0.20403173565864563\n",
      "epoch: 1 step: 223, loss is 0.19161948561668396\n",
      "epoch: 1 step: 224, loss is 0.16644072532653809\n",
      "epoch: 1 step: 225, loss is 0.4298224449157715\n",
      "epoch: 1 step: 226, loss is 0.16194471716880798\n",
      "epoch: 1 step: 227, loss is 0.23499788343906403\n",
      "epoch: 1 step: 228, loss is 0.08700654655694962\n",
      "epoch: 1 step: 229, loss is 0.2637394666671753\n",
      "epoch: 1 step: 230, loss is 0.433631956577301\n",
      "epoch: 1 step: 231, loss is 0.41027596592903137\n",
      "epoch: 1 step: 232, loss is 0.21629838645458221\n",
      "epoch: 1 step: 233, loss is 0.22090323269367218\n",
      "epoch: 1 step: 234, loss is 0.14308486878871918\n",
      "epoch: 1 step: 235, loss is 0.18427343666553497\n",
      "epoch: 1 step: 236, loss is 0.23738153278827667\n",
      "epoch: 1 step: 237, loss is 0.20132789015769958\n",
      "epoch: 1 step: 238, loss is 0.28211888670921326\n",
      "epoch: 1 step: 239, loss is 0.4446195363998413\n",
      "epoch: 1 step: 240, loss is 0.49313580989837646\n",
      "epoch: 1 step: 241, loss is 0.34892112016677856\n",
      "epoch: 1 step: 242, loss is 0.09343215823173523\n",
      "epoch: 1 step: 243, loss is 0.22496020793914795\n",
      "epoch: 1 step: 244, loss is 0.18704867362976074\n",
      "epoch: 1 step: 245, loss is 0.11238659173250198\n",
      "epoch: 1 step: 246, loss is 0.2459544837474823\n",
      "epoch: 1 step: 247, loss is 0.28769391775131226\n",
      "epoch: 1 step: 248, loss is 0.13381649553775787\n",
      "epoch: 1 step: 249, loss is 0.22008274495601654\n",
      "epoch: 1 step: 250, loss is 0.18215112388134003\n",
      "epoch: 1 step: 251, loss is 0.05730640888214111\n",
      "epoch: 1 step: 252, loss is 0.32168060541152954\n",
      "epoch: 1 step: 253, loss is 0.2483561784029007\n",
      "epoch: 1 step: 254, loss is 0.1349961906671524\n",
      "epoch: 1 step: 255, loss is 0.18781957030296326\n",
      "epoch: 1 step: 256, loss is 0.2963232398033142\n",
      "epoch: 1 step: 257, loss is 0.2625424861907959\n",
      "epoch: 1 step: 258, loss is 0.09552006423473358\n",
      "epoch: 1 step: 259, loss is 0.17659462988376617\n",
      "epoch: 1 step: 260, loss is 0.13359476625919342\n",
      "epoch: 1 step: 261, loss is 0.3197508454322815\n",
      "epoch: 1 step: 262, loss is 0.1752696931362152\n",
      "epoch: 1 step: 263, loss is 0.36164823174476624\n",
      "epoch: 1 step: 264, loss is 0.09864076226949692\n",
      "epoch: 1 step: 265, loss is 0.37782397866249084\n",
      "epoch: 1 step: 266, loss is 0.17577525973320007\n",
      "epoch: 1 step: 267, loss is 0.14000681042671204\n",
      "epoch: 1 step: 268, loss is 0.3371841311454773\n",
      "epoch: 1 step: 269, loss is 0.4703980088233948\n",
      "epoch: 1 step: 270, loss is 0.2736318111419678\n",
      "epoch: 1 step: 271, loss is 0.1019330844283104\n",
      "epoch: 1 step: 272, loss is 0.10382860153913498\n",
      "epoch: 1 step: 273, loss is 0.2370898723602295\n",
      "epoch: 1 step: 274, loss is 0.1162853091955185\n",
      "epoch: 1 step: 275, loss is 0.24805426597595215\n",
      "epoch: 1 step: 276, loss is 0.16943161189556122\n",
      "epoch: 1 step: 277, loss is 0.15452460944652557\n",
      "epoch: 1 step: 278, loss is 0.11183533817529678\n",
      "epoch: 1 step: 279, loss is 0.22407718002796173\n",
      "epoch: 1 step: 280, loss is 0.2301005721092224\n",
      "epoch: 1 step: 281, loss is 0.08086030185222626\n",
      "epoch: 1 step: 282, loss is 0.11917596310377121\n",
      "epoch: 1 step: 283, loss is 0.10907353460788727\n",
      "epoch: 1 step: 284, loss is 0.2578270137310028\n",
      "epoch: 1 step: 285, loss is 0.16806674003601074\n",
      "epoch: 1 step: 286, loss is 0.2669854760169983\n",
      "epoch: 1 step: 287, loss is 0.09988421201705933\n",
      "epoch: 1 step: 288, loss is 0.1596585065126419\n",
      "epoch: 1 step: 289, loss is 0.11607625335454941\n",
      "epoch: 1 step: 290, loss is 0.08603616803884506\n",
      "epoch: 1 step: 291, loss is 0.05189337208867073\n",
      "epoch: 1 step: 292, loss is 0.11783679574728012\n",
      "epoch: 1 step: 293, loss is 0.29529252648353577\n",
      "epoch: 1 step: 294, loss is 0.2752448618412018\n",
      "epoch: 1 step: 295, loss is 0.204662024974823\n",
      "epoch: 1 step: 296, loss is 0.23136183619499207\n",
      "epoch: 1 step: 297, loss is 0.6555410027503967\n",
      "epoch: 1 step: 298, loss is 0.06940391659736633\n",
      "epoch: 1 step: 299, loss is 0.0634239912033081\n",
      "epoch: 1 step: 300, loss is 0.48190587759017944\n",
      "epoch: 1 step: 301, loss is 0.5663076639175415\n",
      "epoch: 1 step: 302, loss is 0.3704090118408203\n",
      "epoch: 1 step: 303, loss is 0.07334533333778381\n",
      "epoch: 1 step: 304, loss is 0.09098739176988602\n",
      "epoch: 1 step: 305, loss is 0.15101400017738342\n",
      "epoch: 1 step: 306, loss is 0.32517650723457336\n",
      "epoch: 1 step: 307, loss is 0.05853941664099693\n",
      "epoch: 1 step: 308, loss is 0.24975882470607758\n",
      "epoch: 1 step: 309, loss is 0.09925667941570282\n",
      "epoch: 1 step: 310, loss is 0.865217387676239\n",
      "epoch: 1 step: 311, loss is 0.030967634171247482\n",
      "epoch: 1 step: 312, loss is 0.3886668384075165\n",
      "epoch: 1 step: 313, loss is 0.08837807178497314\n",
      "epoch: 1 step: 314, loss is 0.1968039572238922\n",
      "epoch: 1 step: 315, loss is 0.30188098549842834\n",
      "epoch: 1 step: 316, loss is 0.22518134117126465\n",
      "epoch: 1 step: 317, loss is 0.20836134254932404\n",
      "epoch: 1 step: 318, loss is 0.14337371289730072\n",
      "epoch: 1 step: 319, loss is 0.3125492036342621\n",
      "epoch: 1 step: 320, loss is 0.5289171934127808\n",
      "epoch: 1 step: 321, loss is 0.3228837251663208\n",
      "epoch: 1 step: 322, loss is 0.17632943391799927\n",
      "epoch: 1 step: 323, loss is 0.39853808283805847\n",
      "epoch: 1 step: 324, loss is 0.15022394061088562\n",
      "epoch: 1 step: 325, loss is 0.30129900574684143\n",
      "epoch: 1 step: 326, loss is 0.24605892598628998\n",
      "epoch: 1 step: 327, loss is 0.2399788200855255\n",
      "epoch: 1 step: 328, loss is 0.29397648572921753\n",
      "epoch: 1 step: 329, loss is 0.05073109269142151\n",
      "epoch: 1 step: 330, loss is 0.1943701058626175\n",
      "epoch: 1 step: 331, loss is 0.186749666929245\n",
      "epoch: 1 step: 332, loss is 0.07661106437444687\n",
      "epoch: 1 step: 333, loss is 0.10346318781375885\n",
      "epoch: 1 step: 334, loss is 0.4952208995819092\n",
      "epoch: 1 step: 335, loss is 0.23301248252391815\n",
      "epoch: 1 step: 336, loss is 0.27926161885261536\n",
      "epoch: 1 step: 337, loss is 0.17115075886249542\n",
      "epoch: 1 step: 338, loss is 0.11761052906513214\n",
      "epoch: 1 step: 339, loss is 0.24857407808303833\n",
      "epoch: 1 step: 340, loss is 0.22485415637493134\n",
      "epoch: 1 step: 341, loss is 0.1670868992805481\n",
      "epoch: 1 step: 342, loss is 0.14479312300682068\n",
      "epoch: 1 step: 343, loss is 0.3688966631889343\n",
      "epoch: 1 step: 344, loss is 0.057753365486860275\n",
      "epoch: 1 step: 345, loss is 0.04185975342988968\n",
      "epoch: 1 step: 346, loss is 0.11003182828426361\n",
      "epoch: 1 step: 347, loss is 0.030625637620687485\n",
      "epoch: 1 step: 348, loss is 0.5322091579437256\n",
      "epoch: 1 step: 349, loss is 0.18819159269332886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 350, loss is 0.15100015699863434\n",
      "epoch: 1 step: 351, loss is 0.178117036819458\n",
      "epoch: 1 step: 352, loss is 0.19426289200782776\n",
      "epoch: 1 step: 353, loss is 0.13013839721679688\n",
      "epoch: 1 step: 354, loss is 0.02224874123930931\n",
      "epoch: 1 step: 355, loss is 0.1651298999786377\n",
      "epoch: 1 step: 356, loss is 0.13923370838165283\n",
      "epoch: 1 step: 357, loss is 0.09570399671792984\n",
      "epoch: 1 step: 358, loss is 0.17957375943660736\n",
      "epoch: 1 step: 359, loss is 0.7028428316116333\n",
      "epoch: 1 step: 360, loss is 0.257169634103775\n",
      "epoch: 1 step: 361, loss is 0.05880412459373474\n",
      "epoch: 1 step: 362, loss is 0.11625021696090698\n",
      "epoch: 1 step: 363, loss is 0.40064123272895813\n",
      "epoch: 1 step: 364, loss is 0.4207502007484436\n",
      "epoch: 1 step: 365, loss is 0.3292776346206665\n",
      "epoch: 1 step: 366, loss is 0.03021877259016037\n",
      "epoch: 1 step: 367, loss is 0.20577846467494965\n",
      "epoch: 1 step: 368, loss is 0.07347355782985687\n",
      "epoch: 1 step: 369, loss is 0.21268638968467712\n",
      "epoch: 1 step: 370, loss is 0.25891658663749695\n",
      "epoch: 1 step: 371, loss is 0.07757827639579773\n",
      "epoch: 1 step: 372, loss is 0.03909033536911011\n",
      "epoch: 1 step: 373, loss is 0.20687083899974823\n",
      "epoch: 1 step: 374, loss is 0.145162895321846\n",
      "epoch: 1 step: 375, loss is 0.04964491352438927\n",
      "epoch: 1 step: 376, loss is 0.23767706751823425\n",
      "epoch: 1 step: 377, loss is 0.20324569940567017\n",
      "epoch: 1 step: 378, loss is 0.3009102940559387\n",
      "epoch: 1 step: 379, loss is 0.07085735350847244\n",
      "epoch: 1 step: 380, loss is 0.11008820682764053\n",
      "epoch: 1 step: 381, loss is 0.13192835450172424\n",
      "epoch: 1 step: 382, loss is 0.1185617446899414\n",
      "epoch: 1 step: 383, loss is 0.4087490439414978\n",
      "epoch: 1 step: 384, loss is 0.2649782598018646\n",
      "epoch: 1 step: 385, loss is 0.6200593113899231\n",
      "epoch: 1 step: 386, loss is 0.2587627172470093\n",
      "epoch: 1 step: 387, loss is 0.30526918172836304\n",
      "epoch: 1 step: 388, loss is 0.037917669862508774\n",
      "epoch: 1 step: 389, loss is 0.06533776223659515\n",
      "epoch: 1 step: 390, loss is 0.2122301459312439\n",
      "epoch: 1 step: 391, loss is 0.063897043466568\n",
      "epoch: 1 step: 392, loss is 0.32544875144958496\n",
      "epoch: 1 step: 393, loss is 0.23513956367969513\n",
      "epoch: 1 step: 394, loss is 0.13928864896297455\n",
      "epoch: 1 step: 395, loss is 0.18091222643852234\n",
      "epoch: 1 step: 396, loss is 0.17940111458301544\n",
      "epoch: 1 step: 397, loss is 0.13688190281391144\n",
      "epoch: 1 step: 398, loss is 0.4313735365867615\n",
      "epoch: 1 step: 399, loss is 0.05932013690471649\n",
      "epoch: 1 step: 400, loss is 0.37120357155799866\n",
      "epoch: 1 step: 401, loss is 0.3484007716178894\n",
      "epoch: 1 step: 402, loss is 0.063887819647789\n",
      "epoch: 1 step: 403, loss is 0.10918385535478592\n",
      "epoch: 1 step: 404, loss is 0.15831992030143738\n",
      "epoch: 1 step: 405, loss is 0.11790110170841217\n",
      "epoch: 1 step: 406, loss is 0.355755090713501\n",
      "epoch: 1 step: 407, loss is 0.12146714329719543\n",
      "epoch: 1 step: 408, loss is 0.10114014148712158\n",
      "epoch: 1 step: 409, loss is 0.32643812894821167\n",
      "epoch: 1 step: 410, loss is 0.033123429864645004\n",
      "epoch: 1 step: 411, loss is 0.13422326743602753\n",
      "epoch: 1 step: 412, loss is 0.1292591094970703\n",
      "epoch: 1 step: 413, loss is 0.3350502550601959\n",
      "epoch: 1 step: 414, loss is 0.13996858894824982\n",
      "epoch: 1 step: 415, loss is 0.09432101994752884\n",
      "epoch: 1 step: 416, loss is 0.07609251141548157\n",
      "epoch: 1 step: 417, loss is 0.19150708615779877\n",
      "epoch: 1 step: 418, loss is 0.012651784345507622\n",
      "epoch: 1 step: 419, loss is 0.04182575270533562\n",
      "epoch: 1 step: 420, loss is 0.14638188481330872\n",
      "epoch: 1 step: 421, loss is 0.0751120075583458\n",
      "epoch: 1 step: 422, loss is 0.16616810858249664\n",
      "epoch: 1 step: 423, loss is 0.033731505274772644\n",
      "epoch: 1 step: 424, loss is 0.08632350713014603\n",
      "epoch: 1 step: 425, loss is 0.22973687946796417\n",
      "epoch: 1 step: 426, loss is 0.576037585735321\n",
      "epoch: 1 step: 427, loss is 0.05792661011219025\n",
      "epoch: 1 step: 428, loss is 0.04394634813070297\n",
      "epoch: 1 step: 429, loss is 0.12968710064888\n",
      "epoch: 1 step: 430, loss is 0.1527213752269745\n",
      "epoch: 1 step: 431, loss is 0.1119287982583046\n",
      "epoch: 1 step: 432, loss is 0.2171502411365509\n",
      "epoch: 1 step: 433, loss is 0.05358494818210602\n",
      "epoch: 1 step: 434, loss is 0.17598815262317657\n",
      "epoch: 1 step: 435, loss is 0.08692483603954315\n",
      "epoch: 1 step: 436, loss is 0.11726848036050797\n",
      "epoch: 1 step: 437, loss is 0.30310654640197754\n",
      "epoch: 1 step: 438, loss is 0.047401752322912216\n",
      "epoch: 1 step: 439, loss is 0.16699232161045074\n",
      "epoch: 1 step: 440, loss is 0.08043239265680313\n",
      "epoch: 1 step: 441, loss is 0.0451098196208477\n",
      "epoch: 1 step: 442, loss is 0.05500231683254242\n",
      "epoch: 1 step: 443, loss is 0.0392165444791317\n",
      "epoch: 1 step: 444, loss is 0.5666540861129761\n",
      "epoch: 1 step: 445, loss is 0.027122976258397102\n",
      "epoch: 1 step: 446, loss is 0.38827285170555115\n",
      "epoch: 1 step: 447, loss is 0.029146023094654083\n",
      "epoch: 1 step: 448, loss is 0.041637420654296875\n",
      "epoch: 1 step: 449, loss is 0.3927779793739319\n",
      "epoch: 1 step: 450, loss is 0.31882965564727783\n",
      "epoch: 1 step: 451, loss is 0.09863525629043579\n",
      "epoch: 1 step: 452, loss is 0.2920491397380829\n",
      "epoch: 1 step: 453, loss is 0.05271214619278908\n",
      "epoch: 1 step: 454, loss is 0.021118560805916786\n",
      "epoch: 1 step: 455, loss is 0.15797275304794312\n",
      "epoch: 1 step: 456, loss is 0.22906117141246796\n",
      "epoch: 1 step: 457, loss is 0.29570242762565613\n",
      "epoch: 1 step: 458, loss is 0.223746195435524\n",
      "epoch: 1 step: 459, loss is 0.13028192520141602\n",
      "epoch: 1 step: 460, loss is 0.2573194205760956\n",
      "epoch: 1 step: 461, loss is 0.2662920355796814\n",
      "epoch: 1 step: 462, loss is 0.022065531462430954\n",
      "epoch: 1 step: 463, loss is 0.07814203202724457\n",
      "epoch: 1 step: 464, loss is 0.2670292258262634\n",
      "epoch: 1 step: 465, loss is 0.07685360312461853\n",
      "epoch: 1 step: 466, loss is 0.11393282562494278\n",
      "epoch: 1 step: 467, loss is 0.2259562611579895\n",
      "epoch: 1 step: 468, loss is 0.04226590692996979\n",
      "epoch: 1 step: 469, loss is 0.050052326172590256\n",
      "epoch: 1 step: 470, loss is 0.11466081440448761\n",
      "epoch: 1 step: 471, loss is 0.07378344982862473\n",
      "epoch: 1 step: 472, loss is 0.08200564235448837\n",
      "epoch: 1 step: 473, loss is 0.19986048340797424\n",
      "epoch: 1 step: 474, loss is 0.15793731808662415\n",
      "epoch: 1 step: 475, loss is 0.1004333421587944\n",
      "epoch: 1 step: 476, loss is 0.2006312906742096\n",
      "epoch: 1 step: 477, loss is 0.030221296474337578\n",
      "epoch: 1 step: 478, loss is 0.1064210757613182\n",
      "epoch: 1 step: 479, loss is 0.050465378910303116\n",
      "epoch: 1 step: 480, loss is 0.14268912374973297\n",
      "epoch: 1 step: 481, loss is 0.05031504109501839\n",
      "epoch: 1 step: 482, loss is 0.23204781115055084\n",
      "epoch: 1 step: 483, loss is 0.3759137988090515\n",
      "epoch: 1 step: 484, loss is 0.04043695330619812\n",
      "epoch: 1 step: 485, loss is 0.5286310911178589\n",
      "epoch: 1 step: 486, loss is 0.3172118365764618\n",
      "epoch: 1 step: 487, loss is 0.07916204631328583\n",
      "epoch: 1 step: 488, loss is 0.23013116419315338\n",
      "epoch: 1 step: 489, loss is 0.21549692749977112\n",
      "epoch: 1 step: 490, loss is 0.01749805174767971\n",
      "epoch: 1 step: 491, loss is 0.10456760227680206\n",
      "epoch: 1 step: 492, loss is 0.18691854178905487\n",
      "epoch: 1 step: 493, loss is 0.22638630867004395\n",
      "epoch: 1 step: 494, loss is 0.2657374143600464\n",
      "epoch: 1 step: 495, loss is 0.0820007398724556\n",
      "epoch: 1 step: 496, loss is 0.3269454836845398\n",
      "epoch: 1 step: 497, loss is 0.08251889795064926\n",
      "epoch: 1 step: 498, loss is 0.02450823225080967\n",
      "epoch: 1 step: 499, loss is 0.23111774027347565\n",
      "epoch: 1 step: 500, loss is 0.26234617829322815\n",
      "epoch: 1 step: 501, loss is 0.17657718062400818\n",
      "epoch: 1 step: 502, loss is 0.18105217814445496\n",
      "epoch: 1 step: 503, loss is 0.28920185565948486\n",
      "epoch: 1 step: 504, loss is 0.18450741469860077\n",
      "epoch: 1 step: 505, loss is 0.07026904076337814\n",
      "epoch: 1 step: 506, loss is 0.2209358960390091\n",
      "epoch: 1 step: 507, loss is 0.1468586027622223\n",
      "epoch: 1 step: 508, loss is 0.5282381176948547\n",
      "epoch: 1 step: 509, loss is 0.2863159775733948\n",
      "epoch: 1 step: 510, loss is 0.09168807417154312\n",
      "epoch: 1 step: 511, loss is 0.042605649679899216\n",
      "epoch: 1 step: 512, loss is 0.047232337296009064\n",
      "epoch: 1 step: 513, loss is 0.32931405305862427\n",
      "epoch: 1 step: 514, loss is 0.03920011594891548\n",
      "epoch: 1 step: 515, loss is 0.10831332206726074\n",
      "epoch: 1 step: 516, loss is 0.1366083025932312\n",
      "epoch: 1 step: 517, loss is 0.17408113181591034\n",
      "epoch: 1 step: 518, loss is 0.16720741987228394\n",
      "epoch: 1 step: 519, loss is 0.2062828093767166\n",
      "epoch: 1 step: 520, loss is 0.18398508429527283\n",
      "epoch: 1 step: 521, loss is 0.11492184549570084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 522, loss is 0.10779721289873123\n",
      "epoch: 1 step: 523, loss is 0.24831610918045044\n",
      "epoch: 1 step: 524, loss is 0.1394273042678833\n",
      "epoch: 1 step: 525, loss is 0.09465250372886658\n",
      "epoch: 1 step: 526, loss is 0.2404889166355133\n",
      "epoch: 1 step: 527, loss is 0.13177050650119781\n",
      "epoch: 1 step: 528, loss is 0.21349062025547028\n",
      "epoch: 1 step: 529, loss is 0.1194353699684143\n",
      "epoch: 1 step: 530, loss is 0.2565283179283142\n",
      "epoch: 1 step: 531, loss is 0.039831675589084625\n",
      "epoch: 1 step: 532, loss is 0.08793859928846359\n",
      "epoch: 1 step: 533, loss is 0.15323005616664886\n",
      "epoch: 1 step: 534, loss is 0.06748926639556885\n",
      "epoch: 1 step: 535, loss is 0.2148684561252594\n",
      "epoch: 1 step: 536, loss is 0.4421308934688568\n",
      "epoch: 1 step: 537, loss is 0.041479241102933884\n",
      "epoch: 1 step: 538, loss is 0.05381716415286064\n",
      "epoch: 1 step: 539, loss is 0.06971662491559982\n",
      "epoch: 1 step: 540, loss is 0.07796497642993927\n",
      "epoch: 1 step: 541, loss is 0.10505308955907822\n",
      "epoch: 1 step: 542, loss is 0.12726730108261108\n",
      "epoch: 1 step: 543, loss is 0.028174031525850296\n",
      "epoch: 1 step: 544, loss is 0.20734262466430664\n",
      "epoch: 1 step: 545, loss is 0.14722426235675812\n",
      "epoch: 1 step: 546, loss is 0.018981633707880974\n",
      "epoch: 1 step: 547, loss is 0.30173036456108093\n",
      "epoch: 1 step: 548, loss is 0.15655989944934845\n",
      "epoch: 1 step: 549, loss is 0.3115261495113373\n",
      "epoch: 1 step: 550, loss is 0.0927727222442627\n",
      "epoch: 1 step: 551, loss is 0.12826178967952728\n",
      "epoch: 1 step: 552, loss is 0.10420049726963043\n",
      "epoch: 1 step: 553, loss is 0.007452494464814663\n",
      "epoch: 1 step: 554, loss is 0.2769768238067627\n",
      "epoch: 1 step: 555, loss is 0.1963994950056076\n",
      "epoch: 1 step: 556, loss is 0.17365887761116028\n",
      "epoch: 1 step: 557, loss is 0.15491725504398346\n",
      "epoch: 1 step: 558, loss is 0.38548433780670166\n",
      "epoch: 1 step: 559, loss is 0.057717930525541306\n",
      "epoch: 1 step: 560, loss is 0.23498277366161346\n",
      "epoch: 1 step: 561, loss is 0.05213428661227226\n",
      "epoch: 1 step: 562, loss is 0.12682494521141052\n",
      "epoch: 1 step: 563, loss is 0.27430060505867004\n",
      "epoch: 1 step: 564, loss is 0.15294583141803741\n",
      "epoch: 1 step: 565, loss is 0.033170491456985474\n",
      "epoch: 1 step: 566, loss is 0.04369290918111801\n",
      "epoch: 1 step: 567, loss is 0.015258140861988068\n",
      "epoch: 1 step: 568, loss is 0.030972424894571304\n",
      "epoch: 1 step: 569, loss is 0.2993629276752472\n",
      "epoch: 1 step: 570, loss is 0.24966487288475037\n",
      "epoch: 1 step: 571, loss is 0.11977602541446686\n",
      "epoch: 1 step: 572, loss is 0.3914138078689575\n",
      "epoch: 1 step: 573, loss is 0.21344076097011566\n",
      "epoch: 1 step: 574, loss is 0.011948978528380394\n",
      "epoch: 1 step: 575, loss is 0.2479015290737152\n",
      "epoch: 1 step: 576, loss is 0.10164438188076019\n",
      "epoch: 1 step: 577, loss is 0.15389569103717804\n",
      "epoch: 1 step: 578, loss is 0.13880082964897156\n",
      "epoch: 1 step: 579, loss is 0.025454629212617874\n",
      "epoch: 1 step: 580, loss is 0.31586503982543945\n",
      "epoch: 1 step: 581, loss is 0.10131673514842987\n",
      "epoch: 1 step: 582, loss is 0.1802906095981598\n",
      "epoch: 1 step: 583, loss is 0.0422075130045414\n",
      "epoch: 1 step: 584, loss is 0.18895365297794342\n",
      "epoch: 1 step: 585, loss is 0.09911725670099258\n",
      "epoch: 1 step: 586, loss is 0.10550565272569656\n",
      "epoch: 1 step: 587, loss is 0.11934079974889755\n",
      "epoch: 1 step: 588, loss is 0.29439812898635864\n",
      "epoch: 1 step: 589, loss is 0.06520041078329086\n",
      "epoch: 1 step: 590, loss is 0.11345590651035309\n",
      "epoch: 1 step: 591, loss is 0.016556942835450172\n",
      "epoch: 1 step: 592, loss is 0.013387064449489117\n",
      "epoch: 1 step: 593, loss is 0.0571732223033905\n",
      "epoch: 1 step: 594, loss is 0.21655504405498505\n",
      "epoch: 1 step: 595, loss is 0.11215637624263763\n",
      "epoch: 1 step: 596, loss is 0.07004062831401825\n",
      "epoch: 1 step: 597, loss is 0.01701347343623638\n",
      "epoch: 1 step: 598, loss is 0.0818600133061409\n",
      "epoch: 1 step: 599, loss is 0.060329899191856384\n",
      "epoch: 1 step: 600, loss is 0.2134389579296112\n",
      "epoch: 1 step: 601, loss is 0.39739471673965454\n",
      "epoch: 1 step: 602, loss is 0.009422830305993557\n",
      "epoch: 1 step: 603, loss is 0.4829534590244293\n",
      "epoch: 1 step: 604, loss is 0.08382561802864075\n",
      "epoch: 1 step: 605, loss is 0.1253100335597992\n",
      "epoch: 1 step: 606, loss is 0.02304740995168686\n",
      "epoch: 1 step: 607, loss is 0.3576226830482483\n",
      "epoch: 1 step: 608, loss is 0.2772485017776489\n",
      "epoch: 1 step: 609, loss is 0.11447159945964813\n",
      "epoch: 1 step: 610, loss is 0.16015882790088654\n",
      "epoch: 1 step: 611, loss is 0.07300794124603271\n",
      "epoch: 1 step: 612, loss is 0.037712547928094864\n",
      "epoch: 1 step: 613, loss is 0.05333181843161583\n",
      "epoch: 1 step: 614, loss is 0.3218775987625122\n",
      "epoch: 1 step: 615, loss is 0.16894033551216125\n",
      "epoch: 1 step: 616, loss is 0.30378103256225586\n",
      "epoch: 1 step: 617, loss is 0.02134586311876774\n",
      "epoch: 1 step: 618, loss is 0.09462814033031464\n",
      "epoch: 1 step: 619, loss is 0.28487083315849304\n",
      "epoch: 1 step: 620, loss is 0.1822931170463562\n",
      "epoch: 1 step: 621, loss is 0.19231824576854706\n",
      "epoch: 1 step: 622, loss is 0.13968443870544434\n",
      "epoch: 1 step: 623, loss is 0.04975385218858719\n",
      "epoch: 1 step: 624, loss is 0.24438542127609253\n",
      "epoch: 1 step: 625, loss is 0.0215346347540617\n",
      "epoch: 1 step: 626, loss is 0.2448408454656601\n",
      "epoch: 1 step: 627, loss is 0.13090790808200836\n",
      "epoch: 1 step: 628, loss is 0.032735057175159454\n",
      "epoch: 1 step: 629, loss is 0.14440524578094482\n",
      "epoch: 1 step: 630, loss is 0.06369058787822723\n",
      "epoch: 1 step: 631, loss is 0.09045270085334778\n",
      "epoch: 1 step: 632, loss is 0.16277094185352325\n",
      "epoch: 1 step: 633, loss is 0.05235124006867409\n",
      "epoch: 1 step: 634, loss is 0.03238452225923538\n",
      "epoch: 1 step: 635, loss is 0.11765292286872864\n",
      "epoch: 1 step: 636, loss is 0.09777041524648666\n",
      "epoch: 1 step: 637, loss is 0.19763264060020447\n",
      "epoch: 1 step: 638, loss is 0.3351893424987793\n",
      "epoch: 1 step: 639, loss is 0.010080154985189438\n",
      "epoch: 1 step: 640, loss is 0.07811451703310013\n",
      "epoch: 1 step: 641, loss is 0.029020462185144424\n",
      "epoch: 1 step: 642, loss is 0.011357526294887066\n",
      "epoch: 1 step: 643, loss is 0.3004440665245056\n",
      "epoch: 1 step: 644, loss is 0.2705863118171692\n",
      "epoch: 1 step: 645, loss is 0.01761976070702076\n",
      "epoch: 1 step: 646, loss is 0.08916567265987396\n",
      "epoch: 1 step: 647, loss is 0.1082753837108612\n",
      "epoch: 1 step: 648, loss is 0.09589625149965286\n",
      "epoch: 1 step: 649, loss is 0.04469560459256172\n",
      "epoch: 1 step: 650, loss is 0.030918188393115997\n",
      "epoch: 1 step: 651, loss is 0.35540756583213806\n",
      "epoch: 1 step: 652, loss is 0.2523200213909149\n",
      "epoch: 1 step: 653, loss is 0.08670512586832047\n",
      "epoch: 1 step: 654, loss is 0.06372354179620743\n",
      "epoch: 1 step: 655, loss is 0.13513138890266418\n",
      "epoch: 1 step: 656, loss is 0.08502239733934402\n",
      "epoch: 1 step: 657, loss is 0.0698229968547821\n",
      "epoch: 1 step: 658, loss is 0.23280280828475952\n",
      "epoch: 1 step: 659, loss is 0.28012222051620483\n",
      "epoch: 1 step: 660, loss is 0.023122146725654602\n",
      "epoch: 1 step: 661, loss is 0.04987552762031555\n",
      "epoch: 1 step: 662, loss is 0.22297674417495728\n",
      "epoch: 1 step: 663, loss is 0.005879352800548077\n",
      "epoch: 1 step: 664, loss is 0.02703358232975006\n",
      "epoch: 1 step: 665, loss is 0.01794382743537426\n",
      "epoch: 1 step: 666, loss is 0.10379914194345474\n",
      "epoch: 1 step: 667, loss is 0.36937031149864197\n",
      "epoch: 1 step: 668, loss is 0.12868806719779968\n",
      "epoch: 1 step: 669, loss is 0.013169190846383572\n",
      "epoch: 1 step: 670, loss is 0.09044669568538666\n",
      "epoch: 1 step: 671, loss is 0.049702148884534836\n",
      "epoch: 1 step: 672, loss is 0.04347805306315422\n",
      "epoch: 1 step: 673, loss is 0.23373597860336304\n",
      "epoch: 1 step: 674, loss is 0.02537405863404274\n",
      "epoch: 1 step: 675, loss is 0.0908050537109375\n",
      "epoch: 1 step: 676, loss is 0.12168584018945694\n",
      "epoch: 1 step: 677, loss is 0.18826140463352203\n",
      "epoch: 1 step: 678, loss is 0.30954399704933167\n",
      "epoch: 1 step: 679, loss is 0.18930871784687042\n",
      "epoch: 1 step: 680, loss is 0.024736011400818825\n",
      "epoch: 1 step: 681, loss is 0.7234175801277161\n",
      "epoch: 1 step: 682, loss is 0.08899733424186707\n",
      "epoch: 1 step: 683, loss is 0.07579608261585236\n",
      "epoch: 1 step: 684, loss is 0.035699982196092606\n",
      "epoch: 1 step: 685, loss is 0.04597476124763489\n",
      "epoch: 1 step: 686, loss is 0.256898432970047\n",
      "epoch: 1 step: 687, loss is 0.12386341392993927\n",
      "epoch: 1 step: 688, loss is 0.014194128103554249\n",
      "epoch: 1 step: 689, loss is 0.1509624868631363\n",
      "epoch: 1 step: 690, loss is 0.0339658223092556\n",
      "epoch: 1 step: 691, loss is 0.11314219236373901\n",
      "epoch: 1 step: 692, loss is 0.027799859642982483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 693, loss is 0.027540216222405434\n",
      "epoch: 1 step: 694, loss is 0.008850938640534878\n",
      "epoch: 1 step: 695, loss is 0.02411147579550743\n",
      "epoch: 1 step: 696, loss is 0.15351097285747528\n",
      "epoch: 1 step: 697, loss is 0.004932492971420288\n",
      "epoch: 1 step: 698, loss is 0.37934738397598267\n",
      "epoch: 1 step: 699, loss is 0.12641601264476776\n",
      "epoch: 1 step: 700, loss is 0.08105283975601196\n",
      "epoch: 1 step: 701, loss is 0.2781510353088379\n",
      "epoch: 1 step: 702, loss is 0.45568183064460754\n",
      "epoch: 1 step: 703, loss is 0.12686043977737427\n",
      "epoch: 1 step: 704, loss is 0.19782616198062897\n",
      "epoch: 1 step: 705, loss is 0.0784536823630333\n",
      "epoch: 1 step: 706, loss is 0.10888228565454483\n",
      "epoch: 1 step: 707, loss is 0.2121647447347641\n",
      "epoch: 1 step: 708, loss is 0.09598977118730545\n",
      "epoch: 1 step: 709, loss is 0.37403392791748047\n",
      "epoch: 1 step: 710, loss is 0.1398908942937851\n",
      "epoch: 1 step: 711, loss is 0.13291901350021362\n",
      "epoch: 1 step: 712, loss is 0.07515129446983337\n",
      "epoch: 1 step: 713, loss is 0.06492391973733902\n",
      "epoch: 1 step: 714, loss is 0.10476380586624146\n",
      "epoch: 1 step: 715, loss is 0.06883236765861511\n",
      "epoch: 1 step: 716, loss is 0.1026858389377594\n",
      "epoch: 1 step: 717, loss is 0.19667185842990875\n",
      "epoch: 1 step: 718, loss is 0.1818787008523941\n",
      "epoch: 1 step: 719, loss is 0.0438433475792408\n",
      "epoch: 1 step: 720, loss is 0.10821262747049332\n",
      "epoch: 1 step: 721, loss is 0.02493252232670784\n",
      "epoch: 1 step: 722, loss is 0.16672702133655548\n",
      "epoch: 1 step: 723, loss is 0.14508269727230072\n",
      "epoch: 1 step: 724, loss is 0.053387485444545746\n",
      "epoch: 1 step: 725, loss is 0.07497942447662354\n",
      "epoch: 1 step: 726, loss is 0.11411295086145401\n",
      "epoch: 1 step: 727, loss is 0.05237066000699997\n",
      "epoch: 1 step: 728, loss is 0.24868549406528473\n",
      "epoch: 1 step: 729, loss is 0.1325424462556839\n",
      "epoch: 1 step: 730, loss is 0.035504329949617386\n",
      "epoch: 1 step: 731, loss is 0.06099360063672066\n",
      "epoch: 1 step: 732, loss is 0.0297611765563488\n",
      "epoch: 1 step: 733, loss is 0.1215352937579155\n",
      "epoch: 1 step: 734, loss is 0.04269316792488098\n",
      "epoch: 1 step: 735, loss is 0.0365765355527401\n",
      "epoch: 1 step: 736, loss is 0.10139281302690506\n",
      "epoch: 1 step: 737, loss is 0.06304997205734253\n",
      "epoch: 1 step: 738, loss is 0.07622359693050385\n",
      "epoch: 1 step: 739, loss is 0.019084755331277847\n",
      "epoch: 1 step: 740, loss is 0.032434556633234024\n",
      "epoch: 1 step: 741, loss is 0.019783956930041313\n",
      "epoch: 1 step: 742, loss is 0.133625328540802\n",
      "epoch: 1 step: 743, loss is 0.05389602109789848\n",
      "epoch: 1 step: 744, loss is 0.056198567152023315\n",
      "epoch: 1 step: 745, loss is 0.015306556597352028\n",
      "epoch: 1 step: 746, loss is 0.18934406340122223\n",
      "epoch: 1 step: 747, loss is 0.0032520724926143885\n",
      "epoch: 1 step: 748, loss is 0.15430912375450134\n",
      "epoch: 1 step: 749, loss is 0.0826607346534729\n",
      "epoch: 1 step: 750, loss is 0.05259275063872337\n",
      "epoch: 1 step: 751, loss is 0.009976452216506004\n",
      "epoch: 1 step: 752, loss is 0.05428885295987129\n",
      "epoch: 1 step: 753, loss is 0.006836432032287121\n",
      "epoch: 1 step: 754, loss is 0.07785087078809738\n",
      "epoch: 1 step: 755, loss is 0.12386883795261383\n",
      "epoch: 1 step: 756, loss is 0.2889326512813568\n",
      "epoch: 1 step: 757, loss is 0.3912053108215332\n",
      "epoch: 1 step: 758, loss is 0.09497664868831635\n",
      "epoch: 1 step: 759, loss is 0.14127515256404877\n",
      "epoch: 1 step: 760, loss is 0.16329430043697357\n",
      "epoch: 1 step: 761, loss is 0.24660830199718475\n",
      "epoch: 1 step: 762, loss is 0.1277495175600052\n",
      "epoch: 1 step: 763, loss is 0.008904686197638512\n",
      "epoch: 1 step: 764, loss is 0.10068824887275696\n",
      "epoch: 1 step: 765, loss is 0.1291297823190689\n",
      "epoch: 1 step: 766, loss is 0.14735768735408783\n",
      "epoch: 1 step: 767, loss is 0.2064807116985321\n",
      "epoch: 1 step: 768, loss is 0.08792831748723984\n",
      "epoch: 1 step: 769, loss is 0.017252933233976364\n",
      "epoch: 1 step: 770, loss is 0.01021804753690958\n",
      "epoch: 1 step: 771, loss is 0.05778966844081879\n",
      "epoch: 1 step: 772, loss is 0.048666130751371384\n",
      "epoch: 1 step: 773, loss is 0.12471716105937958\n",
      "epoch: 1 step: 774, loss is 0.08202393352985382\n",
      "epoch: 1 step: 775, loss is 0.09380435943603516\n",
      "epoch: 1 step: 776, loss is 0.10544179379940033\n",
      "epoch: 1 step: 777, loss is 0.09772957861423492\n",
      "epoch: 1 step: 778, loss is 0.021725794300436974\n",
      "epoch: 1 step: 779, loss is 0.014887621626257896\n",
      "epoch: 1 step: 780, loss is 0.05520128086209297\n",
      "epoch: 1 step: 781, loss is 0.004000004846602678\n",
      "epoch: 1 step: 782, loss is 0.06016860529780388\n",
      "epoch: 1 step: 783, loss is 0.11696114391088486\n",
      "epoch: 1 step: 784, loss is 0.0413687601685524\n",
      "epoch: 1 step: 785, loss is 0.06188370659947395\n",
      "epoch: 1 step: 786, loss is 0.188898503780365\n",
      "epoch: 1 step: 787, loss is 0.12559670209884644\n",
      "epoch: 1 step: 788, loss is 0.03295597806572914\n",
      "epoch: 1 step: 789, loss is 0.00881043542176485\n",
      "epoch: 1 step: 790, loss is 0.15806761384010315\n",
      "epoch: 1 step: 791, loss is 0.20298130810260773\n",
      "epoch: 1 step: 792, loss is 0.17911364138126373\n",
      "epoch: 1 step: 793, loss is 0.1764499396085739\n",
      "epoch: 1 step: 794, loss is 0.09302292764186859\n",
      "epoch: 1 step: 795, loss is 0.0675852820277214\n",
      "epoch: 1 step: 796, loss is 0.14234589040279388\n",
      "epoch: 1 step: 797, loss is 0.09066339582204819\n",
      "epoch: 1 step: 798, loss is 0.07163919508457184\n",
      "epoch: 1 step: 799, loss is 0.1213482990860939\n",
      "epoch: 1 step: 800, loss is 0.08615167438983917\n",
      "epoch: 1 step: 801, loss is 0.25441375374794006\n",
      "epoch: 1 step: 802, loss is 0.2659547030925751\n",
      "epoch: 1 step: 803, loss is 0.13862833380699158\n",
      "epoch: 1 step: 804, loss is 0.09740239381790161\n",
      "epoch: 1 step: 805, loss is 0.07396388798952103\n",
      "epoch: 1 step: 806, loss is 0.14892344176769257\n",
      "epoch: 1 step: 807, loss is 0.09763569384813309\n",
      "epoch: 1 step: 808, loss is 0.1310344934463501\n",
      "epoch: 1 step: 809, loss is 0.16855479776859283\n",
      "epoch: 1 step: 810, loss is 0.0411175936460495\n",
      "epoch: 1 step: 811, loss is 0.14537066221237183\n",
      "epoch: 1 step: 812, loss is 0.10276245325803757\n",
      "epoch: 1 step: 813, loss is 0.021468499675393105\n",
      "epoch: 1 step: 814, loss is 0.20439010858535767\n",
      "epoch: 1 step: 815, loss is 0.04995771497488022\n",
      "epoch: 1 step: 816, loss is 0.02629675529897213\n",
      "epoch: 1 step: 817, loss is 0.08504709601402283\n",
      "epoch: 1 step: 818, loss is 0.16590406000614166\n",
      "epoch: 1 step: 819, loss is 0.029127588495612144\n",
      "epoch: 1 step: 820, loss is 0.15587188303470612\n",
      "epoch: 1 step: 821, loss is 0.00522053986787796\n",
      "epoch: 1 step: 822, loss is 0.25533944368362427\n",
      "epoch: 1 step: 823, loss is 0.08555375784635544\n",
      "epoch: 1 step: 824, loss is 0.01766788214445114\n",
      "epoch: 1 step: 825, loss is 0.08758015930652618\n",
      "epoch: 1 step: 826, loss is 0.010021931491792202\n",
      "epoch: 1 step: 827, loss is 0.13099682331085205\n",
      "epoch: 1 step: 828, loss is 0.06392736732959747\n",
      "epoch: 1 step: 829, loss is 0.48705074191093445\n",
      "epoch: 1 step: 830, loss is 0.045380182564258575\n",
      "epoch: 1 step: 831, loss is 0.008032573387026787\n",
      "epoch: 1 step: 832, loss is 0.056272394955158234\n",
      "epoch: 1 step: 833, loss is 0.15155887603759766\n",
      "epoch: 1 step: 834, loss is 0.153687983751297\n",
      "epoch: 1 step: 835, loss is 0.04335618391633034\n",
      "epoch: 1 step: 836, loss is 0.0160842128098011\n",
      "epoch: 1 step: 837, loss is 0.015663577243685722\n",
      "epoch: 1 step: 838, loss is 0.07057351619005203\n",
      "epoch: 1 step: 839, loss is 0.15360379219055176\n",
      "epoch: 1 step: 840, loss is 0.08967117965221405\n",
      "epoch: 1 step: 841, loss is 0.202122762799263\n",
      "epoch: 1 step: 842, loss is 0.3106491267681122\n",
      "epoch: 1 step: 843, loss is 0.1045241579413414\n",
      "epoch: 1 step: 844, loss is 0.13041949272155762\n",
      "epoch: 1 step: 845, loss is 0.3521427810192108\n",
      "epoch: 1 step: 846, loss is 0.09067951142787933\n",
      "epoch: 1 step: 847, loss is 0.05767405778169632\n",
      "epoch: 1 step: 848, loss is 0.014692958444356918\n",
      "epoch: 1 step: 849, loss is 0.004246671684086323\n",
      "epoch: 1 step: 850, loss is 0.22921344637870789\n",
      "epoch: 1 step: 851, loss is 0.17346902191638947\n",
      "epoch: 1 step: 852, loss is 0.013515278697013855\n",
      "epoch: 1 step: 853, loss is 0.3778091371059418\n",
      "epoch: 1 step: 854, loss is 0.15052156150341034\n",
      "epoch: 1 step: 855, loss is 0.02386336959898472\n",
      "epoch: 1 step: 856, loss is 0.028277570381760597\n",
      "epoch: 1 step: 857, loss is 0.04116280376911163\n",
      "epoch: 1 step: 858, loss is 0.18111753463745117\n",
      "epoch: 1 step: 859, loss is 0.18299227952957153\n",
      "epoch: 1 step: 860, loss is 0.04722152277827263\n",
      "epoch: 1 step: 861, loss is 0.24214476346969604\n",
      "epoch: 1 step: 862, loss is 0.010552513413131237\n",
      "epoch: 1 step: 863, loss is 0.06466009467840195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 864, loss is 0.15190017223358154\n",
      "epoch: 1 step: 865, loss is 0.038339536637067795\n",
      "epoch: 1 step: 866, loss is 0.22408555448055267\n",
      "epoch: 1 step: 867, loss is 0.04005185887217522\n",
      "epoch: 1 step: 868, loss is 0.02768946811556816\n",
      "epoch: 1 step: 869, loss is 0.019322702661156654\n",
      "epoch: 1 step: 870, loss is 0.012362620793282986\n",
      "epoch: 1 step: 871, loss is 0.07627417892217636\n",
      "epoch: 1 step: 872, loss is 0.17202307283878326\n",
      "epoch: 1 step: 873, loss is 0.0032714547123759985\n",
      "epoch: 1 step: 874, loss is 0.011270343326032162\n",
      "epoch: 1 step: 875, loss is 0.013383056037127972\n",
      "epoch: 1 step: 876, loss is 0.10402186214923859\n",
      "epoch: 1 step: 877, loss is 0.23330187797546387\n",
      "epoch: 1 step: 878, loss is 0.5011972188949585\n",
      "epoch: 1 step: 879, loss is 0.12036632746458054\n",
      "epoch: 1 step: 880, loss is 0.01850488968193531\n",
      "epoch: 1 step: 881, loss is 0.0929601788520813\n",
      "epoch: 1 step: 882, loss is 0.1438855230808258\n",
      "epoch: 1 step: 883, loss is 0.1626630425453186\n",
      "epoch: 1 step: 884, loss is 0.008048216812312603\n",
      "epoch: 1 step: 885, loss is 0.05496814101934433\n",
      "epoch: 1 step: 886, loss is 0.08931025862693787\n",
      "epoch: 1 step: 887, loss is 0.14721760153770447\n",
      "epoch: 1 step: 888, loss is 0.06862065196037292\n",
      "epoch: 1 step: 889, loss is 0.05211738497018814\n",
      "epoch: 1 step: 890, loss is 0.13282468914985657\n",
      "epoch: 1 step: 891, loss is 0.03283372521400452\n",
      "epoch: 1 step: 892, loss is 0.024475734680891037\n",
      "epoch: 1 step: 893, loss is 0.01651025004684925\n",
      "epoch: 1 step: 894, loss is 0.022514762356877327\n",
      "epoch: 1 step: 895, loss is 0.015690907835960388\n",
      "epoch: 1 step: 896, loss is 0.44291672110557556\n",
      "epoch: 1 step: 897, loss is 0.011781937442719936\n",
      "epoch: 1 step: 898, loss is 0.016091186553239822\n",
      "epoch: 1 step: 899, loss is 0.1282980740070343\n",
      "epoch: 1 step: 900, loss is 0.04526776820421219\n",
      "epoch: 1 step: 901, loss is 0.08461099117994308\n",
      "epoch: 1 step: 902, loss is 0.022852230817079544\n",
      "epoch: 1 step: 903, loss is 0.008439396508038044\n",
      "epoch: 1 step: 904, loss is 0.020193319767713547\n",
      "epoch: 1 step: 905, loss is 0.06027999520301819\n",
      "epoch: 1 step: 906, loss is 0.12721891701221466\n",
      "epoch: 1 step: 907, loss is 0.05579811707139015\n",
      "epoch: 1 step: 908, loss is 0.22637200355529785\n",
      "epoch: 1 step: 909, loss is 0.007081789895892143\n",
      "epoch: 1 step: 910, loss is 0.04102274030447006\n",
      "epoch: 1 step: 911, loss is 0.13096651434898376\n",
      "epoch: 1 step: 912, loss is 0.008067675866186619\n",
      "epoch: 1 step: 913, loss is 0.28894442319869995\n",
      "epoch: 1 step: 914, loss is 0.053487226366996765\n",
      "epoch: 1 step: 915, loss is 0.019850486889481544\n",
      "epoch: 1 step: 916, loss is 0.17825157940387726\n",
      "epoch: 1 step: 917, loss is 0.0696244165301323\n",
      "epoch: 1 step: 918, loss is 0.13589848577976227\n",
      "epoch: 1 step: 919, loss is 0.030798478052020073\n",
      "epoch: 1 step: 920, loss is 0.09574972093105316\n",
      "epoch: 1 step: 921, loss is 0.02260199561715126\n",
      "epoch: 1 step: 922, loss is 0.07659485191106796\n",
      "epoch: 1 step: 923, loss is 0.010624500922858715\n",
      "epoch: 1 step: 924, loss is 0.10192539542913437\n",
      "epoch: 1 step: 925, loss is 0.14448387920856476\n",
      "epoch: 1 step: 926, loss is 0.4463270902633667\n",
      "epoch: 1 step: 927, loss is 0.059600360691547394\n",
      "epoch: 1 step: 928, loss is 0.02319359965622425\n",
      "epoch: 1 step: 929, loss is 0.011462931521236897\n",
      "epoch: 1 step: 930, loss is 0.0354076586663723\n",
      "epoch: 1 step: 931, loss is 0.10665279626846313\n",
      "epoch: 1 step: 932, loss is 0.12981556355953217\n",
      "epoch: 1 step: 933, loss is 0.1255323886871338\n",
      "epoch: 1 step: 934, loss is 0.06440657377243042\n",
      "epoch: 1 step: 935, loss is 0.13546901941299438\n",
      "epoch: 1 step: 936, loss is 0.06516651809215546\n",
      "epoch: 1 step: 937, loss is 0.060841772705316544\n",
      "epoch: 1 step: 938, loss is 0.0019801114685833454\n",
      "epoch: 1 step: 939, loss is 0.22069045901298523\n",
      "epoch: 1 step: 940, loss is 0.12303604930639267\n",
      "epoch: 1 step: 941, loss is 0.04673459753394127\n",
      "epoch: 1 step: 942, loss is 0.2767481505870819\n",
      "epoch: 1 step: 943, loss is 0.12652501463890076\n",
      "epoch: 1 step: 944, loss is 0.07365122437477112\n",
      "epoch: 1 step: 945, loss is 0.018284674733877182\n",
      "epoch: 1 step: 946, loss is 0.04274363070726395\n",
      "epoch: 1 step: 947, loss is 0.18611446022987366\n",
      "epoch: 1 step: 948, loss is 0.11196151375770569\n",
      "epoch: 1 step: 949, loss is 0.015469883568584919\n",
      "epoch: 1 step: 950, loss is 0.013646152801811695\n",
      "epoch: 1 step: 951, loss is 0.17845645546913147\n",
      "epoch: 1 step: 952, loss is 0.014544550329446793\n",
      "epoch: 1 step: 953, loss is 0.021894123405218124\n",
      "epoch: 1 step: 954, loss is 0.0685705617070198\n",
      "epoch: 1 step: 955, loss is 0.05037260055541992\n",
      "epoch: 1 step: 956, loss is 0.06933997571468353\n",
      "epoch: 1 step: 957, loss is 0.13640743494033813\n",
      "epoch: 1 step: 958, loss is 0.033621884882450104\n",
      "epoch: 1 step: 959, loss is 0.009806576184928417\n",
      "epoch: 1 step: 960, loss is 0.1359470784664154\n",
      "epoch: 1 step: 961, loss is 0.005244794767349958\n",
      "epoch: 1 step: 962, loss is 0.052402373403310776\n",
      "epoch: 1 step: 963, loss is 0.23402656614780426\n",
      "epoch: 1 step: 964, loss is 0.023946505039930344\n",
      "epoch: 1 step: 965, loss is 0.030290823429822922\n",
      "epoch: 1 step: 966, loss is 0.013486654497683048\n",
      "epoch: 1 step: 967, loss is 0.12573793530464172\n",
      "epoch: 1 step: 968, loss is 0.2742640972137451\n",
      "epoch: 1 step: 969, loss is 0.15474168956279755\n",
      "epoch: 1 step: 970, loss is 0.05838200822472572\n",
      "epoch: 1 step: 971, loss is 0.03618083894252777\n",
      "epoch: 1 step: 972, loss is 0.04201193526387215\n",
      "epoch: 1 step: 973, loss is 0.06939343363046646\n",
      "epoch: 1 step: 974, loss is 0.11556430160999298\n",
      "epoch: 1 step: 975, loss is 0.18702258169651031\n",
      "epoch: 1 step: 976, loss is 0.048080697655677795\n",
      "epoch: 1 step: 977, loss is 0.007765499409288168\n",
      "epoch: 1 step: 978, loss is 0.04268742352724075\n",
      "epoch: 1 step: 979, loss is 0.026387201622128487\n",
      "epoch: 1 step: 980, loss is 0.04905947297811508\n",
      "epoch: 1 step: 981, loss is 0.028615444898605347\n",
      "epoch: 1 step: 982, loss is 0.1844298243522644\n",
      "epoch: 1 step: 983, loss is 0.011321394704282284\n",
      "epoch: 1 step: 984, loss is 0.002276875078678131\n",
      "epoch: 1 step: 985, loss is 0.16108505427837372\n",
      "epoch: 1 step: 986, loss is 0.14546948671340942\n",
      "epoch: 1 step: 987, loss is 0.07742586731910706\n",
      "epoch: 1 step: 988, loss is 0.015060107223689556\n",
      "epoch: 1 step: 989, loss is 0.05289629474282265\n",
      "epoch: 1 step: 990, loss is 0.07591165602207184\n",
      "epoch: 1 step: 991, loss is 0.20685771107673645\n",
      "epoch: 1 step: 992, loss is 0.023569075390696526\n",
      "epoch: 1 step: 993, loss is 0.01460346020758152\n",
      "epoch: 1 step: 994, loss is 0.12860307097434998\n",
      "epoch: 1 step: 995, loss is 0.0838221088051796\n",
      "epoch: 1 step: 996, loss is 0.2659488022327423\n",
      "epoch: 1 step: 997, loss is 0.10463260114192963\n",
      "epoch: 1 step: 998, loss is 0.2922653555870056\n",
      "epoch: 1 step: 999, loss is 0.08151326328516006\n",
      "epoch: 1 step: 1000, loss is 0.09936258941888809\n",
      "epoch: 1 step: 1001, loss is 0.17242319881916046\n",
      "epoch: 1 step: 1002, loss is 0.0660630315542221\n",
      "epoch: 1 step: 1003, loss is 0.004246823024004698\n",
      "epoch: 1 step: 1004, loss is 0.004223733674734831\n",
      "epoch: 1 step: 1005, loss is 0.04149414226412773\n",
      "epoch: 1 step: 1006, loss is 0.14658379554748535\n",
      "epoch: 1 step: 1007, loss is 0.11888439208269119\n",
      "epoch: 1 step: 1008, loss is 0.15591572225093842\n",
      "epoch: 1 step: 1009, loss is 0.018220124766230583\n",
      "epoch: 1 step: 1010, loss is 0.09600386768579483\n",
      "epoch: 1 step: 1011, loss is 0.26132169365882874\n",
      "epoch: 1 step: 1012, loss is 0.04107871651649475\n",
      "epoch: 1 step: 1013, loss is 0.09273339807987213\n",
      "epoch: 1 step: 1014, loss is 0.08956494927406311\n",
      "epoch: 1 step: 1015, loss is 0.20875920355319977\n",
      "epoch: 1 step: 1016, loss is 0.2790728509426117\n",
      "epoch: 1 step: 1017, loss is 0.01549574639648199\n",
      "epoch: 1 step: 1018, loss is 0.09382294863462448\n",
      "epoch: 1 step: 1019, loss is 0.25846564769744873\n",
      "epoch: 1 step: 1020, loss is 0.41662612557411194\n",
      "epoch: 1 step: 1021, loss is 0.015836076810956\n",
      "epoch: 1 step: 1022, loss is 0.011845254339277744\n",
      "epoch: 1 step: 1023, loss is 0.01280118152499199\n",
      "epoch: 1 step: 1024, loss is 0.027859851717948914\n",
      "epoch: 1 step: 1025, loss is 0.08978145569562912\n",
      "epoch: 1 step: 1026, loss is 0.14793607592582703\n",
      "epoch: 1 step: 1027, loss is 0.164521262049675\n",
      "epoch: 1 step: 1028, loss is 0.10545771569013596\n",
      "epoch: 1 step: 1029, loss is 0.03034832328557968\n",
      "epoch: 1 step: 1030, loss is 0.2163100391626358\n",
      "epoch: 1 step: 1031, loss is 0.0977749451994896\n",
      "epoch: 1 step: 1032, loss is 0.024870997294783592\n",
      "epoch: 1 step: 1033, loss is 0.049661602824926376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1034, loss is 0.14198675751686096\n",
      "epoch: 1 step: 1035, loss is 0.06554936617612839\n",
      "epoch: 1 step: 1036, loss is 0.01079215295612812\n",
      "epoch: 1 step: 1037, loss is 0.09581349045038223\n",
      "epoch: 1 step: 1038, loss is 0.11530087888240814\n",
      "epoch: 1 step: 1039, loss is 0.03877302259206772\n",
      "epoch: 1 step: 1040, loss is 0.13716518878936768\n",
      "epoch: 1 step: 1041, loss is 0.04000960290431976\n",
      "epoch: 1 step: 1042, loss is 0.10766974836587906\n",
      "epoch: 1 step: 1043, loss is 0.02667236141860485\n",
      "epoch: 1 step: 1044, loss is 0.015621624886989594\n",
      "epoch: 1 step: 1045, loss is 0.11677470803260803\n",
      "epoch: 1 step: 1046, loss is 0.047826118767261505\n",
      "epoch: 1 step: 1047, loss is 0.11761388182640076\n",
      "epoch: 1 step: 1048, loss is 0.012074509635567665\n",
      "epoch: 1 step: 1049, loss is 0.1611384153366089\n",
      "epoch: 1 step: 1050, loss is 0.018501996994018555\n",
      "epoch: 1 step: 1051, loss is 0.07732710242271423\n",
      "epoch: 1 step: 1052, loss is 0.019553424790501595\n",
      "epoch: 1 step: 1053, loss is 0.058448225259780884\n",
      "epoch: 1 step: 1054, loss is 0.1896355003118515\n",
      "epoch: 1 step: 1055, loss is 0.05304862931370735\n",
      "epoch: 1 step: 1056, loss is 0.020096994936466217\n",
      "epoch: 1 step: 1057, loss is 0.32037055492401123\n",
      "epoch: 1 step: 1058, loss is 0.018808122724294662\n",
      "epoch: 1 step: 1059, loss is 0.013306017965078354\n",
      "epoch: 1 step: 1060, loss is 0.13653850555419922\n",
      "epoch: 1 step: 1061, loss is 0.04658694565296173\n",
      "epoch: 1 step: 1062, loss is 0.1261524111032486\n",
      "epoch: 1 step: 1063, loss is 0.01638743095099926\n",
      "epoch: 1 step: 1064, loss is 0.014801309444010258\n",
      "epoch: 1 step: 1065, loss is 0.18027009069919586\n",
      "epoch: 1 step: 1066, loss is 0.07263649255037308\n",
      "epoch: 1 step: 1067, loss is 0.06086751073598862\n",
      "epoch: 1 step: 1068, loss is 0.028631767258048058\n",
      "epoch: 1 step: 1069, loss is 0.10958908498287201\n",
      "epoch: 1 step: 1070, loss is 0.07702019810676575\n",
      "epoch: 1 step: 1071, loss is 0.022567320615053177\n",
      "epoch: 1 step: 1072, loss is 0.3592222034931183\n",
      "epoch: 1 step: 1073, loss is 0.15385852754116058\n",
      "epoch: 1 step: 1074, loss is 0.4004153609275818\n",
      "epoch: 1 step: 1075, loss is 0.2633056044578552\n",
      "epoch: 1 step: 1076, loss is 0.15595991909503937\n",
      "epoch: 1 step: 1077, loss is 0.010429460555315018\n",
      "epoch: 1 step: 1078, loss is 0.05358826369047165\n",
      "epoch: 1 step: 1079, loss is 0.16503682732582092\n",
      "epoch: 1 step: 1080, loss is 0.22826647758483887\n",
      "epoch: 1 step: 1081, loss is 0.22512131929397583\n",
      "epoch: 1 step: 1082, loss is 0.18696218729019165\n",
      "epoch: 1 step: 1083, loss is 0.04011329263448715\n",
      "epoch: 1 step: 1084, loss is 0.009135992266237736\n",
      "epoch: 1 step: 1085, loss is 0.08754564076662064\n",
      "epoch: 1 step: 1086, loss is 0.08275430649518967\n",
      "epoch: 1 step: 1087, loss is 0.07503397017717361\n",
      "epoch: 1 step: 1088, loss is 0.024164404720067978\n",
      "epoch: 1 step: 1089, loss is 0.08278531581163406\n",
      "epoch: 1 step: 1090, loss is 0.07254786044359207\n",
      "epoch: 1 step: 1091, loss is 0.355133593082428\n",
      "epoch: 1 step: 1092, loss is 0.17544330656528473\n",
      "epoch: 1 step: 1093, loss is 0.31307947635650635\n",
      "epoch: 1 step: 1094, loss is 0.08413390070199966\n",
      "epoch: 1 step: 1095, loss is 0.10230129957199097\n",
      "epoch: 1 step: 1096, loss is 0.05008627474308014\n",
      "epoch: 1 step: 1097, loss is 0.013211843557655811\n",
      "epoch: 1 step: 1098, loss is 0.1888749748468399\n",
      "epoch: 1 step: 1099, loss is 0.0387943759560585\n",
      "epoch: 1 step: 1100, loss is 0.02795221284031868\n",
      "epoch: 1 step: 1101, loss is 0.00508382311090827\n",
      "epoch: 1 step: 1102, loss is 0.06757671386003494\n",
      "epoch: 1 step: 1103, loss is 0.19338777661323547\n",
      "epoch: 1 step: 1104, loss is 0.17027752101421356\n",
      "epoch: 1 step: 1105, loss is 0.024614643305540085\n",
      "epoch: 1 step: 1106, loss is 0.2548072338104248\n",
      "epoch: 1 step: 1107, loss is 0.028974955901503563\n",
      "epoch: 1 step: 1108, loss is 0.06395988911390305\n",
      "epoch: 1 step: 1109, loss is 0.06671136617660522\n",
      "epoch: 1 step: 1110, loss is 0.049067750573158264\n",
      "epoch: 1 step: 1111, loss is 0.07045507431030273\n",
      "epoch: 1 step: 1112, loss is 0.028013499453663826\n",
      "epoch: 1 step: 1113, loss is 0.007314175833016634\n",
      "epoch: 1 step: 1114, loss is 0.07229693979024887\n",
      "epoch: 1 step: 1115, loss is 0.008455364033579826\n",
      "epoch: 1 step: 1116, loss is 0.011761710979044437\n",
      "epoch: 1 step: 1117, loss is 0.16488996148109436\n",
      "epoch: 1 step: 1118, loss is 0.04193739593029022\n",
      "epoch: 1 step: 1119, loss is 0.07602043449878693\n",
      "epoch: 1 step: 1120, loss is 0.15827986598014832\n",
      "epoch: 1 step: 1121, loss is 0.08467907458543777\n",
      "epoch: 1 step: 1122, loss is 0.019030999392271042\n",
      "epoch: 1 step: 1123, loss is 0.008649327792227268\n",
      "epoch: 1 step: 1124, loss is 0.002715153619647026\n",
      "epoch: 1 step: 1125, loss is 0.03555591404438019\n",
      "epoch: 1 step: 1126, loss is 0.03228454291820526\n",
      "epoch: 1 step: 1127, loss is 0.10766316950321198\n",
      "epoch: 1 step: 1128, loss is 0.08826923370361328\n",
      "epoch: 1 step: 1129, loss is 0.05781947821378708\n",
      "epoch: 1 step: 1130, loss is 0.009241179563105106\n",
      "epoch: 1 step: 1131, loss is 0.007479378022253513\n",
      "epoch: 1 step: 1132, loss is 0.027221590280532837\n",
      "epoch: 1 step: 1133, loss is 0.0011454347986727953\n",
      "epoch: 1 step: 1134, loss is 0.007662308868020773\n",
      "epoch: 1 step: 1135, loss is 0.09072273224592209\n",
      "epoch: 1 step: 1136, loss is 0.056138213723897934\n",
      "epoch: 1 step: 1137, loss is 0.10134797543287277\n",
      "epoch: 1 step: 1138, loss is 0.07779604196548462\n",
      "epoch: 1 step: 1139, loss is 0.045360904186964035\n",
      "epoch: 1 step: 1140, loss is 0.029689157381653786\n",
      "epoch: 1 step: 1141, loss is 0.006764138583093882\n",
      "epoch: 1 step: 1142, loss is 0.07641304284334183\n",
      "epoch: 1 step: 1143, loss is 0.08756142854690552\n",
      "epoch: 1 step: 1144, loss is 0.1734888255596161\n",
      "epoch: 1 step: 1145, loss is 0.12902894616127014\n",
      "epoch: 1 step: 1146, loss is 0.04571564868092537\n",
      "epoch: 1 step: 1147, loss is 0.1604585498571396\n",
      "epoch: 1 step: 1148, loss is 0.011356119066476822\n",
      "epoch: 1 step: 1149, loss is 0.1349131017923355\n",
      "epoch: 1 step: 1150, loss is 0.021388772875070572\n",
      "epoch: 1 step: 1151, loss is 0.14017540216445923\n",
      "epoch: 1 step: 1152, loss is 0.3589681386947632\n",
      "epoch: 1 step: 1153, loss is 0.002305185655131936\n",
      "epoch: 1 step: 1154, loss is 0.022820768877863884\n",
      "epoch: 1 step: 1155, loss is 0.008932385593652725\n",
      "epoch: 1 step: 1156, loss is 0.22245058417320251\n",
      "epoch: 1 step: 1157, loss is 0.029522281140089035\n",
      "epoch: 1 step: 1158, loss is 0.21462036669254303\n",
      "epoch: 1 step: 1159, loss is 0.02158079482614994\n",
      "epoch: 1 step: 1160, loss is 0.04265432432293892\n",
      "epoch: 1 step: 1161, loss is 0.10775269567966461\n",
      "epoch: 1 step: 1162, loss is 0.08100688457489014\n",
      "epoch: 1 step: 1163, loss is 0.1596584916114807\n",
      "epoch: 1 step: 1164, loss is 0.10581748187541962\n",
      "epoch: 1 step: 1165, loss is 0.04551466554403305\n",
      "epoch: 1 step: 1166, loss is 0.08260148763656616\n",
      "epoch: 1 step: 1167, loss is 0.02051372081041336\n",
      "epoch: 1 step: 1168, loss is 0.10890678316354752\n",
      "epoch: 1 step: 1169, loss is 0.18452200293540955\n",
      "epoch: 1 step: 1170, loss is 0.11425681412220001\n",
      "epoch: 1 step: 1171, loss is 0.18351735174655914\n",
      "epoch: 1 step: 1172, loss is 0.14284031093120575\n",
      "epoch: 1 step: 1173, loss is 0.3380402624607086\n",
      "epoch: 1 step: 1174, loss is 0.16561603546142578\n",
      "epoch: 1 step: 1175, loss is 0.060010265558958054\n",
      "epoch: 1 step: 1176, loss is 0.16974645853042603\n",
      "epoch: 1 step: 1177, loss is 0.031065596267580986\n",
      "epoch: 1 step: 1178, loss is 0.2575552463531494\n",
      "epoch: 1 step: 1179, loss is 0.07444020360708237\n",
      "epoch: 1 step: 1180, loss is 0.03578421473503113\n",
      "epoch: 1 step: 1181, loss is 0.2207961231470108\n",
      "epoch: 1 step: 1182, loss is 0.04364097863435745\n",
      "epoch: 1 step: 1183, loss is 0.18885259330272675\n",
      "epoch: 1 step: 1184, loss is 0.13523918390274048\n",
      "epoch: 1 step: 1185, loss is 0.0049292221665382385\n",
      "epoch: 1 step: 1186, loss is 0.26155251264572144\n",
      "epoch: 1 step: 1187, loss is 0.14677715301513672\n",
      "epoch: 1 step: 1188, loss is 0.018188226968050003\n",
      "epoch: 1 step: 1189, loss is 0.014891302213072777\n",
      "epoch: 1 step: 1190, loss is 0.18363891541957855\n",
      "epoch: 1 step: 1191, loss is 0.16338767111301422\n",
      "epoch: 1 step: 1192, loss is 0.010793861001729965\n",
      "epoch: 1 step: 1193, loss is 0.11290404945611954\n",
      "epoch: 1 step: 1194, loss is 0.05617918074131012\n",
      "epoch: 1 step: 1195, loss is 0.029551619663834572\n",
      "epoch: 1 step: 1196, loss is 0.1550482213497162\n",
      "epoch: 1 step: 1197, loss is 0.013662687502801418\n",
      "epoch: 1 step: 1198, loss is 0.0880647748708725\n",
      "epoch: 1 step: 1199, loss is 0.13565701246261597\n",
      "epoch: 1 step: 1200, loss is 0.11940647661685944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1201, loss is 0.029598090797662735\n",
      "epoch: 1 step: 1202, loss is 0.06141181290149689\n",
      "epoch: 1 step: 1203, loss is 0.09625694155693054\n",
      "epoch: 1 step: 1204, loss is 0.0515173114836216\n",
      "epoch: 1 step: 1205, loss is 0.007538415491580963\n",
      "epoch: 1 step: 1206, loss is 0.0432145781815052\n",
      "epoch: 1 step: 1207, loss is 0.050306640565395355\n",
      "epoch: 1 step: 1208, loss is 0.09341582655906677\n",
      "epoch: 1 step: 1209, loss is 0.05677484720945358\n",
      "epoch: 1 step: 1210, loss is 0.014183803461492062\n",
      "epoch: 1 step: 1211, loss is 0.01457598339766264\n",
      "epoch: 1 step: 1212, loss is 0.1587926596403122\n",
      "epoch: 1 step: 1213, loss is 0.1530013084411621\n",
      "epoch: 1 step: 1214, loss is 0.008268073201179504\n",
      "epoch: 1 step: 1215, loss is 0.04427216202020645\n",
      "epoch: 1 step: 1216, loss is 0.09464527666568756\n",
      "epoch: 1 step: 1217, loss is 0.029706323519349098\n",
      "epoch: 1 step: 1218, loss is 0.010507545433938503\n",
      "epoch: 1 step: 1219, loss is 0.01144428364932537\n",
      "epoch: 1 step: 1220, loss is 0.1324881911277771\n",
      "epoch: 1 step: 1221, loss is 0.11885588616132736\n",
      "epoch: 1 step: 1222, loss is 0.01846717670559883\n",
      "epoch: 1 step: 1223, loss is 0.0043191732838749886\n",
      "epoch: 1 step: 1224, loss is 0.3072415888309479\n",
      "epoch: 1 step: 1225, loss is 0.24490205943584442\n",
      "epoch: 1 step: 1226, loss is 0.1346093863248825\n",
      "epoch: 1 step: 1227, loss is 0.008118873462080956\n",
      "epoch: 1 step: 1228, loss is 0.20652954280376434\n",
      "epoch: 1 step: 1229, loss is 0.015405010432004929\n",
      "epoch: 1 step: 1230, loss is 0.24132287502288818\n",
      "epoch: 1 step: 1231, loss is 0.025775112211704254\n",
      "epoch: 1 step: 1232, loss is 0.04678761959075928\n",
      "epoch: 1 step: 1233, loss is 0.0284509789198637\n",
      "epoch: 1 step: 1234, loss is 0.04448879137635231\n",
      "epoch: 1 step: 1235, loss is 0.030081842094659805\n",
      "epoch: 1 step: 1236, loss is 0.12393689900636673\n",
      "epoch: 1 step: 1237, loss is 0.03837282955646515\n",
      "epoch: 1 step: 1238, loss is 0.006826229393482208\n",
      "epoch: 1 step: 1239, loss is 0.08063889294862747\n",
      "epoch: 1 step: 1240, loss is 0.055114272981882095\n",
      "epoch: 1 step: 1241, loss is 0.13943131268024445\n",
      "epoch: 1 step: 1242, loss is 0.04867471009492874\n",
      "epoch: 1 step: 1243, loss is 0.16544078290462494\n",
      "epoch: 1 step: 1244, loss is 0.0771791860461235\n",
      "epoch: 1 step: 1245, loss is 0.39788618683815\n",
      "epoch: 1 step: 1246, loss is 0.020263705402612686\n",
      "epoch: 1 step: 1247, loss is 0.10003628581762314\n",
      "epoch: 1 step: 1248, loss is 0.10504989326000214\n",
      "epoch: 1 step: 1249, loss is 0.14357158541679382\n",
      "epoch: 1 step: 1250, loss is 0.1286180466413498\n",
      "epoch: 1 step: 1251, loss is 0.1401032656431198\n",
      "epoch: 1 step: 1252, loss is 0.05324969068169594\n",
      "epoch: 1 step: 1253, loss is 0.10456067323684692\n",
      "epoch: 1 step: 1254, loss is 0.06096656620502472\n",
      "epoch: 1 step: 1255, loss is 0.08974277228116989\n",
      "epoch: 1 step: 1256, loss is 0.05125570669770241\n",
      "epoch: 1 step: 1257, loss is 0.018240422010421753\n",
      "epoch: 1 step: 1258, loss is 0.021836047992110252\n",
      "epoch: 1 step: 1259, loss is 0.127867192029953\n",
      "epoch: 1 step: 1260, loss is 0.36910146474838257\n",
      "epoch: 1 step: 1261, loss is 0.18736401200294495\n",
      "epoch: 1 step: 1262, loss is 0.12860584259033203\n",
      "epoch: 1 step: 1263, loss is 0.01921791397035122\n",
      "epoch: 1 step: 1264, loss is 0.07786236703395844\n",
      "epoch: 1 step: 1265, loss is 0.11517278105020523\n",
      "epoch: 1 step: 1266, loss is 0.010328237898647785\n",
      "epoch: 1 step: 1267, loss is 0.02198377437889576\n",
      "epoch: 1 step: 1268, loss is 0.1398051530122757\n",
      "epoch: 1 step: 1269, loss is 0.03565824776887894\n",
      "epoch: 1 step: 1270, loss is 0.0034325027372688055\n",
      "epoch: 1 step: 1271, loss is 0.16907261312007904\n",
      "epoch: 1 step: 1272, loss is 0.17990483343601227\n",
      "epoch: 1 step: 1273, loss is 0.044068384915590286\n",
      "epoch: 1 step: 1274, loss is 0.18938158452510834\n",
      "epoch: 1 step: 1275, loss is 0.04274473711848259\n",
      "epoch: 1 step: 1276, loss is 0.0202648788690567\n",
      "epoch: 1 step: 1277, loss is 0.009963244199752808\n",
      "epoch: 1 step: 1278, loss is 0.055798958986997604\n",
      "epoch: 1 step: 1279, loss is 0.01807437092065811\n",
      "epoch: 1 step: 1280, loss is 0.07419977337121964\n",
      "epoch: 1 step: 1281, loss is 0.02793779969215393\n",
      "epoch: 1 step: 1282, loss is 0.1534968912601471\n",
      "epoch: 1 step: 1283, loss is 0.0141495605930686\n",
      "epoch: 1 step: 1284, loss is 0.023752665147185326\n",
      "epoch: 1 step: 1285, loss is 0.013831323012709618\n",
      "epoch: 1 step: 1286, loss is 0.0270713958889246\n",
      "epoch: 1 step: 1287, loss is 0.0713859498500824\n",
      "epoch: 1 step: 1288, loss is 0.02841358818113804\n",
      "epoch: 1 step: 1289, loss is 0.05059962347149849\n",
      "epoch: 1 step: 1290, loss is 0.03493949770927429\n",
      "epoch: 1 step: 1291, loss is 0.2442854642868042\n",
      "epoch: 1 step: 1292, loss is 0.009153041057288647\n",
      "epoch: 1 step: 1293, loss is 0.022380400449037552\n",
      "epoch: 1 step: 1294, loss is 0.19911135733127594\n",
      "epoch: 1 step: 1295, loss is 0.12703564763069153\n",
      "epoch: 1 step: 1296, loss is 0.011191608384251595\n",
      "epoch: 1 step: 1297, loss is 0.02874753810465336\n",
      "epoch: 1 step: 1298, loss is 0.0015375716611742973\n",
      "epoch: 1 step: 1299, loss is 0.06572061032056808\n",
      "epoch: 1 step: 1300, loss is 0.08464545756578445\n",
      "epoch: 1 step: 1301, loss is 0.009455794468522072\n",
      "epoch: 1 step: 1302, loss is 0.00353533448651433\n",
      "epoch: 1 step: 1303, loss is 0.019437158480286598\n",
      "epoch: 1 step: 1304, loss is 0.0036327738780528307\n",
      "epoch: 1 step: 1305, loss is 0.013886859640479088\n",
      "epoch: 1 step: 1306, loss is 0.01124495081603527\n",
      "epoch: 1 step: 1307, loss is 0.00783092062920332\n",
      "epoch: 1 step: 1308, loss is 0.021679403260350227\n",
      "epoch: 1 step: 1309, loss is 0.15032421052455902\n",
      "epoch: 1 step: 1310, loss is 0.06279370933771133\n",
      "epoch: 1 step: 1311, loss is 0.1417485922574997\n",
      "epoch: 1 step: 1312, loss is 0.0036280504427850246\n",
      "epoch: 1 step: 1313, loss is 0.05135548859834671\n",
      "epoch: 1 step: 1314, loss is 0.010802698321640491\n",
      "epoch: 1 step: 1315, loss is 0.03176698088645935\n",
      "epoch: 1 step: 1316, loss is 0.18495580554008484\n",
      "epoch: 1 step: 1317, loss is 0.032475803047418594\n",
      "epoch: 1 step: 1318, loss is 0.002405639039352536\n",
      "epoch: 1 step: 1319, loss is 0.03701053932309151\n",
      "epoch: 1 step: 1320, loss is 0.11921054124832153\n",
      "epoch: 1 step: 1321, loss is 0.005852518603205681\n",
      "epoch: 1 step: 1322, loss is 0.013735492713749409\n",
      "epoch: 1 step: 1323, loss is 0.017754219472408295\n",
      "epoch: 1 step: 1324, loss is 0.007341188844293356\n",
      "epoch: 1 step: 1325, loss is 0.004405598156154156\n",
      "epoch: 1 step: 1326, loss is 0.006973285228013992\n",
      "epoch: 1 step: 1327, loss is 0.01361064612865448\n",
      "epoch: 1 step: 1328, loss is 0.14079032838344574\n",
      "epoch: 1 step: 1329, loss is 0.22444215416908264\n",
      "epoch: 1 step: 1330, loss is 0.05629242584109306\n",
      "epoch: 1 step: 1331, loss is 0.2175734043121338\n",
      "epoch: 1 step: 1332, loss is 0.09294579178094864\n",
      "epoch: 1 step: 1333, loss is 0.25859424471855164\n",
      "epoch: 1 step: 1334, loss is 0.016545213758945465\n",
      "epoch: 1 step: 1335, loss is 0.24582302570343018\n",
      "epoch: 1 step: 1336, loss is 0.1494358628988266\n",
      "epoch: 1 step: 1337, loss is 0.3011852502822876\n",
      "epoch: 1 step: 1338, loss is 0.005818033125251532\n",
      "epoch: 1 step: 1339, loss is 0.150627002120018\n",
      "epoch: 1 step: 1340, loss is 0.04032992571592331\n",
      "epoch: 1 step: 1341, loss is 0.048284851014614105\n",
      "epoch: 1 step: 1342, loss is 0.045161738991737366\n",
      "epoch: 1 step: 1343, loss is 0.048591699451208115\n",
      "epoch: 1 step: 1344, loss is 0.006629281211644411\n",
      "epoch: 1 step: 1345, loss is 0.042876213788986206\n",
      "epoch: 1 step: 1346, loss is 0.07151389122009277\n",
      "epoch: 1 step: 1347, loss is 0.05530840903520584\n",
      "epoch: 1 step: 1348, loss is 0.027171427384018898\n",
      "epoch: 1 step: 1349, loss is 0.2031766176223755\n",
      "epoch: 1 step: 1350, loss is 0.18821924924850464\n",
      "epoch: 1 step: 1351, loss is 0.007448806427419186\n",
      "epoch: 1 step: 1352, loss is 0.10261013358831406\n",
      "epoch: 1 step: 1353, loss is 0.18250642716884613\n",
      "epoch: 1 step: 1354, loss is 0.11091367900371552\n",
      "epoch: 1 step: 1355, loss is 0.020323336124420166\n",
      "epoch: 1 step: 1356, loss is 0.014285167679190636\n",
      "epoch: 1 step: 1357, loss is 0.0012793641071766615\n",
      "epoch: 1 step: 1358, loss is 0.18249906599521637\n",
      "epoch: 1 step: 1359, loss is 0.06674159318208694\n",
      "epoch: 1 step: 1360, loss is 0.04119718447327614\n",
      "epoch: 1 step: 1361, loss is 0.013793271966278553\n",
      "epoch: 1 step: 1362, loss is 0.01807277649641037\n",
      "epoch: 1 step: 1363, loss is 0.14837124943733215\n",
      "epoch: 1 step: 1364, loss is 0.2256208211183548\n",
      "epoch: 1 step: 1365, loss is 0.06476234644651413\n",
      "epoch: 1 step: 1366, loss is 0.1404813826084137\n",
      "epoch: 1 step: 1367, loss is 0.1746857762336731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1368, loss is 0.024640314280986786\n",
      "epoch: 1 step: 1369, loss is 0.010188971646130085\n",
      "epoch: 1 step: 1370, loss is 0.005057030823081732\n",
      "epoch: 1 step: 1371, loss is 0.16682879626750946\n",
      "epoch: 1 step: 1372, loss is 0.0715051218867302\n",
      "epoch: 1 step: 1373, loss is 0.008286496624350548\n",
      "epoch: 1 step: 1374, loss is 0.013482420705258846\n",
      "epoch: 1 step: 1375, loss is 0.06715387105941772\n",
      "epoch: 1 step: 1376, loss is 0.07105474919080734\n",
      "epoch: 1 step: 1377, loss is 0.08097165822982788\n",
      "epoch: 1 step: 1378, loss is 0.12408548593521118\n",
      "epoch: 1 step: 1379, loss is 0.024133961647748947\n",
      "epoch: 1 step: 1380, loss is 0.17873510718345642\n",
      "epoch: 1 step: 1381, loss is 0.06254412978887558\n",
      "epoch: 1 step: 1382, loss is 0.06938114762306213\n",
      "epoch: 1 step: 1383, loss is 0.10394518077373505\n",
      "epoch: 1 step: 1384, loss is 0.168577641248703\n",
      "epoch: 1 step: 1385, loss is 0.04276799038052559\n",
      "epoch: 1 step: 1386, loss is 0.038972724229097366\n",
      "epoch: 1 step: 1387, loss is 0.12333432585000992\n",
      "epoch: 1 step: 1388, loss is 0.01245926320552826\n",
      "epoch: 1 step: 1389, loss is 0.09982462972402573\n",
      "epoch: 1 step: 1390, loss is 0.03866945207118988\n",
      "epoch: 1 step: 1391, loss is 0.041336268186569214\n",
      "epoch: 1 step: 1392, loss is 0.13970157504081726\n",
      "epoch: 1 step: 1393, loss is 0.1143902987241745\n",
      "epoch: 1 step: 1394, loss is 0.06776551157236099\n",
      "epoch: 1 step: 1395, loss is 0.21166753768920898\n",
      "epoch: 1 step: 1396, loss is 0.07019451260566711\n",
      "epoch: 1 step: 1397, loss is 0.11401759088039398\n",
      "epoch: 1 step: 1398, loss is 0.021228954195976257\n",
      "epoch: 1 step: 1399, loss is 0.283858060836792\n",
      "epoch: 1 step: 1400, loss is 0.020320575684309006\n",
      "epoch: 1 step: 1401, loss is 0.044751010835170746\n",
      "epoch: 1 step: 1402, loss is 0.05732673034071922\n",
      "epoch: 1 step: 1403, loss is 0.05926917865872383\n",
      "epoch: 1 step: 1404, loss is 0.06431777030229568\n",
      "epoch: 1 step: 1405, loss is 0.07757364958524704\n",
      "epoch: 1 step: 1406, loss is 0.21951104700565338\n",
      "epoch: 1 step: 1407, loss is 0.00971884373575449\n",
      "epoch: 1 step: 1408, loss is 0.02194020338356495\n",
      "epoch: 1 step: 1409, loss is 0.16108311712741852\n",
      "epoch: 1 step: 1410, loss is 0.03257866948843002\n",
      "epoch: 1 step: 1411, loss is 0.18540561199188232\n",
      "epoch: 1 step: 1412, loss is 0.058708783239126205\n",
      "epoch: 1 step: 1413, loss is 0.14694397151470184\n",
      "epoch: 1 step: 1414, loss is 0.02087993361055851\n",
      "epoch: 1 step: 1415, loss is 0.06428837776184082\n",
      "epoch: 1 step: 1416, loss is 0.025159699842333794\n",
      "epoch: 1 step: 1417, loss is 0.03381915017962456\n",
      "epoch: 1 step: 1418, loss is 0.03860880434513092\n",
      "epoch: 1 step: 1419, loss is 0.016725294291973114\n",
      "epoch: 1 step: 1420, loss is 0.016229761764407158\n",
      "epoch: 1 step: 1421, loss is 0.04838315770030022\n",
      "epoch: 1 step: 1422, loss is 0.16996778547763824\n",
      "epoch: 1 step: 1423, loss is 0.01885480061173439\n",
      "epoch: 1 step: 1424, loss is 0.0171681959182024\n",
      "epoch: 1 step: 1425, loss is 0.13062551617622375\n",
      "epoch: 1 step: 1426, loss is 0.1013227328658104\n",
      "epoch: 1 step: 1427, loss is 0.15396365523338318\n",
      "epoch: 1 step: 1428, loss is 0.023274526000022888\n",
      "epoch: 1 step: 1429, loss is 0.2765049636363983\n",
      "epoch: 1 step: 1430, loss is 0.10687009990215302\n",
      "epoch: 1 step: 1431, loss is 0.09916798025369644\n",
      "epoch: 1 step: 1432, loss is 0.03465515002608299\n",
      "epoch: 1 step: 1433, loss is 0.03241218999028206\n",
      "epoch: 1 step: 1434, loss is 0.06989530473947525\n",
      "epoch: 1 step: 1435, loss is 0.08717788755893707\n",
      "epoch: 1 step: 1436, loss is 0.13311319053173065\n",
      "epoch: 1 step: 1437, loss is 0.12140180915594101\n",
      "epoch: 1 step: 1438, loss is 0.03449958190321922\n",
      "epoch: 1 step: 1439, loss is 0.013291933573782444\n",
      "epoch: 1 step: 1440, loss is 0.05812349170446396\n",
      "epoch: 1 step: 1441, loss is 0.01899002492427826\n",
      "epoch: 1 step: 1442, loss is 0.08517388999462128\n",
      "epoch: 1 step: 1443, loss is 0.023060211911797523\n",
      "epoch: 1 step: 1444, loss is 0.027899745851755142\n",
      "epoch: 1 step: 1445, loss is 0.03780555725097656\n",
      "epoch: 1 step: 1446, loss is 0.1706644594669342\n",
      "epoch: 1 step: 1447, loss is 0.007059544324874878\n",
      "epoch: 1 step: 1448, loss is 0.016745638102293015\n",
      "epoch: 1 step: 1449, loss is 0.012996058911085129\n",
      "epoch: 1 step: 1450, loss is 0.13886921107769012\n",
      "epoch: 1 step: 1451, loss is 0.3561309576034546\n",
      "epoch: 1 step: 1452, loss is 0.12653757631778717\n",
      "epoch: 1 step: 1453, loss is 0.040032342076301575\n",
      "epoch: 1 step: 1454, loss is 0.112830251455307\n",
      "epoch: 1 step: 1455, loss is 0.0015645986422896385\n",
      "epoch: 1 step: 1456, loss is 0.08603021502494812\n",
      "epoch: 1 step: 1457, loss is 0.11309195309877396\n",
      "epoch: 1 step: 1458, loss is 0.0019031813135370612\n",
      "epoch: 1 step: 1459, loss is 0.007900349795818329\n",
      "epoch: 1 step: 1460, loss is 0.1914854496717453\n",
      "epoch: 1 step: 1461, loss is 0.1518680602312088\n",
      "epoch: 1 step: 1462, loss is 0.04468350484967232\n",
      "epoch: 1 step: 1463, loss is 0.010157126933336258\n",
      "epoch: 1 step: 1464, loss is 0.18315516412258148\n",
      "epoch: 1 step: 1465, loss is 0.011702601797878742\n",
      "epoch: 1 step: 1466, loss is 0.07251834869384766\n",
      "epoch: 1 step: 1467, loss is 0.04724652320146561\n",
      "epoch: 1 step: 1468, loss is 0.05333557352423668\n",
      "epoch: 1 step: 1469, loss is 0.0020910673774778843\n",
      "epoch: 1 step: 1470, loss is 0.039501890540122986\n",
      "epoch: 1 step: 1471, loss is 0.04985989257693291\n",
      "epoch: 1 step: 1472, loss is 0.022221505641937256\n",
      "epoch: 1 step: 1473, loss is 0.1287335604429245\n",
      "epoch: 1 step: 1474, loss is 0.0028362926095724106\n",
      "epoch: 1 step: 1475, loss is 0.0637134239077568\n",
      "epoch: 1 step: 1476, loss is 0.08557555824518204\n",
      "epoch: 1 step: 1477, loss is 0.35486868023872375\n",
      "epoch: 1 step: 1478, loss is 0.0034224973060190678\n",
      "epoch: 1 step: 1479, loss is 0.12421511858701706\n",
      "epoch: 1 step: 1480, loss is 0.013387953862547874\n",
      "epoch: 1 step: 1481, loss is 0.011496299877762794\n",
      "epoch: 1 step: 1482, loss is 0.01459363754838705\n",
      "epoch: 1 step: 1483, loss is 0.04040529578924179\n",
      "epoch: 1 step: 1484, loss is 0.23887263238430023\n",
      "epoch: 1 step: 1485, loss is 0.02718191407620907\n",
      "epoch: 1 step: 1486, loss is 0.28064125776290894\n",
      "epoch: 1 step: 1487, loss is 0.09612783789634705\n",
      "epoch: 1 step: 1488, loss is 0.24404405057430267\n",
      "epoch: 1 step: 1489, loss is 0.01778062991797924\n",
      "epoch: 1 step: 1490, loss is 0.03354206308722496\n",
      "epoch: 1 step: 1491, loss is 0.22307977080345154\n",
      "epoch: 1 step: 1492, loss is 0.006752848159521818\n",
      "epoch: 1 step: 1493, loss is 0.007285975851118565\n",
      "epoch: 1 step: 1494, loss is 0.004088301211595535\n",
      "epoch: 1 step: 1495, loss is 0.02481989935040474\n",
      "epoch: 1 step: 1496, loss is 0.16974543035030365\n",
      "epoch: 1 step: 1497, loss is 0.014398227445781231\n",
      "epoch: 1 step: 1498, loss is 0.0411546491086483\n",
      "epoch: 1 step: 1499, loss is 0.01992597058415413\n",
      "epoch: 1 step: 1500, loss is 0.03831709548830986\n",
      "epoch: 1 step: 1501, loss is 0.05724753811955452\n",
      "epoch: 1 step: 1502, loss is 0.03396746888756752\n",
      "epoch: 1 step: 1503, loss is 0.014795935712754726\n",
      "epoch: 1 step: 1504, loss is 0.02970767952501774\n",
      "epoch: 1 step: 1505, loss is 0.0077779702842235565\n",
      "epoch: 1 step: 1506, loss is 0.07820738106966019\n",
      "epoch: 1 step: 1507, loss is 0.007909187115728855\n",
      "epoch: 1 step: 1508, loss is 0.17365482449531555\n",
      "epoch: 1 step: 1509, loss is 0.03509598225355148\n",
      "epoch: 1 step: 1510, loss is 0.06281250715255737\n",
      "epoch: 1 step: 1511, loss is 0.038169004023075104\n",
      "epoch: 1 step: 1512, loss is 0.032982368022203445\n",
      "epoch: 1 step: 1513, loss is 0.20694823563098907\n",
      "epoch: 1 step: 1514, loss is 0.02548215165734291\n",
      "epoch: 1 step: 1515, loss is 0.07704684138298035\n",
      "epoch: 1 step: 1516, loss is 0.12093070149421692\n",
      "epoch: 1 step: 1517, loss is 0.003443857654929161\n",
      "epoch: 1 step: 1518, loss is 0.1225970983505249\n",
      "epoch: 1 step: 1519, loss is 0.05097857117652893\n",
      "epoch: 1 step: 1520, loss is 0.008323589339852333\n",
      "epoch: 1 step: 1521, loss is 0.23977404832839966\n",
      "epoch: 1 step: 1522, loss is 0.04061293229460716\n",
      "epoch: 1 step: 1523, loss is 0.007659659255295992\n",
      "epoch: 1 step: 1524, loss is 0.05062362179160118\n",
      "epoch: 1 step: 1525, loss is 0.06512518227100372\n",
      "epoch: 1 step: 1526, loss is 0.0144800478592515\n",
      "epoch: 1 step: 1527, loss is 0.2058393657207489\n",
      "epoch: 1 step: 1528, loss is 0.07955154776573181\n",
      "epoch: 1 step: 1529, loss is 0.03699825704097748\n",
      "epoch: 1 step: 1530, loss is 0.042957909405231476\n",
      "epoch: 1 step: 1531, loss is 0.11409441381692886\n",
      "epoch: 1 step: 1532, loss is 0.2679472863674164\n",
      "epoch: 1 step: 1533, loss is 0.017508385702967644\n",
      "epoch: 1 step: 1534, loss is 0.030772695317864418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1535, loss is 0.04456080496311188\n",
      "epoch: 1 step: 1536, loss is 0.014552523382008076\n",
      "epoch: 1 step: 1537, loss is 0.08312486112117767\n",
      "epoch: 1 step: 1538, loss is 0.06701555103063583\n",
      "epoch: 1 step: 1539, loss is 0.017097335308790207\n",
      "epoch: 1 step: 1540, loss is 0.06606299430131912\n",
      "epoch: 1 step: 1541, loss is 0.03509145230054855\n",
      "epoch: 1 step: 1542, loss is 0.05889586731791496\n",
      "epoch: 1 step: 1543, loss is 0.09799590706825256\n",
      "epoch: 1 step: 1544, loss is 0.010943678207695484\n",
      "epoch: 1 step: 1545, loss is 0.02009459212422371\n",
      "epoch: 1 step: 1546, loss is 0.03946515917778015\n",
      "epoch: 1 step: 1547, loss is 0.039532385766506195\n",
      "epoch: 1 step: 1548, loss is 0.1621931940317154\n",
      "epoch: 1 step: 1549, loss is 0.18320554494857788\n",
      "epoch: 1 step: 1550, loss is 0.26190251111984253\n",
      "epoch: 1 step: 1551, loss is 0.16314201056957245\n",
      "epoch: 1 step: 1552, loss is 0.1744450032711029\n",
      "epoch: 1 step: 1553, loss is 0.07062267512083054\n",
      "epoch: 1 step: 1554, loss is 0.03350003808736801\n",
      "epoch: 1 step: 1555, loss is 0.08335518091917038\n",
      "epoch: 1 step: 1556, loss is 0.30236461758613586\n",
      "epoch: 1 step: 1557, loss is 0.023702897131443024\n",
      "epoch: 1 step: 1558, loss is 0.008712906390428543\n",
      "epoch: 1 step: 1559, loss is 0.07599806040525436\n",
      "epoch: 1 step: 1560, loss is 0.08985830843448639\n",
      "epoch: 1 step: 1561, loss is 0.023049455136060715\n",
      "epoch: 1 step: 1562, loss is 0.0051208361983299255\n",
      "epoch: 1 step: 1563, loss is 0.00461005512624979\n",
      "epoch: 1 step: 1564, loss is 0.0013300185091793537\n",
      "epoch: 1 step: 1565, loss is 0.006787200924009085\n",
      "epoch: 1 step: 1566, loss is 0.00854003056883812\n",
      "epoch: 1 step: 1567, loss is 0.10566296428442001\n",
      "epoch: 1 step: 1568, loss is 0.26217347383499146\n",
      "epoch: 1 step: 1569, loss is 0.017687810584902763\n",
      "epoch: 1 step: 1570, loss is 0.2081693857908249\n",
      "epoch: 1 step: 1571, loss is 0.18126344680786133\n",
      "epoch: 1 step: 1572, loss is 0.05242905393242836\n",
      "epoch: 1 step: 1573, loss is 0.09334848821163177\n",
      "epoch: 1 step: 1574, loss is 0.2970620095729828\n",
      "epoch: 1 step: 1575, loss is 0.07864713668823242\n",
      "epoch: 1 step: 1576, loss is 0.04133186116814613\n",
      "epoch: 1 step: 1577, loss is 0.11326371133327484\n",
      "epoch: 1 step: 1578, loss is 0.11382048577070236\n",
      "epoch: 1 step: 1579, loss is 0.06318795680999756\n",
      "epoch: 1 step: 1580, loss is 0.03256665915250778\n",
      "epoch: 1 step: 1581, loss is 0.08780363202095032\n",
      "epoch: 1 step: 1582, loss is 0.06266944855451584\n",
      "epoch: 1 step: 1583, loss is 0.009560499340295792\n",
      "epoch: 1 step: 1584, loss is 0.028619669377803802\n",
      "epoch: 1 step: 1585, loss is 0.03627544641494751\n",
      "epoch: 1 step: 1586, loss is 0.014348533935844898\n",
      "epoch: 1 step: 1587, loss is 0.02828761376440525\n",
      "epoch: 1 step: 1588, loss is 0.31391870975494385\n",
      "epoch: 1 step: 1589, loss is 0.023999175056815147\n",
      "epoch: 1 step: 1590, loss is 0.07535860687494278\n",
      "epoch: 1 step: 1591, loss is 0.022295478731393814\n",
      "epoch: 1 step: 1592, loss is 0.0703478455543518\n",
      "epoch: 1 step: 1593, loss is 0.08685673773288727\n",
      "epoch: 1 step: 1594, loss is 0.020788604393601418\n",
      "epoch: 1 step: 1595, loss is 0.035978544503450394\n",
      "epoch: 1 step: 1596, loss is 0.037205860018730164\n",
      "epoch: 1 step: 1597, loss is 0.042794156819581985\n",
      "epoch: 1 step: 1598, loss is 0.003950373735278845\n",
      "epoch: 1 step: 1599, loss is 0.06918613612651825\n",
      "epoch: 1 step: 1600, loss is 0.016468994319438934\n",
      "epoch: 1 step: 1601, loss is 0.13420231640338898\n",
      "epoch: 1 step: 1602, loss is 0.006803940050303936\n",
      "epoch: 1 step: 1603, loss is 0.0362047515809536\n",
      "epoch: 1 step: 1604, loss is 0.0015238214982673526\n",
      "epoch: 1 step: 1605, loss is 0.027225414291024208\n",
      "epoch: 1 step: 1606, loss is 0.002267487347126007\n",
      "epoch: 1 step: 1607, loss is 0.19459371268749237\n",
      "epoch: 1 step: 1608, loss is 0.1086067482829094\n",
      "epoch: 1 step: 1609, loss is 0.008284233510494232\n",
      "epoch: 1 step: 1610, loss is 0.2462136447429657\n",
      "epoch: 1 step: 1611, loss is 0.12025415897369385\n",
      "epoch: 1 step: 1612, loss is 0.019187655299901962\n",
      "epoch: 1 step: 1613, loss is 0.11089981347322464\n",
      "epoch: 1 step: 1614, loss is 0.04396473616361618\n",
      "epoch: 1 step: 1615, loss is 0.11984097212553024\n",
      "epoch: 1 step: 1616, loss is 0.0447147935628891\n",
      "epoch: 1 step: 1617, loss is 0.08127852529287338\n",
      "epoch: 1 step: 1618, loss is 0.06821870803833008\n",
      "epoch: 1 step: 1619, loss is 0.016174012795090675\n",
      "epoch: 1 step: 1620, loss is 0.06639517843723297\n",
      "epoch: 1 step: 1621, loss is 0.12978100776672363\n",
      "epoch: 1 step: 1622, loss is 0.03961833193898201\n",
      "epoch: 1 step: 1623, loss is 0.14222367107868195\n",
      "epoch: 1 step: 1624, loss is 0.15092667937278748\n",
      "epoch: 1 step: 1625, loss is 0.01186827477067709\n",
      "epoch: 1 step: 1626, loss is 0.04384154826402664\n",
      "epoch: 1 step: 1627, loss is 0.1947045773267746\n",
      "epoch: 1 step: 1628, loss is 0.0875653550028801\n",
      "epoch: 1 step: 1629, loss is 0.04730090871453285\n",
      "epoch: 1 step: 1630, loss is 0.02055186778306961\n",
      "epoch: 1 step: 1631, loss is 0.012988871894776821\n",
      "epoch: 1 step: 1632, loss is 0.015721812844276428\n",
      "epoch: 1 step: 1633, loss is 0.308079332113266\n",
      "epoch: 1 step: 1634, loss is 0.07502011954784393\n",
      "epoch: 1 step: 1635, loss is 0.022419093176722527\n",
      "epoch: 1 step: 1636, loss is 0.12163887172937393\n",
      "epoch: 1 step: 1637, loss is 0.07835493981838226\n",
      "epoch: 1 step: 1638, loss is 0.09720202535390854\n",
      "epoch: 1 step: 1639, loss is 0.06661812216043472\n",
      "epoch: 1 step: 1640, loss is 0.06294796615839005\n",
      "epoch: 1 step: 1641, loss is 0.10464107990264893\n",
      "epoch: 1 step: 1642, loss is 0.016424428671598434\n",
      "epoch: 1 step: 1643, loss is 0.013518871739506721\n",
      "epoch: 1 step: 1644, loss is 0.008644869551062584\n",
      "epoch: 1 step: 1645, loss is 0.016434451565146446\n",
      "epoch: 1 step: 1646, loss is 0.11354794353246689\n",
      "epoch: 1 step: 1647, loss is 0.019836749881505966\n",
      "epoch: 1 step: 1648, loss is 0.3419339954853058\n",
      "epoch: 1 step: 1649, loss is 0.23720286786556244\n",
      "epoch: 1 step: 1650, loss is 0.03279748931527138\n",
      "epoch: 1 step: 1651, loss is 0.009411673061549664\n",
      "epoch: 1 step: 1652, loss is 0.11696106195449829\n",
      "epoch: 1 step: 1653, loss is 0.020086724311113358\n",
      "epoch: 1 step: 1654, loss is 0.024569734930992126\n",
      "epoch: 1 step: 1655, loss is 0.1822100132703781\n",
      "epoch: 1 step: 1656, loss is 0.41995421051979065\n",
      "epoch: 1 step: 1657, loss is 0.03984120115637779\n",
      "epoch: 1 step: 1658, loss is 0.20349563658237457\n",
      "epoch: 1 step: 1659, loss is 0.00543876551091671\n",
      "epoch: 1 step: 1660, loss is 0.02856101095676422\n",
      "epoch: 1 step: 1661, loss is 0.012603014707565308\n",
      "epoch: 1 step: 1662, loss is 0.021591641008853912\n",
      "epoch: 1 step: 1663, loss is 0.10080817341804504\n",
      "epoch: 1 step: 1664, loss is 0.02738322503864765\n",
      "epoch: 1 step: 1665, loss is 0.08386491984128952\n",
      "epoch: 1 step: 1666, loss is 0.10999153554439545\n",
      "epoch: 1 step: 1667, loss is 0.06993530690670013\n",
      "epoch: 1 step: 1668, loss is 0.08545371890068054\n",
      "epoch: 1 step: 1669, loss is 0.04439206048846245\n",
      "epoch: 1 step: 1670, loss is 0.04232597351074219\n",
      "epoch: 1 step: 1671, loss is 0.05190673843026161\n",
      "epoch: 1 step: 1672, loss is 0.20310284197330475\n",
      "epoch: 1 step: 1673, loss is 0.026502372696995735\n",
      "epoch: 1 step: 1674, loss is 0.11226939409971237\n",
      "epoch: 1 step: 1675, loss is 0.196440652012825\n",
      "epoch: 1 step: 1676, loss is 0.008137829601764679\n",
      "epoch: 1 step: 1677, loss is 0.009482081048190594\n",
      "epoch: 1 step: 1678, loss is 0.06449457257986069\n",
      "epoch: 1 step: 1679, loss is 0.07619232684373856\n",
      "epoch: 1 step: 1680, loss is 0.049963001161813736\n",
      "epoch: 1 step: 1681, loss is 0.020170914009213448\n",
      "epoch: 1 step: 1682, loss is 0.01857510767877102\n",
      "epoch: 1 step: 1683, loss is 0.033193476498126984\n",
      "epoch: 1 step: 1684, loss is 0.0521899051964283\n",
      "epoch: 1 step: 1685, loss is 0.09951826184988022\n",
      "epoch: 1 step: 1686, loss is 0.08946879953145981\n",
      "epoch: 1 step: 1687, loss is 0.10956693440675735\n",
      "epoch: 1 step: 1688, loss is 0.0308671984821558\n",
      "epoch: 1 step: 1689, loss is 0.1281576156616211\n",
      "epoch: 1 step: 1690, loss is 0.06030776724219322\n",
      "epoch: 1 step: 1691, loss is 0.038199540227651596\n",
      "epoch: 1 step: 1692, loss is 0.014012511819601059\n",
      "epoch: 1 step: 1693, loss is 0.003595571732148528\n",
      "epoch: 1 step: 1694, loss is 0.024491528049111366\n",
      "epoch: 1 step: 1695, loss is 0.017478864639997482\n",
      "epoch: 1 step: 1696, loss is 0.07463090866804123\n",
      "epoch: 1 step: 1697, loss is 0.11633536964654922\n",
      "epoch: 1 step: 1698, loss is 0.11476851254701614\n",
      "epoch: 1 step: 1699, loss is 0.02518000267446041\n",
      "epoch: 1 step: 1700, loss is 0.17325399816036224\n",
      "epoch: 1 step: 1701, loss is 0.05615030974149704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1702, loss is 0.05058243125677109\n",
      "epoch: 1 step: 1703, loss is 0.0013739299029111862\n",
      "epoch: 1 step: 1704, loss is 0.0029298721347004175\n",
      "epoch: 1 step: 1705, loss is 0.2746153175830841\n",
      "epoch: 1 step: 1706, loss is 0.05073817819356918\n",
      "epoch: 1 step: 1707, loss is 0.19794830679893494\n",
      "epoch: 1 step: 1708, loss is 0.2006533145904541\n",
      "epoch: 1 step: 1709, loss is 0.1498280018568039\n",
      "epoch: 1 step: 1710, loss is 0.15861757099628448\n",
      "epoch: 1 step: 1711, loss is 0.05024115741252899\n",
      "epoch: 1 step: 1712, loss is 0.04811462387442589\n",
      "epoch: 1 step: 1713, loss is 0.09302955120801926\n",
      "epoch: 1 step: 1714, loss is 0.15037642419338226\n",
      "epoch: 1 step: 1715, loss is 0.0766156017780304\n",
      "epoch: 1 step: 1716, loss is 0.011061782017350197\n",
      "epoch: 1 step: 1717, loss is 0.03506561741232872\n",
      "epoch: 1 step: 1718, loss is 0.17323338985443115\n",
      "epoch: 1 step: 1719, loss is 0.05315908417105675\n",
      "epoch: 1 step: 1720, loss is 0.012474296614527702\n",
      "epoch: 1 step: 1721, loss is 0.17202849686145782\n",
      "epoch: 1 step: 1722, loss is 0.020538603886961937\n",
      "epoch: 1 step: 1723, loss is 0.09754633158445358\n",
      "epoch: 1 step: 1724, loss is 0.14016616344451904\n",
      "epoch: 1 step: 1725, loss is 0.2603289783000946\n",
      "epoch: 1 step: 1726, loss is 0.037127718329429626\n",
      "epoch: 1 step: 1727, loss is 0.010936957783997059\n",
      "epoch: 1 step: 1728, loss is 0.08865434676408768\n",
      "epoch: 1 step: 1729, loss is 0.11978134512901306\n",
      "epoch: 1 step: 1730, loss is 0.0736311823129654\n",
      "epoch: 1 step: 1731, loss is 0.006162676494568586\n",
      "epoch: 1 step: 1732, loss is 0.12512560188770294\n",
      "epoch: 1 step: 1733, loss is 0.05426821857690811\n",
      "epoch: 1 step: 1734, loss is 0.2526601552963257\n",
      "epoch: 1 step: 1735, loss is 0.006942452397197485\n",
      "epoch: 1 step: 1736, loss is 0.003005597973242402\n",
      "epoch: 1 step: 1737, loss is 0.1071726605296135\n",
      "epoch: 1 step: 1738, loss is 0.08855913579463959\n",
      "epoch: 1 step: 1739, loss is 0.010774407535791397\n",
      "epoch: 1 step: 1740, loss is 0.061303041875362396\n",
      "epoch: 1 step: 1741, loss is 0.14741750061511993\n",
      "epoch: 1 step: 1742, loss is 0.0065721916034817696\n",
      "epoch: 1 step: 1743, loss is 0.12241319566965103\n",
      "epoch: 1 step: 1744, loss is 0.01561226136982441\n",
      "epoch: 1 step: 1745, loss is 0.08225960284471512\n",
      "epoch: 1 step: 1746, loss is 0.05341136455535889\n",
      "epoch: 1 step: 1747, loss is 0.014972306787967682\n",
      "epoch: 1 step: 1748, loss is 0.06870543956756592\n",
      "epoch: 1 step: 1749, loss is 0.1046605110168457\n",
      "epoch: 1 step: 1750, loss is 0.13651154935359955\n",
      "epoch: 1 step: 1751, loss is 0.0033321836963295937\n",
      "epoch: 1 step: 1752, loss is 0.005963981617242098\n",
      "epoch: 1 step: 1753, loss is 0.23703809082508087\n",
      "epoch: 1 step: 1754, loss is 0.01650129444897175\n",
      "epoch: 1 step: 1755, loss is 0.17324954271316528\n",
      "epoch: 1 step: 1756, loss is 0.030381441116333008\n",
      "epoch: 1 step: 1757, loss is 0.05655396357178688\n",
      "epoch: 1 step: 1758, loss is 0.09227053821086884\n",
      "epoch: 1 step: 1759, loss is 0.1748029738664627\n",
      "epoch: 1 step: 1760, loss is 0.01176438108086586\n",
      "epoch: 1 step: 1761, loss is 0.04280772805213928\n",
      "epoch: 1 step: 1762, loss is 0.013729730620980263\n",
      "epoch: 1 step: 1763, loss is 0.2011881321668625\n",
      "epoch: 1 step: 1764, loss is 0.01880856789648533\n",
      "epoch: 1 step: 1765, loss is 0.03492576628923416\n",
      "epoch: 1 step: 1766, loss is 0.07733280956745148\n",
      "epoch: 1 step: 1767, loss is 0.003702679881826043\n",
      "epoch: 1 step: 1768, loss is 0.2790519595146179\n",
      "epoch: 1 step: 1769, loss is 0.02772325463593006\n",
      "epoch: 1 step: 1770, loss is 0.04298555850982666\n",
      "epoch: 1 step: 1771, loss is 0.15343640744686127\n",
      "epoch: 1 step: 1772, loss is 0.2137230634689331\n",
      "epoch: 1 step: 1773, loss is 0.0014702420448884368\n",
      "epoch: 1 step: 1774, loss is 0.03741072118282318\n",
      "epoch: 1 step: 1775, loss is 0.002750709652900696\n",
      "epoch: 1 step: 1776, loss is 0.019410334527492523\n",
      "epoch: 1 step: 1777, loss is 0.06929974257946014\n",
      "epoch: 1 step: 1778, loss is 0.08230311423540115\n",
      "epoch: 1 step: 1779, loss is 0.013779931701719761\n",
      "epoch: 1 step: 1780, loss is 0.25527819991111755\n",
      "epoch: 1 step: 1781, loss is 0.21850664913654327\n",
      "epoch: 1 step: 1782, loss is 0.10256920754909515\n",
      "epoch: 1 step: 1783, loss is 0.027677178382873535\n",
      "epoch: 1 step: 1784, loss is 0.014540642499923706\n",
      "epoch: 1 step: 1785, loss is 0.050250642001628876\n",
      "epoch: 1 step: 1786, loss is 0.03041117452085018\n",
      "epoch: 1 step: 1787, loss is 0.020344074815511703\n",
      "epoch: 1 step: 1788, loss is 0.07134777307510376\n",
      "epoch: 1 step: 1789, loss is 0.036621611565351486\n",
      "epoch: 1 step: 1790, loss is 0.017626654356718063\n",
      "epoch: 1 step: 1791, loss is 0.043015189468860626\n",
      "epoch: 1 step: 1792, loss is 0.012417029589414597\n",
      "epoch: 1 step: 1793, loss is 0.040633585304021835\n",
      "epoch: 1 step: 1794, loss is 0.09834294021129608\n",
      "epoch: 1 step: 1795, loss is 0.01835385523736477\n",
      "epoch: 1 step: 1796, loss is 0.003313504159450531\n",
      "epoch: 1 step: 1797, loss is 0.27648892998695374\n",
      "epoch: 1 step: 1798, loss is 0.012906135991215706\n",
      "epoch: 1 step: 1799, loss is 0.035453956574201584\n",
      "epoch: 1 step: 1800, loss is 0.008151066489517689\n",
      "epoch: 1 step: 1801, loss is 0.2530061900615692\n",
      "epoch: 1 step: 1802, loss is 0.03628022223711014\n",
      "epoch: 1 step: 1803, loss is 0.0014887660508975387\n",
      "epoch: 1 step: 1804, loss is 0.015609459020197392\n",
      "epoch: 1 step: 1805, loss is 0.005168247502297163\n",
      "epoch: 1 step: 1806, loss is 0.1208590716123581\n",
      "epoch: 1 step: 1807, loss is 0.1286584436893463\n",
      "epoch: 1 step: 1808, loss is 0.07132496684789658\n",
      "epoch: 1 step: 1809, loss is 0.026154065504670143\n",
      "epoch: 1 step: 1810, loss is 0.03707586228847504\n",
      "epoch: 1 step: 1811, loss is 0.18106712400913239\n",
      "epoch: 1 step: 1812, loss is 0.13820098340511322\n",
      "epoch: 1 step: 1813, loss is 0.08571866899728775\n",
      "epoch: 1 step: 1814, loss is 0.05378930643200874\n",
      "epoch: 1 step: 1815, loss is 0.03378090262413025\n",
      "epoch: 1 step: 1816, loss is 0.01811852492392063\n",
      "epoch: 1 step: 1817, loss is 0.04834367707371712\n",
      "epoch: 1 step: 1818, loss is 0.06575535237789154\n",
      "epoch: 1 step: 1819, loss is 0.025505727156996727\n",
      "epoch: 1 step: 1820, loss is 0.06823180615901947\n",
      "epoch: 1 step: 1821, loss is 0.025402678176760674\n",
      "epoch: 1 step: 1822, loss is 0.012264581397175789\n",
      "epoch: 1 step: 1823, loss is 0.03370997682213783\n",
      "epoch: 1 step: 1824, loss is 0.07115819305181503\n",
      "epoch: 1 step: 1825, loss is 0.05880441516637802\n",
      "epoch: 1 step: 1826, loss is 0.05672623589634895\n",
      "epoch: 1 step: 1827, loss is 0.06963463127613068\n",
      "epoch: 1 step: 1828, loss is 0.13474354147911072\n",
      "epoch: 1 step: 1829, loss is 0.04778417944908142\n",
      "epoch: 1 step: 1830, loss is 0.043480779975652695\n",
      "epoch: 1 step: 1831, loss is 0.01407886203378439\n",
      "epoch: 1 step: 1832, loss is 0.10341402888298035\n",
      "epoch: 1 step: 1833, loss is 0.0856751948595047\n",
      "epoch: 1 step: 1834, loss is 0.03561829403042793\n",
      "epoch: 1 step: 1835, loss is 0.120378278195858\n",
      "epoch: 1 step: 1836, loss is 0.0636262372136116\n",
      "epoch: 1 step: 1837, loss is 0.003063548356294632\n",
      "epoch: 1 step: 1838, loss is 0.03737389296293259\n",
      "epoch: 1 step: 1839, loss is 0.04522297903895378\n",
      "epoch: 1 step: 1840, loss is 0.018610475584864616\n",
      "epoch: 1 step: 1841, loss is 0.010386042296886444\n",
      "epoch: 1 step: 1842, loss is 0.16165675222873688\n",
      "epoch: 1 step: 1843, loss is 0.005997246131300926\n",
      "epoch: 1 step: 1844, loss is 0.20600435137748718\n",
      "epoch: 1 step: 1845, loss is 0.0007808880181983113\n",
      "epoch: 1 step: 1846, loss is 0.009307574480772018\n",
      "epoch: 1 step: 1847, loss is 0.0027542703319340944\n",
      "epoch: 1 step: 1848, loss is 0.14698749780654907\n",
      "epoch: 1 step: 1849, loss is 0.09614840149879456\n",
      "epoch: 1 step: 1850, loss is 0.0018747153226286173\n",
      "epoch: 1 step: 1851, loss is 0.08162429183721542\n",
      "epoch: 1 step: 1852, loss is 0.0931338295340538\n",
      "epoch: 1 step: 1853, loss is 0.017558971419930458\n",
      "epoch: 1 step: 1854, loss is 0.14126832783222198\n",
      "epoch: 1 step: 1855, loss is 0.04767431318759918\n",
      "epoch: 1 step: 1856, loss is 0.03863127902150154\n",
      "epoch: 1 step: 1857, loss is 0.2696792185306549\n",
      "epoch: 1 step: 1858, loss is 0.10544168949127197\n",
      "epoch: 1 step: 1859, loss is 0.24971254169940948\n",
      "epoch: 1 step: 1860, loss is 0.02583899162709713\n",
      "epoch: 1 step: 1861, loss is 0.2274932861328125\n",
      "epoch: 1 step: 1862, loss is 0.03672417625784874\n",
      "epoch: 1 step: 1863, loss is 0.01254548691213131\n",
      "epoch: 1 step: 1864, loss is 0.01327948085963726\n",
      "epoch: 1 step: 1865, loss is 0.06757545471191406\n",
      "epoch: 1 step: 1866, loss is 0.1537189930677414\n",
      "epoch: 1 step: 1867, loss is 0.4747878611087799\n",
      "epoch: 1 step: 1868, loss is 0.013183509930968285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1869, loss is 0.10151880979537964\n",
      "epoch: 1 step: 1870, loss is 0.007022312842309475\n",
      "epoch: 1 step: 1871, loss is 0.15927298367023468\n",
      "epoch: 1 step: 1872, loss is 0.011741270311176777\n",
      "epoch: 1 step: 1873, loss is 0.02782483957707882\n",
      "epoch: 1 step: 1874, loss is 0.05767851695418358\n",
      "epoch: 1 step: 1875, loss is 0.007893281988799572\n",
      "epoch: 1 step: 1876, loss is 0.1495991200208664\n",
      "epoch: 1 step: 1877, loss is 0.007201217580586672\n",
      "epoch: 1 step: 1878, loss is 0.044414177536964417\n",
      "epoch: 1 step: 1879, loss is 0.014730896800756454\n",
      "epoch: 1 step: 1880, loss is 0.023878516629338264\n",
      "epoch: 1 step: 1881, loss is 0.08600729703903198\n",
      "epoch: 1 step: 1882, loss is 0.05762689188122749\n",
      "epoch: 1 step: 1883, loss is 0.19915060698986053\n",
      "epoch: 1 step: 1884, loss is 0.03852972760796547\n",
      "epoch: 1 step: 1885, loss is 0.015817763283848763\n",
      "epoch: 1 step: 1886, loss is 0.006966069806367159\n",
      "epoch: 1 step: 1887, loss is 0.07390894740819931\n",
      "epoch: 1 step: 1888, loss is 0.046118054538965225\n",
      "epoch: 1 step: 1889, loss is 0.17113184928894043\n",
      "epoch: 1 step: 1890, loss is 0.011448378674685955\n",
      "epoch: 1 step: 1891, loss is 0.15546853840351105\n",
      "epoch: 1 step: 1892, loss is 0.0022091083228588104\n",
      "epoch: 1 step: 1893, loss is 0.29500553011894226\n",
      "epoch: 1 step: 1894, loss is 0.09493875503540039\n",
      "epoch: 1 step: 1895, loss is 0.0014228574000298977\n",
      "epoch: 1 step: 1896, loss is 0.057735417038202286\n",
      "epoch: 1 step: 1897, loss is 0.11290796101093292\n",
      "epoch: 1 step: 1898, loss is 0.04972653463482857\n",
      "epoch: 1 step: 1899, loss is 0.09243541210889816\n",
      "epoch: 1 step: 1900, loss is 0.010672514326870441\n",
      "epoch: 1 step: 1901, loss is 0.010042905807495117\n",
      "epoch: 1 step: 1902, loss is 0.0052054584957659245\n",
      "epoch: 1 step: 1903, loss is 0.2745569348335266\n",
      "epoch: 1 step: 1904, loss is 0.017245963215827942\n",
      "epoch: 1 step: 1905, loss is 0.007604547310620546\n",
      "epoch: 1 step: 1906, loss is 0.006415794137865305\n",
      "epoch: 1 step: 1907, loss is 0.12412513792514801\n",
      "epoch: 1 step: 1908, loss is 0.07928808778524399\n",
      "epoch: 1 step: 1909, loss is 0.05773499980568886\n",
      "epoch: 1 step: 1910, loss is 0.07119002938270569\n",
      "epoch: 1 step: 1911, loss is 0.25046825408935547\n",
      "epoch: 1 step: 1912, loss is 0.020588284358382225\n",
      "epoch: 1 step: 1913, loss is 0.005913600791245699\n",
      "epoch: 1 step: 1914, loss is 0.10337721556425095\n",
      "epoch: 1 step: 1915, loss is 0.19099773466587067\n",
      "epoch: 1 step: 1916, loss is 0.010386544279754162\n",
      "epoch: 1 step: 1917, loss is 0.035390421748161316\n",
      "epoch: 1 step: 1918, loss is 0.1353892982006073\n",
      "epoch: 1 step: 1919, loss is 0.0753878578543663\n",
      "epoch: 1 step: 1920, loss is 0.012186174280941486\n",
      "epoch: 1 step: 1921, loss is 0.01150352694094181\n",
      "epoch: 1 step: 1922, loss is 0.003684548195451498\n",
      "epoch: 1 step: 1923, loss is 0.011989683844149113\n",
      "epoch: 1 step: 1924, loss is 0.026365410536527634\n",
      "epoch: 1 step: 1925, loss is 0.018868060782551765\n",
      "epoch: 1 step: 1926, loss is 0.12252999097108841\n",
      "epoch: 1 step: 1927, loss is 0.014408493414521217\n",
      "epoch: 1 step: 1928, loss is 0.005967583041638136\n",
      "epoch: 1 step: 1929, loss is 0.026782408356666565\n",
      "epoch: 1 step: 1930, loss is 0.0030013318173587322\n",
      "epoch: 1 step: 1931, loss is 0.5066404342651367\n",
      "epoch: 1 step: 1932, loss is 0.003648080164566636\n",
      "epoch: 1 step: 1933, loss is 0.014559810981154442\n",
      "epoch: 1 step: 1934, loss is 0.1377047449350357\n",
      "epoch: 1 step: 1935, loss is 0.02114453911781311\n",
      "epoch: 1 step: 1936, loss is 0.3327431082725525\n",
      "epoch: 1 step: 1937, loss is 0.019417833536863327\n",
      "epoch: 1 step: 1938, loss is 0.016267981380224228\n",
      "epoch: 1 step: 1939, loss is 0.0795985609292984\n",
      "epoch: 1 step: 1940, loss is 0.007759361527860165\n",
      "epoch: 1 step: 1941, loss is 0.31656602025032043\n",
      "epoch: 1 step: 1942, loss is 0.002786265918985009\n",
      "epoch: 1 step: 1943, loss is 0.2816571593284607\n",
      "epoch: 1 step: 1944, loss is 0.0929548516869545\n",
      "epoch: 1 step: 1945, loss is 0.02803967334330082\n",
      "epoch: 1 step: 1946, loss is 0.03513175994157791\n",
      "epoch: 1 step: 1947, loss is 0.056996941566467285\n",
      "epoch: 1 step: 1948, loss is 0.10117378830909729\n",
      "epoch: 1 step: 1949, loss is 0.032496459782123566\n",
      "epoch: 1 step: 1950, loss is 0.014026941731572151\n",
      "epoch: 1 step: 1951, loss is 0.00300103472545743\n",
      "epoch: 1 step: 1952, loss is 0.02711266279220581\n",
      "epoch: 1 step: 1953, loss is 0.09739851206541061\n",
      "epoch: 1 step: 1954, loss is 0.018400881439447403\n",
      "epoch: 1 step: 1955, loss is 0.02681191824376583\n",
      "epoch: 1 step: 1956, loss is 0.06167278066277504\n",
      "epoch: 1 step: 1957, loss is 0.01327594369649887\n",
      "epoch: 1 step: 1958, loss is 0.025505272671580315\n",
      "epoch: 1 step: 1959, loss is 0.05325508117675781\n",
      "epoch: 1 step: 1960, loss is 0.0032835444435477257\n",
      "epoch: 1 step: 1961, loss is 0.0675460696220398\n",
      "epoch: 1 step: 1962, loss is 0.09030143916606903\n",
      "epoch: 1 step: 1963, loss is 0.07600629329681396\n",
      "epoch: 1 step: 1964, loss is 0.05289599299430847\n",
      "epoch: 1 step: 1965, loss is 0.0397731214761734\n",
      "epoch: 1 step: 1966, loss is 0.23137755692005157\n",
      "epoch: 1 step: 1967, loss is 0.04315457120537758\n",
      "epoch: 1 step: 1968, loss is 0.3118555247783661\n",
      "epoch: 1 step: 1969, loss is 0.05548003688454628\n",
      "epoch: 1 step: 1970, loss is 0.2589729428291321\n",
      "epoch: 1 step: 1971, loss is 0.01973389834165573\n",
      "epoch: 1 step: 1972, loss is 0.003922542091459036\n",
      "epoch: 1 step: 1973, loss is 0.14790219068527222\n",
      "epoch: 1 step: 1974, loss is 0.0009817148093134165\n",
      "epoch: 1 step: 1975, loss is 0.06018340215086937\n",
      "epoch: 1 step: 1976, loss is 0.11875591427087784\n",
      "epoch: 1 step: 1977, loss is 0.012617114931344986\n",
      "epoch: 1 step: 1978, loss is 0.03600231558084488\n",
      "epoch: 1 step: 1979, loss is 0.08424647897481918\n",
      "epoch: 1 step: 1980, loss is 0.11410935968160629\n",
      "epoch: 1 step: 1981, loss is 0.024097919464111328\n",
      "epoch: 1 step: 1982, loss is 0.015209933742880821\n",
      "epoch: 1 step: 1983, loss is 0.0895027443766594\n",
      "epoch: 1 step: 1984, loss is 0.20213976502418518\n",
      "epoch: 1 step: 1985, loss is 0.1157284677028656\n",
      "epoch: 1 step: 1986, loss is 0.07114008814096451\n",
      "epoch: 1 step: 1987, loss is 0.09233509749174118\n",
      "epoch: 1 step: 1988, loss is 0.053535282611846924\n",
      "epoch: 1 step: 1989, loss is 0.07168721407651901\n",
      "epoch: 1 step: 1990, loss is 0.07615429908037186\n",
      "epoch: 1 step: 1991, loss is 0.008103334344923496\n",
      "epoch: 1 step: 1992, loss is 0.04549538716673851\n",
      "epoch: 1 step: 1993, loss is 0.06973724812269211\n",
      "epoch: 1 step: 1994, loss is 0.037251923233270645\n",
      "epoch: 1 step: 1995, loss is 0.008661692030727863\n",
      "epoch: 1 step: 1996, loss is 0.11345437169075012\n",
      "epoch: 1 step: 1997, loss is 0.07012643665075302\n",
      "epoch: 1 step: 1998, loss is 0.0616777129471302\n",
      "epoch: 1 step: 1999, loss is 0.0025132005102932453\n",
      "epoch: 1 step: 2000, loss is 0.16693119704723358\n",
      "epoch: 1 step: 2001, loss is 0.12762078642845154\n",
      "epoch: 1 step: 2002, loss is 0.08715245872735977\n",
      "epoch: 1 step: 2003, loss is 0.03264173865318298\n",
      "epoch: 1 step: 2004, loss is 0.11963418871164322\n",
      "epoch: 1 step: 2005, loss is 0.03472810611128807\n",
      "epoch: 1 step: 2006, loss is 0.19272832572460175\n",
      "epoch: 1 step: 2007, loss is 0.02422744408249855\n",
      "epoch: 1 step: 2008, loss is 0.03657447546720505\n",
      "epoch: 1 step: 2009, loss is 0.05708499625325203\n",
      "epoch: 1 step: 2010, loss is 0.4815709888935089\n",
      "epoch: 1 step: 2011, loss is 0.034733619540929794\n",
      "epoch: 1 step: 2012, loss is 0.08922506868839264\n",
      "epoch: 1 step: 2013, loss is 0.03651442006230354\n",
      "epoch: 1 step: 2014, loss is 0.008311212994158268\n",
      "epoch: 1 step: 2015, loss is 0.0029368300456553698\n",
      "epoch: 1 step: 2016, loss is 0.1248309463262558\n",
      "epoch: 1 step: 2017, loss is 0.010409370996057987\n",
      "epoch: 1 step: 2018, loss is 0.08049046993255615\n",
      "epoch: 1 step: 2019, loss is 0.20952220261096954\n",
      "epoch: 1 step: 2020, loss is 0.07114864885807037\n",
      "epoch: 1 step: 2021, loss is 0.041187383234500885\n",
      "epoch: 1 step: 2022, loss is 0.026457879692316055\n",
      "epoch: 1 step: 2023, loss is 0.17995966970920563\n",
      "epoch: 1 step: 2024, loss is 0.0209723599255085\n",
      "epoch: 1 step: 2025, loss is 0.020305659621953964\n",
      "epoch: 1 step: 2026, loss is 0.2831094563007355\n",
      "epoch: 1 step: 2027, loss is 0.026420162990689278\n",
      "epoch: 1 step: 2028, loss is 0.05929627642035484\n",
      "epoch: 1 step: 2029, loss is 0.0022445525974035263\n",
      "epoch: 1 step: 2030, loss is 0.029627416282892227\n",
      "epoch: 1 step: 2031, loss is 0.012684384360909462\n",
      "epoch: 1 step: 2032, loss is 0.005234639625996351\n",
      "epoch: 1 step: 2033, loss is 0.0009211875731125474\n",
      "epoch: 1 step: 2034, loss is 0.20758506655693054\n",
      "epoch: 1 step: 2035, loss is 0.023408420383930206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 2036, loss is 0.012469121254980564\n",
      "epoch: 1 step: 2037, loss is 0.024066641926765442\n",
      "epoch: 1 step: 2038, loss is 0.04525028169155121\n",
      "epoch: 1 step: 2039, loss is 0.046636395156383514\n",
      "epoch: 1 step: 2040, loss is 0.018521582707762718\n",
      "epoch: 1 step: 2041, loss is 0.05916030704975128\n",
      "epoch: 1 step: 2042, loss is 0.21266034245491028\n",
      "epoch: 1 step: 2043, loss is 0.12001945078372955\n",
      "epoch: 1 step: 2044, loss is 0.03446924686431885\n",
      "epoch: 1 step: 2045, loss is 0.03990945592522621\n",
      "epoch: 1 step: 2046, loss is 0.0695941299200058\n",
      "epoch: 1 step: 2047, loss is 0.005954862106591463\n",
      "epoch: 1 step: 2048, loss is 0.09586509317159653\n",
      "epoch: 1 step: 2049, loss is 0.027880152687430382\n",
      "epoch: 1 step: 2050, loss is 0.27306705713272095\n",
      "epoch: 1 step: 2051, loss is 0.01887589879333973\n",
      "epoch: 1 step: 2052, loss is 0.13615064322948456\n",
      "epoch: 1 step: 2053, loss is 0.002181887160986662\n",
      "epoch: 1 step: 2054, loss is 0.07316244393587112\n",
      "epoch: 1 step: 2055, loss is 0.020839383825659752\n",
      "epoch: 1 step: 2056, loss is 0.10082961618900299\n",
      "epoch: 1 step: 2057, loss is 0.015829337760806084\n",
      "epoch: 1 step: 2058, loss is 0.0031631523743271828\n",
      "epoch: 1 step: 2059, loss is 0.04517493024468422\n",
      "epoch: 1 step: 2060, loss is 0.0820290595293045\n",
      "epoch: 1 step: 2061, loss is 0.029602687805891037\n",
      "epoch: 1 step: 2062, loss is 0.1716434806585312\n",
      "epoch: 1 step: 2063, loss is 0.1345500946044922\n",
      "epoch: 1 step: 2064, loss is 0.038604654371738434\n",
      "epoch: 1 step: 2065, loss is 0.01509118266403675\n",
      "epoch: 1 step: 2066, loss is 0.023190289735794067\n",
      "epoch: 1 step: 2067, loss is 0.10298864543437958\n",
      "epoch: 1 step: 2068, loss is 0.2760118544101715\n",
      "epoch: 1 step: 2069, loss is 0.1526605784893036\n",
      "epoch: 1 step: 2070, loss is 0.014741552993655205\n",
      "epoch: 1 step: 2071, loss is 0.02716073766350746\n",
      "epoch: 1 step: 2072, loss is 0.10846440494060516\n",
      "epoch: 1 step: 2073, loss is 0.09891689568758011\n",
      "epoch: 1 step: 2074, loss is 0.007569164503365755\n",
      "epoch: 1 step: 2075, loss is 0.04390653595328331\n",
      "epoch: 1 step: 2076, loss is 0.005645664408802986\n",
      "epoch: 1 step: 2077, loss is 0.024557914584875107\n",
      "epoch: 1 step: 2078, loss is 0.147142231464386\n",
      "epoch: 1 step: 2079, loss is 0.03767136484384537\n",
      "epoch: 1 step: 2080, loss is 0.07310785353183746\n",
      "epoch: 1 step: 2081, loss is 0.08479496091604233\n",
      "epoch: 1 step: 2082, loss is 0.008817913010716438\n",
      "epoch: 1 step: 2083, loss is 0.19135123491287231\n",
      "epoch: 1 step: 2084, loss is 0.003163837594911456\n",
      "epoch: 1 step: 2085, loss is 0.07442188262939453\n",
      "epoch: 1 step: 2086, loss is 0.07727599889039993\n",
      "epoch: 1 step: 2087, loss is 0.04055078327655792\n",
      "epoch: 1 step: 2088, loss is 0.012361702509224415\n",
      "epoch: 1 step: 2089, loss is 0.13217753171920776\n",
      "epoch: 1 step: 2090, loss is 0.012227448634803295\n",
      "epoch: 1 step: 2091, loss is 0.007231938187032938\n",
      "epoch: 1 step: 2092, loss is 0.006066701374948025\n",
      "epoch: 1 step: 2093, loss is 0.15689700841903687\n",
      "epoch: 1 step: 2094, loss is 0.010927959345281124\n",
      "epoch: 1 step: 2095, loss is 0.001544538652524352\n",
      "epoch: 1 step: 2096, loss is 0.10769359022378922\n",
      "epoch: 1 step: 2097, loss is 0.17752860486507416\n",
      "epoch: 1 step: 2098, loss is 0.15523654222488403\n",
      "epoch: 1 step: 2099, loss is 0.014548609964549541\n",
      "epoch: 1 step: 2100, loss is 0.06254614144563675\n",
      "epoch: 1 step: 2101, loss is 0.15033194422721863\n",
      "epoch: 1 step: 2102, loss is 0.23460368812084198\n",
      "epoch: 1 step: 2103, loss is 0.004430937580764294\n",
      "epoch: 1 step: 2104, loss is 0.0527837835252285\n",
      "epoch: 1 step: 2105, loss is 0.006170156877487898\n",
      "epoch: 1 step: 2106, loss is 0.011764719150960445\n",
      "epoch: 1 step: 2107, loss is 0.0396408848464489\n",
      "epoch: 1 step: 2108, loss is 0.011544416658580303\n",
      "epoch: 1 step: 2109, loss is 0.0067384676076471806\n",
      "epoch: 1 step: 2110, loss is 0.10610532015562057\n",
      "epoch: 1 step: 2111, loss is 0.0065688481554389\n",
      "epoch: 1 step: 2112, loss is 0.14262822270393372\n",
      "epoch: 1 step: 2113, loss is 0.0332639217376709\n",
      "epoch: 1 step: 2114, loss is 0.030709195882081985\n",
      "epoch: 1 step: 2115, loss is 0.008080540224909782\n",
      "epoch: 1 step: 2116, loss is 0.04659225046634674\n",
      "epoch: 1 step: 2117, loss is 0.1600124090909958\n",
      "epoch: 1 step: 2118, loss is 0.014737444929778576\n",
      "epoch: 1 step: 2119, loss is 0.23244509100914001\n",
      "epoch: 1 step: 2120, loss is 0.00556330056861043\n",
      "epoch: 1 step: 2121, loss is 0.22780631482601166\n",
      "epoch: 1 step: 2122, loss is 0.3219963610172272\n",
      "epoch: 1 step: 2123, loss is 0.017106592655181885\n",
      "epoch: 1 step: 2124, loss is 0.014052484184503555\n",
      "epoch: 1 step: 2125, loss is 0.2786233127117157\n",
      "epoch: 1 step: 2126, loss is 0.07630845159292221\n",
      "epoch: 1 step: 2127, loss is 0.1516977697610855\n",
      "epoch: 1 step: 2128, loss is 0.004918306600302458\n",
      "epoch: 1 step: 2129, loss is 0.03023768588900566\n",
      "epoch: 1 step: 2130, loss is 0.06387331336736679\n",
      "epoch: 1 step: 2131, loss is 0.03300490975379944\n",
      "epoch: 1 step: 2132, loss is 0.08501512557268143\n",
      "epoch: 1 step: 2133, loss is 0.0066025168634951115\n",
      "epoch: 1 step: 2134, loss is 0.10989344120025635\n",
      "epoch: 1 step: 2135, loss is 0.08883551508188248\n",
      "epoch: 1 step: 2136, loss is 0.09483163803815842\n",
      "epoch: 1 step: 2137, loss is 0.11036230623722076\n",
      "epoch: 1 step: 2138, loss is 0.15421156585216522\n",
      "epoch: 1 step: 2139, loss is 0.051251672208309174\n",
      "epoch: 1 step: 2140, loss is 0.33556926250457764\n",
      "epoch: 1 step: 2141, loss is 0.14570501446723938\n",
      "epoch: 1 step: 2142, loss is 0.30701518058776855\n",
      "epoch: 1 step: 2143, loss is 0.09094615280628204\n",
      "epoch: 1 step: 2144, loss is 0.04509352520108223\n",
      "epoch: 1 step: 2145, loss is 0.005200413055717945\n",
      "epoch: 1 step: 2146, loss is 0.24442371726036072\n",
      "epoch: 1 step: 2147, loss is 0.13658058643341064\n",
      "epoch: 1 step: 2148, loss is 0.027197059243917465\n",
      "epoch: 1 step: 2149, loss is 0.01689145900309086\n",
      "epoch: 1 step: 2150, loss is 0.017351994290947914\n",
      "epoch: 1 step: 2151, loss is 0.0421094186604023\n",
      "epoch: 1 step: 2152, loss is 0.004045325797051191\n",
      "epoch: 1 step: 2153, loss is 0.016602259129285812\n",
      "epoch: 1 step: 2154, loss is 0.06756217777729034\n",
      "epoch: 1 step: 2155, loss is 0.026010558009147644\n",
      "epoch: 1 step: 2156, loss is 0.002272021723911166\n",
      "epoch: 1 step: 2157, loss is 0.06995020061731339\n",
      "epoch: 1 step: 2158, loss is 0.00783613696694374\n",
      "epoch: 1 step: 2159, loss is 0.06384158134460449\n",
      "epoch: 1 step: 2160, loss is 0.10701743513345718\n",
      "epoch: 1 step: 2161, loss is 0.05532239004969597\n",
      "epoch: 1 step: 2162, loss is 0.053715553134679794\n",
      "epoch: 1 step: 2163, loss is 0.0036073157098144293\n",
      "epoch: 1 step: 2164, loss is 0.27775871753692627\n",
      "epoch: 1 step: 2165, loss is 0.02239351160824299\n",
      "epoch: 1 step: 2166, loss is 0.24016793072223663\n",
      "epoch: 1 step: 2167, loss is 0.004896041005849838\n",
      "epoch: 1 step: 2168, loss is 0.00833181943744421\n",
      "epoch: 1 step: 2169, loss is 0.07766184955835342\n",
      "epoch: 1 step: 2170, loss is 0.08258256316184998\n",
      "epoch: 1 step: 2171, loss is 0.018612027168273926\n",
      "epoch: 1 step: 2172, loss is 0.031837765127420425\n",
      "epoch: 1 step: 2173, loss is 0.004878262523561716\n",
      "epoch: 1 step: 2174, loss is 0.03184155002236366\n",
      "epoch: 1 step: 2175, loss is 0.003914467990398407\n",
      "epoch: 1 step: 2176, loss is 0.11798666417598724\n",
      "epoch: 1 step: 2177, loss is 0.017198259010910988\n",
      "epoch: 1 step: 2178, loss is 0.004229754209518433\n",
      "epoch: 1 step: 2179, loss is 0.24730892479419708\n",
      "epoch: 1 step: 2180, loss is 0.06831970065832138\n",
      "epoch: 1 step: 2181, loss is 0.0050074150785803795\n",
      "epoch: 1 step: 2182, loss is 0.08059462159872055\n",
      "epoch: 1 step: 2183, loss is 0.06536349654197693\n",
      "epoch: 1 step: 2184, loss is 0.02958434633910656\n",
      "epoch: 1 step: 2185, loss is 0.17808470129966736\n",
      "epoch: 1 step: 2186, loss is 0.004047563765197992\n",
      "epoch: 1 step: 2187, loss is 0.04498518258333206\n",
      "epoch: 2 step: 1, loss is 0.00304581830278039\n",
      "epoch: 2 step: 2, loss is 0.02189852111041546\n",
      "epoch: 2 step: 3, loss is 0.07343075424432755\n",
      "epoch: 2 step: 4, loss is 0.04741678386926651\n",
      "epoch: 2 step: 5, loss is 0.006960519589483738\n",
      "epoch: 2 step: 6, loss is 0.12948185205459595\n",
      "epoch: 2 step: 7, loss is 0.34242013096809387\n",
      "epoch: 2 step: 8, loss is 0.04500141367316246\n",
      "epoch: 2 step: 9, loss is 0.07678399980068207\n",
      "epoch: 2 step: 10, loss is 0.009330223314464092\n",
      "epoch: 2 step: 11, loss is 0.013136674650013447\n",
      "epoch: 2 step: 12, loss is 0.2590388059616089\n",
      "epoch: 2 step: 13, loss is 0.017291229218244553\n",
      "epoch: 2 step: 14, loss is 0.03477877005934715\n",
      "epoch: 2 step: 15, loss is 0.021057672798633575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 16, loss is 0.06100604683160782\n",
      "epoch: 2 step: 17, loss is 0.024007173255085945\n",
      "epoch: 2 step: 18, loss is 0.010738963261246681\n",
      "epoch: 2 step: 19, loss is 0.006826065946370363\n",
      "epoch: 2 step: 20, loss is 0.10025569796562195\n",
      "epoch: 2 step: 21, loss is 0.002188390353694558\n",
      "epoch: 2 step: 22, loss is 0.3281690776348114\n",
      "epoch: 2 step: 23, loss is 0.04626629501581192\n",
      "epoch: 2 step: 24, loss is 0.014061564579606056\n",
      "epoch: 2 step: 25, loss is 0.0271637961268425\n",
      "epoch: 2 step: 26, loss is 0.013628214597702026\n",
      "epoch: 2 step: 27, loss is 0.025987083092331886\n",
      "epoch: 2 step: 28, loss is 0.06193333491683006\n",
      "epoch: 2 step: 29, loss is 0.022467663511633873\n",
      "epoch: 2 step: 30, loss is 0.023733850568532944\n",
      "epoch: 2 step: 31, loss is 0.08477118611335754\n",
      "epoch: 2 step: 32, loss is 0.12424872070550919\n",
      "epoch: 2 step: 33, loss is 0.004547164775431156\n",
      "epoch: 2 step: 34, loss is 0.1099422350525856\n",
      "epoch: 2 step: 35, loss is 0.06600237637758255\n",
      "epoch: 2 step: 36, loss is 0.00460507906973362\n",
      "epoch: 2 step: 37, loss is 0.011612171307206154\n",
      "epoch: 2 step: 38, loss is 0.02180846780538559\n",
      "epoch: 2 step: 39, loss is 0.010708530433475971\n",
      "epoch: 2 step: 40, loss is 0.1225767657160759\n",
      "epoch: 2 step: 41, loss is 0.0863519236445427\n",
      "epoch: 2 step: 42, loss is 0.1716836839914322\n",
      "epoch: 2 step: 43, loss is 0.061931509524583817\n",
      "epoch: 2 step: 44, loss is 0.03567052632570267\n",
      "epoch: 2 step: 45, loss is 0.007481346372514963\n",
      "epoch: 2 step: 46, loss is 0.004563795868307352\n",
      "epoch: 2 step: 47, loss is 0.2833384871482849\n",
      "epoch: 2 step: 48, loss is 0.008757337927818298\n",
      "epoch: 2 step: 49, loss is 0.0023962731938809156\n",
      "epoch: 2 step: 50, loss is 0.17710727453231812\n",
      "epoch: 2 step: 51, loss is 0.06653743982315063\n",
      "epoch: 2 step: 52, loss is 0.03928383067250252\n",
      "epoch: 2 step: 53, loss is 0.010916205123066902\n",
      "epoch: 2 step: 54, loss is 0.016513649374246597\n",
      "epoch: 2 step: 55, loss is 0.0251440592110157\n",
      "epoch: 2 step: 56, loss is 0.01888563483953476\n",
      "epoch: 2 step: 57, loss is 0.02996101789176464\n",
      "epoch: 2 step: 58, loss is 0.011069885455071926\n",
      "epoch: 2 step: 59, loss is 0.16932086646556854\n",
      "epoch: 2 step: 60, loss is 0.059284135699272156\n",
      "epoch: 2 step: 61, loss is 0.01124492660164833\n",
      "epoch: 2 step: 62, loss is 0.02927875518798828\n",
      "epoch: 2 step: 63, loss is 0.006879047490656376\n",
      "epoch: 2 step: 64, loss is 0.003485671943053603\n",
      "epoch: 2 step: 65, loss is 0.03939078748226166\n",
      "epoch: 2 step: 66, loss is 0.013808582909405231\n",
      "epoch: 2 step: 67, loss is 0.004340837709605694\n",
      "epoch: 2 step: 68, loss is 0.1094692274928093\n",
      "epoch: 2 step: 69, loss is 0.02293669618666172\n",
      "epoch: 2 step: 70, loss is 0.013754751533269882\n",
      "epoch: 2 step: 71, loss is 0.09223559498786926\n",
      "epoch: 2 step: 72, loss is 0.09747432172298431\n",
      "epoch: 2 step: 73, loss is 0.009243100881576538\n",
      "epoch: 2 step: 74, loss is 0.012361221015453339\n",
      "epoch: 2 step: 75, loss is 0.07216791808605194\n",
      "epoch: 2 step: 76, loss is 0.004166102968156338\n",
      "epoch: 2 step: 77, loss is 0.009364200755953789\n",
      "epoch: 2 step: 78, loss is 0.015198138542473316\n",
      "epoch: 2 step: 79, loss is 0.039717670530080795\n",
      "epoch: 2 step: 80, loss is 0.008323940448462963\n",
      "epoch: 2 step: 81, loss is 0.023013250902295113\n",
      "epoch: 2 step: 82, loss is 0.16609179973602295\n",
      "epoch: 2 step: 83, loss is 0.025840282440185547\n",
      "epoch: 2 step: 84, loss is 0.001018036506138742\n",
      "epoch: 2 step: 85, loss is 0.0016528349369764328\n",
      "epoch: 2 step: 86, loss is 0.011713368818163872\n",
      "epoch: 2 step: 87, loss is 0.024179330095648766\n",
      "epoch: 2 step: 88, loss is 0.024681096896529198\n",
      "epoch: 2 step: 89, loss is 0.0012232885928824544\n",
      "epoch: 2 step: 90, loss is 0.027841104194521904\n",
      "epoch: 2 step: 91, loss is 0.002911270596086979\n",
      "epoch: 2 step: 92, loss is 0.007562215905636549\n",
      "epoch: 2 step: 93, loss is 0.008016768842935562\n",
      "epoch: 2 step: 94, loss is 0.299672394990921\n",
      "epoch: 2 step: 95, loss is 0.12349369376897812\n",
      "epoch: 2 step: 96, loss is 0.0005841896054334939\n",
      "epoch: 2 step: 97, loss is 0.024774936959147453\n",
      "epoch: 2 step: 98, loss is 0.06035665422677994\n",
      "epoch: 2 step: 99, loss is 0.10719887912273407\n",
      "epoch: 2 step: 100, loss is 0.17030535638332367\n",
      "epoch: 2 step: 101, loss is 0.04051816463470459\n",
      "epoch: 2 step: 102, loss is 0.024334678426384926\n",
      "epoch: 2 step: 103, loss is 0.013943301513791084\n",
      "epoch: 2 step: 104, loss is 0.012874739244580269\n",
      "epoch: 2 step: 105, loss is 0.006686522159725428\n",
      "epoch: 2 step: 106, loss is 0.03921361267566681\n",
      "epoch: 2 step: 107, loss is 0.06965862214565277\n",
      "epoch: 2 step: 108, loss is 0.09588123112916946\n",
      "epoch: 2 step: 109, loss is 0.00801444798707962\n",
      "epoch: 2 step: 110, loss is 0.004791774787008762\n",
      "epoch: 2 step: 111, loss is 0.19761329889297485\n",
      "epoch: 2 step: 112, loss is 0.02181950956583023\n",
      "epoch: 2 step: 113, loss is 0.020770838484168053\n",
      "epoch: 2 step: 114, loss is 0.24060486257076263\n",
      "epoch: 2 step: 115, loss is 0.07571257650852203\n",
      "epoch: 2 step: 116, loss is 0.18521061539649963\n",
      "epoch: 2 step: 117, loss is 0.0373610220849514\n",
      "epoch: 2 step: 118, loss is 0.007043357938528061\n",
      "epoch: 2 step: 119, loss is 0.11660999804735184\n",
      "epoch: 2 step: 120, loss is 0.014191579073667526\n",
      "epoch: 2 step: 121, loss is 0.03333643078804016\n",
      "epoch: 2 step: 122, loss is 0.11184849590063095\n",
      "epoch: 2 step: 123, loss is 0.03348936140537262\n",
      "epoch: 2 step: 124, loss is 0.00721081392839551\n",
      "epoch: 2 step: 125, loss is 0.046577055007219315\n",
      "epoch: 2 step: 126, loss is 0.19514985382556915\n",
      "epoch: 2 step: 127, loss is 0.11278273165225983\n",
      "epoch: 2 step: 128, loss is 0.11602848023176193\n",
      "epoch: 2 step: 129, loss is 0.018334174528717995\n",
      "epoch: 2 step: 130, loss is 0.013856825418770313\n",
      "epoch: 2 step: 131, loss is 0.048686519265174866\n",
      "epoch: 2 step: 132, loss is 0.03416275233030319\n",
      "epoch: 2 step: 133, loss is 0.03375691547989845\n",
      "epoch: 2 step: 134, loss is 0.07758660614490509\n",
      "epoch: 2 step: 135, loss is 0.04074155539274216\n",
      "epoch: 2 step: 136, loss is 0.05840452015399933\n",
      "epoch: 2 step: 137, loss is 0.0018270426662638783\n",
      "epoch: 2 step: 138, loss is 0.001968376338481903\n",
      "epoch: 2 step: 139, loss is 0.014712759293615818\n",
      "epoch: 2 step: 140, loss is 0.09146328270435333\n",
      "epoch: 2 step: 141, loss is 0.040490590035915375\n",
      "epoch: 2 step: 142, loss is 0.1600727140903473\n",
      "epoch: 2 step: 143, loss is 0.032442357391119\n",
      "epoch: 2 step: 144, loss is 0.08066597580909729\n",
      "epoch: 2 step: 145, loss is 0.042666882276535034\n",
      "epoch: 2 step: 146, loss is 0.010667241178452969\n",
      "epoch: 2 step: 147, loss is 0.07986350357532501\n",
      "epoch: 2 step: 148, loss is 0.017130039632320404\n",
      "epoch: 2 step: 149, loss is 0.07004199177026749\n",
      "epoch: 2 step: 150, loss is 0.008646148256957531\n",
      "epoch: 2 step: 151, loss is 0.0016019027680158615\n",
      "epoch: 2 step: 152, loss is 0.0013394784182310104\n",
      "epoch: 2 step: 153, loss is 0.10321250557899475\n",
      "epoch: 2 step: 154, loss is 0.007416602224111557\n",
      "epoch: 2 step: 155, loss is 0.1396331638097763\n",
      "epoch: 2 step: 156, loss is 0.007637457922101021\n",
      "epoch: 2 step: 157, loss is 0.1503121703863144\n",
      "epoch: 2 step: 158, loss is 0.0961107686161995\n",
      "epoch: 2 step: 159, loss is 0.035612184554338455\n",
      "epoch: 2 step: 160, loss is 0.017759036272764206\n",
      "epoch: 2 step: 161, loss is 0.07151880115270615\n",
      "epoch: 2 step: 162, loss is 0.22275279462337494\n",
      "epoch: 2 step: 163, loss is 0.06346721202135086\n",
      "epoch: 2 step: 164, loss is 0.17553594708442688\n",
      "epoch: 2 step: 165, loss is 0.013928646221756935\n",
      "epoch: 2 step: 166, loss is 0.010619757696986198\n",
      "epoch: 2 step: 167, loss is 0.09890101104974747\n",
      "epoch: 2 step: 168, loss is 0.015347153879702091\n",
      "epoch: 2 step: 169, loss is 0.03348749503493309\n",
      "epoch: 2 step: 170, loss is 0.08489686995744705\n",
      "epoch: 2 step: 171, loss is 0.08921492099761963\n",
      "epoch: 2 step: 172, loss is 0.010480191558599472\n",
      "epoch: 2 step: 173, loss is 0.020197808742523193\n",
      "epoch: 2 step: 174, loss is 0.024414731189608574\n",
      "epoch: 2 step: 175, loss is 0.020182106643915176\n",
      "epoch: 2 step: 176, loss is 0.014945837669074535\n",
      "epoch: 2 step: 177, loss is 0.044852301478385925\n",
      "epoch: 2 step: 178, loss is 0.09794948995113373\n",
      "epoch: 2 step: 179, loss is 0.002295747632160783\n",
      "epoch: 2 step: 180, loss is 0.04943171888589859\n",
      "epoch: 2 step: 181, loss is 0.04640118032693863\n",
      "epoch: 2 step: 182, loss is 0.04735090211033821\n",
      "epoch: 2 step: 183, loss is 0.0032160887494683266\n",
      "epoch: 2 step: 184, loss is 0.07641679793596268\n",
      "epoch: 2 step: 185, loss is 0.002225451171398163\n",
      "epoch: 2 step: 186, loss is 0.0954912006855011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 187, loss is 0.0029210741631686687\n",
      "epoch: 2 step: 188, loss is 0.09262656420469284\n",
      "epoch: 2 step: 189, loss is 0.051439233124256134\n",
      "epoch: 2 step: 190, loss is 0.006674550473690033\n",
      "epoch: 2 step: 191, loss is 0.0023484104312956333\n",
      "epoch: 2 step: 192, loss is 0.010242295451462269\n",
      "epoch: 2 step: 193, loss is 0.06549658626317978\n",
      "epoch: 2 step: 194, loss is 0.03228284791111946\n",
      "epoch: 2 step: 195, loss is 0.013376508839428425\n",
      "epoch: 2 step: 196, loss is 0.005419047549366951\n",
      "epoch: 2 step: 197, loss is 0.0007548260036855936\n",
      "epoch: 2 step: 198, loss is 0.1187121719121933\n",
      "epoch: 2 step: 199, loss is 0.032066475600004196\n",
      "epoch: 2 step: 200, loss is 0.014822406694293022\n",
      "epoch: 2 step: 201, loss is 0.024967726320028305\n",
      "epoch: 2 step: 202, loss is 0.06221739947795868\n",
      "epoch: 2 step: 203, loss is 0.4359198808670044\n",
      "epoch: 2 step: 204, loss is 0.120168037712574\n",
      "epoch: 2 step: 205, loss is 0.1380840390920639\n",
      "epoch: 2 step: 206, loss is 0.10555221885442734\n",
      "epoch: 2 step: 207, loss is 0.0077064186334609985\n",
      "epoch: 2 step: 208, loss is 0.24144691228866577\n",
      "epoch: 2 step: 209, loss is 0.008582230657339096\n",
      "epoch: 2 step: 210, loss is 0.15988312661647797\n",
      "epoch: 2 step: 211, loss is 0.11288712918758392\n",
      "epoch: 2 step: 212, loss is 0.05169036239385605\n",
      "epoch: 2 step: 213, loss is 0.0961008071899414\n",
      "epoch: 2 step: 214, loss is 0.055575110018253326\n",
      "epoch: 2 step: 215, loss is 0.05420200526714325\n",
      "epoch: 2 step: 216, loss is 0.037389371544122696\n",
      "epoch: 2 step: 217, loss is 0.0039518726989626884\n",
      "epoch: 2 step: 218, loss is 0.07336004823446274\n",
      "epoch: 2 step: 219, loss is 0.08604978770017624\n",
      "epoch: 2 step: 220, loss is 0.002884738380089402\n",
      "epoch: 2 step: 221, loss is 0.0027989433147013187\n",
      "epoch: 2 step: 222, loss is 0.14076939225196838\n",
      "epoch: 2 step: 223, loss is 0.030450766906142235\n",
      "epoch: 2 step: 224, loss is 0.014430561102926731\n",
      "epoch: 2 step: 225, loss is 0.007831016555428505\n",
      "epoch: 2 step: 226, loss is 0.01195884682238102\n",
      "epoch: 2 step: 227, loss is 0.010306132026016712\n",
      "epoch: 2 step: 228, loss is 0.07070091366767883\n",
      "epoch: 2 step: 229, loss is 0.09751579165458679\n",
      "epoch: 2 step: 230, loss is 0.01238155271857977\n",
      "epoch: 2 step: 231, loss is 0.017609892413020134\n",
      "epoch: 2 step: 232, loss is 0.2624126970767975\n",
      "epoch: 2 step: 233, loss is 0.05909343436360359\n",
      "epoch: 2 step: 234, loss is 0.03208708390593529\n",
      "epoch: 2 step: 235, loss is 0.0015674192691221833\n",
      "epoch: 2 step: 236, loss is 0.05613115802407265\n",
      "epoch: 2 step: 237, loss is 0.05793878808617592\n",
      "epoch: 2 step: 238, loss is 0.004511210136115551\n",
      "epoch: 2 step: 239, loss is 0.005391725804656744\n",
      "epoch: 2 step: 240, loss is 0.046096593141555786\n",
      "epoch: 2 step: 241, loss is 0.2573181390762329\n",
      "epoch: 2 step: 242, loss is 0.03653664514422417\n",
      "epoch: 2 step: 243, loss is 0.08823707699775696\n",
      "epoch: 2 step: 244, loss is 0.016427308320999146\n",
      "epoch: 2 step: 245, loss is 0.03049284964799881\n",
      "epoch: 2 step: 246, loss is 0.09174291044473648\n",
      "epoch: 2 step: 247, loss is 0.11117777228355408\n",
      "epoch: 2 step: 248, loss is 0.06596667319536209\n",
      "epoch: 2 step: 249, loss is 0.010138299316167831\n",
      "epoch: 2 step: 250, loss is 0.21069343388080597\n",
      "epoch: 2 step: 251, loss is 0.3400852084159851\n",
      "epoch: 2 step: 252, loss is 0.08293598145246506\n",
      "epoch: 2 step: 253, loss is 0.015709079802036285\n",
      "epoch: 2 step: 254, loss is 0.0840035080909729\n",
      "epoch: 2 step: 255, loss is 0.00793954636901617\n",
      "epoch: 2 step: 256, loss is 0.00988072995096445\n",
      "epoch: 2 step: 257, loss is 0.1759122759103775\n",
      "epoch: 2 step: 258, loss is 0.02192413993179798\n",
      "epoch: 2 step: 259, loss is 0.004883253946900368\n",
      "epoch: 2 step: 260, loss is 0.03077254816889763\n",
      "epoch: 2 step: 261, loss is 0.016437672078609467\n",
      "epoch: 2 step: 262, loss is 0.12259970605373383\n",
      "epoch: 2 step: 263, loss is 0.07073557376861572\n",
      "epoch: 2 step: 264, loss is 0.13001154363155365\n",
      "epoch: 2 step: 265, loss is 0.07633532583713531\n",
      "epoch: 2 step: 266, loss is 0.02060985006392002\n",
      "epoch: 2 step: 267, loss is 0.0024609353858977556\n",
      "epoch: 2 step: 268, loss is 0.009489904157817364\n",
      "epoch: 2 step: 269, loss is 0.005343659780919552\n",
      "epoch: 2 step: 270, loss is 0.007263231556862593\n",
      "epoch: 2 step: 271, loss is 0.029312118887901306\n",
      "epoch: 2 step: 272, loss is 0.144987553358078\n",
      "epoch: 2 step: 273, loss is 0.019004279747605324\n",
      "epoch: 2 step: 274, loss is 0.04972711205482483\n",
      "epoch: 2 step: 275, loss is 0.035512592643499374\n",
      "epoch: 2 step: 276, loss is 0.03149263933300972\n",
      "epoch: 2 step: 277, loss is 0.00913555733859539\n",
      "epoch: 2 step: 278, loss is 0.013829330913722515\n",
      "epoch: 2 step: 279, loss is 0.013549845665693283\n",
      "epoch: 2 step: 280, loss is 0.1334044188261032\n",
      "epoch: 2 step: 281, loss is 0.06615682691335678\n",
      "epoch: 2 step: 282, loss is 0.20426185429096222\n",
      "epoch: 2 step: 283, loss is 0.07667176425457001\n",
      "epoch: 2 step: 284, loss is 0.026980087161064148\n",
      "epoch: 2 step: 285, loss is 0.011548475362360477\n",
      "epoch: 2 step: 286, loss is 0.0017631200607866049\n",
      "epoch: 2 step: 287, loss is 0.01037649903446436\n",
      "epoch: 2 step: 288, loss is 0.003400756511837244\n",
      "epoch: 2 step: 289, loss is 0.07100449502468109\n",
      "epoch: 2 step: 290, loss is 0.003005208447575569\n",
      "epoch: 2 step: 291, loss is 0.007547616958618164\n",
      "epoch: 2 step: 292, loss is 0.02519252896308899\n",
      "epoch: 2 step: 293, loss is 0.019847901538014412\n",
      "epoch: 2 step: 294, loss is 0.008318588137626648\n",
      "epoch: 2 step: 295, loss is 0.006030272226780653\n",
      "epoch: 2 step: 296, loss is 0.05154682323336601\n",
      "epoch: 2 step: 297, loss is 0.015127786435186863\n",
      "epoch: 2 step: 298, loss is 0.0441206693649292\n",
      "epoch: 2 step: 299, loss is 0.03333233669400215\n",
      "epoch: 2 step: 300, loss is 0.0023454539477825165\n",
      "epoch: 2 step: 301, loss is 0.009115136228501797\n",
      "epoch: 2 step: 302, loss is 0.025998026132583618\n",
      "epoch: 2 step: 303, loss is 0.1250782161951065\n",
      "epoch: 2 step: 304, loss is 0.0755954459309578\n",
      "epoch: 2 step: 305, loss is 0.0017153079388663173\n",
      "epoch: 2 step: 306, loss is 0.004946214146912098\n",
      "epoch: 2 step: 307, loss is 0.021123524755239487\n",
      "epoch: 2 step: 308, loss is 0.011314363218843937\n",
      "epoch: 2 step: 309, loss is 0.07510420680046082\n",
      "epoch: 2 step: 310, loss is 0.007521557155996561\n",
      "epoch: 2 step: 311, loss is 0.011728559620678425\n",
      "epoch: 2 step: 312, loss is 0.17468152940273285\n",
      "epoch: 2 step: 313, loss is 0.14095918834209442\n",
      "epoch: 2 step: 314, loss is 0.00245244475081563\n",
      "epoch: 2 step: 315, loss is 0.07832007855176926\n",
      "epoch: 2 step: 316, loss is 0.13612565398216248\n",
      "epoch: 2 step: 317, loss is 0.06348738074302673\n",
      "epoch: 2 step: 318, loss is 0.008796620182693005\n",
      "epoch: 2 step: 319, loss is 0.03832225874066353\n",
      "epoch: 2 step: 320, loss is 0.0005014031194150448\n",
      "epoch: 2 step: 321, loss is 0.07415761053562164\n",
      "epoch: 2 step: 322, loss is 0.012107540853321552\n",
      "epoch: 2 step: 323, loss is 0.16975584626197815\n",
      "epoch: 2 step: 324, loss is 0.05203741788864136\n",
      "epoch: 2 step: 325, loss is 0.03631126508116722\n",
      "epoch: 2 step: 326, loss is 0.006954996380954981\n",
      "epoch: 2 step: 327, loss is 0.03377477452158928\n",
      "epoch: 2 step: 328, loss is 0.01604004204273224\n",
      "epoch: 2 step: 329, loss is 0.055273305624723434\n",
      "epoch: 2 step: 330, loss is 0.000723028089851141\n",
      "epoch: 2 step: 331, loss is 0.10975757986307144\n",
      "epoch: 2 step: 332, loss is 0.012179032899439335\n",
      "epoch: 2 step: 333, loss is 0.2374032437801361\n",
      "epoch: 2 step: 334, loss is 0.09550520777702332\n",
      "epoch: 2 step: 335, loss is 0.05804352089762688\n",
      "epoch: 2 step: 336, loss is 0.01904166117310524\n",
      "epoch: 2 step: 337, loss is 0.0009262027451768517\n",
      "epoch: 2 step: 338, loss is 0.13800375163555145\n",
      "epoch: 2 step: 339, loss is 0.0058481767773628235\n",
      "epoch: 2 step: 340, loss is 0.012647782452404499\n",
      "epoch: 2 step: 341, loss is 0.11912577599287033\n",
      "epoch: 2 step: 342, loss is 0.04038798436522484\n",
      "epoch: 2 step: 343, loss is 0.08287044614553452\n",
      "epoch: 2 step: 344, loss is 0.12046206742525101\n",
      "epoch: 2 step: 345, loss is 0.02237674407660961\n",
      "epoch: 2 step: 346, loss is 0.005435781553387642\n",
      "epoch: 2 step: 347, loss is 0.010386789217591286\n",
      "epoch: 2 step: 348, loss is 0.057556137442588806\n",
      "epoch: 2 step: 349, loss is 0.06811950355768204\n",
      "epoch: 2 step: 350, loss is 0.04107830673456192\n",
      "epoch: 2 step: 351, loss is 0.04183072969317436\n",
      "epoch: 2 step: 352, loss is 0.004045679699629545\n",
      "epoch: 2 step: 353, loss is 0.029297245666384697\n",
      "epoch: 2 step: 354, loss is 0.009212580509483814\n",
      "epoch: 2 step: 355, loss is 0.002087716944515705\n",
      "epoch: 2 step: 356, loss is 0.0025989008136093616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 357, loss is 0.008029894903302193\n",
      "epoch: 2 step: 358, loss is 0.02933543361723423\n",
      "epoch: 2 step: 359, loss is 0.04330308362841606\n",
      "epoch: 2 step: 360, loss is 0.008794102817773819\n",
      "epoch: 2 step: 361, loss is 0.19788162410259247\n",
      "epoch: 2 step: 362, loss is 0.000529047567397356\n",
      "epoch: 2 step: 363, loss is 0.0006838973495177925\n",
      "epoch: 2 step: 364, loss is 0.040788546204566956\n",
      "epoch: 2 step: 365, loss is 0.26290228962898254\n",
      "epoch: 2 step: 366, loss is 0.15275810658931732\n",
      "epoch: 2 step: 367, loss is 0.005953857209533453\n",
      "epoch: 2 step: 368, loss is 0.03379572555422783\n",
      "epoch: 2 step: 369, loss is 0.004575215280056\n",
      "epoch: 2 step: 370, loss is 0.029227696359157562\n",
      "epoch: 2 step: 371, loss is 0.06261080503463745\n",
      "epoch: 2 step: 372, loss is 0.11490123718976974\n",
      "epoch: 2 step: 373, loss is 0.02228430286049843\n",
      "epoch: 2 step: 374, loss is 0.14867350459098816\n",
      "epoch: 2 step: 375, loss is 0.0015383799327537417\n",
      "epoch: 2 step: 376, loss is 0.007468131370842457\n",
      "epoch: 2 step: 377, loss is 0.03774069994688034\n",
      "epoch: 2 step: 378, loss is 0.004235766362398863\n",
      "epoch: 2 step: 379, loss is 0.00512452470138669\n",
      "epoch: 2 step: 380, loss is 0.012691027484834194\n",
      "epoch: 2 step: 381, loss is 0.007864768616855145\n",
      "epoch: 2 step: 382, loss is 0.13894978165626526\n",
      "epoch: 2 step: 383, loss is 0.01757584884762764\n",
      "epoch: 2 step: 384, loss is 0.0890362486243248\n",
      "epoch: 2 step: 385, loss is 0.1766076385974884\n",
      "epoch: 2 step: 386, loss is 0.12180574238300323\n",
      "epoch: 2 step: 387, loss is 0.04554416611790657\n",
      "epoch: 2 step: 388, loss is 0.05931774526834488\n",
      "epoch: 2 step: 389, loss is 0.042861517518758774\n",
      "epoch: 2 step: 390, loss is 0.035091593861579895\n",
      "epoch: 2 step: 391, loss is 0.02399325743317604\n",
      "epoch: 2 step: 392, loss is 0.1058824434876442\n",
      "epoch: 2 step: 393, loss is 0.033528365194797516\n",
      "epoch: 2 step: 394, loss is 0.017215562984347343\n",
      "epoch: 2 step: 395, loss is 0.008023553527891636\n",
      "epoch: 2 step: 396, loss is 0.09418174624443054\n",
      "epoch: 2 step: 397, loss is 0.006167977582663298\n",
      "epoch: 2 step: 398, loss is 0.13467568159103394\n",
      "epoch: 2 step: 399, loss is 0.012488321401178837\n",
      "epoch: 2 step: 400, loss is 0.20877103507518768\n",
      "epoch: 2 step: 401, loss is 0.12012536823749542\n",
      "epoch: 2 step: 402, loss is 0.0033644847571849823\n",
      "epoch: 2 step: 403, loss is 0.02227320335805416\n",
      "epoch: 2 step: 404, loss is 0.07793479412794113\n",
      "epoch: 2 step: 405, loss is 0.0410693921148777\n",
      "epoch: 2 step: 406, loss is 0.03355930745601654\n",
      "epoch: 2 step: 407, loss is 0.01573788747191429\n",
      "epoch: 2 step: 408, loss is 0.013991273939609528\n",
      "epoch: 2 step: 409, loss is 0.07208386808633804\n",
      "epoch: 2 step: 410, loss is 0.22605319321155548\n",
      "epoch: 2 step: 411, loss is 0.017629258334636688\n",
      "epoch: 2 step: 412, loss is 0.011536825448274612\n",
      "epoch: 2 step: 413, loss is 0.0011098480317741632\n",
      "epoch: 2 step: 414, loss is 0.000953234382905066\n",
      "epoch: 2 step: 415, loss is 0.14961321651935577\n",
      "epoch: 2 step: 416, loss is 0.026952167972922325\n",
      "epoch: 2 step: 417, loss is 0.3810301423072815\n",
      "epoch: 2 step: 418, loss is 0.0014202177990227938\n",
      "epoch: 2 step: 419, loss is 0.03997652232646942\n",
      "epoch: 2 step: 420, loss is 0.02543710172176361\n",
      "epoch: 2 step: 421, loss is 0.005736098159104586\n",
      "epoch: 2 step: 422, loss is 0.05510035902261734\n",
      "epoch: 2 step: 423, loss is 0.0810994952917099\n",
      "epoch: 2 step: 424, loss is 0.013650770299136639\n",
      "epoch: 2 step: 425, loss is 0.01512669026851654\n",
      "epoch: 2 step: 426, loss is 0.0058246091939508915\n",
      "epoch: 2 step: 427, loss is 0.026235608384013176\n",
      "epoch: 2 step: 428, loss is 0.037209559231996536\n",
      "epoch: 2 step: 429, loss is 0.0462382547557354\n",
      "epoch: 2 step: 430, loss is 0.0036947811022400856\n",
      "epoch: 2 step: 431, loss is 0.005903960671275854\n",
      "epoch: 2 step: 432, loss is 0.13749812543392181\n",
      "epoch: 2 step: 433, loss is 0.03665836527943611\n",
      "epoch: 2 step: 434, loss is 0.12838780879974365\n",
      "epoch: 2 step: 435, loss is 0.0033703141380101442\n",
      "epoch: 2 step: 436, loss is 0.08594226837158203\n",
      "epoch: 2 step: 437, loss is 0.059412140399217606\n",
      "epoch: 2 step: 438, loss is 0.003834324888885021\n",
      "epoch: 2 step: 439, loss is 0.07001414149999619\n",
      "epoch: 2 step: 440, loss is 0.006274852901697159\n",
      "epoch: 2 step: 441, loss is 0.07349210232496262\n",
      "epoch: 2 step: 442, loss is 0.013104704208672047\n",
      "epoch: 2 step: 443, loss is 0.0016416833968833089\n",
      "epoch: 2 step: 444, loss is 0.023191697895526886\n",
      "epoch: 2 step: 445, loss is 0.006057169288396835\n",
      "epoch: 2 step: 446, loss is 0.005806722678244114\n",
      "epoch: 2 step: 447, loss is 0.04127681627869606\n",
      "epoch: 2 step: 448, loss is 0.20426511764526367\n",
      "epoch: 2 step: 449, loss is 0.002200509188696742\n",
      "epoch: 2 step: 450, loss is 0.006173508707433939\n",
      "epoch: 2 step: 451, loss is 0.0018129401141777635\n",
      "epoch: 2 step: 452, loss is 0.0515320785343647\n",
      "epoch: 2 step: 453, loss is 0.2979973554611206\n",
      "epoch: 2 step: 454, loss is 0.37877997756004333\n",
      "epoch: 2 step: 455, loss is 0.004770895000547171\n",
      "epoch: 2 step: 456, loss is 0.01145061757415533\n",
      "epoch: 2 step: 457, loss is 0.0730714350938797\n",
      "epoch: 2 step: 458, loss is 0.112428680062294\n",
      "epoch: 2 step: 459, loss is 0.005790054798126221\n",
      "epoch: 2 step: 460, loss is 0.006138240918517113\n",
      "epoch: 2 step: 461, loss is 0.10316798090934753\n",
      "epoch: 2 step: 462, loss is 0.01104335393756628\n",
      "epoch: 2 step: 463, loss is 0.2064216434955597\n",
      "epoch: 2 step: 464, loss is 0.0568072535097599\n",
      "epoch: 2 step: 465, loss is 0.003334446344524622\n",
      "epoch: 2 step: 466, loss is 0.03416166082024574\n",
      "epoch: 2 step: 467, loss is 0.09977778792381287\n",
      "epoch: 2 step: 468, loss is 0.04781371355056763\n",
      "epoch: 2 step: 469, loss is 0.010242925956845284\n",
      "epoch: 2 step: 470, loss is 0.007025431375950575\n",
      "epoch: 2 step: 471, loss is 0.01434393972158432\n",
      "epoch: 2 step: 472, loss is 0.059140894562006\n",
      "epoch: 2 step: 473, loss is 0.024977559223771095\n",
      "epoch: 2 step: 474, loss is 0.007030533626675606\n",
      "epoch: 2 step: 475, loss is 0.012455364689230919\n",
      "epoch: 2 step: 476, loss is 0.017799686640501022\n",
      "epoch: 2 step: 477, loss is 0.010925973765552044\n",
      "epoch: 2 step: 478, loss is 0.006402802187949419\n",
      "epoch: 2 step: 479, loss is 0.05602826178073883\n",
      "epoch: 2 step: 480, loss is 0.11728885769844055\n",
      "epoch: 2 step: 481, loss is 0.018172841519117355\n",
      "epoch: 2 step: 482, loss is 0.05552084371447563\n",
      "epoch: 2 step: 483, loss is 0.23329629004001617\n",
      "epoch: 2 step: 484, loss is 0.002542892936617136\n",
      "epoch: 2 step: 485, loss is 0.12111538648605347\n",
      "epoch: 2 step: 486, loss is 0.012939607724547386\n",
      "epoch: 2 step: 487, loss is 0.037443410605192184\n",
      "epoch: 2 step: 488, loss is 0.050367094576358795\n",
      "epoch: 2 step: 489, loss is 0.030834747478365898\n",
      "epoch: 2 step: 490, loss is 0.017604008316993713\n",
      "epoch: 2 step: 491, loss is 0.01717313937842846\n",
      "epoch: 2 step: 492, loss is 0.11437754333019257\n",
      "epoch: 2 step: 493, loss is 0.1321098655462265\n",
      "epoch: 2 step: 494, loss is 0.004343200474977493\n",
      "epoch: 2 step: 495, loss is 0.21691499650478363\n",
      "epoch: 2 step: 496, loss is 0.03694726899266243\n",
      "epoch: 2 step: 497, loss is 0.002835371531546116\n",
      "epoch: 2 step: 498, loss is 0.06041913852095604\n",
      "epoch: 2 step: 499, loss is 0.13388366997241974\n",
      "epoch: 2 step: 500, loss is 0.0672077164053917\n",
      "epoch: 2 step: 501, loss is 0.05031416192650795\n",
      "epoch: 2 step: 502, loss is 0.118792325258255\n",
      "epoch: 2 step: 503, loss is 0.03041612170636654\n",
      "epoch: 2 step: 504, loss is 0.10762515664100647\n",
      "epoch: 2 step: 505, loss is 0.018378444015979767\n",
      "epoch: 2 step: 506, loss is 0.06889955699443817\n",
      "epoch: 2 step: 507, loss is 0.11617184430360794\n",
      "epoch: 2 step: 508, loss is 0.005538469180464745\n",
      "epoch: 2 step: 509, loss is 0.007872155867516994\n",
      "epoch: 2 step: 510, loss is 0.003854809794574976\n",
      "epoch: 2 step: 511, loss is 0.10020041465759277\n",
      "epoch: 2 step: 512, loss is 0.001024528406560421\n",
      "epoch: 2 step: 513, loss is 0.038003090769052505\n",
      "epoch: 2 step: 514, loss is 0.0025286462623625994\n",
      "epoch: 2 step: 515, loss is 0.0013880003243684769\n",
      "epoch: 2 step: 516, loss is 0.0016380029264837503\n",
      "epoch: 2 step: 517, loss is 0.04088249430060387\n",
      "epoch: 2 step: 518, loss is 0.012837544083595276\n",
      "epoch: 2 step: 519, loss is 0.05854879319667816\n",
      "epoch: 2 step: 520, loss is 0.12427366524934769\n",
      "epoch: 2 step: 521, loss is 0.006700701080262661\n",
      "epoch: 2 step: 522, loss is 0.011513733305037022\n",
      "epoch: 2 step: 523, loss is 0.011014026589691639\n",
      "epoch: 2 step: 524, loss is 0.009845687076449394\n",
      "epoch: 2 step: 525, loss is 0.03395523503422737\n",
      "epoch: 2 step: 526, loss is 0.03265269845724106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 527, loss is 0.22074605524539948\n",
      "epoch: 2 step: 528, loss is 0.004915940575301647\n",
      "epoch: 2 step: 529, loss is 0.12459760159254074\n",
      "epoch: 2 step: 530, loss is 0.032078973948955536\n",
      "epoch: 2 step: 531, loss is 0.014229311607778072\n",
      "epoch: 2 step: 532, loss is 0.038505442440509796\n",
      "epoch: 2 step: 533, loss is 0.13664069771766663\n",
      "epoch: 2 step: 534, loss is 0.013823526911437511\n",
      "epoch: 2 step: 535, loss is 0.036672938615083694\n",
      "epoch: 2 step: 536, loss is 0.047335658222436905\n",
      "epoch: 2 step: 537, loss is 0.0016115133184939623\n",
      "epoch: 2 step: 538, loss is 0.047385748475790024\n",
      "epoch: 2 step: 539, loss is 0.0180682186037302\n",
      "epoch: 2 step: 540, loss is 0.20029520988464355\n",
      "epoch: 2 step: 541, loss is 0.208749458193779\n",
      "epoch: 2 step: 542, loss is 0.0015283036045730114\n",
      "epoch: 2 step: 543, loss is 0.18812023103237152\n",
      "epoch: 2 step: 544, loss is 0.12805256247520447\n",
      "epoch: 2 step: 545, loss is 0.036818474531173706\n",
      "epoch: 2 step: 546, loss is 0.030076056718826294\n",
      "epoch: 2 step: 547, loss is 0.004252552520483732\n",
      "epoch: 2 step: 548, loss is 0.16119259595870972\n",
      "epoch: 2 step: 549, loss is 0.02476559579372406\n",
      "epoch: 2 step: 550, loss is 0.11530129611492157\n",
      "epoch: 2 step: 551, loss is 0.011073444969952106\n",
      "epoch: 2 step: 552, loss is 0.032073553651571274\n",
      "epoch: 2 step: 553, loss is 0.01311718113720417\n",
      "epoch: 2 step: 554, loss is 0.11051048338413239\n",
      "epoch: 2 step: 555, loss is 0.08036164194345474\n",
      "epoch: 2 step: 556, loss is 0.002207122975960374\n",
      "epoch: 2 step: 557, loss is 0.011900979094207287\n",
      "epoch: 2 step: 558, loss is 0.0014871854800730944\n",
      "epoch: 2 step: 559, loss is 0.0005176757113076746\n",
      "epoch: 2 step: 560, loss is 0.028011932969093323\n",
      "epoch: 2 step: 561, loss is 0.059314701706171036\n",
      "epoch: 2 step: 562, loss is 0.12934930622577667\n",
      "epoch: 2 step: 563, loss is 0.15508580207824707\n",
      "epoch: 2 step: 564, loss is 0.22089731693267822\n",
      "epoch: 2 step: 565, loss is 0.0015795843210071325\n",
      "epoch: 2 step: 566, loss is 0.039051298052072525\n",
      "epoch: 2 step: 567, loss is 0.017433244735002518\n",
      "epoch: 2 step: 568, loss is 0.04445866495370865\n",
      "epoch: 2 step: 569, loss is 0.08577503263950348\n",
      "epoch: 2 step: 570, loss is 0.05056462809443474\n",
      "epoch: 2 step: 571, loss is 0.017166413366794586\n",
      "epoch: 2 step: 572, loss is 0.03292936459183693\n",
      "epoch: 2 step: 573, loss is 0.034330662339925766\n",
      "epoch: 2 step: 574, loss is 0.098444864153862\n",
      "epoch: 2 step: 575, loss is 0.19802802801132202\n",
      "epoch: 2 step: 576, loss is 0.1507261097431183\n",
      "epoch: 2 step: 577, loss is 0.024920718744397163\n",
      "epoch: 2 step: 578, loss is 0.16556814312934875\n",
      "epoch: 2 step: 579, loss is 0.007922887802124023\n",
      "epoch: 2 step: 580, loss is 0.01587698608636856\n",
      "epoch: 2 step: 581, loss is 0.07439059764146805\n",
      "epoch: 2 step: 582, loss is 0.016329364851117134\n",
      "epoch: 2 step: 583, loss is 0.02857356145977974\n",
      "epoch: 2 step: 584, loss is 0.012263013049960136\n",
      "epoch: 2 step: 585, loss is 0.049819767475128174\n",
      "epoch: 2 step: 586, loss is 0.10508595407009125\n",
      "epoch: 2 step: 587, loss is 0.03844289854168892\n",
      "epoch: 2 step: 588, loss is 0.005652622319757938\n",
      "epoch: 2 step: 589, loss is 0.01799565926194191\n",
      "epoch: 2 step: 590, loss is 0.008437255397439003\n",
      "epoch: 2 step: 591, loss is 0.014571158215403557\n",
      "epoch: 2 step: 592, loss is 0.011881002224981785\n",
      "epoch: 2 step: 593, loss is 0.016089484095573425\n",
      "epoch: 2 step: 594, loss is 0.23588760197162628\n",
      "epoch: 2 step: 595, loss is 0.0269003976136446\n",
      "epoch: 2 step: 596, loss is 0.02043624222278595\n",
      "epoch: 2 step: 597, loss is 0.0029658698476850986\n",
      "epoch: 2 step: 598, loss is 0.09462960809469223\n",
      "epoch: 2 step: 599, loss is 0.01420949399471283\n",
      "epoch: 2 step: 600, loss is 0.04353254660964012\n",
      "epoch: 2 step: 601, loss is 0.17488828301429749\n",
      "epoch: 2 step: 602, loss is 0.0495414100587368\n",
      "epoch: 2 step: 603, loss is 0.14038586616516113\n",
      "epoch: 2 step: 604, loss is 0.056943248957395554\n",
      "epoch: 2 step: 605, loss is 0.11456914246082306\n",
      "epoch: 2 step: 606, loss is 0.025142740458250046\n",
      "epoch: 2 step: 607, loss is 0.011306853964924812\n",
      "epoch: 2 step: 608, loss is 0.1780342310667038\n",
      "epoch: 2 step: 609, loss is 0.021454423666000366\n",
      "epoch: 2 step: 610, loss is 0.08033087104558945\n",
      "epoch: 2 step: 611, loss is 0.04056226462125778\n",
      "epoch: 2 step: 612, loss is 0.027400897815823555\n",
      "epoch: 2 step: 613, loss is 0.03965939208865166\n",
      "epoch: 2 step: 614, loss is 0.002613356104120612\n",
      "epoch: 2 step: 615, loss is 0.09447085857391357\n",
      "epoch: 2 step: 616, loss is 0.09608528017997742\n",
      "epoch: 2 step: 617, loss is 0.004097424913197756\n",
      "epoch: 2 step: 618, loss is 0.07930876314640045\n",
      "epoch: 2 step: 619, loss is 0.13124658167362213\n",
      "epoch: 2 step: 620, loss is 0.011065690778195858\n",
      "epoch: 2 step: 621, loss is 0.009423259645700455\n",
      "epoch: 2 step: 622, loss is 0.05396063253283501\n",
      "epoch: 2 step: 623, loss is 0.030269859358668327\n",
      "epoch: 2 step: 624, loss is 0.007852885872125626\n",
      "epoch: 2 step: 625, loss is 0.03872296214103699\n",
      "epoch: 2 step: 626, loss is 0.050991352647542953\n",
      "epoch: 2 step: 627, loss is 0.0019935767631977797\n",
      "epoch: 2 step: 628, loss is 0.004959768615663052\n",
      "epoch: 2 step: 629, loss is 0.04404948651790619\n",
      "epoch: 2 step: 630, loss is 0.02001427300274372\n",
      "epoch: 2 step: 631, loss is 0.06389559060335159\n",
      "epoch: 2 step: 632, loss is 0.08971899747848511\n",
      "epoch: 2 step: 633, loss is 0.054246630519628525\n",
      "epoch: 2 step: 634, loss is 0.05505630373954773\n",
      "epoch: 2 step: 635, loss is 0.06204918771982193\n",
      "epoch: 2 step: 636, loss is 0.10939808189868927\n",
      "epoch: 2 step: 637, loss is 0.009022156707942486\n",
      "epoch: 2 step: 638, loss is 0.0024669531267136335\n",
      "epoch: 2 step: 639, loss is 0.16523893177509308\n",
      "epoch: 2 step: 640, loss is 0.004095771349966526\n",
      "epoch: 2 step: 641, loss is 0.16673415899276733\n",
      "epoch: 2 step: 642, loss is 0.21326158940792084\n",
      "epoch: 2 step: 643, loss is 0.037834879010915756\n",
      "epoch: 2 step: 644, loss is 0.034497201442718506\n",
      "epoch: 2 step: 645, loss is 0.008251572027802467\n",
      "epoch: 2 step: 646, loss is 0.008876388892531395\n",
      "epoch: 2 step: 647, loss is 0.07833275198936462\n",
      "epoch: 2 step: 648, loss is 0.009873557835817337\n",
      "epoch: 2 step: 649, loss is 0.16955424845218658\n",
      "epoch: 2 step: 650, loss is 0.012745528481900692\n",
      "epoch: 2 step: 651, loss is 0.0071069421246647835\n",
      "epoch: 2 step: 652, loss is 0.0886412262916565\n",
      "epoch: 2 step: 653, loss is 0.005539061035960913\n",
      "epoch: 2 step: 654, loss is 0.03435409814119339\n",
      "epoch: 2 step: 655, loss is 0.16530467569828033\n",
      "epoch: 2 step: 656, loss is 0.43583256006240845\n",
      "epoch: 2 step: 657, loss is 0.026092709973454475\n",
      "epoch: 2 step: 658, loss is 0.07197429239749908\n",
      "epoch: 2 step: 659, loss is 0.005279450677335262\n",
      "epoch: 2 step: 660, loss is 0.005473244469612837\n",
      "epoch: 2 step: 661, loss is 0.0031450707465410233\n",
      "epoch: 2 step: 662, loss is 0.07631292939186096\n",
      "epoch: 2 step: 663, loss is 0.0019443248165771365\n",
      "epoch: 2 step: 664, loss is 0.3424796760082245\n",
      "epoch: 2 step: 665, loss is 0.03051815554499626\n",
      "epoch: 2 step: 666, loss is 0.028444845229387283\n",
      "epoch: 2 step: 667, loss is 0.03350235894322395\n",
      "epoch: 2 step: 668, loss is 0.02236061356961727\n",
      "epoch: 2 step: 669, loss is 0.15366250276565552\n",
      "epoch: 2 step: 670, loss is 0.2263258993625641\n",
      "epoch: 2 step: 671, loss is 0.08395121246576309\n",
      "epoch: 2 step: 672, loss is 0.010734515264630318\n",
      "epoch: 2 step: 673, loss is 0.03899442031979561\n",
      "epoch: 2 step: 674, loss is 0.07060850411653519\n",
      "epoch: 2 step: 675, loss is 0.08211877942085266\n",
      "epoch: 2 step: 676, loss is 0.011857225559651852\n",
      "epoch: 2 step: 677, loss is 0.21882514655590057\n",
      "epoch: 2 step: 678, loss is 0.16985462605953217\n",
      "epoch: 2 step: 679, loss is 0.07048329710960388\n",
      "epoch: 2 step: 680, loss is 0.011229025200009346\n",
      "epoch: 2 step: 681, loss is 0.005764969624578953\n",
      "epoch: 2 step: 682, loss is 0.3642990291118622\n",
      "epoch: 2 step: 683, loss is 0.09115287661552429\n",
      "epoch: 2 step: 684, loss is 0.2086893618106842\n",
      "epoch: 2 step: 685, loss is 0.04610710218548775\n",
      "epoch: 2 step: 686, loss is 0.008458150550723076\n",
      "epoch: 2 step: 687, loss is 0.11084325611591339\n",
      "epoch: 2 step: 688, loss is 0.07172311097383499\n",
      "epoch: 2 step: 689, loss is 0.006313798017799854\n",
      "epoch: 2 step: 690, loss is 0.0200551338493824\n",
      "epoch: 2 step: 691, loss is 0.07258061319589615\n",
      "epoch: 2 step: 692, loss is 0.01712931878864765\n",
      "epoch: 2 step: 693, loss is 0.010172671638429165\n",
      "epoch: 2 step: 694, loss is 0.0640009418129921\n",
      "epoch: 2 step: 695, loss is 0.2231772243976593\n",
      "epoch: 2 step: 696, loss is 0.01536521501839161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 697, loss is 0.02075064741075039\n",
      "epoch: 2 step: 698, loss is 0.06087150052189827\n",
      "epoch: 2 step: 699, loss is 0.035518042743206024\n",
      "epoch: 2 step: 700, loss is 0.14160118997097015\n",
      "epoch: 2 step: 701, loss is 0.14792129397392273\n",
      "epoch: 2 step: 702, loss is 0.007319771219044924\n",
      "epoch: 2 step: 703, loss is 0.027157582342624664\n",
      "epoch: 2 step: 704, loss is 0.0518629252910614\n",
      "epoch: 2 step: 705, loss is 0.006301390938460827\n",
      "epoch: 2 step: 706, loss is 0.36890074610710144\n",
      "epoch: 2 step: 707, loss is 0.039035864174366\n",
      "epoch: 2 step: 708, loss is 0.0037043821066617966\n",
      "epoch: 2 step: 709, loss is 0.00812527071684599\n",
      "epoch: 2 step: 710, loss is 0.06854887306690216\n",
      "epoch: 2 step: 711, loss is 0.004381773993372917\n",
      "epoch: 2 step: 712, loss is 0.024167008697986603\n",
      "epoch: 2 step: 713, loss is 0.05714568868279457\n",
      "epoch: 2 step: 714, loss is 0.014068888500332832\n",
      "epoch: 2 step: 715, loss is 0.022503497079014778\n",
      "epoch: 2 step: 716, loss is 0.037887971848249435\n",
      "epoch: 2 step: 717, loss is 0.11497105658054352\n",
      "epoch: 2 step: 718, loss is 0.006427513901144266\n",
      "epoch: 2 step: 719, loss is 0.043791092932224274\n",
      "epoch: 2 step: 720, loss is 0.04862977936863899\n",
      "epoch: 2 step: 721, loss is 0.03753191605210304\n",
      "epoch: 2 step: 722, loss is 0.01219880674034357\n",
      "epoch: 2 step: 723, loss is 0.03448152169585228\n",
      "epoch: 2 step: 724, loss is 0.01828080601990223\n",
      "epoch: 2 step: 725, loss is 0.14154323935508728\n",
      "epoch: 2 step: 726, loss is 0.00583435595035553\n",
      "epoch: 2 step: 727, loss is 0.017894092947244644\n",
      "epoch: 2 step: 728, loss is 0.0902239978313446\n",
      "epoch: 2 step: 729, loss is 0.008866513147950172\n",
      "epoch: 2 step: 730, loss is 0.05897613242268562\n",
      "epoch: 2 step: 731, loss is 0.010209307074546814\n",
      "epoch: 2 step: 732, loss is 0.006507947109639645\n",
      "epoch: 2 step: 733, loss is 0.06726504862308502\n",
      "epoch: 2 step: 734, loss is 0.1010158434510231\n",
      "epoch: 2 step: 735, loss is 0.11555003374814987\n",
      "epoch: 2 step: 736, loss is 0.04550674185156822\n",
      "epoch: 2 step: 737, loss is 0.1529725044965744\n",
      "epoch: 2 step: 738, loss is 0.103073351085186\n",
      "epoch: 2 step: 739, loss is 0.009757994674146175\n",
      "epoch: 2 step: 740, loss is 0.01814536564052105\n",
      "epoch: 2 step: 741, loss is 0.06556019186973572\n",
      "epoch: 2 step: 742, loss is 0.026097383350133896\n",
      "epoch: 2 step: 743, loss is 0.028302932158112526\n",
      "epoch: 2 step: 744, loss is 0.18647634983062744\n",
      "epoch: 2 step: 745, loss is 0.00570214306935668\n",
      "epoch: 2 step: 746, loss is 0.06148742139339447\n",
      "epoch: 2 step: 747, loss is 0.01423635147511959\n",
      "epoch: 2 step: 748, loss is 0.011366046033799648\n",
      "epoch: 2 step: 749, loss is 0.02711019478738308\n",
      "epoch: 2 step: 750, loss is 0.02424989454448223\n",
      "epoch: 2 step: 751, loss is 0.03531072661280632\n",
      "epoch: 2 step: 752, loss is 0.010409573093056679\n",
      "epoch: 2 step: 753, loss is 0.0340670645236969\n",
      "epoch: 2 step: 754, loss is 0.29559430480003357\n",
      "epoch: 2 step: 755, loss is 0.04622563347220421\n",
      "epoch: 2 step: 756, loss is 0.11715442687273026\n",
      "epoch: 2 step: 757, loss is 0.008435838855803013\n",
      "epoch: 2 step: 758, loss is 0.04292258620262146\n",
      "epoch: 2 step: 759, loss is 0.024157648906111717\n",
      "epoch: 2 step: 760, loss is 0.009807010181248188\n",
      "epoch: 2 step: 761, loss is 0.0013815801357850432\n",
      "epoch: 2 step: 762, loss is 0.03049873188138008\n",
      "epoch: 2 step: 763, loss is 0.07835526019334793\n",
      "epoch: 2 step: 764, loss is 0.004203335847705603\n",
      "epoch: 2 step: 765, loss is 0.0020210985094308853\n",
      "epoch: 2 step: 766, loss is 0.026963191106915474\n",
      "epoch: 2 step: 767, loss is 0.4242505431175232\n",
      "epoch: 2 step: 768, loss is 0.12383482605218887\n",
      "epoch: 2 step: 769, loss is 0.009632648900151253\n",
      "epoch: 2 step: 770, loss is 0.01662451960146427\n",
      "epoch: 2 step: 771, loss is 0.053887322545051575\n",
      "epoch: 2 step: 772, loss is 0.04895570129156113\n",
      "epoch: 2 step: 773, loss is 0.057712070643901825\n",
      "epoch: 2 step: 774, loss is 0.07257039844989777\n",
      "epoch: 2 step: 775, loss is 0.0653396025300026\n",
      "epoch: 2 step: 776, loss is 0.07605288177728653\n",
      "epoch: 2 step: 777, loss is 0.11820457875728607\n",
      "epoch: 2 step: 778, loss is 0.0016716731479391456\n",
      "epoch: 2 step: 779, loss is 0.023908322677016258\n",
      "epoch: 2 step: 780, loss is 0.0016903304494917393\n",
      "epoch: 2 step: 781, loss is 0.1146131157875061\n",
      "epoch: 2 step: 782, loss is 0.03385237231850624\n",
      "epoch: 2 step: 783, loss is 0.005824886728078127\n",
      "epoch: 2 step: 784, loss is 0.12217669934034348\n",
      "epoch: 2 step: 785, loss is 0.1611732393503189\n",
      "epoch: 2 step: 786, loss is 0.012782778590917587\n",
      "epoch: 2 step: 787, loss is 0.006771603599190712\n",
      "epoch: 2 step: 788, loss is 0.06096072122454643\n",
      "epoch: 2 step: 789, loss is 0.009710361249744892\n",
      "epoch: 2 step: 790, loss is 0.01866275444626808\n",
      "epoch: 2 step: 791, loss is 0.09341312944889069\n",
      "epoch: 2 step: 792, loss is 0.2748010456562042\n",
      "epoch: 2 step: 793, loss is 0.07809106260538101\n",
      "epoch: 2 step: 794, loss is 0.0496358759701252\n",
      "epoch: 2 step: 795, loss is 0.008752086199820042\n",
      "epoch: 2 step: 796, loss is 0.021743325516581535\n",
      "epoch: 2 step: 797, loss is 0.0494166761636734\n",
      "epoch: 2 step: 798, loss is 0.003593093017116189\n",
      "epoch: 2 step: 799, loss is 0.14838574826717377\n",
      "epoch: 2 step: 800, loss is 0.2053636610507965\n",
      "epoch: 2 step: 801, loss is 0.015372319146990776\n",
      "epoch: 2 step: 802, loss is 0.10215826332569122\n",
      "epoch: 2 step: 803, loss is 0.0028734353836625814\n",
      "epoch: 2 step: 804, loss is 0.023604337126016617\n",
      "epoch: 2 step: 805, loss is 0.032849349081516266\n",
      "epoch: 2 step: 806, loss is 0.001393437385559082\n",
      "epoch: 2 step: 807, loss is 0.002050096867606044\n",
      "epoch: 2 step: 808, loss is 0.2001517415046692\n",
      "epoch: 2 step: 809, loss is 0.05369638651609421\n",
      "epoch: 2 step: 810, loss is 0.030289623886346817\n",
      "epoch: 2 step: 811, loss is 0.0798974484205246\n",
      "epoch: 2 step: 812, loss is 0.041554998606443405\n",
      "epoch: 2 step: 813, loss is 0.05470013618469238\n",
      "epoch: 2 step: 814, loss is 0.06852927058935165\n",
      "epoch: 2 step: 815, loss is 0.002873346209526062\n",
      "epoch: 2 step: 816, loss is 0.008420203812420368\n",
      "epoch: 2 step: 817, loss is 0.012203081510961056\n",
      "epoch: 2 step: 818, loss is 0.004669610410928726\n",
      "epoch: 2 step: 819, loss is 0.0012992043048143387\n",
      "epoch: 2 step: 820, loss is 0.005381116643548012\n",
      "epoch: 2 step: 821, loss is 0.054341934621334076\n",
      "epoch: 2 step: 822, loss is 0.036961112171411514\n",
      "epoch: 2 step: 823, loss is 0.006699457764625549\n",
      "epoch: 2 step: 824, loss is 0.09224338829517365\n",
      "epoch: 2 step: 825, loss is 0.07606113702058792\n",
      "epoch: 2 step: 826, loss is 0.034626130014657974\n",
      "epoch: 2 step: 827, loss is 0.07997548580169678\n",
      "epoch: 2 step: 828, loss is 0.006083235144615173\n",
      "epoch: 2 step: 829, loss is 0.05675928667187691\n",
      "epoch: 2 step: 830, loss is 0.0019510274287313223\n",
      "epoch: 2 step: 831, loss is 0.0008771767024882138\n",
      "epoch: 2 step: 832, loss is 0.15701930224895477\n",
      "epoch: 2 step: 833, loss is 0.13428708910942078\n",
      "epoch: 2 step: 834, loss is 0.002171147149056196\n",
      "epoch: 2 step: 835, loss is 0.0006489112856797874\n",
      "epoch: 2 step: 836, loss is 0.0008558579720556736\n",
      "epoch: 2 step: 837, loss is 0.010468126274645329\n",
      "epoch: 2 step: 838, loss is 0.027823297306895256\n",
      "epoch: 2 step: 839, loss is 0.016994932666420937\n",
      "epoch: 2 step: 840, loss is 0.03042975626885891\n",
      "epoch: 2 step: 841, loss is 0.19061176478862762\n",
      "epoch: 2 step: 842, loss is 0.05593082308769226\n",
      "epoch: 2 step: 843, loss is 0.007566370069980621\n",
      "epoch: 2 step: 844, loss is 0.009132225066423416\n",
      "epoch: 2 step: 845, loss is 0.06863176077604294\n",
      "epoch: 2 step: 846, loss is 0.0012777986703440547\n",
      "epoch: 2 step: 847, loss is 0.086509570479393\n",
      "epoch: 2 step: 848, loss is 0.015503746457397938\n",
      "epoch: 2 step: 849, loss is 0.05107153207063675\n",
      "epoch: 2 step: 850, loss is 0.02552463859319687\n",
      "epoch: 2 step: 851, loss is 0.008480261079967022\n",
      "epoch: 2 step: 852, loss is 0.22070761024951935\n",
      "epoch: 2 step: 853, loss is 0.00930074043571949\n",
      "epoch: 2 step: 854, loss is 0.09839998185634613\n",
      "epoch: 2 step: 855, loss is 0.003356195753440261\n",
      "epoch: 2 step: 856, loss is 0.0040755560621619225\n",
      "epoch: 2 step: 857, loss is 0.07291766256093979\n",
      "epoch: 2 step: 858, loss is 0.03674570098519325\n",
      "epoch: 2 step: 859, loss is 0.003763571847230196\n",
      "epoch: 2 step: 860, loss is 0.031026596203446388\n",
      "epoch: 2 step: 861, loss is 0.06121012568473816\n",
      "epoch: 2 step: 862, loss is 0.16394343972206116\n",
      "epoch: 2 step: 863, loss is 0.008979786187410355\n",
      "epoch: 2 step: 864, loss is 0.0008825927507132292\n",
      "epoch: 2 step: 865, loss is 0.009021257981657982\n",
      "epoch: 2 step: 866, loss is 0.02079286240041256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 867, loss is 0.20719586312770844\n",
      "epoch: 2 step: 868, loss is 0.013262994587421417\n",
      "epoch: 2 step: 869, loss is 0.004139031749218702\n",
      "epoch: 2 step: 870, loss is 0.007661988027393818\n",
      "epoch: 2 step: 871, loss is 0.037747785449028015\n",
      "epoch: 2 step: 872, loss is 0.010963758453726768\n",
      "epoch: 2 step: 873, loss is 0.09741798788309097\n",
      "epoch: 2 step: 874, loss is 0.05293875187635422\n",
      "epoch: 2 step: 875, loss is 0.01962684839963913\n",
      "epoch: 2 step: 876, loss is 0.07991275936365128\n",
      "epoch: 2 step: 877, loss is 0.06471257656812668\n",
      "epoch: 2 step: 878, loss is 0.25294768810272217\n",
      "epoch: 2 step: 879, loss is 0.011725247837603092\n",
      "epoch: 2 step: 880, loss is 0.15866661071777344\n",
      "epoch: 2 step: 881, loss is 0.06547330319881439\n",
      "epoch: 2 step: 882, loss is 0.05225400626659393\n",
      "epoch: 2 step: 883, loss is 0.006193642038851976\n",
      "epoch: 2 step: 884, loss is 0.04640199616551399\n",
      "epoch: 2 step: 885, loss is 0.0019128036219626665\n",
      "epoch: 2 step: 886, loss is 0.02720351703464985\n",
      "epoch: 2 step: 887, loss is 0.05666561797261238\n",
      "epoch: 2 step: 888, loss is 0.016654033213853836\n",
      "epoch: 2 step: 889, loss is 0.23673658072948456\n",
      "epoch: 2 step: 890, loss is 0.05121937394142151\n",
      "epoch: 2 step: 891, loss is 0.17997689545154572\n",
      "epoch: 2 step: 892, loss is 0.12211360037326813\n",
      "epoch: 2 step: 893, loss is 0.025869078934192657\n",
      "epoch: 2 step: 894, loss is 0.0030310489237308502\n",
      "epoch: 2 step: 895, loss is 0.025796301662921906\n",
      "epoch: 2 step: 896, loss is 0.06973906606435776\n",
      "epoch: 2 step: 897, loss is 0.005357217974960804\n",
      "epoch: 2 step: 898, loss is 0.026544885709881783\n",
      "epoch: 2 step: 899, loss is 0.029363833367824554\n",
      "epoch: 2 step: 900, loss is 0.2635839879512787\n",
      "epoch: 2 step: 901, loss is 0.1898212432861328\n",
      "epoch: 2 step: 902, loss is 0.013885179534554482\n",
      "epoch: 2 step: 903, loss is 0.10355257242918015\n",
      "epoch: 2 step: 904, loss is 0.004205640871077776\n",
      "epoch: 2 step: 905, loss is 0.05982082709670067\n",
      "epoch: 2 step: 906, loss is 0.12463489919900894\n",
      "epoch: 2 step: 907, loss is 0.15296165645122528\n",
      "epoch: 2 step: 908, loss is 0.15988846123218536\n",
      "epoch: 2 step: 909, loss is 0.03714030981063843\n",
      "epoch: 2 step: 910, loss is 0.012889758683741093\n",
      "epoch: 2 step: 911, loss is 0.006478778552263975\n",
      "epoch: 2 step: 912, loss is 0.12653034925460815\n",
      "epoch: 2 step: 913, loss is 0.007775518111884594\n",
      "epoch: 2 step: 914, loss is 0.0007748150383122265\n",
      "epoch: 2 step: 915, loss is 0.11727846413850784\n",
      "epoch: 2 step: 916, loss is 0.042584314942359924\n",
      "epoch: 2 step: 917, loss is 0.024439679458737373\n",
      "epoch: 2 step: 918, loss is 0.09371835738420486\n",
      "epoch: 2 step: 919, loss is 0.11278810352087021\n",
      "epoch: 2 step: 920, loss is 0.03520611301064491\n",
      "epoch: 2 step: 921, loss is 0.004866642877459526\n",
      "epoch: 2 step: 922, loss is 0.01189515646547079\n",
      "epoch: 2 step: 923, loss is 0.054181475192308426\n",
      "epoch: 2 step: 924, loss is 0.07318846881389618\n",
      "epoch: 2 step: 925, loss is 0.01541853416711092\n",
      "epoch: 2 step: 926, loss is 0.018779369071125984\n",
      "epoch: 2 step: 927, loss is 0.07599582523107529\n",
      "epoch: 2 step: 928, loss is 0.014204651117324829\n",
      "epoch: 2 step: 929, loss is 0.24487543106079102\n",
      "epoch: 2 step: 930, loss is 0.008633206598460674\n",
      "epoch: 2 step: 931, loss is 0.012233379296958447\n",
      "epoch: 2 step: 932, loss is 0.03233746066689491\n",
      "epoch: 2 step: 933, loss is 0.013009302318096161\n",
      "epoch: 2 step: 934, loss is 0.003964931238442659\n",
      "epoch: 2 step: 935, loss is 0.06733840703964233\n",
      "epoch: 2 step: 936, loss is 0.02267042174935341\n",
      "epoch: 2 step: 937, loss is 0.024054402485489845\n",
      "epoch: 2 step: 938, loss is 0.012918946333229542\n",
      "epoch: 2 step: 939, loss is 0.01589624211192131\n",
      "epoch: 2 step: 940, loss is 0.0010046620154753327\n",
      "epoch: 2 step: 941, loss is 0.053701408207416534\n",
      "epoch: 2 step: 942, loss is 0.00271016638725996\n",
      "epoch: 2 step: 943, loss is 0.19531846046447754\n",
      "epoch: 2 step: 944, loss is 0.015273717232048512\n",
      "epoch: 2 step: 945, loss is 0.0016437434824183583\n",
      "epoch: 2 step: 946, loss is 0.003912733402103186\n",
      "epoch: 2 step: 947, loss is 0.03065785951912403\n",
      "epoch: 2 step: 948, loss is 0.0016758765559643507\n",
      "epoch: 2 step: 949, loss is 0.0006329369498416781\n",
      "epoch: 2 step: 950, loss is 0.0007063414668664336\n",
      "epoch: 2 step: 951, loss is 0.12680259346961975\n",
      "epoch: 2 step: 952, loss is 0.0015889505157247186\n",
      "epoch: 2 step: 953, loss is 0.0779920220375061\n",
      "epoch: 2 step: 954, loss is 0.004280224908143282\n",
      "epoch: 2 step: 955, loss is 0.006843956653028727\n",
      "epoch: 2 step: 956, loss is 0.0009451484074816108\n",
      "epoch: 2 step: 957, loss is 0.0045549459755420685\n",
      "epoch: 2 step: 958, loss is 0.08496437966823578\n",
      "epoch: 2 step: 959, loss is 0.002034877659752965\n",
      "epoch: 2 step: 960, loss is 0.0016251729102805257\n",
      "epoch: 2 step: 961, loss is 0.04412130266427994\n",
      "epoch: 2 step: 962, loss is 0.07756881415843964\n",
      "epoch: 2 step: 963, loss is 0.008048586547374725\n",
      "epoch: 2 step: 964, loss is 0.009949661791324615\n",
      "epoch: 2 step: 965, loss is 0.04428945481777191\n",
      "epoch: 2 step: 966, loss is 0.046127475798130035\n",
      "epoch: 2 step: 967, loss is 0.07934392988681793\n",
      "epoch: 2 step: 968, loss is 0.018617497757077217\n",
      "epoch: 2 step: 969, loss is 0.05098981782793999\n",
      "epoch: 2 step: 970, loss is 0.006977935787290335\n",
      "epoch: 2 step: 971, loss is 0.0011738750617951155\n",
      "epoch: 2 step: 972, loss is 0.015828588977456093\n",
      "epoch: 2 step: 973, loss is 0.1863834708929062\n",
      "epoch: 2 step: 974, loss is 0.015323801897466183\n",
      "epoch: 2 step: 975, loss is 0.0024353652261197567\n",
      "epoch: 2 step: 976, loss is 0.03168420121073723\n",
      "epoch: 2 step: 977, loss is 0.043041519820690155\n",
      "epoch: 2 step: 978, loss is 0.0009375314693897963\n",
      "epoch: 2 step: 979, loss is 0.043193940073251724\n",
      "epoch: 2 step: 980, loss is 0.4621160626411438\n",
      "epoch: 2 step: 981, loss is 0.004626984242349863\n",
      "epoch: 2 step: 982, loss is 0.024768495932221413\n",
      "epoch: 2 step: 983, loss is 0.17957958579063416\n",
      "epoch: 2 step: 984, loss is 0.00015360864927060902\n",
      "epoch: 2 step: 985, loss is 0.004266251809895039\n",
      "epoch: 2 step: 986, loss is 0.0012771512847393751\n",
      "epoch: 2 step: 987, loss is 0.012365416623651981\n",
      "epoch: 2 step: 988, loss is 0.029958339408040047\n",
      "epoch: 2 step: 989, loss is 0.003052900545299053\n",
      "epoch: 2 step: 990, loss is 0.020376263186335564\n",
      "epoch: 2 step: 991, loss is 0.12944836914539337\n",
      "epoch: 2 step: 992, loss is 0.0019317372934892774\n",
      "epoch: 2 step: 993, loss is 0.011090797372162342\n",
      "epoch: 2 step: 994, loss is 0.051537126302719116\n",
      "epoch: 2 step: 995, loss is 0.22085382044315338\n",
      "epoch: 2 step: 996, loss is 0.03143046051263809\n",
      "epoch: 2 step: 997, loss is 0.3431958854198456\n",
      "epoch: 2 step: 998, loss is 0.015412281267344952\n",
      "epoch: 2 step: 999, loss is 0.06595870107412338\n",
      "epoch: 2 step: 1000, loss is 0.027046754956245422\n",
      "epoch: 2 step: 1001, loss is 0.06921672821044922\n",
      "epoch: 2 step: 1002, loss is 0.1571243554353714\n",
      "epoch: 2 step: 1003, loss is 0.012421289458870888\n",
      "epoch: 2 step: 1004, loss is 0.0908401608467102\n",
      "epoch: 2 step: 1005, loss is 0.03956323117017746\n",
      "epoch: 2 step: 1006, loss is 0.004661906510591507\n",
      "epoch: 2 step: 1007, loss is 0.0848541185259819\n",
      "epoch: 2 step: 1008, loss is 0.012861939147114754\n",
      "epoch: 2 step: 1009, loss is 0.04713364690542221\n",
      "epoch: 2 step: 1010, loss is 0.011305156163871288\n",
      "epoch: 2 step: 1011, loss is 0.0012556408764794469\n",
      "epoch: 2 step: 1012, loss is 0.02837921865284443\n",
      "epoch: 2 step: 1013, loss is 0.11033899337053299\n",
      "epoch: 2 step: 1014, loss is 0.004626650828868151\n",
      "epoch: 2 step: 1015, loss is 0.019087521359324455\n",
      "epoch: 2 step: 1016, loss is 0.010936964303255081\n",
      "epoch: 2 step: 1017, loss is 0.01743672788143158\n",
      "epoch: 2 step: 1018, loss is 0.04990357160568237\n",
      "epoch: 2 step: 1019, loss is 0.012854281812906265\n",
      "epoch: 2 step: 1020, loss is 0.004161180928349495\n",
      "epoch: 2 step: 1021, loss is 0.03592947870492935\n",
      "epoch: 2 step: 1022, loss is 0.09883544594049454\n",
      "epoch: 2 step: 1023, loss is 0.2999703586101532\n",
      "epoch: 2 step: 1024, loss is 0.017476893961429596\n",
      "epoch: 2 step: 1025, loss is 0.024748090654611588\n",
      "epoch: 2 step: 1026, loss is 0.17680780589580536\n",
      "epoch: 2 step: 1027, loss is 0.16447778046131134\n",
      "epoch: 2 step: 1028, loss is 0.024431977421045303\n",
      "epoch: 2 step: 1029, loss is 0.002189985476434231\n",
      "epoch: 2 step: 1030, loss is 0.09737824648618698\n",
      "epoch: 2 step: 1031, loss is 0.003958566579967737\n",
      "epoch: 2 step: 1032, loss is 0.12435107678174973\n",
      "epoch: 2 step: 1033, loss is 0.28677132725715637\n",
      "epoch: 2 step: 1034, loss is 0.09864462167024612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1035, loss is 0.038349248468875885\n",
      "epoch: 2 step: 1036, loss is 0.02018527314066887\n",
      "epoch: 2 step: 1037, loss is 0.1268623024225235\n",
      "epoch: 2 step: 1038, loss is 0.011045741848647594\n",
      "epoch: 2 step: 1039, loss is 0.014553138986229897\n",
      "epoch: 2 step: 1040, loss is 0.043132130056619644\n",
      "epoch: 2 step: 1041, loss is 0.13481926918029785\n",
      "epoch: 2 step: 1042, loss is 0.02063574269413948\n",
      "epoch: 2 step: 1043, loss is 0.0397455170750618\n",
      "epoch: 2 step: 1044, loss is 0.0026295040734112263\n",
      "epoch: 2 step: 1045, loss is 0.030193360522389412\n",
      "epoch: 2 step: 1046, loss is 0.010226024314761162\n",
      "epoch: 2 step: 1047, loss is 0.07418888807296753\n",
      "epoch: 2 step: 1048, loss is 0.0238228477537632\n",
      "epoch: 2 step: 1049, loss is 0.23227980732917786\n",
      "epoch: 2 step: 1050, loss is 0.09600639343261719\n",
      "epoch: 2 step: 1051, loss is 0.011076525785028934\n",
      "epoch: 2 step: 1052, loss is 0.021400494500994682\n",
      "epoch: 2 step: 1053, loss is 0.053074877709150314\n",
      "epoch: 2 step: 1054, loss is 0.09581906348466873\n",
      "epoch: 2 step: 1055, loss is 0.0030885699670761824\n",
      "epoch: 2 step: 1056, loss is 0.019004665315151215\n",
      "epoch: 2 step: 1057, loss is 0.11755883693695068\n",
      "epoch: 2 step: 1058, loss is 0.011116879060864449\n",
      "epoch: 2 step: 1059, loss is 0.031175702810287476\n",
      "epoch: 2 step: 1060, loss is 0.16387535631656647\n",
      "epoch: 2 step: 1061, loss is 0.019910788163542747\n",
      "epoch: 2 step: 1062, loss is 0.010392960160970688\n",
      "epoch: 2 step: 1063, loss is 0.11248283088207245\n",
      "epoch: 2 step: 1064, loss is 0.13463138043880463\n",
      "epoch: 2 step: 1065, loss is 0.1096254512667656\n",
      "epoch: 2 step: 1066, loss is 0.0026764310896396637\n",
      "epoch: 2 step: 1067, loss is 0.014386780560016632\n",
      "epoch: 2 step: 1068, loss is 0.15485763549804688\n",
      "epoch: 2 step: 1069, loss is 0.000674887967761606\n",
      "epoch: 2 step: 1070, loss is 0.1517917960882187\n",
      "epoch: 2 step: 1071, loss is 0.053873226046562195\n",
      "epoch: 2 step: 1072, loss is 0.014172712340950966\n",
      "epoch: 2 step: 1073, loss is 0.08340335637331009\n",
      "epoch: 2 step: 1074, loss is 0.013217421248555183\n",
      "epoch: 2 step: 1075, loss is 0.001640901667997241\n",
      "epoch: 2 step: 1076, loss is 0.01252601109445095\n",
      "epoch: 2 step: 1077, loss is 0.0035430274438112974\n",
      "epoch: 2 step: 1078, loss is 0.019734663888812065\n",
      "epoch: 2 step: 1079, loss is 0.08364173769950867\n",
      "epoch: 2 step: 1080, loss is 0.017282096669077873\n",
      "epoch: 2 step: 1081, loss is 0.25659868121147156\n",
      "epoch: 2 step: 1082, loss is 0.004769692663103342\n",
      "epoch: 2 step: 1083, loss is 0.01306215487420559\n",
      "epoch: 2 step: 1084, loss is 0.10693751275539398\n",
      "epoch: 2 step: 1085, loss is 0.00493765389546752\n",
      "epoch: 2 step: 1086, loss is 0.023212255910038948\n",
      "epoch: 2 step: 1087, loss is 0.012950094416737556\n",
      "epoch: 2 step: 1088, loss is 0.022263318300247192\n",
      "epoch: 2 step: 1089, loss is 0.0023306687362492085\n",
      "epoch: 2 step: 1090, loss is 0.012159405276179314\n",
      "epoch: 2 step: 1091, loss is 0.027862800285220146\n",
      "epoch: 2 step: 1092, loss is 0.01105683483183384\n",
      "epoch: 2 step: 1093, loss is 0.01964876614511013\n",
      "epoch: 2 step: 1094, loss is 0.01446817722171545\n",
      "epoch: 2 step: 1095, loss is 0.1675442010164261\n",
      "epoch: 2 step: 1096, loss is 0.02229326218366623\n",
      "epoch: 2 step: 1097, loss is 0.04737675189971924\n",
      "epoch: 2 step: 1098, loss is 0.002182857831940055\n",
      "epoch: 2 step: 1099, loss is 0.006814018357545137\n",
      "epoch: 2 step: 1100, loss is 0.0032153697684407234\n",
      "epoch: 2 step: 1101, loss is 0.15592004358768463\n",
      "epoch: 2 step: 1102, loss is 0.17673955857753754\n",
      "epoch: 2 step: 1103, loss is 0.004949563182890415\n",
      "epoch: 2 step: 1104, loss is 0.005410258192569017\n",
      "epoch: 2 step: 1105, loss is 0.005454832222312689\n",
      "epoch: 2 step: 1106, loss is 0.027196135371923447\n",
      "epoch: 2 step: 1107, loss is 0.03545641154050827\n",
      "epoch: 2 step: 1108, loss is 0.0034061698243021965\n",
      "epoch: 2 step: 1109, loss is 0.016312314197421074\n",
      "epoch: 2 step: 1110, loss is 0.06759767234325409\n",
      "epoch: 2 step: 1111, loss is 0.25334808230400085\n",
      "epoch: 2 step: 1112, loss is 0.22813226282596588\n",
      "epoch: 2 step: 1113, loss is 0.13299761712551117\n",
      "epoch: 2 step: 1114, loss is 0.02620799094438553\n",
      "epoch: 2 step: 1115, loss is 0.0010711440118029714\n",
      "epoch: 2 step: 1116, loss is 0.004276456777006388\n",
      "epoch: 2 step: 1117, loss is 0.006307580508291721\n",
      "epoch: 2 step: 1118, loss is 0.030464770272374153\n",
      "epoch: 2 step: 1119, loss is 0.03159049525856972\n",
      "epoch: 2 step: 1120, loss is 0.0016022485215216875\n",
      "epoch: 2 step: 1121, loss is 0.015897070989012718\n",
      "epoch: 2 step: 1122, loss is 0.02003020979464054\n",
      "epoch: 2 step: 1123, loss is 0.005746735725551844\n",
      "epoch: 2 step: 1124, loss is 0.0354546494781971\n",
      "epoch: 2 step: 1125, loss is 0.04368113726377487\n",
      "epoch: 2 step: 1126, loss is 0.018301213160157204\n",
      "epoch: 2 step: 1127, loss is 0.26739487051963806\n",
      "epoch: 2 step: 1128, loss is 0.046658262610435486\n",
      "epoch: 2 step: 1129, loss is 0.019833020865917206\n",
      "epoch: 2 step: 1130, loss is 0.016845956444740295\n",
      "epoch: 2 step: 1131, loss is 0.003931351471692324\n",
      "epoch: 2 step: 1132, loss is 0.14943693578243256\n",
      "epoch: 2 step: 1133, loss is 0.03656885772943497\n",
      "epoch: 2 step: 1134, loss is 0.060309235006570816\n",
      "epoch: 2 step: 1135, loss is 0.038696736097335815\n",
      "epoch: 2 step: 1136, loss is 0.0274443868547678\n",
      "epoch: 2 step: 1137, loss is 0.005905940663069487\n",
      "epoch: 2 step: 1138, loss is 0.0013244554866105318\n",
      "epoch: 2 step: 1139, loss is 0.010317572392523289\n",
      "epoch: 2 step: 1140, loss is 0.017379427328705788\n",
      "epoch: 2 step: 1141, loss is 0.024002935737371445\n",
      "epoch: 2 step: 1142, loss is 0.03139011934399605\n",
      "epoch: 2 step: 1143, loss is 0.03742390125989914\n",
      "epoch: 2 step: 1144, loss is 0.0019101890502497554\n",
      "epoch: 2 step: 1145, loss is 0.14487972855567932\n",
      "epoch: 2 step: 1146, loss is 0.0065947058610618114\n",
      "epoch: 2 step: 1147, loss is 0.0010573160834610462\n",
      "epoch: 2 step: 1148, loss is 0.014624039642512798\n",
      "epoch: 2 step: 1149, loss is 0.006164755206555128\n",
      "epoch: 2 step: 1150, loss is 0.03323390707373619\n",
      "epoch: 2 step: 1151, loss is 0.11303649842739105\n",
      "epoch: 2 step: 1152, loss is 0.0041371607221663\n",
      "epoch: 2 step: 1153, loss is 0.003975430969148874\n",
      "epoch: 2 step: 1154, loss is 0.0010495901806280017\n",
      "epoch: 2 step: 1155, loss is 0.1645408421754837\n",
      "epoch: 2 step: 1156, loss is 0.05293573811650276\n",
      "epoch: 2 step: 1157, loss is 0.006664087064564228\n",
      "epoch: 2 step: 1158, loss is 0.016419027000665665\n",
      "epoch: 2 step: 1159, loss is 0.005638845264911652\n",
      "epoch: 2 step: 1160, loss is 0.01571149006485939\n",
      "epoch: 2 step: 1161, loss is 0.002855634316802025\n",
      "epoch: 2 step: 1162, loss is 0.26700907945632935\n",
      "epoch: 2 step: 1163, loss is 0.016209689900279045\n",
      "epoch: 2 step: 1164, loss is 0.047117095440626144\n",
      "epoch: 2 step: 1165, loss is 0.21650779247283936\n",
      "epoch: 2 step: 1166, loss is 0.08692663162946701\n",
      "epoch: 2 step: 1167, loss is 0.044190362095832825\n",
      "epoch: 2 step: 1168, loss is 0.024429554119706154\n",
      "epoch: 2 step: 1169, loss is 0.28891894221305847\n",
      "epoch: 2 step: 1170, loss is 0.199315145611763\n",
      "epoch: 2 step: 1171, loss is 0.023430274799466133\n",
      "epoch: 2 step: 1172, loss is 0.013624206185340881\n",
      "epoch: 2 step: 1173, loss is 0.0030407030135393143\n",
      "epoch: 2 step: 1174, loss is 0.02614574320614338\n",
      "epoch: 2 step: 1175, loss is 0.15596088767051697\n",
      "epoch: 2 step: 1176, loss is 0.0012360734399408102\n",
      "epoch: 2 step: 1177, loss is 0.006844715215265751\n",
      "epoch: 2 step: 1178, loss is 0.10011565685272217\n",
      "epoch: 2 step: 1179, loss is 0.0006556481239385903\n",
      "epoch: 2 step: 1180, loss is 0.14511308073997498\n",
      "epoch: 2 step: 1181, loss is 0.018581029027700424\n",
      "epoch: 2 step: 1182, loss is 0.023955944925546646\n",
      "epoch: 2 step: 1183, loss is 0.026194598525762558\n",
      "epoch: 2 step: 1184, loss is 0.016011405736207962\n",
      "epoch: 2 step: 1185, loss is 0.03680017217993736\n",
      "epoch: 2 step: 1186, loss is 0.006773021072149277\n",
      "epoch: 2 step: 1187, loss is 0.0016828072257339954\n",
      "epoch: 2 step: 1188, loss is 0.02628045715391636\n",
      "epoch: 2 step: 1189, loss is 0.010594656690955162\n",
      "epoch: 2 step: 1190, loss is 0.12257060408592224\n",
      "epoch: 2 step: 1191, loss is 0.0014653579564765096\n",
      "epoch: 2 step: 1192, loss is 0.06702470034360886\n",
      "epoch: 2 step: 1193, loss is 0.003127750474959612\n",
      "epoch: 2 step: 1194, loss is 0.11296956241130829\n",
      "epoch: 2 step: 1195, loss is 0.015539918094873428\n",
      "epoch: 2 step: 1196, loss is 0.09765873104333878\n",
      "epoch: 2 step: 1197, loss is 0.006076101213693619\n",
      "epoch: 2 step: 1198, loss is 0.017666932195425034\n",
      "epoch: 2 step: 1199, loss is 0.026252472773194313\n",
      "epoch: 2 step: 1200, loss is 0.06712903082370758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1201, loss is 0.07034455239772797\n",
      "epoch: 2 step: 1202, loss is 0.0682775005698204\n",
      "epoch: 2 step: 1203, loss is 0.05745251104235649\n",
      "epoch: 2 step: 1204, loss is 0.07328896969556808\n",
      "epoch: 2 step: 1205, loss is 0.3112734854221344\n",
      "epoch: 2 step: 1206, loss is 0.0028492591809481382\n",
      "epoch: 2 step: 1207, loss is 0.09710926562547684\n",
      "epoch: 2 step: 1208, loss is 0.04984254390001297\n",
      "epoch: 2 step: 1209, loss is 0.010738399811089039\n",
      "epoch: 2 step: 1210, loss is 0.08790338784456253\n",
      "epoch: 2 step: 1211, loss is 0.06760832667350769\n",
      "epoch: 2 step: 1212, loss is 0.05581609904766083\n",
      "epoch: 2 step: 1213, loss is 0.0024299731012433767\n",
      "epoch: 2 step: 1214, loss is 0.009562957100570202\n",
      "epoch: 2 step: 1215, loss is 0.005819584242999554\n",
      "epoch: 2 step: 1216, loss is 0.19597581028938293\n",
      "epoch: 2 step: 1217, loss is 0.13179002702236176\n",
      "epoch: 2 step: 1218, loss is 0.018066054210066795\n",
      "epoch: 2 step: 1219, loss is 0.006828371901065111\n",
      "epoch: 2 step: 1220, loss is 0.0008537669200450182\n",
      "epoch: 2 step: 1221, loss is 0.020645149052143097\n",
      "epoch: 2 step: 1222, loss is 0.037887539714574814\n",
      "epoch: 2 step: 1223, loss is 0.04398774728178978\n",
      "epoch: 2 step: 1224, loss is 0.0808558538556099\n",
      "epoch: 2 step: 1225, loss is 0.00184683280531317\n",
      "epoch: 2 step: 1226, loss is 0.022749457508325577\n",
      "epoch: 2 step: 1227, loss is 0.031387731432914734\n",
      "epoch: 2 step: 1228, loss is 0.018831903114914894\n",
      "epoch: 2 step: 1229, loss is 0.0037261592224240303\n",
      "epoch: 2 step: 1230, loss is 0.13136756420135498\n",
      "epoch: 2 step: 1231, loss is 0.006587448064237833\n",
      "epoch: 2 step: 1232, loss is 0.12644903361797333\n",
      "epoch: 2 step: 1233, loss is 0.0026393013540655375\n",
      "epoch: 2 step: 1234, loss is 0.03010554611682892\n",
      "epoch: 2 step: 1235, loss is 0.02781500667333603\n",
      "epoch: 2 step: 1236, loss is 0.000615621218457818\n",
      "epoch: 2 step: 1237, loss is 0.06036776676774025\n",
      "epoch: 2 step: 1238, loss is 0.03430238366127014\n",
      "epoch: 2 step: 1239, loss is 0.015005163848400116\n",
      "epoch: 2 step: 1240, loss is 0.0745360404253006\n",
      "epoch: 2 step: 1241, loss is 0.07736820727586746\n",
      "epoch: 2 step: 1242, loss is 0.00854929443448782\n",
      "epoch: 2 step: 1243, loss is 0.006731052417308092\n",
      "epoch: 2 step: 1244, loss is 0.06627002358436584\n",
      "epoch: 2 step: 1245, loss is 0.009236513637006283\n",
      "epoch: 2 step: 1246, loss is 0.014957414008677006\n",
      "epoch: 2 step: 1247, loss is 0.004420339595526457\n",
      "epoch: 2 step: 1248, loss is 0.0005826689302921295\n",
      "epoch: 2 step: 1249, loss is 0.010435076430439949\n",
      "epoch: 2 step: 1250, loss is 0.004294228740036488\n",
      "epoch: 2 step: 1251, loss is 0.0008230582461692393\n",
      "epoch: 2 step: 1252, loss is 0.03909546881914139\n",
      "epoch: 2 step: 1253, loss is 0.010734506882727146\n",
      "epoch: 2 step: 1254, loss is 0.0028652313631027937\n",
      "epoch: 2 step: 1255, loss is 0.0008079588878899813\n",
      "epoch: 2 step: 1256, loss is 0.020921289920806885\n",
      "epoch: 2 step: 1257, loss is 0.09226226806640625\n",
      "epoch: 2 step: 1258, loss is 0.0015296447090804577\n",
      "epoch: 2 step: 1259, loss is 0.020227573812007904\n",
      "epoch: 2 step: 1260, loss is 0.13732367753982544\n",
      "epoch: 2 step: 1261, loss is 0.021017009392380714\n",
      "epoch: 2 step: 1262, loss is 0.005125846713781357\n",
      "epoch: 2 step: 1263, loss is 0.0035366187803447247\n",
      "epoch: 2 step: 1264, loss is 0.16934573650360107\n",
      "epoch: 2 step: 1265, loss is 0.005226162262260914\n",
      "epoch: 2 step: 1266, loss is 0.015457144007086754\n",
      "epoch: 2 step: 1267, loss is 0.012296929955482483\n",
      "epoch: 2 step: 1268, loss is 0.22571291029453278\n",
      "epoch: 2 step: 1269, loss is 0.0024709925055503845\n",
      "epoch: 2 step: 1270, loss is 0.0005019885138608515\n",
      "epoch: 2 step: 1271, loss is 0.0013648481108248234\n",
      "epoch: 2 step: 1272, loss is 0.006763699930161238\n",
      "epoch: 2 step: 1273, loss is 0.0009470960358157754\n",
      "epoch: 2 step: 1274, loss is 0.01088319718837738\n",
      "epoch: 2 step: 1275, loss is 0.0045331791043281555\n",
      "epoch: 2 step: 1276, loss is 0.02407405525445938\n",
      "epoch: 2 step: 1277, loss is 0.03223330155014992\n",
      "epoch: 2 step: 1278, loss is 0.09772935509681702\n",
      "epoch: 2 step: 1279, loss is 0.15008528530597687\n",
      "epoch: 2 step: 1280, loss is 0.012375547550618649\n",
      "epoch: 2 step: 1281, loss is 0.06195003539323807\n",
      "epoch: 2 step: 1282, loss is 0.003222521860152483\n",
      "epoch: 2 step: 1283, loss is 0.05615843087434769\n",
      "epoch: 2 step: 1284, loss is 0.003060318995267153\n",
      "epoch: 2 step: 1285, loss is 0.010191203095018864\n",
      "epoch: 2 step: 1286, loss is 0.0009035594994202256\n",
      "epoch: 2 step: 1287, loss is 0.04808925464749336\n",
      "epoch: 2 step: 1288, loss is 0.006603000685572624\n",
      "epoch: 2 step: 1289, loss is 0.0610426664352417\n",
      "epoch: 2 step: 1290, loss is 0.023576881736516953\n",
      "epoch: 2 step: 1291, loss is 0.0029973224736750126\n",
      "epoch: 2 step: 1292, loss is 0.5282102227210999\n",
      "epoch: 2 step: 1293, loss is 0.4707878828048706\n",
      "epoch: 2 step: 1294, loss is 0.0052357017993927\n",
      "epoch: 2 step: 1295, loss is 0.016987474635243416\n",
      "epoch: 2 step: 1296, loss is 0.07716570049524307\n",
      "epoch: 2 step: 1297, loss is 0.041719306260347366\n",
      "epoch: 2 step: 1298, loss is 0.07804569602012634\n",
      "epoch: 2 step: 1299, loss is 0.0033027566969394684\n",
      "epoch: 2 step: 1300, loss is 0.07325263321399689\n",
      "epoch: 2 step: 1301, loss is 0.13509847223758698\n",
      "epoch: 2 step: 1302, loss is 0.07940444350242615\n",
      "epoch: 2 step: 1303, loss is 0.021825887262821198\n",
      "epoch: 2 step: 1304, loss is 0.038836050778627396\n",
      "epoch: 2 step: 1305, loss is 0.2559250295162201\n",
      "epoch: 2 step: 1306, loss is 0.027173982933163643\n",
      "epoch: 2 step: 1307, loss is 0.002727735787630081\n",
      "epoch: 2 step: 1308, loss is 0.010161994025111198\n",
      "epoch: 2 step: 1309, loss is 0.08239125460386276\n",
      "epoch: 2 step: 1310, loss is 0.03893595561385155\n",
      "epoch: 2 step: 1311, loss is 0.17202989757061005\n",
      "epoch: 2 step: 1312, loss is 0.005849646870046854\n",
      "epoch: 2 step: 1313, loss is 0.0620405413210392\n",
      "epoch: 2 step: 1314, loss is 0.010316461324691772\n",
      "epoch: 2 step: 1315, loss is 0.02326704002916813\n",
      "epoch: 2 step: 1316, loss is 0.0531887412071228\n",
      "epoch: 2 step: 1317, loss is 0.14941531419754028\n",
      "epoch: 2 step: 1318, loss is 0.01984921656548977\n",
      "epoch: 2 step: 1319, loss is 0.011018329299986362\n",
      "epoch: 2 step: 1320, loss is 0.03912872076034546\n",
      "epoch: 2 step: 1321, loss is 0.025883901864290237\n",
      "epoch: 2 step: 1322, loss is 0.002984470222145319\n",
      "epoch: 2 step: 1323, loss is 0.019185954704880714\n",
      "epoch: 2 step: 1324, loss is 0.022208329290151596\n",
      "epoch: 2 step: 1325, loss is 0.0010924771195277572\n",
      "epoch: 2 step: 1326, loss is 0.16694270074367523\n",
      "epoch: 2 step: 1327, loss is 0.026002192869782448\n",
      "epoch: 2 step: 1328, loss is 0.04577723518013954\n",
      "epoch: 2 step: 1329, loss is 0.018554609268903732\n",
      "epoch: 2 step: 1330, loss is 0.008770857937633991\n",
      "epoch: 2 step: 1331, loss is 0.002438628813251853\n",
      "epoch: 2 step: 1332, loss is 0.00416654022410512\n",
      "epoch: 2 step: 1333, loss is 0.022269994020462036\n",
      "epoch: 2 step: 1334, loss is 0.12471909821033478\n",
      "epoch: 2 step: 1335, loss is 0.000837985600810498\n",
      "epoch: 2 step: 1336, loss is 0.01363880280405283\n",
      "epoch: 2 step: 1337, loss is 0.021764960139989853\n",
      "epoch: 2 step: 1338, loss is 0.0035913262981921434\n",
      "epoch: 2 step: 1339, loss is 0.002949636662378907\n",
      "epoch: 2 step: 1340, loss is 0.0016465442022308707\n",
      "epoch: 2 step: 1341, loss is 0.0021306616254150867\n",
      "epoch: 2 step: 1342, loss is 0.011330872774124146\n",
      "epoch: 2 step: 1343, loss is 0.17157137393951416\n",
      "epoch: 2 step: 1344, loss is 0.10030801594257355\n",
      "epoch: 2 step: 1345, loss is 0.0009829314658418298\n",
      "epoch: 2 step: 1346, loss is 0.15146537125110626\n",
      "epoch: 2 step: 1347, loss is 0.052151940762996674\n",
      "epoch: 2 step: 1348, loss is 0.3189961016178131\n",
      "epoch: 2 step: 1349, loss is 0.25479403138160706\n",
      "epoch: 2 step: 1350, loss is 0.018230684101581573\n",
      "epoch: 2 step: 1351, loss is 0.011938883922994137\n",
      "epoch: 2 step: 1352, loss is 0.003642797702923417\n",
      "epoch: 2 step: 1353, loss is 0.04645390063524246\n",
      "epoch: 2 step: 1354, loss is 0.09469961374998093\n",
      "epoch: 2 step: 1355, loss is 0.0017163469456136227\n",
      "epoch: 2 step: 1356, loss is 0.0013884033542126417\n",
      "epoch: 2 step: 1357, loss is 0.048745136708021164\n",
      "epoch: 2 step: 1358, loss is 0.003761336440220475\n",
      "epoch: 2 step: 1359, loss is 0.00015248314593918622\n",
      "epoch: 2 step: 1360, loss is 0.026521671563386917\n",
      "epoch: 2 step: 1361, loss is 0.11359801143407822\n",
      "epoch: 2 step: 1362, loss is 0.0026270991656929255\n",
      "epoch: 2 step: 1363, loss is 0.1574520766735077\n",
      "epoch: 2 step: 1364, loss is 0.043632056564092636\n",
      "epoch: 2 step: 1365, loss is 0.0005251104012131691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1366, loss is 0.004216596484184265\n",
      "epoch: 2 step: 1367, loss is 0.006398165598511696\n",
      "epoch: 2 step: 1368, loss is 0.006400563754141331\n",
      "epoch: 2 step: 1369, loss is 0.0017891231691464782\n",
      "epoch: 2 step: 1370, loss is 0.014269931241869926\n",
      "epoch: 2 step: 1371, loss is 0.17806120216846466\n",
      "epoch: 2 step: 1372, loss is 0.004793296102434397\n",
      "epoch: 2 step: 1373, loss is 0.08879204094409943\n",
      "epoch: 2 step: 1374, loss is 0.006400813814252615\n",
      "epoch: 2 step: 1375, loss is 0.018158208578824997\n",
      "epoch: 2 step: 1376, loss is 0.0030748017597943544\n",
      "epoch: 2 step: 1377, loss is 0.22513137757778168\n",
      "epoch: 2 step: 1378, loss is 0.030637826770544052\n",
      "epoch: 2 step: 1379, loss is 0.08159633725881577\n",
      "epoch: 2 step: 1380, loss is 0.09511947631835938\n",
      "epoch: 2 step: 1381, loss is 0.002273769583553076\n",
      "epoch: 2 step: 1382, loss is 0.11148595064878464\n",
      "epoch: 2 step: 1383, loss is 0.013240517117083073\n",
      "epoch: 2 step: 1384, loss is 0.0674477219581604\n",
      "epoch: 2 step: 1385, loss is 0.006662101484835148\n",
      "epoch: 2 step: 1386, loss is 0.004859205335378647\n",
      "epoch: 2 step: 1387, loss is 0.014505363069474697\n",
      "epoch: 2 step: 1388, loss is 0.004056909121572971\n",
      "epoch: 2 step: 1389, loss is 0.04245642572641373\n",
      "epoch: 2 step: 1390, loss is 0.08506565541028976\n",
      "epoch: 2 step: 1391, loss is 0.010446948930621147\n",
      "epoch: 2 step: 1392, loss is 0.0006862478912808001\n",
      "epoch: 2 step: 1393, loss is 0.004913610871881247\n",
      "epoch: 2 step: 1394, loss is 0.024707136675715446\n",
      "epoch: 2 step: 1395, loss is 0.2619503140449524\n",
      "epoch: 2 step: 1396, loss is 0.007349399849772453\n",
      "epoch: 2 step: 1397, loss is 0.03435191139578819\n",
      "epoch: 2 step: 1398, loss is 0.006032649893313646\n",
      "epoch: 2 step: 1399, loss is 0.00074549246346578\n",
      "epoch: 2 step: 1400, loss is 0.011135930195450783\n",
      "epoch: 2 step: 1401, loss is 0.02809843048453331\n",
      "epoch: 2 step: 1402, loss is 0.026393910869956017\n",
      "epoch: 2 step: 1403, loss is 0.022959604859352112\n",
      "epoch: 2 step: 1404, loss is 0.0006535911816172302\n",
      "epoch: 2 step: 1405, loss is 0.017716895788908005\n",
      "epoch: 2 step: 1406, loss is 0.04124629497528076\n",
      "epoch: 2 step: 1407, loss is 0.09821051359176636\n",
      "epoch: 2 step: 1408, loss is 0.007338483817875385\n",
      "epoch: 2 step: 1409, loss is 0.03291243314743042\n",
      "epoch: 2 step: 1410, loss is 0.21432292461395264\n",
      "epoch: 2 step: 1411, loss is 0.02844659797847271\n",
      "epoch: 2 step: 1412, loss is 0.23272712528705597\n",
      "epoch: 2 step: 1413, loss is 0.0015012979274615645\n",
      "epoch: 2 step: 1414, loss is 0.14636872708797455\n",
      "epoch: 2 step: 1415, loss is 0.15905354917049408\n",
      "epoch: 2 step: 1416, loss is 0.06761086732149124\n",
      "epoch: 2 step: 1417, loss is 0.00036416988587006927\n",
      "epoch: 2 step: 1418, loss is 0.0407850556075573\n",
      "epoch: 2 step: 1419, loss is 0.09327825903892517\n",
      "epoch: 2 step: 1420, loss is 0.015893613919615746\n",
      "epoch: 2 step: 1421, loss is 0.015432899817824364\n",
      "epoch: 2 step: 1422, loss is 0.1449093222618103\n",
      "epoch: 2 step: 1423, loss is 0.0055516185238957405\n",
      "epoch: 2 step: 1424, loss is 0.18114151060581207\n",
      "epoch: 2 step: 1425, loss is 0.12936939299106598\n",
      "epoch: 2 step: 1426, loss is 0.07008674740791321\n",
      "epoch: 2 step: 1427, loss is 0.014030561782419682\n",
      "epoch: 2 step: 1428, loss is 0.2606693506240845\n",
      "epoch: 2 step: 1429, loss is 0.012292751111090183\n",
      "epoch: 2 step: 1430, loss is 0.0037815370596945286\n",
      "epoch: 2 step: 1431, loss is 0.0023541669361293316\n",
      "epoch: 2 step: 1432, loss is 0.062138479202985764\n",
      "epoch: 2 step: 1433, loss is 0.13202373683452606\n",
      "epoch: 2 step: 1434, loss is 0.0009244472021237016\n",
      "epoch: 2 step: 1435, loss is 0.014952304773032665\n",
      "epoch: 2 step: 1436, loss is 0.13761331140995026\n",
      "epoch: 2 step: 1437, loss is 0.002547512063756585\n",
      "epoch: 2 step: 1438, loss is 0.001954565290361643\n",
      "epoch: 2 step: 1439, loss is 0.018680084496736526\n",
      "epoch: 2 step: 1440, loss is 0.271061509847641\n",
      "epoch: 2 step: 1441, loss is 0.007125955540686846\n",
      "epoch: 2 step: 1442, loss is 0.0017181143630295992\n",
      "epoch: 2 step: 1443, loss is 0.002716420218348503\n",
      "epoch: 2 step: 1444, loss is 0.005040708929300308\n",
      "epoch: 2 step: 1445, loss is 0.044041045010089874\n",
      "epoch: 2 step: 1446, loss is 0.07882092148065567\n",
      "epoch: 2 step: 1447, loss is 0.014029547572135925\n",
      "epoch: 2 step: 1448, loss is 0.01140839233994484\n",
      "epoch: 2 step: 1449, loss is 0.025690896436572075\n",
      "epoch: 2 step: 1450, loss is 0.07853715866804123\n",
      "epoch: 2 step: 1451, loss is 0.038085490465164185\n",
      "epoch: 2 step: 1452, loss is 0.010813014581799507\n",
      "epoch: 2 step: 1453, loss is 0.07112451642751694\n",
      "epoch: 2 step: 1454, loss is 0.05915474891662598\n",
      "epoch: 2 step: 1455, loss is 0.003962744493037462\n",
      "epoch: 2 step: 1456, loss is 0.0014065911527723074\n",
      "epoch: 2 step: 1457, loss is 0.0109103349968791\n",
      "epoch: 2 step: 1458, loss is 0.009330935776233673\n",
      "epoch: 2 step: 1459, loss is 0.0021902520675212145\n",
      "epoch: 2 step: 1460, loss is 0.21456760168075562\n",
      "epoch: 2 step: 1461, loss is 0.08390900492668152\n",
      "epoch: 2 step: 1462, loss is 0.2390807718038559\n",
      "epoch: 2 step: 1463, loss is 0.01749385893344879\n",
      "epoch: 2 step: 1464, loss is 0.13056565821170807\n",
      "epoch: 2 step: 1465, loss is 0.08426131308078766\n",
      "epoch: 2 step: 1466, loss is 0.04063204675912857\n",
      "epoch: 2 step: 1467, loss is 0.031638745218515396\n",
      "epoch: 2 step: 1468, loss is 0.02638201043009758\n",
      "epoch: 2 step: 1469, loss is 0.015142127871513367\n",
      "epoch: 2 step: 1470, loss is 0.029216617345809937\n",
      "epoch: 2 step: 1471, loss is 0.0045782397501170635\n",
      "epoch: 2 step: 1472, loss is 0.017769627273082733\n",
      "epoch: 2 step: 1473, loss is 0.027483955025672913\n",
      "epoch: 2 step: 1474, loss is 0.00517602264881134\n",
      "epoch: 2 step: 1475, loss is 0.0013668953906744719\n",
      "epoch: 2 step: 1476, loss is 0.000946373213082552\n",
      "epoch: 2 step: 1477, loss is 0.033236972987651825\n",
      "epoch: 2 step: 1478, loss is 0.03741155564785004\n",
      "epoch: 2 step: 1479, loss is 0.06435682624578476\n",
      "epoch: 2 step: 1480, loss is 0.012592398561537266\n",
      "epoch: 2 step: 1481, loss is 0.0065190610475838184\n",
      "epoch: 2 step: 1482, loss is 0.1677352488040924\n",
      "epoch: 2 step: 1483, loss is 0.04048912599682808\n",
      "epoch: 2 step: 1484, loss is 0.34891584515571594\n",
      "epoch: 2 step: 1485, loss is 0.06240563467144966\n",
      "epoch: 2 step: 1486, loss is 0.17709140479564667\n",
      "epoch: 2 step: 1487, loss is 0.005735056009143591\n",
      "epoch: 2 step: 1488, loss is 0.026874249801039696\n",
      "epoch: 2 step: 1489, loss is 0.008384031243622303\n",
      "epoch: 2 step: 1490, loss is 0.013377358205616474\n",
      "epoch: 2 step: 1491, loss is 0.09066087752580643\n",
      "epoch: 2 step: 1492, loss is 0.04420631378889084\n",
      "epoch: 2 step: 1493, loss is 0.006752682849764824\n",
      "epoch: 2 step: 1494, loss is 0.030092090368270874\n",
      "epoch: 2 step: 1495, loss is 0.06816093623638153\n",
      "epoch: 2 step: 1496, loss is 0.266730934381485\n",
      "epoch: 2 step: 1497, loss is 0.11601826548576355\n",
      "epoch: 2 step: 1498, loss is 0.10974238812923431\n",
      "epoch: 2 step: 1499, loss is 0.08295602351427078\n",
      "epoch: 2 step: 1500, loss is 0.02955567091703415\n",
      "epoch: 2 step: 1501, loss is 0.03395609185099602\n",
      "epoch: 2 step: 1502, loss is 0.06114797666668892\n",
      "epoch: 2 step: 1503, loss is 0.002150530694052577\n",
      "epoch: 2 step: 1504, loss is 0.04192296043038368\n",
      "epoch: 2 step: 1505, loss is 0.01402465719729662\n",
      "epoch: 2 step: 1506, loss is 0.12731730937957764\n",
      "epoch: 2 step: 1507, loss is 0.003064524382352829\n",
      "epoch: 2 step: 1508, loss is 0.0281684510409832\n",
      "epoch: 2 step: 1509, loss is 0.16623082756996155\n",
      "epoch: 2 step: 1510, loss is 0.020021282136440277\n",
      "epoch: 2 step: 1511, loss is 0.04378403723239899\n",
      "epoch: 2 step: 1512, loss is 0.003607872175052762\n",
      "epoch: 2 step: 1513, loss is 0.0015730225713923573\n",
      "epoch: 2 step: 1514, loss is 0.1375959813594818\n",
      "epoch: 2 step: 1515, loss is 0.007211328949779272\n",
      "epoch: 2 step: 1516, loss is 0.044529106467962265\n",
      "epoch: 2 step: 1517, loss is 0.018869806081056595\n",
      "epoch: 2 step: 1518, loss is 0.014882729388773441\n",
      "epoch: 2 step: 1519, loss is 0.1247011348605156\n",
      "epoch: 2 step: 1520, loss is 0.1480197310447693\n",
      "epoch: 2 step: 1521, loss is 0.017024213448166847\n",
      "epoch: 2 step: 1522, loss is 0.0033661224879324436\n",
      "epoch: 2 step: 1523, loss is 0.014585339464247227\n",
      "epoch: 2 step: 1524, loss is 0.007256497163325548\n",
      "epoch: 2 step: 1525, loss is 0.004802008159458637\n",
      "epoch: 2 step: 1526, loss is 0.0036096060648560524\n",
      "epoch: 2 step: 1527, loss is 0.007130383979529142\n",
      "epoch: 2 step: 1528, loss is 0.00427506398409605\n",
      "epoch: 2 step: 1529, loss is 0.10240950435400009\n",
      "epoch: 2 step: 1530, loss is 0.06321236491203308\n",
      "epoch: 2 step: 1531, loss is 0.0016969051212072372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1532, loss is 0.000931176298763603\n",
      "epoch: 2 step: 1533, loss is 0.026924733072519302\n",
      "epoch: 2 step: 1534, loss is 0.05363716185092926\n",
      "epoch: 2 step: 1535, loss is 0.015465463511645794\n",
      "epoch: 2 step: 1536, loss is 0.010614852420985699\n",
      "epoch: 2 step: 1537, loss is 0.024683577939867973\n",
      "epoch: 2 step: 1538, loss is 0.04839349910616875\n",
      "epoch: 2 step: 1539, loss is 0.006127081345766783\n",
      "epoch: 2 step: 1540, loss is 0.02087424509227276\n",
      "epoch: 2 step: 1541, loss is 0.00288441963493824\n",
      "epoch: 2 step: 1542, loss is 0.0228379238396883\n",
      "epoch: 2 step: 1543, loss is 0.039570316672325134\n",
      "epoch: 2 step: 1544, loss is 0.015331939794123173\n",
      "epoch: 2 step: 1545, loss is 0.13037098944187164\n",
      "epoch: 2 step: 1546, loss is 0.012830585241317749\n",
      "epoch: 2 step: 1547, loss is 0.11136626452207565\n",
      "epoch: 2 step: 1548, loss is 0.001877583796158433\n",
      "epoch: 2 step: 1549, loss is 0.0014753631548956037\n",
      "epoch: 2 step: 1550, loss is 0.03868023678660393\n",
      "epoch: 2 step: 1551, loss is 0.20280346274375916\n",
      "epoch: 2 step: 1552, loss is 0.04193919897079468\n",
      "epoch: 2 step: 1553, loss is 0.001027856138534844\n",
      "epoch: 2 step: 1554, loss is 0.003082509385421872\n",
      "epoch: 2 step: 1555, loss is 0.0029571889899671078\n",
      "epoch: 2 step: 1556, loss is 0.0013308185152709484\n",
      "epoch: 2 step: 1557, loss is 0.004771943669766188\n",
      "epoch: 2 step: 1558, loss is 0.0005138592678122222\n",
      "epoch: 2 step: 1559, loss is 0.005097513552755117\n",
      "epoch: 2 step: 1560, loss is 0.050348374992609024\n",
      "epoch: 2 step: 1561, loss is 0.011390252970159054\n",
      "epoch: 2 step: 1562, loss is 0.0008292762795463204\n",
      "epoch: 2 step: 1563, loss is 0.1999499499797821\n",
      "epoch: 2 step: 1564, loss is 0.001676169573329389\n",
      "epoch: 2 step: 1565, loss is 0.0013470719568431377\n",
      "epoch: 2 step: 1566, loss is 0.003946084529161453\n",
      "epoch: 2 step: 1567, loss is 0.023647556081414223\n",
      "epoch: 2 step: 1568, loss is 0.00042598249274306\n",
      "epoch: 2 step: 1569, loss is 0.029343968257308006\n",
      "epoch: 2 step: 1570, loss is 0.05813898891210556\n",
      "epoch: 2 step: 1571, loss is 0.001491343486122787\n",
      "epoch: 2 step: 1572, loss is 0.0023930659517645836\n",
      "epoch: 2 step: 1573, loss is 0.040615372359752655\n",
      "epoch: 2 step: 1574, loss is 0.028128040954470634\n",
      "epoch: 2 step: 1575, loss is 0.0767955631017685\n",
      "epoch: 2 step: 1576, loss is 0.058216728270053864\n",
      "epoch: 2 step: 1577, loss is 0.005809885915368795\n",
      "epoch: 2 step: 1578, loss is 0.011074459180235863\n",
      "epoch: 2 step: 1579, loss is 0.06154151260852814\n",
      "epoch: 2 step: 1580, loss is 0.013770950958132744\n",
      "epoch: 2 step: 1581, loss is 0.0021019186824560165\n",
      "epoch: 2 step: 1582, loss is 0.010445737279951572\n",
      "epoch: 2 step: 1583, loss is 0.03192847594618797\n",
      "epoch: 2 step: 1584, loss is 0.14631535112857819\n",
      "epoch: 2 step: 1585, loss is 0.19246482849121094\n",
      "epoch: 2 step: 1586, loss is 0.02073097974061966\n",
      "epoch: 2 step: 1587, loss is 0.0021379536483436823\n",
      "epoch: 2 step: 1588, loss is 0.08669833838939667\n",
      "epoch: 2 step: 1589, loss is 0.06290137767791748\n",
      "epoch: 2 step: 1590, loss is 0.09552808105945587\n",
      "epoch: 2 step: 1591, loss is 0.08736921846866608\n",
      "epoch: 2 step: 1592, loss is 0.07203852385282516\n",
      "epoch: 2 step: 1593, loss is 0.10259260982275009\n",
      "epoch: 2 step: 1594, loss is 0.04868565872311592\n",
      "epoch: 2 step: 1595, loss is 0.04789664223790169\n",
      "epoch: 2 step: 1596, loss is 0.012380676344037056\n",
      "epoch: 2 step: 1597, loss is 0.04250902310013771\n",
      "epoch: 2 step: 1598, loss is 0.0881955549120903\n",
      "epoch: 2 step: 1599, loss is 0.017694322392344475\n",
      "epoch: 2 step: 1600, loss is 0.04415794461965561\n",
      "epoch: 2 step: 1601, loss is 0.03998741880059242\n",
      "epoch: 2 step: 1602, loss is 0.007081301417201757\n",
      "epoch: 2 step: 1603, loss is 0.15281125903129578\n",
      "epoch: 2 step: 1604, loss is 0.08048020303249359\n",
      "epoch: 2 step: 1605, loss is 0.02554909884929657\n",
      "epoch: 2 step: 1606, loss is 0.0113076725974679\n",
      "epoch: 2 step: 1607, loss is 0.012321285903453827\n",
      "epoch: 2 step: 1608, loss is 0.000752852822188288\n",
      "epoch: 2 step: 1609, loss is 0.0031261390540748835\n",
      "epoch: 2 step: 1610, loss is 0.024624371901154518\n",
      "epoch: 2 step: 1611, loss is 0.010114343836903572\n",
      "epoch: 2 step: 1612, loss is 0.0016200412064790726\n",
      "epoch: 2 step: 1613, loss is 0.033167965710163116\n",
      "epoch: 2 step: 1614, loss is 0.007474547252058983\n",
      "epoch: 2 step: 1615, loss is 0.0410483255982399\n",
      "epoch: 2 step: 1616, loss is 0.008977193385362625\n",
      "epoch: 2 step: 1617, loss is 0.0027607993688434362\n",
      "epoch: 2 step: 1618, loss is 0.008480903692543507\n",
      "epoch: 2 step: 1619, loss is 0.009292461909353733\n",
      "epoch: 2 step: 1620, loss is 0.007991106249392033\n",
      "epoch: 2 step: 1621, loss is 0.028886953368782997\n",
      "epoch: 2 step: 1622, loss is 0.05994526296854019\n",
      "epoch: 2 step: 1623, loss is 0.11640501022338867\n",
      "epoch: 2 step: 1624, loss is 0.006126874126493931\n",
      "epoch: 2 step: 1625, loss is 0.3141371011734009\n",
      "epoch: 2 step: 1626, loss is 0.03949696943163872\n",
      "epoch: 2 step: 1627, loss is 0.0078755347058177\n",
      "epoch: 2 step: 1628, loss is 0.017523180693387985\n",
      "epoch: 2 step: 1629, loss is 0.005656430497765541\n",
      "epoch: 2 step: 1630, loss is 0.002471993677318096\n",
      "epoch: 2 step: 1631, loss is 0.015425519086420536\n",
      "epoch: 2 step: 1632, loss is 0.005122635047882795\n",
      "epoch: 2 step: 1633, loss is 0.10555150359869003\n",
      "epoch: 2 step: 1634, loss is 0.12199363857507706\n",
      "epoch: 2 step: 1635, loss is 0.008606454357504845\n",
      "epoch: 2 step: 1636, loss is 0.10966756194829941\n",
      "epoch: 2 step: 1637, loss is 0.011914034374058247\n",
      "epoch: 2 step: 1638, loss is 0.15766486525535583\n",
      "epoch: 2 step: 1639, loss is 0.0018495293334126472\n",
      "epoch: 2 step: 1640, loss is 0.03281596675515175\n",
      "epoch: 2 step: 1641, loss is 0.0993664562702179\n",
      "epoch: 2 step: 1642, loss is 0.008614988997578621\n",
      "epoch: 2 step: 1643, loss is 0.13354027271270752\n",
      "epoch: 2 step: 1644, loss is 0.01537133939564228\n",
      "epoch: 2 step: 1645, loss is 0.00530085526406765\n",
      "epoch: 2 step: 1646, loss is 0.05412402004003525\n",
      "epoch: 2 step: 1647, loss is 0.0003745323629118502\n",
      "epoch: 2 step: 1648, loss is 0.0027552933897823095\n",
      "epoch: 2 step: 1649, loss is 0.02313351072371006\n",
      "epoch: 2 step: 1650, loss is 0.03936277702450752\n",
      "epoch: 2 step: 1651, loss is 0.21862594783306122\n",
      "epoch: 2 step: 1652, loss is 0.0011152041843160987\n",
      "epoch: 2 step: 1653, loss is 0.004682022146880627\n",
      "epoch: 2 step: 1654, loss is 0.03344820439815521\n",
      "epoch: 2 step: 1655, loss is 0.1900203377008438\n",
      "epoch: 2 step: 1656, loss is 0.022480597719550133\n",
      "epoch: 2 step: 1657, loss is 0.04460113123059273\n",
      "epoch: 2 step: 1658, loss is 0.0005575643153861165\n",
      "epoch: 2 step: 1659, loss is 0.004996826406568289\n",
      "epoch: 2 step: 1660, loss is 0.010859622620046139\n",
      "epoch: 2 step: 1661, loss is 0.009768147952854633\n",
      "epoch: 2 step: 1662, loss is 0.06675047427415848\n",
      "epoch: 2 step: 1663, loss is 0.07910376787185669\n",
      "epoch: 2 step: 1664, loss is 0.22501783072948456\n",
      "epoch: 2 step: 1665, loss is 0.1276809126138687\n",
      "epoch: 2 step: 1666, loss is 0.005559357348829508\n",
      "epoch: 2 step: 1667, loss is 0.01617337390780449\n",
      "epoch: 2 step: 1668, loss is 0.01034762617200613\n",
      "epoch: 2 step: 1669, loss is 0.06494040787220001\n",
      "epoch: 2 step: 1670, loss is 0.008907376788556576\n",
      "epoch: 2 step: 1671, loss is 0.4139006435871124\n",
      "epoch: 2 step: 1672, loss is 0.013288027606904507\n",
      "epoch: 2 step: 1673, loss is 0.04351162910461426\n",
      "epoch: 2 step: 1674, loss is 0.0479898601770401\n",
      "epoch: 2 step: 1675, loss is 0.4056626558303833\n",
      "epoch: 2 step: 1676, loss is 0.1817423701286316\n",
      "epoch: 2 step: 1677, loss is 0.06627549976110458\n",
      "epoch: 2 step: 1678, loss is 0.03794587403535843\n",
      "epoch: 2 step: 1679, loss is 0.017190292477607727\n",
      "epoch: 2 step: 1680, loss is 0.08298756927251816\n",
      "epoch: 2 step: 1681, loss is 0.0031052236445248127\n",
      "epoch: 2 step: 1682, loss is 0.03471377119421959\n",
      "epoch: 2 step: 1683, loss is 0.06473443657159805\n",
      "epoch: 2 step: 1684, loss is 0.20055650174617767\n",
      "epoch: 2 step: 1685, loss is 0.010548286139965057\n",
      "epoch: 2 step: 1686, loss is 0.2266721874475479\n",
      "epoch: 2 step: 1687, loss is 0.09186571836471558\n",
      "epoch: 2 step: 1688, loss is 0.04932801052927971\n",
      "epoch: 2 step: 1689, loss is 0.03864360600709915\n",
      "epoch: 2 step: 1690, loss is 0.01432129368185997\n",
      "epoch: 2 step: 1691, loss is 0.03533754125237465\n",
      "epoch: 2 step: 1692, loss is 0.04982876032590866\n",
      "epoch: 2 step: 1693, loss is 0.010581286624073982\n",
      "epoch: 2 step: 1694, loss is 0.0038618529215455055\n",
      "epoch: 2 step: 1695, loss is 0.0017894633347168565\n",
      "epoch: 2 step: 1696, loss is 0.011227036826312542\n",
      "epoch: 2 step: 1697, loss is 0.020767852663993835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1698, loss is 0.06031203642487526\n",
      "epoch: 2 step: 1699, loss is 0.040457241237163544\n",
      "epoch: 2 step: 1700, loss is 0.007135003339499235\n",
      "epoch: 2 step: 1701, loss is 0.0022368254140019417\n",
      "epoch: 2 step: 1702, loss is 0.07282327860593796\n",
      "epoch: 2 step: 1703, loss is 0.07091215997934341\n",
      "epoch: 2 step: 1704, loss is 0.015543445013463497\n",
      "epoch: 2 step: 1705, loss is 0.003135586390271783\n",
      "epoch: 2 step: 1706, loss is 0.01440662145614624\n",
      "epoch: 2 step: 1707, loss is 0.03180164471268654\n",
      "epoch: 2 step: 1708, loss is 0.04605864733457565\n",
      "epoch: 2 step: 1709, loss is 0.00912439078092575\n",
      "epoch: 2 step: 1710, loss is 0.030199512839317322\n",
      "epoch: 2 step: 1711, loss is 0.351796418428421\n",
      "epoch: 2 step: 1712, loss is 0.006692103575915098\n",
      "epoch: 2 step: 1713, loss is 0.008288884535431862\n",
      "epoch: 2 step: 1714, loss is 0.00606945063918829\n",
      "epoch: 2 step: 1715, loss is 0.07916666567325592\n",
      "epoch: 2 step: 1716, loss is 0.04235280677676201\n",
      "epoch: 2 step: 1717, loss is 0.05016372725367546\n",
      "epoch: 2 step: 1718, loss is 0.05631150305271149\n",
      "epoch: 2 step: 1719, loss is 0.044835664331912994\n",
      "epoch: 2 step: 1720, loss is 0.009634057059884071\n",
      "epoch: 2 step: 1721, loss is 0.010496558621525764\n",
      "epoch: 2 step: 1722, loss is 0.0060831052251160145\n",
      "epoch: 2 step: 1723, loss is 0.022876963019371033\n",
      "epoch: 2 step: 1724, loss is 0.006285601295530796\n",
      "epoch: 2 step: 1725, loss is 0.24340061843395233\n",
      "epoch: 2 step: 1726, loss is 0.025847848504781723\n",
      "epoch: 2 step: 1727, loss is 0.0034310731571167707\n",
      "epoch: 2 step: 1728, loss is 0.14105135202407837\n",
      "epoch: 2 step: 1729, loss is 0.0018704370595514774\n",
      "epoch: 2 step: 1730, loss is 0.0032616916578263044\n",
      "epoch: 2 step: 1731, loss is 0.0364973321557045\n",
      "epoch: 2 step: 1732, loss is 0.013380222022533417\n",
      "epoch: 2 step: 1733, loss is 0.25523653626441956\n",
      "epoch: 2 step: 1734, loss is 0.09620041400194168\n",
      "epoch: 2 step: 1735, loss is 0.21997308731079102\n",
      "epoch: 2 step: 1736, loss is 0.07888469099998474\n",
      "epoch: 2 step: 1737, loss is 0.011792981997132301\n",
      "epoch: 2 step: 1738, loss is 0.006742640398442745\n",
      "epoch: 2 step: 1739, loss is 0.08847376704216003\n",
      "epoch: 2 step: 1740, loss is 0.007894203066825867\n",
      "epoch: 2 step: 1741, loss is 0.0014850093284621835\n",
      "epoch: 2 step: 1742, loss is 0.004426445811986923\n",
      "epoch: 2 step: 1743, loss is 0.04727373644709587\n",
      "epoch: 2 step: 1744, loss is 0.005044691264629364\n",
      "epoch: 2 step: 1745, loss is 0.007559766992926598\n",
      "epoch: 2 step: 1746, loss is 0.03662589564919472\n",
      "epoch: 2 step: 1747, loss is 0.09601402282714844\n",
      "epoch: 2 step: 1748, loss is 0.018826600164175034\n",
      "epoch: 2 step: 1749, loss is 0.0481560193002224\n",
      "epoch: 2 step: 1750, loss is 0.053957249969244\n",
      "epoch: 2 step: 1751, loss is 0.009305095300078392\n",
      "epoch: 2 step: 1752, loss is 0.04344141483306885\n",
      "epoch: 2 step: 1753, loss is 0.0433785542845726\n",
      "epoch: 2 step: 1754, loss is 0.009934390895068645\n",
      "epoch: 2 step: 1755, loss is 0.08884752541780472\n",
      "epoch: 2 step: 1756, loss is 0.13037492334842682\n",
      "epoch: 2 step: 1757, loss is 0.10973861813545227\n",
      "epoch: 2 step: 1758, loss is 0.4684542119503021\n",
      "epoch: 2 step: 1759, loss is 0.013115975074470043\n",
      "epoch: 2 step: 1760, loss is 0.0023911285679787397\n",
      "epoch: 2 step: 1761, loss is 0.14615429937839508\n",
      "epoch: 2 step: 1762, loss is 0.003979117143899202\n",
      "epoch: 2 step: 1763, loss is 0.0014573292573913932\n",
      "epoch: 2 step: 1764, loss is 0.002068860922008753\n",
      "epoch: 2 step: 1765, loss is 0.009021708741784096\n",
      "epoch: 2 step: 1766, loss is 0.013836458325386047\n",
      "epoch: 2 step: 1767, loss is 0.0047342595644295216\n",
      "epoch: 2 step: 1768, loss is 0.033682189881801605\n",
      "epoch: 2 step: 1769, loss is 0.1784975528717041\n",
      "epoch: 2 step: 1770, loss is 0.002356552518904209\n",
      "epoch: 2 step: 1771, loss is 0.009507432579994202\n",
      "epoch: 2 step: 1772, loss is 0.011163647286593914\n",
      "epoch: 2 step: 1773, loss is 0.11138664186000824\n",
      "epoch: 2 step: 1774, loss is 0.035939790308475494\n",
      "epoch: 2 step: 1775, loss is 0.010718307457864285\n",
      "epoch: 2 step: 1776, loss is 0.1115589290857315\n",
      "epoch: 2 step: 1777, loss is 0.019271260127425194\n",
      "epoch: 2 step: 1778, loss is 0.02081511728465557\n",
      "epoch: 2 step: 1779, loss is 0.02214646339416504\n",
      "epoch: 2 step: 1780, loss is 0.002671747002750635\n",
      "epoch: 2 step: 1781, loss is 0.06219854950904846\n",
      "epoch: 2 step: 1782, loss is 0.09661731123924255\n",
      "epoch: 2 step: 1783, loss is 0.1577356904745102\n",
      "epoch: 2 step: 1784, loss is 0.0085802236571908\n",
      "epoch: 2 step: 1785, loss is 0.042927030473947525\n",
      "epoch: 2 step: 1786, loss is 0.006528587080538273\n",
      "epoch: 2 step: 1787, loss is 0.03161821514368057\n",
      "epoch: 2 step: 1788, loss is 0.06588295102119446\n",
      "epoch: 2 step: 1789, loss is 0.010725370608270168\n",
      "epoch: 2 step: 1790, loss is 0.003695014165714383\n",
      "epoch: 2 step: 1791, loss is 0.0030301047954708338\n",
      "epoch: 2 step: 1792, loss is 0.2295115739107132\n",
      "epoch: 2 step: 1793, loss is 0.11455544084310532\n",
      "epoch: 2 step: 1794, loss is 0.007117665372788906\n",
      "epoch: 2 step: 1795, loss is 0.09940323233604431\n",
      "epoch: 2 step: 1796, loss is 0.0013379722367972136\n",
      "epoch: 2 step: 1797, loss is 0.03943110257387161\n",
      "epoch: 2 step: 1798, loss is 0.0008326969109475613\n",
      "epoch: 2 step: 1799, loss is 0.01398976519703865\n",
      "epoch: 2 step: 1800, loss is 0.002596375998109579\n",
      "epoch: 2 step: 1801, loss is 0.028445815667510033\n",
      "epoch: 2 step: 1802, loss is 0.13493399322032928\n",
      "epoch: 2 step: 1803, loss is 0.03900725021958351\n",
      "epoch: 2 step: 1804, loss is 0.04690515249967575\n",
      "epoch: 2 step: 1805, loss is 0.012852057814598083\n",
      "epoch: 2 step: 1806, loss is 0.09166139364242554\n",
      "epoch: 2 step: 1807, loss is 0.01610252633690834\n",
      "epoch: 2 step: 1808, loss is 0.043665312230587006\n",
      "epoch: 2 step: 1809, loss is 0.1027330532670021\n",
      "epoch: 2 step: 1810, loss is 0.001960328547284007\n",
      "epoch: 2 step: 1811, loss is 0.17570896446704865\n",
      "epoch: 2 step: 1812, loss is 0.019359230995178223\n",
      "epoch: 2 step: 1813, loss is 0.019010836258530617\n",
      "epoch: 2 step: 1814, loss is 0.00457614753395319\n",
      "epoch: 2 step: 1815, loss is 0.004614835139364004\n",
      "epoch: 2 step: 1816, loss is 0.029959358274936676\n",
      "epoch: 2 step: 1817, loss is 0.22742901742458344\n",
      "epoch: 2 step: 1818, loss is 0.012041863054037094\n",
      "epoch: 2 step: 1819, loss is 0.0007747578783892095\n",
      "epoch: 2 step: 1820, loss is 0.03950042650103569\n",
      "epoch: 2 step: 1821, loss is 0.001151415635831654\n",
      "epoch: 2 step: 1822, loss is 0.280575156211853\n",
      "epoch: 2 step: 1823, loss is 0.0032995035871863365\n",
      "epoch: 2 step: 1824, loss is 0.007258489262312651\n",
      "epoch: 2 step: 1825, loss is 0.24774979054927826\n",
      "epoch: 2 step: 1826, loss is 0.09590622782707214\n",
      "epoch: 2 step: 1827, loss is 0.0049011316150426865\n",
      "epoch: 2 step: 1828, loss is 0.03719177097082138\n",
      "epoch: 2 step: 1829, loss is 0.006947288755327463\n",
      "epoch: 2 step: 1830, loss is 0.06464137881994247\n",
      "epoch: 2 step: 1831, loss is 0.010527468286454678\n",
      "epoch: 2 step: 1832, loss is 0.010068496689200401\n",
      "epoch: 2 step: 1833, loss is 0.1616741120815277\n",
      "epoch: 2 step: 1834, loss is 0.041794948279857635\n",
      "epoch: 2 step: 1835, loss is 0.010321564972400665\n",
      "epoch: 2 step: 1836, loss is 0.18252409994602203\n",
      "epoch: 2 step: 1837, loss is 0.02559923194348812\n",
      "epoch: 2 step: 1838, loss is 0.1546032428741455\n",
      "epoch: 2 step: 1839, loss is 0.07388578355312347\n",
      "epoch: 2 step: 1840, loss is 0.013137995265424252\n",
      "epoch: 2 step: 1841, loss is 0.005817231256514788\n",
      "epoch: 2 step: 1842, loss is 0.08775848895311356\n",
      "epoch: 2 step: 1843, loss is 0.02577829733490944\n",
      "epoch: 2 step: 1844, loss is 0.00231226091273129\n",
      "epoch: 2 step: 1845, loss is 0.0568733885884285\n",
      "epoch: 2 step: 1846, loss is 0.0072397505864501\n",
      "epoch: 2 step: 1847, loss is 0.0019591536838561296\n",
      "epoch: 2 step: 1848, loss is 0.033985063433647156\n",
      "epoch: 2 step: 1849, loss is 0.010761636309325695\n",
      "epoch: 2 step: 1850, loss is 0.034415267407894135\n",
      "epoch: 2 step: 1851, loss is 0.010096589103341103\n",
      "epoch: 2 step: 1852, loss is 0.16673117876052856\n",
      "epoch: 2 step: 1853, loss is 0.004689943045377731\n",
      "epoch: 2 step: 1854, loss is 0.04264536499977112\n",
      "epoch: 2 step: 1855, loss is 0.004364980850368738\n",
      "epoch: 2 step: 1856, loss is 0.013147513382136822\n",
      "epoch: 2 step: 1857, loss is 0.14017364382743835\n",
      "epoch: 2 step: 1858, loss is 0.0403066910803318\n",
      "epoch: 2 step: 1859, loss is 0.002529782010242343\n",
      "epoch: 2 step: 1860, loss is 0.04297354072332382\n",
      "epoch: 2 step: 1861, loss is 0.045144688338041306\n",
      "epoch: 2 step: 1862, loss is 0.008232091553509235\n",
      "epoch: 2 step: 1863, loss is 0.022229153662919998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1864, loss is 0.22841283679008484\n",
      "epoch: 2 step: 1865, loss is 0.023997193202376366\n",
      "epoch: 2 step: 1866, loss is 0.020300090312957764\n",
      "epoch: 2 step: 1867, loss is 0.06114561855792999\n",
      "epoch: 2 step: 1868, loss is 0.14434638619422913\n",
      "epoch: 2 step: 1869, loss is 0.024418331682682037\n",
      "epoch: 2 step: 1870, loss is 0.007561173755675554\n",
      "epoch: 2 step: 1871, loss is 0.16388975083827972\n",
      "epoch: 2 step: 1872, loss is 0.008337916806340218\n",
      "epoch: 2 step: 1873, loss is 0.002086945343762636\n",
      "epoch: 2 step: 1874, loss is 0.0707833543419838\n",
      "epoch: 2 step: 1875, loss is 0.0031394914258271456\n",
      "epoch: 2 step: 1876, loss is 0.005163346882909536\n",
      "epoch: 2 step: 1877, loss is 0.33359476923942566\n",
      "epoch: 2 step: 1878, loss is 0.02350710891187191\n",
      "epoch: 2 step: 1879, loss is 0.0022171323653310537\n",
      "epoch: 2 step: 1880, loss is 0.006392354611307383\n",
      "epoch: 2 step: 1881, loss is 0.10784091055393219\n",
      "epoch: 2 step: 1882, loss is 0.06510050594806671\n",
      "epoch: 2 step: 1883, loss is 0.043552789837121964\n",
      "epoch: 2 step: 1884, loss is 0.10938746482133865\n",
      "epoch: 2 step: 1885, loss is 0.0331714041531086\n",
      "epoch: 2 step: 1886, loss is 0.009448802098631859\n",
      "epoch: 2 step: 1887, loss is 0.000911542447283864\n",
      "epoch: 2 step: 1888, loss is 0.0038407945539802313\n",
      "epoch: 2 step: 1889, loss is 0.12347779422998428\n",
      "epoch: 2 step: 1890, loss is 0.0070044007152318954\n",
      "epoch: 2 step: 1891, loss is 0.06838288903236389\n",
      "epoch: 2 step: 1892, loss is 0.1033153161406517\n",
      "epoch: 2 step: 1893, loss is 0.10995135456323624\n",
      "epoch: 2 step: 1894, loss is 0.14014820754528046\n",
      "epoch: 2 step: 1895, loss is 0.05933510884642601\n",
      "epoch: 2 step: 1896, loss is 0.013245798647403717\n",
      "epoch: 2 step: 1897, loss is 0.009037433192133904\n",
      "epoch: 2 step: 1898, loss is 0.03925323113799095\n",
      "epoch: 2 step: 1899, loss is 0.009276296943426132\n",
      "epoch: 2 step: 1900, loss is 0.0313228964805603\n",
      "epoch: 2 step: 1901, loss is 0.0018168920651078224\n",
      "epoch: 2 step: 1902, loss is 0.04056559130549431\n",
      "epoch: 2 step: 1903, loss is 0.1596721112728119\n",
      "epoch: 2 step: 1904, loss is 0.018731096759438515\n",
      "epoch: 2 step: 1905, loss is 0.06204082444310188\n",
      "epoch: 2 step: 1906, loss is 0.162770077586174\n",
      "epoch: 2 step: 1907, loss is 0.0017683554906398058\n",
      "epoch: 2 step: 1908, loss is 0.05600317195057869\n",
      "epoch: 2 step: 1909, loss is 0.14437761902809143\n",
      "epoch: 2 step: 1910, loss is 0.0018459653947502375\n",
      "epoch: 2 step: 1911, loss is 0.0105811832472682\n",
      "epoch: 2 step: 1912, loss is 0.002403841819614172\n",
      "epoch: 2 step: 1913, loss is 0.08388075232505798\n",
      "epoch: 2 step: 1914, loss is 0.006986376363784075\n",
      "epoch: 2 step: 1915, loss is 0.35336509346961975\n",
      "epoch: 2 step: 1916, loss is 0.11967604607343674\n",
      "epoch: 2 step: 1917, loss is 0.026026150211691856\n",
      "epoch: 2 step: 1918, loss is 0.005358393769711256\n",
      "epoch: 2 step: 1919, loss is 0.001554533839225769\n",
      "epoch: 2 step: 1920, loss is 0.026654334738850594\n",
      "epoch: 2 step: 1921, loss is 0.029635794460773468\n",
      "epoch: 2 step: 1922, loss is 0.002475943649187684\n",
      "epoch: 2 step: 1923, loss is 0.051792360842227936\n",
      "epoch: 2 step: 1924, loss is 0.14985916018486023\n",
      "epoch: 2 step: 1925, loss is 0.015854356810450554\n",
      "epoch: 2 step: 1926, loss is 0.000921623024623841\n",
      "epoch: 2 step: 1927, loss is 0.019273219630122185\n",
      "epoch: 2 step: 1928, loss is 0.04801049828529358\n",
      "epoch: 2 step: 1929, loss is 0.08727402985095978\n",
      "epoch: 2 step: 1930, loss is 0.03160355985164642\n",
      "epoch: 2 step: 1931, loss is 0.0985296443104744\n",
      "epoch: 2 step: 1932, loss is 0.016416266560554504\n",
      "epoch: 2 step: 1933, loss is 0.002017961349338293\n",
      "epoch: 2 step: 1934, loss is 0.01115759089589119\n",
      "epoch: 2 step: 1935, loss is 0.012064449489116669\n",
      "epoch: 2 step: 1936, loss is 0.014555683359503746\n",
      "epoch: 2 step: 1937, loss is 0.004006111063063145\n",
      "epoch: 2 step: 1938, loss is 0.11115463078022003\n",
      "epoch: 2 step: 1939, loss is 0.05794801563024521\n",
      "epoch: 2 step: 1940, loss is 0.032984960824251175\n",
      "epoch: 2 step: 1941, loss is 0.034943174570798874\n",
      "epoch: 2 step: 1942, loss is 0.004006546922028065\n",
      "epoch: 2 step: 1943, loss is 0.004902939312160015\n",
      "epoch: 2 step: 1944, loss is 0.01023639552295208\n",
      "epoch: 2 step: 1945, loss is 0.010948298498988152\n",
      "epoch: 2 step: 1946, loss is 0.022458158433437347\n",
      "epoch: 2 step: 1947, loss is 0.0035351549740880728\n",
      "epoch: 2 step: 1948, loss is 0.06354986876249313\n",
      "epoch: 2 step: 1949, loss is 0.034343548119068146\n",
      "epoch: 2 step: 1950, loss is 0.04888821020722389\n",
      "epoch: 2 step: 1951, loss is 0.006478695664554834\n",
      "epoch: 2 step: 1952, loss is 0.10328175872564316\n",
      "epoch: 2 step: 1953, loss is 0.12946482002735138\n",
      "epoch: 2 step: 1954, loss is 0.010068563744425774\n",
      "epoch: 2 step: 1955, loss is 0.000911685056053102\n",
      "epoch: 2 step: 1956, loss is 0.17489884793758392\n",
      "epoch: 2 step: 1957, loss is 0.05098253861069679\n",
      "epoch: 2 step: 1958, loss is 0.009690314531326294\n",
      "epoch: 2 step: 1959, loss is 0.02513803355395794\n",
      "epoch: 2 step: 1960, loss is 0.06001497805118561\n",
      "epoch: 2 step: 1961, loss is 0.0011172402882948518\n",
      "epoch: 2 step: 1962, loss is 0.039343398064374924\n",
      "epoch: 2 step: 1963, loss is 0.01335146464407444\n",
      "epoch: 2 step: 1964, loss is 0.008754129521548748\n",
      "epoch: 2 step: 1965, loss is 0.01626596227288246\n",
      "epoch: 2 step: 1966, loss is 0.11686748266220093\n",
      "epoch: 2 step: 1967, loss is 0.06272019445896149\n",
      "epoch: 2 step: 1968, loss is 0.018645407631993294\n",
      "epoch: 2 step: 1969, loss is 0.3396502435207367\n",
      "epoch: 2 step: 1970, loss is 0.00698118144646287\n",
      "epoch: 2 step: 1971, loss is 0.13417573273181915\n",
      "epoch: 2 step: 1972, loss is 0.005817857105284929\n",
      "epoch: 2 step: 1973, loss is 0.017723089084029198\n",
      "epoch: 2 step: 1974, loss is 0.0029297361616045237\n",
      "epoch: 2 step: 1975, loss is 0.266622930765152\n",
      "epoch: 2 step: 1976, loss is 0.027487486600875854\n",
      "epoch: 2 step: 1977, loss is 0.056482113897800446\n",
      "epoch: 2 step: 1978, loss is 0.08446531742811203\n",
      "epoch: 2 step: 1979, loss is 0.0009762699482962489\n",
      "epoch: 2 step: 1980, loss is 0.003408314660191536\n",
      "epoch: 2 step: 1981, loss is 0.08854450285434723\n",
      "epoch: 2 step: 1982, loss is 0.021036989986896515\n",
      "epoch: 2 step: 1983, loss is 0.04091327637434006\n",
      "epoch: 2 step: 1984, loss is 0.025974737480282784\n",
      "epoch: 2 step: 1985, loss is 0.02747192792594433\n",
      "epoch: 2 step: 1986, loss is 0.0022984081879258156\n",
      "epoch: 2 step: 1987, loss is 0.24742519855499268\n",
      "epoch: 2 step: 1988, loss is 0.012394225224852562\n",
      "epoch: 2 step: 1989, loss is 0.004259072709828615\n",
      "epoch: 2 step: 1990, loss is 0.0069657075218856335\n",
      "epoch: 2 step: 1991, loss is 0.002662419341504574\n",
      "epoch: 2 step: 1992, loss is 0.02797248773276806\n",
      "epoch: 2 step: 1993, loss is 0.028631605207920074\n",
      "epoch: 2 step: 1994, loss is 0.0018064695177599788\n",
      "epoch: 2 step: 1995, loss is 0.0014930996112525463\n",
      "epoch: 2 step: 1996, loss is 0.13032123446464539\n",
      "epoch: 2 step: 1997, loss is 0.01908198744058609\n",
      "epoch: 2 step: 1998, loss is 0.10643768310546875\n",
      "epoch: 2 step: 1999, loss is 0.06033167243003845\n",
      "epoch: 2 step: 2000, loss is 0.047149233520030975\n",
      "epoch: 2 step: 2001, loss is 0.03420966863632202\n",
      "epoch: 2 step: 2002, loss is 0.031236916780471802\n",
      "epoch: 2 step: 2003, loss is 0.09397970885038376\n",
      "epoch: 2 step: 2004, loss is 0.0012007964542135596\n",
      "epoch: 2 step: 2005, loss is 0.03211919218301773\n",
      "epoch: 2 step: 2006, loss is 0.0006303182453848422\n",
      "epoch: 2 step: 2007, loss is 0.0018028449267148972\n",
      "epoch: 2 step: 2008, loss is 0.005030232015997171\n",
      "epoch: 2 step: 2009, loss is 0.035935867577791214\n",
      "epoch: 2 step: 2010, loss is 0.015028008259832859\n",
      "epoch: 2 step: 2011, loss is 0.0007544800755567849\n",
      "epoch: 2 step: 2012, loss is 0.003563881618902087\n",
      "epoch: 2 step: 2013, loss is 0.007199139799922705\n",
      "epoch: 2 step: 2014, loss is 0.10940391570329666\n",
      "epoch: 2 step: 2015, loss is 0.0013865395449101925\n",
      "epoch: 2 step: 2016, loss is 0.037264786660671234\n",
      "epoch: 2 step: 2017, loss is 0.00802494678646326\n",
      "epoch: 2 step: 2018, loss is 0.019525863230228424\n",
      "epoch: 2 step: 2019, loss is 0.054762743413448334\n",
      "epoch: 2 step: 2020, loss is 0.04030954837799072\n",
      "epoch: 2 step: 2021, loss is 0.01345459371805191\n",
      "epoch: 2 step: 2022, loss is 0.04143619164824486\n",
      "epoch: 2 step: 2023, loss is 0.13562512397766113\n",
      "epoch: 2 step: 2024, loss is 0.04179975017905235\n",
      "epoch: 2 step: 2025, loss is 0.1531745195388794\n",
      "epoch: 2 step: 2026, loss is 0.024403385818004608\n",
      "epoch: 2 step: 2027, loss is 0.0015550850657746196\n",
      "epoch: 2 step: 2028, loss is 0.04093115031719208\n",
      "epoch: 2 step: 2029, loss is 0.0014482747064903378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 2030, loss is 0.16717170178890228\n",
      "epoch: 2 step: 2031, loss is 0.009658467024564743\n",
      "epoch: 2 step: 2032, loss is 0.16811732947826385\n",
      "epoch: 2 step: 2033, loss is 0.13811838626861572\n",
      "epoch: 2 step: 2034, loss is 0.046284954994916916\n",
      "epoch: 2 step: 2035, loss is 0.035705000162124634\n",
      "epoch: 2 step: 2036, loss is 0.002605505520477891\n",
      "epoch: 2 step: 2037, loss is 0.11455710977315903\n",
      "epoch: 2 step: 2038, loss is 0.035951100289821625\n",
      "epoch: 2 step: 2039, loss is 0.03580784425139427\n",
      "epoch: 2 step: 2040, loss is 0.00155375967733562\n",
      "epoch: 2 step: 2041, loss is 0.03172410652041435\n",
      "epoch: 2 step: 2042, loss is 0.004558110143989325\n",
      "epoch: 2 step: 2043, loss is 0.003071374027058482\n",
      "epoch: 2 step: 2044, loss is 0.018928201869130135\n",
      "epoch: 2 step: 2045, loss is 0.07073605060577393\n",
      "epoch: 2 step: 2046, loss is 0.0018407140159979463\n",
      "epoch: 2 step: 2047, loss is 0.011584983207285404\n",
      "epoch: 2 step: 2048, loss is 0.057462405413389206\n",
      "epoch: 2 step: 2049, loss is 0.06080617383122444\n",
      "epoch: 2 step: 2050, loss is 0.24131742119789124\n",
      "epoch: 2 step: 2051, loss is 0.005634813569486141\n",
      "epoch: 2 step: 2052, loss is 0.0007871085545048118\n",
      "epoch: 2 step: 2053, loss is 0.005395360756665468\n",
      "epoch: 2 step: 2054, loss is 0.0015119275776669383\n",
      "epoch: 2 step: 2055, loss is 0.01945735141634941\n",
      "epoch: 2 step: 2056, loss is 0.018928438425064087\n",
      "epoch: 2 step: 2057, loss is 0.00687910383567214\n",
      "epoch: 2 step: 2058, loss is 0.26276540756225586\n",
      "epoch: 2 step: 2059, loss is 0.03528723493218422\n",
      "epoch: 2 step: 2060, loss is 0.09133776277303696\n",
      "epoch: 2 step: 2061, loss is 0.0008820916409604251\n",
      "epoch: 2 step: 2062, loss is 0.015749948099255562\n",
      "epoch: 2 step: 2063, loss is 0.07879869639873505\n",
      "epoch: 2 step: 2064, loss is 0.31408268213272095\n",
      "epoch: 2 step: 2065, loss is 0.12325811386108398\n",
      "epoch: 2 step: 2066, loss is 0.21401454508304596\n",
      "epoch: 2 step: 2067, loss is 0.08213207870721817\n",
      "epoch: 2 step: 2068, loss is 0.09937979280948639\n",
      "epoch: 2 step: 2069, loss is 0.021059444174170494\n",
      "epoch: 2 step: 2070, loss is 0.02024776302278042\n",
      "epoch: 2 step: 2071, loss is 0.09160813689231873\n",
      "epoch: 2 step: 2072, loss is 0.053687918931245804\n",
      "epoch: 2 step: 2073, loss is 0.06337007880210876\n",
      "epoch: 2 step: 2074, loss is 0.008367880247533321\n",
      "epoch: 2 step: 2075, loss is 0.01890261471271515\n",
      "epoch: 2 step: 2076, loss is 0.11977603286504745\n",
      "epoch: 2 step: 2077, loss is 0.010205467231571674\n",
      "epoch: 2 step: 2078, loss is 0.38523590564727783\n",
      "epoch: 2 step: 2079, loss is 0.009323390200734138\n",
      "epoch: 2 step: 2080, loss is 0.14666473865509033\n",
      "epoch: 2 step: 2081, loss is 0.02903592772781849\n",
      "epoch: 2 step: 2082, loss is 0.000527195748873055\n",
      "epoch: 2 step: 2083, loss is 0.054572731256484985\n",
      "epoch: 2 step: 2084, loss is 0.005403195042163134\n",
      "epoch: 2 step: 2085, loss is 0.039977457374334335\n",
      "epoch: 2 step: 2086, loss is 0.0023454176262021065\n",
      "epoch: 2 step: 2087, loss is 0.01345243863761425\n",
      "epoch: 2 step: 2088, loss is 0.028624361380934715\n",
      "epoch: 2 step: 2089, loss is 0.02448013424873352\n",
      "epoch: 2 step: 2090, loss is 0.007385689299553633\n",
      "epoch: 2 step: 2091, loss is 0.02976805344223976\n",
      "epoch: 2 step: 2092, loss is 0.06870143115520477\n",
      "epoch: 2 step: 2093, loss is 0.0025175667833536863\n",
      "epoch: 2 step: 2094, loss is 0.020406045019626617\n",
      "epoch: 2 step: 2095, loss is 0.1565554440021515\n",
      "epoch: 2 step: 2096, loss is 0.05048908293247223\n",
      "epoch: 2 step: 2097, loss is 0.04078182205557823\n",
      "epoch: 2 step: 2098, loss is 0.019663967192173004\n",
      "epoch: 2 step: 2099, loss is 0.13211604952812195\n",
      "epoch: 2 step: 2100, loss is 0.0026224451139569283\n",
      "epoch: 2 step: 2101, loss is 0.008793221786618233\n",
      "epoch: 2 step: 2102, loss is 0.007890045642852783\n",
      "epoch: 2 step: 2103, loss is 0.010059296153485775\n",
      "epoch: 2 step: 2104, loss is 0.026070507243275642\n",
      "epoch: 2 step: 2105, loss is 0.08385702967643738\n",
      "epoch: 2 step: 2106, loss is 0.0011759749613702297\n",
      "epoch: 2 step: 2107, loss is 0.000680375553201884\n",
      "epoch: 2 step: 2108, loss is 0.060528017580509186\n",
      "epoch: 2 step: 2109, loss is 0.006804370786994696\n",
      "epoch: 2 step: 2110, loss is 0.0030758902430534363\n",
      "epoch: 2 step: 2111, loss is 0.05988799408078194\n",
      "epoch: 2 step: 2112, loss is 0.005992659833282232\n",
      "epoch: 2 step: 2113, loss is 0.09614934772253036\n",
      "epoch: 2 step: 2114, loss is 0.00027515162946656346\n",
      "epoch: 2 step: 2115, loss is 0.04454446956515312\n",
      "epoch: 2 step: 2116, loss is 0.003276383737102151\n",
      "epoch: 2 step: 2117, loss is 0.05394323915243149\n",
      "epoch: 2 step: 2118, loss is 0.30316129326820374\n",
      "epoch: 2 step: 2119, loss is 0.0003308697778265923\n",
      "epoch: 2 step: 2120, loss is 0.005153050180524588\n",
      "epoch: 2 step: 2121, loss is 0.00087910977890715\n",
      "epoch: 2 step: 2122, loss is 0.05668242648243904\n",
      "epoch: 2 step: 2123, loss is 0.1517690122127533\n",
      "epoch: 2 step: 2124, loss is 0.013845622539520264\n",
      "epoch: 2 step: 2125, loss is 0.008192644454538822\n",
      "epoch: 2 step: 2126, loss is 0.0722920373082161\n",
      "epoch: 2 step: 2127, loss is 0.01984012871980667\n",
      "epoch: 2 step: 2128, loss is 0.025152523070573807\n",
      "epoch: 2 step: 2129, loss is 0.01194598525762558\n",
      "epoch: 2 step: 2130, loss is 0.07316967844963074\n",
      "epoch: 2 step: 2131, loss is 0.003974702209234238\n",
      "epoch: 2 step: 2132, loss is 0.03743863105773926\n",
      "epoch: 2 step: 2133, loss is 0.009096398018300533\n",
      "epoch: 2 step: 2134, loss is 0.09842204302549362\n",
      "epoch: 2 step: 2135, loss is 0.07747168093919754\n",
      "epoch: 2 step: 2136, loss is 0.05755540728569031\n",
      "epoch: 2 step: 2137, loss is 0.007693507242947817\n",
      "epoch: 2 step: 2138, loss is 0.007858257740736008\n",
      "epoch: 2 step: 2139, loss is 0.037084631621837616\n",
      "epoch: 2 step: 2140, loss is 0.21912676095962524\n",
      "epoch: 2 step: 2141, loss is 0.013041038066148758\n",
      "epoch: 2 step: 2142, loss is 0.003087658202275634\n",
      "epoch: 2 step: 2143, loss is 0.02229253761470318\n",
      "epoch: 2 step: 2144, loss is 0.018417445942759514\n",
      "epoch: 2 step: 2145, loss is 0.0021751204039901495\n",
      "epoch: 2 step: 2146, loss is 0.0014544727746397257\n",
      "epoch: 2 step: 2147, loss is 0.07955283671617508\n",
      "epoch: 2 step: 2148, loss is 0.031609807163476944\n",
      "epoch: 2 step: 2149, loss is 0.022194229066371918\n",
      "epoch: 2 step: 2150, loss is 0.013983783312141895\n",
      "epoch: 2 step: 2151, loss is 0.08165507763624191\n",
      "epoch: 2 step: 2152, loss is 0.015363236889243126\n",
      "epoch: 2 step: 2153, loss is 0.008232143707573414\n",
      "epoch: 2 step: 2154, loss is 0.08772692084312439\n",
      "epoch: 2 step: 2155, loss is 0.060745514929294586\n",
      "epoch: 2 step: 2156, loss is 0.4372217357158661\n",
      "epoch: 2 step: 2157, loss is 0.0030907082837074995\n",
      "epoch: 2 step: 2158, loss is 0.01110470574349165\n",
      "epoch: 2 step: 2159, loss is 0.010035962797701359\n",
      "epoch: 2 step: 2160, loss is 0.00164378946647048\n",
      "epoch: 2 step: 2161, loss is 0.013316560536623001\n",
      "epoch: 2 step: 2162, loss is 0.001232351758517325\n",
      "epoch: 2 step: 2163, loss is 0.004897169768810272\n",
      "epoch: 2 step: 2164, loss is 0.10439864546060562\n",
      "epoch: 2 step: 2165, loss is 0.10303258150815964\n",
      "epoch: 2 step: 2166, loss is 0.04813895374536514\n",
      "epoch: 2 step: 2167, loss is 0.01149715855717659\n",
      "epoch: 2 step: 2168, loss is 0.03035261668264866\n",
      "epoch: 2 step: 2169, loss is 0.052643682807683945\n",
      "epoch: 2 step: 2170, loss is 0.03066396899521351\n",
      "epoch: 2 step: 2171, loss is 0.04486280679702759\n",
      "epoch: 2 step: 2172, loss is 0.1257534772157669\n",
      "epoch: 2 step: 2173, loss is 0.021271497011184692\n",
      "epoch: 2 step: 2174, loss is 0.04996807873249054\n",
      "epoch: 2 step: 2175, loss is 0.06655565649271011\n",
      "epoch: 2 step: 2176, loss is 0.013675584457814693\n",
      "epoch: 2 step: 2177, loss is 0.010564790107309818\n",
      "epoch: 2 step: 2178, loss is 0.0006347226444631815\n",
      "epoch: 2 step: 2179, loss is 0.11859431862831116\n",
      "epoch: 2 step: 2180, loss is 0.00047752217506058514\n",
      "epoch: 2 step: 2181, loss is 0.175446555018425\n",
      "epoch: 2 step: 2182, loss is 0.011422064155340195\n",
      "epoch: 2 step: 2183, loss is 0.031045276671648026\n",
      "epoch: 2 step: 2184, loss is 0.024867190048098564\n",
      "epoch: 2 step: 2185, loss is 0.002287356648594141\n",
      "epoch: 2 step: 2186, loss is 0.005435108672827482\n",
      "epoch: 2 step: 2187, loss is 0.0011117998510599136\n",
      "epoch: 3 step: 1, loss is 0.01718207821249962\n",
      "epoch: 3 step: 2, loss is 0.005290588364005089\n",
      "epoch: 3 step: 3, loss is 0.001205579494126141\n",
      "epoch: 3 step: 4, loss is 0.02252517268061638\n",
      "epoch: 3 step: 5, loss is 0.0058265794068574905\n",
      "epoch: 3 step: 6, loss is 0.006292229518294334\n",
      "epoch: 3 step: 7, loss is 0.2172345668077469\n",
      "epoch: 3 step: 8, loss is 0.001265553291887045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 9, loss is 0.004165573976933956\n",
      "epoch: 3 step: 10, loss is 0.03421208634972572\n",
      "epoch: 3 step: 11, loss is 0.010686258785426617\n",
      "epoch: 3 step: 12, loss is 0.021172169595956802\n",
      "epoch: 3 step: 13, loss is 0.0016572444001212716\n",
      "epoch: 3 step: 14, loss is 0.013642393983900547\n",
      "epoch: 3 step: 15, loss is 0.19992807507514954\n",
      "epoch: 3 step: 16, loss is 0.0017331538256257772\n",
      "epoch: 3 step: 17, loss is 0.14200282096862793\n",
      "epoch: 3 step: 18, loss is 0.006344019901007414\n",
      "epoch: 3 step: 19, loss is 0.035597484558820724\n",
      "epoch: 3 step: 20, loss is 0.0456603579223156\n",
      "epoch: 3 step: 21, loss is 0.004020743537694216\n",
      "epoch: 3 step: 22, loss is 0.0006489938823506236\n",
      "epoch: 3 step: 23, loss is 0.001129279495216906\n",
      "epoch: 3 step: 24, loss is 0.002068739850074053\n",
      "epoch: 3 step: 25, loss is 0.0037686419673264027\n",
      "epoch: 3 step: 26, loss is 0.10870642215013504\n",
      "epoch: 3 step: 27, loss is 0.0013865054352208972\n",
      "epoch: 3 step: 28, loss is 0.0005968367913737893\n",
      "epoch: 3 step: 29, loss is 0.009957186877727509\n",
      "epoch: 3 step: 30, loss is 0.052282460033893585\n",
      "epoch: 3 step: 31, loss is 0.021266143769025803\n",
      "epoch: 3 step: 32, loss is 0.002208308782428503\n",
      "epoch: 3 step: 33, loss is 0.002305026166141033\n",
      "epoch: 3 step: 34, loss is 0.004470487125217915\n",
      "epoch: 3 step: 35, loss is 0.04098457098007202\n",
      "epoch: 3 step: 36, loss is 0.00025994019233621657\n",
      "epoch: 3 step: 37, loss is 0.031920500099658966\n",
      "epoch: 3 step: 38, loss is 0.10731387138366699\n",
      "epoch: 3 step: 39, loss is 0.0026419763453304768\n",
      "epoch: 3 step: 40, loss is 0.009243697859346867\n",
      "epoch: 3 step: 41, loss is 0.3534936308860779\n",
      "epoch: 3 step: 42, loss is 0.0014385662507265806\n",
      "epoch: 3 step: 43, loss is 0.08062689006328583\n",
      "epoch: 3 step: 44, loss is 0.0011431098682805896\n",
      "epoch: 3 step: 45, loss is 0.11211147159337997\n",
      "epoch: 3 step: 46, loss is 0.03480887413024902\n",
      "epoch: 3 step: 47, loss is 0.0027367526199668646\n",
      "epoch: 3 step: 48, loss is 0.001347248675301671\n",
      "epoch: 3 step: 49, loss is 0.1807233989238739\n",
      "epoch: 3 step: 50, loss is 0.004981338512152433\n",
      "epoch: 3 step: 51, loss is 0.05386746674776077\n",
      "epoch: 3 step: 52, loss is 0.005760290659964085\n",
      "epoch: 3 step: 53, loss is 0.006487214472144842\n",
      "epoch: 3 step: 54, loss is 0.006484511308372021\n",
      "epoch: 3 step: 55, loss is 0.001069233170710504\n",
      "epoch: 3 step: 56, loss is 0.006463783327490091\n",
      "epoch: 3 step: 57, loss is 0.04284384846687317\n",
      "epoch: 3 step: 58, loss is 0.05832444131374359\n",
      "epoch: 3 step: 59, loss is 0.00963891763240099\n",
      "epoch: 3 step: 60, loss is 0.011202828958630562\n",
      "epoch: 3 step: 61, loss is 0.0639566034078598\n",
      "epoch: 3 step: 62, loss is 0.004502539522945881\n",
      "epoch: 3 step: 63, loss is 0.0259422454982996\n",
      "epoch: 3 step: 64, loss is 0.02151815965771675\n",
      "epoch: 3 step: 65, loss is 0.02927139773964882\n",
      "epoch: 3 step: 66, loss is 0.005925219040364027\n",
      "epoch: 3 step: 67, loss is 0.0026980547700077295\n",
      "epoch: 3 step: 68, loss is 0.005961436778306961\n",
      "epoch: 3 step: 69, loss is 0.04811200127005577\n",
      "epoch: 3 step: 70, loss is 0.0017333707073703408\n",
      "epoch: 3 step: 71, loss is 0.010032882913947105\n",
      "epoch: 3 step: 72, loss is 0.1575026959180832\n",
      "epoch: 3 step: 73, loss is 0.010524557903409004\n",
      "epoch: 3 step: 74, loss is 0.01299272570759058\n",
      "epoch: 3 step: 75, loss is 0.0005495105870068073\n",
      "epoch: 3 step: 76, loss is 0.020460525527596474\n",
      "epoch: 3 step: 77, loss is 0.0011631724191829562\n",
      "epoch: 3 step: 78, loss is 0.004077392164617777\n",
      "epoch: 3 step: 79, loss is 0.0050017498433589935\n",
      "epoch: 3 step: 80, loss is 0.015031512826681137\n",
      "epoch: 3 step: 81, loss is 0.23259924352169037\n",
      "epoch: 3 step: 82, loss is 0.002364611253142357\n",
      "epoch: 3 step: 83, loss is 0.011319042183458805\n",
      "epoch: 3 step: 84, loss is 0.052029676735401154\n",
      "epoch: 3 step: 85, loss is 0.030062295496463776\n",
      "epoch: 3 step: 86, loss is 0.14321984350681305\n",
      "epoch: 3 step: 87, loss is 0.0006765627767890692\n",
      "epoch: 3 step: 88, loss is 0.0018275484908372164\n",
      "epoch: 3 step: 89, loss is 0.0034879108425229788\n",
      "epoch: 3 step: 90, loss is 0.1831013262271881\n",
      "epoch: 3 step: 91, loss is 0.045554645359516144\n",
      "epoch: 3 step: 92, loss is 0.05010949820280075\n",
      "epoch: 3 step: 93, loss is 0.033390868455171585\n",
      "epoch: 3 step: 94, loss is 0.03282903879880905\n",
      "epoch: 3 step: 95, loss is 0.20117872953414917\n",
      "epoch: 3 step: 96, loss is 0.05975326895713806\n",
      "epoch: 3 step: 97, loss is 0.004534447565674782\n",
      "epoch: 3 step: 98, loss is 0.015382399782538414\n",
      "epoch: 3 step: 99, loss is 0.27648288011550903\n",
      "epoch: 3 step: 100, loss is 0.012693889439105988\n",
      "epoch: 3 step: 101, loss is 0.006831693928688765\n",
      "epoch: 3 step: 102, loss is 0.0024688136763870716\n",
      "epoch: 3 step: 103, loss is 0.01569429598748684\n",
      "epoch: 3 step: 104, loss is 0.017080072313547134\n",
      "epoch: 3 step: 105, loss is 0.0038325919304043055\n",
      "epoch: 3 step: 106, loss is 0.04817779362201691\n",
      "epoch: 3 step: 107, loss is 0.07154327630996704\n",
      "epoch: 3 step: 108, loss is 0.0046103885397315025\n",
      "epoch: 3 step: 109, loss is 0.05449498072266579\n",
      "epoch: 3 step: 110, loss is 0.004648945294320583\n",
      "epoch: 3 step: 111, loss is 0.02199520729482174\n",
      "epoch: 3 step: 112, loss is 0.003768304595723748\n",
      "epoch: 3 step: 113, loss is 0.008246835321187973\n",
      "epoch: 3 step: 114, loss is 0.012578609399497509\n",
      "epoch: 3 step: 115, loss is 0.12771941721439362\n",
      "epoch: 3 step: 116, loss is 0.11764582991600037\n",
      "epoch: 3 step: 117, loss is 0.0072013624012470245\n",
      "epoch: 3 step: 118, loss is 0.016148682683706284\n",
      "epoch: 3 step: 119, loss is 0.0014541377313435078\n",
      "epoch: 3 step: 120, loss is 0.028943132609128952\n",
      "epoch: 3 step: 121, loss is 0.021871909499168396\n",
      "epoch: 3 step: 122, loss is 0.03391209989786148\n",
      "epoch: 3 step: 123, loss is 0.002499924972653389\n",
      "epoch: 3 step: 124, loss is 0.09382954239845276\n",
      "epoch: 3 step: 125, loss is 0.011818935163319111\n",
      "epoch: 3 step: 126, loss is 0.0020425277762115\n",
      "epoch: 3 step: 127, loss is 0.002518111141398549\n",
      "epoch: 3 step: 128, loss is 0.005706020165234804\n",
      "epoch: 3 step: 129, loss is 0.04537873715162277\n",
      "epoch: 3 step: 130, loss is 0.24327228963375092\n",
      "epoch: 3 step: 131, loss is 0.0001566508290125057\n",
      "epoch: 3 step: 132, loss is 0.009249485097825527\n",
      "epoch: 3 step: 133, loss is 0.001526495791040361\n",
      "epoch: 3 step: 134, loss is 0.06019343435764313\n",
      "epoch: 3 step: 135, loss is 0.04853074997663498\n",
      "epoch: 3 step: 136, loss is 0.0620068684220314\n",
      "epoch: 3 step: 137, loss is 0.008184405043721199\n",
      "epoch: 3 step: 138, loss is 0.015385987237095833\n",
      "epoch: 3 step: 139, loss is 0.21706528961658478\n",
      "epoch: 3 step: 140, loss is 0.022561602294445038\n",
      "epoch: 3 step: 141, loss is 0.0008215862326323986\n",
      "epoch: 3 step: 142, loss is 0.12390556931495667\n",
      "epoch: 3 step: 143, loss is 0.0929705798625946\n",
      "epoch: 3 step: 144, loss is 0.09448419511318207\n",
      "epoch: 3 step: 145, loss is 0.012029186822474003\n",
      "epoch: 3 step: 146, loss is 0.07072854787111282\n",
      "epoch: 3 step: 147, loss is 0.00827740877866745\n",
      "epoch: 3 step: 148, loss is 0.18378566205501556\n",
      "epoch: 3 step: 149, loss is 0.12691138684749603\n",
      "epoch: 3 step: 150, loss is 0.11617235094308853\n",
      "epoch: 3 step: 151, loss is 0.047654636204242706\n",
      "epoch: 3 step: 152, loss is 0.02430214174091816\n",
      "epoch: 3 step: 153, loss is 0.005769381299614906\n",
      "epoch: 3 step: 154, loss is 0.06802048534154892\n",
      "epoch: 3 step: 155, loss is 0.005643364507704973\n",
      "epoch: 3 step: 156, loss is 0.005176559556275606\n",
      "epoch: 3 step: 157, loss is 0.0006601522327400744\n",
      "epoch: 3 step: 158, loss is 0.0013981396332383156\n",
      "epoch: 3 step: 159, loss is 0.02751908265054226\n",
      "epoch: 3 step: 160, loss is 0.001183554413728416\n",
      "epoch: 3 step: 161, loss is 0.19805921614170074\n",
      "epoch: 3 step: 162, loss is 0.0015375984366983175\n",
      "epoch: 3 step: 163, loss is 0.021719973534345627\n",
      "epoch: 3 step: 164, loss is 0.006059359293431044\n",
      "epoch: 3 step: 165, loss is 0.02885378897190094\n",
      "epoch: 3 step: 166, loss is 0.013777876272797585\n",
      "epoch: 3 step: 167, loss is 0.005126639734953642\n",
      "epoch: 3 step: 168, loss is 0.011469871737062931\n",
      "epoch: 3 step: 169, loss is 0.03236676752567291\n",
      "epoch: 3 step: 170, loss is 0.002690557623282075\n",
      "epoch: 3 step: 171, loss is 0.016322201117873192\n",
      "epoch: 3 step: 172, loss is 0.0019012141274288297\n",
      "epoch: 3 step: 173, loss is 0.09921815991401672\n",
      "epoch: 3 step: 174, loss is 0.038038622587919235\n",
      "epoch: 3 step: 175, loss is 0.030822759494185448\n",
      "epoch: 3 step: 176, loss is 0.04086669161915779\n",
      "epoch: 3 step: 177, loss is 0.04042225331068039\n",
      "epoch: 3 step: 178, loss is 0.002818702021613717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 179, loss is 0.0007493687444366515\n",
      "epoch: 3 step: 180, loss is 0.007239590864628553\n",
      "epoch: 3 step: 181, loss is 0.11243490129709244\n",
      "epoch: 3 step: 182, loss is 0.013155796565115452\n",
      "epoch: 3 step: 183, loss is 0.01777390018105507\n",
      "epoch: 3 step: 184, loss is 0.005165429785847664\n",
      "epoch: 3 step: 185, loss is 0.01456738356500864\n",
      "epoch: 3 step: 186, loss is 0.056200191378593445\n",
      "epoch: 3 step: 187, loss is 0.058593593537807465\n",
      "epoch: 3 step: 188, loss is 0.005421123467385769\n",
      "epoch: 3 step: 189, loss is 0.0030218379106372595\n",
      "epoch: 3 step: 190, loss is 0.16608016192913055\n",
      "epoch: 3 step: 191, loss is 0.002205595374107361\n",
      "epoch: 3 step: 192, loss is 0.0007100944640114903\n",
      "epoch: 3 step: 193, loss is 0.0010843250202015042\n",
      "epoch: 3 step: 194, loss is 0.006596853956580162\n",
      "epoch: 3 step: 195, loss is 0.010814384557306767\n",
      "epoch: 3 step: 196, loss is 0.050567202270030975\n",
      "epoch: 3 step: 197, loss is 0.0018663129303604364\n",
      "epoch: 3 step: 198, loss is 0.004449768923223019\n",
      "epoch: 3 step: 199, loss is 0.010892905294895172\n",
      "epoch: 3 step: 200, loss is 0.011951669119298458\n",
      "epoch: 3 step: 201, loss is 0.03193961828947067\n",
      "epoch: 3 step: 202, loss is 0.0007255625096149743\n",
      "epoch: 3 step: 203, loss is 0.038563571870326996\n",
      "epoch: 3 step: 204, loss is 0.0011103719007223845\n",
      "epoch: 3 step: 205, loss is 0.000597802922129631\n",
      "epoch: 3 step: 206, loss is 0.00694530364125967\n",
      "epoch: 3 step: 207, loss is 0.0011441081296652555\n",
      "epoch: 3 step: 208, loss is 0.005381823983043432\n",
      "epoch: 3 step: 209, loss is 0.1236826553940773\n",
      "epoch: 3 step: 210, loss is 0.0035138013772666454\n",
      "epoch: 3 step: 211, loss is 0.08314003795385361\n",
      "epoch: 3 step: 212, loss is 0.12268366664648056\n",
      "epoch: 3 step: 213, loss is 0.030607517808675766\n",
      "epoch: 3 step: 214, loss is 0.004844989627599716\n",
      "epoch: 3 step: 215, loss is 0.0006874175160191953\n",
      "epoch: 3 step: 216, loss is 0.0031144586391747\n",
      "epoch: 3 step: 217, loss is 0.018239036202430725\n",
      "epoch: 3 step: 218, loss is 0.01676579937338829\n",
      "epoch: 3 step: 219, loss is 0.005921803414821625\n",
      "epoch: 3 step: 220, loss is 0.0352899543941021\n",
      "epoch: 3 step: 221, loss is 0.0010275724343955517\n",
      "epoch: 3 step: 222, loss is 0.0007323150057345629\n",
      "epoch: 3 step: 223, loss is 0.1396327167749405\n",
      "epoch: 3 step: 224, loss is 0.0809108316898346\n",
      "epoch: 3 step: 225, loss is 0.30732062458992004\n",
      "epoch: 3 step: 226, loss is 0.2317943125963211\n",
      "epoch: 3 step: 227, loss is 0.02905770018696785\n",
      "epoch: 3 step: 228, loss is 0.0042907483875751495\n",
      "epoch: 3 step: 229, loss is 0.004101653583347797\n",
      "epoch: 3 step: 230, loss is 0.00507784727960825\n",
      "epoch: 3 step: 231, loss is 0.002701141405850649\n",
      "epoch: 3 step: 232, loss is 0.04552798718214035\n",
      "epoch: 3 step: 233, loss is 0.004339448641985655\n",
      "epoch: 3 step: 234, loss is 0.22321084141731262\n",
      "epoch: 3 step: 235, loss is 0.003122396534308791\n",
      "epoch: 3 step: 236, loss is 0.00986188743263483\n",
      "epoch: 3 step: 237, loss is 0.009207183495163918\n",
      "epoch: 3 step: 238, loss is 0.014654794707894325\n",
      "epoch: 3 step: 239, loss is 0.0073866997845470905\n",
      "epoch: 3 step: 240, loss is 0.17332717776298523\n",
      "epoch: 3 step: 241, loss is 0.010328474454581738\n",
      "epoch: 3 step: 242, loss is 0.018456432968378067\n",
      "epoch: 3 step: 243, loss is 0.004653371870517731\n",
      "epoch: 3 step: 244, loss is 0.0016463748179376125\n",
      "epoch: 3 step: 245, loss is 0.003366928780451417\n",
      "epoch: 3 step: 246, loss is 0.022001348435878754\n",
      "epoch: 3 step: 247, loss is 0.14182080328464508\n",
      "epoch: 3 step: 248, loss is 0.011237791739404202\n",
      "epoch: 3 step: 249, loss is 0.025506531819701195\n",
      "epoch: 3 step: 250, loss is 0.025097794830799103\n",
      "epoch: 3 step: 251, loss is 0.005391437094658613\n",
      "epoch: 3 step: 252, loss is 0.0034624477848410606\n",
      "epoch: 3 step: 253, loss is 0.06972169131040573\n",
      "epoch: 3 step: 254, loss is 0.004185489844530821\n",
      "epoch: 3 step: 255, loss is 0.002047633519396186\n",
      "epoch: 3 step: 256, loss is 0.1638602912425995\n",
      "epoch: 3 step: 257, loss is 0.011329540982842445\n",
      "epoch: 3 step: 258, loss is 0.004739643540233374\n",
      "epoch: 3 step: 259, loss is 0.005900949239730835\n",
      "epoch: 3 step: 260, loss is 0.011389944702386856\n",
      "epoch: 3 step: 261, loss is 0.05846448987722397\n",
      "epoch: 3 step: 262, loss is 0.007882846519351006\n",
      "epoch: 3 step: 263, loss is 0.10724534839391708\n",
      "epoch: 3 step: 264, loss is 0.042021624743938446\n",
      "epoch: 3 step: 265, loss is 0.005869148764759302\n",
      "epoch: 3 step: 266, loss is 0.05091998726129532\n",
      "epoch: 3 step: 267, loss is 0.0008507544989697635\n",
      "epoch: 3 step: 268, loss is 0.019212938845157623\n",
      "epoch: 3 step: 269, loss is 0.013524814508855343\n",
      "epoch: 3 step: 270, loss is 0.0867534652352333\n",
      "epoch: 3 step: 271, loss is 0.007895574904978275\n",
      "epoch: 3 step: 272, loss is 0.017406899482011795\n",
      "epoch: 3 step: 273, loss is 0.009487660601735115\n",
      "epoch: 3 step: 274, loss is 0.015378965064883232\n",
      "epoch: 3 step: 275, loss is 0.020115718245506287\n",
      "epoch: 3 step: 276, loss is 0.04084620624780655\n",
      "epoch: 3 step: 277, loss is 0.03880994766950607\n",
      "epoch: 3 step: 278, loss is 0.06188327074050903\n",
      "epoch: 3 step: 279, loss is 0.001346903620287776\n",
      "epoch: 3 step: 280, loss is 0.013542301021516323\n",
      "epoch: 3 step: 281, loss is 0.003020042786374688\n",
      "epoch: 3 step: 282, loss is 0.0025435916613787413\n",
      "epoch: 3 step: 283, loss is 5.8009372878586873e-05\n",
      "epoch: 3 step: 284, loss is 0.0014328688848763704\n",
      "epoch: 3 step: 285, loss is 0.06377231329679489\n",
      "epoch: 3 step: 286, loss is 0.0005367111880332232\n",
      "epoch: 3 step: 287, loss is 0.011029430665075779\n",
      "epoch: 3 step: 288, loss is 0.07737582921981812\n",
      "epoch: 3 step: 289, loss is 0.01651354320347309\n",
      "epoch: 3 step: 290, loss is 0.013598007149994373\n",
      "epoch: 3 step: 291, loss is 0.025954479351639748\n",
      "epoch: 3 step: 292, loss is 0.08409792184829712\n",
      "epoch: 3 step: 293, loss is 0.12204135954380035\n",
      "epoch: 3 step: 294, loss is 0.0026456674095243216\n",
      "epoch: 3 step: 295, loss is 0.022422559559345245\n",
      "epoch: 3 step: 296, loss is 0.005970141384750605\n",
      "epoch: 3 step: 297, loss is 0.03473682701587677\n",
      "epoch: 3 step: 298, loss is 0.02276095375418663\n",
      "epoch: 3 step: 299, loss is 0.00017135875532403588\n",
      "epoch: 3 step: 300, loss is 0.0486464761197567\n",
      "epoch: 3 step: 301, loss is 0.0016877185553312302\n",
      "epoch: 3 step: 302, loss is 0.0016104280948638916\n",
      "epoch: 3 step: 303, loss is 0.054861146956682205\n",
      "epoch: 3 step: 304, loss is 0.0012773785274475813\n",
      "epoch: 3 step: 305, loss is 0.08259216696023941\n",
      "epoch: 3 step: 306, loss is 0.006503572687506676\n",
      "epoch: 3 step: 307, loss is 0.0071496726013720036\n",
      "epoch: 3 step: 308, loss is 0.017671382054686546\n",
      "epoch: 3 step: 309, loss is 0.0012506679631769657\n",
      "epoch: 3 step: 310, loss is 0.002161164302378893\n",
      "epoch: 3 step: 311, loss is 0.00022581632947549224\n",
      "epoch: 3 step: 312, loss is 0.07878509163856506\n",
      "epoch: 3 step: 313, loss is 0.05070693790912628\n",
      "epoch: 3 step: 314, loss is 0.036763887852430344\n",
      "epoch: 3 step: 315, loss is 0.015307732857763767\n",
      "epoch: 3 step: 316, loss is 0.08881823718547821\n",
      "epoch: 3 step: 317, loss is 0.2599847614765167\n",
      "epoch: 3 step: 318, loss is 0.005092345643788576\n",
      "epoch: 3 step: 319, loss is 0.0794651135802269\n",
      "epoch: 3 step: 320, loss is 0.0012127029476687312\n",
      "epoch: 3 step: 321, loss is 0.022558091208338737\n",
      "epoch: 3 step: 322, loss is 0.06157263368368149\n",
      "epoch: 3 step: 323, loss is 0.17529533803462982\n",
      "epoch: 3 step: 324, loss is 0.09808209538459778\n",
      "epoch: 3 step: 325, loss is 0.006855363957583904\n",
      "epoch: 3 step: 326, loss is 0.03378208354115486\n",
      "epoch: 3 step: 327, loss is 0.0034780860878527164\n",
      "epoch: 3 step: 328, loss is 0.12256626784801483\n",
      "epoch: 3 step: 329, loss is 0.01992170885205269\n",
      "epoch: 3 step: 330, loss is 0.0008602759917266667\n",
      "epoch: 3 step: 331, loss is 0.0069526308216154575\n",
      "epoch: 3 step: 332, loss is 0.09193453192710876\n",
      "epoch: 3 step: 333, loss is 0.17603591084480286\n",
      "epoch: 3 step: 334, loss is 0.020809195935726166\n",
      "epoch: 3 step: 335, loss is 0.009658599272370338\n",
      "epoch: 3 step: 336, loss is 0.07310451567173004\n",
      "epoch: 3 step: 337, loss is 0.01589296944439411\n",
      "epoch: 3 step: 338, loss is 0.002949574263766408\n",
      "epoch: 3 step: 339, loss is 0.01903298683464527\n",
      "epoch: 3 step: 340, loss is 0.0007027176325209439\n",
      "epoch: 3 step: 341, loss is 0.0020832710433751345\n",
      "epoch: 3 step: 342, loss is 0.02060210518538952\n",
      "epoch: 3 step: 343, loss is 0.009276664815843105\n",
      "epoch: 3 step: 344, loss is 0.06074949726462364\n",
      "epoch: 3 step: 345, loss is 0.03676498681306839\n",
      "epoch: 3 step: 346, loss is 0.16095620393753052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 347, loss is 0.0057752844877541065\n",
      "epoch: 3 step: 348, loss is 0.035894185304641724\n",
      "epoch: 3 step: 349, loss is 0.013771583326160908\n",
      "epoch: 3 step: 350, loss is 0.06985469162464142\n",
      "epoch: 3 step: 351, loss is 0.11418576538562775\n",
      "epoch: 3 step: 352, loss is 0.006907305680215359\n",
      "epoch: 3 step: 353, loss is 0.017882267013192177\n",
      "epoch: 3 step: 354, loss is 0.008852493017911911\n",
      "epoch: 3 step: 355, loss is 0.0011265004286542535\n",
      "epoch: 3 step: 356, loss is 0.001044012140482664\n",
      "epoch: 3 step: 357, loss is 0.07657324522733688\n",
      "epoch: 3 step: 358, loss is 0.0015328521840274334\n",
      "epoch: 3 step: 359, loss is 0.005110735073685646\n",
      "epoch: 3 step: 360, loss is 0.027270697057247162\n",
      "epoch: 3 step: 361, loss is 0.0006172883440740407\n",
      "epoch: 3 step: 362, loss is 0.044845692813396454\n",
      "epoch: 3 step: 363, loss is 0.013877215795218945\n",
      "epoch: 3 step: 364, loss is 0.01857725903391838\n",
      "epoch: 3 step: 365, loss is 0.0016431799158453941\n",
      "epoch: 3 step: 366, loss is 0.0360087975859642\n",
      "epoch: 3 step: 367, loss is 0.03510895371437073\n",
      "epoch: 3 step: 368, loss is 0.0035230289213359356\n",
      "epoch: 3 step: 369, loss is 0.0025765537284314632\n",
      "epoch: 3 step: 370, loss is 0.05338554084300995\n",
      "epoch: 3 step: 371, loss is 0.005772840231657028\n",
      "epoch: 3 step: 372, loss is 0.339449405670166\n",
      "epoch: 3 step: 373, loss is 0.058878324925899506\n",
      "epoch: 3 step: 374, loss is 0.11810669302940369\n",
      "epoch: 3 step: 375, loss is 0.005344930570572615\n",
      "epoch: 3 step: 376, loss is 0.11123571544885635\n",
      "epoch: 3 step: 377, loss is 0.011344624683260918\n",
      "epoch: 3 step: 378, loss is 0.03440282493829727\n",
      "epoch: 3 step: 379, loss is 0.004999586846679449\n",
      "epoch: 3 step: 380, loss is 0.09216810762882233\n",
      "epoch: 3 step: 381, loss is 0.03637326881289482\n",
      "epoch: 3 step: 382, loss is 0.05639553442597389\n",
      "epoch: 3 step: 383, loss is 0.006454749498516321\n",
      "epoch: 3 step: 384, loss is 0.015170502476394176\n",
      "epoch: 3 step: 385, loss is 0.01137781236320734\n",
      "epoch: 3 step: 386, loss is 0.021936379373073578\n",
      "epoch: 3 step: 387, loss is 0.10286947339773178\n",
      "epoch: 3 step: 388, loss is 0.008924596942961216\n",
      "epoch: 3 step: 389, loss is 0.004592812154442072\n",
      "epoch: 3 step: 390, loss is 0.07081004977226257\n",
      "epoch: 3 step: 391, loss is 0.02609032392501831\n",
      "epoch: 3 step: 392, loss is 0.08385477215051651\n",
      "epoch: 3 step: 393, loss is 0.008989492431282997\n",
      "epoch: 3 step: 394, loss is 0.26889410614967346\n",
      "epoch: 3 step: 395, loss is 0.13951517641544342\n",
      "epoch: 3 step: 396, loss is 0.007940161041915417\n",
      "epoch: 3 step: 397, loss is 0.020991716533899307\n",
      "epoch: 3 step: 398, loss is 0.03519846871495247\n",
      "epoch: 3 step: 399, loss is 0.00607305159792304\n",
      "epoch: 3 step: 400, loss is 0.1885872185230255\n",
      "epoch: 3 step: 401, loss is 0.09010300040245056\n",
      "epoch: 3 step: 402, loss is 0.018733419477939606\n",
      "epoch: 3 step: 403, loss is 0.16555334627628326\n",
      "epoch: 3 step: 404, loss is 0.03120361641049385\n",
      "epoch: 3 step: 405, loss is 0.06550092250108719\n",
      "epoch: 3 step: 406, loss is 0.010285960510373116\n",
      "epoch: 3 step: 407, loss is 0.17330488562583923\n",
      "epoch: 3 step: 408, loss is 0.006972331088036299\n",
      "epoch: 3 step: 409, loss is 0.0797775611281395\n",
      "epoch: 3 step: 410, loss is 0.2762557864189148\n",
      "epoch: 3 step: 411, loss is 0.2634974420070648\n",
      "epoch: 3 step: 412, loss is 0.0105510912835598\n",
      "epoch: 3 step: 413, loss is 0.004698319360613823\n",
      "epoch: 3 step: 414, loss is 0.12872233986854553\n",
      "epoch: 3 step: 415, loss is 0.01784548908472061\n",
      "epoch: 3 step: 416, loss is 0.003776064608246088\n",
      "epoch: 3 step: 417, loss is 0.1429150104522705\n",
      "epoch: 3 step: 418, loss is 0.17956455051898956\n",
      "epoch: 3 step: 419, loss is 0.008320825174450874\n",
      "epoch: 3 step: 420, loss is 0.005185164976865053\n",
      "epoch: 3 step: 421, loss is 0.0030517992563545704\n",
      "epoch: 3 step: 422, loss is 0.015175829641520977\n",
      "epoch: 3 step: 423, loss is 0.0355040542781353\n",
      "epoch: 3 step: 424, loss is 0.009356626309454441\n",
      "epoch: 3 step: 425, loss is 0.09864267706871033\n",
      "epoch: 3 step: 426, loss is 0.017924897372722626\n",
      "epoch: 3 step: 427, loss is 0.02048768475651741\n",
      "epoch: 3 step: 428, loss is 0.03498442843556404\n",
      "epoch: 3 step: 429, loss is 0.0039463527500629425\n",
      "epoch: 3 step: 430, loss is 0.0007359680603258312\n",
      "epoch: 3 step: 431, loss is 0.015375254675745964\n",
      "epoch: 3 step: 432, loss is 0.1846955567598343\n",
      "epoch: 3 step: 433, loss is 0.06824059784412384\n",
      "epoch: 3 step: 434, loss is 0.003487722249701619\n",
      "epoch: 3 step: 435, loss is 0.00402299128472805\n",
      "epoch: 3 step: 436, loss is 0.10052803158760071\n",
      "epoch: 3 step: 437, loss is 0.004617948085069656\n",
      "epoch: 3 step: 438, loss is 0.11731631308794022\n",
      "epoch: 3 step: 439, loss is 0.0857163518667221\n",
      "epoch: 3 step: 440, loss is 0.1896137148141861\n",
      "epoch: 3 step: 441, loss is 0.0027380564715713263\n",
      "epoch: 3 step: 442, loss is 0.024031976237893105\n",
      "epoch: 3 step: 443, loss is 0.02823183871805668\n",
      "epoch: 3 step: 444, loss is 0.005564401391893625\n",
      "epoch: 3 step: 445, loss is 0.025016941130161285\n",
      "epoch: 3 step: 446, loss is 0.006754857953637838\n",
      "epoch: 3 step: 447, loss is 0.0875050276517868\n",
      "epoch: 3 step: 448, loss is 0.1208256334066391\n",
      "epoch: 3 step: 449, loss is 0.010934379883110523\n",
      "epoch: 3 step: 450, loss is 0.015541224740445614\n",
      "epoch: 3 step: 451, loss is 0.014633161947131157\n",
      "epoch: 3 step: 452, loss is 0.17910757660865784\n",
      "epoch: 3 step: 453, loss is 0.21255405247211456\n",
      "epoch: 3 step: 454, loss is 0.09425494819879532\n",
      "epoch: 3 step: 455, loss is 0.01001583319157362\n",
      "epoch: 3 step: 456, loss is 0.0029453241731971502\n",
      "epoch: 3 step: 457, loss is 0.003734382102265954\n",
      "epoch: 3 step: 458, loss is 0.059570200741291046\n",
      "epoch: 3 step: 459, loss is 0.19759272038936615\n",
      "epoch: 3 step: 460, loss is 0.0040314700454473495\n",
      "epoch: 3 step: 461, loss is 0.09228407591581345\n",
      "epoch: 3 step: 462, loss is 0.23298139870166779\n",
      "epoch: 3 step: 463, loss is 0.025668267160654068\n",
      "epoch: 3 step: 464, loss is 0.1100332960486412\n",
      "epoch: 3 step: 465, loss is 0.05031347647309303\n",
      "epoch: 3 step: 466, loss is 0.0033057034015655518\n",
      "epoch: 3 step: 467, loss is 0.2208661139011383\n",
      "epoch: 3 step: 468, loss is 0.0015514061087742448\n",
      "epoch: 3 step: 469, loss is 0.0032312043476849794\n",
      "epoch: 3 step: 470, loss is 0.11113634705543518\n",
      "epoch: 3 step: 471, loss is 0.0010905165690928698\n",
      "epoch: 3 step: 472, loss is 0.028951767832040787\n",
      "epoch: 3 step: 473, loss is 0.005602575372904539\n",
      "epoch: 3 step: 474, loss is 0.004636611323803663\n",
      "epoch: 3 step: 475, loss is 0.16594122350215912\n",
      "epoch: 3 step: 476, loss is 0.0039208815433084965\n",
      "epoch: 3 step: 477, loss is 0.008085655979812145\n",
      "epoch: 3 step: 478, loss is 0.00027843896532431245\n",
      "epoch: 3 step: 479, loss is 0.023608196526765823\n",
      "epoch: 3 step: 480, loss is 0.020649120211601257\n",
      "epoch: 3 step: 481, loss is 0.059524934738874435\n",
      "epoch: 3 step: 482, loss is 0.04845329001545906\n",
      "epoch: 3 step: 483, loss is 0.02992783486843109\n",
      "epoch: 3 step: 484, loss is 0.2042475938796997\n",
      "epoch: 3 step: 485, loss is 0.0023558742832392454\n",
      "epoch: 3 step: 486, loss is 0.003189696464687586\n",
      "epoch: 3 step: 487, loss is 0.009331694804131985\n",
      "epoch: 3 step: 488, loss is 0.22862882912158966\n",
      "epoch: 3 step: 489, loss is 0.11641155928373337\n",
      "epoch: 3 step: 490, loss is 0.0721566304564476\n",
      "epoch: 3 step: 491, loss is 0.04845324158668518\n",
      "epoch: 3 step: 492, loss is 0.0034788688644766808\n",
      "epoch: 3 step: 493, loss is 0.001493107876740396\n",
      "epoch: 3 step: 494, loss is 0.0010517204646021128\n",
      "epoch: 3 step: 495, loss is 0.008350326679646969\n",
      "epoch: 3 step: 496, loss is 0.057914599776268005\n",
      "epoch: 3 step: 497, loss is 0.08434080332517624\n",
      "epoch: 3 step: 498, loss is 0.008692717179656029\n",
      "epoch: 3 step: 499, loss is 0.049961939454078674\n",
      "epoch: 3 step: 500, loss is 0.024375692009925842\n",
      "epoch: 3 step: 501, loss is 0.08446887880563736\n",
      "epoch: 3 step: 502, loss is 0.002328313887119293\n",
      "epoch: 3 step: 503, loss is 0.036315061151981354\n",
      "epoch: 3 step: 504, loss is 0.054787978529930115\n",
      "epoch: 3 step: 505, loss is 0.001945465337485075\n",
      "epoch: 3 step: 506, loss is 0.05876992642879486\n",
      "epoch: 3 step: 507, loss is 0.0730198323726654\n",
      "epoch: 3 step: 508, loss is 0.17096476256847382\n",
      "epoch: 3 step: 509, loss is 0.08002050966024399\n",
      "epoch: 3 step: 510, loss is 0.011344064958393574\n",
      "epoch: 3 step: 511, loss is 0.0010211467742919922\n",
      "epoch: 3 step: 512, loss is 0.029322583228349686\n",
      "epoch: 3 step: 513, loss is 0.13327957689762115\n",
      "epoch: 3 step: 514, loss is 0.011010855436325073\n",
      "epoch: 3 step: 515, loss is 0.03462453559041023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 516, loss is 0.009012204594910145\n",
      "epoch: 3 step: 517, loss is 0.01038969773799181\n",
      "epoch: 3 step: 518, loss is 0.011715967208147049\n",
      "epoch: 3 step: 519, loss is 0.01920628733932972\n",
      "epoch: 3 step: 520, loss is 0.025856876745820045\n",
      "epoch: 3 step: 521, loss is 0.0017057721270248294\n",
      "epoch: 3 step: 522, loss is 0.008466578088700771\n",
      "epoch: 3 step: 523, loss is 0.009536819532513618\n",
      "epoch: 3 step: 524, loss is 0.04925651103258133\n",
      "epoch: 3 step: 525, loss is 0.02965848706662655\n",
      "epoch: 3 step: 526, loss is 0.0019211549079045653\n",
      "epoch: 3 step: 527, loss is 0.0023947127629071474\n",
      "epoch: 3 step: 528, loss is 0.0013370707165449858\n",
      "epoch: 3 step: 529, loss is 0.09850800037384033\n",
      "epoch: 3 step: 530, loss is 0.11758535355329514\n",
      "epoch: 3 step: 531, loss is 0.000957953161559999\n",
      "epoch: 3 step: 532, loss is 0.0014157327823340893\n",
      "epoch: 3 step: 533, loss is 0.12568867206573486\n",
      "epoch: 3 step: 534, loss is 0.025652583688497543\n",
      "epoch: 3 step: 535, loss is 0.00427266675978899\n",
      "epoch: 3 step: 536, loss is 0.016015315428376198\n",
      "epoch: 3 step: 537, loss is 0.003997085150331259\n",
      "epoch: 3 step: 538, loss is 0.0059126317501068115\n",
      "epoch: 3 step: 539, loss is 0.032657332718372345\n",
      "epoch: 3 step: 540, loss is 0.0066215950064361095\n",
      "epoch: 3 step: 541, loss is 0.07431655377149582\n",
      "epoch: 3 step: 542, loss is 0.004368727561086416\n",
      "epoch: 3 step: 543, loss is 0.016849003732204437\n",
      "epoch: 3 step: 544, loss is 0.01638215035200119\n",
      "epoch: 3 step: 545, loss is 0.0084893349558115\n",
      "epoch: 3 step: 546, loss is 0.08175594359636307\n",
      "epoch: 3 step: 547, loss is 0.11083576828241348\n",
      "epoch: 3 step: 548, loss is 0.001795312506146729\n",
      "epoch: 3 step: 549, loss is 0.005213673692196608\n",
      "epoch: 3 step: 550, loss is 0.020086120814085007\n",
      "epoch: 3 step: 551, loss is 0.014525435864925385\n",
      "epoch: 3 step: 552, loss is 0.002609814051538706\n",
      "epoch: 3 step: 553, loss is 0.00048375516780652106\n",
      "epoch: 3 step: 554, loss is 0.18059705197811127\n",
      "epoch: 3 step: 555, loss is 0.014889405108988285\n",
      "epoch: 3 step: 556, loss is 0.0015580295585095882\n",
      "epoch: 3 step: 557, loss is 0.012337294407188892\n",
      "epoch: 3 step: 558, loss is 0.021772854030132294\n",
      "epoch: 3 step: 559, loss is 0.014110271818935871\n",
      "epoch: 3 step: 560, loss is 0.007364547811448574\n",
      "epoch: 3 step: 561, loss is 0.0014567816397175193\n",
      "epoch: 3 step: 562, loss is 0.07443025708198547\n",
      "epoch: 3 step: 563, loss is 0.0032406190875917673\n",
      "epoch: 3 step: 564, loss is 0.00758369080722332\n",
      "epoch: 3 step: 565, loss is 0.0038841250352561474\n",
      "epoch: 3 step: 566, loss is 0.006072225049138069\n",
      "epoch: 3 step: 567, loss is 0.054169122129678726\n",
      "epoch: 3 step: 568, loss is 0.0025757504627108574\n",
      "epoch: 3 step: 569, loss is 0.02127472124993801\n",
      "epoch: 3 step: 570, loss is 0.00030265937675721943\n",
      "epoch: 3 step: 571, loss is 0.012804058380424976\n",
      "epoch: 3 step: 572, loss is 0.0238790400326252\n",
      "epoch: 3 step: 573, loss is 0.015286436304450035\n",
      "epoch: 3 step: 574, loss is 0.08146996051073074\n",
      "epoch: 3 step: 575, loss is 0.0009069218649528921\n",
      "epoch: 3 step: 576, loss is 0.1855681985616684\n",
      "epoch: 3 step: 577, loss is 0.010682799853384495\n",
      "epoch: 3 step: 578, loss is 0.03281218558549881\n",
      "epoch: 3 step: 579, loss is 0.008876372128725052\n",
      "epoch: 3 step: 580, loss is 0.006482646334916353\n",
      "epoch: 3 step: 581, loss is 0.014468705281615257\n",
      "epoch: 3 step: 582, loss is 0.0034873117692768574\n",
      "epoch: 3 step: 583, loss is 0.00020579325791914016\n",
      "epoch: 3 step: 584, loss is 0.06860984861850739\n",
      "epoch: 3 step: 585, loss is 0.003775649704039097\n",
      "epoch: 3 step: 586, loss is 0.00045279794721864164\n",
      "epoch: 3 step: 587, loss is 0.07032491266727448\n",
      "epoch: 3 step: 588, loss is 0.002406110754236579\n",
      "epoch: 3 step: 589, loss is 0.039518143981695175\n",
      "epoch: 3 step: 590, loss is 0.005806677974760532\n",
      "epoch: 3 step: 591, loss is 0.04764242097735405\n",
      "epoch: 3 step: 592, loss is 0.0002556979306973517\n",
      "epoch: 3 step: 593, loss is 0.01260603778064251\n",
      "epoch: 3 step: 594, loss is 0.0004604448040481657\n",
      "epoch: 3 step: 595, loss is 0.0010058589978143573\n",
      "epoch: 3 step: 596, loss is 0.0017230994999408722\n",
      "epoch: 3 step: 597, loss is 0.0019410080276429653\n",
      "epoch: 3 step: 598, loss is 0.008845305070281029\n",
      "epoch: 3 step: 599, loss is 0.004496104083955288\n",
      "epoch: 3 step: 600, loss is 0.0004840581677854061\n",
      "epoch: 3 step: 601, loss is 0.0006791552295908332\n",
      "epoch: 3 step: 602, loss is 0.01951921172440052\n",
      "epoch: 3 step: 603, loss is 0.00531687680631876\n",
      "epoch: 3 step: 604, loss is 0.004475710913538933\n",
      "epoch: 3 step: 605, loss is 0.0027949060313403606\n",
      "epoch: 3 step: 606, loss is 0.005415226332843304\n",
      "epoch: 3 step: 607, loss is 0.003917992580682039\n",
      "epoch: 3 step: 608, loss is 0.02140996977686882\n",
      "epoch: 3 step: 609, loss is 0.002970632864162326\n",
      "epoch: 3 step: 610, loss is 0.12903746962547302\n",
      "epoch: 3 step: 611, loss is 0.12174224853515625\n",
      "epoch: 3 step: 612, loss is 0.0025308593176305294\n",
      "epoch: 3 step: 613, loss is 0.0009214105666615069\n",
      "epoch: 3 step: 614, loss is 0.014801849611103535\n",
      "epoch: 3 step: 615, loss is 0.1396641880273819\n",
      "epoch: 3 step: 616, loss is 0.0005970384227111936\n",
      "epoch: 3 step: 617, loss is 0.0014012341853231192\n",
      "epoch: 3 step: 618, loss is 0.03276993706822395\n",
      "epoch: 3 step: 619, loss is 0.0012060943990945816\n",
      "epoch: 3 step: 620, loss is 0.00700173806399107\n",
      "epoch: 3 step: 621, loss is 0.1447683721780777\n",
      "epoch: 3 step: 622, loss is 0.2827162742614746\n",
      "epoch: 3 step: 623, loss is 0.0026821100618690252\n",
      "epoch: 3 step: 624, loss is 0.017547395080327988\n",
      "epoch: 3 step: 625, loss is 0.0005149135831743479\n",
      "epoch: 3 step: 626, loss is 0.06236480548977852\n",
      "epoch: 3 step: 627, loss is 0.001792637980543077\n",
      "epoch: 3 step: 628, loss is 0.08301575481891632\n",
      "epoch: 3 step: 629, loss is 0.11421218514442444\n",
      "epoch: 3 step: 630, loss is 0.0034036028664559126\n",
      "epoch: 3 step: 631, loss is 0.016932092607021332\n",
      "epoch: 3 step: 632, loss is 0.004068679641932249\n",
      "epoch: 3 step: 633, loss is 0.018890876322984695\n",
      "epoch: 3 step: 634, loss is 0.0015328662702813745\n",
      "epoch: 3 step: 635, loss is 0.0019568942952901125\n",
      "epoch: 3 step: 636, loss is 0.035707440227270126\n",
      "epoch: 3 step: 637, loss is 0.026211589574813843\n",
      "epoch: 3 step: 638, loss is 0.2694537341594696\n",
      "epoch: 3 step: 639, loss is 0.003344410564750433\n",
      "epoch: 3 step: 640, loss is 0.00137798092328012\n",
      "epoch: 3 step: 641, loss is 0.0004951405571773648\n",
      "epoch: 3 step: 642, loss is 0.011709718964993954\n",
      "epoch: 3 step: 643, loss is 0.032754506915807724\n",
      "epoch: 3 step: 644, loss is 0.061397697776556015\n",
      "epoch: 3 step: 645, loss is 0.008816306479275227\n",
      "epoch: 3 step: 646, loss is 0.012944197282195091\n",
      "epoch: 3 step: 647, loss is 0.054719969630241394\n",
      "epoch: 3 step: 648, loss is 0.10171304643154144\n",
      "epoch: 3 step: 649, loss is 0.012835972011089325\n",
      "epoch: 3 step: 650, loss is 0.009121530689299107\n",
      "epoch: 3 step: 651, loss is 0.04975023493170738\n",
      "epoch: 3 step: 652, loss is 0.1358339488506317\n",
      "epoch: 3 step: 653, loss is 0.002546388888731599\n",
      "epoch: 3 step: 654, loss is 0.009583177044987679\n",
      "epoch: 3 step: 655, loss is 0.13574610650539398\n",
      "epoch: 3 step: 656, loss is 0.1345272809267044\n",
      "epoch: 3 step: 657, loss is 0.00037675275234505534\n",
      "epoch: 3 step: 658, loss is 0.07976085692644119\n",
      "epoch: 3 step: 659, loss is 0.0029148731846362352\n",
      "epoch: 3 step: 660, loss is 0.0002679760509636253\n",
      "epoch: 3 step: 661, loss is 0.016024412587285042\n",
      "epoch: 3 step: 662, loss is 0.0018811860354617238\n",
      "epoch: 3 step: 663, loss is 0.015851741656661034\n",
      "epoch: 3 step: 664, loss is 0.02297220192849636\n",
      "epoch: 3 step: 665, loss is 0.00042921287240460515\n",
      "epoch: 3 step: 666, loss is 0.0011925660073757172\n",
      "epoch: 3 step: 667, loss is 0.0014374149031937122\n",
      "epoch: 3 step: 668, loss is 0.03660115227103233\n",
      "epoch: 3 step: 669, loss is 0.004342543892562389\n",
      "epoch: 3 step: 670, loss is 0.09897569566965103\n",
      "epoch: 3 step: 671, loss is 0.002236712258309126\n",
      "epoch: 3 step: 672, loss is 0.012461707927286625\n",
      "epoch: 3 step: 673, loss is 0.02725691720843315\n",
      "epoch: 3 step: 674, loss is 0.08778475224971771\n",
      "epoch: 3 step: 675, loss is 0.014099320396780968\n",
      "epoch: 3 step: 676, loss is 0.020668717101216316\n",
      "epoch: 3 step: 677, loss is 0.032795604318380356\n",
      "epoch: 3 step: 678, loss is 9.633001172915101e-05\n",
      "epoch: 3 step: 679, loss is 0.0011694446438923478\n",
      "epoch: 3 step: 680, loss is 0.11417803913354874\n",
      "epoch: 3 step: 681, loss is 0.07009277492761612\n",
      "epoch: 3 step: 682, loss is 0.00391834182664752\n",
      "epoch: 3 step: 683, loss is 0.07931995391845703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 684, loss is 0.0062553780153393745\n",
      "epoch: 3 step: 685, loss is 0.0008296677260659635\n",
      "epoch: 3 step: 686, loss is 0.024545729160308838\n",
      "epoch: 3 step: 687, loss is 0.0025316497776657343\n",
      "epoch: 3 step: 688, loss is 0.0033433788921684027\n",
      "epoch: 3 step: 689, loss is 0.004019691608846188\n",
      "epoch: 3 step: 690, loss is 0.005183997564017773\n",
      "epoch: 3 step: 691, loss is 0.007882744073867798\n",
      "epoch: 3 step: 692, loss is 0.006187887396663427\n",
      "epoch: 3 step: 693, loss is 0.03280484676361084\n",
      "epoch: 3 step: 694, loss is 0.01440050732344389\n",
      "epoch: 3 step: 695, loss is 0.010464716702699661\n",
      "epoch: 3 step: 696, loss is 0.002682673977687955\n",
      "epoch: 3 step: 697, loss is 0.00034852998214773834\n",
      "epoch: 3 step: 698, loss is 0.10411237925291061\n",
      "epoch: 3 step: 699, loss is 0.021469855681061745\n",
      "epoch: 3 step: 700, loss is 0.18404562771320343\n",
      "epoch: 3 step: 701, loss is 0.32064247131347656\n",
      "epoch: 3 step: 702, loss is 0.09009431302547455\n",
      "epoch: 3 step: 703, loss is 0.049839701503515244\n",
      "epoch: 3 step: 704, loss is 0.12617714703083038\n",
      "epoch: 3 step: 705, loss is 0.004958577919751406\n",
      "epoch: 3 step: 706, loss is 0.00026789912953972816\n",
      "epoch: 3 step: 707, loss is 0.00035173536161892116\n",
      "epoch: 3 step: 708, loss is 0.0064764972776174545\n",
      "epoch: 3 step: 709, loss is 0.000875753175932914\n",
      "epoch: 3 step: 710, loss is 0.007602545898407698\n",
      "epoch: 3 step: 711, loss is 0.030658932402729988\n",
      "epoch: 3 step: 712, loss is 0.015152514912188053\n",
      "epoch: 3 step: 713, loss is 0.004193642642349005\n",
      "epoch: 3 step: 714, loss is 0.13421426713466644\n",
      "epoch: 3 step: 715, loss is 0.011543232016265392\n",
      "epoch: 3 step: 716, loss is 0.016679832711815834\n",
      "epoch: 3 step: 717, loss is 0.1605563759803772\n",
      "epoch: 3 step: 718, loss is 0.01628420129418373\n",
      "epoch: 3 step: 719, loss is 0.0438389889895916\n",
      "epoch: 3 step: 720, loss is 0.08792910724878311\n",
      "epoch: 3 step: 721, loss is 0.008463725447654724\n",
      "epoch: 3 step: 722, loss is 0.0017853061435744166\n",
      "epoch: 3 step: 723, loss is 0.09956839680671692\n",
      "epoch: 3 step: 724, loss is 0.10872237384319305\n",
      "epoch: 3 step: 725, loss is 0.001314629684202373\n",
      "epoch: 3 step: 726, loss is 0.021090272814035416\n",
      "epoch: 3 step: 727, loss is 0.025362102314829826\n",
      "epoch: 3 step: 728, loss is 0.057586099952459335\n",
      "epoch: 3 step: 729, loss is 0.049921829253435135\n",
      "epoch: 3 step: 730, loss is 0.022581974044442177\n",
      "epoch: 3 step: 731, loss is 0.11230628192424774\n",
      "epoch: 3 step: 732, loss is 0.2349063605070114\n",
      "epoch: 3 step: 733, loss is 0.023469284176826477\n",
      "epoch: 3 step: 734, loss is 0.0211404450237751\n",
      "epoch: 3 step: 735, loss is 0.011454911902546883\n",
      "epoch: 3 step: 736, loss is 0.06803186237812042\n",
      "epoch: 3 step: 737, loss is 0.04913425073027611\n",
      "epoch: 3 step: 738, loss is 0.23091885447502136\n",
      "epoch: 3 step: 739, loss is 0.0017017618520185351\n",
      "epoch: 3 step: 740, loss is 0.04763108491897583\n",
      "epoch: 3 step: 741, loss is 0.03162724897265434\n",
      "epoch: 3 step: 742, loss is 0.024758819490671158\n",
      "epoch: 3 step: 743, loss is 0.1825455278158188\n",
      "epoch: 3 step: 744, loss is 0.04231630265712738\n",
      "epoch: 3 step: 745, loss is 0.020076630637049675\n",
      "epoch: 3 step: 746, loss is 0.000139079726068303\n",
      "epoch: 3 step: 747, loss is 0.004438851960003376\n",
      "epoch: 3 step: 748, loss is 0.06346782296895981\n",
      "epoch: 3 step: 749, loss is 0.005962439812719822\n",
      "epoch: 3 step: 750, loss is 0.06319437175989151\n",
      "epoch: 3 step: 751, loss is 0.02801654301583767\n",
      "epoch: 3 step: 752, loss is 0.11018253117799759\n",
      "epoch: 3 step: 753, loss is 0.11317358911037445\n",
      "epoch: 3 step: 754, loss is 0.1365688145160675\n",
      "epoch: 3 step: 755, loss is 0.17578597366809845\n",
      "epoch: 3 step: 756, loss is 0.054806552827358246\n",
      "epoch: 3 step: 757, loss is 0.045140210539102554\n",
      "epoch: 3 step: 758, loss is 0.09551138430833817\n",
      "epoch: 3 step: 759, loss is 0.04564131423830986\n",
      "epoch: 3 step: 760, loss is 0.0038776923902332783\n",
      "epoch: 3 step: 761, loss is 0.07376151531934738\n",
      "epoch: 3 step: 762, loss is 0.003865043865516782\n",
      "epoch: 3 step: 763, loss is 0.06148931384086609\n",
      "epoch: 3 step: 764, loss is 0.10602512210607529\n",
      "epoch: 3 step: 765, loss is 0.06469230353832245\n",
      "epoch: 3 step: 766, loss is 0.0035057724453508854\n",
      "epoch: 3 step: 767, loss is 0.010167059488594532\n",
      "epoch: 3 step: 768, loss is 0.0549018494784832\n",
      "epoch: 3 step: 769, loss is 0.15657617151737213\n",
      "epoch: 3 step: 770, loss is 0.006021581590175629\n",
      "epoch: 3 step: 771, loss is 0.01620054803788662\n",
      "epoch: 3 step: 772, loss is 0.053812142461538315\n",
      "epoch: 3 step: 773, loss is 0.007925589568912983\n",
      "epoch: 3 step: 774, loss is 0.002778675640001893\n",
      "epoch: 3 step: 775, loss is 0.1440197229385376\n",
      "epoch: 3 step: 776, loss is 0.005925740581005812\n",
      "epoch: 3 step: 777, loss is 0.0010881656780838966\n",
      "epoch: 3 step: 778, loss is 0.07747413963079453\n",
      "epoch: 3 step: 779, loss is 0.05789104104042053\n",
      "epoch: 3 step: 780, loss is 0.00834419671446085\n",
      "epoch: 3 step: 781, loss is 0.0010240781120955944\n",
      "epoch: 3 step: 782, loss is 0.016764961183071136\n",
      "epoch: 3 step: 783, loss is 0.12387533485889435\n",
      "epoch: 3 step: 784, loss is 0.0036256888415664434\n",
      "epoch: 3 step: 785, loss is 0.03521187976002693\n",
      "epoch: 3 step: 786, loss is 0.09998679906129837\n",
      "epoch: 3 step: 787, loss is 0.02338925376534462\n",
      "epoch: 3 step: 788, loss is 0.010364037938416004\n",
      "epoch: 3 step: 789, loss is 0.12334581464529037\n",
      "epoch: 3 step: 790, loss is 0.024030623957514763\n",
      "epoch: 3 step: 791, loss is 0.05624045059084892\n",
      "epoch: 3 step: 792, loss is 0.07903515547513962\n",
      "epoch: 3 step: 793, loss is 0.016461392864584923\n",
      "epoch: 3 step: 794, loss is 0.008093515411019325\n",
      "epoch: 3 step: 795, loss is 0.04251720383763313\n",
      "epoch: 3 step: 796, loss is 0.004150316584855318\n",
      "epoch: 3 step: 797, loss is 0.033227261155843735\n",
      "epoch: 3 step: 798, loss is 0.052796620875597\n",
      "epoch: 3 step: 799, loss is 0.006482732482254505\n",
      "epoch: 3 step: 800, loss is 0.0012021261500194669\n",
      "epoch: 3 step: 801, loss is 0.004157065413892269\n",
      "epoch: 3 step: 802, loss is 0.26733076572418213\n",
      "epoch: 3 step: 803, loss is 0.07667092978954315\n",
      "epoch: 3 step: 804, loss is 0.061805013567209244\n",
      "epoch: 3 step: 805, loss is 0.01836276426911354\n",
      "epoch: 3 step: 806, loss is 0.018380723893642426\n",
      "epoch: 3 step: 807, loss is 0.001095016486942768\n",
      "epoch: 3 step: 808, loss is 0.012839563190937042\n",
      "epoch: 3 step: 809, loss is 0.03097766451537609\n",
      "epoch: 3 step: 810, loss is 0.01205037347972393\n",
      "epoch: 3 step: 811, loss is 0.0014373705489560962\n",
      "epoch: 3 step: 812, loss is 0.06830526888370514\n",
      "epoch: 3 step: 813, loss is 0.005231463350355625\n",
      "epoch: 3 step: 814, loss is 0.15106528997421265\n",
      "epoch: 3 step: 815, loss is 0.0021739588119089603\n",
      "epoch: 3 step: 816, loss is 0.006830557249486446\n",
      "epoch: 3 step: 817, loss is 0.28455716371536255\n",
      "epoch: 3 step: 818, loss is 0.013059940189123154\n",
      "epoch: 3 step: 819, loss is 0.0799427181482315\n",
      "epoch: 3 step: 820, loss is 0.010740314610302448\n",
      "epoch: 3 step: 821, loss is 0.054759640246629715\n",
      "epoch: 3 step: 822, loss is 0.010401872918009758\n",
      "epoch: 3 step: 823, loss is 0.016896327957510948\n",
      "epoch: 3 step: 824, loss is 0.0036731993313878775\n",
      "epoch: 3 step: 825, loss is 0.007789183408021927\n",
      "epoch: 3 step: 826, loss is 0.0027255117893218994\n",
      "epoch: 3 step: 827, loss is 0.0003068885998800397\n",
      "epoch: 3 step: 828, loss is 0.0038342252373695374\n",
      "epoch: 3 step: 829, loss is 0.09848909825086594\n",
      "epoch: 3 step: 830, loss is 0.15217477083206177\n",
      "epoch: 3 step: 831, loss is 0.006202214863151312\n",
      "epoch: 3 step: 832, loss is 0.014171932823956013\n",
      "epoch: 3 step: 833, loss is 0.013621816411614418\n",
      "epoch: 3 step: 834, loss is 0.05929131805896759\n",
      "epoch: 3 step: 835, loss is 0.04071883484721184\n",
      "epoch: 3 step: 836, loss is 0.10165653377771378\n",
      "epoch: 3 step: 837, loss is 0.11416700482368469\n",
      "epoch: 3 step: 838, loss is 0.08031307905912399\n",
      "epoch: 3 step: 839, loss is 0.009936087764799595\n",
      "epoch: 3 step: 840, loss is 0.010008145123720169\n",
      "epoch: 3 step: 841, loss is 0.13941438496112823\n",
      "epoch: 3 step: 842, loss is 0.011302564293146133\n",
      "epoch: 3 step: 843, loss is 0.010092658922076225\n",
      "epoch: 3 step: 844, loss is 0.0004772419633809477\n",
      "epoch: 3 step: 845, loss is 0.000949005305301398\n",
      "epoch: 3 step: 846, loss is 0.0050895302556455135\n",
      "epoch: 3 step: 847, loss is 0.03723062202334404\n",
      "epoch: 3 step: 848, loss is 0.02321224845945835\n",
      "epoch: 3 step: 849, loss is 0.0024031605571508408\n",
      "epoch: 3 step: 850, loss is 0.002597016980871558\n",
      "epoch: 3 step: 851, loss is 0.09555625915527344\n",
      "epoch: 3 step: 852, loss is 0.00832296721637249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 853, loss is 0.037725236266851425\n",
      "epoch: 3 step: 854, loss is 0.0083583053201437\n",
      "epoch: 3 step: 855, loss is 0.00995537731796503\n",
      "epoch: 3 step: 856, loss is 0.15349918603897095\n",
      "epoch: 3 step: 857, loss is 0.03812322020530701\n",
      "epoch: 3 step: 858, loss is 0.06575299799442291\n",
      "epoch: 3 step: 859, loss is 0.010337981395423412\n",
      "epoch: 3 step: 860, loss is 0.18081840872764587\n",
      "epoch: 3 step: 861, loss is 0.027174079790711403\n",
      "epoch: 3 step: 862, loss is 0.006381211802363396\n",
      "epoch: 3 step: 863, loss is 0.04423931986093521\n",
      "epoch: 3 step: 864, loss is 0.03765300661325455\n",
      "epoch: 3 step: 865, loss is 0.001320294919423759\n",
      "epoch: 3 step: 866, loss is 0.07551030069589615\n",
      "epoch: 3 step: 867, loss is 0.029772166162729263\n",
      "epoch: 3 step: 868, loss is 0.058538634330034256\n",
      "epoch: 3 step: 869, loss is 0.012069160118699074\n",
      "epoch: 3 step: 870, loss is 0.17873333394527435\n",
      "epoch: 3 step: 871, loss is 0.04197843372821808\n",
      "epoch: 3 step: 872, loss is 0.10413806140422821\n",
      "epoch: 3 step: 873, loss is 0.003309021471068263\n",
      "epoch: 3 step: 874, loss is 0.17282642424106598\n",
      "epoch: 3 step: 875, loss is 0.011738101951777935\n",
      "epoch: 3 step: 876, loss is 0.009613066911697388\n",
      "epoch: 3 step: 877, loss is 0.006202045828104019\n",
      "epoch: 3 step: 878, loss is 0.005784796550869942\n",
      "epoch: 3 step: 879, loss is 0.0008319119224324822\n",
      "epoch: 3 step: 880, loss is 0.06902530044317245\n",
      "epoch: 3 step: 881, loss is 0.002209792146459222\n",
      "epoch: 3 step: 882, loss is 0.009295900352299213\n",
      "epoch: 3 step: 883, loss is 0.009921329095959663\n",
      "epoch: 3 step: 884, loss is 0.07699357718229294\n",
      "epoch: 3 step: 885, loss is 0.09089038521051407\n",
      "epoch: 3 step: 886, loss is 0.06583812832832336\n",
      "epoch: 3 step: 887, loss is 0.10074778646230698\n",
      "epoch: 3 step: 888, loss is 0.03150331601500511\n",
      "epoch: 3 step: 889, loss is 0.04923591762781143\n",
      "epoch: 3 step: 890, loss is 0.0015961090102791786\n",
      "epoch: 3 step: 891, loss is 0.11939624696969986\n",
      "epoch: 3 step: 892, loss is 0.00038839629269205034\n",
      "epoch: 3 step: 893, loss is 0.018677065148949623\n",
      "epoch: 3 step: 894, loss is 0.041230835020542145\n",
      "epoch: 3 step: 895, loss is 0.06304414570331573\n",
      "epoch: 3 step: 896, loss is 0.0019092331640422344\n",
      "epoch: 3 step: 897, loss is 0.08584293723106384\n",
      "epoch: 3 step: 898, loss is 0.00551501102745533\n",
      "epoch: 3 step: 899, loss is 0.0009496085112914443\n",
      "epoch: 3 step: 900, loss is 0.16048043966293335\n",
      "epoch: 3 step: 901, loss is 0.14557881653308868\n",
      "epoch: 3 step: 902, loss is 0.0006561446934938431\n",
      "epoch: 3 step: 903, loss is 0.1605716347694397\n",
      "epoch: 3 step: 904, loss is 0.174264594912529\n",
      "epoch: 3 step: 905, loss is 0.02025965228676796\n",
      "epoch: 3 step: 906, loss is 0.021457510069012642\n",
      "epoch: 3 step: 907, loss is 0.03454659506678581\n",
      "epoch: 3 step: 908, loss is 0.003497292986139655\n",
      "epoch: 3 step: 909, loss is 0.1977529525756836\n",
      "epoch: 3 step: 910, loss is 0.004851494450122118\n",
      "epoch: 3 step: 911, loss is 0.04475382715463638\n",
      "epoch: 3 step: 912, loss is 0.0968896746635437\n",
      "epoch: 3 step: 913, loss is 0.1737501472234726\n",
      "epoch: 3 step: 914, loss is 0.12786749005317688\n",
      "epoch: 3 step: 915, loss is 0.07160069048404694\n",
      "epoch: 3 step: 916, loss is 0.0014550620689988136\n",
      "epoch: 3 step: 917, loss is 0.05573273450136185\n",
      "epoch: 3 step: 918, loss is 0.0033551764208823442\n",
      "epoch: 3 step: 919, loss is 0.017581287771463394\n",
      "epoch: 3 step: 920, loss is 0.004972997587174177\n",
      "epoch: 3 step: 921, loss is 0.005901598371565342\n",
      "epoch: 3 step: 922, loss is 0.012794449925422668\n",
      "epoch: 3 step: 923, loss is 0.008887803182005882\n",
      "epoch: 3 step: 924, loss is 0.038102682679891586\n",
      "epoch: 3 step: 925, loss is 0.2900601625442505\n",
      "epoch: 3 step: 926, loss is 0.0018983694026246667\n",
      "epoch: 3 step: 927, loss is 0.10037362575531006\n",
      "epoch: 3 step: 928, loss is 0.00357440416701138\n",
      "epoch: 3 step: 929, loss is 0.022159438580274582\n",
      "epoch: 3 step: 930, loss is 0.08559821546077728\n",
      "epoch: 3 step: 931, loss is 0.035426873713731766\n",
      "epoch: 3 step: 932, loss is 0.030032653361558914\n",
      "epoch: 3 step: 933, loss is 0.004087618552148342\n",
      "epoch: 3 step: 934, loss is 0.001214833464473486\n",
      "epoch: 3 step: 935, loss is 0.01569417491555214\n",
      "epoch: 3 step: 936, loss is 0.2279815524816513\n",
      "epoch: 3 step: 937, loss is 0.00416033947840333\n",
      "epoch: 3 step: 938, loss is 0.023578621447086334\n",
      "epoch: 3 step: 939, loss is 0.015645956620573997\n",
      "epoch: 3 step: 940, loss is 0.02433294989168644\n",
      "epoch: 3 step: 941, loss is 0.0021488263737410307\n",
      "epoch: 3 step: 942, loss is 0.0039047389291226864\n",
      "epoch: 3 step: 943, loss is 0.020171305164694786\n",
      "epoch: 3 step: 944, loss is 0.009286205284297466\n",
      "epoch: 3 step: 945, loss is 0.008084379136562347\n",
      "epoch: 3 step: 946, loss is 0.17962022125720978\n",
      "epoch: 3 step: 947, loss is 0.003985942341387272\n",
      "epoch: 3 step: 948, loss is 0.0035020383074879646\n",
      "epoch: 3 step: 949, loss is 0.051386911422014236\n",
      "epoch: 3 step: 950, loss is 0.013554323464632034\n",
      "epoch: 3 step: 951, loss is 0.011101731099188328\n",
      "epoch: 3 step: 952, loss is 0.006497987546026707\n",
      "epoch: 3 step: 953, loss is 0.003805864602327347\n",
      "epoch: 3 step: 954, loss is 0.004425970371812582\n",
      "epoch: 3 step: 955, loss is 0.026051681488752365\n",
      "epoch: 3 step: 956, loss is 0.05032036826014519\n",
      "epoch: 3 step: 957, loss is 0.012004554271697998\n",
      "epoch: 3 step: 958, loss is 0.01093983743339777\n",
      "epoch: 3 step: 959, loss is 0.0705045759677887\n",
      "epoch: 3 step: 960, loss is 0.10757660865783691\n",
      "epoch: 3 step: 961, loss is 0.06432903558015823\n",
      "epoch: 3 step: 962, loss is 0.0013374679256230593\n",
      "epoch: 3 step: 963, loss is 0.0030810267198830843\n",
      "epoch: 3 step: 964, loss is 0.02470364235341549\n",
      "epoch: 3 step: 965, loss is 0.04992881044745445\n",
      "epoch: 3 step: 966, loss is 0.10970872640609741\n",
      "epoch: 3 step: 967, loss is 0.07340388745069504\n",
      "epoch: 3 step: 968, loss is 0.05606634169816971\n",
      "epoch: 3 step: 969, loss is 0.005951036233454943\n",
      "epoch: 3 step: 970, loss is 0.07473296672105789\n",
      "epoch: 3 step: 971, loss is 0.0014524292200803757\n",
      "epoch: 3 step: 972, loss is 0.005066392477601767\n",
      "epoch: 3 step: 973, loss is 0.01550841424614191\n",
      "epoch: 3 step: 974, loss is 0.013799288310110569\n",
      "epoch: 3 step: 975, loss is 0.002130956621840596\n",
      "epoch: 3 step: 976, loss is 0.0013246072921901941\n",
      "epoch: 3 step: 977, loss is 0.02716323360800743\n",
      "epoch: 3 step: 978, loss is 0.00018436207028571516\n",
      "epoch: 3 step: 979, loss is 0.03740676864981651\n",
      "epoch: 3 step: 980, loss is 0.04360686242580414\n",
      "epoch: 3 step: 981, loss is 0.002487449673935771\n",
      "epoch: 3 step: 982, loss is 0.005059913266450167\n",
      "epoch: 3 step: 983, loss is 0.023701781406998634\n",
      "epoch: 3 step: 984, loss is 0.08498424291610718\n",
      "epoch: 3 step: 985, loss is 0.0009092259570024908\n",
      "epoch: 3 step: 986, loss is 0.022601941600441933\n",
      "epoch: 3 step: 987, loss is 0.03493055701255798\n",
      "epoch: 3 step: 988, loss is 0.0019977728370577097\n",
      "epoch: 3 step: 989, loss is 0.0021016693208366632\n",
      "epoch: 3 step: 990, loss is 0.005603634752333164\n",
      "epoch: 3 step: 991, loss is 0.0022288078907877207\n",
      "epoch: 3 step: 992, loss is 0.004211218561977148\n",
      "epoch: 3 step: 993, loss is 0.006368786562234163\n",
      "epoch: 3 step: 994, loss is 0.07865588366985321\n",
      "epoch: 3 step: 995, loss is 0.05279541015625\n",
      "epoch: 3 step: 996, loss is 0.008656480349600315\n",
      "epoch: 3 step: 997, loss is 0.036723196506500244\n",
      "epoch: 3 step: 998, loss is 0.002702312543988228\n",
      "epoch: 3 step: 999, loss is 0.0632866621017456\n",
      "epoch: 3 step: 1000, loss is 0.15762868523597717\n",
      "epoch: 3 step: 1001, loss is 0.029652385041117668\n",
      "epoch: 3 step: 1002, loss is 0.04698282852768898\n",
      "epoch: 3 step: 1003, loss is 0.0008635006379336119\n",
      "epoch: 3 step: 1004, loss is 0.0003224709362257272\n",
      "epoch: 3 step: 1005, loss is 0.0190324354916811\n",
      "epoch: 3 step: 1006, loss is 0.0023468334693461657\n",
      "epoch: 3 step: 1007, loss is 0.11399489641189575\n",
      "epoch: 3 step: 1008, loss is 0.03849337249994278\n",
      "epoch: 3 step: 1009, loss is 0.05904100462794304\n",
      "epoch: 3 step: 1010, loss is 0.034600671380758286\n",
      "epoch: 3 step: 1011, loss is 0.19941766560077667\n",
      "epoch: 3 step: 1012, loss is 0.003991270903497934\n",
      "epoch: 3 step: 1013, loss is 0.0333307683467865\n",
      "epoch: 3 step: 1014, loss is 0.0014849876752123237\n",
      "epoch: 3 step: 1015, loss is 0.0005772418226115406\n",
      "epoch: 3 step: 1016, loss is 0.00045027208398096263\n",
      "epoch: 3 step: 1017, loss is 0.06972488015890121\n",
      "epoch: 3 step: 1018, loss is 0.01065721083432436\n",
      "epoch: 3 step: 1019, loss is 0.032383281737565994\n",
      "epoch: 3 step: 1020, loss is 0.11954302340745926\n",
      "epoch: 3 step: 1021, loss is 0.0044525014236569405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1022, loss is 0.021007653325796127\n",
      "epoch: 3 step: 1023, loss is 0.0908132940530777\n",
      "epoch: 3 step: 1024, loss is 0.0061357757076621056\n",
      "epoch: 3 step: 1025, loss is 0.14178109169006348\n",
      "epoch: 3 step: 1026, loss is 0.07802054286003113\n",
      "epoch: 3 step: 1027, loss is 0.02298269420862198\n",
      "epoch: 3 step: 1028, loss is 0.0913018211722374\n",
      "epoch: 3 step: 1029, loss is 0.0054339515045285225\n",
      "epoch: 3 step: 1030, loss is 0.0006179005140438676\n",
      "epoch: 3 step: 1031, loss is 0.021559130400419235\n",
      "epoch: 3 step: 1032, loss is 0.00031708282767795026\n",
      "epoch: 3 step: 1033, loss is 0.020025478675961494\n",
      "epoch: 3 step: 1034, loss is 0.041118960827589035\n",
      "epoch: 3 step: 1035, loss is 0.000986415077932179\n",
      "epoch: 3 step: 1036, loss is 0.1777959167957306\n",
      "epoch: 3 step: 1037, loss is 0.0004770101513713598\n",
      "epoch: 3 step: 1038, loss is 0.022588100284337997\n",
      "epoch: 3 step: 1039, loss is 0.00019769376376643777\n",
      "epoch: 3 step: 1040, loss is 0.001766496803611517\n",
      "epoch: 3 step: 1041, loss is 0.02099352329969406\n",
      "epoch: 3 step: 1042, loss is 0.004418179392814636\n",
      "epoch: 3 step: 1043, loss is 0.002369802910834551\n",
      "epoch: 3 step: 1044, loss is 0.002520656678825617\n",
      "epoch: 3 step: 1045, loss is 0.0005123352748341858\n",
      "epoch: 3 step: 1046, loss is 0.0177850890904665\n",
      "epoch: 3 step: 1047, loss is 0.018346747383475304\n",
      "epoch: 3 step: 1048, loss is 0.00043651042506098747\n",
      "epoch: 3 step: 1049, loss is 0.04551861435174942\n",
      "epoch: 3 step: 1050, loss is 0.010160742327570915\n",
      "epoch: 3 step: 1051, loss is 0.0008108032052405179\n",
      "epoch: 3 step: 1052, loss is 0.017334138974547386\n",
      "epoch: 3 step: 1053, loss is 0.008563423529267311\n",
      "epoch: 3 step: 1054, loss is 0.18167047202587128\n",
      "epoch: 3 step: 1055, loss is 0.002507499884814024\n",
      "epoch: 3 step: 1056, loss is 0.0023648180067539215\n",
      "epoch: 3 step: 1057, loss is 0.004626750014722347\n",
      "epoch: 3 step: 1058, loss is 0.0028893619310110807\n",
      "epoch: 3 step: 1059, loss is 0.0021376393269747496\n",
      "epoch: 3 step: 1060, loss is 0.031604569405317307\n",
      "epoch: 3 step: 1061, loss is 0.03876470774412155\n",
      "epoch: 3 step: 1062, loss is 0.17761489748954773\n",
      "epoch: 3 step: 1063, loss is 0.02020588144659996\n",
      "epoch: 3 step: 1064, loss is 0.016209814697504044\n",
      "epoch: 3 step: 1065, loss is 0.00015668068954255432\n",
      "epoch: 3 step: 1066, loss is 0.12348471581935883\n",
      "epoch: 3 step: 1067, loss is 0.06600339710712433\n",
      "epoch: 3 step: 1068, loss is 0.054206911474466324\n",
      "epoch: 3 step: 1069, loss is 0.000981460209004581\n",
      "epoch: 3 step: 1070, loss is 0.019114000722765923\n",
      "epoch: 3 step: 1071, loss is 0.06501438468694687\n",
      "epoch: 3 step: 1072, loss is 0.15295183658599854\n",
      "epoch: 3 step: 1073, loss is 0.04269896820187569\n",
      "epoch: 3 step: 1074, loss is 0.061264265328645706\n",
      "epoch: 3 step: 1075, loss is 0.000370197172742337\n",
      "epoch: 3 step: 1076, loss is 0.010916467756032944\n",
      "epoch: 3 step: 1077, loss is 0.034320492297410965\n",
      "epoch: 3 step: 1078, loss is 0.11474683880805969\n",
      "epoch: 3 step: 1079, loss is 0.003596697933971882\n",
      "epoch: 3 step: 1080, loss is 0.0019568109419196844\n",
      "epoch: 3 step: 1081, loss is 0.031220072880387306\n",
      "epoch: 3 step: 1082, loss is 0.12302063405513763\n",
      "epoch: 3 step: 1083, loss is 0.08222122490406036\n",
      "epoch: 3 step: 1084, loss is 0.0007357000722549856\n",
      "epoch: 3 step: 1085, loss is 0.0031027894001454115\n",
      "epoch: 3 step: 1086, loss is 0.016527779400348663\n",
      "epoch: 3 step: 1087, loss is 0.016581568866968155\n",
      "epoch: 3 step: 1088, loss is 0.12602588534355164\n",
      "epoch: 3 step: 1089, loss is 0.0037757272366434336\n",
      "epoch: 3 step: 1090, loss is 0.013928242027759552\n",
      "epoch: 3 step: 1091, loss is 0.04810493439435959\n",
      "epoch: 3 step: 1092, loss is 0.0010638561798259616\n",
      "epoch: 3 step: 1093, loss is 0.00044314496335573494\n",
      "epoch: 3 step: 1094, loss is 0.0019493467407301068\n",
      "epoch: 3 step: 1095, loss is 0.0020427850540727377\n",
      "epoch: 3 step: 1096, loss is 0.000776156724896282\n",
      "epoch: 3 step: 1097, loss is 0.002229266334325075\n",
      "epoch: 3 step: 1098, loss is 0.07311145216226578\n",
      "epoch: 3 step: 1099, loss is 0.10648141801357269\n",
      "epoch: 3 step: 1100, loss is 0.0025405671913176775\n",
      "epoch: 3 step: 1101, loss is 0.0013341150479391217\n",
      "epoch: 3 step: 1102, loss is 0.00794654805213213\n",
      "epoch: 3 step: 1103, loss is 0.019034279510378838\n",
      "epoch: 3 step: 1104, loss is 0.0011993983061984181\n",
      "epoch: 3 step: 1105, loss is 0.012760505080223083\n",
      "epoch: 3 step: 1106, loss is 0.007061452139168978\n",
      "epoch: 3 step: 1107, loss is 0.006791921332478523\n",
      "epoch: 3 step: 1108, loss is 0.1830720156431198\n",
      "epoch: 3 step: 1109, loss is 0.0013716520043089986\n",
      "epoch: 3 step: 1110, loss is 0.09814778715372086\n",
      "epoch: 3 step: 1111, loss is 0.07438929378986359\n",
      "epoch: 3 step: 1112, loss is 0.003959896508604288\n",
      "epoch: 3 step: 1113, loss is 0.02644617110490799\n",
      "epoch: 3 step: 1114, loss is 0.03061569668352604\n",
      "epoch: 3 step: 1115, loss is 0.27462705969810486\n",
      "epoch: 3 step: 1116, loss is 0.016806481406092644\n",
      "epoch: 3 step: 1117, loss is 0.011793247424066067\n",
      "epoch: 3 step: 1118, loss is 0.009080516174435616\n",
      "epoch: 3 step: 1119, loss is 0.0009806986199691892\n",
      "epoch: 3 step: 1120, loss is 0.0018626756500452757\n",
      "epoch: 3 step: 1121, loss is 0.025736432522535324\n",
      "epoch: 3 step: 1122, loss is 0.08128340542316437\n",
      "epoch: 3 step: 1123, loss is 0.007771298289299011\n",
      "epoch: 3 step: 1124, loss is 0.007304659113287926\n",
      "epoch: 3 step: 1125, loss is 0.01850784569978714\n",
      "epoch: 3 step: 1126, loss is 0.0214002076536417\n",
      "epoch: 3 step: 1127, loss is 0.004960107617080212\n",
      "epoch: 3 step: 1128, loss is 0.0027020012494176626\n",
      "epoch: 3 step: 1129, loss is 0.009352616965770721\n",
      "epoch: 3 step: 1130, loss is 0.0033472105860710144\n",
      "epoch: 3 step: 1131, loss is 0.055500589311122894\n",
      "epoch: 3 step: 1132, loss is 0.022997183725237846\n",
      "epoch: 3 step: 1133, loss is 0.004553587641566992\n",
      "epoch: 3 step: 1134, loss is 0.09964058548212051\n",
      "epoch: 3 step: 1135, loss is 0.2447056770324707\n",
      "epoch: 3 step: 1136, loss is 0.016648270189762115\n",
      "epoch: 3 step: 1137, loss is 0.0023768788669258356\n",
      "epoch: 3 step: 1138, loss is 0.0036380805540829897\n",
      "epoch: 3 step: 1139, loss is 0.009458096697926521\n",
      "epoch: 3 step: 1140, loss is 0.0074883936904370785\n",
      "epoch: 3 step: 1141, loss is 0.043781690299510956\n",
      "epoch: 3 step: 1142, loss is 0.03683757036924362\n",
      "epoch: 3 step: 1143, loss is 0.005097218789160252\n",
      "epoch: 3 step: 1144, loss is 0.006765054538846016\n",
      "epoch: 3 step: 1145, loss is 0.05276472121477127\n",
      "epoch: 3 step: 1146, loss is 0.17020615935325623\n",
      "epoch: 3 step: 1147, loss is 0.0026072231121361256\n",
      "epoch: 3 step: 1148, loss is 0.0013271807692945004\n",
      "epoch: 3 step: 1149, loss is 0.07922132313251495\n",
      "epoch: 3 step: 1150, loss is 0.1881117969751358\n",
      "epoch: 3 step: 1151, loss is 0.17388659715652466\n",
      "epoch: 3 step: 1152, loss is 0.01984037645161152\n",
      "epoch: 3 step: 1153, loss is 0.005423954222351313\n",
      "epoch: 3 step: 1154, loss is 0.012746206484735012\n",
      "epoch: 3 step: 1155, loss is 0.015118297189474106\n",
      "epoch: 3 step: 1156, loss is 0.08166272193193436\n",
      "epoch: 3 step: 1157, loss is 0.03366689383983612\n",
      "epoch: 3 step: 1158, loss is 0.0011582679580897093\n",
      "epoch: 3 step: 1159, loss is 0.08456294983625412\n",
      "epoch: 3 step: 1160, loss is 0.04727397486567497\n",
      "epoch: 3 step: 1161, loss is 0.09578222036361694\n",
      "epoch: 3 step: 1162, loss is 0.13486507534980774\n",
      "epoch: 3 step: 1163, loss is 0.002091066911816597\n",
      "epoch: 3 step: 1164, loss is 0.1197463646531105\n",
      "epoch: 3 step: 1165, loss is 0.002468396443873644\n",
      "epoch: 3 step: 1166, loss is 0.06156863644719124\n",
      "epoch: 3 step: 1167, loss is 0.0369054451584816\n",
      "epoch: 3 step: 1168, loss is 0.019211651757359505\n",
      "epoch: 3 step: 1169, loss is 0.10095151513814926\n",
      "epoch: 3 step: 1170, loss is 0.04771992564201355\n",
      "epoch: 3 step: 1171, loss is 0.04401742294430733\n",
      "epoch: 3 step: 1172, loss is 0.011329900473356247\n",
      "epoch: 3 step: 1173, loss is 0.05159131437540054\n",
      "epoch: 3 step: 1174, loss is 0.019992578774690628\n",
      "epoch: 3 step: 1175, loss is 0.0044461688958108425\n",
      "epoch: 3 step: 1176, loss is 0.07855966687202454\n",
      "epoch: 3 step: 1177, loss is 0.0037338973488658667\n",
      "epoch: 3 step: 1178, loss is 0.016678161919116974\n",
      "epoch: 3 step: 1179, loss is 0.18182916939258575\n",
      "epoch: 3 step: 1180, loss is 0.006856262683868408\n",
      "epoch: 3 step: 1181, loss is 0.008293692022562027\n",
      "epoch: 3 step: 1182, loss is 0.06418625265359879\n",
      "epoch: 3 step: 1183, loss is 0.031206782907247543\n",
      "epoch: 3 step: 1184, loss is 0.010891511105000973\n",
      "epoch: 3 step: 1185, loss is 0.010166012682020664\n",
      "epoch: 3 step: 1186, loss is 0.028172409161925316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1187, loss is 0.0208006352186203\n",
      "epoch: 3 step: 1188, loss is 0.04671109467744827\n",
      "epoch: 3 step: 1189, loss is 0.003358513815328479\n",
      "epoch: 3 step: 1190, loss is 0.0029057443607598543\n",
      "epoch: 3 step: 1191, loss is 0.21044650673866272\n",
      "epoch: 3 step: 1192, loss is 0.022435711696743965\n",
      "epoch: 3 step: 1193, loss is 0.0014065655414015055\n",
      "epoch: 3 step: 1194, loss is 0.0239575058221817\n",
      "epoch: 3 step: 1195, loss is 0.034481264650821686\n",
      "epoch: 3 step: 1196, loss is 0.012953367084264755\n",
      "epoch: 3 step: 1197, loss is 0.004761064425110817\n",
      "epoch: 3 step: 1198, loss is 0.0032361745834350586\n",
      "epoch: 3 step: 1199, loss is 0.004015506710857153\n",
      "epoch: 3 step: 1200, loss is 0.058823831379413605\n",
      "epoch: 3 step: 1201, loss is 0.002661427715793252\n",
      "epoch: 3 step: 1202, loss is 0.0007970382575877011\n",
      "epoch: 3 step: 1203, loss is 0.0007395230932161212\n",
      "epoch: 3 step: 1204, loss is 0.008518454618752003\n",
      "epoch: 3 step: 1205, loss is 0.008047659881412983\n",
      "epoch: 3 step: 1206, loss is 0.10002944618463516\n",
      "epoch: 3 step: 1207, loss is 0.003809866728261113\n",
      "epoch: 3 step: 1208, loss is 0.06196220591664314\n",
      "epoch: 3 step: 1209, loss is 0.23131485283374786\n",
      "epoch: 3 step: 1210, loss is 0.0031347349286079407\n",
      "epoch: 3 step: 1211, loss is 0.0030166024807840586\n",
      "epoch: 3 step: 1212, loss is 0.04107073321938515\n",
      "epoch: 3 step: 1213, loss is 0.11168842017650604\n",
      "epoch: 3 step: 1214, loss is 0.003975339699536562\n",
      "epoch: 3 step: 1215, loss is 0.008652038872241974\n",
      "epoch: 3 step: 1216, loss is 0.01976950839161873\n",
      "epoch: 3 step: 1217, loss is 0.058142390102148056\n",
      "epoch: 3 step: 1218, loss is 0.015040326863527298\n",
      "epoch: 3 step: 1219, loss is 0.08385936915874481\n",
      "epoch: 3 step: 1220, loss is 0.0323331356048584\n",
      "epoch: 3 step: 1221, loss is 0.0008619838044978678\n",
      "epoch: 3 step: 1222, loss is 0.022858550772070885\n",
      "epoch: 3 step: 1223, loss is 0.0007345900521613657\n",
      "epoch: 3 step: 1224, loss is 0.011124992743134499\n",
      "epoch: 3 step: 1225, loss is 0.0008331193821504712\n",
      "epoch: 3 step: 1226, loss is 0.00791169237345457\n",
      "epoch: 3 step: 1227, loss is 0.014403588138520718\n",
      "epoch: 3 step: 1228, loss is 0.0017879193183034658\n",
      "epoch: 3 step: 1229, loss is 0.039454713463783264\n",
      "epoch: 3 step: 1230, loss is 0.0054636672139167786\n",
      "epoch: 3 step: 1231, loss is 0.10529554635286331\n",
      "epoch: 3 step: 1232, loss is 0.03870363160967827\n",
      "epoch: 3 step: 1233, loss is 0.0008140124846249819\n",
      "epoch: 3 step: 1234, loss is 0.03315568342804909\n",
      "epoch: 3 step: 1235, loss is 0.08065228164196014\n",
      "epoch: 3 step: 1236, loss is 0.18053537607192993\n",
      "epoch: 3 step: 1237, loss is 0.002293236553668976\n",
      "epoch: 3 step: 1238, loss is 0.0002905102155636996\n",
      "epoch: 3 step: 1239, loss is 0.01782131753861904\n",
      "epoch: 3 step: 1240, loss is 0.06811588257551193\n",
      "epoch: 3 step: 1241, loss is 0.0010188486194238067\n",
      "epoch: 3 step: 1242, loss is 0.01983402669429779\n",
      "epoch: 3 step: 1243, loss is 0.17017224431037903\n",
      "epoch: 3 step: 1244, loss is 0.052842289209365845\n",
      "epoch: 3 step: 1245, loss is 0.016634244471788406\n",
      "epoch: 3 step: 1246, loss is 0.03346925973892212\n",
      "epoch: 3 step: 1247, loss is 0.15274712443351746\n",
      "epoch: 3 step: 1248, loss is 0.07462096214294434\n",
      "epoch: 3 step: 1249, loss is 0.024305198341608047\n",
      "epoch: 3 step: 1250, loss is 0.03948584571480751\n",
      "epoch: 3 step: 1251, loss is 0.08387695997953415\n",
      "epoch: 3 step: 1252, loss is 0.014382155612111092\n",
      "epoch: 3 step: 1253, loss is 0.01281209196895361\n",
      "epoch: 3 step: 1254, loss is 0.01919942907989025\n",
      "epoch: 3 step: 1255, loss is 0.00025004122289828956\n",
      "epoch: 3 step: 1256, loss is 0.012705978937447071\n",
      "epoch: 3 step: 1257, loss is 0.01841399446129799\n",
      "epoch: 3 step: 1258, loss is 0.029481250792741776\n",
      "epoch: 3 step: 1259, loss is 0.10330606997013092\n",
      "epoch: 3 step: 1260, loss is 0.01286326814442873\n",
      "epoch: 3 step: 1261, loss is 0.015522425994277\n",
      "epoch: 3 step: 1262, loss is 0.08607606589794159\n",
      "epoch: 3 step: 1263, loss is 0.16904738545417786\n",
      "epoch: 3 step: 1264, loss is 0.04620002955198288\n",
      "epoch: 3 step: 1265, loss is 0.009443609043955803\n",
      "epoch: 3 step: 1266, loss is 0.0021660267375409603\n",
      "epoch: 3 step: 1267, loss is 0.0005643775803036988\n",
      "epoch: 3 step: 1268, loss is 0.06249874085187912\n",
      "epoch: 3 step: 1269, loss is 0.0031262387055903673\n",
      "epoch: 3 step: 1270, loss is 0.10514049232006073\n",
      "epoch: 3 step: 1271, loss is 0.006652400828897953\n",
      "epoch: 3 step: 1272, loss is 0.002265019342303276\n",
      "epoch: 3 step: 1273, loss is 0.12272380292415619\n",
      "epoch: 3 step: 1274, loss is 0.0036672342102974653\n",
      "epoch: 3 step: 1275, loss is 0.1707996428012848\n",
      "epoch: 3 step: 1276, loss is 0.0038027106784284115\n",
      "epoch: 3 step: 1277, loss is 0.07761656492948532\n",
      "epoch: 3 step: 1278, loss is 0.008007090538740158\n",
      "epoch: 3 step: 1279, loss is 0.076043039560318\n",
      "epoch: 3 step: 1280, loss is 0.042810820043087006\n",
      "epoch: 3 step: 1281, loss is 0.028626184910535812\n",
      "epoch: 3 step: 1282, loss is 0.019541466608643532\n",
      "epoch: 3 step: 1283, loss is 0.002996345516294241\n",
      "epoch: 3 step: 1284, loss is 0.07324947416782379\n",
      "epoch: 3 step: 1285, loss is 0.021488556638360023\n",
      "epoch: 3 step: 1286, loss is 0.0016196968499571085\n",
      "epoch: 3 step: 1287, loss is 0.001919272355735302\n",
      "epoch: 3 step: 1288, loss is 0.018617145717144012\n",
      "epoch: 3 step: 1289, loss is 0.01099914126098156\n",
      "epoch: 3 step: 1290, loss is 0.001600470975972712\n",
      "epoch: 3 step: 1291, loss is 0.049357734620571136\n",
      "epoch: 3 step: 1292, loss is 0.10357719659805298\n",
      "epoch: 3 step: 1293, loss is 0.0406072698533535\n",
      "epoch: 3 step: 1294, loss is 0.00508430041372776\n",
      "epoch: 3 step: 1295, loss is 0.11809854954481125\n",
      "epoch: 3 step: 1296, loss is 0.05933534726500511\n",
      "epoch: 3 step: 1297, loss is 0.05276757851243019\n",
      "epoch: 3 step: 1298, loss is 0.004304173868149519\n",
      "epoch: 3 step: 1299, loss is 0.048767633736133575\n",
      "epoch: 3 step: 1300, loss is 0.0036090004723519087\n",
      "epoch: 3 step: 1301, loss is 0.00048674739082343876\n",
      "epoch: 3 step: 1302, loss is 0.0018745741108432412\n",
      "epoch: 3 step: 1303, loss is 0.012123554944992065\n",
      "epoch: 3 step: 1304, loss is 0.0025796203408390284\n",
      "epoch: 3 step: 1305, loss is 0.011819230392575264\n",
      "epoch: 3 step: 1306, loss is 0.11790067702531815\n",
      "epoch: 3 step: 1307, loss is 0.06436687707901001\n",
      "epoch: 3 step: 1308, loss is 0.05441303178668022\n",
      "epoch: 3 step: 1309, loss is 0.0036654751747846603\n",
      "epoch: 3 step: 1310, loss is 0.00021736470807809383\n",
      "epoch: 3 step: 1311, loss is 0.02321380376815796\n",
      "epoch: 3 step: 1312, loss is 0.007011973299086094\n",
      "epoch: 3 step: 1313, loss is 0.03484524041414261\n",
      "epoch: 3 step: 1314, loss is 0.07830006629228592\n",
      "epoch: 3 step: 1315, loss is 0.011074673384428024\n",
      "epoch: 3 step: 1316, loss is 0.018369605764746666\n",
      "epoch: 3 step: 1317, loss is 0.3328806459903717\n",
      "epoch: 3 step: 1318, loss is 0.10165046900510788\n",
      "epoch: 3 step: 1319, loss is 0.03048456460237503\n",
      "epoch: 3 step: 1320, loss is 0.24112489819526672\n",
      "epoch: 3 step: 1321, loss is 0.00032868707785382867\n",
      "epoch: 3 step: 1322, loss is 0.2387085258960724\n",
      "epoch: 3 step: 1323, loss is 0.008603472262620926\n",
      "epoch: 3 step: 1324, loss is 0.35952866077423096\n",
      "epoch: 3 step: 1325, loss is 0.0278632752597332\n",
      "epoch: 3 step: 1326, loss is 0.0076384288258850574\n",
      "epoch: 3 step: 1327, loss is 0.0029342682100832462\n",
      "epoch: 3 step: 1328, loss is 0.1402566134929657\n",
      "epoch: 3 step: 1329, loss is 0.0006702999235130847\n",
      "epoch: 3 step: 1330, loss is 0.14952224493026733\n",
      "epoch: 3 step: 1331, loss is 0.05160629749298096\n",
      "epoch: 3 step: 1332, loss is 0.059879761189222336\n",
      "epoch: 3 step: 1333, loss is 0.0030120632145553827\n",
      "epoch: 3 step: 1334, loss is 0.0051800888031721115\n",
      "epoch: 3 step: 1335, loss is 0.0041016824543476105\n",
      "epoch: 3 step: 1336, loss is 0.00937140267342329\n",
      "epoch: 3 step: 1337, loss is 0.001864720368757844\n",
      "epoch: 3 step: 1338, loss is 0.0009593346621841192\n",
      "epoch: 3 step: 1339, loss is 0.18280385434627533\n",
      "epoch: 3 step: 1340, loss is 0.004207560792565346\n",
      "epoch: 3 step: 1341, loss is 0.04263360798358917\n",
      "epoch: 3 step: 1342, loss is 0.018079956993460655\n",
      "epoch: 3 step: 1343, loss is 0.049688730388879776\n",
      "epoch: 3 step: 1344, loss is 0.10635294765233994\n",
      "epoch: 3 step: 1345, loss is 0.0034788204357028008\n",
      "epoch: 3 step: 1346, loss is 0.012893696315586567\n",
      "epoch: 3 step: 1347, loss is 0.0034420073498040438\n",
      "epoch: 3 step: 1348, loss is 0.03716282546520233\n",
      "epoch: 3 step: 1349, loss is 0.0048212152905762196\n",
      "epoch: 3 step: 1350, loss is 0.00279247690923512\n",
      "epoch: 3 step: 1351, loss is 0.0557674877345562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1352, loss is 0.006703004706650972\n",
      "epoch: 3 step: 1353, loss is 0.04506947472691536\n",
      "epoch: 3 step: 1354, loss is 0.12666265666484833\n",
      "epoch: 3 step: 1355, loss is 0.0013754728715866804\n",
      "epoch: 3 step: 1356, loss is 0.02355150505900383\n",
      "epoch: 3 step: 1357, loss is 0.06736711412668228\n",
      "epoch: 3 step: 1358, loss is 0.011998919770121574\n",
      "epoch: 3 step: 1359, loss is 0.019648773595690727\n",
      "epoch: 3 step: 1360, loss is 0.09915770590305328\n",
      "epoch: 3 step: 1361, loss is 0.061261583119630814\n",
      "epoch: 3 step: 1362, loss is 0.005027439445257187\n",
      "epoch: 3 step: 1363, loss is 0.02357127144932747\n",
      "epoch: 3 step: 1364, loss is 0.005945321638137102\n",
      "epoch: 3 step: 1365, loss is 0.2703690826892853\n",
      "epoch: 3 step: 1366, loss is 0.0018517294665798545\n",
      "epoch: 3 step: 1367, loss is 0.1329013556241989\n",
      "epoch: 3 step: 1368, loss is 0.049320466816425323\n",
      "epoch: 3 step: 1369, loss is 0.005045711062848568\n",
      "epoch: 3 step: 1370, loss is 0.0011845326516777277\n",
      "epoch: 3 step: 1371, loss is 0.2038552463054657\n",
      "epoch: 3 step: 1372, loss is 0.012024655938148499\n",
      "epoch: 3 step: 1373, loss is 0.005269787274301052\n",
      "epoch: 3 step: 1374, loss is 0.01545611210167408\n",
      "epoch: 3 step: 1375, loss is 0.004523599054664373\n",
      "epoch: 3 step: 1376, loss is 0.008132530376315117\n",
      "epoch: 3 step: 1377, loss is 0.009631689637899399\n",
      "epoch: 3 step: 1378, loss is 0.003359593218192458\n",
      "epoch: 3 step: 1379, loss is 0.0003476549172773957\n",
      "epoch: 3 step: 1380, loss is 0.167741596698761\n",
      "epoch: 3 step: 1381, loss is 0.005719244945794344\n",
      "epoch: 3 step: 1382, loss is 0.01122990157455206\n",
      "epoch: 3 step: 1383, loss is 0.04924112185835838\n",
      "epoch: 3 step: 1384, loss is 0.01355031318962574\n",
      "epoch: 3 step: 1385, loss is 0.1944073587656021\n",
      "epoch: 3 step: 1386, loss is 0.004109903238713741\n",
      "epoch: 3 step: 1387, loss is 0.009585786610841751\n",
      "epoch: 3 step: 1388, loss is 0.008650582283735275\n",
      "epoch: 3 step: 1389, loss is 0.0014611892402172089\n",
      "epoch: 3 step: 1390, loss is 0.3078843653202057\n",
      "epoch: 3 step: 1391, loss is 0.002516299718990922\n",
      "epoch: 3 step: 1392, loss is 0.23124931752681732\n",
      "epoch: 3 step: 1393, loss is 0.030743559822440147\n",
      "epoch: 3 step: 1394, loss is 0.10158982872962952\n",
      "epoch: 3 step: 1395, loss is 0.0018150649266317487\n",
      "epoch: 3 step: 1396, loss is 0.006892327219247818\n",
      "epoch: 3 step: 1397, loss is 0.01060539297759533\n",
      "epoch: 3 step: 1398, loss is 0.006670956499874592\n",
      "epoch: 3 step: 1399, loss is 0.06331179291009903\n",
      "epoch: 3 step: 1400, loss is 0.02290981076657772\n",
      "epoch: 3 step: 1401, loss is 0.1987268477678299\n",
      "epoch: 3 step: 1402, loss is 0.010739630088210106\n",
      "epoch: 3 step: 1403, loss is 0.0037895108107477427\n",
      "epoch: 3 step: 1404, loss is 0.014576200395822525\n",
      "epoch: 3 step: 1405, loss is 0.0050201620906591415\n",
      "epoch: 3 step: 1406, loss is 0.026566628366708755\n",
      "epoch: 3 step: 1407, loss is 0.00996391475200653\n",
      "epoch: 3 step: 1408, loss is 0.04087633639574051\n",
      "epoch: 3 step: 1409, loss is 0.008107287809252739\n",
      "epoch: 3 step: 1410, loss is 0.007760119158774614\n",
      "epoch: 3 step: 1411, loss is 0.06811334192752838\n",
      "epoch: 3 step: 1412, loss is 0.03636230155825615\n",
      "epoch: 3 step: 1413, loss is 0.0465366430580616\n",
      "epoch: 3 step: 1414, loss is 0.007645286154001951\n",
      "epoch: 3 step: 1415, loss is 0.003198495600372553\n",
      "epoch: 3 step: 1416, loss is 0.0748019590973854\n",
      "epoch: 3 step: 1417, loss is 0.024990985170006752\n",
      "epoch: 3 step: 1418, loss is 0.025065798312425613\n",
      "epoch: 3 step: 1419, loss is 0.20882689952850342\n",
      "epoch: 3 step: 1420, loss is 0.01994749903678894\n",
      "epoch: 3 step: 1421, loss is 0.054608482867479324\n",
      "epoch: 3 step: 1422, loss is 0.0010605951538309455\n",
      "epoch: 3 step: 1423, loss is 0.0232270248234272\n",
      "epoch: 3 step: 1424, loss is 0.003433916252106428\n",
      "epoch: 3 step: 1425, loss is 0.047352250665426254\n",
      "epoch: 3 step: 1426, loss is 0.22593146562576294\n",
      "epoch: 3 step: 1427, loss is 0.001572927227243781\n",
      "epoch: 3 step: 1428, loss is 0.016828451305627823\n",
      "epoch: 3 step: 1429, loss is 0.0531843900680542\n",
      "epoch: 3 step: 1430, loss is 0.09687141329050064\n",
      "epoch: 3 step: 1431, loss is 0.03361060842871666\n",
      "epoch: 3 step: 1432, loss is 0.027416901662945747\n",
      "epoch: 3 step: 1433, loss is 0.17422641813755035\n",
      "epoch: 3 step: 1434, loss is 0.0021705422550439835\n",
      "epoch: 3 step: 1435, loss is 0.007038138806819916\n",
      "epoch: 3 step: 1436, loss is 0.03273675963282585\n",
      "epoch: 3 step: 1437, loss is 0.0802575945854187\n",
      "epoch: 3 step: 1438, loss is 0.004206355661153793\n",
      "epoch: 3 step: 1439, loss is 0.007149400655180216\n",
      "epoch: 3 step: 1440, loss is 0.1752602607011795\n",
      "epoch: 3 step: 1441, loss is 0.015302861109375954\n",
      "epoch: 3 step: 1442, loss is 0.023146869614720345\n",
      "epoch: 3 step: 1443, loss is 0.04029282182455063\n",
      "epoch: 3 step: 1444, loss is 0.008235613815486431\n",
      "epoch: 3 step: 1445, loss is 0.01574074849486351\n",
      "epoch: 3 step: 1446, loss is 0.0007209916948340833\n",
      "epoch: 3 step: 1447, loss is 0.06966926902532578\n",
      "epoch: 3 step: 1448, loss is 0.14970886707305908\n",
      "epoch: 3 step: 1449, loss is 0.002266576047986746\n",
      "epoch: 3 step: 1450, loss is 0.05026021599769592\n",
      "epoch: 3 step: 1451, loss is 0.010021794587373734\n",
      "epoch: 3 step: 1452, loss is 0.12178900092840195\n",
      "epoch: 3 step: 1453, loss is 0.0029387492686510086\n",
      "epoch: 3 step: 1454, loss is 0.01696021854877472\n",
      "epoch: 3 step: 1455, loss is 0.010610799305140972\n",
      "epoch: 3 step: 1456, loss is 0.0008983120205812156\n",
      "epoch: 3 step: 1457, loss is 0.024262316524982452\n",
      "epoch: 3 step: 1458, loss is 0.012750992551445961\n",
      "epoch: 3 step: 1459, loss is 0.18317504227161407\n",
      "epoch: 3 step: 1460, loss is 0.007266799919307232\n",
      "epoch: 3 step: 1461, loss is 0.010701227001845837\n",
      "epoch: 3 step: 1462, loss is 0.005276590585708618\n",
      "epoch: 3 step: 1463, loss is 0.009889652952551842\n",
      "epoch: 3 step: 1464, loss is 0.01380927674472332\n",
      "epoch: 3 step: 1465, loss is 0.010602951981127262\n",
      "epoch: 3 step: 1466, loss is 0.22525177896022797\n",
      "epoch: 3 step: 1467, loss is 0.004142977297306061\n",
      "epoch: 3 step: 1468, loss is 0.0005306922248564661\n",
      "epoch: 3 step: 1469, loss is 0.0005104235606268048\n",
      "epoch: 3 step: 1470, loss is 0.0006157879251986742\n",
      "epoch: 3 step: 1471, loss is 0.11688338220119476\n",
      "epoch: 3 step: 1472, loss is 0.07548484951257706\n",
      "epoch: 3 step: 1473, loss is 0.007030715234577656\n",
      "epoch: 3 step: 1474, loss is 0.005695518106222153\n",
      "epoch: 3 step: 1475, loss is 0.019832728430628777\n",
      "epoch: 3 step: 1476, loss is 0.0021497777197510004\n",
      "epoch: 3 step: 1477, loss is 0.007691793609410524\n",
      "epoch: 3 step: 1478, loss is 0.00416609738022089\n",
      "epoch: 3 step: 1479, loss is 0.000531864701770246\n",
      "epoch: 3 step: 1480, loss is 0.053295526653528214\n",
      "epoch: 3 step: 1481, loss is 0.020173514261841774\n",
      "epoch: 3 step: 1482, loss is 0.002871414413675666\n",
      "epoch: 3 step: 1483, loss is 0.0112540815025568\n",
      "epoch: 3 step: 1484, loss is 0.002016301266849041\n",
      "epoch: 3 step: 1485, loss is 0.05142911523580551\n",
      "epoch: 3 step: 1486, loss is 0.013018887490034103\n",
      "epoch: 3 step: 1487, loss is 0.003937033005058765\n",
      "epoch: 3 step: 1488, loss is 0.0006093007978051901\n",
      "epoch: 3 step: 1489, loss is 0.003293468616902828\n",
      "epoch: 3 step: 1490, loss is 0.002563453046604991\n",
      "epoch: 3 step: 1491, loss is 0.003315169597044587\n",
      "epoch: 3 step: 1492, loss is 0.0034142937511205673\n",
      "epoch: 3 step: 1493, loss is 0.0044051832519471645\n",
      "epoch: 3 step: 1494, loss is 0.06107663735747337\n",
      "epoch: 3 step: 1495, loss is 0.04062864929437637\n",
      "epoch: 3 step: 1496, loss is 0.0028391920495778322\n",
      "epoch: 3 step: 1497, loss is 0.007958018220961094\n",
      "epoch: 3 step: 1498, loss is 0.06832848489284515\n",
      "epoch: 3 step: 1499, loss is 0.010779310949146748\n",
      "epoch: 3 step: 1500, loss is 0.04590814560651779\n",
      "epoch: 3 step: 1501, loss is 0.06377793848514557\n",
      "epoch: 3 step: 1502, loss is 0.06102538853883743\n",
      "epoch: 3 step: 1503, loss is 0.0006020812434144318\n",
      "epoch: 3 step: 1504, loss is 0.007694507483392954\n",
      "epoch: 3 step: 1505, loss is 0.0010413402924314141\n",
      "epoch: 3 step: 1506, loss is 0.029433567076921463\n",
      "epoch: 3 step: 1507, loss is 0.0015575478319078684\n",
      "epoch: 3 step: 1508, loss is 0.005832508206367493\n",
      "epoch: 3 step: 1509, loss is 0.18433667719364166\n",
      "epoch: 3 step: 1510, loss is 0.002918631536886096\n",
      "epoch: 3 step: 1511, loss is 0.10914978384971619\n",
      "epoch: 3 step: 1512, loss is 0.046090610325336456\n",
      "epoch: 3 step: 1513, loss is 0.004058000631630421\n",
      "epoch: 3 step: 1514, loss is 0.013917232863605022\n",
      "epoch: 3 step: 1515, loss is 0.00033001223346218467\n",
      "epoch: 3 step: 1516, loss is 0.0018654076848179102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1517, loss is 0.17353875935077667\n",
      "epoch: 3 step: 1518, loss is 0.009634150192141533\n",
      "epoch: 3 step: 1519, loss is 0.0037985811941325665\n",
      "epoch: 3 step: 1520, loss is 0.035896528512239456\n",
      "epoch: 3 step: 1521, loss is 0.006542056333273649\n",
      "epoch: 3 step: 1522, loss is 0.012180204503238201\n",
      "epoch: 3 step: 1523, loss is 0.044467464089393616\n",
      "epoch: 3 step: 1524, loss is 0.0002678932505659759\n",
      "epoch: 3 step: 1525, loss is 0.0017431476153433323\n",
      "epoch: 3 step: 1526, loss is 0.03651293367147446\n",
      "epoch: 3 step: 1527, loss is 0.000801716698333621\n",
      "epoch: 3 step: 1528, loss is 0.006646221969276667\n",
      "epoch: 3 step: 1529, loss is 0.008104737848043442\n",
      "epoch: 3 step: 1530, loss is 0.003910926170647144\n",
      "epoch: 3 step: 1531, loss is 0.005003633443266153\n",
      "epoch: 3 step: 1532, loss is 0.0009850928327068686\n",
      "epoch: 3 step: 1533, loss is 0.2886998951435089\n",
      "epoch: 3 step: 1534, loss is 0.008578185923397541\n",
      "epoch: 3 step: 1535, loss is 0.004757432267069817\n",
      "epoch: 3 step: 1536, loss is 0.035322416573762894\n",
      "epoch: 3 step: 1537, loss is 0.0017610857030376792\n",
      "epoch: 3 step: 1538, loss is 0.0024916501715779305\n",
      "epoch: 3 step: 1539, loss is 0.021349841728806496\n",
      "epoch: 3 step: 1540, loss is 0.0040817102417349815\n",
      "epoch: 3 step: 1541, loss is 0.07051515579223633\n",
      "epoch: 3 step: 1542, loss is 0.004807841032743454\n",
      "epoch: 3 step: 1543, loss is 0.003146049566566944\n",
      "epoch: 3 step: 1544, loss is 0.10405120253562927\n",
      "epoch: 3 step: 1545, loss is 0.05769260972738266\n",
      "epoch: 3 step: 1546, loss is 0.1987147033214569\n",
      "epoch: 3 step: 1547, loss is 0.008539438247680664\n",
      "epoch: 3 step: 1548, loss is 0.005794648081064224\n",
      "epoch: 3 step: 1549, loss is 0.007426767610013485\n",
      "epoch: 3 step: 1550, loss is 0.13902299106121063\n",
      "epoch: 3 step: 1551, loss is 0.07707688957452774\n",
      "epoch: 3 step: 1552, loss is 0.004265212919563055\n",
      "epoch: 3 step: 1553, loss is 0.017553668469190598\n",
      "epoch: 3 step: 1554, loss is 0.0008930742042139173\n",
      "epoch: 3 step: 1555, loss is 0.024922115728259087\n",
      "epoch: 3 step: 1556, loss is 0.0011224511545151472\n",
      "epoch: 3 step: 1557, loss is 0.06158512085676193\n",
      "epoch: 3 step: 1558, loss is 0.000977525021880865\n",
      "epoch: 3 step: 1559, loss is 0.00869192648679018\n",
      "epoch: 3 step: 1560, loss is 0.008800565265119076\n",
      "epoch: 3 step: 1561, loss is 0.0680549144744873\n",
      "epoch: 3 step: 1562, loss is 0.0007919772760942578\n",
      "epoch: 3 step: 1563, loss is 0.043137773871421814\n",
      "epoch: 3 step: 1564, loss is 0.0060025230050086975\n",
      "epoch: 3 step: 1565, loss is 0.009383373893797398\n",
      "epoch: 3 step: 1566, loss is 0.0010482497746124864\n",
      "epoch: 3 step: 1567, loss is 0.0389493964612484\n",
      "epoch: 3 step: 1568, loss is 0.09968290477991104\n",
      "epoch: 3 step: 1569, loss is 0.0023143526632338762\n",
      "epoch: 3 step: 1570, loss is 0.023758135735988617\n",
      "epoch: 3 step: 1571, loss is 0.0025184217374771833\n",
      "epoch: 3 step: 1572, loss is 0.0016456682933494449\n",
      "epoch: 3 step: 1573, loss is 0.1584857702255249\n",
      "epoch: 3 step: 1574, loss is 0.018485594540834427\n",
      "epoch: 3 step: 1575, loss is 0.004851676989346743\n",
      "epoch: 3 step: 1576, loss is 0.005614739377051592\n",
      "epoch: 3 step: 1577, loss is 0.1517157107591629\n",
      "epoch: 3 step: 1578, loss is 0.007561099249869585\n",
      "epoch: 3 step: 1579, loss is 0.17853505909442902\n",
      "epoch: 3 step: 1580, loss is 0.005640605464577675\n",
      "epoch: 3 step: 1581, loss is 0.003970191348344088\n",
      "epoch: 3 step: 1582, loss is 0.01638919487595558\n",
      "epoch: 3 step: 1583, loss is 0.00830096285790205\n",
      "epoch: 3 step: 1584, loss is 0.1838189661502838\n",
      "epoch: 3 step: 1585, loss is 0.11274760961532593\n",
      "epoch: 3 step: 1586, loss is 0.044585008174180984\n",
      "epoch: 3 step: 1587, loss is 0.023531431332230568\n",
      "epoch: 3 step: 1588, loss is 0.0308550912886858\n",
      "epoch: 3 step: 1589, loss is 0.013036424294114113\n",
      "epoch: 3 step: 1590, loss is 0.00110721739474684\n",
      "epoch: 3 step: 1591, loss is 0.01649428904056549\n",
      "epoch: 3 step: 1592, loss is 0.08452362567186356\n",
      "epoch: 3 step: 1593, loss is 0.012781678698956966\n",
      "epoch: 3 step: 1594, loss is 0.0030239801853895187\n",
      "epoch: 3 step: 1595, loss is 0.0038052694872021675\n",
      "epoch: 3 step: 1596, loss is 0.03439541533589363\n",
      "epoch: 3 step: 1597, loss is 0.05363751947879791\n",
      "epoch: 3 step: 1598, loss is 0.04185086488723755\n",
      "epoch: 3 step: 1599, loss is 0.16339896619319916\n",
      "epoch: 3 step: 1600, loss is 0.001493769814260304\n",
      "epoch: 3 step: 1601, loss is 0.007143101654946804\n",
      "epoch: 3 step: 1602, loss is 0.02132987789809704\n",
      "epoch: 3 step: 1603, loss is 0.0542522594332695\n",
      "epoch: 3 step: 1604, loss is 0.00897937174886465\n",
      "epoch: 3 step: 1605, loss is 0.004771241918206215\n",
      "epoch: 3 step: 1606, loss is 0.031820256263017654\n",
      "epoch: 3 step: 1607, loss is 0.0005202751490287483\n",
      "epoch: 3 step: 1608, loss is 0.008309196680784225\n",
      "epoch: 3 step: 1609, loss is 0.008626364171504974\n",
      "epoch: 3 step: 1610, loss is 0.036869730800390244\n",
      "epoch: 3 step: 1611, loss is 0.06802114099264145\n",
      "epoch: 3 step: 1612, loss is 0.003504763590171933\n",
      "epoch: 3 step: 1613, loss is 0.10605652630329132\n",
      "epoch: 3 step: 1614, loss is 0.0058516389690339565\n",
      "epoch: 3 step: 1615, loss is 0.012219509109854698\n",
      "epoch: 3 step: 1616, loss is 0.009682678617537022\n",
      "epoch: 3 step: 1617, loss is 0.027308516204357147\n",
      "epoch: 3 step: 1618, loss is 0.27937114238739014\n",
      "epoch: 3 step: 1619, loss is 0.004133796319365501\n",
      "epoch: 3 step: 1620, loss is 0.009423058480024338\n",
      "epoch: 3 step: 1621, loss is 0.04018470644950867\n",
      "epoch: 3 step: 1622, loss is 0.0005409437580965459\n",
      "epoch: 3 step: 1623, loss is 0.055327001959085464\n",
      "epoch: 3 step: 1624, loss is 0.00332055427134037\n",
      "epoch: 3 step: 1625, loss is 0.05856000632047653\n",
      "epoch: 3 step: 1626, loss is 0.05836835876107216\n",
      "epoch: 3 step: 1627, loss is 0.17347319424152374\n",
      "epoch: 3 step: 1628, loss is 0.0018362647388130426\n",
      "epoch: 3 step: 1629, loss is 0.014209378510713577\n",
      "epoch: 3 step: 1630, loss is 0.00029349623946473\n",
      "epoch: 3 step: 1631, loss is 0.0019975772593170404\n",
      "epoch: 3 step: 1632, loss is 0.0008854172774590552\n",
      "epoch: 3 step: 1633, loss is 0.03546111658215523\n",
      "epoch: 3 step: 1634, loss is 0.04733744636178017\n",
      "epoch: 3 step: 1635, loss is 0.0021633198484778404\n",
      "epoch: 3 step: 1636, loss is 0.0033730182331055403\n",
      "epoch: 3 step: 1637, loss is 0.009715944528579712\n",
      "epoch: 3 step: 1638, loss is 0.03935779258608818\n",
      "epoch: 3 step: 1639, loss is 0.005771788768470287\n",
      "epoch: 3 step: 1640, loss is 0.004662004299461842\n",
      "epoch: 3 step: 1641, loss is 0.0010509564308449626\n",
      "epoch: 3 step: 1642, loss is 0.0028692299965769053\n",
      "epoch: 3 step: 1643, loss is 0.0010057584149762988\n",
      "epoch: 3 step: 1644, loss is 0.012995624914765358\n",
      "epoch: 3 step: 1645, loss is 0.0030739265494048595\n",
      "epoch: 3 step: 1646, loss is 0.004951404873281717\n",
      "epoch: 3 step: 1647, loss is 0.14435924589633942\n",
      "epoch: 3 step: 1648, loss is 0.03667611628770828\n",
      "epoch: 3 step: 1649, loss is 0.02689291350543499\n",
      "epoch: 3 step: 1650, loss is 0.0865798369050026\n",
      "epoch: 3 step: 1651, loss is 0.0035385419614613056\n",
      "epoch: 3 step: 1652, loss is 0.0012073309626430273\n",
      "epoch: 3 step: 1653, loss is 0.0009394485969096422\n",
      "epoch: 3 step: 1654, loss is 0.003098237095400691\n",
      "epoch: 3 step: 1655, loss is 0.20932438969612122\n",
      "epoch: 3 step: 1656, loss is 0.2355470508337021\n",
      "epoch: 3 step: 1657, loss is 0.03390256315469742\n",
      "epoch: 3 step: 1658, loss is 0.06431903690099716\n",
      "epoch: 3 step: 1659, loss is 0.06435082107782364\n",
      "epoch: 3 step: 1660, loss is 0.04061508923768997\n",
      "epoch: 3 step: 1661, loss is 0.011606129817664623\n",
      "epoch: 3 step: 1662, loss is 0.0506133958697319\n",
      "epoch: 3 step: 1663, loss is 0.0020948192104697227\n",
      "epoch: 3 step: 1664, loss is 0.014373255893588066\n",
      "epoch: 3 step: 1665, loss is 0.005987043026834726\n",
      "epoch: 3 step: 1666, loss is 0.02752654068171978\n",
      "epoch: 3 step: 1667, loss is 0.12951162457466125\n",
      "epoch: 3 step: 1668, loss is 0.004008408170193434\n",
      "epoch: 3 step: 1669, loss is 0.004584792535752058\n",
      "epoch: 3 step: 1670, loss is 0.2467811554670334\n",
      "epoch: 3 step: 1671, loss is 0.10808558017015457\n",
      "epoch: 3 step: 1672, loss is 0.19148467481136322\n",
      "epoch: 3 step: 1673, loss is 0.0032378605101257563\n",
      "epoch: 3 step: 1674, loss is 0.11352506279945374\n",
      "epoch: 3 step: 1675, loss is 0.014084613882005215\n",
      "epoch: 3 step: 1676, loss is 0.004394464194774628\n",
      "epoch: 3 step: 1677, loss is 0.009985383599996567\n",
      "epoch: 3 step: 1678, loss is 0.026545513421297073\n",
      "epoch: 3 step: 1679, loss is 0.0244606863707304\n",
      "epoch: 3 step: 1680, loss is 0.08439455926418304\n",
      "epoch: 3 step: 1681, loss is 0.0045791929587721825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1682, loss is 0.0480613112449646\n",
      "epoch: 3 step: 1683, loss is 0.001254756236448884\n",
      "epoch: 3 step: 1684, loss is 0.009898647665977478\n",
      "epoch: 3 step: 1685, loss is 0.05175756290555\n",
      "epoch: 3 step: 1686, loss is 0.07678627222776413\n",
      "epoch: 3 step: 1687, loss is 0.042703092098236084\n",
      "epoch: 3 step: 1688, loss is 0.037873879075050354\n",
      "epoch: 3 step: 1689, loss is 0.00032355228904634714\n",
      "epoch: 3 step: 1690, loss is 0.044818077236413956\n",
      "epoch: 3 step: 1691, loss is 0.06775782257318497\n",
      "epoch: 3 step: 1692, loss is 0.06860066950321198\n",
      "epoch: 3 step: 1693, loss is 0.02365698479115963\n",
      "epoch: 3 step: 1694, loss is 0.012485007755458355\n",
      "epoch: 3 step: 1695, loss is 0.0074316151440143585\n",
      "epoch: 3 step: 1696, loss is 0.003295683767646551\n",
      "epoch: 3 step: 1697, loss is 0.0655258446931839\n",
      "epoch: 3 step: 1698, loss is 0.003428989788517356\n",
      "epoch: 3 step: 1699, loss is 0.0008834616164676845\n",
      "epoch: 3 step: 1700, loss is 0.017868440598249435\n",
      "epoch: 3 step: 1701, loss is 0.016203049570322037\n",
      "epoch: 3 step: 1702, loss is 0.1463593989610672\n",
      "epoch: 3 step: 1703, loss is 0.11870388686656952\n",
      "epoch: 3 step: 1704, loss is 0.015073169022798538\n",
      "epoch: 3 step: 1705, loss is 0.03657447546720505\n",
      "epoch: 3 step: 1706, loss is 0.03387373313307762\n",
      "epoch: 3 step: 1707, loss is 0.02424568124115467\n",
      "epoch: 3 step: 1708, loss is 0.0027655870653688908\n",
      "epoch: 3 step: 1709, loss is 0.007808975409716368\n",
      "epoch: 3 step: 1710, loss is 0.03977669030427933\n",
      "epoch: 3 step: 1711, loss is 0.05564669519662857\n",
      "epoch: 3 step: 1712, loss is 0.0013953145826235414\n",
      "epoch: 3 step: 1713, loss is 0.0019065396627411246\n",
      "epoch: 3 step: 1714, loss is 0.09268410503864288\n",
      "epoch: 3 step: 1715, loss is 0.11952154338359833\n",
      "epoch: 3 step: 1716, loss is 0.022503456100821495\n",
      "epoch: 3 step: 1717, loss is 0.009877510368824005\n",
      "epoch: 3 step: 1718, loss is 0.06859495490789413\n",
      "epoch: 3 step: 1719, loss is 0.004433713387697935\n",
      "epoch: 3 step: 1720, loss is 0.0046870592050254345\n",
      "epoch: 3 step: 1721, loss is 0.002503471216186881\n",
      "epoch: 3 step: 1722, loss is 0.07814590632915497\n",
      "epoch: 3 step: 1723, loss is 0.0006778386887162924\n",
      "epoch: 3 step: 1724, loss is 0.0752703994512558\n",
      "epoch: 3 step: 1725, loss is 0.025289500132203102\n",
      "epoch: 3 step: 1726, loss is 0.001369787729345262\n",
      "epoch: 3 step: 1727, loss is 0.031129498034715652\n",
      "epoch: 3 step: 1728, loss is 0.01906311884522438\n",
      "epoch: 3 step: 1729, loss is 0.14450860023498535\n",
      "epoch: 3 step: 1730, loss is 0.01103886216878891\n",
      "epoch: 3 step: 1731, loss is 0.02180665172636509\n",
      "epoch: 3 step: 1732, loss is 0.05319646745920181\n",
      "epoch: 3 step: 1733, loss is 0.02707694098353386\n",
      "epoch: 3 step: 1734, loss is 0.0017939687240868807\n",
      "epoch: 3 step: 1735, loss is 0.07940901815891266\n",
      "epoch: 3 step: 1736, loss is 0.010081563144922256\n",
      "epoch: 3 step: 1737, loss is 0.0002546967880334705\n",
      "epoch: 3 step: 1738, loss is 0.01920832321047783\n",
      "epoch: 3 step: 1739, loss is 0.04182830825448036\n",
      "epoch: 3 step: 1740, loss is 0.01712910830974579\n",
      "epoch: 3 step: 1741, loss is 0.017449311912059784\n",
      "epoch: 3 step: 1742, loss is 0.006748741492629051\n",
      "epoch: 3 step: 1743, loss is 0.00445935782045126\n",
      "epoch: 3 step: 1744, loss is 0.035317182540893555\n",
      "epoch: 3 step: 1745, loss is 0.02744964137673378\n",
      "epoch: 3 step: 1746, loss is 0.01352609321475029\n",
      "epoch: 3 step: 1747, loss is 0.020971795544028282\n",
      "epoch: 3 step: 1748, loss is 0.05043138563632965\n",
      "epoch: 3 step: 1749, loss is 0.04201332852244377\n",
      "epoch: 3 step: 1750, loss is 0.007446683011949062\n",
      "epoch: 3 step: 1751, loss is 0.00047816475853323936\n",
      "epoch: 3 step: 1752, loss is 0.0012600366026163101\n",
      "epoch: 3 step: 1753, loss is 0.21211548149585724\n",
      "epoch: 3 step: 1754, loss is 0.013803924433887005\n",
      "epoch: 3 step: 1755, loss is 0.10055431723594666\n",
      "epoch: 3 step: 1756, loss is 0.0011496866354718804\n",
      "epoch: 3 step: 1757, loss is 0.0015998154412955046\n",
      "epoch: 3 step: 1758, loss is 0.009455610997974873\n",
      "epoch: 3 step: 1759, loss is 0.008523423224687576\n",
      "epoch: 3 step: 1760, loss is 0.010557201690971851\n",
      "epoch: 3 step: 1761, loss is 0.031859710812568665\n",
      "epoch: 3 step: 1762, loss is 0.07669348269701004\n",
      "epoch: 3 step: 1763, loss is 0.009853534400463104\n",
      "epoch: 3 step: 1764, loss is 0.04383157938718796\n",
      "epoch: 3 step: 1765, loss is 0.12401466816663742\n",
      "epoch: 3 step: 1766, loss is 0.06825071573257446\n",
      "epoch: 3 step: 1767, loss is 0.004937826190143824\n",
      "epoch: 3 step: 1768, loss is 0.00066518469247967\n",
      "epoch: 3 step: 1769, loss is 0.08309745788574219\n",
      "epoch: 3 step: 1770, loss is 0.024846434593200684\n",
      "epoch: 3 step: 1771, loss is 0.0010598973603919148\n",
      "epoch: 3 step: 1772, loss is 0.010126703418791294\n",
      "epoch: 3 step: 1773, loss is 0.02401527389883995\n",
      "epoch: 3 step: 1774, loss is 0.01586880348622799\n",
      "epoch: 3 step: 1775, loss is 0.08579226583242416\n",
      "epoch: 3 step: 1776, loss is 0.07777368277311325\n",
      "epoch: 3 step: 1777, loss is 0.0005792732117697597\n",
      "epoch: 3 step: 1778, loss is 0.0018126670038327575\n",
      "epoch: 3 step: 1779, loss is 0.0005859351367689669\n",
      "epoch: 3 step: 1780, loss is 0.00014840329822618514\n",
      "epoch: 3 step: 1781, loss is 0.013625159859657288\n",
      "epoch: 3 step: 1782, loss is 0.00483024911954999\n",
      "epoch: 3 step: 1783, loss is 8.322719077114016e-05\n",
      "epoch: 3 step: 1784, loss is 0.04158853739500046\n",
      "epoch: 3 step: 1785, loss is 0.00042913161450996995\n",
      "epoch: 3 step: 1786, loss is 0.0010823012562468648\n",
      "epoch: 3 step: 1787, loss is 0.027653072029352188\n",
      "epoch: 3 step: 1788, loss is 0.07522054761648178\n",
      "epoch: 3 step: 1789, loss is 0.05863408371806145\n",
      "epoch: 3 step: 1790, loss is 0.014435368590056896\n",
      "epoch: 3 step: 1791, loss is 0.0014891054015606642\n",
      "epoch: 3 step: 1792, loss is 0.004881983622908592\n",
      "epoch: 3 step: 1793, loss is 0.0020387812983244658\n",
      "epoch: 3 step: 1794, loss is 0.061184655874967575\n",
      "epoch: 3 step: 1795, loss is 0.0069584776647388935\n",
      "epoch: 3 step: 1796, loss is 0.03057263232767582\n",
      "epoch: 3 step: 1797, loss is 0.016286570578813553\n",
      "epoch: 3 step: 1798, loss is 0.000806304335128516\n",
      "epoch: 3 step: 1799, loss is 0.04157475382089615\n",
      "epoch: 3 step: 1800, loss is 0.005383842159062624\n",
      "epoch: 3 step: 1801, loss is 0.258218914270401\n",
      "epoch: 3 step: 1802, loss is 0.07358046621084213\n",
      "epoch: 3 step: 1803, loss is 8.332815923495218e-05\n",
      "epoch: 3 step: 1804, loss is 0.019706401973962784\n",
      "epoch: 3 step: 1805, loss is 0.00017418181232642382\n",
      "epoch: 3 step: 1806, loss is 0.02855960838496685\n",
      "epoch: 3 step: 1807, loss is 0.03601246327161789\n",
      "epoch: 3 step: 1808, loss is 0.0013832534896209836\n",
      "epoch: 3 step: 1809, loss is 0.0032071101013571024\n",
      "epoch: 3 step: 1810, loss is 0.003075614105910063\n",
      "epoch: 3 step: 1811, loss is 0.3309834897518158\n",
      "epoch: 3 step: 1812, loss is 0.017091352492570877\n",
      "epoch: 3 step: 1813, loss is 0.09655120223760605\n",
      "epoch: 3 step: 1814, loss is 0.006001351401209831\n",
      "epoch: 3 step: 1815, loss is 0.045590244233608246\n",
      "epoch: 3 step: 1816, loss is 0.007957675494253635\n",
      "epoch: 3 step: 1817, loss is 0.0005314219160936773\n",
      "epoch: 3 step: 1818, loss is 0.014586576260626316\n",
      "epoch: 3 step: 1819, loss is 0.304822713136673\n",
      "epoch: 3 step: 1820, loss is 0.03748682141304016\n",
      "epoch: 3 step: 1821, loss is 0.056172072887420654\n",
      "epoch: 3 step: 1822, loss is 0.0012614271836355329\n",
      "epoch: 3 step: 1823, loss is 0.010788756422698498\n",
      "epoch: 3 step: 1824, loss is 0.0006064241752028465\n",
      "epoch: 3 step: 1825, loss is 0.002844814909622073\n",
      "epoch: 3 step: 1826, loss is 0.0035792957060039043\n",
      "epoch: 3 step: 1827, loss is 0.09569717198610306\n",
      "epoch: 3 step: 1828, loss is 0.2532680034637451\n",
      "epoch: 3 step: 1829, loss is 0.001407017232850194\n",
      "epoch: 3 step: 1830, loss is 0.05108357593417168\n",
      "epoch: 3 step: 1831, loss is 0.014607121236622334\n",
      "epoch: 3 step: 1832, loss is 0.0050898646004498005\n",
      "epoch: 3 step: 1833, loss is 0.037445276975631714\n",
      "epoch: 3 step: 1834, loss is 0.0010699097765609622\n",
      "epoch: 3 step: 1835, loss is 0.0016233606729656458\n",
      "epoch: 3 step: 1836, loss is 0.017367737367749214\n",
      "epoch: 3 step: 1837, loss is 0.003497212426736951\n",
      "epoch: 3 step: 1838, loss is 0.26016339659690857\n",
      "epoch: 3 step: 1839, loss is 0.003576131071895361\n",
      "epoch: 3 step: 1840, loss is 0.19218659400939941\n",
      "epoch: 3 step: 1841, loss is 0.006304656621068716\n",
      "epoch: 3 step: 1842, loss is 0.16997043788433075\n",
      "epoch: 3 step: 1843, loss is 0.020078303292393684\n",
      "epoch: 3 step: 1844, loss is 0.002866315422579646\n",
      "epoch: 3 step: 1845, loss is 0.012598679400980473\n",
      "epoch: 3 step: 1846, loss is 0.09222310036420822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1847, loss is 0.08291136473417282\n",
      "epoch: 3 step: 1848, loss is 0.01403328962624073\n",
      "epoch: 3 step: 1849, loss is 0.009968478232622147\n",
      "epoch: 3 step: 1850, loss is 0.008026201277971268\n",
      "epoch: 3 step: 1851, loss is 0.18904748558998108\n",
      "epoch: 3 step: 1852, loss is 0.0004984118859283626\n",
      "epoch: 3 step: 1853, loss is 0.08047512173652649\n",
      "epoch: 3 step: 1854, loss is 0.023307127878069878\n",
      "epoch: 3 step: 1855, loss is 0.005838294513523579\n",
      "epoch: 3 step: 1856, loss is 0.03817030042409897\n",
      "epoch: 3 step: 1857, loss is 0.02007225900888443\n",
      "epoch: 3 step: 1858, loss is 0.06324116140604019\n",
      "epoch: 3 step: 1859, loss is 0.0016787262866273522\n",
      "epoch: 3 step: 1860, loss is 0.18749991059303284\n",
      "epoch: 3 step: 1861, loss is 0.0008463881677016616\n",
      "epoch: 3 step: 1862, loss is 0.00300598400644958\n",
      "epoch: 3 step: 1863, loss is 0.0007396169239655137\n",
      "epoch: 3 step: 1864, loss is 0.008930029347538948\n",
      "epoch: 3 step: 1865, loss is 0.010039902292191982\n",
      "epoch: 3 step: 1866, loss is 0.005760610569268465\n",
      "epoch: 3 step: 1867, loss is 0.031996872276067734\n",
      "epoch: 3 step: 1868, loss is 0.009837892837822437\n",
      "epoch: 3 step: 1869, loss is 0.0013239295221865177\n",
      "epoch: 3 step: 1870, loss is 0.002501966431736946\n",
      "epoch: 3 step: 1871, loss is 0.015234188176691532\n",
      "epoch: 3 step: 1872, loss is 0.010233934037387371\n",
      "epoch: 3 step: 1873, loss is 0.004180434159934521\n",
      "epoch: 3 step: 1874, loss is 8.382599480682984e-05\n",
      "epoch: 3 step: 1875, loss is 0.004520362243056297\n",
      "epoch: 3 step: 1876, loss is 0.016339492052793503\n",
      "epoch: 3 step: 1877, loss is 0.11232446879148483\n",
      "epoch: 3 step: 1878, loss is 0.09387446939945221\n",
      "epoch: 3 step: 1879, loss is 0.0017779981717467308\n",
      "epoch: 3 step: 1880, loss is 0.042914699763059616\n",
      "epoch: 3 step: 1881, loss is 0.00990948174148798\n",
      "epoch: 3 step: 1882, loss is 0.0258636511862278\n",
      "epoch: 3 step: 1883, loss is 0.007223036605864763\n",
      "epoch: 3 step: 1884, loss is 0.0346854105591774\n",
      "epoch: 3 step: 1885, loss is 0.002052080584689975\n",
      "epoch: 3 step: 1886, loss is 0.0013906325912103057\n",
      "epoch: 3 step: 1887, loss is 0.0017667588545009494\n",
      "epoch: 3 step: 1888, loss is 0.003910254221409559\n",
      "epoch: 3 step: 1889, loss is 0.006028865464031696\n",
      "epoch: 3 step: 1890, loss is 0.009426235221326351\n",
      "epoch: 3 step: 1891, loss is 0.016980871558189392\n",
      "epoch: 3 step: 1892, loss is 0.06331586092710495\n",
      "epoch: 3 step: 1893, loss is 0.08860106021165848\n",
      "epoch: 3 step: 1894, loss is 0.21714317798614502\n",
      "epoch: 3 step: 1895, loss is 0.00031340724672190845\n",
      "epoch: 3 step: 1896, loss is 0.0017251336248591542\n",
      "epoch: 3 step: 1897, loss is 0.04734349995851517\n",
      "epoch: 3 step: 1898, loss is 0.0328468456864357\n",
      "epoch: 3 step: 1899, loss is 0.0006329795578494668\n",
      "epoch: 3 step: 1900, loss is 0.0007360412273555994\n",
      "epoch: 3 step: 1901, loss is 0.010521462187170982\n",
      "epoch: 3 step: 1902, loss is 0.11041309684515\n",
      "epoch: 3 step: 1903, loss is 0.0012415542732924223\n",
      "epoch: 3 step: 1904, loss is 0.02381654642522335\n",
      "epoch: 3 step: 1905, loss is 0.26645463705062866\n",
      "epoch: 3 step: 1906, loss is 0.12134820967912674\n",
      "epoch: 3 step: 1907, loss is 0.07696232199668884\n",
      "epoch: 3 step: 1908, loss is 0.024540020152926445\n",
      "epoch: 3 step: 1909, loss is 0.00306413765065372\n",
      "epoch: 3 step: 1910, loss is 0.04925282672047615\n",
      "epoch: 3 step: 1911, loss is 0.006335814483463764\n",
      "epoch: 3 step: 1912, loss is 0.0005019293166697025\n",
      "epoch: 3 step: 1913, loss is 0.001626617624424398\n",
      "epoch: 3 step: 1914, loss is 0.0003975338477175683\n",
      "epoch: 3 step: 1915, loss is 0.04308832436800003\n",
      "epoch: 3 step: 1916, loss is 0.10246089845895767\n",
      "epoch: 3 step: 1917, loss is 0.01122778095304966\n",
      "epoch: 3 step: 1918, loss is 0.11680234223604202\n",
      "epoch: 3 step: 1919, loss is 0.20774787664413452\n",
      "epoch: 3 step: 1920, loss is 0.0007491220021620393\n",
      "epoch: 3 step: 1921, loss is 0.004041979089379311\n",
      "epoch: 3 step: 1922, loss is 0.008599658496677876\n",
      "epoch: 3 step: 1923, loss is 0.002780304988846183\n",
      "epoch: 3 step: 1924, loss is 0.0008197068818844855\n",
      "epoch: 3 step: 1925, loss is 0.15770955383777618\n",
      "epoch: 3 step: 1926, loss is 0.007935496978461742\n",
      "epoch: 3 step: 1927, loss is 0.03634374961256981\n",
      "epoch: 3 step: 1928, loss is 0.0013912050053477287\n",
      "epoch: 3 step: 1929, loss is 0.12779046595096588\n",
      "epoch: 3 step: 1930, loss is 0.07860900461673737\n",
      "epoch: 3 step: 1931, loss is 0.1269564926624298\n",
      "epoch: 3 step: 1932, loss is 0.045775335282087326\n",
      "epoch: 3 step: 1933, loss is 0.05859866365790367\n",
      "epoch: 3 step: 1934, loss is 0.0034072152338922024\n",
      "epoch: 3 step: 1935, loss is 0.0048407018184661865\n",
      "epoch: 3 step: 1936, loss is 0.04539845511317253\n",
      "epoch: 3 step: 1937, loss is 0.016131538897752762\n",
      "epoch: 3 step: 1938, loss is 0.0009348151506856084\n",
      "epoch: 3 step: 1939, loss is 0.0015009413473308086\n",
      "epoch: 3 step: 1940, loss is 0.013915794901549816\n",
      "epoch: 3 step: 1941, loss is 0.011186161078512669\n",
      "epoch: 3 step: 1942, loss is 0.003751640673726797\n",
      "epoch: 3 step: 1943, loss is 0.008732571266591549\n",
      "epoch: 3 step: 1944, loss is 0.02033323422074318\n",
      "epoch: 3 step: 1945, loss is 0.0018594157882034779\n",
      "epoch: 3 step: 1946, loss is 0.048723530024290085\n",
      "epoch: 3 step: 1947, loss is 0.0017480773385614157\n",
      "epoch: 3 step: 1948, loss is 0.07537560909986496\n",
      "epoch: 3 step: 1949, loss is 0.28291046619415283\n",
      "epoch: 3 step: 1950, loss is 0.03510193154215813\n",
      "epoch: 3 step: 1951, loss is 0.023969212546944618\n",
      "epoch: 3 step: 1952, loss is 0.0021244522649794817\n",
      "epoch: 3 step: 1953, loss is 0.03875654190778732\n",
      "epoch: 3 step: 1954, loss is 0.16319039463996887\n",
      "epoch: 3 step: 1955, loss is 0.004201292060315609\n",
      "epoch: 3 step: 1956, loss is 0.08263910561800003\n",
      "epoch: 3 step: 1957, loss is 0.0371304489672184\n",
      "epoch: 3 step: 1958, loss is 0.004139565862715244\n",
      "epoch: 3 step: 1959, loss is 0.18493157625198364\n",
      "epoch: 3 step: 1960, loss is 0.015571728348731995\n",
      "epoch: 3 step: 1961, loss is 0.04479781165719032\n",
      "epoch: 3 step: 1962, loss is 0.01103739719837904\n",
      "epoch: 3 step: 1963, loss is 0.019930332899093628\n",
      "epoch: 3 step: 1964, loss is 0.003919289447367191\n",
      "epoch: 3 step: 1965, loss is 0.7087989449501038\n",
      "epoch: 3 step: 1966, loss is 0.0029804203659296036\n",
      "epoch: 3 step: 1967, loss is 0.02097497507929802\n",
      "epoch: 3 step: 1968, loss is 0.06491903215646744\n",
      "epoch: 3 step: 1969, loss is 0.18821236491203308\n",
      "epoch: 3 step: 1970, loss is 0.023004023358225822\n",
      "epoch: 3 step: 1971, loss is 0.005547122098505497\n",
      "epoch: 3 step: 1972, loss is 0.009722896851599216\n",
      "epoch: 3 step: 1973, loss is 0.011561752296984196\n",
      "epoch: 3 step: 1974, loss is 0.03999626636505127\n",
      "epoch: 3 step: 1975, loss is 0.06856665015220642\n",
      "epoch: 3 step: 1976, loss is 0.004149645566940308\n",
      "epoch: 3 step: 1977, loss is 0.013378025963902473\n",
      "epoch: 3 step: 1978, loss is 0.023238593712449074\n",
      "epoch: 3 step: 1979, loss is 0.00794108584523201\n",
      "epoch: 3 step: 1980, loss is 0.006794809363782406\n",
      "epoch: 3 step: 1981, loss is 0.012711066752672195\n",
      "epoch: 3 step: 1982, loss is 0.048898473381996155\n",
      "epoch: 3 step: 1983, loss is 0.03680037334561348\n",
      "epoch: 3 step: 1984, loss is 0.011675954796373844\n",
      "epoch: 3 step: 1985, loss is 0.0008564837044104934\n",
      "epoch: 3 step: 1986, loss is 0.0035525166895240545\n",
      "epoch: 3 step: 1987, loss is 0.0008896305807866156\n",
      "epoch: 3 step: 1988, loss is 0.059894632548093796\n",
      "epoch: 3 step: 1989, loss is 0.004114300943911076\n",
      "epoch: 3 step: 1990, loss is 0.037570081651210785\n",
      "epoch: 3 step: 1991, loss is 0.0024493313394486904\n",
      "epoch: 3 step: 1992, loss is 0.003501076018437743\n",
      "epoch: 3 step: 1993, loss is 0.18443213403224945\n",
      "epoch: 3 step: 1994, loss is 0.05894779786467552\n",
      "epoch: 3 step: 1995, loss is 0.02759154513478279\n",
      "epoch: 3 step: 1996, loss is 0.26857897639274597\n",
      "epoch: 3 step: 1997, loss is 0.0695912316441536\n",
      "epoch: 3 step: 1998, loss is 0.004011481534689665\n",
      "epoch: 3 step: 1999, loss is 0.02976701408624649\n",
      "epoch: 3 step: 2000, loss is 0.009467815980315208\n",
      "epoch: 3 step: 2001, loss is 0.06120067462325096\n",
      "epoch: 3 step: 2002, loss is 0.015688925981521606\n",
      "epoch: 3 step: 2003, loss is 0.024518294259905815\n",
      "epoch: 3 step: 2004, loss is 0.001102027716115117\n",
      "epoch: 3 step: 2005, loss is 0.00150869763456285\n",
      "epoch: 3 step: 2006, loss is 0.08231458812952042\n",
      "epoch: 3 step: 2007, loss is 0.0005529389018192887\n",
      "epoch: 3 step: 2008, loss is 0.0010689293267205358\n",
      "epoch: 3 step: 2009, loss is 0.008384332992136478\n",
      "epoch: 3 step: 2010, loss is 0.002492271363735199\n",
      "epoch: 3 step: 2011, loss is 0.0023576586972922087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 2012, loss is 0.0659768283367157\n",
      "epoch: 3 step: 2013, loss is 0.0014390498399734497\n",
      "epoch: 3 step: 2014, loss is 0.027470823377370834\n",
      "epoch: 3 step: 2015, loss is 0.0005876323557458818\n",
      "epoch: 3 step: 2016, loss is 0.004149707965552807\n",
      "epoch: 3 step: 2017, loss is 0.000871131953317672\n",
      "epoch: 3 step: 2018, loss is 0.00701764365658164\n",
      "epoch: 3 step: 2019, loss is 0.029281282797455788\n",
      "epoch: 3 step: 2020, loss is 0.0020544235594570637\n",
      "epoch: 3 step: 2021, loss is 0.012280737981200218\n",
      "epoch: 3 step: 2022, loss is 0.18241386115550995\n",
      "epoch: 3 step: 2023, loss is 0.10919485241174698\n",
      "epoch: 3 step: 2024, loss is 0.010018293745815754\n",
      "epoch: 3 step: 2025, loss is 0.002504447242245078\n",
      "epoch: 3 step: 2026, loss is 0.07289514690637589\n",
      "epoch: 3 step: 2027, loss is 0.005940879695117474\n",
      "epoch: 3 step: 2028, loss is 0.004666863474994898\n",
      "epoch: 3 step: 2029, loss is 0.018241170793771744\n",
      "epoch: 3 step: 2030, loss is 0.12274883687496185\n",
      "epoch: 3 step: 2031, loss is 0.0008620674489066005\n",
      "epoch: 3 step: 2032, loss is 0.08569991588592529\n",
      "epoch: 3 step: 2033, loss is 0.06256945431232452\n",
      "epoch: 3 step: 2034, loss is 0.000716589333023876\n",
      "epoch: 3 step: 2035, loss is 0.0032155662775039673\n",
      "epoch: 3 step: 2036, loss is 0.019654927775263786\n",
      "epoch: 3 step: 2037, loss is 0.029776528477668762\n",
      "epoch: 3 step: 2038, loss is 0.03418663516640663\n",
      "epoch: 3 step: 2039, loss is 0.01815750263631344\n",
      "epoch: 3 step: 2040, loss is 0.0017107134917750955\n",
      "epoch: 3 step: 2041, loss is 0.0005880107637494802\n",
      "epoch: 3 step: 2042, loss is 0.0213245190680027\n",
      "epoch: 3 step: 2043, loss is 0.26746612787246704\n",
      "epoch: 3 step: 2044, loss is 0.003595503978431225\n",
      "epoch: 3 step: 2045, loss is 0.0020995107479393482\n",
      "epoch: 3 step: 2046, loss is 0.009011423215270042\n",
      "epoch: 3 step: 2047, loss is 0.12932783365249634\n",
      "epoch: 3 step: 2048, loss is 0.004287661053240299\n",
      "epoch: 3 step: 2049, loss is 0.045169733464717865\n",
      "epoch: 3 step: 2050, loss is 0.00292911846190691\n",
      "epoch: 3 step: 2051, loss is 0.0018530705710873008\n",
      "epoch: 3 step: 2052, loss is 0.002163183642551303\n",
      "epoch: 3 step: 2053, loss is 0.021293459460139275\n",
      "epoch: 3 step: 2054, loss is 0.003841054392978549\n",
      "epoch: 3 step: 2055, loss is 0.06604982912540436\n",
      "epoch: 3 step: 2056, loss is 0.00720168137922883\n",
      "epoch: 3 step: 2057, loss is 0.05209248140454292\n",
      "epoch: 3 step: 2058, loss is 0.05286542326211929\n",
      "epoch: 3 step: 2059, loss is 0.062438685446977615\n",
      "epoch: 3 step: 2060, loss is 0.11788859218358994\n",
      "epoch: 3 step: 2061, loss is 0.07726559787988663\n",
      "epoch: 3 step: 2062, loss is 0.22867612540721893\n",
      "epoch: 3 step: 2063, loss is 0.008055044338107109\n",
      "epoch: 3 step: 2064, loss is 0.012890036217868328\n",
      "epoch: 3 step: 2065, loss is 0.06826947629451752\n",
      "epoch: 3 step: 2066, loss is 0.002255053259432316\n",
      "epoch: 3 step: 2067, loss is 0.0006509413360618055\n",
      "epoch: 3 step: 2068, loss is 0.06147308275103569\n",
      "epoch: 3 step: 2069, loss is 0.03344034031033516\n",
      "epoch: 3 step: 2070, loss is 0.06308265030384064\n",
      "epoch: 3 step: 2071, loss is 0.1842130422592163\n",
      "epoch: 3 step: 2072, loss is 0.009712846018373966\n",
      "epoch: 3 step: 2073, loss is 0.022510671988129616\n",
      "epoch: 3 step: 2074, loss is 0.054403048008680344\n",
      "epoch: 3 step: 2075, loss is 0.0006000815774314106\n",
      "epoch: 3 step: 2076, loss is 0.020449260249733925\n",
      "epoch: 3 step: 2077, loss is 0.030880942940711975\n",
      "epoch: 3 step: 2078, loss is 0.15198522806167603\n",
      "epoch: 3 step: 2079, loss is 0.028541872277855873\n",
      "epoch: 3 step: 2080, loss is 0.08774519711732864\n",
      "epoch: 3 step: 2081, loss is 0.04470648989081383\n",
      "epoch: 3 step: 2082, loss is 0.059233859181404114\n",
      "epoch: 3 step: 2083, loss is 0.0008978849509730935\n",
      "epoch: 3 step: 2084, loss is 0.07241655886173248\n",
      "epoch: 3 step: 2085, loss is 0.014682117849588394\n",
      "epoch: 3 step: 2086, loss is 0.03834177926182747\n",
      "epoch: 3 step: 2087, loss is 0.020570235326886177\n",
      "epoch: 3 step: 2088, loss is 0.008916563354432583\n",
      "epoch: 3 step: 2089, loss is 0.012399043887853622\n",
      "epoch: 3 step: 2090, loss is 0.04074884206056595\n",
      "epoch: 3 step: 2091, loss is 0.03167745843529701\n",
      "epoch: 3 step: 2092, loss is 0.04961692914366722\n",
      "epoch: 3 step: 2093, loss is 0.011042247526347637\n",
      "epoch: 3 step: 2094, loss is 0.00927920825779438\n",
      "epoch: 3 step: 2095, loss is 0.002349543385207653\n",
      "epoch: 3 step: 2096, loss is 0.06697511672973633\n",
      "epoch: 3 step: 2097, loss is 0.04018080234527588\n",
      "epoch: 3 step: 2098, loss is 0.04250304028391838\n",
      "epoch: 3 step: 2099, loss is 0.018283983692526817\n",
      "epoch: 3 step: 2100, loss is 0.0005301308701746166\n",
      "epoch: 3 step: 2101, loss is 0.02314627915620804\n",
      "epoch: 3 step: 2102, loss is 0.0006728302105329931\n",
      "epoch: 3 step: 2103, loss is 0.0011868065921589732\n",
      "epoch: 3 step: 2104, loss is 0.09548084437847137\n",
      "epoch: 3 step: 2105, loss is 0.06154215335845947\n",
      "epoch: 3 step: 2106, loss is 0.039963334798812866\n",
      "epoch: 3 step: 2107, loss is 0.011168273165822029\n",
      "epoch: 3 step: 2108, loss is 0.07483957707881927\n",
      "epoch: 3 step: 2109, loss is 0.013957653194665909\n",
      "epoch: 3 step: 2110, loss is 0.002694632625207305\n",
      "epoch: 3 step: 2111, loss is 0.00903287436813116\n",
      "epoch: 3 step: 2112, loss is 0.02316260151565075\n",
      "epoch: 3 step: 2113, loss is 0.019539181143045425\n",
      "epoch: 3 step: 2114, loss is 0.007859757170081139\n",
      "epoch: 3 step: 2115, loss is 0.023191655054688454\n",
      "epoch: 3 step: 2116, loss is 0.0069901542738080025\n",
      "epoch: 3 step: 2117, loss is 0.03667275235056877\n",
      "epoch: 3 step: 2118, loss is 0.005417580716311932\n",
      "epoch: 3 step: 2119, loss is 0.00038477295311167836\n",
      "epoch: 3 step: 2120, loss is 0.012310950085520744\n",
      "epoch: 3 step: 2121, loss is 0.0266574639827013\n",
      "epoch: 3 step: 2122, loss is 0.0025473767891526222\n",
      "epoch: 3 step: 2123, loss is 0.09068368375301361\n",
      "epoch: 3 step: 2124, loss is 0.057520586997270584\n",
      "epoch: 3 step: 2125, loss is 0.12049247324466705\n",
      "epoch: 3 step: 2126, loss is 0.0008440886740572751\n",
      "epoch: 3 step: 2127, loss is 0.007533265743404627\n",
      "epoch: 3 step: 2128, loss is 0.0011431585298851132\n",
      "epoch: 3 step: 2129, loss is 0.004137744661420584\n",
      "epoch: 3 step: 2130, loss is 0.10337401926517487\n",
      "epoch: 3 step: 2131, loss is 0.07521813362836838\n",
      "epoch: 3 step: 2132, loss is 0.16800861060619354\n",
      "epoch: 3 step: 2133, loss is 0.22047799825668335\n",
      "epoch: 3 step: 2134, loss is 0.0024160905741155148\n",
      "epoch: 3 step: 2135, loss is 0.00025719916447997093\n",
      "epoch: 3 step: 2136, loss is 0.011550418101251125\n",
      "epoch: 3 step: 2137, loss is 0.009254537522792816\n",
      "epoch: 3 step: 2138, loss is 0.0014746354427188635\n",
      "epoch: 3 step: 2139, loss is 0.03644748777151108\n",
      "epoch: 3 step: 2140, loss is 0.008449138142168522\n",
      "epoch: 3 step: 2141, loss is 0.0037421018350869417\n",
      "epoch: 3 step: 2142, loss is 0.000767027959227562\n",
      "epoch: 3 step: 2143, loss is 0.03951052203774452\n",
      "epoch: 3 step: 2144, loss is 0.024179751053452492\n",
      "epoch: 3 step: 2145, loss is 0.0022204651031643152\n",
      "epoch: 3 step: 2146, loss is 0.044871736317873\n",
      "epoch: 3 step: 2147, loss is 0.0015755579806864262\n",
      "epoch: 3 step: 2148, loss is 0.0017046872526407242\n",
      "epoch: 3 step: 2149, loss is 0.17017406225204468\n",
      "epoch: 3 step: 2150, loss is 0.028788980096578598\n",
      "epoch: 3 step: 2151, loss is 0.1187358871102333\n",
      "epoch: 3 step: 2152, loss is 0.0002861515968106687\n",
      "epoch: 3 step: 2153, loss is 0.02651623636484146\n",
      "epoch: 3 step: 2154, loss is 0.0023576158564537764\n",
      "epoch: 3 step: 2155, loss is 0.1268978714942932\n",
      "epoch: 3 step: 2156, loss is 0.0002396516065346077\n",
      "epoch: 3 step: 2157, loss is 0.0793391689658165\n",
      "epoch: 3 step: 2158, loss is 0.0006594556616619229\n",
      "epoch: 3 step: 2159, loss is 0.002142596058547497\n",
      "epoch: 3 step: 2160, loss is 0.02136385068297386\n",
      "epoch: 3 step: 2161, loss is 0.004927928559482098\n",
      "epoch: 3 step: 2162, loss is 0.026785437017679214\n",
      "epoch: 3 step: 2163, loss is 0.07078030705451965\n",
      "epoch: 3 step: 2164, loss is 0.002666299697011709\n",
      "epoch: 3 step: 2165, loss is 0.0016609716694802046\n",
      "epoch: 3 step: 2166, loss is 0.0013986974954605103\n",
      "epoch: 3 step: 2167, loss is 0.07512984424829483\n",
      "epoch: 3 step: 2168, loss is 0.01827304996550083\n",
      "epoch: 3 step: 2169, loss is 0.022195130586624146\n",
      "epoch: 3 step: 2170, loss is 0.01662272773683071\n",
      "epoch: 3 step: 2171, loss is 0.0021799502428621054\n",
      "epoch: 3 step: 2172, loss is 0.0003889824147336185\n",
      "epoch: 3 step: 2173, loss is 0.06726453453302383\n",
      "epoch: 3 step: 2174, loss is 0.014906206168234348\n",
      "epoch: 3 step: 2175, loss is 0.0005207357462495565\n",
      "epoch: 3 step: 2176, loss is 0.010959779843688011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 2177, loss is 0.01368491631001234\n",
      "epoch: 3 step: 2178, loss is 0.13971421122550964\n",
      "epoch: 3 step: 2179, loss is 0.0030262579675763845\n",
      "epoch: 3 step: 2180, loss is 0.04240600764751434\n",
      "epoch: 3 step: 2181, loss is 0.08737480640411377\n",
      "epoch: 3 step: 2182, loss is 0.0031176041811704636\n",
      "epoch: 3 step: 2183, loss is 0.006440145894885063\n",
      "epoch: 3 step: 2184, loss is 0.09578009694814682\n",
      "epoch: 3 step: 2185, loss is 0.07547813653945923\n",
      "epoch: 3 step: 2186, loss is 0.0004797744331881404\n",
      "epoch: 3 step: 2187, loss is 0.020599599927663803\n",
      "epoch: 4 step: 1, loss is 0.0038974552880972624\n",
      "epoch: 4 step: 2, loss is 0.003847783897072077\n",
      "epoch: 4 step: 3, loss is 0.00022964119852986187\n",
      "epoch: 4 step: 4, loss is 0.22100453078746796\n",
      "epoch: 4 step: 5, loss is 0.007212646305561066\n",
      "epoch: 4 step: 6, loss is 0.02271612547338009\n",
      "epoch: 4 step: 7, loss is 0.01761390082538128\n",
      "epoch: 4 step: 8, loss is 0.03540951386094093\n",
      "epoch: 4 step: 9, loss is 0.05590544268488884\n",
      "epoch: 4 step: 10, loss is 0.19151225686073303\n",
      "epoch: 4 step: 11, loss is 0.1515330821275711\n",
      "epoch: 4 step: 12, loss is 0.22287310659885406\n",
      "epoch: 4 step: 13, loss is 0.0012221263023093343\n",
      "epoch: 4 step: 14, loss is 0.04422512650489807\n",
      "epoch: 4 step: 15, loss is 0.0006265768315643072\n",
      "epoch: 4 step: 16, loss is 0.005591084249317646\n",
      "epoch: 4 step: 17, loss is 0.0038926813285797834\n",
      "epoch: 4 step: 18, loss is 0.012826303951442242\n",
      "epoch: 4 step: 19, loss is 0.03912945091724396\n",
      "epoch: 4 step: 20, loss is 0.02602180652320385\n",
      "epoch: 4 step: 21, loss is 0.01224685087800026\n",
      "epoch: 4 step: 22, loss is 0.32291802763938904\n",
      "epoch: 4 step: 23, loss is 0.030201448127627373\n",
      "epoch: 4 step: 24, loss is 0.017525924369692802\n",
      "epoch: 4 step: 25, loss is 0.03614698722958565\n",
      "epoch: 4 step: 26, loss is 0.045137565582990646\n",
      "epoch: 4 step: 27, loss is 0.08964276313781738\n",
      "epoch: 4 step: 28, loss is 0.01013079471886158\n",
      "epoch: 4 step: 29, loss is 0.0033399288076907396\n",
      "epoch: 4 step: 30, loss is 0.017817314714193344\n",
      "epoch: 4 step: 31, loss is 0.09664508700370789\n",
      "epoch: 4 step: 32, loss is 0.004993881098926067\n",
      "epoch: 4 step: 33, loss is 0.0008098910329863429\n",
      "epoch: 4 step: 34, loss is 0.1594453752040863\n",
      "epoch: 4 step: 35, loss is 0.013513597659766674\n",
      "epoch: 4 step: 36, loss is 0.1956138163805008\n",
      "epoch: 4 step: 37, loss is 0.006990653462707996\n",
      "epoch: 4 step: 38, loss is 0.013693948276340961\n",
      "epoch: 4 step: 39, loss is 0.02167903631925583\n",
      "epoch: 4 step: 40, loss is 0.15842771530151367\n",
      "epoch: 4 step: 41, loss is 0.0571785531938076\n",
      "epoch: 4 step: 42, loss is 0.005926691927015781\n",
      "epoch: 4 step: 43, loss is 0.003751841839402914\n",
      "epoch: 4 step: 44, loss is 0.009571690112352371\n",
      "epoch: 4 step: 45, loss is 0.0019994163885712624\n",
      "epoch: 4 step: 46, loss is 0.00043048348743468523\n",
      "epoch: 4 step: 47, loss is 0.006416442804038525\n",
      "epoch: 4 step: 48, loss is 0.012174881063401699\n",
      "epoch: 4 step: 49, loss is 0.021481765434145927\n",
      "epoch: 4 step: 50, loss is 0.12704989314079285\n",
      "epoch: 4 step: 51, loss is 0.002101955935359001\n",
      "epoch: 4 step: 52, loss is 0.14362919330596924\n",
      "epoch: 4 step: 53, loss is 0.002016200451180339\n",
      "epoch: 4 step: 54, loss is 0.007125865202397108\n",
      "epoch: 4 step: 55, loss is 0.0063185556791722775\n",
      "epoch: 4 step: 56, loss is 0.0709366723895073\n",
      "epoch: 4 step: 57, loss is 0.047902997583150864\n",
      "epoch: 4 step: 58, loss is 0.00067008106270805\n",
      "epoch: 4 step: 59, loss is 0.003430993529036641\n",
      "epoch: 4 step: 60, loss is 0.012728984467685223\n",
      "epoch: 4 step: 61, loss is 0.00109603232704103\n",
      "epoch: 4 step: 62, loss is 0.03087165206670761\n",
      "epoch: 4 step: 63, loss is 0.014293283224105835\n",
      "epoch: 4 step: 64, loss is 0.023177659139037132\n",
      "epoch: 4 step: 65, loss is 0.002126299776136875\n",
      "epoch: 4 step: 66, loss is 0.06628648191690445\n",
      "epoch: 4 step: 67, loss is 0.07703391462564468\n",
      "epoch: 4 step: 68, loss is 0.0006097553414292634\n",
      "epoch: 4 step: 69, loss is 0.06509952247142792\n",
      "epoch: 4 step: 70, loss is 0.04611120745539665\n",
      "epoch: 4 step: 71, loss is 0.020535921677947044\n",
      "epoch: 4 step: 72, loss is 0.0009873636299744248\n",
      "epoch: 4 step: 73, loss is 0.01085335947573185\n",
      "epoch: 4 step: 74, loss is 0.07776261121034622\n",
      "epoch: 4 step: 75, loss is 0.0024664446245878935\n",
      "epoch: 4 step: 76, loss is 0.03202538564801216\n",
      "epoch: 4 step: 77, loss is 0.006260976195335388\n",
      "epoch: 4 step: 78, loss is 0.004178231116384268\n",
      "epoch: 4 step: 79, loss is 0.0018168921815231442\n",
      "epoch: 4 step: 80, loss is 0.0019606018904596567\n",
      "epoch: 4 step: 81, loss is 0.003165080677717924\n",
      "epoch: 4 step: 82, loss is 0.038788802921772\n",
      "epoch: 4 step: 83, loss is 0.02558870241045952\n",
      "epoch: 4 step: 84, loss is 0.009919170290231705\n",
      "epoch: 4 step: 85, loss is 0.06749846786260605\n",
      "epoch: 4 step: 86, loss is 0.057483043521642685\n",
      "epoch: 4 step: 87, loss is 0.002146349521353841\n",
      "epoch: 4 step: 88, loss is 0.0015785673167556524\n",
      "epoch: 4 step: 89, loss is 0.011756866239011288\n",
      "epoch: 4 step: 90, loss is 0.05764101445674896\n",
      "epoch: 4 step: 91, loss is 0.36471888422966003\n",
      "epoch: 4 step: 92, loss is 0.07984478771686554\n",
      "epoch: 4 step: 93, loss is 0.005731169134378433\n",
      "epoch: 4 step: 94, loss is 0.2624305784702301\n",
      "epoch: 4 step: 95, loss is 0.002697806106880307\n",
      "epoch: 4 step: 96, loss is 0.030094174668192863\n",
      "epoch: 4 step: 97, loss is 0.06409727782011032\n",
      "epoch: 4 step: 98, loss is 0.0025441604666411877\n",
      "epoch: 4 step: 99, loss is 0.024590451270341873\n",
      "epoch: 4 step: 100, loss is 0.0017359458142891526\n",
      "epoch: 4 step: 101, loss is 0.002828284865245223\n",
      "epoch: 4 step: 102, loss is 0.043774865567684174\n",
      "epoch: 4 step: 103, loss is 0.004786563105881214\n",
      "epoch: 4 step: 104, loss is 0.011846505105495453\n",
      "epoch: 4 step: 105, loss is 0.002910183509811759\n",
      "epoch: 4 step: 106, loss is 0.10113506019115448\n",
      "epoch: 4 step: 107, loss is 0.005168895702809095\n",
      "epoch: 4 step: 108, loss is 0.06445363163948059\n",
      "epoch: 4 step: 109, loss is 0.001325842342339456\n",
      "epoch: 4 step: 110, loss is 0.03594139218330383\n",
      "epoch: 4 step: 111, loss is 0.0036539873108267784\n",
      "epoch: 4 step: 112, loss is 0.0961356833577156\n",
      "epoch: 4 step: 113, loss is 0.001267186482436955\n",
      "epoch: 4 step: 114, loss is 0.2887933850288391\n",
      "epoch: 4 step: 115, loss is 0.11622599512338638\n",
      "epoch: 4 step: 116, loss is 0.011595772579312325\n",
      "epoch: 4 step: 117, loss is 0.002246301621198654\n",
      "epoch: 4 step: 118, loss is 0.0021937210112810135\n",
      "epoch: 4 step: 119, loss is 0.04505923017859459\n",
      "epoch: 4 step: 120, loss is 0.0031346972100436687\n",
      "epoch: 4 step: 121, loss is 0.026233231648802757\n",
      "epoch: 4 step: 122, loss is 0.0012589485850185156\n",
      "epoch: 4 step: 123, loss is 0.03768547996878624\n",
      "epoch: 4 step: 124, loss is 0.0011129938066005707\n",
      "epoch: 4 step: 125, loss is 0.10406830906867981\n",
      "epoch: 4 step: 126, loss is 0.06901690363883972\n",
      "epoch: 4 step: 127, loss is 0.0024617048911750317\n",
      "epoch: 4 step: 128, loss is 0.006219761911779642\n",
      "epoch: 4 step: 129, loss is 0.001463877153582871\n",
      "epoch: 4 step: 130, loss is 0.00616308581084013\n",
      "epoch: 4 step: 131, loss is 0.001975607592612505\n",
      "epoch: 4 step: 132, loss is 0.008851615712046623\n",
      "epoch: 4 step: 133, loss is 0.003335534129291773\n",
      "epoch: 4 step: 134, loss is 0.018746482208371162\n",
      "epoch: 4 step: 135, loss is 0.002391334855929017\n",
      "epoch: 4 step: 136, loss is 0.05834994092583656\n",
      "epoch: 4 step: 137, loss is 0.007321896031498909\n",
      "epoch: 4 step: 138, loss is 0.0764274001121521\n",
      "epoch: 4 step: 139, loss is 0.11107317358255386\n",
      "epoch: 4 step: 140, loss is 0.011081483215093613\n",
      "epoch: 4 step: 141, loss is 0.005293125752359629\n",
      "epoch: 4 step: 142, loss is 0.003581474767997861\n",
      "epoch: 4 step: 143, loss is 0.0325833261013031\n",
      "epoch: 4 step: 144, loss is 0.007471836172044277\n",
      "epoch: 4 step: 145, loss is 0.0009133077692240477\n",
      "epoch: 4 step: 146, loss is 0.14681093394756317\n",
      "epoch: 4 step: 147, loss is 0.17000238597393036\n",
      "epoch: 4 step: 148, loss is 0.06219926103949547\n",
      "epoch: 4 step: 149, loss is 0.011899604462087154\n",
      "epoch: 4 step: 150, loss is 0.008052160032093525\n",
      "epoch: 4 step: 151, loss is 0.027033235877752304\n",
      "epoch: 4 step: 152, loss is 0.012019223533570766\n",
      "epoch: 4 step: 153, loss is 0.017896540462970734\n",
      "epoch: 4 step: 154, loss is 0.0011210483498871326\n",
      "epoch: 4 step: 155, loss is 0.02827644720673561\n",
      "epoch: 4 step: 156, loss is 0.0536063089966774\n",
      "epoch: 4 step: 157, loss is 0.003638916416093707\n",
      "epoch: 4 step: 158, loss is 0.0013483682414516807\n",
      "epoch: 4 step: 159, loss is 0.007139775902032852\n",
      "epoch: 4 step: 160, loss is 0.002829419681802392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 161, loss is 0.006886345334351063\n",
      "epoch: 4 step: 162, loss is 0.021806376054883003\n",
      "epoch: 4 step: 163, loss is 0.009680360555648804\n",
      "epoch: 4 step: 164, loss is 0.0015730231534689665\n",
      "epoch: 4 step: 165, loss is 0.02027696929872036\n",
      "epoch: 4 step: 166, loss is 0.013717396184802055\n",
      "epoch: 4 step: 167, loss is 0.0027103067841380835\n",
      "epoch: 4 step: 168, loss is 0.012032424099743366\n",
      "epoch: 4 step: 169, loss is 0.043441291898489\n",
      "epoch: 4 step: 170, loss is 0.0336020365357399\n",
      "epoch: 4 step: 171, loss is 0.04411832243204117\n",
      "epoch: 4 step: 172, loss is 0.140692800283432\n",
      "epoch: 4 step: 173, loss is 0.16978120803833008\n",
      "epoch: 4 step: 174, loss is 0.0020752246491611004\n",
      "epoch: 4 step: 175, loss is 0.03546890243887901\n",
      "epoch: 4 step: 176, loss is 0.010607401840388775\n",
      "epoch: 4 step: 177, loss is 0.1299770325422287\n",
      "epoch: 4 step: 178, loss is 0.004610906820744276\n",
      "epoch: 4 step: 179, loss is 0.00034977341420017183\n",
      "epoch: 4 step: 180, loss is 0.0010196485091000795\n",
      "epoch: 4 step: 181, loss is 0.03527397662401199\n",
      "epoch: 4 step: 182, loss is 0.003016849746927619\n",
      "epoch: 4 step: 183, loss is 0.10017095506191254\n",
      "epoch: 4 step: 184, loss is 0.004972217604517937\n",
      "epoch: 4 step: 185, loss is 0.009517667815089226\n",
      "epoch: 4 step: 186, loss is 0.0023357351310551167\n",
      "epoch: 4 step: 187, loss is 0.1258975714445114\n",
      "epoch: 4 step: 188, loss is 0.030241068452596664\n",
      "epoch: 4 step: 189, loss is 0.08304057270288467\n",
      "epoch: 4 step: 190, loss is 0.06558171659708023\n",
      "epoch: 4 step: 191, loss is 0.003575701965019107\n",
      "epoch: 4 step: 192, loss is 0.02414005436003208\n",
      "epoch: 4 step: 193, loss is 0.037597112357616425\n",
      "epoch: 4 step: 194, loss is 0.003719778498634696\n",
      "epoch: 4 step: 195, loss is 0.0030197687447071075\n",
      "epoch: 4 step: 196, loss is 0.009183964692056179\n",
      "epoch: 4 step: 197, loss is 0.0008743248763494194\n",
      "epoch: 4 step: 198, loss is 0.006428879220038652\n",
      "epoch: 4 step: 199, loss is 0.007672404404729605\n",
      "epoch: 4 step: 200, loss is 0.05846580117940903\n",
      "epoch: 4 step: 201, loss is 0.000608396134339273\n",
      "epoch: 4 step: 202, loss is 0.004104927182197571\n",
      "epoch: 4 step: 203, loss is 0.0022380549926310778\n",
      "epoch: 4 step: 204, loss is 0.12293403595685959\n",
      "epoch: 4 step: 205, loss is 0.0004800673632416874\n",
      "epoch: 4 step: 206, loss is 0.00046251193271018565\n",
      "epoch: 4 step: 207, loss is 0.04014277458190918\n",
      "epoch: 4 step: 208, loss is 0.0048614321276545525\n",
      "epoch: 4 step: 209, loss is 0.033611781895160675\n",
      "epoch: 4 step: 210, loss is 0.09679273515939713\n",
      "epoch: 4 step: 211, loss is 0.05096345394849777\n",
      "epoch: 4 step: 212, loss is 0.0032620925921946764\n",
      "epoch: 4 step: 213, loss is 0.0017242624890059233\n",
      "epoch: 4 step: 214, loss is 0.0175493024289608\n",
      "epoch: 4 step: 215, loss is 0.008468949235975742\n",
      "epoch: 4 step: 216, loss is 0.03138011693954468\n",
      "epoch: 4 step: 217, loss is 0.0005714504513889551\n",
      "epoch: 4 step: 218, loss is 0.03170176222920418\n",
      "epoch: 4 step: 219, loss is 0.0027017095126211643\n",
      "epoch: 4 step: 220, loss is 0.0016709621995687485\n",
      "epoch: 4 step: 221, loss is 0.06551169604063034\n",
      "epoch: 4 step: 222, loss is 0.0005849828012287617\n",
      "epoch: 4 step: 223, loss is 0.02658785693347454\n",
      "epoch: 4 step: 224, loss is 0.001859067240729928\n",
      "epoch: 4 step: 225, loss is 0.08057969063520432\n",
      "epoch: 4 step: 226, loss is 0.027033329010009766\n",
      "epoch: 4 step: 227, loss is 0.002738794544711709\n",
      "epoch: 4 step: 228, loss is 0.008005372248589993\n",
      "epoch: 4 step: 229, loss is 0.002204063581302762\n",
      "epoch: 4 step: 230, loss is 0.028225693851709366\n",
      "epoch: 4 step: 231, loss is 0.0007597743533551693\n",
      "epoch: 4 step: 232, loss is 0.016378842294216156\n",
      "epoch: 4 step: 233, loss is 0.004968269728124142\n",
      "epoch: 4 step: 234, loss is 0.0010734888492152095\n",
      "epoch: 4 step: 235, loss is 0.05164942890405655\n",
      "epoch: 4 step: 236, loss is 0.00021464833116624504\n",
      "epoch: 4 step: 237, loss is 0.007330610416829586\n",
      "epoch: 4 step: 238, loss is 0.02620091661810875\n",
      "epoch: 4 step: 239, loss is 0.0004051710129715502\n",
      "epoch: 4 step: 240, loss is 0.1201748475432396\n",
      "epoch: 4 step: 241, loss is 0.005933241453021765\n",
      "epoch: 4 step: 242, loss is 0.01311210636049509\n",
      "epoch: 4 step: 243, loss is 0.05103042721748352\n",
      "epoch: 4 step: 244, loss is 0.022565312683582306\n",
      "epoch: 4 step: 245, loss is 0.0030657644383609295\n",
      "epoch: 4 step: 246, loss is 0.001355624757707119\n",
      "epoch: 4 step: 247, loss is 0.0009169313707388937\n",
      "epoch: 4 step: 248, loss is 0.003499478567391634\n",
      "epoch: 4 step: 249, loss is 0.0011900389799848199\n",
      "epoch: 4 step: 250, loss is 0.0054329088889062405\n",
      "epoch: 4 step: 251, loss is 0.0031886606011539698\n",
      "epoch: 4 step: 252, loss is 0.002306247130036354\n",
      "epoch: 4 step: 253, loss is 0.0008912975899875164\n",
      "epoch: 4 step: 254, loss is 0.0004115006304346025\n",
      "epoch: 4 step: 255, loss is 0.006251321639865637\n",
      "epoch: 4 step: 256, loss is 0.000933359726332128\n",
      "epoch: 4 step: 257, loss is 0.007527758367359638\n",
      "epoch: 4 step: 258, loss is 0.0022620444651693106\n",
      "epoch: 4 step: 259, loss is 0.0014534932561218739\n",
      "epoch: 4 step: 260, loss is 0.002441179007291794\n",
      "epoch: 4 step: 261, loss is 0.00015217778855003417\n",
      "epoch: 4 step: 262, loss is 0.16569878160953522\n",
      "epoch: 4 step: 263, loss is 0.0002374391769990325\n",
      "epoch: 4 step: 264, loss is 0.02892148308455944\n",
      "epoch: 4 step: 265, loss is 0.01024477556347847\n",
      "epoch: 4 step: 266, loss is 0.01591774821281433\n",
      "epoch: 4 step: 267, loss is 0.04200594872236252\n",
      "epoch: 4 step: 268, loss is 0.036061421036720276\n",
      "epoch: 4 step: 269, loss is 0.010342068038880825\n",
      "epoch: 4 step: 270, loss is 0.0005578473210334778\n",
      "epoch: 4 step: 271, loss is 0.005594324320554733\n",
      "epoch: 4 step: 272, loss is 0.016476867720484734\n",
      "epoch: 4 step: 273, loss is 0.017660513520240784\n",
      "epoch: 4 step: 274, loss is 0.004371402785181999\n",
      "epoch: 4 step: 275, loss is 0.0003808467590715736\n",
      "epoch: 4 step: 276, loss is 0.0006425123428925872\n",
      "epoch: 4 step: 277, loss is 0.001746071269735694\n",
      "epoch: 4 step: 278, loss is 0.002384395804256201\n",
      "epoch: 4 step: 279, loss is 0.0423792339861393\n",
      "epoch: 4 step: 280, loss is 0.053120579570531845\n",
      "epoch: 4 step: 281, loss is 0.0010497033363208175\n",
      "epoch: 4 step: 282, loss is 0.1276269108057022\n",
      "epoch: 4 step: 283, loss is 0.004115642048418522\n",
      "epoch: 4 step: 284, loss is 0.00065189617453143\n",
      "epoch: 4 step: 285, loss is 0.009191198274493217\n",
      "epoch: 4 step: 286, loss is 0.09075946360826492\n",
      "epoch: 4 step: 287, loss is 0.005439296830445528\n",
      "epoch: 4 step: 288, loss is 0.0013704744633287191\n",
      "epoch: 4 step: 289, loss is 0.002927500521764159\n",
      "epoch: 4 step: 290, loss is 0.011949076317250729\n",
      "epoch: 4 step: 291, loss is 0.00045460424735210836\n",
      "epoch: 4 step: 292, loss is 0.0013972267042845488\n",
      "epoch: 4 step: 293, loss is 0.043321214616298676\n",
      "epoch: 4 step: 294, loss is 0.0014216562267392874\n",
      "epoch: 4 step: 295, loss is 0.002827770309522748\n",
      "epoch: 4 step: 296, loss is 0.0017525748116895556\n",
      "epoch: 4 step: 297, loss is 0.0033031259663403034\n",
      "epoch: 4 step: 298, loss is 0.03284035623073578\n",
      "epoch: 4 step: 299, loss is 0.0003729771706275642\n",
      "epoch: 4 step: 300, loss is 0.00390181178227067\n",
      "epoch: 4 step: 301, loss is 0.016015667468309402\n",
      "epoch: 4 step: 302, loss is 0.060179609805345535\n",
      "epoch: 4 step: 303, loss is 0.015134253539144993\n",
      "epoch: 4 step: 304, loss is 0.005399794317781925\n",
      "epoch: 4 step: 305, loss is 0.0002497390378266573\n",
      "epoch: 4 step: 306, loss is 0.15290406346321106\n",
      "epoch: 4 step: 307, loss is 0.002578504616394639\n",
      "epoch: 4 step: 308, loss is 0.05665881559252739\n",
      "epoch: 4 step: 309, loss is 0.01831630803644657\n",
      "epoch: 4 step: 310, loss is 0.10386175662279129\n",
      "epoch: 4 step: 311, loss is 0.006172898691147566\n",
      "epoch: 4 step: 312, loss is 0.03671297803521156\n",
      "epoch: 4 step: 313, loss is 0.014867990277707577\n",
      "epoch: 4 step: 314, loss is 0.005429969169199467\n",
      "epoch: 4 step: 315, loss is 0.0021925491746515036\n",
      "epoch: 4 step: 316, loss is 0.00033114705001935363\n",
      "epoch: 4 step: 317, loss is 0.0035674232058227062\n",
      "epoch: 4 step: 318, loss is 0.014860083349049091\n",
      "epoch: 4 step: 319, loss is 0.001499429577961564\n",
      "epoch: 4 step: 320, loss is 0.002504150616005063\n",
      "epoch: 4 step: 321, loss is 0.10030687600374222\n",
      "epoch: 4 step: 322, loss is 0.000926612876355648\n",
      "epoch: 4 step: 323, loss is 0.021895531564950943\n",
      "epoch: 4 step: 324, loss is 0.0004176999500487\n",
      "epoch: 4 step: 325, loss is 0.0027073859237134457\n",
      "epoch: 4 step: 326, loss is 0.0009941961616277695\n",
      "epoch: 4 step: 327, loss is 0.09346435219049454\n",
      "epoch: 4 step: 328, loss is 0.009094664826989174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 329, loss is 0.039711032062768936\n",
      "epoch: 4 step: 330, loss is 0.0008988498011603951\n",
      "epoch: 4 step: 331, loss is 0.05653129890561104\n",
      "epoch: 4 step: 332, loss is 0.000562588160391897\n",
      "epoch: 4 step: 333, loss is 0.012566390447318554\n",
      "epoch: 4 step: 334, loss is 0.0030477603431791067\n",
      "epoch: 4 step: 335, loss is 0.0016418419545516372\n",
      "epoch: 4 step: 336, loss is 0.030538471415638924\n",
      "epoch: 4 step: 337, loss is 0.04350288584828377\n",
      "epoch: 4 step: 338, loss is 0.010405655018985271\n",
      "epoch: 4 step: 339, loss is 0.017742564901709557\n",
      "epoch: 4 step: 340, loss is 0.0004745018668472767\n",
      "epoch: 4 step: 341, loss is 0.021702401340007782\n",
      "epoch: 4 step: 342, loss is 0.12598751485347748\n",
      "epoch: 4 step: 343, loss is 0.0004234365769661963\n",
      "epoch: 4 step: 344, loss is 0.03665934503078461\n",
      "epoch: 4 step: 345, loss is 0.02400961145758629\n",
      "epoch: 4 step: 346, loss is 0.0018152233678847551\n",
      "epoch: 4 step: 347, loss is 0.0035173906944692135\n",
      "epoch: 4 step: 348, loss is 0.034510284662246704\n",
      "epoch: 4 step: 349, loss is 0.001011042157188058\n",
      "epoch: 4 step: 350, loss is 0.010017154738307\n",
      "epoch: 4 step: 351, loss is 0.063558429479599\n",
      "epoch: 4 step: 352, loss is 0.00879942998290062\n",
      "epoch: 4 step: 353, loss is 0.0014365339884534478\n",
      "epoch: 4 step: 354, loss is 0.02163415215909481\n",
      "epoch: 4 step: 355, loss is 0.02938305400311947\n",
      "epoch: 4 step: 356, loss is 0.007757549174129963\n",
      "epoch: 4 step: 357, loss is 0.16487568616867065\n",
      "epoch: 4 step: 358, loss is 0.0015022414736449718\n",
      "epoch: 4 step: 359, loss is 0.030387476086616516\n",
      "epoch: 4 step: 360, loss is 0.0046696895733475685\n",
      "epoch: 4 step: 361, loss is 0.012115901336073875\n",
      "epoch: 4 step: 362, loss is 0.02356904000043869\n",
      "epoch: 4 step: 363, loss is 0.012795566581189632\n",
      "epoch: 4 step: 364, loss is 0.15006345510482788\n",
      "epoch: 4 step: 365, loss is 0.10337985306978226\n",
      "epoch: 4 step: 366, loss is 0.0734640508890152\n",
      "epoch: 4 step: 367, loss is 0.0008619994623586535\n",
      "epoch: 4 step: 368, loss is 0.011783908121287823\n",
      "epoch: 4 step: 369, loss is 0.00038871608558110893\n",
      "epoch: 4 step: 370, loss is 0.0071777948178350925\n",
      "epoch: 4 step: 371, loss is 0.004378228913992643\n",
      "epoch: 4 step: 372, loss is 0.004676288925111294\n",
      "epoch: 4 step: 373, loss is 0.045904818922281265\n",
      "epoch: 4 step: 374, loss is 0.03627218306064606\n",
      "epoch: 4 step: 375, loss is 0.003173969453200698\n",
      "epoch: 4 step: 376, loss is 0.1216287910938263\n",
      "epoch: 4 step: 377, loss is 0.0019709125626832247\n",
      "epoch: 4 step: 378, loss is 0.011051534675061703\n",
      "epoch: 4 step: 379, loss is 0.0018317201174795628\n",
      "epoch: 4 step: 380, loss is 0.0009838482365012169\n",
      "epoch: 4 step: 381, loss is 0.00459434324875474\n",
      "epoch: 4 step: 382, loss is 0.05565735697746277\n",
      "epoch: 4 step: 383, loss is 0.0488855242729187\n",
      "epoch: 4 step: 384, loss is 0.06986327469348907\n",
      "epoch: 4 step: 385, loss is 0.011790243908762932\n",
      "epoch: 4 step: 386, loss is 0.0038137517403811216\n",
      "epoch: 4 step: 387, loss is 0.19804124534130096\n",
      "epoch: 4 step: 388, loss is 0.01297887321561575\n",
      "epoch: 4 step: 389, loss is 0.008880622684955597\n",
      "epoch: 4 step: 390, loss is 0.012738739140331745\n",
      "epoch: 4 step: 391, loss is 0.000732681539375335\n",
      "epoch: 4 step: 392, loss is 0.002484443597495556\n",
      "epoch: 4 step: 393, loss is 0.23581409454345703\n",
      "epoch: 4 step: 394, loss is 0.01890612207353115\n",
      "epoch: 4 step: 395, loss is 0.1295030415058136\n",
      "epoch: 4 step: 396, loss is 0.005402047652751207\n",
      "epoch: 4 step: 397, loss is 0.005403342191129923\n",
      "epoch: 4 step: 398, loss is 0.17898550629615784\n",
      "epoch: 4 step: 399, loss is 0.007129686884582043\n",
      "epoch: 4 step: 400, loss is 0.1176161840558052\n",
      "epoch: 4 step: 401, loss is 0.0041731358505785465\n",
      "epoch: 4 step: 402, loss is 0.0305826086550951\n",
      "epoch: 4 step: 403, loss is 0.004768745508044958\n",
      "epoch: 4 step: 404, loss is 0.005387499462813139\n",
      "epoch: 4 step: 405, loss is 0.0016709822230041027\n",
      "epoch: 4 step: 406, loss is 0.025819897651672363\n",
      "epoch: 4 step: 407, loss is 0.0020058017689734697\n",
      "epoch: 4 step: 408, loss is 0.0011928122257813811\n",
      "epoch: 4 step: 409, loss is 0.14801083505153656\n",
      "epoch: 4 step: 410, loss is 0.001012327498756349\n",
      "epoch: 4 step: 411, loss is 0.009940255433321\n",
      "epoch: 4 step: 412, loss is 0.005216819699853659\n",
      "epoch: 4 step: 413, loss is 0.015688620507717133\n",
      "epoch: 4 step: 414, loss is 0.0022058046888560057\n",
      "epoch: 4 step: 415, loss is 0.004774597939103842\n",
      "epoch: 4 step: 416, loss is 0.01954067125916481\n",
      "epoch: 4 step: 417, loss is 0.0061942352913320065\n",
      "epoch: 4 step: 418, loss is 0.011674730107188225\n",
      "epoch: 4 step: 419, loss is 0.0030841445550322533\n",
      "epoch: 4 step: 420, loss is 0.11629227548837662\n",
      "epoch: 4 step: 421, loss is 0.09458929300308228\n",
      "epoch: 4 step: 422, loss is 0.005134955048561096\n",
      "epoch: 4 step: 423, loss is 0.007544563151896\n",
      "epoch: 4 step: 424, loss is 0.011862218379974365\n",
      "epoch: 4 step: 425, loss is 0.12450502067804337\n",
      "epoch: 4 step: 426, loss is 0.008064530789852142\n",
      "epoch: 4 step: 427, loss is 0.08037124574184418\n",
      "epoch: 4 step: 428, loss is 0.09329669922590256\n",
      "epoch: 4 step: 429, loss is 0.011225446127355099\n",
      "epoch: 4 step: 430, loss is 0.008968978188931942\n",
      "epoch: 4 step: 431, loss is 0.000185755270649679\n",
      "epoch: 4 step: 432, loss is 0.13804860413074493\n",
      "epoch: 4 step: 433, loss is 0.004805481527000666\n",
      "epoch: 4 step: 434, loss is 0.022732120007276535\n",
      "epoch: 4 step: 435, loss is 0.020937031134963036\n",
      "epoch: 4 step: 436, loss is 0.03532423451542854\n",
      "epoch: 4 step: 437, loss is 0.007373419590294361\n",
      "epoch: 4 step: 438, loss is 0.0016748030902817845\n",
      "epoch: 4 step: 439, loss is 0.010842187330126762\n",
      "epoch: 4 step: 440, loss is 0.008523262105882168\n",
      "epoch: 4 step: 441, loss is 0.003293856279924512\n",
      "epoch: 4 step: 442, loss is 0.11711866408586502\n",
      "epoch: 4 step: 443, loss is 0.05611744895577431\n",
      "epoch: 4 step: 444, loss is 0.010558385401964188\n",
      "epoch: 4 step: 445, loss is 0.10108716785907745\n",
      "epoch: 4 step: 446, loss is 0.00028495967853814363\n",
      "epoch: 4 step: 447, loss is 0.027900921180844307\n",
      "epoch: 4 step: 448, loss is 0.01168279442936182\n",
      "epoch: 4 step: 449, loss is 0.0025679157115519047\n",
      "epoch: 4 step: 450, loss is 0.019917497411370277\n",
      "epoch: 4 step: 451, loss is 0.00022435153368860483\n",
      "epoch: 4 step: 452, loss is 0.04994088411331177\n",
      "epoch: 4 step: 453, loss is 0.000978604075498879\n",
      "epoch: 4 step: 454, loss is 0.0012027507182210684\n",
      "epoch: 4 step: 455, loss is 0.07681780308485031\n",
      "epoch: 4 step: 456, loss is 0.00042409347952343524\n",
      "epoch: 4 step: 457, loss is 0.2010679692029953\n",
      "epoch: 4 step: 458, loss is 0.03216976672410965\n",
      "epoch: 4 step: 459, loss is 0.06610696762800217\n",
      "epoch: 4 step: 460, loss is 0.07100006192922592\n",
      "epoch: 4 step: 461, loss is 0.007810445036739111\n",
      "epoch: 4 step: 462, loss is 0.010215753689408302\n",
      "epoch: 4 step: 463, loss is 0.0006668489659205079\n",
      "epoch: 4 step: 464, loss is 0.028549406677484512\n",
      "epoch: 4 step: 465, loss is 0.12585651874542236\n",
      "epoch: 4 step: 466, loss is 0.0010903970105573535\n",
      "epoch: 4 step: 467, loss is 0.0002884186105802655\n",
      "epoch: 4 step: 468, loss is 0.03273472189903259\n",
      "epoch: 4 step: 469, loss is 0.02637278288602829\n",
      "epoch: 4 step: 470, loss is 0.0011692626867443323\n",
      "epoch: 4 step: 471, loss is 0.0038701461162418127\n",
      "epoch: 4 step: 472, loss is 0.00022222095867618918\n",
      "epoch: 4 step: 473, loss is 0.033626385033130646\n",
      "epoch: 4 step: 474, loss is 0.0006081436877138913\n",
      "epoch: 4 step: 475, loss is 0.056281015276908875\n",
      "epoch: 4 step: 476, loss is 0.0018186684465035796\n",
      "epoch: 4 step: 477, loss is 0.06080473214387894\n",
      "epoch: 4 step: 478, loss is 0.009312872774899006\n",
      "epoch: 4 step: 479, loss is 0.049832213670015335\n",
      "epoch: 4 step: 480, loss is 0.13815398514270782\n",
      "epoch: 4 step: 481, loss is 0.0031108581461012363\n",
      "epoch: 4 step: 482, loss is 0.0031992094591259956\n",
      "epoch: 4 step: 483, loss is 0.09363663196563721\n",
      "epoch: 4 step: 484, loss is 0.0021539144217967987\n",
      "epoch: 4 step: 485, loss is 0.0006361803389154375\n",
      "epoch: 4 step: 486, loss is 0.0014030317543074489\n",
      "epoch: 4 step: 487, loss is 0.009043075144290924\n",
      "epoch: 4 step: 488, loss is 0.005215099081397057\n",
      "epoch: 4 step: 489, loss is 0.001402466674335301\n",
      "epoch: 4 step: 490, loss is 0.00021222782379481941\n",
      "epoch: 4 step: 491, loss is 0.005295292474329472\n",
      "epoch: 4 step: 492, loss is 0.001514103845693171\n",
      "epoch: 4 step: 493, loss is 0.0020759347826242447\n",
      "epoch: 4 step: 494, loss is 0.01783372461795807\n",
      "epoch: 4 step: 495, loss is 0.031187666580080986\n",
      "epoch: 4 step: 496, loss is 0.0002218680747319013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 497, loss is 0.010567431338131428\n",
      "epoch: 4 step: 498, loss is 0.06553169339895248\n",
      "epoch: 4 step: 499, loss is 0.003373353974893689\n",
      "epoch: 4 step: 500, loss is 0.009302559308707714\n",
      "epoch: 4 step: 501, loss is 0.002022312255576253\n",
      "epoch: 4 step: 502, loss is 0.001772883115336299\n",
      "epoch: 4 step: 503, loss is 0.10781095176935196\n",
      "epoch: 4 step: 504, loss is 0.08879736065864563\n",
      "epoch: 4 step: 505, loss is 0.002000079257413745\n",
      "epoch: 4 step: 506, loss is 0.07772549241781235\n",
      "epoch: 4 step: 507, loss is 0.09380165487527847\n",
      "epoch: 4 step: 508, loss is 0.02032097615301609\n",
      "epoch: 4 step: 509, loss is 0.007966858334839344\n",
      "epoch: 4 step: 510, loss is 0.014184537343680859\n",
      "epoch: 4 step: 511, loss is 0.0035600527189671993\n",
      "epoch: 4 step: 512, loss is 0.0003425090399105102\n",
      "epoch: 4 step: 513, loss is 0.032611455768346786\n",
      "epoch: 4 step: 514, loss is 0.004380608443170786\n",
      "epoch: 4 step: 515, loss is 0.00036004872526973486\n",
      "epoch: 4 step: 516, loss is 0.0014041389804333448\n",
      "epoch: 4 step: 517, loss is 0.0015767172444611788\n",
      "epoch: 4 step: 518, loss is 0.001330728642642498\n",
      "epoch: 4 step: 519, loss is 0.038197945803403854\n",
      "epoch: 4 step: 520, loss is 0.03063676692545414\n",
      "epoch: 4 step: 521, loss is 0.005525894928723574\n",
      "epoch: 4 step: 522, loss is 0.0050331405363976955\n",
      "epoch: 4 step: 523, loss is 0.09396801143884659\n",
      "epoch: 4 step: 524, loss is 0.0012755314819514751\n",
      "epoch: 4 step: 525, loss is 0.08914582431316376\n",
      "epoch: 4 step: 526, loss is 0.007887824438512325\n",
      "epoch: 4 step: 527, loss is 0.05827182158827782\n",
      "epoch: 4 step: 528, loss is 0.00025847775395959616\n",
      "epoch: 4 step: 529, loss is 0.004526949487626553\n",
      "epoch: 4 step: 530, loss is 0.003587360493838787\n",
      "epoch: 4 step: 531, loss is 0.016521921381354332\n",
      "epoch: 4 step: 532, loss is 0.0005037396331317723\n",
      "epoch: 4 step: 533, loss is 0.009281585924327374\n",
      "epoch: 4 step: 534, loss is 0.000424245314206928\n",
      "epoch: 4 step: 535, loss is 0.017465174198150635\n",
      "epoch: 4 step: 536, loss is 0.004970354028046131\n",
      "epoch: 4 step: 537, loss is 0.0007075904868543148\n",
      "epoch: 4 step: 538, loss is 0.0029132585041224957\n",
      "epoch: 4 step: 539, loss is 0.4018958806991577\n",
      "epoch: 4 step: 540, loss is 0.058593254536390305\n",
      "epoch: 4 step: 541, loss is 0.1363413780927658\n",
      "epoch: 4 step: 542, loss is 0.0031326781027019024\n",
      "epoch: 4 step: 543, loss is 0.00918172113597393\n",
      "epoch: 4 step: 544, loss is 0.1293429136276245\n",
      "epoch: 4 step: 545, loss is 0.008194154128432274\n",
      "epoch: 4 step: 546, loss is 0.024553705006837845\n",
      "epoch: 4 step: 547, loss is 0.007662464864552021\n",
      "epoch: 4 step: 548, loss is 0.1437709927558899\n",
      "epoch: 4 step: 549, loss is 0.05709376931190491\n",
      "epoch: 4 step: 550, loss is 0.004050164017826319\n",
      "epoch: 4 step: 551, loss is 0.008301143534481525\n",
      "epoch: 4 step: 552, loss is 0.011169864796102047\n",
      "epoch: 4 step: 553, loss is 0.0031658874358981848\n",
      "epoch: 4 step: 554, loss is 0.0013295314274728298\n",
      "epoch: 4 step: 555, loss is 0.0006430839421227574\n",
      "epoch: 4 step: 556, loss is 0.0017232222016900778\n",
      "epoch: 4 step: 557, loss is 0.0012066976632922888\n",
      "epoch: 4 step: 558, loss is 0.016721220687031746\n",
      "epoch: 4 step: 559, loss is 0.019034873694181442\n",
      "epoch: 4 step: 560, loss is 0.00782185047864914\n",
      "epoch: 4 step: 561, loss is 0.052178170531988144\n",
      "epoch: 4 step: 562, loss is 0.0007497264887206256\n",
      "epoch: 4 step: 563, loss is 0.0009007541229948401\n",
      "epoch: 4 step: 564, loss is 0.025824323296546936\n",
      "epoch: 4 step: 565, loss is 0.0027578193694353104\n",
      "epoch: 4 step: 566, loss is 0.25954219698905945\n",
      "epoch: 4 step: 567, loss is 0.0008663648623041809\n",
      "epoch: 4 step: 568, loss is 0.0009855135576799512\n",
      "epoch: 4 step: 569, loss is 0.0013598420191556215\n",
      "epoch: 4 step: 570, loss is 0.038226429373025894\n",
      "epoch: 4 step: 571, loss is 0.0065440833568573\n",
      "epoch: 4 step: 572, loss is 0.005954126827418804\n",
      "epoch: 4 step: 573, loss is 0.007090361788868904\n",
      "epoch: 4 step: 574, loss is 0.18767420947551727\n",
      "epoch: 4 step: 575, loss is 0.00665680505335331\n",
      "epoch: 4 step: 576, loss is 0.0015037829289212823\n",
      "epoch: 4 step: 577, loss is 0.016597388312220573\n",
      "epoch: 4 step: 578, loss is 0.00827811099588871\n",
      "epoch: 4 step: 579, loss is 0.0034193226601928473\n",
      "epoch: 4 step: 580, loss is 0.19909417629241943\n",
      "epoch: 4 step: 581, loss is 0.0383811891078949\n",
      "epoch: 4 step: 582, loss is 0.0046026986092329025\n",
      "epoch: 4 step: 583, loss is 0.021361958235502243\n",
      "epoch: 4 step: 584, loss is 0.0013150771846994758\n",
      "epoch: 4 step: 585, loss is 0.016476722434163094\n",
      "epoch: 4 step: 586, loss is 0.00043755953083746135\n",
      "epoch: 4 step: 587, loss is 0.0009643463417887688\n",
      "epoch: 4 step: 588, loss is 0.040105853229761124\n",
      "epoch: 4 step: 589, loss is 0.14873577654361725\n",
      "epoch: 4 step: 590, loss is 0.06637545675039291\n",
      "epoch: 4 step: 591, loss is 0.0002727622340898961\n",
      "epoch: 4 step: 592, loss is 0.010007393546402454\n",
      "epoch: 4 step: 593, loss is 0.012949911877512932\n",
      "epoch: 4 step: 594, loss is 0.011419233866035938\n",
      "epoch: 4 step: 595, loss is 0.08286400884389877\n",
      "epoch: 4 step: 596, loss is 0.0016889855032786727\n",
      "epoch: 4 step: 597, loss is 0.008881947956979275\n",
      "epoch: 4 step: 598, loss is 0.0015975122805684805\n",
      "epoch: 4 step: 599, loss is 0.014828811399638653\n",
      "epoch: 4 step: 600, loss is 0.00018929506768472493\n",
      "epoch: 4 step: 601, loss is 0.0038670478388667107\n",
      "epoch: 4 step: 602, loss is 0.0018907308112829924\n",
      "epoch: 4 step: 603, loss is 0.02236844412982464\n",
      "epoch: 4 step: 604, loss is 0.06433029472827911\n",
      "epoch: 4 step: 605, loss is 0.0038357581943273544\n",
      "epoch: 4 step: 606, loss is 0.0003151213168166578\n",
      "epoch: 4 step: 607, loss is 0.11235953867435455\n",
      "epoch: 4 step: 608, loss is 0.035281095653772354\n",
      "epoch: 4 step: 609, loss is 0.016992054879665375\n",
      "epoch: 4 step: 610, loss is 0.06181038171052933\n",
      "epoch: 4 step: 611, loss is 0.0028087859973311424\n",
      "epoch: 4 step: 612, loss is 0.0010846747318282723\n",
      "epoch: 4 step: 613, loss is 0.0022871389519423246\n",
      "epoch: 4 step: 614, loss is 0.000741761876270175\n",
      "epoch: 4 step: 615, loss is 0.0009971203980967402\n",
      "epoch: 4 step: 616, loss is 0.0005574983661063015\n",
      "epoch: 4 step: 617, loss is 0.0006992314592935145\n",
      "epoch: 4 step: 618, loss is 0.08318372815847397\n",
      "epoch: 4 step: 619, loss is 0.0005185790942050517\n",
      "epoch: 4 step: 620, loss is 0.0004273340164218098\n",
      "epoch: 4 step: 621, loss is 0.1279522180557251\n",
      "epoch: 4 step: 622, loss is 0.04795609787106514\n",
      "epoch: 4 step: 623, loss is 0.010717450641095638\n",
      "epoch: 4 step: 624, loss is 0.007186029572039843\n",
      "epoch: 4 step: 625, loss is 0.0045449864119291306\n",
      "epoch: 4 step: 626, loss is 0.06316637992858887\n",
      "epoch: 4 step: 627, loss is 0.009458701126277447\n",
      "epoch: 4 step: 628, loss is 0.002514804247766733\n",
      "epoch: 4 step: 629, loss is 0.02217402309179306\n",
      "epoch: 4 step: 630, loss is 0.0011043110862374306\n",
      "epoch: 4 step: 631, loss is 0.0010820823954418302\n",
      "epoch: 4 step: 632, loss is 0.0009233423043042421\n",
      "epoch: 4 step: 633, loss is 0.0033851221669465303\n",
      "epoch: 4 step: 634, loss is 0.014819133095443249\n",
      "epoch: 4 step: 635, loss is 0.005922799929976463\n",
      "epoch: 4 step: 636, loss is 0.01525246724486351\n",
      "epoch: 4 step: 637, loss is 0.0037838348653167486\n",
      "epoch: 4 step: 638, loss is 0.0049059283919632435\n",
      "epoch: 4 step: 639, loss is 0.015743711963295937\n",
      "epoch: 4 step: 640, loss is 0.07155458629131317\n",
      "epoch: 4 step: 641, loss is 0.0033964423928409815\n",
      "epoch: 4 step: 642, loss is 0.06316018849611282\n",
      "epoch: 4 step: 643, loss is 0.0012362736742943525\n",
      "epoch: 4 step: 644, loss is 0.009643896482884884\n",
      "epoch: 4 step: 645, loss is 0.00395149877294898\n",
      "epoch: 4 step: 646, loss is 0.008187484927475452\n",
      "epoch: 4 step: 647, loss is 0.05545187368988991\n",
      "epoch: 4 step: 648, loss is 0.007823683321475983\n",
      "epoch: 4 step: 649, loss is 0.0016835322603583336\n",
      "epoch: 4 step: 650, loss is 0.026076436042785645\n",
      "epoch: 4 step: 651, loss is 0.0007595255738124251\n",
      "epoch: 4 step: 652, loss is 0.0002407919819233939\n",
      "epoch: 4 step: 653, loss is 0.015340006910264492\n",
      "epoch: 4 step: 654, loss is 0.012491201981902122\n",
      "epoch: 4 step: 655, loss is 0.08176043629646301\n",
      "epoch: 4 step: 656, loss is 0.0016141966916620731\n",
      "epoch: 4 step: 657, loss is 0.015201198868453503\n",
      "epoch: 4 step: 658, loss is 0.01687990128993988\n",
      "epoch: 4 step: 659, loss is 0.021236101165413857\n",
      "epoch: 4 step: 660, loss is 0.005269508808851242\n",
      "epoch: 4 step: 661, loss is 0.04300103709101677\n",
      "epoch: 4 step: 662, loss is 0.09627524018287659\n",
      "epoch: 4 step: 663, loss is 0.043436892330646515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 664, loss is 2.095283525704872e-05\n",
      "epoch: 4 step: 665, loss is 0.0026456054765731096\n",
      "epoch: 4 step: 666, loss is 0.001352900406345725\n",
      "epoch: 4 step: 667, loss is 0.12610623240470886\n",
      "epoch: 4 step: 668, loss is 0.02744555100798607\n",
      "epoch: 4 step: 669, loss is 0.0005743827787227929\n",
      "epoch: 4 step: 670, loss is 0.0017277207225561142\n",
      "epoch: 4 step: 671, loss is 0.0024633987341076136\n",
      "epoch: 4 step: 672, loss is 0.0006183122168295085\n",
      "epoch: 4 step: 673, loss is 0.05173126980662346\n",
      "epoch: 4 step: 674, loss is 0.013020186685025692\n",
      "epoch: 4 step: 675, loss is 0.012081661261618137\n",
      "epoch: 4 step: 676, loss is 0.007731152232736349\n",
      "epoch: 4 step: 677, loss is 0.0011531689669936895\n",
      "epoch: 4 step: 678, loss is 0.003554996568709612\n",
      "epoch: 4 step: 679, loss is 0.1305093765258789\n",
      "epoch: 4 step: 680, loss is 0.05749622359871864\n",
      "epoch: 4 step: 681, loss is 0.0001479114143876359\n",
      "epoch: 4 step: 682, loss is 0.0015454539097845554\n",
      "epoch: 4 step: 683, loss is 0.1251686066389084\n",
      "epoch: 4 step: 684, loss is 0.15184123814105988\n",
      "epoch: 4 step: 685, loss is 0.00041971655446104705\n",
      "epoch: 4 step: 686, loss is 0.0005923414137214422\n",
      "epoch: 4 step: 687, loss is 0.007000688463449478\n",
      "epoch: 4 step: 688, loss is 0.10073213279247284\n",
      "epoch: 4 step: 689, loss is 0.011566169559955597\n",
      "epoch: 4 step: 690, loss is 0.0020175985991954803\n",
      "epoch: 4 step: 691, loss is 0.008996877819299698\n",
      "epoch: 4 step: 692, loss is 0.04960649833083153\n",
      "epoch: 4 step: 693, loss is 0.0009779322426766157\n",
      "epoch: 4 step: 694, loss is 0.010501531884074211\n",
      "epoch: 4 step: 695, loss is 0.004602028522640467\n",
      "epoch: 4 step: 696, loss is 0.04885086789727211\n",
      "epoch: 4 step: 697, loss is 0.30066338181495667\n",
      "epoch: 4 step: 698, loss is 0.014501751400530338\n",
      "epoch: 4 step: 699, loss is 0.002271183067932725\n",
      "epoch: 4 step: 700, loss is 0.013008845038712025\n",
      "epoch: 4 step: 701, loss is 0.00590820237994194\n",
      "epoch: 4 step: 702, loss is 0.01218319870531559\n",
      "epoch: 4 step: 703, loss is 0.00026715549756772816\n",
      "epoch: 4 step: 704, loss is 0.020098267123103142\n",
      "epoch: 4 step: 705, loss is 0.008810504339635372\n",
      "epoch: 4 step: 706, loss is 0.0007183009875006974\n",
      "epoch: 4 step: 707, loss is 0.014789098873734474\n",
      "epoch: 4 step: 708, loss is 0.00741614680737257\n",
      "epoch: 4 step: 709, loss is 0.00026481066015549004\n",
      "epoch: 4 step: 710, loss is 0.05886883661150932\n",
      "epoch: 4 step: 711, loss is 0.0050336383283138275\n",
      "epoch: 4 step: 712, loss is 0.020803488790988922\n",
      "epoch: 4 step: 713, loss is 0.0052179982885718346\n",
      "epoch: 4 step: 714, loss is 0.00013623815902974457\n",
      "epoch: 4 step: 715, loss is 0.0048166727647185326\n",
      "epoch: 4 step: 716, loss is 0.0014409013092517853\n",
      "epoch: 4 step: 717, loss is 0.03323207050561905\n",
      "epoch: 4 step: 718, loss is 0.017465252429246902\n",
      "epoch: 4 step: 719, loss is 0.00013889427646063268\n",
      "epoch: 4 step: 720, loss is 0.0017678417498245835\n",
      "epoch: 4 step: 721, loss is 0.08999120444059372\n",
      "epoch: 4 step: 722, loss is 0.0009518037550151348\n",
      "epoch: 4 step: 723, loss is 0.005961093120276928\n",
      "epoch: 4 step: 724, loss is 0.18582797050476074\n",
      "epoch: 4 step: 725, loss is 0.0029028886929154396\n",
      "epoch: 4 step: 726, loss is 0.011563761159777641\n",
      "epoch: 4 step: 727, loss is 0.06703951209783554\n",
      "epoch: 4 step: 728, loss is 0.00761270010843873\n",
      "epoch: 4 step: 729, loss is 0.0008835573098622262\n",
      "epoch: 4 step: 730, loss is 0.0018113780533894897\n",
      "epoch: 4 step: 731, loss is 0.011437793262302876\n",
      "epoch: 4 step: 732, loss is 0.026239363476634026\n",
      "epoch: 4 step: 733, loss is 0.003988487645983696\n",
      "epoch: 4 step: 734, loss is 0.024850448593497276\n",
      "epoch: 4 step: 735, loss is 0.00011166055628564209\n",
      "epoch: 4 step: 736, loss is 0.005053219851106405\n",
      "epoch: 4 step: 737, loss is 0.010140120051801205\n",
      "epoch: 4 step: 738, loss is 0.007184197660535574\n",
      "epoch: 4 step: 739, loss is 0.003649820340797305\n",
      "epoch: 4 step: 740, loss is 0.04268743097782135\n",
      "epoch: 4 step: 741, loss is 0.005483795888721943\n",
      "epoch: 4 step: 742, loss is 0.007142776157706976\n",
      "epoch: 4 step: 743, loss is 0.12307887524366379\n",
      "epoch: 4 step: 744, loss is 0.00015462434384971857\n",
      "epoch: 4 step: 745, loss is 0.0012891198275610805\n",
      "epoch: 4 step: 746, loss is 0.1893276870250702\n",
      "epoch: 4 step: 747, loss is 0.017174258828163147\n",
      "epoch: 4 step: 748, loss is 9.012090595206246e-05\n",
      "epoch: 4 step: 749, loss is 0.005828844383358955\n",
      "epoch: 4 step: 750, loss is 0.00143731280695647\n",
      "epoch: 4 step: 751, loss is 0.0013320577563717961\n",
      "epoch: 4 step: 752, loss is 0.005524144973605871\n",
      "epoch: 4 step: 753, loss is 0.023629173636436462\n",
      "epoch: 4 step: 754, loss is 0.0009012908558361232\n",
      "epoch: 4 step: 755, loss is 0.10965612530708313\n",
      "epoch: 4 step: 756, loss is 0.012492102570831776\n",
      "epoch: 4 step: 757, loss is 0.0069485013373196125\n",
      "epoch: 4 step: 758, loss is 0.0024034837260842323\n",
      "epoch: 4 step: 759, loss is 0.010158343240618706\n",
      "epoch: 4 step: 760, loss is 0.021407539024949074\n",
      "epoch: 4 step: 761, loss is 0.00039321157964877784\n",
      "epoch: 4 step: 762, loss is 0.2669536769390106\n",
      "epoch: 4 step: 763, loss is 0.05624524876475334\n",
      "epoch: 4 step: 764, loss is 0.010782063938677311\n",
      "epoch: 4 step: 765, loss is 0.0002779707428999245\n",
      "epoch: 4 step: 766, loss is 0.001184159074909985\n",
      "epoch: 4 step: 767, loss is 0.0010438116732984781\n",
      "epoch: 4 step: 768, loss is 0.002900158753618598\n",
      "epoch: 4 step: 769, loss is 0.001274854177609086\n",
      "epoch: 4 step: 770, loss is 0.0016616499051451683\n",
      "epoch: 4 step: 771, loss is 0.004915033467113972\n",
      "epoch: 4 step: 772, loss is 0.12847483158111572\n",
      "epoch: 4 step: 773, loss is 0.011703405529260635\n",
      "epoch: 4 step: 774, loss is 0.12211669236421585\n",
      "epoch: 4 step: 775, loss is 0.0027674913872033358\n",
      "epoch: 4 step: 776, loss is 0.02675160951912403\n",
      "epoch: 4 step: 777, loss is 0.0002576490514911711\n",
      "epoch: 4 step: 778, loss is 0.0008630353840999305\n",
      "epoch: 4 step: 779, loss is 0.004918553400784731\n",
      "epoch: 4 step: 780, loss is 0.0007693227380514145\n",
      "epoch: 4 step: 781, loss is 0.007963797077536583\n",
      "epoch: 4 step: 782, loss is 0.022615084424614906\n",
      "epoch: 4 step: 783, loss is 0.010324962437152863\n",
      "epoch: 4 step: 784, loss is 0.0029278970323503017\n",
      "epoch: 4 step: 785, loss is 0.000748443475458771\n",
      "epoch: 4 step: 786, loss is 0.023440593853592873\n",
      "epoch: 4 step: 787, loss is 0.0001951409358298406\n",
      "epoch: 4 step: 788, loss is 0.17714008688926697\n",
      "epoch: 4 step: 789, loss is 0.000861744221765548\n",
      "epoch: 4 step: 790, loss is 0.0019644489511847496\n",
      "epoch: 4 step: 791, loss is 0.2125963419675827\n",
      "epoch: 4 step: 792, loss is 0.0036940211430191994\n",
      "epoch: 4 step: 793, loss is 0.10375811904668808\n",
      "epoch: 4 step: 794, loss is 0.012024890631437302\n",
      "epoch: 4 step: 795, loss is 0.00521750608459115\n",
      "epoch: 4 step: 796, loss is 0.010743716731667519\n",
      "epoch: 4 step: 797, loss is 0.07401148974895477\n",
      "epoch: 4 step: 798, loss is 0.00037742964923381805\n",
      "epoch: 4 step: 799, loss is 0.1032034307718277\n",
      "epoch: 4 step: 800, loss is 0.00013725209282711148\n",
      "epoch: 4 step: 801, loss is 0.00018636758613865823\n",
      "epoch: 4 step: 802, loss is 0.018098512664437294\n",
      "epoch: 4 step: 803, loss is 0.0029683688189834356\n",
      "epoch: 4 step: 804, loss is 0.0024847108870744705\n",
      "epoch: 4 step: 805, loss is 8.186129707610235e-05\n",
      "epoch: 4 step: 806, loss is 0.0049232374876737595\n",
      "epoch: 4 step: 807, loss is 0.07798274606466293\n",
      "epoch: 4 step: 808, loss is 0.09744717180728912\n",
      "epoch: 4 step: 809, loss is 0.023312130942940712\n",
      "epoch: 4 step: 810, loss is 0.06086115911602974\n",
      "epoch: 4 step: 811, loss is 0.01651618629693985\n",
      "epoch: 4 step: 812, loss is 0.018539205193519592\n",
      "epoch: 4 step: 813, loss is 0.002009634394198656\n",
      "epoch: 4 step: 814, loss is 0.029498709365725517\n",
      "epoch: 4 step: 815, loss is 0.002281351713463664\n",
      "epoch: 4 step: 816, loss is 0.10734649002552032\n",
      "epoch: 4 step: 817, loss is 0.004844438284635544\n",
      "epoch: 4 step: 818, loss is 0.029733940958976746\n",
      "epoch: 4 step: 819, loss is 0.0021757713984698057\n",
      "epoch: 4 step: 820, loss is 0.0011618444696068764\n",
      "epoch: 4 step: 821, loss is 0.10558094084262848\n",
      "epoch: 4 step: 822, loss is 0.002863061847165227\n",
      "epoch: 4 step: 823, loss is 0.034657739102840424\n",
      "epoch: 4 step: 824, loss is 0.043128568679094315\n",
      "epoch: 4 step: 825, loss is 0.0005809544236399233\n",
      "epoch: 4 step: 826, loss is 0.05698752775788307\n",
      "epoch: 4 step: 827, loss is 0.0018421390559524298\n",
      "epoch: 4 step: 828, loss is 0.0014720095787197351\n",
      "epoch: 4 step: 829, loss is 0.0005720328190363944\n",
      "epoch: 4 step: 830, loss is 0.14889277517795563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 831, loss is 0.00022521107166539878\n",
      "epoch: 4 step: 832, loss is 0.00015248566342052072\n",
      "epoch: 4 step: 833, loss is 0.004625464323908091\n",
      "epoch: 4 step: 834, loss is 0.04739559441804886\n",
      "epoch: 4 step: 835, loss is 0.005207603331655264\n",
      "epoch: 4 step: 836, loss is 0.00407068058848381\n",
      "epoch: 4 step: 837, loss is 0.0075719100423157215\n",
      "epoch: 4 step: 838, loss is 0.004156399983912706\n",
      "epoch: 4 step: 839, loss is 0.003916809801012278\n",
      "epoch: 4 step: 840, loss is 0.03603276610374451\n",
      "epoch: 4 step: 841, loss is 0.009152648039162159\n",
      "epoch: 4 step: 842, loss is 0.10296883434057236\n",
      "epoch: 4 step: 843, loss is 0.010573988780379295\n",
      "epoch: 4 step: 844, loss is 0.0024292445741593838\n",
      "epoch: 4 step: 845, loss is 0.004707674495875835\n",
      "epoch: 4 step: 846, loss is 0.011866211891174316\n",
      "epoch: 4 step: 847, loss is 0.008020115084946156\n",
      "epoch: 4 step: 848, loss is 0.00849644560366869\n",
      "epoch: 4 step: 849, loss is 0.001441307133063674\n",
      "epoch: 4 step: 850, loss is 0.007335800677537918\n",
      "epoch: 4 step: 851, loss is 0.006410923786461353\n",
      "epoch: 4 step: 852, loss is 0.0019350637448951602\n",
      "epoch: 4 step: 853, loss is 0.0232840683311224\n",
      "epoch: 4 step: 854, loss is 0.0003166197275277227\n",
      "epoch: 4 step: 855, loss is 0.0020092290360480547\n",
      "epoch: 4 step: 856, loss is 0.0055352007038891315\n",
      "epoch: 4 step: 857, loss is 0.004703449085354805\n",
      "epoch: 4 step: 858, loss is 0.08054061233997345\n",
      "epoch: 4 step: 859, loss is 0.0006901431479491293\n",
      "epoch: 4 step: 860, loss is 0.0033613117411732674\n",
      "epoch: 4 step: 861, loss is 0.002472609980031848\n",
      "epoch: 4 step: 862, loss is 0.0002316890168003738\n",
      "epoch: 4 step: 863, loss is 0.03484455868601799\n",
      "epoch: 4 step: 864, loss is 0.001948541379533708\n",
      "epoch: 4 step: 865, loss is 0.0007394419517368078\n",
      "epoch: 4 step: 866, loss is 0.0005428447620943189\n",
      "epoch: 4 step: 867, loss is 0.013738407753407955\n",
      "epoch: 4 step: 868, loss is 0.003656151005998254\n",
      "epoch: 4 step: 869, loss is 0.0028507292736321688\n",
      "epoch: 4 step: 870, loss is 0.008300695568323135\n",
      "epoch: 4 step: 871, loss is 0.00809994712471962\n",
      "epoch: 4 step: 872, loss is 0.2939590811729431\n",
      "epoch: 4 step: 873, loss is 0.0004676728567574173\n",
      "epoch: 4 step: 874, loss is 0.002343014581128955\n",
      "epoch: 4 step: 875, loss is 0.003572969464585185\n",
      "epoch: 4 step: 876, loss is 0.0038623777218163013\n",
      "epoch: 4 step: 877, loss is 0.0003719916276168078\n",
      "epoch: 4 step: 878, loss is 0.001015817397274077\n",
      "epoch: 4 step: 879, loss is 0.0026422846131026745\n",
      "epoch: 4 step: 880, loss is 0.03131880611181259\n",
      "epoch: 4 step: 881, loss is 0.03698337823152542\n",
      "epoch: 4 step: 882, loss is 0.01744285225868225\n",
      "epoch: 4 step: 883, loss is 0.007952979765832424\n",
      "epoch: 4 step: 884, loss is 0.006755110342055559\n",
      "epoch: 4 step: 885, loss is 0.003315055277198553\n",
      "epoch: 4 step: 886, loss is 0.01379118487238884\n",
      "epoch: 4 step: 887, loss is 0.004670030903071165\n",
      "epoch: 4 step: 888, loss is 0.18857872486114502\n",
      "epoch: 4 step: 889, loss is 0.01207009982317686\n",
      "epoch: 4 step: 890, loss is 0.0004674454394262284\n",
      "epoch: 4 step: 891, loss is 0.001193571137264371\n",
      "epoch: 4 step: 892, loss is 0.019525159150362015\n",
      "epoch: 4 step: 893, loss is 0.0027710155118256807\n",
      "epoch: 4 step: 894, loss is 0.019854698330163956\n",
      "epoch: 4 step: 895, loss is 0.010567625053226948\n",
      "epoch: 4 step: 896, loss is 0.0002377614437136799\n",
      "epoch: 4 step: 897, loss is 0.009794019162654877\n",
      "epoch: 4 step: 898, loss is 0.0036875559017062187\n",
      "epoch: 4 step: 899, loss is 0.0690205991268158\n",
      "epoch: 4 step: 900, loss is 0.051628511399030685\n",
      "epoch: 4 step: 901, loss is 0.037918929010629654\n",
      "epoch: 4 step: 902, loss is 0.0024576508440077305\n",
      "epoch: 4 step: 903, loss is 0.0011637975694611669\n",
      "epoch: 4 step: 904, loss is 0.08909737318754196\n",
      "epoch: 4 step: 905, loss is 0.13919201493263245\n",
      "epoch: 4 step: 906, loss is 0.0018184598302468657\n",
      "epoch: 4 step: 907, loss is 0.013428954407572746\n",
      "epoch: 4 step: 908, loss is 0.09366621822118759\n",
      "epoch: 4 step: 909, loss is 0.008574247360229492\n",
      "epoch: 4 step: 910, loss is 0.0003292273613624275\n",
      "epoch: 4 step: 911, loss is 0.002549302764236927\n",
      "epoch: 4 step: 912, loss is 0.00019603660621214658\n",
      "epoch: 4 step: 913, loss is 0.053942665457725525\n",
      "epoch: 4 step: 914, loss is 0.005895232316106558\n",
      "epoch: 4 step: 915, loss is 0.051718469709157944\n",
      "epoch: 4 step: 916, loss is 0.0346321277320385\n",
      "epoch: 4 step: 917, loss is 0.00017270947864744812\n",
      "epoch: 4 step: 918, loss is 0.3499932289123535\n",
      "epoch: 4 step: 919, loss is 0.03533684462308884\n",
      "epoch: 4 step: 920, loss is 0.02311037667095661\n",
      "epoch: 4 step: 921, loss is 0.062126126140356064\n",
      "epoch: 4 step: 922, loss is 0.04507077485322952\n",
      "epoch: 4 step: 923, loss is 0.05366192013025284\n",
      "epoch: 4 step: 924, loss is 0.037197090685367584\n",
      "epoch: 4 step: 925, loss is 0.007984697818756104\n",
      "epoch: 4 step: 926, loss is 0.0035285349003970623\n",
      "epoch: 4 step: 927, loss is 0.08128567039966583\n",
      "epoch: 4 step: 928, loss is 0.0048835380002856255\n",
      "epoch: 4 step: 929, loss is 0.00986183900386095\n",
      "epoch: 4 step: 930, loss is 0.002640576334670186\n",
      "epoch: 4 step: 931, loss is 0.11166713386774063\n",
      "epoch: 4 step: 932, loss is 0.0028248741291463375\n",
      "epoch: 4 step: 933, loss is 0.002909081056714058\n",
      "epoch: 4 step: 934, loss is 0.14020748436450958\n",
      "epoch: 4 step: 935, loss is 0.06847137957811356\n",
      "epoch: 4 step: 936, loss is 0.018356595188379288\n",
      "epoch: 4 step: 937, loss is 0.008871518075466156\n",
      "epoch: 4 step: 938, loss is 0.04309921711683273\n",
      "epoch: 4 step: 939, loss is 0.00508382823318243\n",
      "epoch: 4 step: 940, loss is 0.07921125739812851\n",
      "epoch: 4 step: 941, loss is 0.01293307077139616\n",
      "epoch: 4 step: 942, loss is 0.022263331338763237\n",
      "epoch: 4 step: 943, loss is 0.13869129121303558\n",
      "epoch: 4 step: 944, loss is 0.02375403419137001\n",
      "epoch: 4 step: 945, loss is 0.008218139410018921\n",
      "epoch: 4 step: 946, loss is 0.0046416986733675\n",
      "epoch: 4 step: 947, loss is 0.13728660345077515\n",
      "epoch: 4 step: 948, loss is 0.005143072456121445\n",
      "epoch: 4 step: 949, loss is 0.00824540015310049\n",
      "epoch: 4 step: 950, loss is 0.006412227172404528\n",
      "epoch: 4 step: 951, loss is 0.010019740089774132\n",
      "epoch: 4 step: 952, loss is 0.0036225616931915283\n",
      "epoch: 4 step: 953, loss is 0.00010939624189632013\n",
      "epoch: 4 step: 954, loss is 0.06774076074361801\n",
      "epoch: 4 step: 955, loss is 0.0009057421120814979\n",
      "epoch: 4 step: 956, loss is 0.006044961977750063\n",
      "epoch: 4 step: 957, loss is 0.0023314000573009253\n",
      "epoch: 4 step: 958, loss is 0.1060391515493393\n",
      "epoch: 4 step: 959, loss is 0.0038901364896446466\n",
      "epoch: 4 step: 960, loss is 0.0034082976635545492\n",
      "epoch: 4 step: 961, loss is 0.02777046710252762\n",
      "epoch: 4 step: 962, loss is 0.0012855533277615905\n",
      "epoch: 4 step: 963, loss is 0.018540034070611\n",
      "epoch: 4 step: 964, loss is 0.016094468533992767\n",
      "epoch: 4 step: 965, loss is 0.17157749831676483\n",
      "epoch: 4 step: 966, loss is 0.0007637818926014006\n",
      "epoch: 4 step: 967, loss is 0.02850804291665554\n",
      "epoch: 4 step: 968, loss is 0.1788237988948822\n",
      "epoch: 4 step: 969, loss is 0.11704748123884201\n",
      "epoch: 4 step: 970, loss is 0.014517949894070625\n",
      "epoch: 4 step: 971, loss is 0.11327662318944931\n",
      "epoch: 4 step: 972, loss is 0.0494307279586792\n",
      "epoch: 4 step: 973, loss is 0.29435858130455017\n",
      "epoch: 4 step: 974, loss is 0.0005388977006077766\n",
      "epoch: 4 step: 975, loss is 0.00029887750861234963\n",
      "epoch: 4 step: 976, loss is 0.02467171661555767\n",
      "epoch: 4 step: 977, loss is 0.06336715817451477\n",
      "epoch: 4 step: 978, loss is 0.00760246766731143\n",
      "epoch: 4 step: 979, loss is 0.041491854935884476\n",
      "epoch: 4 step: 980, loss is 0.04471468925476074\n",
      "epoch: 4 step: 981, loss is 0.0009841433493420482\n",
      "epoch: 4 step: 982, loss is 0.0008789307903498411\n",
      "epoch: 4 step: 983, loss is 0.004064890090376139\n",
      "epoch: 4 step: 984, loss is 0.0006222777883522213\n",
      "epoch: 4 step: 985, loss is 0.1244688630104065\n",
      "epoch: 4 step: 986, loss is 0.00023242853058036417\n",
      "epoch: 4 step: 987, loss is 0.003219925332814455\n",
      "epoch: 4 step: 988, loss is 0.04609494283795357\n",
      "epoch: 4 step: 989, loss is 0.0038818586617708206\n",
      "epoch: 4 step: 990, loss is 0.006084055174142122\n",
      "epoch: 4 step: 991, loss is 0.002128508174791932\n",
      "epoch: 4 step: 992, loss is 0.0022401809692382812\n",
      "epoch: 4 step: 993, loss is 0.0022910533007234335\n",
      "epoch: 4 step: 994, loss is 0.0007339896401390433\n",
      "epoch: 4 step: 995, loss is 0.07637662440538406\n",
      "epoch: 4 step: 996, loss is 6.35238247923553e-05\n",
      "epoch: 4 step: 997, loss is 0.03771200776100159\n",
      "epoch: 4 step: 998, loss is 0.002380379708483815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 999, loss is 0.049364831298589706\n",
      "epoch: 4 step: 1000, loss is 0.20773744583129883\n",
      "epoch: 4 step: 1001, loss is 0.012022255919873714\n",
      "epoch: 4 step: 1002, loss is 0.0021905195899307728\n",
      "epoch: 4 step: 1003, loss is 0.11462510377168655\n",
      "epoch: 4 step: 1004, loss is 0.07981811463832855\n",
      "epoch: 4 step: 1005, loss is 0.09882157295942307\n",
      "epoch: 4 step: 1006, loss is 0.0007232293137349188\n",
      "epoch: 4 step: 1007, loss is 0.0034133456647396088\n",
      "epoch: 4 step: 1008, loss is 0.0012269893195480108\n",
      "epoch: 4 step: 1009, loss is 0.09141126275062561\n",
      "epoch: 4 step: 1010, loss is 0.0007086239638738334\n",
      "epoch: 4 step: 1011, loss is 0.053030725568532944\n",
      "epoch: 4 step: 1012, loss is 0.03659046068787575\n",
      "epoch: 4 step: 1013, loss is 0.0007585263228975236\n",
      "epoch: 4 step: 1014, loss is 0.006313443183898926\n",
      "epoch: 4 step: 1015, loss is 0.003411070443689823\n",
      "epoch: 4 step: 1016, loss is 0.007864397950470448\n",
      "epoch: 4 step: 1017, loss is 0.17128346860408783\n",
      "epoch: 4 step: 1018, loss is 0.11815360188484192\n",
      "epoch: 4 step: 1019, loss is 0.04506315663456917\n",
      "epoch: 4 step: 1020, loss is 0.02123211696743965\n",
      "epoch: 4 step: 1021, loss is 0.06815942376852036\n",
      "epoch: 4 step: 1022, loss is 0.0010294616222381592\n",
      "epoch: 4 step: 1023, loss is 0.01151067204773426\n",
      "epoch: 4 step: 1024, loss is 0.025956282392144203\n",
      "epoch: 4 step: 1025, loss is 0.01610505022108555\n",
      "epoch: 4 step: 1026, loss is 0.032085321843624115\n",
      "epoch: 4 step: 1027, loss is 0.0005315031739883125\n",
      "epoch: 4 step: 1028, loss is 0.000734463392291218\n",
      "epoch: 4 step: 1029, loss is 0.0803789421916008\n",
      "epoch: 4 step: 1030, loss is 0.003499433631077409\n",
      "epoch: 4 step: 1031, loss is 0.03657812625169754\n",
      "epoch: 4 step: 1032, loss is 0.0031832752283662558\n",
      "epoch: 4 step: 1033, loss is 0.0005872889305464923\n",
      "epoch: 4 step: 1034, loss is 0.038057591766119\n",
      "epoch: 4 step: 1035, loss is 0.0013597208308055997\n",
      "epoch: 4 step: 1036, loss is 0.004609940107911825\n",
      "epoch: 4 step: 1037, loss is 0.0026477156206965446\n",
      "epoch: 4 step: 1038, loss is 0.0015881996368989348\n",
      "epoch: 4 step: 1039, loss is 0.013446398079395294\n",
      "epoch: 4 step: 1040, loss is 0.0031060376204550266\n",
      "epoch: 4 step: 1041, loss is 0.0024494051467627287\n",
      "epoch: 4 step: 1042, loss is 0.007364517543464899\n",
      "epoch: 4 step: 1043, loss is 0.14320111274719238\n",
      "epoch: 4 step: 1044, loss is 0.0935288742184639\n",
      "epoch: 4 step: 1045, loss is 0.0003193441079929471\n",
      "epoch: 4 step: 1046, loss is 0.026109954342246056\n",
      "epoch: 4 step: 1047, loss is 0.005644512362778187\n",
      "epoch: 4 step: 1048, loss is 0.13534122705459595\n",
      "epoch: 4 step: 1049, loss is 0.08106224983930588\n",
      "epoch: 4 step: 1050, loss is 0.014630335383117199\n",
      "epoch: 4 step: 1051, loss is 0.0035121997352689505\n",
      "epoch: 4 step: 1052, loss is 0.03662686422467232\n",
      "epoch: 4 step: 1053, loss is 0.009417804889380932\n",
      "epoch: 4 step: 1054, loss is 0.04025759920477867\n",
      "epoch: 4 step: 1055, loss is 0.0014224133919924498\n",
      "epoch: 4 step: 1056, loss is 0.13063885271549225\n",
      "epoch: 4 step: 1057, loss is 0.043434128165245056\n",
      "epoch: 4 step: 1058, loss is 0.10622784495353699\n",
      "epoch: 4 step: 1059, loss is 0.003486047498881817\n",
      "epoch: 4 step: 1060, loss is 0.0005233300616964698\n",
      "epoch: 4 step: 1061, loss is 0.005095768719911575\n",
      "epoch: 4 step: 1062, loss is 0.21859529614448547\n",
      "epoch: 4 step: 1063, loss is 0.0001893217850010842\n",
      "epoch: 4 step: 1064, loss is 0.0710269883275032\n",
      "epoch: 4 step: 1065, loss is 0.17771607637405396\n",
      "epoch: 4 step: 1066, loss is 0.003363373689353466\n",
      "epoch: 4 step: 1067, loss is 0.003890044055879116\n",
      "epoch: 4 step: 1068, loss is 0.0012216074392199516\n",
      "epoch: 4 step: 1069, loss is 0.0016086641699075699\n",
      "epoch: 4 step: 1070, loss is 0.06178521364927292\n",
      "epoch: 4 step: 1071, loss is 0.057630281895399094\n",
      "epoch: 4 step: 1072, loss is 0.14747603237628937\n",
      "epoch: 4 step: 1073, loss is 0.0007228525937534869\n",
      "epoch: 4 step: 1074, loss is 0.002283148467540741\n",
      "epoch: 4 step: 1075, loss is 0.018651776015758514\n",
      "epoch: 4 step: 1076, loss is 0.004201845731586218\n",
      "epoch: 4 step: 1077, loss is 0.037224140018224716\n",
      "epoch: 4 step: 1078, loss is 0.0012472361559048295\n",
      "epoch: 4 step: 1079, loss is 0.0017179464921355247\n",
      "epoch: 4 step: 1080, loss is 0.021140405908226967\n",
      "epoch: 4 step: 1081, loss is 0.0023660422302782536\n",
      "epoch: 4 step: 1082, loss is 0.055495914071798325\n",
      "epoch: 4 step: 1083, loss is 0.002906478475779295\n",
      "epoch: 4 step: 1084, loss is 0.0001614411303307861\n",
      "epoch: 4 step: 1085, loss is 0.03504115343093872\n",
      "epoch: 4 step: 1086, loss is 0.0007304997998289764\n",
      "epoch: 4 step: 1087, loss is 0.0032856108155101538\n",
      "epoch: 4 step: 1088, loss is 0.06457770615816116\n",
      "epoch: 4 step: 1089, loss is 0.014876195229589939\n",
      "epoch: 4 step: 1090, loss is 0.002602769760414958\n",
      "epoch: 4 step: 1091, loss is 0.0008079832186922431\n",
      "epoch: 4 step: 1092, loss is 0.0035742006730288267\n",
      "epoch: 4 step: 1093, loss is 0.02131551131606102\n",
      "epoch: 4 step: 1094, loss is 0.0008542067371308804\n",
      "epoch: 4 step: 1095, loss is 0.009773478843271732\n",
      "epoch: 4 step: 1096, loss is 0.003457105252891779\n",
      "epoch: 4 step: 1097, loss is 0.00044802759657613933\n",
      "epoch: 4 step: 1098, loss is 0.0007562466198578477\n",
      "epoch: 4 step: 1099, loss is 0.004122256767004728\n",
      "epoch: 4 step: 1100, loss is 0.01943877898156643\n",
      "epoch: 4 step: 1101, loss is 0.0036657091695815325\n",
      "epoch: 4 step: 1102, loss is 0.0008437953074462712\n",
      "epoch: 4 step: 1103, loss is 0.0023952177725732327\n",
      "epoch: 4 step: 1104, loss is 0.09793323278427124\n",
      "epoch: 4 step: 1105, loss is 0.017382031306624413\n",
      "epoch: 4 step: 1106, loss is 0.04112257435917854\n",
      "epoch: 4 step: 1107, loss is 0.00018614568398334086\n",
      "epoch: 4 step: 1108, loss is 0.037953898310661316\n",
      "epoch: 4 step: 1109, loss is 0.0012685814872384071\n",
      "epoch: 4 step: 1110, loss is 0.012341988272964954\n",
      "epoch: 4 step: 1111, loss is 0.0007635977235622704\n",
      "epoch: 4 step: 1112, loss is 0.01563710719347\n",
      "epoch: 4 step: 1113, loss is 0.04093311354517937\n",
      "epoch: 4 step: 1114, loss is 0.040376123040914536\n",
      "epoch: 4 step: 1115, loss is 0.3147059977054596\n",
      "epoch: 4 step: 1116, loss is 0.0011683633783832192\n",
      "epoch: 4 step: 1117, loss is 0.00025747044128365815\n",
      "epoch: 4 step: 1118, loss is 0.029393170028924942\n",
      "epoch: 4 step: 1119, loss is 0.09031089395284653\n",
      "epoch: 4 step: 1120, loss is 0.041354916989803314\n",
      "epoch: 4 step: 1121, loss is 0.010124260559678078\n",
      "epoch: 4 step: 1122, loss is 0.0048012323677539825\n",
      "epoch: 4 step: 1123, loss is 0.04632068797945976\n",
      "epoch: 4 step: 1124, loss is 0.005365618504583836\n",
      "epoch: 4 step: 1125, loss is 0.008204437792301178\n",
      "epoch: 4 step: 1126, loss is 0.0009332475601695478\n",
      "epoch: 4 step: 1127, loss is 0.08263334631919861\n",
      "epoch: 4 step: 1128, loss is 0.27693605422973633\n",
      "epoch: 4 step: 1129, loss is 0.00014771470159757882\n",
      "epoch: 4 step: 1130, loss is 0.0012387940660119057\n",
      "epoch: 4 step: 1131, loss is 0.0052382852882146835\n",
      "epoch: 4 step: 1132, loss is 0.056514445692300797\n",
      "epoch: 4 step: 1133, loss is 0.00013614709314424545\n",
      "epoch: 4 step: 1134, loss is 0.029093917459249496\n",
      "epoch: 4 step: 1135, loss is 0.0008558670524507761\n",
      "epoch: 4 step: 1136, loss is 0.00955014768987894\n",
      "epoch: 4 step: 1137, loss is 0.06428662687540054\n",
      "epoch: 4 step: 1138, loss is 0.032980870455503464\n",
      "epoch: 4 step: 1139, loss is 0.0017684274353086948\n",
      "epoch: 4 step: 1140, loss is 0.07308898121118546\n",
      "epoch: 4 step: 1141, loss is 0.00044705657637678087\n",
      "epoch: 4 step: 1142, loss is 0.012431414797902107\n",
      "epoch: 4 step: 1143, loss is 0.193727508187294\n",
      "epoch: 4 step: 1144, loss is 0.008138738572597504\n",
      "epoch: 4 step: 1145, loss is 0.003941837698221207\n",
      "epoch: 4 step: 1146, loss is 0.001521429279819131\n",
      "epoch: 4 step: 1147, loss is 0.008069229312241077\n",
      "epoch: 4 step: 1148, loss is 0.0006977329612709582\n",
      "epoch: 4 step: 1149, loss is 0.15010860562324524\n",
      "epoch: 4 step: 1150, loss is 0.0013777537969872355\n",
      "epoch: 4 step: 1151, loss is 0.006759283132851124\n",
      "epoch: 4 step: 1152, loss is 0.0012834426015615463\n",
      "epoch: 4 step: 1153, loss is 0.006308449432253838\n",
      "epoch: 4 step: 1154, loss is 0.06512992084026337\n",
      "epoch: 4 step: 1155, loss is 0.0021539214067161083\n",
      "epoch: 4 step: 1156, loss is 0.05920146405696869\n",
      "epoch: 4 step: 1157, loss is 0.003661805298179388\n",
      "epoch: 4 step: 1158, loss is 0.002162069547921419\n",
      "epoch: 4 step: 1159, loss is 0.01574021205306053\n",
      "epoch: 4 step: 1160, loss is 0.0012430313508957624\n",
      "epoch: 4 step: 1161, loss is 0.0009207357652485371\n",
      "epoch: 4 step: 1162, loss is 0.025316547602415085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1163, loss is 0.13327668607234955\n",
      "epoch: 4 step: 1164, loss is 0.017580365762114525\n",
      "epoch: 4 step: 1165, loss is 0.0004910234129056334\n",
      "epoch: 4 step: 1166, loss is 0.0047319913282990456\n",
      "epoch: 4 step: 1167, loss is 0.0017475011991336942\n",
      "epoch: 4 step: 1168, loss is 0.002599089639261365\n",
      "epoch: 4 step: 1169, loss is 0.009779680520296097\n",
      "epoch: 4 step: 1170, loss is 0.24328143894672394\n",
      "epoch: 4 step: 1171, loss is 0.0007851325208321214\n",
      "epoch: 4 step: 1172, loss is 0.0004364686901681125\n",
      "epoch: 4 step: 1173, loss is 0.02714049071073532\n",
      "epoch: 4 step: 1174, loss is 0.001550914254039526\n",
      "epoch: 4 step: 1175, loss is 0.000793343991972506\n",
      "epoch: 4 step: 1176, loss is 0.01707279309630394\n",
      "epoch: 4 step: 1177, loss is 0.0016188689041882753\n",
      "epoch: 4 step: 1178, loss is 0.018018562346696854\n",
      "epoch: 4 step: 1179, loss is 0.02794157713651657\n",
      "epoch: 4 step: 1180, loss is 0.019281141459941864\n",
      "epoch: 4 step: 1181, loss is 0.0007306389161385596\n",
      "epoch: 4 step: 1182, loss is 0.0008392318850383162\n",
      "epoch: 4 step: 1183, loss is 0.029368005692958832\n",
      "epoch: 4 step: 1184, loss is 0.006197250913828611\n",
      "epoch: 4 step: 1185, loss is 0.018567124381661415\n",
      "epoch: 4 step: 1186, loss is 0.009319278411567211\n",
      "epoch: 4 step: 1187, loss is 0.003044262295588851\n",
      "epoch: 4 step: 1188, loss is 0.007087748032063246\n",
      "epoch: 4 step: 1189, loss is 0.001115200575441122\n",
      "epoch: 4 step: 1190, loss is 0.0013225397560745478\n",
      "epoch: 4 step: 1191, loss is 0.0026210639625787735\n",
      "epoch: 4 step: 1192, loss is 0.0007465459639206529\n",
      "epoch: 4 step: 1193, loss is 0.07012484967708588\n",
      "epoch: 4 step: 1194, loss is 0.006906910799443722\n",
      "epoch: 4 step: 1195, loss is 0.15934959053993225\n",
      "epoch: 4 step: 1196, loss is 0.004584388807415962\n",
      "epoch: 4 step: 1197, loss is 0.0020674108527600765\n",
      "epoch: 4 step: 1198, loss is 0.0009440779103897512\n",
      "epoch: 4 step: 1199, loss is 0.00209630629979074\n",
      "epoch: 4 step: 1200, loss is 0.004489985294640064\n",
      "epoch: 4 step: 1201, loss is 0.0006012633675709367\n",
      "epoch: 4 step: 1202, loss is 0.002444124547764659\n",
      "epoch: 4 step: 1203, loss is 0.0023160481359809637\n",
      "epoch: 4 step: 1204, loss is 0.0057642776519060135\n",
      "epoch: 4 step: 1205, loss is 0.01584816910326481\n",
      "epoch: 4 step: 1206, loss is 0.12046030163764954\n",
      "epoch: 4 step: 1207, loss is 0.005756748840212822\n",
      "epoch: 4 step: 1208, loss is 0.0009908528300002217\n",
      "epoch: 4 step: 1209, loss is 0.0015743483090773225\n",
      "epoch: 4 step: 1210, loss is 0.0004129036096855998\n",
      "epoch: 4 step: 1211, loss is 0.0694044753909111\n",
      "epoch: 4 step: 1212, loss is 0.058373644948005676\n",
      "epoch: 4 step: 1213, loss is 0.014856557361781597\n",
      "epoch: 4 step: 1214, loss is 0.0010356447892263532\n",
      "epoch: 4 step: 1215, loss is 0.16848614811897278\n",
      "epoch: 4 step: 1216, loss is 0.0014359792694449425\n",
      "epoch: 4 step: 1217, loss is 0.000658068573102355\n",
      "epoch: 4 step: 1218, loss is 4.146482751821168e-05\n",
      "epoch: 4 step: 1219, loss is 0.0026177566032856703\n",
      "epoch: 4 step: 1220, loss is 0.12491389364004135\n",
      "epoch: 4 step: 1221, loss is 0.11352290958166122\n",
      "epoch: 4 step: 1222, loss is 0.001707270392216742\n",
      "epoch: 4 step: 1223, loss is 0.04082585126161575\n",
      "epoch: 4 step: 1224, loss is 0.0004944795509800315\n",
      "epoch: 4 step: 1225, loss is 0.001193343778140843\n",
      "epoch: 4 step: 1226, loss is 0.002194702159613371\n",
      "epoch: 4 step: 1227, loss is 0.11920655518770218\n",
      "epoch: 4 step: 1228, loss is 0.0012449361383914948\n",
      "epoch: 4 step: 1229, loss is 0.020197387784719467\n",
      "epoch: 4 step: 1230, loss is 0.010940957814455032\n",
      "epoch: 4 step: 1231, loss is 0.0046540722250938416\n",
      "epoch: 4 step: 1232, loss is 0.0018515196861699224\n",
      "epoch: 4 step: 1233, loss is 0.0009386723977513611\n",
      "epoch: 4 step: 1234, loss is 0.020490318536758423\n",
      "epoch: 4 step: 1235, loss is 0.01347578875720501\n",
      "epoch: 4 step: 1236, loss is 0.003778713522478938\n",
      "epoch: 4 step: 1237, loss is 0.00030962435994297266\n",
      "epoch: 4 step: 1238, loss is 0.00022529484704136848\n",
      "epoch: 4 step: 1239, loss is 0.004411238711327314\n",
      "epoch: 4 step: 1240, loss is 0.0006980903563089669\n",
      "epoch: 4 step: 1241, loss is 0.03008859045803547\n",
      "epoch: 4 step: 1242, loss is 0.0008313339785672724\n",
      "epoch: 4 step: 1243, loss is 0.0005852060276083648\n",
      "epoch: 4 step: 1244, loss is 0.0023928829468786716\n",
      "epoch: 4 step: 1245, loss is 0.0004895685124211013\n",
      "epoch: 4 step: 1246, loss is 0.002184094162657857\n",
      "epoch: 4 step: 1247, loss is 0.003773908130824566\n",
      "epoch: 4 step: 1248, loss is 0.062389373779296875\n",
      "epoch: 4 step: 1249, loss is 0.0007036588503979146\n",
      "epoch: 4 step: 1250, loss is 7.694793021073565e-05\n",
      "epoch: 4 step: 1251, loss is 0.030179796740412712\n",
      "epoch: 4 step: 1252, loss is 0.010806596837937832\n",
      "epoch: 4 step: 1253, loss is 0.08490956574678421\n",
      "epoch: 4 step: 1254, loss is 0.022761398926377296\n",
      "epoch: 4 step: 1255, loss is 0.000850542273838073\n",
      "epoch: 4 step: 1256, loss is 0.008460832759737968\n",
      "epoch: 4 step: 1257, loss is 0.04845355451107025\n",
      "epoch: 4 step: 1258, loss is 0.0009094031411223114\n",
      "epoch: 4 step: 1259, loss is 0.0010913254227489233\n",
      "epoch: 4 step: 1260, loss is 0.012440075166523457\n",
      "epoch: 4 step: 1261, loss is 0.0013963168021291494\n",
      "epoch: 4 step: 1262, loss is 0.007965871132910252\n",
      "epoch: 4 step: 1263, loss is 0.07713010162115097\n",
      "epoch: 4 step: 1264, loss is 0.026145555078983307\n",
      "epoch: 4 step: 1265, loss is 0.005880782380700111\n",
      "epoch: 4 step: 1266, loss is 0.0006662948289886117\n",
      "epoch: 4 step: 1267, loss is 0.0017264342168346047\n",
      "epoch: 4 step: 1268, loss is 0.008490007370710373\n",
      "epoch: 4 step: 1269, loss is 0.007153769489377737\n",
      "epoch: 4 step: 1270, loss is 0.012201217003166676\n",
      "epoch: 4 step: 1271, loss is 0.009894834831357002\n",
      "epoch: 4 step: 1272, loss is 0.0589449480175972\n",
      "epoch: 4 step: 1273, loss is 0.005260704550892115\n",
      "epoch: 4 step: 1274, loss is 0.0009646923863328993\n",
      "epoch: 4 step: 1275, loss is 0.0009538537706248462\n",
      "epoch: 4 step: 1276, loss is 0.0026016016490757465\n",
      "epoch: 4 step: 1277, loss is 0.005037873983383179\n",
      "epoch: 4 step: 1278, loss is 0.0007812048424966633\n",
      "epoch: 4 step: 1279, loss is 0.0006591551355086267\n",
      "epoch: 4 step: 1280, loss is 0.024874843657016754\n",
      "epoch: 4 step: 1281, loss is 0.0237362552434206\n",
      "epoch: 4 step: 1282, loss is 0.012647265568375587\n",
      "epoch: 4 step: 1283, loss is 0.0009867422049865127\n",
      "epoch: 4 step: 1284, loss is 0.07627962529659271\n",
      "epoch: 4 step: 1285, loss is 0.0009927202481776476\n",
      "epoch: 4 step: 1286, loss is 0.004172757733613253\n",
      "epoch: 4 step: 1287, loss is 0.001527131418697536\n",
      "epoch: 4 step: 1288, loss is 0.0009511427488178015\n",
      "epoch: 4 step: 1289, loss is 0.0007258516852743924\n",
      "epoch: 4 step: 1290, loss is 0.0007780019077472389\n",
      "epoch: 4 step: 1291, loss is 0.014605105854570866\n",
      "epoch: 4 step: 1292, loss is 0.008949961513280869\n",
      "epoch: 4 step: 1293, loss is 0.005941534414887428\n",
      "epoch: 4 step: 1294, loss is 0.016290578991174698\n",
      "epoch: 4 step: 1295, loss is 0.0007532950839959085\n",
      "epoch: 4 step: 1296, loss is 0.06462918221950531\n",
      "epoch: 4 step: 1297, loss is 0.0008566421456634998\n",
      "epoch: 4 step: 1298, loss is 0.036503616720438004\n",
      "epoch: 4 step: 1299, loss is 0.0005988908815197647\n",
      "epoch: 4 step: 1300, loss is 0.048085931688547134\n",
      "epoch: 4 step: 1301, loss is 0.03674275800585747\n",
      "epoch: 4 step: 1302, loss is 5.0423219363437966e-05\n",
      "epoch: 4 step: 1303, loss is 0.0017575303791090846\n",
      "epoch: 4 step: 1304, loss is 0.00017386206309311092\n",
      "epoch: 4 step: 1305, loss is 0.006326295435428619\n",
      "epoch: 4 step: 1306, loss is 0.0031473797280341387\n",
      "epoch: 4 step: 1307, loss is 0.017003579065203667\n",
      "epoch: 4 step: 1308, loss is 0.009074358269572258\n",
      "epoch: 4 step: 1309, loss is 0.23719219863414764\n",
      "epoch: 4 step: 1310, loss is 0.009944385848939419\n",
      "epoch: 4 step: 1311, loss is 0.00013390523963607848\n",
      "epoch: 4 step: 1312, loss is 0.0024672667495906353\n",
      "epoch: 4 step: 1313, loss is 0.0032089240849018097\n",
      "epoch: 4 step: 1314, loss is 0.00035616508102975786\n",
      "epoch: 4 step: 1315, loss is 0.007341104559600353\n",
      "epoch: 4 step: 1316, loss is 0.0021072227973490953\n",
      "epoch: 4 step: 1317, loss is 0.009161443449556828\n",
      "epoch: 4 step: 1318, loss is 0.0020459918305277824\n",
      "epoch: 4 step: 1319, loss is 0.05730897933244705\n",
      "epoch: 4 step: 1320, loss is 0.0033559820149093866\n",
      "epoch: 4 step: 1321, loss is 0.0025112575385719538\n",
      "epoch: 4 step: 1322, loss is 0.004957898519933224\n",
      "epoch: 4 step: 1323, loss is 0.007072661072015762\n",
      "epoch: 4 step: 1324, loss is 0.011167758144438267\n",
      "epoch: 4 step: 1325, loss is 0.00013216622755862772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1326, loss is 0.00540496688336134\n",
      "epoch: 4 step: 1327, loss is 0.022037958726286888\n",
      "epoch: 4 step: 1328, loss is 2.7542782845557667e-05\n",
      "epoch: 4 step: 1329, loss is 0.04851479083299637\n",
      "epoch: 4 step: 1330, loss is 0.0004553919134195894\n",
      "epoch: 4 step: 1331, loss is 3.379713598405942e-05\n",
      "epoch: 4 step: 1332, loss is 6.583658250747249e-05\n",
      "epoch: 4 step: 1333, loss is 0.0006837433320470154\n",
      "epoch: 4 step: 1334, loss is 0.0007027848623692989\n",
      "epoch: 4 step: 1335, loss is 9.864909225143492e-05\n",
      "epoch: 4 step: 1336, loss is 0.09147511422634125\n",
      "epoch: 4 step: 1337, loss is 0.1657121479511261\n",
      "epoch: 4 step: 1338, loss is 0.158108189702034\n",
      "epoch: 4 step: 1339, loss is 0.009282732382416725\n",
      "epoch: 4 step: 1340, loss is 0.0005698908935301006\n",
      "epoch: 4 step: 1341, loss is 0.007993726059794426\n",
      "epoch: 4 step: 1342, loss is 0.23039890825748444\n",
      "epoch: 4 step: 1343, loss is 0.001807568478398025\n",
      "epoch: 4 step: 1344, loss is 0.001102923764847219\n",
      "epoch: 4 step: 1345, loss is 0.005490363575518131\n",
      "epoch: 4 step: 1346, loss is 0.007001417223364115\n",
      "epoch: 4 step: 1347, loss is 0.0019967174157500267\n",
      "epoch: 4 step: 1348, loss is 0.21516165137290955\n",
      "epoch: 4 step: 1349, loss is 0.0012327382573857903\n",
      "epoch: 4 step: 1350, loss is 0.0005369811551645398\n",
      "epoch: 4 step: 1351, loss is 0.0428355373442173\n",
      "epoch: 4 step: 1352, loss is 0.029717762023210526\n",
      "epoch: 4 step: 1353, loss is 0.001379135763272643\n",
      "epoch: 4 step: 1354, loss is 0.11048515141010284\n",
      "epoch: 4 step: 1355, loss is 0.18806882202625275\n",
      "epoch: 4 step: 1356, loss is 0.09437184780836105\n",
      "epoch: 4 step: 1357, loss is 0.0004094045434612781\n",
      "epoch: 4 step: 1358, loss is 0.0030990089289844036\n",
      "epoch: 4 step: 1359, loss is 0.0007334472029469907\n",
      "epoch: 4 step: 1360, loss is 0.004444412421435118\n",
      "epoch: 4 step: 1361, loss is 0.0009032629895955324\n",
      "epoch: 4 step: 1362, loss is 0.0037890381645411253\n",
      "epoch: 4 step: 1363, loss is 0.044334735721349716\n",
      "epoch: 4 step: 1364, loss is 0.0060239797458052635\n",
      "epoch: 4 step: 1365, loss is 0.02057379111647606\n",
      "epoch: 4 step: 1366, loss is 0.01766086183488369\n",
      "epoch: 4 step: 1367, loss is 0.10809886455535889\n",
      "epoch: 4 step: 1368, loss is 0.0008969391346909106\n",
      "epoch: 4 step: 1369, loss is 0.0006935519049875438\n",
      "epoch: 4 step: 1370, loss is 0.07004407048225403\n",
      "epoch: 4 step: 1371, loss is 0.029395325109362602\n",
      "epoch: 4 step: 1372, loss is 0.06739573180675507\n",
      "epoch: 4 step: 1373, loss is 0.01627347804605961\n",
      "epoch: 4 step: 1374, loss is 0.0005787882837466896\n",
      "epoch: 4 step: 1375, loss is 0.10925493389368057\n",
      "epoch: 4 step: 1376, loss is 0.14773353934288025\n",
      "epoch: 4 step: 1377, loss is 0.004005065653473139\n",
      "epoch: 4 step: 1378, loss is 0.04500173032283783\n",
      "epoch: 4 step: 1379, loss is 0.02623657137155533\n",
      "epoch: 4 step: 1380, loss is 0.005656033288687468\n",
      "epoch: 4 step: 1381, loss is 0.0017681431490927935\n",
      "epoch: 4 step: 1382, loss is 0.052188847213983536\n",
      "epoch: 4 step: 1383, loss is 0.05413892865180969\n",
      "epoch: 4 step: 1384, loss is 0.0013174808118492365\n",
      "epoch: 4 step: 1385, loss is 0.001693528494797647\n",
      "epoch: 4 step: 1386, loss is 0.011494571343064308\n",
      "epoch: 4 step: 1387, loss is 0.011406096629798412\n",
      "epoch: 4 step: 1388, loss is 0.014214239083230495\n",
      "epoch: 4 step: 1389, loss is 0.0006140176556073129\n",
      "epoch: 4 step: 1390, loss is 0.00017767175449989736\n",
      "epoch: 4 step: 1391, loss is 0.0015054731629788876\n",
      "epoch: 4 step: 1392, loss is 0.0024287800770252943\n",
      "epoch: 4 step: 1393, loss is 0.0007827137596905231\n",
      "epoch: 4 step: 1394, loss is 0.08931168168783188\n",
      "epoch: 4 step: 1395, loss is 0.1175229549407959\n",
      "epoch: 4 step: 1396, loss is 0.0065108793787658215\n",
      "epoch: 4 step: 1397, loss is 0.0074461097829043865\n",
      "epoch: 4 step: 1398, loss is 4.8663750931154937e-05\n",
      "epoch: 4 step: 1399, loss is 0.009361623786389828\n",
      "epoch: 4 step: 1400, loss is 0.09115961194038391\n",
      "epoch: 4 step: 1401, loss is 0.020326750352978706\n",
      "epoch: 4 step: 1402, loss is 0.02187173441052437\n",
      "epoch: 4 step: 1403, loss is 0.0011735878651961684\n",
      "epoch: 4 step: 1404, loss is 0.007243433967232704\n",
      "epoch: 4 step: 1405, loss is 0.07406476885080338\n",
      "epoch: 4 step: 1406, loss is 0.015207950957119465\n",
      "epoch: 4 step: 1407, loss is 0.027115099132061005\n",
      "epoch: 4 step: 1408, loss is 0.020100541412830353\n",
      "epoch: 4 step: 1409, loss is 0.07511354237794876\n",
      "epoch: 4 step: 1410, loss is 0.007589495275169611\n",
      "epoch: 4 step: 1411, loss is 0.0005454440251924098\n",
      "epoch: 4 step: 1412, loss is 0.0008791718864813447\n",
      "epoch: 4 step: 1413, loss is 0.009642724879086018\n",
      "epoch: 4 step: 1414, loss is 0.03582746535539627\n",
      "epoch: 4 step: 1415, loss is 0.0006312711630016565\n",
      "epoch: 4 step: 1416, loss is 0.004573986865580082\n",
      "epoch: 4 step: 1417, loss is 0.016953058540821075\n",
      "epoch: 4 step: 1418, loss is 0.0031120306812226772\n",
      "epoch: 4 step: 1419, loss is 0.03769107535481453\n",
      "epoch: 4 step: 1420, loss is 0.0007018496398814023\n",
      "epoch: 4 step: 1421, loss is 0.0017086210427805781\n",
      "epoch: 4 step: 1422, loss is 0.002571525052189827\n",
      "epoch: 4 step: 1423, loss is 0.001314632361754775\n",
      "epoch: 4 step: 1424, loss is 0.0002480919356457889\n",
      "epoch: 4 step: 1425, loss is 0.0003251848975196481\n",
      "epoch: 4 step: 1426, loss is 0.08000548928976059\n",
      "epoch: 4 step: 1427, loss is 0.014242990873754025\n",
      "epoch: 4 step: 1428, loss is 0.046188388019800186\n",
      "epoch: 4 step: 1429, loss is 0.016156278550624847\n",
      "epoch: 4 step: 1430, loss is 0.0007657365640625358\n",
      "epoch: 4 step: 1431, loss is 0.0008457654621452093\n",
      "epoch: 4 step: 1432, loss is 0.0012776822550222278\n",
      "epoch: 4 step: 1433, loss is 0.02006739191710949\n",
      "epoch: 4 step: 1434, loss is 0.003263093065470457\n",
      "epoch: 4 step: 1435, loss is 0.02528972737491131\n",
      "epoch: 4 step: 1436, loss is 0.2866989076137543\n",
      "epoch: 4 step: 1437, loss is 0.041528116911649704\n",
      "epoch: 4 step: 1438, loss is 0.04711240902543068\n",
      "epoch: 4 step: 1439, loss is 0.0014059243258088827\n",
      "epoch: 4 step: 1440, loss is 0.011327816173434258\n",
      "epoch: 4 step: 1441, loss is 0.17389421164989471\n",
      "epoch: 4 step: 1442, loss is 0.054240576922893524\n",
      "epoch: 4 step: 1443, loss is 0.0007624312420375645\n",
      "epoch: 4 step: 1444, loss is 0.0007905706879682839\n",
      "epoch: 4 step: 1445, loss is 0.014868360944092274\n",
      "epoch: 4 step: 1446, loss is 0.0036882120184600353\n",
      "epoch: 4 step: 1447, loss is 0.03874366357922554\n",
      "epoch: 4 step: 1448, loss is 0.2060449868440628\n",
      "epoch: 4 step: 1449, loss is 0.0017823155503720045\n",
      "epoch: 4 step: 1450, loss is 0.056463439017534256\n",
      "epoch: 4 step: 1451, loss is 0.008661921136081219\n",
      "epoch: 4 step: 1452, loss is 0.02552640810608864\n",
      "epoch: 4 step: 1453, loss is 0.017555316910147667\n",
      "epoch: 4 step: 1454, loss is 0.00026818260084837675\n",
      "epoch: 4 step: 1455, loss is 0.026965253055095673\n",
      "epoch: 4 step: 1456, loss is 0.007001922931522131\n",
      "epoch: 4 step: 1457, loss is 0.025193555280566216\n",
      "epoch: 4 step: 1458, loss is 0.014589108526706696\n",
      "epoch: 4 step: 1459, loss is 0.02099839597940445\n",
      "epoch: 4 step: 1460, loss is 0.10416615754365921\n",
      "epoch: 4 step: 1461, loss is 0.00046462813043035567\n",
      "epoch: 4 step: 1462, loss is 0.018222011625766754\n",
      "epoch: 4 step: 1463, loss is 0.007248085457831621\n",
      "epoch: 4 step: 1464, loss is 0.0006936839781701565\n",
      "epoch: 4 step: 1465, loss is 0.03215199336409569\n",
      "epoch: 4 step: 1466, loss is 0.16952519118785858\n",
      "epoch: 4 step: 1467, loss is 0.0020836107432842255\n",
      "epoch: 4 step: 1468, loss is 0.05536332726478577\n",
      "epoch: 4 step: 1469, loss is 0.12512442469596863\n",
      "epoch: 4 step: 1470, loss is 0.007341165095567703\n",
      "epoch: 4 step: 1471, loss is 0.0010067119728773832\n",
      "epoch: 4 step: 1472, loss is 0.002097626682370901\n",
      "epoch: 4 step: 1473, loss is 0.020597781985998154\n",
      "epoch: 4 step: 1474, loss is 0.009631745517253876\n",
      "epoch: 4 step: 1475, loss is 0.006728527136147022\n",
      "epoch: 4 step: 1476, loss is 0.024404510855674744\n",
      "epoch: 4 step: 1477, loss is 0.051946885883808136\n",
      "epoch: 4 step: 1478, loss is 0.0007581310346722603\n",
      "epoch: 4 step: 1479, loss is 0.00966417882591486\n",
      "epoch: 4 step: 1480, loss is 0.003905117278918624\n",
      "epoch: 4 step: 1481, loss is 0.18639294803142548\n",
      "epoch: 4 step: 1482, loss is 0.02791280299425125\n",
      "epoch: 4 step: 1483, loss is 0.0038345595821738243\n",
      "epoch: 4 step: 1484, loss is 0.001105444971472025\n",
      "epoch: 4 step: 1485, loss is 0.0029976842924952507\n",
      "epoch: 4 step: 1486, loss is 0.006309225223958492\n",
      "epoch: 4 step: 1487, loss is 0.06257473677396774\n",
      "epoch: 4 step: 1488, loss is 0.0007061850628815591\n",
      "epoch: 4 step: 1489, loss is 0.09140376001596451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1490, loss is 0.006798615213483572\n",
      "epoch: 4 step: 1491, loss is 0.012471815571188927\n",
      "epoch: 4 step: 1492, loss is 0.11644445359706879\n",
      "epoch: 4 step: 1493, loss is 0.02295074053108692\n",
      "epoch: 4 step: 1494, loss is 0.0008126187021844089\n",
      "epoch: 4 step: 1495, loss is 0.016049649566411972\n",
      "epoch: 4 step: 1496, loss is 0.001547710387967527\n",
      "epoch: 4 step: 1497, loss is 0.024499155580997467\n",
      "epoch: 4 step: 1498, loss is 0.0861414447426796\n",
      "epoch: 4 step: 1499, loss is 0.024868054315447807\n",
      "epoch: 4 step: 1500, loss is 0.0005923531716689467\n",
      "epoch: 4 step: 1501, loss is 0.0005091030616313219\n",
      "epoch: 4 step: 1502, loss is 0.0010760019067674875\n",
      "epoch: 4 step: 1503, loss is 0.16737380623817444\n",
      "epoch: 4 step: 1504, loss is 0.0017033580224961042\n",
      "epoch: 4 step: 1505, loss is 0.054617855697870255\n",
      "epoch: 4 step: 1506, loss is 0.0022722824942320585\n",
      "epoch: 4 step: 1507, loss is 0.0030315082985907793\n",
      "epoch: 4 step: 1508, loss is 0.10833270102739334\n",
      "epoch: 4 step: 1509, loss is 0.0017677375581115484\n",
      "epoch: 4 step: 1510, loss is 0.003088835161179304\n",
      "epoch: 4 step: 1511, loss is 0.0020310557447373867\n",
      "epoch: 4 step: 1512, loss is 0.05501219630241394\n",
      "epoch: 4 step: 1513, loss is 0.0164694394916296\n",
      "epoch: 4 step: 1514, loss is 0.0073488615453243256\n",
      "epoch: 4 step: 1515, loss is 0.0061129010282456875\n",
      "epoch: 4 step: 1516, loss is 0.011709870770573616\n",
      "epoch: 4 step: 1517, loss is 0.0005990288336761296\n",
      "epoch: 4 step: 1518, loss is 0.021489568054676056\n",
      "epoch: 4 step: 1519, loss is 0.08623529970645905\n",
      "epoch: 4 step: 1520, loss is 0.11573626101016998\n",
      "epoch: 4 step: 1521, loss is 0.02014084905385971\n",
      "epoch: 4 step: 1522, loss is 0.0045990063808858395\n",
      "epoch: 4 step: 1523, loss is 0.021781491115689278\n",
      "epoch: 4 step: 1524, loss is 0.0724586695432663\n",
      "epoch: 4 step: 1525, loss is 0.009508072398602962\n",
      "epoch: 4 step: 1526, loss is 0.007518061436712742\n",
      "epoch: 4 step: 1527, loss is 0.00264817476272583\n",
      "epoch: 4 step: 1528, loss is 0.00013595918426290154\n",
      "epoch: 4 step: 1529, loss is 0.23114728927612305\n",
      "epoch: 4 step: 1530, loss is 0.03486456722021103\n",
      "epoch: 4 step: 1531, loss is 0.0020692634861916304\n",
      "epoch: 4 step: 1532, loss is 0.004152590408921242\n",
      "epoch: 4 step: 1533, loss is 0.04938045144081116\n",
      "epoch: 4 step: 1534, loss is 0.0012153441784903407\n",
      "epoch: 4 step: 1535, loss is 0.013404404744505882\n",
      "epoch: 4 step: 1536, loss is 0.004736006259918213\n",
      "epoch: 4 step: 1537, loss is 0.033782538026571274\n",
      "epoch: 4 step: 1538, loss is 0.0006142011261545122\n",
      "epoch: 4 step: 1539, loss is 0.024563999846577644\n",
      "epoch: 4 step: 1540, loss is 0.03439133241772652\n",
      "epoch: 4 step: 1541, loss is 0.0020681344904005527\n",
      "epoch: 4 step: 1542, loss is 0.0011237713042646646\n",
      "epoch: 4 step: 1543, loss is 0.01969210058450699\n",
      "epoch: 4 step: 1544, loss is 0.0068905651569366455\n",
      "epoch: 4 step: 1545, loss is 0.007836959324777126\n",
      "epoch: 4 step: 1546, loss is 0.1759272813796997\n",
      "epoch: 4 step: 1547, loss is 0.00011415448534535244\n",
      "epoch: 4 step: 1548, loss is 0.013580880127847195\n",
      "epoch: 4 step: 1549, loss is 0.0186089426279068\n",
      "epoch: 4 step: 1550, loss is 0.05381618067622185\n",
      "epoch: 4 step: 1551, loss is 0.11253487318754196\n",
      "epoch: 4 step: 1552, loss is 0.04967606067657471\n",
      "epoch: 4 step: 1553, loss is 0.00020297980518080294\n",
      "epoch: 4 step: 1554, loss is 0.009554000571370125\n",
      "epoch: 4 step: 1555, loss is 0.0007867210078984499\n",
      "epoch: 4 step: 1556, loss is 0.09623406082391739\n",
      "epoch: 4 step: 1557, loss is 0.01795533113181591\n",
      "epoch: 4 step: 1558, loss is 0.18638025224208832\n",
      "epoch: 4 step: 1559, loss is 0.02699810080230236\n",
      "epoch: 4 step: 1560, loss is 0.0013762910384684801\n",
      "epoch: 4 step: 1561, loss is 0.1925404816865921\n",
      "epoch: 4 step: 1562, loss is 0.0001796772558009252\n",
      "epoch: 4 step: 1563, loss is 0.000685398408677429\n",
      "epoch: 4 step: 1564, loss is 0.09764830768108368\n",
      "epoch: 4 step: 1565, loss is 0.020413702353835106\n",
      "epoch: 4 step: 1566, loss is 0.00845528393983841\n",
      "epoch: 4 step: 1567, loss is 0.05894717574119568\n",
      "epoch: 4 step: 1568, loss is 0.0044393702410161495\n",
      "epoch: 4 step: 1569, loss is 0.0003765514411497861\n",
      "epoch: 4 step: 1570, loss is 0.05404316633939743\n",
      "epoch: 4 step: 1571, loss is 0.049324747174978256\n",
      "epoch: 4 step: 1572, loss is 0.02026250958442688\n",
      "epoch: 4 step: 1573, loss is 0.054406289011240005\n",
      "epoch: 4 step: 1574, loss is 0.0007126324926503003\n",
      "epoch: 4 step: 1575, loss is 0.04048948734998703\n",
      "epoch: 4 step: 1576, loss is 0.023063763976097107\n",
      "epoch: 4 step: 1577, loss is 0.000708283856511116\n",
      "epoch: 4 step: 1578, loss is 0.0015590718248859048\n",
      "epoch: 4 step: 1579, loss is 0.0022209808230400085\n",
      "epoch: 4 step: 1580, loss is 0.08693201839923859\n",
      "epoch: 4 step: 1581, loss is 0.09330901503562927\n",
      "epoch: 4 step: 1582, loss is 0.02318963035941124\n",
      "epoch: 4 step: 1583, loss is 0.004529127851128578\n",
      "epoch: 4 step: 1584, loss is 0.002447176491841674\n",
      "epoch: 4 step: 1585, loss is 0.024547040462493896\n",
      "epoch: 4 step: 1586, loss is 0.009783286601305008\n",
      "epoch: 4 step: 1587, loss is 0.09285223484039307\n",
      "epoch: 4 step: 1588, loss is 0.11372590810060501\n",
      "epoch: 4 step: 1589, loss is 0.00891190953552723\n",
      "epoch: 4 step: 1590, loss is 0.0026198644191026688\n",
      "epoch: 4 step: 1591, loss is 0.06589484214782715\n",
      "epoch: 4 step: 1592, loss is 0.0035223893355578184\n",
      "epoch: 4 step: 1593, loss is 0.01917102560400963\n",
      "epoch: 4 step: 1594, loss is 0.0011973120272159576\n",
      "epoch: 4 step: 1595, loss is 0.0017561421263962984\n",
      "epoch: 4 step: 1596, loss is 0.2515397369861603\n",
      "epoch: 4 step: 1597, loss is 0.009452697820961475\n",
      "epoch: 4 step: 1598, loss is 0.06202581897377968\n",
      "epoch: 4 step: 1599, loss is 0.009011783637106419\n",
      "epoch: 4 step: 1600, loss is 0.0008661674219183624\n",
      "epoch: 4 step: 1601, loss is 0.0034059020690619946\n",
      "epoch: 4 step: 1602, loss is 0.25465127825737\n",
      "epoch: 4 step: 1603, loss is 0.009151628240942955\n",
      "epoch: 4 step: 1604, loss is 0.003998539876192808\n",
      "epoch: 4 step: 1605, loss is 0.0015980302123352885\n",
      "epoch: 4 step: 1606, loss is 0.0008262788760475814\n",
      "epoch: 4 step: 1607, loss is 0.0033501763828098774\n",
      "epoch: 4 step: 1608, loss is 0.07808445394039154\n",
      "epoch: 4 step: 1609, loss is 0.014924896880984306\n",
      "epoch: 4 step: 1610, loss is 0.007539762184023857\n",
      "epoch: 4 step: 1611, loss is 0.0025560164358466864\n",
      "epoch: 4 step: 1612, loss is 0.0879800096154213\n",
      "epoch: 4 step: 1613, loss is 0.06335660815238953\n",
      "epoch: 4 step: 1614, loss is 0.05478644743561745\n",
      "epoch: 4 step: 1615, loss is 0.0064940983429551125\n",
      "epoch: 4 step: 1616, loss is 0.002050803042948246\n",
      "epoch: 4 step: 1617, loss is 0.0028129960410296917\n",
      "epoch: 4 step: 1618, loss is 0.0006185013335198164\n",
      "epoch: 4 step: 1619, loss is 0.012417209334671497\n",
      "epoch: 4 step: 1620, loss is 0.24783413112163544\n",
      "epoch: 4 step: 1621, loss is 0.0008833676110953093\n",
      "epoch: 4 step: 1622, loss is 0.06482294946908951\n",
      "epoch: 4 step: 1623, loss is 0.007957227528095245\n",
      "epoch: 4 step: 1624, loss is 0.0036469693295657635\n",
      "epoch: 4 step: 1625, loss is 0.004009241703897715\n",
      "epoch: 4 step: 1626, loss is 0.0002946348977275193\n",
      "epoch: 4 step: 1627, loss is 0.049451325088739395\n",
      "epoch: 4 step: 1628, loss is 0.07384506613016129\n",
      "epoch: 4 step: 1629, loss is 0.0003229006251785904\n",
      "epoch: 4 step: 1630, loss is 0.025172168388962746\n",
      "epoch: 4 step: 1631, loss is 0.32286345958709717\n",
      "epoch: 4 step: 1632, loss is 0.00018360215472057462\n",
      "epoch: 4 step: 1633, loss is 0.03917651250958443\n",
      "epoch: 4 step: 1634, loss is 0.0789022371172905\n",
      "epoch: 4 step: 1635, loss is 0.03183433413505554\n",
      "epoch: 4 step: 1636, loss is 0.013225367292761803\n",
      "epoch: 4 step: 1637, loss is 0.05886489897966385\n",
      "epoch: 4 step: 1638, loss is 0.000398123636841774\n",
      "epoch: 4 step: 1639, loss is 0.11767987161874771\n",
      "epoch: 4 step: 1640, loss is 0.001070265076123178\n",
      "epoch: 4 step: 1641, loss is 0.07365211844444275\n",
      "epoch: 4 step: 1642, loss is 0.03954007104039192\n",
      "epoch: 4 step: 1643, loss is 0.07281544804573059\n",
      "epoch: 4 step: 1644, loss is 0.022155409678816795\n",
      "epoch: 4 step: 1645, loss is 0.006442962680011988\n",
      "epoch: 4 step: 1646, loss is 0.003594613866880536\n",
      "epoch: 4 step: 1647, loss is 0.0005825417465530336\n",
      "epoch: 4 step: 1648, loss is 0.028922878205776215\n",
      "epoch: 4 step: 1649, loss is 0.00027952835080213845\n",
      "epoch: 4 step: 1650, loss is 0.16572526097297668\n",
      "epoch: 4 step: 1651, loss is 0.11490130424499512\n",
      "epoch: 4 step: 1652, loss is 0.12206196039915085\n",
      "epoch: 4 step: 1653, loss is 0.029539626091718674\n",
      "epoch: 4 step: 1654, loss is 0.08042023330926895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1655, loss is 0.019297746941447258\n",
      "epoch: 4 step: 1656, loss is 0.0014408560236915946\n",
      "epoch: 4 step: 1657, loss is 0.0013934141024947166\n",
      "epoch: 4 step: 1658, loss is 0.09074416011571884\n",
      "epoch: 4 step: 1659, loss is 0.25131648778915405\n",
      "epoch: 4 step: 1660, loss is 0.08350413292646408\n",
      "epoch: 4 step: 1661, loss is 0.0006256008055061102\n",
      "epoch: 4 step: 1662, loss is 0.013790881261229515\n",
      "epoch: 4 step: 1663, loss is 0.014183282852172852\n",
      "epoch: 4 step: 1664, loss is 0.004509226884692907\n",
      "epoch: 4 step: 1665, loss is 0.011407813057303429\n",
      "epoch: 4 step: 1666, loss is 0.002147125545889139\n",
      "epoch: 4 step: 1667, loss is 0.0027932715602219105\n",
      "epoch: 4 step: 1668, loss is 0.06200003996491432\n",
      "epoch: 4 step: 1669, loss is 0.007775409612804651\n",
      "epoch: 4 step: 1670, loss is 0.007403937168419361\n",
      "epoch: 4 step: 1671, loss is 0.010766152292490005\n",
      "epoch: 4 step: 1672, loss is 0.000759364920668304\n",
      "epoch: 4 step: 1673, loss is 0.00740487314760685\n",
      "epoch: 4 step: 1674, loss is 0.001327462843619287\n",
      "epoch: 4 step: 1675, loss is 0.009506996721029282\n",
      "epoch: 4 step: 1676, loss is 0.0011574290692806244\n",
      "epoch: 4 step: 1677, loss is 0.014742791652679443\n",
      "epoch: 4 step: 1678, loss is 0.028175735846161842\n",
      "epoch: 4 step: 1679, loss is 0.09106362611055374\n",
      "epoch: 4 step: 1680, loss is 0.006841215305030346\n",
      "epoch: 4 step: 1681, loss is 0.0011492744088172913\n",
      "epoch: 4 step: 1682, loss is 0.0035764009226113558\n",
      "epoch: 4 step: 1683, loss is 0.007115841377526522\n",
      "epoch: 4 step: 1684, loss is 0.006097139324992895\n",
      "epoch: 4 step: 1685, loss is 0.023342549800872803\n",
      "epoch: 4 step: 1686, loss is 0.00036026083398610353\n",
      "epoch: 4 step: 1687, loss is 0.00042140690493397415\n",
      "epoch: 4 step: 1688, loss is 0.014962871558964252\n",
      "epoch: 4 step: 1689, loss is 0.06256560981273651\n",
      "epoch: 4 step: 1690, loss is 0.07893569767475128\n",
      "epoch: 4 step: 1691, loss is 0.05149354040622711\n",
      "epoch: 4 step: 1692, loss is 0.0064716036431491375\n",
      "epoch: 4 step: 1693, loss is 0.016392383724451065\n",
      "epoch: 4 step: 1694, loss is 0.0034673085901886225\n",
      "epoch: 4 step: 1695, loss is 0.003221016377210617\n",
      "epoch: 4 step: 1696, loss is 0.06291316449642181\n",
      "epoch: 4 step: 1697, loss is 0.01389837171882391\n",
      "epoch: 4 step: 1698, loss is 0.003954870626330376\n",
      "epoch: 4 step: 1699, loss is 0.004583375528454781\n",
      "epoch: 4 step: 1700, loss is 0.0001957678032340482\n",
      "epoch: 4 step: 1701, loss is 0.0017189534846693277\n",
      "epoch: 4 step: 1702, loss is 0.020011302083730698\n",
      "epoch: 4 step: 1703, loss is 0.019231228157877922\n",
      "epoch: 4 step: 1704, loss is 0.0025391741655766964\n",
      "epoch: 4 step: 1705, loss is 0.010446096770465374\n",
      "epoch: 4 step: 1706, loss is 0.012813636101782322\n",
      "epoch: 4 step: 1707, loss is 0.053513262420892715\n",
      "epoch: 4 step: 1708, loss is 0.1016831174492836\n",
      "epoch: 4 step: 1709, loss is 0.001347354962490499\n",
      "epoch: 4 step: 1710, loss is 0.010531862266361713\n",
      "epoch: 4 step: 1711, loss is 0.002566668437793851\n",
      "epoch: 4 step: 1712, loss is 0.06027138978242874\n",
      "epoch: 4 step: 1713, loss is 8.623865141998976e-05\n",
      "epoch: 4 step: 1714, loss is 0.02952432818710804\n",
      "epoch: 4 step: 1715, loss is 0.014013798907399178\n",
      "epoch: 4 step: 1716, loss is 0.0023594843223690987\n",
      "epoch: 4 step: 1717, loss is 0.0006496363785117865\n",
      "epoch: 4 step: 1718, loss is 0.008095462806522846\n",
      "epoch: 4 step: 1719, loss is 0.015158871188759804\n",
      "epoch: 4 step: 1720, loss is 0.0032258867286145687\n",
      "epoch: 4 step: 1721, loss is 0.0009774784557521343\n",
      "epoch: 4 step: 1722, loss is 0.11212088912725449\n",
      "epoch: 4 step: 1723, loss is 0.0023110604379326105\n",
      "epoch: 4 step: 1724, loss is 0.008985948748886585\n",
      "epoch: 4 step: 1725, loss is 0.010644347406923771\n",
      "epoch: 4 step: 1726, loss is 0.0004551956371869892\n",
      "epoch: 4 step: 1727, loss is 0.019238902255892754\n",
      "epoch: 4 step: 1728, loss is 0.0028317715041339397\n",
      "epoch: 4 step: 1729, loss is 0.03231876343488693\n",
      "epoch: 4 step: 1730, loss is 0.0009068590006791055\n",
      "epoch: 4 step: 1731, loss is 0.0011706473305821419\n",
      "epoch: 4 step: 1732, loss is 0.017925351858139038\n",
      "epoch: 4 step: 1733, loss is 0.03649948537349701\n",
      "epoch: 4 step: 1734, loss is 0.00904223695397377\n",
      "epoch: 4 step: 1735, loss is 0.22560134530067444\n",
      "epoch: 4 step: 1736, loss is 0.021867787465453148\n",
      "epoch: 4 step: 1737, loss is 0.0004577796207740903\n",
      "epoch: 4 step: 1738, loss is 0.0016196025535464287\n",
      "epoch: 4 step: 1739, loss is 0.0020581367425620556\n",
      "epoch: 4 step: 1740, loss is 0.003900469047948718\n",
      "epoch: 4 step: 1741, loss is 0.0002613775432109833\n",
      "epoch: 4 step: 1742, loss is 0.055741239339113235\n",
      "epoch: 4 step: 1743, loss is 0.0025058910250663757\n",
      "epoch: 4 step: 1744, loss is 0.02082335203886032\n",
      "epoch: 4 step: 1745, loss is 0.028260692954063416\n",
      "epoch: 4 step: 1746, loss is 0.0010656388476490974\n",
      "epoch: 4 step: 1747, loss is 0.0007144162082113326\n",
      "epoch: 4 step: 1748, loss is 0.015837883576750755\n",
      "epoch: 4 step: 1749, loss is 0.06863991916179657\n",
      "epoch: 4 step: 1750, loss is 0.0003634269523900002\n",
      "epoch: 4 step: 1751, loss is 0.037232570350170135\n",
      "epoch: 4 step: 1752, loss is 0.002943057334050536\n",
      "epoch: 4 step: 1753, loss is 0.000662769190967083\n",
      "epoch: 4 step: 1754, loss is 0.0011768226977437735\n",
      "epoch: 4 step: 1755, loss is 0.006429687142372131\n",
      "epoch: 4 step: 1756, loss is 0.0005310190026648343\n",
      "epoch: 4 step: 1757, loss is 0.0009782807901501656\n",
      "epoch: 4 step: 1758, loss is 0.11518401652574539\n",
      "epoch: 4 step: 1759, loss is 0.001676969463005662\n",
      "epoch: 4 step: 1760, loss is 0.006041411310434341\n",
      "epoch: 4 step: 1761, loss is 0.009436430409550667\n",
      "epoch: 4 step: 1762, loss is 0.000608462723903358\n",
      "epoch: 4 step: 1763, loss is 0.007274907547980547\n",
      "epoch: 4 step: 1764, loss is 0.0021490948274731636\n",
      "epoch: 4 step: 1765, loss is 0.05846676230430603\n",
      "epoch: 4 step: 1766, loss is 0.0027622017078101635\n",
      "epoch: 4 step: 1767, loss is 0.06007702648639679\n",
      "epoch: 4 step: 1768, loss is 0.025807466357946396\n",
      "epoch: 4 step: 1769, loss is 0.0013174331979826093\n",
      "epoch: 4 step: 1770, loss is 0.007841861806809902\n",
      "epoch: 4 step: 1771, loss is 0.007554046809673309\n",
      "epoch: 4 step: 1772, loss is 0.0005252478295005858\n",
      "epoch: 4 step: 1773, loss is 0.0015007001347839832\n",
      "epoch: 4 step: 1774, loss is 0.05614424869418144\n",
      "epoch: 4 step: 1775, loss is 0.13644719123840332\n",
      "epoch: 4 step: 1776, loss is 0.03226488456130028\n",
      "epoch: 4 step: 1777, loss is 0.007358226925134659\n",
      "epoch: 4 step: 1778, loss is 0.003435329766944051\n",
      "epoch: 4 step: 1779, loss is 0.0017276378348469734\n",
      "epoch: 4 step: 1780, loss is 0.007377518340945244\n",
      "epoch: 4 step: 1781, loss is 0.004363547544926405\n",
      "epoch: 4 step: 1782, loss is 0.0012193017173558474\n",
      "epoch: 4 step: 1783, loss is 0.06695518642663956\n",
      "epoch: 4 step: 1784, loss is 0.033213961869478226\n",
      "epoch: 4 step: 1785, loss is 0.04102712869644165\n",
      "epoch: 4 step: 1786, loss is 0.04714394360780716\n",
      "epoch: 4 step: 1787, loss is 0.004918461199849844\n",
      "epoch: 4 step: 1788, loss is 0.002720852615311742\n",
      "epoch: 4 step: 1789, loss is 0.0034241536632180214\n",
      "epoch: 4 step: 1790, loss is 0.15296991169452667\n",
      "epoch: 4 step: 1791, loss is 0.002215229207649827\n",
      "epoch: 4 step: 1792, loss is 0.011844562366604805\n",
      "epoch: 4 step: 1793, loss is 0.0018564923666417599\n",
      "epoch: 4 step: 1794, loss is 0.0011578751727938652\n",
      "epoch: 4 step: 1795, loss is 0.04098144546151161\n",
      "epoch: 4 step: 1796, loss is 0.0006609958945773542\n",
      "epoch: 4 step: 1797, loss is 0.04898073524236679\n",
      "epoch: 4 step: 1798, loss is 0.00047534049372188747\n",
      "epoch: 4 step: 1799, loss is 0.08039359748363495\n",
      "epoch: 4 step: 1800, loss is 0.003117671702057123\n",
      "epoch: 4 step: 1801, loss is 0.08321303874254227\n",
      "epoch: 4 step: 1802, loss is 0.0011667910730466247\n",
      "epoch: 4 step: 1803, loss is 0.0127046387642622\n",
      "epoch: 4 step: 1804, loss is 0.025499265640974045\n",
      "epoch: 4 step: 1805, loss is 0.004128996282815933\n",
      "epoch: 4 step: 1806, loss is 0.2226448804140091\n",
      "epoch: 4 step: 1807, loss is 0.0034563664812594652\n",
      "epoch: 4 step: 1808, loss is 0.016967017203569412\n",
      "epoch: 4 step: 1809, loss is 0.002689227694645524\n",
      "epoch: 4 step: 1810, loss is 0.09907598793506622\n",
      "epoch: 4 step: 1811, loss is 0.03490061312913895\n",
      "epoch: 4 step: 1812, loss is 0.01039051078259945\n",
      "epoch: 4 step: 1813, loss is 0.0014823728706687689\n",
      "epoch: 4 step: 1814, loss is 0.00037298037204891443\n",
      "epoch: 4 step: 1815, loss is 0.012104827910661697\n",
      "epoch: 4 step: 1816, loss is 0.0003910541126970202\n",
      "epoch: 4 step: 1817, loss is 0.06593883037567139\n",
      "epoch: 4 step: 1818, loss is 0.05488009378314018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1819, loss is 0.12356477975845337\n",
      "epoch: 4 step: 1820, loss is 0.10434111207723618\n",
      "epoch: 4 step: 1821, loss is 0.10084160417318344\n",
      "epoch: 4 step: 1822, loss is 0.002841543173417449\n",
      "epoch: 4 step: 1823, loss is 0.14593809843063354\n",
      "epoch: 4 step: 1824, loss is 0.004180845804512501\n",
      "epoch: 4 step: 1825, loss is 0.031103234738111496\n",
      "epoch: 4 step: 1826, loss is 0.0009606870007701218\n",
      "epoch: 4 step: 1827, loss is 0.0029593007639050484\n",
      "epoch: 4 step: 1828, loss is 0.0032212042715400457\n",
      "epoch: 4 step: 1829, loss is 0.03628700226545334\n",
      "epoch: 4 step: 1830, loss is 0.00014589058991987258\n",
      "epoch: 4 step: 1831, loss is 0.22495731711387634\n",
      "epoch: 4 step: 1832, loss is 0.04002511501312256\n",
      "epoch: 4 step: 1833, loss is 0.012980004772543907\n",
      "epoch: 4 step: 1834, loss is 0.009220205247402191\n",
      "epoch: 4 step: 1835, loss is 0.04160649701952934\n",
      "epoch: 4 step: 1836, loss is 0.1235380694270134\n",
      "epoch: 4 step: 1837, loss is 0.10132212936878204\n",
      "epoch: 4 step: 1838, loss is 0.001278000301681459\n",
      "epoch: 4 step: 1839, loss is 0.002571528311818838\n",
      "epoch: 4 step: 1840, loss is 0.0018822926795110106\n",
      "epoch: 4 step: 1841, loss is 0.0030776183120906353\n",
      "epoch: 4 step: 1842, loss is 0.021421432495117188\n",
      "epoch: 4 step: 1843, loss is 0.04068312793970108\n",
      "epoch: 4 step: 1844, loss is 0.12134241312742233\n",
      "epoch: 4 step: 1845, loss is 0.027174722403287888\n",
      "epoch: 4 step: 1846, loss is 0.007494398392736912\n",
      "epoch: 4 step: 1847, loss is 0.06148744374513626\n",
      "epoch: 4 step: 1848, loss is 0.026695718988776207\n",
      "epoch: 4 step: 1849, loss is 0.002669748617336154\n",
      "epoch: 4 step: 1850, loss is 0.0025758862029761076\n",
      "epoch: 4 step: 1851, loss is 0.02421974018216133\n",
      "epoch: 4 step: 1852, loss is 0.3004671633243561\n",
      "epoch: 4 step: 1853, loss is 0.005101494025439024\n",
      "epoch: 4 step: 1854, loss is 0.041634220629930496\n",
      "epoch: 4 step: 1855, loss is 0.04163992777466774\n",
      "epoch: 4 step: 1856, loss is 0.17984777688980103\n",
      "epoch: 4 step: 1857, loss is 0.02031455934047699\n",
      "epoch: 4 step: 1858, loss is 0.009310762397944927\n",
      "epoch: 4 step: 1859, loss is 0.009419488720595837\n",
      "epoch: 4 step: 1860, loss is 0.006062857806682587\n",
      "epoch: 4 step: 1861, loss is 0.07287030667066574\n",
      "epoch: 4 step: 1862, loss is 0.01650490239262581\n",
      "epoch: 4 step: 1863, loss is 0.0026096368674188852\n",
      "epoch: 4 step: 1864, loss is 0.0035757303703576326\n",
      "epoch: 4 step: 1865, loss is 0.03653782978653908\n",
      "epoch: 4 step: 1866, loss is 0.008760933764278889\n",
      "epoch: 4 step: 1867, loss is 0.023179668933153152\n",
      "epoch: 4 step: 1868, loss is 0.012217920273542404\n",
      "epoch: 4 step: 1869, loss is 0.11388874053955078\n",
      "epoch: 4 step: 1870, loss is 0.011914110742509365\n",
      "epoch: 4 step: 1871, loss is 0.010098489001393318\n",
      "epoch: 4 step: 1872, loss is 0.06503866612911224\n",
      "epoch: 4 step: 1873, loss is 0.2504158914089203\n",
      "epoch: 4 step: 1874, loss is 0.0029306458309292793\n",
      "epoch: 4 step: 1875, loss is 0.018239546567201614\n",
      "epoch: 4 step: 1876, loss is 0.1789703518152237\n",
      "epoch: 4 step: 1877, loss is 0.003544483333826065\n",
      "epoch: 4 step: 1878, loss is 0.0015163847710937262\n",
      "epoch: 4 step: 1879, loss is 0.03880207613110542\n",
      "epoch: 4 step: 1880, loss is 0.019051430746912956\n",
      "epoch: 4 step: 1881, loss is 0.008067899383604527\n",
      "epoch: 4 step: 1882, loss is 0.0016866009682416916\n",
      "epoch: 4 step: 1883, loss is 0.03184327483177185\n",
      "epoch: 4 step: 1884, loss is 0.00044289621291682124\n",
      "epoch: 4 step: 1885, loss is 0.01341178547590971\n",
      "epoch: 4 step: 1886, loss is 0.004521660506725311\n",
      "epoch: 4 step: 1887, loss is 0.002450494095683098\n",
      "epoch: 4 step: 1888, loss is 0.012266553938388824\n",
      "epoch: 4 step: 1889, loss is 0.1457478404045105\n",
      "epoch: 4 step: 1890, loss is 0.007885411381721497\n",
      "epoch: 4 step: 1891, loss is 0.033853355795145035\n",
      "epoch: 4 step: 1892, loss is 0.006369114853441715\n",
      "epoch: 4 step: 1893, loss is 0.056094296276569366\n",
      "epoch: 4 step: 1894, loss is 0.016872907057404518\n",
      "epoch: 4 step: 1895, loss is 0.1899193823337555\n",
      "epoch: 4 step: 1896, loss is 0.09998409450054169\n",
      "epoch: 4 step: 1897, loss is 0.05361301824450493\n",
      "epoch: 4 step: 1898, loss is 0.02223162166774273\n",
      "epoch: 4 step: 1899, loss is 0.008624187670648098\n",
      "epoch: 4 step: 1900, loss is 0.09761492162942886\n",
      "epoch: 4 step: 1901, loss is 0.00027489211061038077\n",
      "epoch: 4 step: 1902, loss is 0.0035768430680036545\n",
      "epoch: 4 step: 1903, loss is 0.03365448862314224\n",
      "epoch: 4 step: 1904, loss is 0.0016012563137337565\n",
      "epoch: 4 step: 1905, loss is 0.0023028228897601366\n",
      "epoch: 4 step: 1906, loss is 0.0009679103386588395\n",
      "epoch: 4 step: 1907, loss is 0.0031547616235911846\n",
      "epoch: 4 step: 1908, loss is 0.0037140129134058952\n",
      "epoch: 4 step: 1909, loss is 0.005682266317307949\n",
      "epoch: 4 step: 1910, loss is 0.0007024842198006809\n",
      "epoch: 4 step: 1911, loss is 0.002735601272433996\n",
      "epoch: 4 step: 1912, loss is 0.010227295570075512\n",
      "epoch: 4 step: 1913, loss is 0.0003160341002512723\n",
      "epoch: 4 step: 1914, loss is 0.01053642388433218\n",
      "epoch: 4 step: 1915, loss is 0.18916276097297668\n",
      "epoch: 4 step: 1916, loss is 0.0014968932373449206\n",
      "epoch: 4 step: 1917, loss is 0.05667610466480255\n",
      "epoch: 4 step: 1918, loss is 0.0017110547050833702\n",
      "epoch: 4 step: 1919, loss is 0.011093630455434322\n",
      "epoch: 4 step: 1920, loss is 0.001786480424925685\n",
      "epoch: 4 step: 1921, loss is 0.028906168416142464\n",
      "epoch: 4 step: 1922, loss is 0.1427476555109024\n",
      "epoch: 4 step: 1923, loss is 0.011660818941891193\n",
      "epoch: 4 step: 1924, loss is 0.04500589892268181\n",
      "epoch: 4 step: 1925, loss is 0.007739503867924213\n",
      "epoch: 4 step: 1926, loss is 0.0874355211853981\n",
      "epoch: 4 step: 1927, loss is 0.06185237690806389\n",
      "epoch: 4 step: 1928, loss is 0.008105271495878696\n",
      "epoch: 4 step: 1929, loss is 0.0029793046414852142\n",
      "epoch: 4 step: 1930, loss is 0.0018569700187072158\n",
      "epoch: 4 step: 1931, loss is 0.07179760187864304\n",
      "epoch: 4 step: 1932, loss is 0.07837624102830887\n",
      "epoch: 4 step: 1933, loss is 0.0028077769093215466\n",
      "epoch: 4 step: 1934, loss is 0.06571800261735916\n",
      "epoch: 4 step: 1935, loss is 0.08188001066446304\n",
      "epoch: 4 step: 1936, loss is 0.00700828293338418\n",
      "epoch: 4 step: 1937, loss is 0.08608018606901169\n",
      "epoch: 4 step: 1938, loss is 0.005778283812105656\n",
      "epoch: 4 step: 1939, loss is 0.02436007931828499\n",
      "epoch: 4 step: 1940, loss is 0.013553173281252384\n",
      "epoch: 4 step: 1941, loss is 0.04316997528076172\n",
      "epoch: 4 step: 1942, loss is 0.013977022841572762\n",
      "epoch: 4 step: 1943, loss is 0.013264495879411697\n",
      "epoch: 4 step: 1944, loss is 0.04574726149439812\n",
      "epoch: 4 step: 1945, loss is 0.0034442779142409563\n",
      "epoch: 4 step: 1946, loss is 0.08541464060544968\n",
      "epoch: 4 step: 1947, loss is 0.017441358417272568\n",
      "epoch: 4 step: 1948, loss is 0.0007415219442918897\n",
      "epoch: 4 step: 1949, loss is 0.029905712231993675\n",
      "epoch: 4 step: 1950, loss is 0.17650820314884186\n",
      "epoch: 4 step: 1951, loss is 0.0021611163392663\n",
      "epoch: 4 step: 1952, loss is 0.0014946478186175227\n",
      "epoch: 4 step: 1953, loss is 0.003311309264972806\n",
      "epoch: 4 step: 1954, loss is 0.0066022686660289764\n",
      "epoch: 4 step: 1955, loss is 0.003537768265232444\n",
      "epoch: 4 step: 1956, loss is 0.04954252764582634\n",
      "epoch: 4 step: 1957, loss is 0.003070272272452712\n",
      "epoch: 4 step: 1958, loss is 0.048901788890361786\n",
      "epoch: 4 step: 1959, loss is 0.07439149171113968\n",
      "epoch: 4 step: 1960, loss is 0.00020306957594584674\n",
      "epoch: 4 step: 1961, loss is 0.01090636383742094\n",
      "epoch: 4 step: 1962, loss is 0.0035678085405379534\n",
      "epoch: 4 step: 1963, loss is 0.007267145439982414\n",
      "epoch: 4 step: 1964, loss is 0.004832804203033447\n",
      "epoch: 4 step: 1965, loss is 0.06029476970434189\n",
      "epoch: 4 step: 1966, loss is 0.0036789062432944775\n",
      "epoch: 4 step: 1967, loss is 0.09499986469745636\n",
      "epoch: 4 step: 1968, loss is 0.06579352170228958\n",
      "epoch: 4 step: 1969, loss is 0.005631252191960812\n",
      "epoch: 4 step: 1970, loss is 0.03005521558225155\n",
      "epoch: 4 step: 1971, loss is 0.0012079982552677393\n",
      "epoch: 4 step: 1972, loss is 0.00042072185897268355\n",
      "epoch: 4 step: 1973, loss is 0.015257222577929497\n",
      "epoch: 4 step: 1974, loss is 0.0033183761406689882\n",
      "epoch: 4 step: 1975, loss is 0.0007135854102671146\n",
      "epoch: 4 step: 1976, loss is 0.0006607028772123158\n",
      "epoch: 4 step: 1977, loss is 0.05105825886130333\n",
      "epoch: 4 step: 1978, loss is 0.15528297424316406\n",
      "epoch: 4 step: 1979, loss is 0.02011922560632229\n",
      "epoch: 4 step: 1980, loss is 0.06932646781206131\n",
      "epoch: 4 step: 1981, loss is 0.023190978914499283\n",
      "epoch: 4 step: 1982, loss is 0.01123893354088068\n",
      "epoch: 4 step: 1983, loss is 0.006352190859615803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1984, loss is 0.19668056070804596\n",
      "epoch: 4 step: 1985, loss is 0.05215747281908989\n",
      "epoch: 4 step: 1986, loss is 0.0026577292010188103\n",
      "epoch: 4 step: 1987, loss is 0.0007513713790103793\n",
      "epoch: 4 step: 1988, loss is 0.002864011563360691\n",
      "epoch: 4 step: 1989, loss is 0.01664794608950615\n",
      "epoch: 4 step: 1990, loss is 0.023897258564829826\n",
      "epoch: 4 step: 1991, loss is 0.014296836219727993\n",
      "epoch: 4 step: 1992, loss is 0.04248451068997383\n",
      "epoch: 4 step: 1993, loss is 0.04371458292007446\n",
      "epoch: 4 step: 1994, loss is 0.10999109596014023\n",
      "epoch: 4 step: 1995, loss is 0.012285199947655201\n",
      "epoch: 4 step: 1996, loss is 0.05087092146277428\n",
      "epoch: 4 step: 1997, loss is 0.48876217007637024\n",
      "epoch: 4 step: 1998, loss is 0.007626631762832403\n",
      "epoch: 4 step: 1999, loss is 0.016535144299268723\n",
      "epoch: 4 step: 2000, loss is 0.0007099639042280614\n",
      "epoch: 4 step: 2001, loss is 0.0023288591764867306\n",
      "epoch: 4 step: 2002, loss is 0.004729801323264837\n",
      "epoch: 4 step: 2003, loss is 0.12374058365821838\n",
      "epoch: 4 step: 2004, loss is 0.0015862461877986789\n",
      "epoch: 4 step: 2005, loss is 0.08851879835128784\n",
      "epoch: 4 step: 2006, loss is 0.0005161185399629176\n",
      "epoch: 4 step: 2007, loss is 0.047344405204057693\n",
      "epoch: 4 step: 2008, loss is 0.0009677043999545276\n",
      "epoch: 4 step: 2009, loss is 0.1319606602191925\n",
      "epoch: 4 step: 2010, loss is 0.00152306049130857\n",
      "epoch: 4 step: 2011, loss is 0.16590413451194763\n",
      "epoch: 4 step: 2012, loss is 0.000970344350207597\n",
      "epoch: 4 step: 2013, loss is 0.002943493193015456\n",
      "epoch: 4 step: 2014, loss is 0.04175422713160515\n",
      "epoch: 4 step: 2015, loss is 0.00834419671446085\n",
      "epoch: 4 step: 2016, loss is 0.03995347395539284\n",
      "epoch: 4 step: 2017, loss is 0.012581290677189827\n",
      "epoch: 4 step: 2018, loss is 0.01342647522687912\n",
      "epoch: 4 step: 2019, loss is 0.059632014483213425\n",
      "epoch: 4 step: 2020, loss is 0.04082639142870903\n",
      "epoch: 4 step: 2021, loss is 0.0016992491437122226\n",
      "epoch: 4 step: 2022, loss is 0.008696075528860092\n",
      "epoch: 4 step: 2023, loss is 0.1561889350414276\n",
      "epoch: 4 step: 2024, loss is 0.2892006039619446\n",
      "epoch: 4 step: 2025, loss is 0.09590426087379456\n",
      "epoch: 4 step: 2026, loss is 0.10336485505104065\n",
      "epoch: 4 step: 2027, loss is 0.18859867751598358\n",
      "epoch: 4 step: 2028, loss is 0.034421298652887344\n",
      "epoch: 4 step: 2029, loss is 0.014491334557533264\n",
      "epoch: 4 step: 2030, loss is 0.04376733675599098\n",
      "epoch: 4 step: 2031, loss is 0.02306479401886463\n",
      "epoch: 4 step: 2032, loss is 0.014962553977966309\n",
      "epoch: 4 step: 2033, loss is 0.10972734540700912\n",
      "epoch: 4 step: 2034, loss is 0.007711801212280989\n",
      "epoch: 4 step: 2035, loss is 0.008168079890310764\n",
      "epoch: 4 step: 2036, loss is 0.06836948543787003\n",
      "epoch: 4 step: 2037, loss is 0.0853932574391365\n",
      "epoch: 4 step: 2038, loss is 0.0013448211830109358\n",
      "epoch: 4 step: 2039, loss is 0.07838472723960876\n",
      "epoch: 4 step: 2040, loss is 0.03152196854352951\n",
      "epoch: 4 step: 2041, loss is 0.054129764437675476\n",
      "epoch: 4 step: 2042, loss is 0.07859653979539871\n",
      "epoch: 4 step: 2043, loss is 0.0282941572368145\n",
      "epoch: 4 step: 2044, loss is 0.0166902057826519\n",
      "epoch: 4 step: 2045, loss is 0.020276833325624466\n",
      "epoch: 4 step: 2046, loss is 0.00347703043371439\n",
      "epoch: 4 step: 2047, loss is 0.002239249413833022\n",
      "epoch: 4 step: 2048, loss is 0.0018949698423966765\n",
      "epoch: 4 step: 2049, loss is 0.12250810861587524\n",
      "epoch: 4 step: 2050, loss is 0.0030892230570316315\n",
      "epoch: 4 step: 2051, loss is 0.02228371426463127\n",
      "epoch: 4 step: 2052, loss is 0.10751297324895859\n",
      "epoch: 4 step: 2053, loss is 0.11056812107563019\n",
      "epoch: 4 step: 2054, loss is 0.012189666740596294\n",
      "epoch: 4 step: 2055, loss is 0.2126898169517517\n",
      "epoch: 4 step: 2056, loss is 0.0405578576028347\n",
      "epoch: 4 step: 2057, loss is 0.0005842134123668075\n",
      "epoch: 4 step: 2058, loss is 0.003045083489269018\n",
      "epoch: 4 step: 2059, loss is 0.003532974747940898\n",
      "epoch: 4 step: 2060, loss is 0.00033102065208368003\n",
      "epoch: 4 step: 2061, loss is 0.003816477954387665\n",
      "epoch: 4 step: 2062, loss is 0.0014808464329689741\n",
      "epoch: 4 step: 2063, loss is 0.002617214573547244\n",
      "epoch: 4 step: 2064, loss is 0.010839438065886497\n",
      "epoch: 4 step: 2065, loss is 0.08216173946857452\n",
      "epoch: 4 step: 2066, loss is 0.02675013057887554\n",
      "epoch: 4 step: 2067, loss is 0.33284398913383484\n",
      "epoch: 4 step: 2068, loss is 0.00025548681151121855\n",
      "epoch: 4 step: 2069, loss is 0.009019896388053894\n",
      "epoch: 4 step: 2070, loss is 0.016703875735402107\n",
      "epoch: 4 step: 2071, loss is 0.10796287655830383\n",
      "epoch: 4 step: 2072, loss is 0.003440084168687463\n",
      "epoch: 4 step: 2073, loss is 0.003192330477759242\n",
      "epoch: 4 step: 2074, loss is 0.00933049526065588\n",
      "epoch: 4 step: 2075, loss is 0.001806753920391202\n",
      "epoch: 4 step: 2076, loss is 0.09442418813705444\n",
      "epoch: 4 step: 2077, loss is 0.0007290726061910391\n",
      "epoch: 4 step: 2078, loss is 0.01809178851544857\n",
      "epoch: 4 step: 2079, loss is 0.0034832353703677654\n",
      "epoch: 4 step: 2080, loss is 0.1678786724805832\n",
      "epoch: 4 step: 2081, loss is 0.05427902936935425\n",
      "epoch: 4 step: 2082, loss is 0.048013631254434586\n",
      "epoch: 4 step: 2083, loss is 0.13051338493824005\n",
      "epoch: 4 step: 2084, loss is 0.002897026715800166\n",
      "epoch: 4 step: 2085, loss is 0.002291639568284154\n",
      "epoch: 4 step: 2086, loss is 0.00728245684877038\n",
      "epoch: 4 step: 2087, loss is 0.28618568181991577\n",
      "epoch: 4 step: 2088, loss is 0.040957819670438766\n",
      "epoch: 4 step: 2089, loss is 0.09962979704141617\n",
      "epoch: 4 step: 2090, loss is 0.010069398209452629\n",
      "epoch: 4 step: 2091, loss is 0.0030568463262170553\n",
      "epoch: 4 step: 2092, loss is 0.03557398542761803\n",
      "epoch: 4 step: 2093, loss is 0.16640633344650269\n",
      "epoch: 4 step: 2094, loss is 0.001980028348043561\n",
      "epoch: 4 step: 2095, loss is 0.10692740231752396\n",
      "epoch: 4 step: 2096, loss is 0.0010109044378623366\n",
      "epoch: 4 step: 2097, loss is 0.12989498674869537\n",
      "epoch: 4 step: 2098, loss is 0.0059842681512236595\n",
      "epoch: 4 step: 2099, loss is 0.0009139057947322726\n",
      "epoch: 4 step: 2100, loss is 0.0020845301914960146\n",
      "epoch: 4 step: 2101, loss is 0.04620447754859924\n",
      "epoch: 4 step: 2102, loss is 0.17586293816566467\n",
      "epoch: 4 step: 2103, loss is 0.009767955169081688\n",
      "epoch: 4 step: 2104, loss is 0.15104849636554718\n",
      "epoch: 4 step: 2105, loss is 0.009302797727286816\n",
      "epoch: 4 step: 2106, loss is 0.026258988305926323\n",
      "epoch: 4 step: 2107, loss is 0.10589500516653061\n",
      "epoch: 4 step: 2108, loss is 0.004236815497279167\n",
      "epoch: 4 step: 2109, loss is 0.002675181021913886\n",
      "epoch: 4 step: 2110, loss is 0.008927677758038044\n",
      "epoch: 4 step: 2111, loss is 0.015378635376691818\n",
      "epoch: 4 step: 2112, loss is 0.012680458836257458\n",
      "epoch: 4 step: 2113, loss is 0.1653061956167221\n",
      "epoch: 4 step: 2114, loss is 0.006036677397787571\n",
      "epoch: 4 step: 2115, loss is 0.06688904762268066\n",
      "epoch: 4 step: 2116, loss is 0.008194901049137115\n",
      "epoch: 4 step: 2117, loss is 0.015807459130883217\n",
      "epoch: 4 step: 2118, loss is 0.0005509215989150107\n",
      "epoch: 4 step: 2119, loss is 0.007301563862711191\n",
      "epoch: 4 step: 2120, loss is 0.019675301387906075\n",
      "epoch: 4 step: 2121, loss is 0.0027503815945237875\n",
      "epoch: 4 step: 2122, loss is 0.012008436024188995\n",
      "epoch: 4 step: 2123, loss is 0.12269408255815506\n",
      "epoch: 4 step: 2124, loss is 0.02215075120329857\n",
      "epoch: 4 step: 2125, loss is 0.006353443954139948\n",
      "epoch: 4 step: 2126, loss is 0.11356399953365326\n",
      "epoch: 4 step: 2127, loss is 0.03627169504761696\n",
      "epoch: 4 step: 2128, loss is 0.001327070058323443\n",
      "epoch: 4 step: 2129, loss is 0.00040972797432914376\n",
      "epoch: 4 step: 2130, loss is 0.0061050718650221825\n",
      "epoch: 4 step: 2131, loss is 0.00584392249584198\n",
      "epoch: 4 step: 2132, loss is 0.007150067016482353\n",
      "epoch: 4 step: 2133, loss is 0.02158528007566929\n",
      "epoch: 4 step: 2134, loss is 0.12697993218898773\n",
      "epoch: 4 step: 2135, loss is 0.0066003454849123955\n",
      "epoch: 4 step: 2136, loss is 0.020643630996346474\n",
      "epoch: 4 step: 2137, loss is 0.010168997570872307\n",
      "epoch: 4 step: 2138, loss is 0.0073440298438072205\n",
      "epoch: 4 step: 2139, loss is 0.00860468577593565\n",
      "epoch: 4 step: 2140, loss is 0.0014953856589272618\n",
      "epoch: 4 step: 2141, loss is 0.0440097413957119\n",
      "epoch: 4 step: 2142, loss is 0.003061163006350398\n",
      "epoch: 4 step: 2143, loss is 0.017772436141967773\n",
      "epoch: 4 step: 2144, loss is 0.006427432410418987\n",
      "epoch: 4 step: 2145, loss is 0.002230470534414053\n",
      "epoch: 4 step: 2146, loss is 0.0032838264014571905\n",
      "epoch: 4 step: 2147, loss is 0.006991430651396513\n",
      "epoch: 4 step: 2148, loss is 0.0010322539601475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 2149, loss is 0.00237242947332561\n",
      "epoch: 4 step: 2150, loss is 0.031731605529785156\n",
      "epoch: 4 step: 2151, loss is 0.10467536747455597\n",
      "epoch: 4 step: 2152, loss is 0.00585150858387351\n",
      "epoch: 4 step: 2153, loss is 0.002880622399970889\n",
      "epoch: 4 step: 2154, loss is 0.014264985918998718\n",
      "epoch: 4 step: 2155, loss is 0.02339458093047142\n",
      "epoch: 4 step: 2156, loss is 0.22243918478488922\n",
      "epoch: 4 step: 2157, loss is 0.16511227190494537\n",
      "epoch: 4 step: 2158, loss is 0.00027526033227331936\n",
      "epoch: 4 step: 2159, loss is 0.031799621880054474\n",
      "epoch: 4 step: 2160, loss is 0.00031934387516230345\n",
      "epoch: 4 step: 2161, loss is 0.005198851227760315\n",
      "epoch: 4 step: 2162, loss is 0.04451170563697815\n",
      "epoch: 4 step: 2163, loss is 0.02953079715371132\n",
      "epoch: 4 step: 2164, loss is 0.1458262801170349\n",
      "epoch: 4 step: 2165, loss is 0.0890447199344635\n",
      "epoch: 4 step: 2166, loss is 0.001234158524312079\n",
      "epoch: 4 step: 2167, loss is 0.07093625515699387\n",
      "epoch: 4 step: 2168, loss is 0.19613949954509735\n",
      "epoch: 4 step: 2169, loss is 0.1713777482509613\n",
      "epoch: 4 step: 2170, loss is 0.023185160011053085\n",
      "epoch: 4 step: 2171, loss is 0.007909744046628475\n",
      "epoch: 4 step: 2172, loss is 0.2913011610507965\n",
      "epoch: 4 step: 2173, loss is 0.0184872318059206\n",
      "epoch: 4 step: 2174, loss is 0.04101413115859032\n",
      "epoch: 4 step: 2175, loss is 0.04477585479617119\n",
      "epoch: 4 step: 2176, loss is 0.024829525500535965\n",
      "epoch: 4 step: 2177, loss is 0.0030321741942316294\n",
      "epoch: 4 step: 2178, loss is 0.022334856912493706\n",
      "epoch: 4 step: 2179, loss is 0.015603232197463512\n",
      "epoch: 4 step: 2180, loss is 0.012824342586100101\n",
      "epoch: 4 step: 2181, loss is 0.0836680680513382\n",
      "epoch: 4 step: 2182, loss is 0.0022963888477534056\n",
      "epoch: 4 step: 2183, loss is 0.00011257256119279191\n",
      "epoch: 4 step: 2184, loss is 0.013719256967306137\n",
      "epoch: 4 step: 2185, loss is 0.012660566717386246\n",
      "epoch: 4 step: 2186, loss is 0.051916081458330154\n",
      "epoch: 4 step: 2187, loss is 0.12209225445985794\n",
      "epoch: 5 step: 1, loss is 0.011562281288206577\n",
      "epoch: 5 step: 2, loss is 0.002733658067882061\n",
      "epoch: 5 step: 3, loss is 0.008513481356203556\n",
      "epoch: 5 step: 4, loss is 0.0012384910369291902\n",
      "epoch: 5 step: 5, loss is 0.0005850952584296465\n",
      "epoch: 5 step: 6, loss is 0.016205372288823128\n",
      "epoch: 5 step: 7, loss is 0.007672988343983889\n",
      "epoch: 5 step: 8, loss is 0.0008203185861930251\n",
      "epoch: 5 step: 9, loss is 0.01789778470993042\n",
      "epoch: 5 step: 10, loss is 0.005584643688052893\n",
      "epoch: 5 step: 11, loss is 0.039253585040569305\n",
      "epoch: 5 step: 12, loss is 0.033358845859766006\n",
      "epoch: 5 step: 13, loss is 0.003129107877612114\n",
      "epoch: 5 step: 14, loss is 0.001435929094441235\n",
      "epoch: 5 step: 15, loss is 0.0033812597393989563\n",
      "epoch: 5 step: 16, loss is 0.001501111895777285\n",
      "epoch: 5 step: 17, loss is 0.00014477195509243757\n",
      "epoch: 5 step: 18, loss is 0.00412049051374197\n",
      "epoch: 5 step: 19, loss is 0.038322895765304565\n",
      "epoch: 5 step: 20, loss is 0.007489153649657965\n",
      "epoch: 5 step: 21, loss is 0.038766320794820786\n",
      "epoch: 5 step: 22, loss is 0.0030994070693850517\n",
      "epoch: 5 step: 23, loss is 0.012592179700732231\n",
      "epoch: 5 step: 24, loss is 0.0007951241568662226\n",
      "epoch: 5 step: 25, loss is 0.05367721617221832\n",
      "epoch: 5 step: 26, loss is 0.01617155782878399\n",
      "epoch: 5 step: 27, loss is 0.04720483347773552\n",
      "epoch: 5 step: 28, loss is 0.001491341507062316\n",
      "epoch: 5 step: 29, loss is 0.0005170645308680832\n",
      "epoch: 5 step: 30, loss is 0.045499350875616074\n",
      "epoch: 5 step: 31, loss is 0.015234929509460926\n",
      "epoch: 5 step: 32, loss is 0.005383789539337158\n",
      "epoch: 5 step: 33, loss is 0.026210468262434006\n",
      "epoch: 5 step: 34, loss is 0.04061752185225487\n",
      "epoch: 5 step: 35, loss is 0.003968060947954655\n",
      "epoch: 5 step: 36, loss is 0.08561962842941284\n",
      "epoch: 5 step: 37, loss is 0.03523985296487808\n",
      "epoch: 5 step: 38, loss is 0.11457768827676773\n",
      "epoch: 5 step: 39, loss is 0.016527049243450165\n",
      "epoch: 5 step: 40, loss is 0.0010110489092767239\n",
      "epoch: 5 step: 41, loss is 0.126242995262146\n",
      "epoch: 5 step: 42, loss is 0.0013901848578825593\n",
      "epoch: 5 step: 43, loss is 0.0006397408433258533\n",
      "epoch: 5 step: 44, loss is 0.06754341721534729\n",
      "epoch: 5 step: 45, loss is 0.0010437163291499019\n",
      "epoch: 5 step: 46, loss is 0.0003645203833002597\n",
      "epoch: 5 step: 47, loss is 0.001820215955376625\n",
      "epoch: 5 step: 48, loss is 0.008749839849770069\n",
      "epoch: 5 step: 49, loss is 0.0037371234502643347\n",
      "epoch: 5 step: 50, loss is 0.017144812270998955\n",
      "epoch: 5 step: 51, loss is 0.0002438614028505981\n",
      "epoch: 5 step: 52, loss is 0.028038883581757545\n",
      "epoch: 5 step: 53, loss is 0.052336275577545166\n",
      "epoch: 5 step: 54, loss is 0.07634513080120087\n",
      "epoch: 5 step: 55, loss is 0.015359803102910519\n",
      "epoch: 5 step: 56, loss is 0.013165440410375595\n",
      "epoch: 5 step: 57, loss is 0.002078154357150197\n",
      "epoch: 5 step: 58, loss is 0.007621597032994032\n",
      "epoch: 5 step: 59, loss is 0.0029247491620481014\n",
      "epoch: 5 step: 60, loss is 0.008925890550017357\n",
      "epoch: 5 step: 61, loss is 0.009614638052880764\n",
      "epoch: 5 step: 62, loss is 0.0011251308023929596\n",
      "epoch: 5 step: 63, loss is 0.01428127195686102\n",
      "epoch: 5 step: 64, loss is 0.1432163268327713\n",
      "epoch: 5 step: 65, loss is 0.0014880584785714746\n",
      "epoch: 5 step: 66, loss is 0.0016132290475070477\n",
      "epoch: 5 step: 67, loss is 0.019089307636022568\n",
      "epoch: 5 step: 68, loss is 0.0011499164393171668\n",
      "epoch: 5 step: 69, loss is 0.06998363137245178\n",
      "epoch: 5 step: 70, loss is 0.0003392219659872353\n",
      "epoch: 5 step: 71, loss is 0.00018240537610836327\n",
      "epoch: 5 step: 72, loss is 0.0017221333691850305\n",
      "epoch: 5 step: 73, loss is 0.0019384309416636825\n",
      "epoch: 5 step: 74, loss is 0.005490914918482304\n",
      "epoch: 5 step: 75, loss is 0.05704442411661148\n",
      "epoch: 5 step: 76, loss is 0.00266647944226861\n",
      "epoch: 5 step: 77, loss is 0.0028235469944775105\n",
      "epoch: 5 step: 78, loss is 0.029970891773700714\n",
      "epoch: 5 step: 79, loss is 0.003099018707871437\n",
      "epoch: 5 step: 80, loss is 0.005060885567218065\n",
      "epoch: 5 step: 81, loss is 0.13267453014850616\n",
      "epoch: 5 step: 82, loss is 0.0009177963947877288\n",
      "epoch: 5 step: 83, loss is 0.03249652683734894\n",
      "epoch: 5 step: 84, loss is 0.0013018302852287889\n",
      "epoch: 5 step: 85, loss is 0.0015353676863014698\n",
      "epoch: 5 step: 86, loss is 0.000488962628878653\n",
      "epoch: 5 step: 87, loss is 0.009638328105211258\n",
      "epoch: 5 step: 88, loss is 0.00021413674403447658\n",
      "epoch: 5 step: 89, loss is 0.0025783414021134377\n",
      "epoch: 5 step: 90, loss is 0.0007507937261834741\n",
      "epoch: 5 step: 91, loss is 0.03861497715115547\n",
      "epoch: 5 step: 92, loss is 0.0032959708478301764\n",
      "epoch: 5 step: 93, loss is 0.012599502690136433\n",
      "epoch: 5 step: 94, loss is 0.10211252421140671\n",
      "epoch: 5 step: 95, loss is 0.0007500534411519766\n",
      "epoch: 5 step: 96, loss is 0.018114615231752396\n",
      "epoch: 5 step: 97, loss is 0.002200980903580785\n",
      "epoch: 5 step: 98, loss is 0.028371458873152733\n",
      "epoch: 5 step: 99, loss is 0.00029222649754956365\n",
      "epoch: 5 step: 100, loss is 0.00040799795533530414\n",
      "epoch: 5 step: 101, loss is 0.0024819602258503437\n",
      "epoch: 5 step: 102, loss is 0.0007001797202974558\n",
      "epoch: 5 step: 103, loss is 0.0014858399517834187\n",
      "epoch: 5 step: 104, loss is 0.019053451716899872\n",
      "epoch: 5 step: 105, loss is 0.0005239570164121687\n",
      "epoch: 5 step: 106, loss is 0.0003628352133091539\n",
      "epoch: 5 step: 107, loss is 0.003337400034070015\n",
      "epoch: 5 step: 108, loss is 0.0005892786430194974\n",
      "epoch: 5 step: 109, loss is 9.357530507259071e-05\n",
      "epoch: 5 step: 110, loss is 0.00031674507772549987\n",
      "epoch: 5 step: 111, loss is 0.0060141305439174175\n",
      "epoch: 5 step: 112, loss is 0.005532623268663883\n",
      "epoch: 5 step: 113, loss is 0.0071695223450660706\n",
      "epoch: 5 step: 114, loss is 0.0003929039230570197\n",
      "epoch: 5 step: 115, loss is 0.00361302075907588\n",
      "epoch: 5 step: 116, loss is 0.0020663770847022533\n",
      "epoch: 5 step: 117, loss is 0.0002579473948571831\n",
      "epoch: 5 step: 118, loss is 0.0001466600806452334\n",
      "epoch: 5 step: 119, loss is 0.00018447954789735377\n",
      "epoch: 5 step: 120, loss is 0.031314559280872345\n",
      "epoch: 5 step: 121, loss is 0.001376509782858193\n",
      "epoch: 5 step: 122, loss is 0.002371616428717971\n",
      "epoch: 5 step: 123, loss is 0.0005438397056423128\n",
      "epoch: 5 step: 124, loss is 0.0018502074526622891\n",
      "epoch: 5 step: 125, loss is 0.009065338410437107\n",
      "epoch: 5 step: 126, loss is 0.009518668055534363\n",
      "epoch: 5 step: 127, loss is 0.0005431455210782588\n",
      "epoch: 5 step: 128, loss is 0.009561690501868725\n",
      "epoch: 5 step: 129, loss is 0.0019731621723622084\n",
      "epoch: 5 step: 130, loss is 0.002350523602217436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 131, loss is 0.014924435876309872\n",
      "epoch: 5 step: 132, loss is 0.005052805878221989\n",
      "epoch: 5 step: 133, loss is 0.001072862185537815\n",
      "epoch: 5 step: 134, loss is 0.0197925828397274\n",
      "epoch: 5 step: 135, loss is 0.0016250014305114746\n",
      "epoch: 5 step: 136, loss is 0.10565206408500671\n",
      "epoch: 5 step: 137, loss is 0.0002467857557348907\n",
      "epoch: 5 step: 138, loss is 0.009731704369187355\n",
      "epoch: 5 step: 139, loss is 0.00019845917995553464\n",
      "epoch: 5 step: 140, loss is 0.0015134408604353666\n",
      "epoch: 5 step: 141, loss is 0.0005859180819243193\n",
      "epoch: 5 step: 142, loss is 0.0001816627336665988\n",
      "epoch: 5 step: 143, loss is 0.00016763345047365874\n",
      "epoch: 5 step: 144, loss is 0.04615124315023422\n",
      "epoch: 5 step: 145, loss is 0.03766708821058273\n",
      "epoch: 5 step: 146, loss is 0.00043746273149736226\n",
      "epoch: 5 step: 147, loss is 0.008648709394037724\n",
      "epoch: 5 step: 148, loss is 0.0016948676202446222\n",
      "epoch: 5 step: 149, loss is 0.0010593633633106947\n",
      "epoch: 5 step: 150, loss is 0.00869736261665821\n",
      "epoch: 5 step: 151, loss is 0.00041898799827322364\n",
      "epoch: 5 step: 152, loss is 0.01947401650249958\n",
      "epoch: 5 step: 153, loss is 0.02444489672780037\n",
      "epoch: 5 step: 154, loss is 0.004425082355737686\n",
      "epoch: 5 step: 155, loss is 0.00027397394296713173\n",
      "epoch: 5 step: 156, loss is 0.0001931442820932716\n",
      "epoch: 5 step: 157, loss is 0.17962750792503357\n",
      "epoch: 5 step: 158, loss is 4.970008012605831e-05\n",
      "epoch: 5 step: 159, loss is 0.0001978411164600402\n",
      "epoch: 5 step: 160, loss is 0.001983666094020009\n",
      "epoch: 5 step: 161, loss is 0.00035127013688907027\n",
      "epoch: 5 step: 162, loss is 0.012187442742288113\n",
      "epoch: 5 step: 163, loss is 0.0001427946554031223\n",
      "epoch: 5 step: 164, loss is 0.16582517325878143\n",
      "epoch: 5 step: 165, loss is 0.002219828777015209\n",
      "epoch: 5 step: 166, loss is 0.031001074239611626\n",
      "epoch: 5 step: 167, loss is 0.004221627023071051\n",
      "epoch: 5 step: 168, loss is 0.0001574565249029547\n",
      "epoch: 5 step: 169, loss is 0.0015619999030604959\n",
      "epoch: 5 step: 170, loss is 0.14657561480998993\n",
      "epoch: 5 step: 171, loss is 0.03339165076613426\n",
      "epoch: 5 step: 172, loss is 0.00029677493148483336\n",
      "epoch: 5 step: 173, loss is 0.0027307216078042984\n",
      "epoch: 5 step: 174, loss is 0.0004598720697686076\n",
      "epoch: 5 step: 175, loss is 0.001339176669716835\n",
      "epoch: 5 step: 176, loss is 0.0045187463983893394\n",
      "epoch: 5 step: 177, loss is 0.038200028240680695\n",
      "epoch: 5 step: 178, loss is 0.11787611246109009\n",
      "epoch: 5 step: 179, loss is 0.024186229333281517\n",
      "epoch: 5 step: 180, loss is 0.046628668904304504\n",
      "epoch: 5 step: 181, loss is 0.0007341613527387381\n",
      "epoch: 5 step: 182, loss is 0.07838088274002075\n",
      "epoch: 5 step: 183, loss is 0.004845611751079559\n",
      "epoch: 5 step: 184, loss is 0.18919789791107178\n",
      "epoch: 5 step: 185, loss is 0.0002874817291740328\n",
      "epoch: 5 step: 186, loss is 0.00199444149620831\n",
      "epoch: 5 step: 187, loss is 0.16534745693206787\n",
      "epoch: 5 step: 188, loss is 0.07609652727842331\n",
      "epoch: 5 step: 189, loss is 0.0021628476679325104\n",
      "epoch: 5 step: 190, loss is 0.004195008892565966\n",
      "epoch: 5 step: 191, loss is 0.006399627774953842\n",
      "epoch: 5 step: 192, loss is 0.014312040992081165\n",
      "epoch: 5 step: 193, loss is 0.0007910158601589501\n",
      "epoch: 5 step: 194, loss is 0.042931631207466125\n",
      "epoch: 5 step: 195, loss is 0.0025002751499414444\n",
      "epoch: 5 step: 196, loss is 0.0032431844156235456\n",
      "epoch: 5 step: 197, loss is 0.19002071022987366\n",
      "epoch: 5 step: 198, loss is 0.0020387431140989065\n",
      "epoch: 5 step: 199, loss is 0.04137954115867615\n",
      "epoch: 5 step: 200, loss is 0.11965988576412201\n",
      "epoch: 5 step: 201, loss is 0.036665599793195724\n",
      "epoch: 5 step: 202, loss is 0.0006028988864272833\n",
      "epoch: 5 step: 203, loss is 0.10892261564731598\n",
      "epoch: 5 step: 204, loss is 0.004442931152880192\n",
      "epoch: 5 step: 205, loss is 0.000506018113810569\n",
      "epoch: 5 step: 206, loss is 0.24827530980110168\n",
      "epoch: 5 step: 207, loss is 0.004399674013257027\n",
      "epoch: 5 step: 208, loss is 0.0005466693546622992\n",
      "epoch: 5 step: 209, loss is 0.13279442489147186\n",
      "epoch: 5 step: 210, loss is 0.00861386489123106\n",
      "epoch: 5 step: 211, loss is 0.010370304808020592\n",
      "epoch: 5 step: 212, loss is 0.0034053358249366283\n",
      "epoch: 5 step: 213, loss is 0.02804115042090416\n",
      "epoch: 5 step: 214, loss is 0.004560372326523066\n",
      "epoch: 5 step: 215, loss is 0.001641897833906114\n",
      "epoch: 5 step: 216, loss is 0.001739101018756628\n",
      "epoch: 5 step: 217, loss is 0.0009753871709108353\n",
      "epoch: 5 step: 218, loss is 0.003157045692205429\n",
      "epoch: 5 step: 219, loss is 0.00286699621938169\n",
      "epoch: 5 step: 220, loss is 0.01739058643579483\n",
      "epoch: 5 step: 221, loss is 0.021610092371702194\n",
      "epoch: 5 step: 222, loss is 0.005330438259989023\n",
      "epoch: 5 step: 223, loss is 0.0013033756986260414\n",
      "epoch: 5 step: 224, loss is 0.002093520713970065\n",
      "epoch: 5 step: 225, loss is 0.0018408482428640127\n",
      "epoch: 5 step: 226, loss is 0.00036634120624512434\n",
      "epoch: 5 step: 227, loss is 0.002318470273166895\n",
      "epoch: 5 step: 228, loss is 0.02822064608335495\n",
      "epoch: 5 step: 229, loss is 0.060666926205158234\n",
      "epoch: 5 step: 230, loss is 0.0015861396677792072\n",
      "epoch: 5 step: 231, loss is 0.0012816579546779394\n",
      "epoch: 5 step: 232, loss is 0.10186778008937836\n",
      "epoch: 5 step: 233, loss is 0.06903602182865143\n",
      "epoch: 5 step: 234, loss is 0.006581693887710571\n",
      "epoch: 5 step: 235, loss is 0.03877022862434387\n",
      "epoch: 5 step: 236, loss is 0.011917727999389172\n",
      "epoch: 5 step: 237, loss is 0.07077004760503769\n",
      "epoch: 5 step: 238, loss is 0.04848704859614372\n",
      "epoch: 5 step: 239, loss is 0.01432747207581997\n",
      "epoch: 5 step: 240, loss is 0.22351615130901337\n",
      "epoch: 5 step: 241, loss is 0.002482883632183075\n",
      "epoch: 5 step: 242, loss is 0.009292847476899624\n",
      "epoch: 5 step: 243, loss is 0.00435083219781518\n",
      "epoch: 5 step: 244, loss is 0.03681313991546631\n",
      "epoch: 5 step: 245, loss is 0.009466228075325489\n",
      "epoch: 5 step: 246, loss is 0.06597317010164261\n",
      "epoch: 5 step: 247, loss is 0.059712085872888565\n",
      "epoch: 5 step: 248, loss is 0.000631590373814106\n",
      "epoch: 5 step: 249, loss is 0.026388458907604218\n",
      "epoch: 5 step: 250, loss is 0.009590648114681244\n",
      "epoch: 5 step: 251, loss is 0.004174548201262951\n",
      "epoch: 5 step: 252, loss is 0.00040359669947065413\n",
      "epoch: 5 step: 253, loss is 0.03823119029402733\n",
      "epoch: 5 step: 254, loss is 0.002890228759497404\n",
      "epoch: 5 step: 255, loss is 0.038711246103048325\n",
      "epoch: 5 step: 256, loss is 0.0031772153452038765\n",
      "epoch: 5 step: 257, loss is 0.010535361245274544\n",
      "epoch: 5 step: 258, loss is 0.0014483571285381913\n",
      "epoch: 5 step: 259, loss is 0.017539430409669876\n",
      "epoch: 5 step: 260, loss is 0.06956157088279724\n",
      "epoch: 5 step: 261, loss is 0.002242631744593382\n",
      "epoch: 5 step: 262, loss is 0.0013395085697993636\n",
      "epoch: 5 step: 263, loss is 0.010145733132958412\n",
      "epoch: 5 step: 264, loss is 0.0013481245841830969\n",
      "epoch: 5 step: 265, loss is 0.0020468803122639656\n",
      "epoch: 5 step: 266, loss is 0.0020188731141388416\n",
      "epoch: 5 step: 267, loss is 0.02641580067574978\n",
      "epoch: 5 step: 268, loss is 0.001131717930547893\n",
      "epoch: 5 step: 269, loss is 0.00030564991175197065\n",
      "epoch: 5 step: 270, loss is 0.011863688006997108\n",
      "epoch: 5 step: 271, loss is 0.001550244283862412\n",
      "epoch: 5 step: 272, loss is 0.0004470098065212369\n",
      "epoch: 5 step: 273, loss is 0.040956050157547\n",
      "epoch: 5 step: 274, loss is 0.017213895916938782\n",
      "epoch: 5 step: 275, loss is 0.22574760019779205\n",
      "epoch: 5 step: 276, loss is 0.0025898858439177275\n",
      "epoch: 5 step: 277, loss is 0.0043541500344872475\n",
      "epoch: 5 step: 278, loss is 0.0004484190430957824\n",
      "epoch: 5 step: 279, loss is 0.001837736344896257\n",
      "epoch: 5 step: 280, loss is 0.00495856162160635\n",
      "epoch: 5 step: 281, loss is 0.00245619541965425\n",
      "epoch: 5 step: 282, loss is 0.0017086256993934512\n",
      "epoch: 5 step: 283, loss is 0.003915606066584587\n",
      "epoch: 5 step: 284, loss is 0.0014253441477194428\n",
      "epoch: 5 step: 285, loss is 0.0209942739456892\n",
      "epoch: 5 step: 286, loss is 0.10318684577941895\n",
      "epoch: 5 step: 287, loss is 0.0896369218826294\n",
      "epoch: 5 step: 288, loss is 0.11519543081521988\n",
      "epoch: 5 step: 289, loss is 0.000634505064226687\n",
      "epoch: 5 step: 290, loss is 0.001098305219784379\n",
      "epoch: 5 step: 291, loss is 0.0005087360041216016\n",
      "epoch: 5 step: 292, loss is 0.07706736773252487\n",
      "epoch: 5 step: 293, loss is 0.02986868843436241\n",
      "epoch: 5 step: 294, loss is 0.13525892794132233\n",
      "epoch: 5 step: 295, loss is 0.0009057323914021254\n",
      "epoch: 5 step: 296, loss is 0.00018268378335051239\n",
      "epoch: 5 step: 297, loss is 0.016550330445170403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 298, loss is 0.04251819849014282\n",
      "epoch: 5 step: 299, loss is 0.0026612328365445137\n",
      "epoch: 5 step: 300, loss is 0.012265698984265327\n",
      "epoch: 5 step: 301, loss is 0.19187776744365692\n",
      "epoch: 5 step: 302, loss is 0.009602969512343407\n",
      "epoch: 5 step: 303, loss is 0.04937021806836128\n",
      "epoch: 5 step: 304, loss is 0.0009666685946285725\n",
      "epoch: 5 step: 305, loss is 0.027683332562446594\n",
      "epoch: 5 step: 306, loss is 0.018730012699961662\n",
      "epoch: 5 step: 307, loss is 0.0008591291843913496\n",
      "epoch: 5 step: 308, loss is 0.013006559573113918\n",
      "epoch: 5 step: 309, loss is 0.004595268052071333\n",
      "epoch: 5 step: 310, loss is 0.020232291892170906\n",
      "epoch: 5 step: 311, loss is 0.004512623883783817\n",
      "epoch: 5 step: 312, loss is 0.07377468049526215\n",
      "epoch: 5 step: 313, loss is 0.04570620879530907\n",
      "epoch: 5 step: 314, loss is 0.002026114845648408\n",
      "epoch: 5 step: 315, loss is 0.0063356938771903515\n",
      "epoch: 5 step: 316, loss is 0.00974242202937603\n",
      "epoch: 5 step: 317, loss is 0.014134975150227547\n",
      "epoch: 5 step: 318, loss is 0.0039212205447256565\n",
      "epoch: 5 step: 319, loss is 0.0005064461729489267\n",
      "epoch: 5 step: 320, loss is 0.01700848899781704\n",
      "epoch: 5 step: 321, loss is 0.0028186773415654898\n",
      "epoch: 5 step: 322, loss is 0.008802839554846287\n",
      "epoch: 5 step: 323, loss is 0.16548152267932892\n",
      "epoch: 5 step: 324, loss is 0.1319957673549652\n",
      "epoch: 5 step: 325, loss is 0.00044201541459187865\n",
      "epoch: 5 step: 326, loss is 0.04940317943692207\n",
      "epoch: 5 step: 327, loss is 0.023908570408821106\n",
      "epoch: 5 step: 328, loss is 0.0028200310189276934\n",
      "epoch: 5 step: 329, loss is 0.020052621141076088\n",
      "epoch: 5 step: 330, loss is 0.0005552688962779939\n",
      "epoch: 5 step: 331, loss is 0.004672440700232983\n",
      "epoch: 5 step: 332, loss is 0.0004333869437687099\n",
      "epoch: 5 step: 333, loss is 0.001153044868260622\n",
      "epoch: 5 step: 334, loss is 0.0019277316750958562\n",
      "epoch: 5 step: 335, loss is 0.039252106100320816\n",
      "epoch: 5 step: 336, loss is 0.022858455777168274\n",
      "epoch: 5 step: 337, loss is 0.05288442224264145\n",
      "epoch: 5 step: 338, loss is 0.0018132281256839633\n",
      "epoch: 5 step: 339, loss is 0.00044979501399211586\n",
      "epoch: 5 step: 340, loss is 0.05906136333942413\n",
      "epoch: 5 step: 341, loss is 0.04678468778729439\n",
      "epoch: 5 step: 342, loss is 0.00776821980252862\n",
      "epoch: 5 step: 343, loss is 0.005980271380394697\n",
      "epoch: 5 step: 344, loss is 0.0017989426851272583\n",
      "epoch: 5 step: 345, loss is 0.00980140920728445\n",
      "epoch: 5 step: 346, loss is 0.008586479350924492\n",
      "epoch: 5 step: 347, loss is 0.0136072663590312\n",
      "epoch: 5 step: 348, loss is 0.01897408254444599\n",
      "epoch: 5 step: 349, loss is 0.0005453318008221686\n",
      "epoch: 5 step: 350, loss is 0.001241570571437478\n",
      "epoch: 5 step: 351, loss is 0.036176975816488266\n",
      "epoch: 5 step: 352, loss is 0.10742511600255966\n",
      "epoch: 5 step: 353, loss is 0.0875953733921051\n",
      "epoch: 5 step: 354, loss is 0.011678509414196014\n",
      "epoch: 5 step: 355, loss is 0.0046708304435014725\n",
      "epoch: 5 step: 356, loss is 0.01838487572968006\n",
      "epoch: 5 step: 357, loss is 0.005990878213196993\n",
      "epoch: 5 step: 358, loss is 0.04998330399394035\n",
      "epoch: 5 step: 359, loss is 0.039914049208164215\n",
      "epoch: 5 step: 360, loss is 0.02560994029045105\n",
      "epoch: 5 step: 361, loss is 0.0009109602542594075\n",
      "epoch: 5 step: 362, loss is 0.007181375753134489\n",
      "epoch: 5 step: 363, loss is 0.004062889609485865\n",
      "epoch: 5 step: 364, loss is 0.011181003414094448\n",
      "epoch: 5 step: 365, loss is 0.00017002127424348146\n",
      "epoch: 5 step: 366, loss is 0.0005038643721491098\n",
      "epoch: 5 step: 367, loss is 0.022148463875055313\n",
      "epoch: 5 step: 368, loss is 0.013917379081249237\n",
      "epoch: 5 step: 369, loss is 0.01153256744146347\n",
      "epoch: 5 step: 370, loss is 0.10376817733049393\n",
      "epoch: 5 step: 371, loss is 0.000499809393659234\n",
      "epoch: 5 step: 372, loss is 0.0010469740955159068\n",
      "epoch: 5 step: 373, loss is 0.028105806559324265\n",
      "epoch: 5 step: 374, loss is 0.03254682943224907\n",
      "epoch: 5 step: 375, loss is 0.0004895058227702975\n",
      "epoch: 5 step: 376, loss is 0.005521678365767002\n",
      "epoch: 5 step: 377, loss is 0.036852456629276276\n",
      "epoch: 5 step: 378, loss is 0.007551663555204868\n",
      "epoch: 5 step: 379, loss is 0.012311268597841263\n",
      "epoch: 5 step: 380, loss is 0.0016403759364038706\n",
      "epoch: 5 step: 381, loss is 0.006449409760534763\n",
      "epoch: 5 step: 382, loss is 0.0020868186838924885\n",
      "epoch: 5 step: 383, loss is 0.0003237744967918843\n",
      "epoch: 5 step: 384, loss is 0.000513330742251128\n",
      "epoch: 5 step: 385, loss is 0.018202589824795723\n",
      "epoch: 5 step: 386, loss is 0.0005194996483623981\n",
      "epoch: 5 step: 387, loss is 0.016576116904616356\n",
      "epoch: 5 step: 388, loss is 0.0017085701692849398\n",
      "epoch: 5 step: 389, loss is 0.03230906277894974\n",
      "epoch: 5 step: 390, loss is 0.03799763694405556\n",
      "epoch: 5 step: 391, loss is 0.0010283805895596743\n",
      "epoch: 5 step: 392, loss is 0.0002317912585567683\n",
      "epoch: 5 step: 393, loss is 0.0003848728956654668\n",
      "epoch: 5 step: 394, loss is 0.0015384913422167301\n",
      "epoch: 5 step: 395, loss is 0.022161230444908142\n",
      "epoch: 5 step: 396, loss is 0.04702369496226311\n",
      "epoch: 5 step: 397, loss is 8.879845699993894e-05\n",
      "epoch: 5 step: 398, loss is 0.00888808909803629\n",
      "epoch: 5 step: 399, loss is 0.013212878257036209\n",
      "epoch: 5 step: 400, loss is 0.011476839892566204\n",
      "epoch: 5 step: 401, loss is 0.013443429954349995\n",
      "epoch: 5 step: 402, loss is 0.004355783574283123\n",
      "epoch: 5 step: 403, loss is 0.003908975515514612\n",
      "epoch: 5 step: 404, loss is 0.006795056629925966\n",
      "epoch: 5 step: 405, loss is 0.00012530383537523448\n",
      "epoch: 5 step: 406, loss is 0.0011407649144530296\n",
      "epoch: 5 step: 407, loss is 0.08506728708744049\n",
      "epoch: 5 step: 408, loss is 0.03796941041946411\n",
      "epoch: 5 step: 409, loss is 0.0021989825181663036\n",
      "epoch: 5 step: 410, loss is 0.0014365044189617038\n",
      "epoch: 5 step: 411, loss is 0.042491693049669266\n",
      "epoch: 5 step: 412, loss is 0.0014960322296246886\n",
      "epoch: 5 step: 413, loss is 0.00013351134839467704\n",
      "epoch: 5 step: 414, loss is 0.0014352098805829883\n",
      "epoch: 5 step: 415, loss is 0.0002309448318555951\n",
      "epoch: 5 step: 416, loss is 0.0025246108416467905\n",
      "epoch: 5 step: 417, loss is 0.0005770241259597242\n",
      "epoch: 5 step: 418, loss is 0.0010883377399295568\n",
      "epoch: 5 step: 419, loss is 0.009869585745036602\n",
      "epoch: 5 step: 420, loss is 0.003969072364270687\n",
      "epoch: 5 step: 421, loss is 0.0004270138742867857\n",
      "epoch: 5 step: 422, loss is 5.4665124480379745e-05\n",
      "epoch: 5 step: 423, loss is 0.0035458493512123823\n",
      "epoch: 5 step: 424, loss is 0.01255863904953003\n",
      "epoch: 5 step: 425, loss is 0.00019520538626238704\n",
      "epoch: 5 step: 426, loss is 0.0031560950446873903\n",
      "epoch: 5 step: 427, loss is 0.004395035095512867\n",
      "epoch: 5 step: 428, loss is 0.015456552617251873\n",
      "epoch: 5 step: 429, loss is 0.0005268724635243416\n",
      "epoch: 5 step: 430, loss is 0.013167009688913822\n",
      "epoch: 5 step: 431, loss is 0.0033780401572585106\n",
      "epoch: 5 step: 432, loss is 4.9712722102412954e-05\n",
      "epoch: 5 step: 433, loss is 0.06697159260511398\n",
      "epoch: 5 step: 434, loss is 0.0003984853392466903\n",
      "epoch: 5 step: 435, loss is 0.01773773692548275\n",
      "epoch: 5 step: 436, loss is 0.0019468852551653981\n",
      "epoch: 5 step: 437, loss is 0.0036628430243581533\n",
      "epoch: 5 step: 438, loss is 0.013533166609704494\n",
      "epoch: 5 step: 439, loss is 0.0020492919720709324\n",
      "epoch: 5 step: 440, loss is 0.0005479722167365253\n",
      "epoch: 5 step: 441, loss is 0.09791246056556702\n",
      "epoch: 5 step: 442, loss is 0.001295951078645885\n",
      "epoch: 5 step: 443, loss is 0.03761817514896393\n",
      "epoch: 5 step: 444, loss is 0.1319684237241745\n",
      "epoch: 5 step: 445, loss is 0.0013103719102218747\n",
      "epoch: 5 step: 446, loss is 0.01227403711527586\n",
      "epoch: 5 step: 447, loss is 0.00043447065399959683\n",
      "epoch: 5 step: 448, loss is 0.00015364799764938653\n",
      "epoch: 5 step: 449, loss is 0.005383562762290239\n",
      "epoch: 5 step: 450, loss is 0.0034156953915953636\n",
      "epoch: 5 step: 451, loss is 0.040552131831645966\n",
      "epoch: 5 step: 452, loss is 0.02770232781767845\n",
      "epoch: 5 step: 453, loss is 0.0006578047177754343\n",
      "epoch: 5 step: 454, loss is 0.0519297793507576\n",
      "epoch: 5 step: 455, loss is 0.0007241094135679305\n",
      "epoch: 5 step: 456, loss is 0.0010248057078570127\n",
      "epoch: 5 step: 457, loss is 0.04930194467306137\n",
      "epoch: 5 step: 458, loss is 0.0006032787496224046\n",
      "epoch: 5 step: 459, loss is 0.12975336611270905\n",
      "epoch: 5 step: 460, loss is 0.001036169589497149\n",
      "epoch: 5 step: 461, loss is 0.0006782012642361224\n",
      "epoch: 5 step: 462, loss is 0.00018840315169654787\n",
      "epoch: 5 step: 463, loss is 8.127657929435372e-05\n",
      "epoch: 5 step: 464, loss is 0.027840889990329742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 465, loss is 0.02926645241677761\n",
      "epoch: 5 step: 466, loss is 0.11034545302391052\n",
      "epoch: 5 step: 467, loss is 0.0019859287422150373\n",
      "epoch: 5 step: 468, loss is 0.014023039489984512\n",
      "epoch: 5 step: 469, loss is 0.015116466209292412\n",
      "epoch: 5 step: 470, loss is 0.00010099754581460729\n",
      "epoch: 5 step: 471, loss is 0.01411727536469698\n",
      "epoch: 5 step: 472, loss is 0.00046358018880710006\n",
      "epoch: 5 step: 473, loss is 0.012295536696910858\n",
      "epoch: 5 step: 474, loss is 0.0010621203109622002\n",
      "epoch: 5 step: 475, loss is 0.04078329727053642\n",
      "epoch: 5 step: 476, loss is 0.17377373576164246\n",
      "epoch: 5 step: 477, loss is 0.0020658071152865887\n",
      "epoch: 5 step: 478, loss is 0.0007024700753390789\n",
      "epoch: 5 step: 479, loss is 0.2668524980545044\n",
      "epoch: 5 step: 480, loss is 0.07412514835596085\n",
      "epoch: 5 step: 481, loss is 0.00035767946974374354\n",
      "epoch: 5 step: 482, loss is 0.01867329329252243\n",
      "epoch: 5 step: 483, loss is 0.010984014719724655\n",
      "epoch: 5 step: 484, loss is 0.0008613175014033914\n",
      "epoch: 5 step: 485, loss is 0.0005087275640107691\n",
      "epoch: 5 step: 486, loss is 0.05199083685874939\n",
      "epoch: 5 step: 487, loss is 0.0025333345402032137\n",
      "epoch: 5 step: 488, loss is 0.00019190202874597162\n",
      "epoch: 5 step: 489, loss is 0.0028094325680285692\n",
      "epoch: 5 step: 490, loss is 0.034867364913225174\n",
      "epoch: 5 step: 491, loss is 0.028750158846378326\n",
      "epoch: 5 step: 492, loss is 0.15160717070102692\n",
      "epoch: 5 step: 493, loss is 0.002084938110783696\n",
      "epoch: 5 step: 494, loss is 0.007853502407670021\n",
      "epoch: 5 step: 495, loss is 0.004302157089114189\n",
      "epoch: 5 step: 496, loss is 0.08279202878475189\n",
      "epoch: 5 step: 497, loss is 0.04937778040766716\n",
      "epoch: 5 step: 498, loss is 0.0004860280314460397\n",
      "epoch: 5 step: 499, loss is 0.04159563034772873\n",
      "epoch: 5 step: 500, loss is 0.00030509373755194247\n",
      "epoch: 5 step: 501, loss is 0.003581724362447858\n",
      "epoch: 5 step: 502, loss is 0.020147651433944702\n",
      "epoch: 5 step: 503, loss is 0.0008753202273510396\n",
      "epoch: 5 step: 504, loss is 0.009792718105018139\n",
      "epoch: 5 step: 505, loss is 0.06733772903680801\n",
      "epoch: 5 step: 506, loss is 0.0024120088201016188\n",
      "epoch: 5 step: 507, loss is 0.012757058255374432\n",
      "epoch: 5 step: 508, loss is 0.004121416248381138\n",
      "epoch: 5 step: 509, loss is 0.0037137852050364017\n",
      "epoch: 5 step: 510, loss is 0.09048464149236679\n",
      "epoch: 5 step: 511, loss is 0.03979238495230675\n",
      "epoch: 5 step: 512, loss is 0.0013938623014837503\n",
      "epoch: 5 step: 513, loss is 0.00011410002480261028\n",
      "epoch: 5 step: 514, loss is 0.03205103054642677\n",
      "epoch: 5 step: 515, loss is 0.00020456755009945482\n",
      "epoch: 5 step: 516, loss is 0.004594952799379826\n",
      "epoch: 5 step: 517, loss is 0.03824741020798683\n",
      "epoch: 5 step: 518, loss is 0.002967648906633258\n",
      "epoch: 5 step: 519, loss is 0.009980458766222\n",
      "epoch: 5 step: 520, loss is 0.00039711978752166033\n",
      "epoch: 5 step: 521, loss is 0.0007871785783208907\n",
      "epoch: 5 step: 522, loss is 0.09475713223218918\n",
      "epoch: 5 step: 523, loss is 0.007446503732353449\n",
      "epoch: 5 step: 524, loss is 0.008820673450827599\n",
      "epoch: 5 step: 525, loss is 0.00016939284978434443\n",
      "epoch: 5 step: 526, loss is 0.002650993876159191\n",
      "epoch: 5 step: 527, loss is 0.001088002580218017\n",
      "epoch: 5 step: 528, loss is 0.0048909373581409454\n",
      "epoch: 5 step: 529, loss is 0.006832528859376907\n",
      "epoch: 5 step: 530, loss is 0.011086306534707546\n",
      "epoch: 5 step: 531, loss is 0.00821783859282732\n",
      "epoch: 5 step: 532, loss is 0.0037644330877810717\n",
      "epoch: 5 step: 533, loss is 0.07734919339418411\n",
      "epoch: 5 step: 534, loss is 0.0008569651981815696\n",
      "epoch: 5 step: 535, loss is 0.00040508416714146733\n",
      "epoch: 5 step: 536, loss is 0.00024197122547775507\n",
      "epoch: 5 step: 537, loss is 0.01371185015887022\n",
      "epoch: 5 step: 538, loss is 0.0004621153639163822\n",
      "epoch: 5 step: 539, loss is 0.017145290970802307\n",
      "epoch: 5 step: 540, loss is 0.0019527934491634369\n",
      "epoch: 5 step: 541, loss is 0.010570592246949673\n",
      "epoch: 5 step: 542, loss is 0.010347812436521053\n",
      "epoch: 5 step: 543, loss is 0.15213575959205627\n",
      "epoch: 5 step: 544, loss is 0.002907347632572055\n",
      "epoch: 5 step: 545, loss is 0.004894738085567951\n",
      "epoch: 5 step: 546, loss is 0.0005374961183406413\n",
      "epoch: 5 step: 547, loss is 0.039675191044807434\n",
      "epoch: 5 step: 548, loss is 0.002805112162604928\n",
      "epoch: 5 step: 549, loss is 0.009382444433867931\n",
      "epoch: 5 step: 550, loss is 0.023834094405174255\n",
      "epoch: 5 step: 551, loss is 0.014827079139649868\n",
      "epoch: 5 step: 552, loss is 0.0002505118609406054\n",
      "epoch: 5 step: 553, loss is 0.025490814819931984\n",
      "epoch: 5 step: 554, loss is 0.0029026588890701532\n",
      "epoch: 5 step: 555, loss is 0.00018488720525056124\n",
      "epoch: 5 step: 556, loss is 0.026436880230903625\n",
      "epoch: 5 step: 557, loss is 0.0024870531633496284\n",
      "epoch: 5 step: 558, loss is 0.06121188402175903\n",
      "epoch: 5 step: 559, loss is 0.12960010766983032\n",
      "epoch: 5 step: 560, loss is 0.002741666976362467\n",
      "epoch: 5 step: 561, loss is 0.003162045730277896\n",
      "epoch: 5 step: 562, loss is 0.0022338679991662502\n",
      "epoch: 5 step: 563, loss is 0.00016183714615181088\n",
      "epoch: 5 step: 564, loss is 8.926985901780427e-05\n",
      "epoch: 5 step: 565, loss is 0.0005633910186588764\n",
      "epoch: 5 step: 566, loss is 0.0005045644356869161\n",
      "epoch: 5 step: 567, loss is 0.01724419556558132\n",
      "epoch: 5 step: 568, loss is 0.2460310310125351\n",
      "epoch: 5 step: 569, loss is 0.0018693277379497886\n",
      "epoch: 5 step: 570, loss is 0.011604060418903828\n",
      "epoch: 5 step: 571, loss is 0.020668255165219307\n",
      "epoch: 5 step: 572, loss is 0.0005287040257826447\n",
      "epoch: 5 step: 573, loss is 0.00230233883485198\n",
      "epoch: 5 step: 574, loss is 0.0005427697906270623\n",
      "epoch: 5 step: 575, loss is 0.0003423262678552419\n",
      "epoch: 5 step: 576, loss is 0.0067083039321005344\n",
      "epoch: 5 step: 577, loss is 0.03281868249177933\n",
      "epoch: 5 step: 578, loss is 0.0011425281409174204\n",
      "epoch: 5 step: 579, loss is 0.011053765192627907\n",
      "epoch: 5 step: 580, loss is 0.002273018006235361\n",
      "epoch: 5 step: 581, loss is 0.003174759913235903\n",
      "epoch: 5 step: 582, loss is 0.002042808337137103\n",
      "epoch: 5 step: 583, loss is 0.020801402628421783\n",
      "epoch: 5 step: 584, loss is 0.08762192726135254\n",
      "epoch: 5 step: 585, loss is 0.07353418320417404\n",
      "epoch: 5 step: 586, loss is 0.010579911060631275\n",
      "epoch: 5 step: 587, loss is 0.0023013101890683174\n",
      "epoch: 5 step: 588, loss is 0.000483121897559613\n",
      "epoch: 5 step: 589, loss is 0.055751170963048935\n",
      "epoch: 5 step: 590, loss is 0.0010489377891644835\n",
      "epoch: 5 step: 591, loss is 6.29774367553182e-05\n",
      "epoch: 5 step: 592, loss is 0.00034381094155833125\n",
      "epoch: 5 step: 593, loss is 0.009755047038197517\n",
      "epoch: 5 step: 594, loss is 0.000767555262427777\n",
      "epoch: 5 step: 595, loss is 0.030691232532262802\n",
      "epoch: 5 step: 596, loss is 0.19708497822284698\n",
      "epoch: 5 step: 597, loss is 0.0024214338045567274\n",
      "epoch: 5 step: 598, loss is 0.0008467398001812398\n",
      "epoch: 5 step: 599, loss is 0.0029208636842668056\n",
      "epoch: 5 step: 600, loss is 0.013851162046194077\n",
      "epoch: 5 step: 601, loss is 0.0009094314882531762\n",
      "epoch: 5 step: 602, loss is 0.0018629060359671712\n",
      "epoch: 5 step: 603, loss is 0.038321103900671005\n",
      "epoch: 5 step: 604, loss is 0.003945667762309313\n",
      "epoch: 5 step: 605, loss is 0.09026546031236649\n",
      "epoch: 5 step: 606, loss is 0.00023084337590262294\n",
      "epoch: 5 step: 607, loss is 0.001394295715726912\n",
      "epoch: 5 step: 608, loss is 3.8629426853731275e-05\n",
      "epoch: 5 step: 609, loss is 0.0036994724068790674\n",
      "epoch: 5 step: 610, loss is 0.0015358587261289358\n",
      "epoch: 5 step: 611, loss is 0.014884473755955696\n",
      "epoch: 5 step: 612, loss is 0.08366402238607407\n",
      "epoch: 5 step: 613, loss is 0.0026086890138685703\n",
      "epoch: 5 step: 614, loss is 0.07446729391813278\n",
      "epoch: 5 step: 615, loss is 0.0015659235650673509\n",
      "epoch: 5 step: 616, loss is 0.04060477390885353\n",
      "epoch: 5 step: 617, loss is 0.002728389110416174\n",
      "epoch: 5 step: 618, loss is 0.008712160401046276\n",
      "epoch: 5 step: 619, loss is 0.0023345602676272392\n",
      "epoch: 5 step: 620, loss is 0.0005945368902757764\n",
      "epoch: 5 step: 621, loss is 0.01905004493892193\n",
      "epoch: 5 step: 622, loss is 0.0019227482844144106\n",
      "epoch: 5 step: 623, loss is 0.015418630093336105\n",
      "epoch: 5 step: 624, loss is 0.2175282984972\n",
      "epoch: 5 step: 625, loss is 0.0033111756201833487\n",
      "epoch: 5 step: 626, loss is 0.00043519807513803244\n",
      "epoch: 5 step: 627, loss is 0.0876183956861496\n",
      "epoch: 5 step: 628, loss is 0.041522588580846786\n",
      "epoch: 5 step: 629, loss is 0.0027217562310397625\n",
      "epoch: 5 step: 630, loss is 0.0007660234696231782\n",
      "epoch: 5 step: 631, loss is 0.005236469674855471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 632, loss is 0.16039280593395233\n",
      "epoch: 5 step: 633, loss is 0.03595590218901634\n",
      "epoch: 5 step: 634, loss is 0.01165690366178751\n",
      "epoch: 5 step: 635, loss is 0.0036629445385187864\n",
      "epoch: 5 step: 636, loss is 0.001332308747805655\n",
      "epoch: 5 step: 637, loss is 0.0047582779079675674\n",
      "epoch: 5 step: 638, loss is 0.03834868595004082\n",
      "epoch: 5 step: 639, loss is 0.03589474782347679\n",
      "epoch: 5 step: 640, loss is 0.0005702367634512484\n",
      "epoch: 5 step: 641, loss is 0.004063349682837725\n",
      "epoch: 5 step: 642, loss is 0.0005679975729435682\n",
      "epoch: 5 step: 643, loss is 0.024184536188840866\n",
      "epoch: 5 step: 644, loss is 0.0325198732316494\n",
      "epoch: 5 step: 645, loss is 0.003982539754360914\n",
      "epoch: 5 step: 646, loss is 0.0010895951418206096\n",
      "epoch: 5 step: 647, loss is 0.00017672906687948853\n",
      "epoch: 5 step: 648, loss is 0.001398110412992537\n",
      "epoch: 5 step: 649, loss is 0.035858992487192154\n",
      "epoch: 5 step: 650, loss is 0.010470351204276085\n",
      "epoch: 5 step: 651, loss is 0.003596968948841095\n",
      "epoch: 5 step: 652, loss is 0.004038604907691479\n",
      "epoch: 5 step: 653, loss is 0.0150695675984025\n",
      "epoch: 5 step: 654, loss is 0.12828198075294495\n",
      "epoch: 5 step: 655, loss is 0.039414044469594955\n",
      "epoch: 5 step: 656, loss is 0.0012134845601394773\n",
      "epoch: 5 step: 657, loss is 0.004395483527332544\n",
      "epoch: 5 step: 658, loss is 0.0411321185529232\n",
      "epoch: 5 step: 659, loss is 0.05945949628949165\n",
      "epoch: 5 step: 660, loss is 0.0002280297048855573\n",
      "epoch: 5 step: 661, loss is 0.0003385195741429925\n",
      "epoch: 5 step: 662, loss is 0.0026545964647084475\n",
      "epoch: 5 step: 663, loss is 0.012366192415356636\n",
      "epoch: 5 step: 664, loss is 0.004582792986184359\n",
      "epoch: 5 step: 665, loss is 0.05000711977481842\n",
      "epoch: 5 step: 666, loss is 0.0020402362570166588\n",
      "epoch: 5 step: 667, loss is 0.0015555726131424308\n",
      "epoch: 5 step: 668, loss is 0.0005638800794258714\n",
      "epoch: 5 step: 669, loss is 0.09483572840690613\n",
      "epoch: 5 step: 670, loss is 0.0013206569710746408\n",
      "epoch: 5 step: 671, loss is 0.02688935399055481\n",
      "epoch: 5 step: 672, loss is 0.0006118505843915045\n",
      "epoch: 5 step: 673, loss is 0.04293709993362427\n",
      "epoch: 5 step: 674, loss is 0.011019262485206127\n",
      "epoch: 5 step: 675, loss is 0.0004305041511543095\n",
      "epoch: 5 step: 676, loss is 0.0007848237291909754\n",
      "epoch: 5 step: 677, loss is 0.06760703772306442\n",
      "epoch: 5 step: 678, loss is 0.009539369493722916\n",
      "epoch: 5 step: 679, loss is 0.004329390823841095\n",
      "epoch: 5 step: 680, loss is 0.004382767248898745\n",
      "epoch: 5 step: 681, loss is 0.001314547029323876\n",
      "epoch: 5 step: 682, loss is 0.00022527763212565333\n",
      "epoch: 5 step: 683, loss is 0.12488054484128952\n",
      "epoch: 5 step: 684, loss is 0.029039185494184494\n",
      "epoch: 5 step: 685, loss is 0.0009539471357129514\n",
      "epoch: 5 step: 686, loss is 0.0024907749611884356\n",
      "epoch: 5 step: 687, loss is 0.24869263172149658\n",
      "epoch: 5 step: 688, loss is 0.0006132762646302581\n",
      "epoch: 5 step: 689, loss is 0.001610859646461904\n",
      "epoch: 5 step: 690, loss is 0.011546997353434563\n",
      "epoch: 5 step: 691, loss is 0.0023640471044927835\n",
      "epoch: 5 step: 692, loss is 0.012954634614288807\n",
      "epoch: 5 step: 693, loss is 0.024890460073947906\n",
      "epoch: 5 step: 694, loss is 0.0030094021931290627\n",
      "epoch: 5 step: 695, loss is 0.005140002816915512\n",
      "epoch: 5 step: 696, loss is 0.02614923007786274\n",
      "epoch: 5 step: 697, loss is 0.008385462686419487\n",
      "epoch: 5 step: 698, loss is 0.005300296004861593\n",
      "epoch: 5 step: 699, loss is 0.0025700752157717943\n",
      "epoch: 5 step: 700, loss is 0.14191840589046478\n",
      "epoch: 5 step: 701, loss is 0.04289921373128891\n",
      "epoch: 5 step: 702, loss is 0.16874068975448608\n",
      "epoch: 5 step: 703, loss is 0.0004665171727538109\n",
      "epoch: 5 step: 704, loss is 0.020457932725548744\n",
      "epoch: 5 step: 705, loss is 0.0011612930102273822\n",
      "epoch: 5 step: 706, loss is 4.556425119517371e-05\n",
      "epoch: 5 step: 707, loss is 0.06277729570865631\n",
      "epoch: 5 step: 708, loss is 0.0036340050864964724\n",
      "epoch: 5 step: 709, loss is 0.024509845301508904\n",
      "epoch: 5 step: 710, loss is 0.010777580551803112\n",
      "epoch: 5 step: 711, loss is 0.02691386267542839\n",
      "epoch: 5 step: 712, loss is 0.06353636831045151\n",
      "epoch: 5 step: 713, loss is 0.006358157377690077\n",
      "epoch: 5 step: 714, loss is 0.007742712739855051\n",
      "epoch: 5 step: 715, loss is 0.0004579130618367344\n",
      "epoch: 5 step: 716, loss is 0.002520353998988867\n",
      "epoch: 5 step: 717, loss is 0.001034788554534316\n",
      "epoch: 5 step: 718, loss is 0.07117460668087006\n",
      "epoch: 5 step: 719, loss is 0.0036427797749638557\n",
      "epoch: 5 step: 720, loss is 0.013508482836186886\n",
      "epoch: 5 step: 721, loss is 0.0013872422277927399\n",
      "epoch: 5 step: 722, loss is 0.004929935093969107\n",
      "epoch: 5 step: 723, loss is 0.036997999995946884\n",
      "epoch: 5 step: 724, loss is 0.0011400830699130893\n",
      "epoch: 5 step: 725, loss is 0.004644724540412426\n",
      "epoch: 5 step: 726, loss is 0.021494794636964798\n",
      "epoch: 5 step: 727, loss is 0.0001191765841213055\n",
      "epoch: 5 step: 728, loss is 0.007165169809013605\n",
      "epoch: 5 step: 729, loss is 0.03043913096189499\n",
      "epoch: 5 step: 730, loss is 0.00021938406280241907\n",
      "epoch: 5 step: 731, loss is 0.0007171856705099344\n",
      "epoch: 5 step: 732, loss is 0.004746577236801386\n",
      "epoch: 5 step: 733, loss is 0.007600093726068735\n",
      "epoch: 5 step: 734, loss is 0.07316858321428299\n",
      "epoch: 5 step: 735, loss is 0.00023027323186397552\n",
      "epoch: 5 step: 736, loss is 0.003108025062829256\n",
      "epoch: 5 step: 737, loss is 0.004154135473072529\n",
      "epoch: 5 step: 738, loss is 0.0034727747552096844\n",
      "epoch: 5 step: 739, loss is 0.0007989982259459794\n",
      "epoch: 5 step: 740, loss is 0.0009133071871474385\n",
      "epoch: 5 step: 741, loss is 0.034473247826099396\n",
      "epoch: 5 step: 742, loss is 0.0005350322462618351\n",
      "epoch: 5 step: 743, loss is 0.1144319549202919\n",
      "epoch: 5 step: 744, loss is 0.12274320423603058\n",
      "epoch: 5 step: 745, loss is 0.08402515947818756\n",
      "epoch: 5 step: 746, loss is 0.0015502426540479064\n",
      "epoch: 5 step: 747, loss is 0.06094597652554512\n",
      "epoch: 5 step: 748, loss is 0.03158990666270256\n",
      "epoch: 5 step: 749, loss is 0.0014584033051505685\n",
      "epoch: 5 step: 750, loss is 0.004696078598499298\n",
      "epoch: 5 step: 751, loss is 0.09538436681032181\n",
      "epoch: 5 step: 752, loss is 0.012426486238837242\n",
      "epoch: 5 step: 753, loss is 0.00234854849986732\n",
      "epoch: 5 step: 754, loss is 0.0006823354051448405\n",
      "epoch: 5 step: 755, loss is 0.01046869345009327\n",
      "epoch: 5 step: 756, loss is 0.001171290990896523\n",
      "epoch: 5 step: 757, loss is 0.01064530573785305\n",
      "epoch: 5 step: 758, loss is 0.005444996990263462\n",
      "epoch: 5 step: 759, loss is 0.0020814663730561733\n",
      "epoch: 5 step: 760, loss is 0.005323719698935747\n",
      "epoch: 5 step: 761, loss is 0.003948525059968233\n",
      "epoch: 5 step: 762, loss is 0.00013709095946978778\n",
      "epoch: 5 step: 763, loss is 0.016260093078017235\n",
      "epoch: 5 step: 764, loss is 0.04136817157268524\n",
      "epoch: 5 step: 765, loss is 0.00523048872128129\n",
      "epoch: 5 step: 766, loss is 0.009442313574254513\n",
      "epoch: 5 step: 767, loss is 0.008142299018800259\n",
      "epoch: 5 step: 768, loss is 0.02893216721713543\n",
      "epoch: 5 step: 769, loss is 0.04991798847913742\n",
      "epoch: 5 step: 770, loss is 0.09754862636327744\n",
      "epoch: 5 step: 771, loss is 0.005534408148378134\n",
      "epoch: 5 step: 772, loss is 0.12620839476585388\n",
      "epoch: 5 step: 773, loss is 0.0009284591069445014\n",
      "epoch: 5 step: 774, loss is 0.0003427281917538494\n",
      "epoch: 5 step: 775, loss is 0.0003330397594254464\n",
      "epoch: 5 step: 776, loss is 0.022873802110552788\n",
      "epoch: 5 step: 777, loss is 0.00047671206993982196\n",
      "epoch: 5 step: 778, loss is 0.0030858158133924007\n",
      "epoch: 5 step: 779, loss is 0.022726530209183693\n",
      "epoch: 5 step: 780, loss is 0.012836746871471405\n",
      "epoch: 5 step: 781, loss is 0.014057788997888565\n",
      "epoch: 5 step: 782, loss is 0.007589329965412617\n",
      "epoch: 5 step: 783, loss is 0.0013598890509456396\n",
      "epoch: 5 step: 784, loss is 0.0033900064881891012\n",
      "epoch: 5 step: 785, loss is 0.015344272367656231\n",
      "epoch: 5 step: 786, loss is 0.008860744535923004\n",
      "epoch: 5 step: 787, loss is 0.002176710171625018\n",
      "epoch: 5 step: 788, loss is 0.010664521716535091\n",
      "epoch: 5 step: 789, loss is 0.03735581040382385\n",
      "epoch: 5 step: 790, loss is 0.0009076137794181705\n",
      "epoch: 5 step: 791, loss is 0.02143942564725876\n",
      "epoch: 5 step: 792, loss is 0.0009367975872009993\n",
      "epoch: 5 step: 793, loss is 0.011467747390270233\n",
      "epoch: 5 step: 794, loss is 0.09655111283063889\n",
      "epoch: 5 step: 795, loss is 0.007877840660512447\n",
      "epoch: 5 step: 796, loss is 0.031344812363386154\n",
      "epoch: 5 step: 797, loss is 0.015357650816440582\n",
      "epoch: 5 step: 798, loss is 0.11290684342384338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 799, loss is 0.022149140015244484\n",
      "epoch: 5 step: 800, loss is 0.03237271308898926\n",
      "epoch: 5 step: 801, loss is 0.03485342860221863\n",
      "epoch: 5 step: 802, loss is 0.0030659916810691357\n",
      "epoch: 5 step: 803, loss is 0.008773764595389366\n",
      "epoch: 5 step: 804, loss is 0.009315287694334984\n",
      "epoch: 5 step: 805, loss is 0.010834229178726673\n",
      "epoch: 5 step: 806, loss is 0.0021073424722999334\n",
      "epoch: 5 step: 807, loss is 0.011282804422080517\n",
      "epoch: 5 step: 808, loss is 0.08533588796854019\n",
      "epoch: 5 step: 809, loss is 0.09151814877986908\n",
      "epoch: 5 step: 810, loss is 0.009837665595114231\n",
      "epoch: 5 step: 811, loss is 0.003385453252121806\n",
      "epoch: 5 step: 812, loss is 0.03498955816030502\n",
      "epoch: 5 step: 813, loss is 0.042895037680864334\n",
      "epoch: 5 step: 814, loss is 0.0018997001461684704\n",
      "epoch: 5 step: 815, loss is 0.00035973472404293716\n",
      "epoch: 5 step: 816, loss is 0.0037405749317258596\n",
      "epoch: 5 step: 817, loss is 0.1158047541975975\n",
      "epoch: 5 step: 818, loss is 0.07899267971515656\n",
      "epoch: 5 step: 819, loss is 0.004761829972267151\n",
      "epoch: 5 step: 820, loss is 0.0002839870285242796\n",
      "epoch: 5 step: 821, loss is 0.016533495858311653\n",
      "epoch: 5 step: 822, loss is 0.003817512420937419\n",
      "epoch: 5 step: 823, loss is 0.07787026464939117\n",
      "epoch: 5 step: 824, loss is 0.046426933258771896\n",
      "epoch: 5 step: 825, loss is 0.009371823631227016\n",
      "epoch: 5 step: 826, loss is 0.02054106444120407\n",
      "epoch: 5 step: 827, loss is 0.002345654182136059\n",
      "epoch: 5 step: 828, loss is 0.006429035682231188\n",
      "epoch: 5 step: 829, loss is 0.009840304031968117\n",
      "epoch: 5 step: 830, loss is 0.0027096315752714872\n",
      "epoch: 5 step: 831, loss is 0.00026185507886111736\n",
      "epoch: 5 step: 832, loss is 0.00042325371759943664\n",
      "epoch: 5 step: 833, loss is 0.00454584788531065\n",
      "epoch: 5 step: 834, loss is 0.00014630079385824502\n",
      "epoch: 5 step: 835, loss is 0.001880610128864646\n",
      "epoch: 5 step: 836, loss is 0.0030740348156541586\n",
      "epoch: 5 step: 837, loss is 0.0023220223374664783\n",
      "epoch: 5 step: 838, loss is 0.004741146694868803\n",
      "epoch: 5 step: 839, loss is 0.15666241943836212\n",
      "epoch: 5 step: 840, loss is 0.009104485623538494\n",
      "epoch: 5 step: 841, loss is 0.007327040657401085\n",
      "epoch: 5 step: 842, loss is 0.010353063233196735\n",
      "epoch: 5 step: 843, loss is 0.026976916939020157\n",
      "epoch: 5 step: 844, loss is 0.0016986370319500566\n",
      "epoch: 5 step: 845, loss is 0.016829119995236397\n",
      "epoch: 5 step: 846, loss is 0.0014118388062343001\n",
      "epoch: 5 step: 847, loss is 0.007607081905007362\n",
      "epoch: 5 step: 848, loss is 0.022360166534781456\n",
      "epoch: 5 step: 849, loss is 0.0009884428000077605\n",
      "epoch: 5 step: 850, loss is 0.00010032601130660623\n",
      "epoch: 5 step: 851, loss is 0.0014779678313061595\n",
      "epoch: 5 step: 852, loss is 0.006377805955708027\n",
      "epoch: 5 step: 853, loss is 0.0018123409245163202\n",
      "epoch: 5 step: 854, loss is 0.000609325070399791\n",
      "epoch: 5 step: 855, loss is 0.000644593732431531\n",
      "epoch: 5 step: 856, loss is 0.0007482473156414926\n",
      "epoch: 5 step: 857, loss is 0.0040320600382983685\n",
      "epoch: 5 step: 858, loss is 0.005360870156437159\n",
      "epoch: 5 step: 859, loss is 0.05313849076628685\n",
      "epoch: 5 step: 860, loss is 0.003180930158123374\n",
      "epoch: 5 step: 861, loss is 0.0012023258022964\n",
      "epoch: 5 step: 862, loss is 0.08293163776397705\n",
      "epoch: 5 step: 863, loss is 0.0008323352667503059\n",
      "epoch: 5 step: 864, loss is 0.006177694071084261\n",
      "epoch: 5 step: 865, loss is 0.003513815812766552\n",
      "epoch: 5 step: 866, loss is 0.0009255710174329579\n",
      "epoch: 5 step: 867, loss is 0.06321245431900024\n",
      "epoch: 5 step: 868, loss is 0.06866692751646042\n",
      "epoch: 5 step: 869, loss is 0.002785565797239542\n",
      "epoch: 5 step: 870, loss is 0.26451197266578674\n",
      "epoch: 5 step: 871, loss is 0.06025117635726929\n",
      "epoch: 5 step: 872, loss is 0.0027359789237380028\n",
      "epoch: 5 step: 873, loss is 0.0681576356291771\n",
      "epoch: 5 step: 874, loss is 0.015522727742791176\n",
      "epoch: 5 step: 875, loss is 0.01519219484180212\n",
      "epoch: 5 step: 876, loss is 0.07692179083824158\n",
      "epoch: 5 step: 877, loss is 0.0005538816913031042\n",
      "epoch: 5 step: 878, loss is 0.0019417465664446354\n",
      "epoch: 5 step: 879, loss is 0.10426079481840134\n",
      "epoch: 5 step: 880, loss is 0.00018642932991497219\n",
      "epoch: 5 step: 881, loss is 0.006398641038686037\n",
      "epoch: 5 step: 882, loss is 0.0004338746366556734\n",
      "epoch: 5 step: 883, loss is 0.029678652063012123\n",
      "epoch: 5 step: 884, loss is 0.01283088605850935\n",
      "epoch: 5 step: 885, loss is 0.005410935264080763\n",
      "epoch: 5 step: 886, loss is 0.002107827691361308\n",
      "epoch: 5 step: 887, loss is 0.0006968408124521375\n",
      "epoch: 5 step: 888, loss is 0.0010619303211569786\n",
      "epoch: 5 step: 889, loss is 0.015307387337088585\n",
      "epoch: 5 step: 890, loss is 0.0014481564285233617\n",
      "epoch: 5 step: 891, loss is 0.001011412125080824\n",
      "epoch: 5 step: 892, loss is 0.030287714675068855\n",
      "epoch: 5 step: 893, loss is 0.020660290494561195\n",
      "epoch: 5 step: 894, loss is 0.17448361217975616\n",
      "epoch: 5 step: 895, loss is 0.0006623066146858037\n",
      "epoch: 5 step: 896, loss is 0.0009326816652901471\n",
      "epoch: 5 step: 897, loss is 0.0013358950382098556\n",
      "epoch: 5 step: 898, loss is 0.05291513353586197\n",
      "epoch: 5 step: 899, loss is 0.07515294849872589\n",
      "epoch: 5 step: 900, loss is 0.11411882191896439\n",
      "epoch: 5 step: 901, loss is 0.026818430051207542\n",
      "epoch: 5 step: 902, loss is 0.0006140939076431096\n",
      "epoch: 5 step: 903, loss is 0.00028840595041401684\n",
      "epoch: 5 step: 904, loss is 0.00028955176821909845\n",
      "epoch: 5 step: 905, loss is 0.002478956012055278\n",
      "epoch: 5 step: 906, loss is 0.0001281105214729905\n",
      "epoch: 5 step: 907, loss is 0.07242900878190994\n",
      "epoch: 5 step: 908, loss is 0.0022057141177356243\n",
      "epoch: 5 step: 909, loss is 0.08873551338911057\n",
      "epoch: 5 step: 910, loss is 0.10007630288600922\n",
      "epoch: 5 step: 911, loss is 0.0018718024948611856\n",
      "epoch: 5 step: 912, loss is 0.00021781167015433311\n",
      "epoch: 5 step: 913, loss is 0.0029318910092115402\n",
      "epoch: 5 step: 914, loss is 0.002065505599603057\n",
      "epoch: 5 step: 915, loss is 0.0014233357505872846\n",
      "epoch: 5 step: 916, loss is 0.0008082322310656309\n",
      "epoch: 5 step: 917, loss is 0.013326290994882584\n",
      "epoch: 5 step: 918, loss is 0.019561536610126495\n",
      "epoch: 5 step: 919, loss is 0.019200388342142105\n",
      "epoch: 5 step: 920, loss is 0.001264289254322648\n",
      "epoch: 5 step: 921, loss is 0.002390173962339759\n",
      "epoch: 5 step: 922, loss is 0.3228757381439209\n",
      "epoch: 5 step: 923, loss is 0.00040718179661780596\n",
      "epoch: 5 step: 924, loss is 0.0011649341322481632\n",
      "epoch: 5 step: 925, loss is 0.005276121664792299\n",
      "epoch: 5 step: 926, loss is 0.125453382730484\n",
      "epoch: 5 step: 927, loss is 0.1928997039794922\n",
      "epoch: 5 step: 928, loss is 0.0027351216413080692\n",
      "epoch: 5 step: 929, loss is 9.089885134017095e-05\n",
      "epoch: 5 step: 930, loss is 0.0029044225811958313\n",
      "epoch: 5 step: 931, loss is 0.03034186363220215\n",
      "epoch: 5 step: 932, loss is 0.003575975075364113\n",
      "epoch: 5 step: 933, loss is 0.0037135332822799683\n",
      "epoch: 5 step: 934, loss is 0.004442507866770029\n",
      "epoch: 5 step: 935, loss is 0.0003864398750010878\n",
      "epoch: 5 step: 936, loss is 0.0002174276887672022\n",
      "epoch: 5 step: 937, loss is 0.0034198430366814137\n",
      "epoch: 5 step: 938, loss is 0.006016585510224104\n",
      "epoch: 5 step: 939, loss is 0.005582455080002546\n",
      "epoch: 5 step: 940, loss is 0.01871129497885704\n",
      "epoch: 5 step: 941, loss is 0.0005819222424179316\n",
      "epoch: 5 step: 942, loss is 0.04707987606525421\n",
      "epoch: 5 step: 943, loss is 0.0027304908726364374\n",
      "epoch: 5 step: 944, loss is 0.08041437715291977\n",
      "epoch: 5 step: 945, loss is 0.0796617642045021\n",
      "epoch: 5 step: 946, loss is 0.0820179358124733\n",
      "epoch: 5 step: 947, loss is 0.09356283396482468\n",
      "epoch: 5 step: 948, loss is 1.752837488311343e-05\n",
      "epoch: 5 step: 949, loss is 0.04536397382616997\n",
      "epoch: 5 step: 950, loss is 0.015083846636116505\n",
      "epoch: 5 step: 951, loss is 0.04592224955558777\n",
      "epoch: 5 step: 952, loss is 0.0015356475487351418\n",
      "epoch: 5 step: 953, loss is 0.0016859145835042\n",
      "epoch: 5 step: 954, loss is 0.004810241516679525\n",
      "epoch: 5 step: 955, loss is 0.002842814428731799\n",
      "epoch: 5 step: 956, loss is 0.0021880129352211952\n",
      "epoch: 5 step: 957, loss is 0.0010256117675453424\n",
      "epoch: 5 step: 958, loss is 0.003869562176987529\n",
      "epoch: 5 step: 959, loss is 0.0027641323395073414\n",
      "epoch: 5 step: 960, loss is 0.09547371417284012\n",
      "epoch: 5 step: 961, loss is 0.01958465203642845\n",
      "epoch: 5 step: 962, loss is 0.014349156990647316\n",
      "epoch: 5 step: 963, loss is 0.011193796060979366\n",
      "epoch: 5 step: 964, loss is 0.012314897030591965\n",
      "epoch: 5 step: 965, loss is 0.025937579572200775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 966, loss is 0.00028011854737997055\n",
      "epoch: 5 step: 967, loss is 0.010540145449340343\n",
      "epoch: 5 step: 968, loss is 0.010111525654792786\n",
      "epoch: 5 step: 969, loss is 0.001295869005843997\n",
      "epoch: 5 step: 970, loss is 0.001076631946489215\n",
      "epoch: 5 step: 971, loss is 0.0011609579669311643\n",
      "epoch: 5 step: 972, loss is 0.0002590948424767703\n",
      "epoch: 5 step: 973, loss is 0.008990844711661339\n",
      "epoch: 5 step: 974, loss is 0.00011077531962655485\n",
      "epoch: 5 step: 975, loss is 0.004545044619590044\n",
      "epoch: 5 step: 976, loss is 0.001301947282627225\n",
      "epoch: 5 step: 977, loss is 0.0006332652410492301\n",
      "epoch: 5 step: 978, loss is 8.939476538216695e-05\n",
      "epoch: 5 step: 979, loss is 0.007297531235963106\n",
      "epoch: 5 step: 980, loss is 0.006834104657173157\n",
      "epoch: 5 step: 981, loss is 0.0004770733357872814\n",
      "epoch: 5 step: 982, loss is 0.00015631596033927053\n",
      "epoch: 5 step: 983, loss is 0.0493740513920784\n",
      "epoch: 5 step: 984, loss is 0.047854553908109665\n",
      "epoch: 5 step: 985, loss is 0.07850825041532516\n",
      "epoch: 5 step: 986, loss is 0.0009038408170454204\n",
      "epoch: 5 step: 987, loss is 0.034346241503953934\n",
      "epoch: 5 step: 988, loss is 0.007037865463644266\n",
      "epoch: 5 step: 989, loss is 0.0013595203636214137\n",
      "epoch: 5 step: 990, loss is 0.002433180343359709\n",
      "epoch: 5 step: 991, loss is 0.41289764642715454\n",
      "epoch: 5 step: 992, loss is 0.0011021480895578861\n",
      "epoch: 5 step: 993, loss is 0.06007201969623566\n",
      "epoch: 5 step: 994, loss is 0.009181085973978043\n",
      "epoch: 5 step: 995, loss is 0.006258048117160797\n",
      "epoch: 5 step: 996, loss is 0.028991438448429108\n",
      "epoch: 5 step: 997, loss is 0.00021825787553098053\n",
      "epoch: 5 step: 998, loss is 0.0010107429698109627\n",
      "epoch: 5 step: 999, loss is 0.04277550429105759\n",
      "epoch: 5 step: 1000, loss is 0.0013046760577708483\n",
      "epoch: 5 step: 1001, loss is 0.008321077562868595\n",
      "epoch: 5 step: 1002, loss is 0.21737508475780487\n",
      "epoch: 5 step: 1003, loss is 0.1529863327741623\n",
      "epoch: 5 step: 1004, loss is 0.0003031743399333209\n",
      "epoch: 5 step: 1005, loss is 0.044768281280994415\n",
      "epoch: 5 step: 1006, loss is 0.02088887244462967\n",
      "epoch: 5 step: 1007, loss is 0.0004237556713633239\n",
      "epoch: 5 step: 1008, loss is 0.01584700308740139\n",
      "epoch: 5 step: 1009, loss is 0.018847549334168434\n",
      "epoch: 5 step: 1010, loss is 0.00506682088598609\n",
      "epoch: 5 step: 1011, loss is 0.0011216660495847464\n",
      "epoch: 5 step: 1012, loss is 0.047457076609134674\n",
      "epoch: 5 step: 1013, loss is 0.015845518559217453\n",
      "epoch: 5 step: 1014, loss is 0.0194354560226202\n",
      "epoch: 5 step: 1015, loss is 0.0006122555932961404\n",
      "epoch: 5 step: 1016, loss is 0.003618404967710376\n",
      "epoch: 5 step: 1017, loss is 0.0009445146424695849\n",
      "epoch: 5 step: 1018, loss is 0.03628953918814659\n",
      "epoch: 5 step: 1019, loss is 0.11829488724470139\n",
      "epoch: 5 step: 1020, loss is 0.0032819435000419617\n",
      "epoch: 5 step: 1021, loss is 0.10802865028381348\n",
      "epoch: 5 step: 1022, loss is 0.012298567220568657\n",
      "epoch: 5 step: 1023, loss is 0.00019436972797848284\n",
      "epoch: 5 step: 1024, loss is 0.0029790899716317654\n",
      "epoch: 5 step: 1025, loss is 0.0010627935407683253\n",
      "epoch: 5 step: 1026, loss is 0.0007000069017522037\n",
      "epoch: 5 step: 1027, loss is 0.02914034202694893\n",
      "epoch: 5 step: 1028, loss is 0.025514570996165276\n",
      "epoch: 5 step: 1029, loss is 0.002067059511318803\n",
      "epoch: 5 step: 1030, loss is 0.0016657834639772773\n",
      "epoch: 5 step: 1031, loss is 0.0013517301995307207\n",
      "epoch: 5 step: 1032, loss is 0.0026189961936324835\n",
      "epoch: 5 step: 1033, loss is 0.0016125808469951153\n",
      "epoch: 5 step: 1034, loss is 0.003174193436279893\n",
      "epoch: 5 step: 1035, loss is 0.003943116404116154\n",
      "epoch: 5 step: 1036, loss is 0.0011280665639787912\n",
      "epoch: 5 step: 1037, loss is 0.013830705545842648\n",
      "epoch: 5 step: 1038, loss is 0.010556470602750778\n",
      "epoch: 5 step: 1039, loss is 0.029823632910847664\n",
      "epoch: 5 step: 1040, loss is 0.0029291610699146986\n",
      "epoch: 5 step: 1041, loss is 0.0032823632936924696\n",
      "epoch: 5 step: 1042, loss is 0.01358131691813469\n",
      "epoch: 5 step: 1043, loss is 0.30706527829170227\n",
      "epoch: 5 step: 1044, loss is 0.05000732094049454\n",
      "epoch: 5 step: 1045, loss is 0.00229294179007411\n",
      "epoch: 5 step: 1046, loss is 0.06745874136686325\n",
      "epoch: 5 step: 1047, loss is 0.29087206721305847\n",
      "epoch: 5 step: 1048, loss is 0.0229496993124485\n",
      "epoch: 5 step: 1049, loss is 0.0017588352784514427\n",
      "epoch: 5 step: 1050, loss is 0.01827061176300049\n",
      "epoch: 5 step: 1051, loss is 0.04216693714261055\n",
      "epoch: 5 step: 1052, loss is 0.008620204403996468\n",
      "epoch: 5 step: 1053, loss is 0.0004941002698615193\n",
      "epoch: 5 step: 1054, loss is 0.0004968098946847022\n",
      "epoch: 5 step: 1055, loss is 0.005650768987834454\n",
      "epoch: 5 step: 1056, loss is 0.06259483098983765\n",
      "epoch: 5 step: 1057, loss is 0.0005772419390268624\n",
      "epoch: 5 step: 1058, loss is 0.05254460498690605\n",
      "epoch: 5 step: 1059, loss is 0.13568685948848724\n",
      "epoch: 5 step: 1060, loss is 0.002535805804654956\n",
      "epoch: 5 step: 1061, loss is 0.05369250848889351\n",
      "epoch: 5 step: 1062, loss is 0.0542229562997818\n",
      "epoch: 5 step: 1063, loss is 0.0008134833769872785\n",
      "epoch: 5 step: 1064, loss is 0.0003241707163397223\n",
      "epoch: 5 step: 1065, loss is 0.0022776674013584852\n",
      "epoch: 5 step: 1066, loss is 0.0013434573775157332\n",
      "epoch: 5 step: 1067, loss is 0.0036941110156476498\n",
      "epoch: 5 step: 1068, loss is 0.09240496158599854\n",
      "epoch: 5 step: 1069, loss is 0.026679042726755142\n",
      "epoch: 5 step: 1070, loss is 0.0034547518007457256\n",
      "epoch: 5 step: 1071, loss is 0.22653724253177643\n",
      "epoch: 5 step: 1072, loss is 0.004691231530159712\n",
      "epoch: 5 step: 1073, loss is 0.005440430715680122\n",
      "epoch: 5 step: 1074, loss is 0.003291275817900896\n",
      "epoch: 5 step: 1075, loss is 0.007609196938574314\n",
      "epoch: 5 step: 1076, loss is 0.033849190920591354\n",
      "epoch: 5 step: 1077, loss is 0.009553924202919006\n",
      "epoch: 5 step: 1078, loss is 0.016636379063129425\n",
      "epoch: 5 step: 1079, loss is 0.2182079553604126\n",
      "epoch: 5 step: 1080, loss is 0.0018688898999243975\n",
      "epoch: 5 step: 1081, loss is 0.0032769343815743923\n",
      "epoch: 5 step: 1082, loss is 0.0008280479232780635\n",
      "epoch: 5 step: 1083, loss is 0.047489725053310394\n",
      "epoch: 5 step: 1084, loss is 0.00027395106735639274\n",
      "epoch: 5 step: 1085, loss is 0.004850136116147041\n",
      "epoch: 5 step: 1086, loss is 0.0034910498652607203\n",
      "epoch: 5 step: 1087, loss is 0.0575043261051178\n",
      "epoch: 5 step: 1088, loss is 0.10707930475473404\n",
      "epoch: 5 step: 1089, loss is 0.003320185234770179\n",
      "epoch: 5 step: 1090, loss is 0.08551880717277527\n",
      "epoch: 5 step: 1091, loss is 0.10632164031267166\n",
      "epoch: 5 step: 1092, loss is 0.0003757286467589438\n",
      "epoch: 5 step: 1093, loss is 0.00018766371067613363\n",
      "epoch: 5 step: 1094, loss is 0.0010741770965978503\n",
      "epoch: 5 step: 1095, loss is 0.1298307627439499\n",
      "epoch: 5 step: 1096, loss is 0.07712604105472565\n",
      "epoch: 5 step: 1097, loss is 0.004877085331827402\n",
      "epoch: 5 step: 1098, loss is 0.0009678033529780805\n",
      "epoch: 5 step: 1099, loss is 0.04474247992038727\n",
      "epoch: 5 step: 1100, loss is 0.0036790864542126656\n",
      "epoch: 5 step: 1101, loss is 0.03275623917579651\n",
      "epoch: 5 step: 1102, loss is 0.01348155178129673\n",
      "epoch: 5 step: 1103, loss is 0.07496508210897446\n",
      "epoch: 5 step: 1104, loss is 0.014121150597929955\n",
      "epoch: 5 step: 1105, loss is 0.013566502369940281\n",
      "epoch: 5 step: 1106, loss is 0.008128179237246513\n",
      "epoch: 5 step: 1107, loss is 0.0020600103307515383\n",
      "epoch: 5 step: 1108, loss is 0.09728672355413437\n",
      "epoch: 5 step: 1109, loss is 0.0013380196178331971\n",
      "epoch: 5 step: 1110, loss is 0.009467482566833496\n",
      "epoch: 5 step: 1111, loss is 0.007909235544502735\n",
      "epoch: 5 step: 1112, loss is 0.007321321405470371\n",
      "epoch: 5 step: 1113, loss is 0.006224744487553835\n",
      "epoch: 5 step: 1114, loss is 0.10343749076128006\n",
      "epoch: 5 step: 1115, loss is 0.00022658737725578249\n",
      "epoch: 5 step: 1116, loss is 0.02722989022731781\n",
      "epoch: 5 step: 1117, loss is 0.008906465955078602\n",
      "epoch: 5 step: 1118, loss is 0.011412887834012508\n",
      "epoch: 5 step: 1119, loss is 0.0012814771616831422\n",
      "epoch: 5 step: 1120, loss is 0.06259351968765259\n",
      "epoch: 5 step: 1121, loss is 0.02356691099703312\n",
      "epoch: 5 step: 1122, loss is 0.00018719145737122744\n",
      "epoch: 5 step: 1123, loss is 0.021283399313688278\n",
      "epoch: 5 step: 1124, loss is 0.10088938474655151\n",
      "epoch: 5 step: 1125, loss is 0.004408964887261391\n",
      "epoch: 5 step: 1126, loss is 0.02802686020731926\n",
      "epoch: 5 step: 1127, loss is 0.003485593944787979\n",
      "epoch: 5 step: 1128, loss is 0.023405177518725395\n",
      "epoch: 5 step: 1129, loss is 0.03482867777347565\n",
      "epoch: 5 step: 1130, loss is 0.0044121816754341125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1131, loss is 0.3043038249015808\n",
      "epoch: 5 step: 1132, loss is 0.010461428202688694\n",
      "epoch: 5 step: 1133, loss is 0.0008671876275911927\n",
      "epoch: 5 step: 1134, loss is 0.009814509190618992\n",
      "epoch: 5 step: 1135, loss is 0.060856714844703674\n",
      "epoch: 5 step: 1136, loss is 0.003375266445800662\n",
      "epoch: 5 step: 1137, loss is 0.00045799562940374017\n",
      "epoch: 5 step: 1138, loss is 0.01907407119870186\n",
      "epoch: 5 step: 1139, loss is 0.1669834703207016\n",
      "epoch: 5 step: 1140, loss is 0.022304346784949303\n",
      "epoch: 5 step: 1141, loss is 0.0003465167828835547\n",
      "epoch: 5 step: 1142, loss is 0.0006524877971969545\n",
      "epoch: 5 step: 1143, loss is 0.0006694881594739854\n",
      "epoch: 5 step: 1144, loss is 0.000782885414082557\n",
      "epoch: 5 step: 1145, loss is 0.002090388908982277\n",
      "epoch: 5 step: 1146, loss is 0.0049490295350551605\n",
      "epoch: 5 step: 1147, loss is 0.018528994172811508\n",
      "epoch: 5 step: 1148, loss is 0.12622177600860596\n",
      "epoch: 5 step: 1149, loss is 0.0011879325611516833\n",
      "epoch: 5 step: 1150, loss is 0.18042272329330444\n",
      "epoch: 5 step: 1151, loss is 0.0022292144130915403\n",
      "epoch: 5 step: 1152, loss is 0.0037910216487944126\n",
      "epoch: 5 step: 1153, loss is 0.0007029037806205451\n",
      "epoch: 5 step: 1154, loss is 0.07373347878456116\n",
      "epoch: 5 step: 1155, loss is 0.001069470657967031\n",
      "epoch: 5 step: 1156, loss is 0.00024381096591241658\n",
      "epoch: 5 step: 1157, loss is 0.0028337612748146057\n",
      "epoch: 5 step: 1158, loss is 0.05506424233317375\n",
      "epoch: 5 step: 1159, loss is 0.006039760075509548\n",
      "epoch: 5 step: 1160, loss is 0.0002999246644321829\n",
      "epoch: 5 step: 1161, loss is 0.0006024310132488608\n",
      "epoch: 5 step: 1162, loss is 0.003191402880474925\n",
      "epoch: 5 step: 1163, loss is 0.12031003087759018\n",
      "epoch: 5 step: 1164, loss is 0.01259631384164095\n",
      "epoch: 5 step: 1165, loss is 0.0002470083418302238\n",
      "epoch: 5 step: 1166, loss is 0.007699974346905947\n",
      "epoch: 5 step: 1167, loss is 0.03857429325580597\n",
      "epoch: 5 step: 1168, loss is 0.026326006278395653\n",
      "epoch: 5 step: 1169, loss is 0.0397043451666832\n",
      "epoch: 5 step: 1170, loss is 0.025442717596888542\n",
      "epoch: 5 step: 1171, loss is 0.023064889013767242\n",
      "epoch: 5 step: 1172, loss is 0.0013141337549313903\n",
      "epoch: 5 step: 1173, loss is 0.0003018667339347303\n",
      "epoch: 5 step: 1174, loss is 0.06086529791355133\n",
      "epoch: 5 step: 1175, loss is 0.02271723747253418\n",
      "epoch: 5 step: 1176, loss is 0.0032509262673556805\n",
      "epoch: 5 step: 1177, loss is 0.0012428589398041368\n",
      "epoch: 5 step: 1178, loss is 0.07740512490272522\n",
      "epoch: 5 step: 1179, loss is 0.0025926160160452127\n",
      "epoch: 5 step: 1180, loss is 0.00159864139277488\n",
      "epoch: 5 step: 1181, loss is 0.018526384606957436\n",
      "epoch: 5 step: 1182, loss is 0.011855151504278183\n",
      "epoch: 5 step: 1183, loss is 0.0279035996645689\n",
      "epoch: 5 step: 1184, loss is 0.05247114598751068\n",
      "epoch: 5 step: 1185, loss is 0.026219459250569344\n",
      "epoch: 5 step: 1186, loss is 0.00018449145136401057\n",
      "epoch: 5 step: 1187, loss is 0.006791106890887022\n",
      "epoch: 5 step: 1188, loss is 0.0314728282392025\n",
      "epoch: 5 step: 1189, loss is 0.0024568899534642696\n",
      "epoch: 5 step: 1190, loss is 0.02196338213980198\n",
      "epoch: 5 step: 1191, loss is 0.09422888606786728\n",
      "epoch: 5 step: 1192, loss is 0.011565239168703556\n",
      "epoch: 5 step: 1193, loss is 0.0025606683921068907\n",
      "epoch: 5 step: 1194, loss is 0.0020299479365348816\n",
      "epoch: 5 step: 1195, loss is 0.001727598486468196\n",
      "epoch: 5 step: 1196, loss is 0.010324249044060707\n",
      "epoch: 5 step: 1197, loss is 0.08614218235015869\n",
      "epoch: 5 step: 1198, loss is 8.309016266139224e-05\n",
      "epoch: 5 step: 1199, loss is 0.09733849763870239\n",
      "epoch: 5 step: 1200, loss is 0.011558916419744492\n",
      "epoch: 5 step: 1201, loss is 0.004357509780675173\n",
      "epoch: 5 step: 1202, loss is 0.002104841871187091\n",
      "epoch: 5 step: 1203, loss is 0.007984176278114319\n",
      "epoch: 5 step: 1204, loss is 0.002091033849865198\n",
      "epoch: 5 step: 1205, loss is 0.003789867740124464\n",
      "epoch: 5 step: 1206, loss is 0.0755869448184967\n",
      "epoch: 5 step: 1207, loss is 0.003765188157558441\n",
      "epoch: 5 step: 1208, loss is 0.004119951277971268\n",
      "epoch: 5 step: 1209, loss is 0.018532635644078255\n",
      "epoch: 5 step: 1210, loss is 0.027111459523439407\n",
      "epoch: 5 step: 1211, loss is 0.17121581733226776\n",
      "epoch: 5 step: 1212, loss is 0.014511112123727798\n",
      "epoch: 5 step: 1213, loss is 0.005042949225753546\n",
      "epoch: 5 step: 1214, loss is 0.16002967953681946\n",
      "epoch: 5 step: 1215, loss is 0.032936275005340576\n",
      "epoch: 5 step: 1216, loss is 0.0005035571521148086\n",
      "epoch: 5 step: 1217, loss is 0.10480927675962448\n",
      "epoch: 5 step: 1218, loss is 0.014385205693542957\n",
      "epoch: 5 step: 1219, loss is 0.0756923109292984\n",
      "epoch: 5 step: 1220, loss is 0.0014498160453513265\n",
      "epoch: 5 step: 1221, loss is 0.00162281293887645\n",
      "epoch: 5 step: 1222, loss is 0.04152464121580124\n",
      "epoch: 5 step: 1223, loss is 0.0907619372010231\n",
      "epoch: 5 step: 1224, loss is 0.000837679544929415\n",
      "epoch: 5 step: 1225, loss is 0.0016896314918994904\n",
      "epoch: 5 step: 1226, loss is 0.2894331216812134\n",
      "epoch: 5 step: 1227, loss is 0.028544142842292786\n",
      "epoch: 5 step: 1228, loss is 0.0008874624036252499\n",
      "epoch: 5 step: 1229, loss is 0.01814303733408451\n",
      "epoch: 5 step: 1230, loss is 0.0016738499980419874\n",
      "epoch: 5 step: 1231, loss is 0.09445659816265106\n",
      "epoch: 5 step: 1232, loss is 0.03281322866678238\n",
      "epoch: 5 step: 1233, loss is 0.006222937256097794\n",
      "epoch: 5 step: 1234, loss is 0.009925737977027893\n",
      "epoch: 5 step: 1235, loss is 0.01960965432226658\n",
      "epoch: 5 step: 1236, loss is 0.002044891705736518\n",
      "epoch: 5 step: 1237, loss is 0.0009607503889128566\n",
      "epoch: 5 step: 1238, loss is 0.01487426646053791\n",
      "epoch: 5 step: 1239, loss is 0.0018402044661343098\n",
      "epoch: 5 step: 1240, loss is 0.01303137931972742\n",
      "epoch: 5 step: 1241, loss is 0.0020708772353827953\n",
      "epoch: 5 step: 1242, loss is 0.001447901246137917\n",
      "epoch: 5 step: 1243, loss is 0.002783456351608038\n",
      "epoch: 5 step: 1244, loss is 0.032090552151203156\n",
      "epoch: 5 step: 1245, loss is 0.0009868255583569407\n",
      "epoch: 5 step: 1246, loss is 0.0035367109812796116\n",
      "epoch: 5 step: 1247, loss is 0.0013403326738625765\n",
      "epoch: 5 step: 1248, loss is 0.012599623762071133\n",
      "epoch: 5 step: 1249, loss is 0.007845343090593815\n",
      "epoch: 5 step: 1250, loss is 0.013156087137758732\n",
      "epoch: 5 step: 1251, loss is 0.0016495188465341926\n",
      "epoch: 5 step: 1252, loss is 0.08215676248073578\n",
      "epoch: 5 step: 1253, loss is 0.048331256955862045\n",
      "epoch: 5 step: 1254, loss is 0.0012027790071442723\n",
      "epoch: 5 step: 1255, loss is 0.0029695050325244665\n",
      "epoch: 5 step: 1256, loss is 0.010789837688207626\n",
      "epoch: 5 step: 1257, loss is 0.006914942059665918\n",
      "epoch: 5 step: 1258, loss is 0.04220312833786011\n",
      "epoch: 5 step: 1259, loss is 0.07588086277246475\n",
      "epoch: 5 step: 1260, loss is 0.03603473678231239\n",
      "epoch: 5 step: 1261, loss is 0.008682950399816036\n",
      "epoch: 5 step: 1262, loss is 0.0018793739145621657\n",
      "epoch: 5 step: 1263, loss is 0.0002341466606594622\n",
      "epoch: 5 step: 1264, loss is 0.018273381516337395\n",
      "epoch: 5 step: 1265, loss is 0.009539433754980564\n",
      "epoch: 5 step: 1266, loss is 0.0009554247371852398\n",
      "epoch: 5 step: 1267, loss is 0.005768742877990007\n",
      "epoch: 5 step: 1268, loss is 0.0018744842382147908\n",
      "epoch: 5 step: 1269, loss is 0.030980834737420082\n",
      "epoch: 5 step: 1270, loss is 0.00026806246023625135\n",
      "epoch: 5 step: 1271, loss is 0.001065054559148848\n",
      "epoch: 5 step: 1272, loss is 0.00023480490199290216\n",
      "epoch: 5 step: 1273, loss is 0.025930384173989296\n",
      "epoch: 5 step: 1274, loss is 0.011718213558197021\n",
      "epoch: 5 step: 1275, loss is 0.022438261657953262\n",
      "epoch: 5 step: 1276, loss is 0.016811255365610123\n",
      "epoch: 5 step: 1277, loss is 0.0003086309880018234\n",
      "epoch: 5 step: 1278, loss is 0.0028320339042693377\n",
      "epoch: 5 step: 1279, loss is 0.0038350278045982122\n",
      "epoch: 5 step: 1280, loss is 0.0024772114120423794\n",
      "epoch: 5 step: 1281, loss is 0.0018176266457885504\n",
      "epoch: 5 step: 1282, loss is 0.005104422569274902\n",
      "epoch: 5 step: 1283, loss is 0.0007827068911865354\n",
      "epoch: 5 step: 1284, loss is 0.0062818266451358795\n",
      "epoch: 5 step: 1285, loss is 0.0035089494194835424\n",
      "epoch: 5 step: 1286, loss is 0.09413569420576096\n",
      "epoch: 5 step: 1287, loss is 0.024639811366796494\n",
      "epoch: 5 step: 1288, loss is 0.001882862881757319\n",
      "epoch: 5 step: 1289, loss is 0.004374833777546883\n",
      "epoch: 5 step: 1290, loss is 0.02100425958633423\n",
      "epoch: 5 step: 1291, loss is 0.007821918465197086\n",
      "epoch: 5 step: 1292, loss is 0.006238178815692663\n",
      "epoch: 5 step: 1293, loss is 0.0008868231670930982\n",
      "epoch: 5 step: 1294, loss is 0.0003716377541422844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1295, loss is 0.17782185971736908\n",
      "epoch: 5 step: 1296, loss is 0.0009101345203816891\n",
      "epoch: 5 step: 1297, loss is 0.014567707665264606\n",
      "epoch: 5 step: 1298, loss is 0.1423357129096985\n",
      "epoch: 5 step: 1299, loss is 0.004428433254361153\n",
      "epoch: 5 step: 1300, loss is 0.007268777582794428\n",
      "epoch: 5 step: 1301, loss is 0.0015844627050682902\n",
      "epoch: 5 step: 1302, loss is 0.007519405335187912\n",
      "epoch: 5 step: 1303, loss is 0.0912262573838234\n",
      "epoch: 5 step: 1304, loss is 0.001809559646062553\n",
      "epoch: 5 step: 1305, loss is 0.1455124467611313\n",
      "epoch: 5 step: 1306, loss is 0.014993703924119473\n",
      "epoch: 5 step: 1307, loss is 0.0014087293529883027\n",
      "epoch: 5 step: 1308, loss is 0.01257992535829544\n",
      "epoch: 5 step: 1309, loss is 0.002121817087754607\n",
      "epoch: 5 step: 1310, loss is 0.14271022379398346\n",
      "epoch: 5 step: 1311, loss is 0.0002825928386300802\n",
      "epoch: 5 step: 1312, loss is 0.001583049655891955\n",
      "epoch: 5 step: 1313, loss is 0.0015480020083487034\n",
      "epoch: 5 step: 1314, loss is 0.0013151810271665454\n",
      "epoch: 5 step: 1315, loss is 0.12223875522613525\n",
      "epoch: 5 step: 1316, loss is 0.01984187215566635\n",
      "epoch: 5 step: 1317, loss is 0.005515698809176683\n",
      "epoch: 5 step: 1318, loss is 0.03407806158065796\n",
      "epoch: 5 step: 1319, loss is 0.003223241539672017\n",
      "epoch: 5 step: 1320, loss is 0.030303509905934334\n",
      "epoch: 5 step: 1321, loss is 0.0028765443712472916\n",
      "epoch: 5 step: 1322, loss is 0.025628890842199326\n",
      "epoch: 5 step: 1323, loss is 0.0014691534452140331\n",
      "epoch: 5 step: 1324, loss is 0.0027889704797416925\n",
      "epoch: 5 step: 1325, loss is 0.05203897878527641\n",
      "epoch: 5 step: 1326, loss is 0.01726640574634075\n",
      "epoch: 5 step: 1327, loss is 0.0055924272164702415\n",
      "epoch: 5 step: 1328, loss is 0.0928163230419159\n",
      "epoch: 5 step: 1329, loss is 0.16139058768749237\n",
      "epoch: 5 step: 1330, loss is 0.11772078275680542\n",
      "epoch: 5 step: 1331, loss is 0.001642538351006806\n",
      "epoch: 5 step: 1332, loss is 0.06089121848344803\n",
      "epoch: 5 step: 1333, loss is 0.03818097710609436\n",
      "epoch: 5 step: 1334, loss is 0.004883323330432177\n",
      "epoch: 5 step: 1335, loss is 0.058121830224990845\n",
      "epoch: 5 step: 1336, loss is 0.04297224059700966\n",
      "epoch: 5 step: 1337, loss is 0.0629444569349289\n",
      "epoch: 5 step: 1338, loss is 0.024792632088065147\n",
      "epoch: 5 step: 1339, loss is 0.06945541501045227\n",
      "epoch: 5 step: 1340, loss is 0.02502218820154667\n",
      "epoch: 5 step: 1341, loss is 0.00038260099245235324\n",
      "epoch: 5 step: 1342, loss is 0.003992707002907991\n",
      "epoch: 5 step: 1343, loss is 0.0015707440907135606\n",
      "epoch: 5 step: 1344, loss is 0.002180740237236023\n",
      "epoch: 5 step: 1345, loss is 0.006030157208442688\n",
      "epoch: 5 step: 1346, loss is 0.0006687360582873225\n",
      "epoch: 5 step: 1347, loss is 0.025250358507037163\n",
      "epoch: 5 step: 1348, loss is 0.009344669990241528\n",
      "epoch: 5 step: 1349, loss is 0.001402936759404838\n",
      "epoch: 5 step: 1350, loss is 0.03297783061861992\n",
      "epoch: 5 step: 1351, loss is 0.007047874387353659\n",
      "epoch: 5 step: 1352, loss is 0.04864543676376343\n",
      "epoch: 5 step: 1353, loss is 0.06039756163954735\n",
      "epoch: 5 step: 1354, loss is 0.0017818417400121689\n",
      "epoch: 5 step: 1355, loss is 0.0006651379517279565\n",
      "epoch: 5 step: 1356, loss is 0.006734036840498447\n",
      "epoch: 5 step: 1357, loss is 0.0007222346030175686\n",
      "epoch: 5 step: 1358, loss is 0.12100669741630554\n",
      "epoch: 5 step: 1359, loss is 0.0055226897820830345\n",
      "epoch: 5 step: 1360, loss is 0.009366360493004322\n",
      "epoch: 5 step: 1361, loss is 0.0066556441597640514\n",
      "epoch: 5 step: 1362, loss is 0.0010966164991259575\n",
      "epoch: 5 step: 1363, loss is 0.004365449771285057\n",
      "epoch: 5 step: 1364, loss is 0.001946170930750668\n",
      "epoch: 5 step: 1365, loss is 0.048047538846731186\n",
      "epoch: 5 step: 1366, loss is 0.08474467694759369\n",
      "epoch: 5 step: 1367, loss is 0.001448643859475851\n",
      "epoch: 5 step: 1368, loss is 0.03357832878828049\n",
      "epoch: 5 step: 1369, loss is 0.07264640182256699\n",
      "epoch: 5 step: 1370, loss is 0.21081982553005219\n",
      "epoch: 5 step: 1371, loss is 0.01577386073768139\n",
      "epoch: 5 step: 1372, loss is 0.009033598937094212\n",
      "epoch: 5 step: 1373, loss is 0.004044446628540754\n",
      "epoch: 5 step: 1374, loss is 0.0015392806380987167\n",
      "epoch: 5 step: 1375, loss is 0.05160561949014664\n",
      "epoch: 5 step: 1376, loss is 0.0003721021639648825\n",
      "epoch: 5 step: 1377, loss is 0.0012692800955846906\n",
      "epoch: 5 step: 1378, loss is 0.0013075456954538822\n",
      "epoch: 5 step: 1379, loss is 0.048038385808467865\n",
      "epoch: 5 step: 1380, loss is 0.0013701838906854391\n",
      "epoch: 5 step: 1381, loss is 0.0003316504298709333\n",
      "epoch: 5 step: 1382, loss is 0.0005126509931869805\n",
      "epoch: 5 step: 1383, loss is 0.0009677800117060542\n",
      "epoch: 5 step: 1384, loss is 0.052002716809511185\n",
      "epoch: 5 step: 1385, loss is 0.0005640363087877631\n",
      "epoch: 5 step: 1386, loss is 0.007275843992829323\n",
      "epoch: 5 step: 1387, loss is 0.002887156791985035\n",
      "epoch: 5 step: 1388, loss is 0.028047943487763405\n",
      "epoch: 5 step: 1389, loss is 0.17364071309566498\n",
      "epoch: 5 step: 1390, loss is 0.0013038930483162403\n",
      "epoch: 5 step: 1391, loss is 0.003609608393162489\n",
      "epoch: 5 step: 1392, loss is 0.02385842055082321\n",
      "epoch: 5 step: 1393, loss is 0.01778324320912361\n",
      "epoch: 5 step: 1394, loss is 0.06913264095783234\n",
      "epoch: 5 step: 1395, loss is 0.0004170627216808498\n",
      "epoch: 5 step: 1396, loss is 0.02523588202893734\n",
      "epoch: 5 step: 1397, loss is 0.04670078679919243\n",
      "epoch: 5 step: 1398, loss is 0.001156515907496214\n",
      "epoch: 5 step: 1399, loss is 0.01722932606935501\n",
      "epoch: 5 step: 1400, loss is 0.0024467657785862684\n",
      "epoch: 5 step: 1401, loss is 0.0001380784233333543\n",
      "epoch: 5 step: 1402, loss is 0.0011730013648048043\n",
      "epoch: 5 step: 1403, loss is 0.0007981384987942874\n",
      "epoch: 5 step: 1404, loss is 0.07804694026708603\n",
      "epoch: 5 step: 1405, loss is 0.008582115173339844\n",
      "epoch: 5 step: 1406, loss is 0.008954038843512535\n",
      "epoch: 5 step: 1407, loss is 0.0015117402654141188\n",
      "epoch: 5 step: 1408, loss is 0.02061058208346367\n",
      "epoch: 5 step: 1409, loss is 0.003746981965377927\n",
      "epoch: 5 step: 1410, loss is 0.006670978851616383\n",
      "epoch: 5 step: 1411, loss is 7.027115498203784e-05\n",
      "epoch: 5 step: 1412, loss is 0.049571529030799866\n",
      "epoch: 5 step: 1413, loss is 0.004487581551074982\n",
      "epoch: 5 step: 1414, loss is 0.008554881438612938\n",
      "epoch: 5 step: 1415, loss is 0.00029222184093669057\n",
      "epoch: 5 step: 1416, loss is 0.0033830490428954363\n",
      "epoch: 5 step: 1417, loss is 0.00042613493860699236\n",
      "epoch: 5 step: 1418, loss is 0.0013450351543724537\n",
      "epoch: 5 step: 1419, loss is 0.050135958939790726\n",
      "epoch: 5 step: 1420, loss is 0.12390676885843277\n",
      "epoch: 5 step: 1421, loss is 0.020798156037926674\n",
      "epoch: 5 step: 1422, loss is 0.00047325919149443507\n",
      "epoch: 5 step: 1423, loss is 0.010337524116039276\n",
      "epoch: 5 step: 1424, loss is 0.0005126711330376565\n",
      "epoch: 5 step: 1425, loss is 0.05359319597482681\n",
      "epoch: 5 step: 1426, loss is 0.029368333518505096\n",
      "epoch: 5 step: 1427, loss is 5.5869142670417204e-05\n",
      "epoch: 5 step: 1428, loss is 0.01986098103225231\n",
      "epoch: 5 step: 1429, loss is 0.00687452545389533\n",
      "epoch: 5 step: 1430, loss is 0.020798370242118835\n",
      "epoch: 5 step: 1431, loss is 0.005476388148963451\n",
      "epoch: 5 step: 1432, loss is 0.0016635190695524216\n",
      "epoch: 5 step: 1433, loss is 0.002817583968862891\n",
      "epoch: 5 step: 1434, loss is 0.00025856721913442016\n",
      "epoch: 5 step: 1435, loss is 0.017198771238327026\n",
      "epoch: 5 step: 1436, loss is 0.03167487308382988\n",
      "epoch: 5 step: 1437, loss is 0.0011022711405530572\n",
      "epoch: 5 step: 1438, loss is 0.054831042885780334\n",
      "epoch: 5 step: 1439, loss is 0.47169622778892517\n",
      "epoch: 5 step: 1440, loss is 0.10077057778835297\n",
      "epoch: 5 step: 1441, loss is 0.011796791106462479\n",
      "epoch: 5 step: 1442, loss is 0.0016866637161001563\n",
      "epoch: 5 step: 1443, loss is 0.0037605115212500095\n",
      "epoch: 5 step: 1444, loss is 0.0010098916245624423\n",
      "epoch: 5 step: 1445, loss is 0.00011296921729808673\n",
      "epoch: 5 step: 1446, loss is 0.006421281490474939\n",
      "epoch: 5 step: 1447, loss is 0.002132222056388855\n",
      "epoch: 5 step: 1448, loss is 0.0035724537447094917\n",
      "epoch: 5 step: 1449, loss is 0.002369100693613291\n",
      "epoch: 5 step: 1450, loss is 0.000900299521163106\n",
      "epoch: 5 step: 1451, loss is 0.009326854720711708\n",
      "epoch: 5 step: 1452, loss is 0.001759182894602418\n",
      "epoch: 5 step: 1453, loss is 0.0012938524596393108\n",
      "epoch: 5 step: 1454, loss is 0.0003009568608831614\n",
      "epoch: 5 step: 1455, loss is 0.014299381524324417\n",
      "epoch: 5 step: 1456, loss is 0.0025084984954446554\n",
      "epoch: 5 step: 1457, loss is 0.1629561483860016\n",
      "epoch: 5 step: 1458, loss is 0.00018272495071869344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1459, loss is 0.0003597321338020265\n",
      "epoch: 5 step: 1460, loss is 0.000503318733535707\n",
      "epoch: 5 step: 1461, loss is 0.018527748063206673\n",
      "epoch: 5 step: 1462, loss is 0.0017686511855572462\n",
      "epoch: 5 step: 1463, loss is 0.0015715686604380608\n",
      "epoch: 5 step: 1464, loss is 0.007002883590757847\n",
      "epoch: 5 step: 1465, loss is 0.002491627587005496\n",
      "epoch: 5 step: 1466, loss is 0.004138563293963671\n",
      "epoch: 5 step: 1467, loss is 0.0010866201482713223\n",
      "epoch: 5 step: 1468, loss is 0.010404440574347973\n",
      "epoch: 5 step: 1469, loss is 0.002260687993839383\n",
      "epoch: 5 step: 1470, loss is 0.009097271598875523\n",
      "epoch: 5 step: 1471, loss is 0.00764757115393877\n",
      "epoch: 5 step: 1472, loss is 0.050598375499248505\n",
      "epoch: 5 step: 1473, loss is 0.005589278880506754\n",
      "epoch: 5 step: 1474, loss is 0.005642914213240147\n",
      "epoch: 5 step: 1475, loss is 0.0004141156969126314\n",
      "epoch: 5 step: 1476, loss is 0.0069177476689219475\n",
      "epoch: 5 step: 1477, loss is 0.01301478873938322\n",
      "epoch: 5 step: 1478, loss is 0.00048447406152263284\n",
      "epoch: 5 step: 1479, loss is 0.009169490076601505\n",
      "epoch: 5 step: 1480, loss is 0.00198442698456347\n",
      "epoch: 5 step: 1481, loss is 0.013165311887860298\n",
      "epoch: 5 step: 1482, loss is 0.0170099139213562\n",
      "epoch: 5 step: 1483, loss is 0.0001719461433822289\n",
      "epoch: 5 step: 1484, loss is 0.01056425366550684\n",
      "epoch: 5 step: 1485, loss is 0.15461024641990662\n",
      "epoch: 5 step: 1486, loss is 0.0019775365944951773\n",
      "epoch: 5 step: 1487, loss is 0.03540399298071861\n",
      "epoch: 5 step: 1488, loss is 0.007772708777338266\n",
      "epoch: 5 step: 1489, loss is 0.0012147375382483006\n",
      "epoch: 5 step: 1490, loss is 0.009233160875737667\n",
      "epoch: 5 step: 1491, loss is 0.10536102950572968\n",
      "epoch: 5 step: 1492, loss is 0.002163248835131526\n",
      "epoch: 5 step: 1493, loss is 0.00961272232234478\n",
      "epoch: 5 step: 1494, loss is 0.010849284008145332\n",
      "epoch: 5 step: 1495, loss is 0.055326469242572784\n",
      "epoch: 5 step: 1496, loss is 0.008768952451646328\n",
      "epoch: 5 step: 1497, loss is 0.008015120401978493\n",
      "epoch: 5 step: 1498, loss is 0.05635330453515053\n",
      "epoch: 5 step: 1499, loss is 0.022368475794792175\n",
      "epoch: 5 step: 1500, loss is 0.00020823071827180684\n",
      "epoch: 5 step: 1501, loss is 0.3793887794017792\n",
      "epoch: 5 step: 1502, loss is 0.1147596538066864\n",
      "epoch: 5 step: 1503, loss is 0.048422183841466904\n",
      "epoch: 5 step: 1504, loss is 0.004725578241050243\n",
      "epoch: 5 step: 1505, loss is 0.005126583855599165\n",
      "epoch: 5 step: 1506, loss is 0.004744574427604675\n",
      "epoch: 5 step: 1507, loss is 0.0007525002583861351\n",
      "epoch: 5 step: 1508, loss is 0.04733350872993469\n",
      "epoch: 5 step: 1509, loss is 0.0807880312204361\n",
      "epoch: 5 step: 1510, loss is 0.3482436239719391\n",
      "epoch: 5 step: 1511, loss is 0.01760365627706051\n",
      "epoch: 5 step: 1512, loss is 0.012736759148538113\n",
      "epoch: 5 step: 1513, loss is 0.01625262014567852\n",
      "epoch: 5 step: 1514, loss is 0.007339897565543652\n",
      "epoch: 5 step: 1515, loss is 0.01813163235783577\n",
      "epoch: 5 step: 1516, loss is 0.022375168278813362\n",
      "epoch: 5 step: 1517, loss is 0.002201144816353917\n",
      "epoch: 5 step: 1518, loss is 0.09807776659727097\n",
      "epoch: 5 step: 1519, loss is 0.03862190619111061\n",
      "epoch: 5 step: 1520, loss is 0.007410313934087753\n",
      "epoch: 5 step: 1521, loss is 0.010678812861442566\n",
      "epoch: 5 step: 1522, loss is 0.001973300939425826\n",
      "epoch: 5 step: 1523, loss is 0.0015191049315035343\n",
      "epoch: 5 step: 1524, loss is 0.005785438232123852\n",
      "epoch: 5 step: 1525, loss is 0.11621443927288055\n",
      "epoch: 5 step: 1526, loss is 0.001762803178280592\n",
      "epoch: 5 step: 1527, loss is 0.000542447145562619\n",
      "epoch: 5 step: 1528, loss is 0.10278687626123428\n",
      "epoch: 5 step: 1529, loss is 0.0020347856916487217\n",
      "epoch: 5 step: 1530, loss is 0.008017197251319885\n",
      "epoch: 5 step: 1531, loss is 0.0017267117509618402\n",
      "epoch: 5 step: 1532, loss is 0.14306791126728058\n",
      "epoch: 5 step: 1533, loss is 0.003932524006813765\n",
      "epoch: 5 step: 1534, loss is 0.0002917925303336233\n",
      "epoch: 5 step: 1535, loss is 0.0036296595353633165\n",
      "epoch: 5 step: 1536, loss is 0.033970415592193604\n",
      "epoch: 5 step: 1537, loss is 0.12164995074272156\n",
      "epoch: 5 step: 1538, loss is 0.04569508135318756\n",
      "epoch: 5 step: 1539, loss is 0.006872950587421656\n",
      "epoch: 5 step: 1540, loss is 0.0014843095559626818\n",
      "epoch: 5 step: 1541, loss is 0.09674036502838135\n",
      "epoch: 5 step: 1542, loss is 0.00025427472428418696\n",
      "epoch: 5 step: 1543, loss is 0.0026104580610990524\n",
      "epoch: 5 step: 1544, loss is 0.005313183180987835\n",
      "epoch: 5 step: 1545, loss is 0.0010004985379055142\n",
      "epoch: 5 step: 1546, loss is 0.0010001291520893574\n",
      "epoch: 5 step: 1547, loss is 0.04351423680782318\n",
      "epoch: 5 step: 1548, loss is 0.0014004780678078532\n",
      "epoch: 5 step: 1549, loss is 0.0888846293091774\n",
      "epoch: 5 step: 1550, loss is 0.005210306495428085\n",
      "epoch: 5 step: 1551, loss is 0.0015107083600014448\n",
      "epoch: 5 step: 1552, loss is 0.004971204325556755\n",
      "epoch: 5 step: 1553, loss is 0.010707237757742405\n",
      "epoch: 5 step: 1554, loss is 0.005177867133170366\n",
      "epoch: 5 step: 1555, loss is 0.0013095531612634659\n",
      "epoch: 5 step: 1556, loss is 0.0005047983722761273\n",
      "epoch: 5 step: 1557, loss is 0.0019360230071470141\n",
      "epoch: 5 step: 1558, loss is 0.09822747856378555\n",
      "epoch: 5 step: 1559, loss is 0.004918874707072973\n",
      "epoch: 5 step: 1560, loss is 0.006745296996086836\n",
      "epoch: 5 step: 1561, loss is 0.07585851103067398\n",
      "epoch: 5 step: 1562, loss is 0.23246268928050995\n",
      "epoch: 5 step: 1563, loss is 0.06914399564266205\n",
      "epoch: 5 step: 1564, loss is 0.09715816378593445\n",
      "epoch: 5 step: 1565, loss is 0.013024451211094856\n",
      "epoch: 5 step: 1566, loss is 0.0010340665467083454\n",
      "epoch: 5 step: 1567, loss is 0.058602482080459595\n",
      "epoch: 5 step: 1568, loss is 0.0011361310025677085\n",
      "epoch: 5 step: 1569, loss is 0.009588601067662239\n",
      "epoch: 5 step: 1570, loss is 0.0006766305305063725\n",
      "epoch: 5 step: 1571, loss is 0.0055917054414749146\n",
      "epoch: 5 step: 1572, loss is 0.011347826570272446\n",
      "epoch: 5 step: 1573, loss is 0.03836251422762871\n",
      "epoch: 5 step: 1574, loss is 0.004844237118959427\n",
      "epoch: 5 step: 1575, loss is 0.03129534050822258\n",
      "epoch: 5 step: 1576, loss is 0.013293415307998657\n",
      "epoch: 5 step: 1577, loss is 0.01340038888156414\n",
      "epoch: 5 step: 1578, loss is 0.015926597639918327\n",
      "epoch: 5 step: 1579, loss is 0.0038632317446172237\n",
      "epoch: 5 step: 1580, loss is 0.006306907162070274\n",
      "epoch: 5 step: 1581, loss is 0.009392957203090191\n",
      "epoch: 5 step: 1582, loss is 0.005583222955465317\n",
      "epoch: 5 step: 1583, loss is 0.015176122076809406\n",
      "epoch: 5 step: 1584, loss is 0.11112271994352341\n",
      "epoch: 5 step: 1585, loss is 0.06206716597080231\n",
      "epoch: 5 step: 1586, loss is 0.046052660793066025\n",
      "epoch: 5 step: 1587, loss is 0.011929118074476719\n",
      "epoch: 5 step: 1588, loss is 0.04776142165064812\n",
      "epoch: 5 step: 1589, loss is 0.039318960160017014\n",
      "epoch: 5 step: 1590, loss is 0.005823074374347925\n",
      "epoch: 5 step: 1591, loss is 0.050447553396224976\n",
      "epoch: 5 step: 1592, loss is 0.0016792098758742213\n",
      "epoch: 5 step: 1593, loss is 0.022318057715892792\n",
      "epoch: 5 step: 1594, loss is 0.001197600970044732\n",
      "epoch: 5 step: 1595, loss is 0.04234131798148155\n",
      "epoch: 5 step: 1596, loss is 0.004366610199213028\n",
      "epoch: 5 step: 1597, loss is 0.012678009457886219\n",
      "epoch: 5 step: 1598, loss is 0.000788866775110364\n",
      "epoch: 5 step: 1599, loss is 0.0003824492741841823\n",
      "epoch: 5 step: 1600, loss is 0.0014377316692844033\n",
      "epoch: 5 step: 1601, loss is 0.00018060996080748737\n",
      "epoch: 5 step: 1602, loss is 0.004335584118962288\n",
      "epoch: 5 step: 1603, loss is 0.004242138005793095\n",
      "epoch: 5 step: 1604, loss is 0.026020823046565056\n",
      "epoch: 5 step: 1605, loss is 0.01953316107392311\n",
      "epoch: 5 step: 1606, loss is 0.01457213331013918\n",
      "epoch: 5 step: 1607, loss is 0.0005266243242658675\n",
      "epoch: 5 step: 1608, loss is 0.004702987615019083\n",
      "epoch: 5 step: 1609, loss is 0.0009062328026629984\n",
      "epoch: 5 step: 1610, loss is 0.07615268975496292\n",
      "epoch: 5 step: 1611, loss is 0.005196437705308199\n",
      "epoch: 5 step: 1612, loss is 0.0045816246420145035\n",
      "epoch: 5 step: 1613, loss is 0.009146766737103462\n",
      "epoch: 5 step: 1614, loss is 0.011267455294728279\n",
      "epoch: 5 step: 1615, loss is 0.004615736659616232\n",
      "epoch: 5 step: 1616, loss is 0.0028811837546527386\n",
      "epoch: 5 step: 1617, loss is 0.007468526251614094\n",
      "epoch: 5 step: 1618, loss is 0.01698235236108303\n",
      "epoch: 5 step: 1619, loss is 0.1129387840628624\n",
      "epoch: 5 step: 1620, loss is 0.006312198005616665\n",
      "epoch: 5 step: 1621, loss is 0.028119532391428947\n",
      "epoch: 5 step: 1622, loss is 0.011864017695188522\n",
      "epoch: 5 step: 1623, loss is 0.0008519543334841728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1624, loss is 0.001102850423194468\n",
      "epoch: 5 step: 1625, loss is 0.0014606480253860354\n",
      "epoch: 5 step: 1626, loss is 0.025001658126711845\n",
      "epoch: 5 step: 1627, loss is 0.0041527473367750645\n",
      "epoch: 5 step: 1628, loss is 0.007586844731122255\n",
      "epoch: 5 step: 1629, loss is 0.000243142043473199\n",
      "epoch: 5 step: 1630, loss is 0.20673136413097382\n",
      "epoch: 5 step: 1631, loss is 0.0303166713565588\n",
      "epoch: 5 step: 1632, loss is 0.026748953387141228\n",
      "epoch: 5 step: 1633, loss is 0.10790412127971649\n",
      "epoch: 5 step: 1634, loss is 0.003286293474957347\n",
      "epoch: 5 step: 1635, loss is 0.012573492713272572\n",
      "epoch: 5 step: 1636, loss is 0.004977676551789045\n",
      "epoch: 5 step: 1637, loss is 0.0647391825914383\n",
      "epoch: 5 step: 1638, loss is 0.009296519681811333\n",
      "epoch: 5 step: 1639, loss is 0.000753256375901401\n",
      "epoch: 5 step: 1640, loss is 0.01296274084597826\n",
      "epoch: 5 step: 1641, loss is 0.02250721864402294\n",
      "epoch: 5 step: 1642, loss is 0.006693108007311821\n",
      "epoch: 5 step: 1643, loss is 0.029026539996266365\n",
      "epoch: 5 step: 1644, loss is 0.0010196918155997992\n",
      "epoch: 5 step: 1645, loss is 0.0047502461820840836\n",
      "epoch: 5 step: 1646, loss is 0.0019138514762744308\n",
      "epoch: 5 step: 1647, loss is 0.0005485084839165211\n",
      "epoch: 5 step: 1648, loss is 0.0014379537897184491\n",
      "epoch: 5 step: 1649, loss is 0.0008071118500083685\n",
      "epoch: 5 step: 1650, loss is 0.02159755490720272\n",
      "epoch: 5 step: 1651, loss is 0.00030388872255571187\n",
      "epoch: 5 step: 1652, loss is 0.0005812991294078529\n",
      "epoch: 5 step: 1653, loss is 0.0003488126676529646\n",
      "epoch: 5 step: 1654, loss is 0.0006093619158491492\n",
      "epoch: 5 step: 1655, loss is 0.050796907395124435\n",
      "epoch: 5 step: 1656, loss is 0.004698192700743675\n",
      "epoch: 5 step: 1657, loss is 0.07926206290721893\n",
      "epoch: 5 step: 1658, loss is 0.0160097386687994\n",
      "epoch: 5 step: 1659, loss is 0.00015452879597432911\n",
      "epoch: 5 step: 1660, loss is 0.0018452012445777655\n",
      "epoch: 5 step: 1661, loss is 0.0030641965568065643\n",
      "epoch: 5 step: 1662, loss is 0.001065072137862444\n",
      "epoch: 5 step: 1663, loss is 0.09405353665351868\n",
      "epoch: 5 step: 1664, loss is 0.1155056580901146\n",
      "epoch: 5 step: 1665, loss is 0.005807580891996622\n",
      "epoch: 5 step: 1666, loss is 0.002537599764764309\n",
      "epoch: 5 step: 1667, loss is 0.0002931820636149496\n",
      "epoch: 5 step: 1668, loss is 0.027126837521791458\n",
      "epoch: 5 step: 1669, loss is 0.0018595934379845858\n",
      "epoch: 5 step: 1670, loss is 0.01578672230243683\n",
      "epoch: 5 step: 1671, loss is 0.00021821628615725785\n",
      "epoch: 5 step: 1672, loss is 0.009048886597156525\n",
      "epoch: 5 step: 1673, loss is 0.0013019938487559557\n",
      "epoch: 5 step: 1674, loss is 0.03822404891252518\n",
      "epoch: 5 step: 1675, loss is 0.12110783159732819\n",
      "epoch: 5 step: 1676, loss is 0.003126445459201932\n",
      "epoch: 5 step: 1677, loss is 0.0012799660908058286\n",
      "epoch: 5 step: 1678, loss is 0.00925371516495943\n",
      "epoch: 5 step: 1679, loss is 0.02964882180094719\n",
      "epoch: 5 step: 1680, loss is 0.002178013324737549\n",
      "epoch: 5 step: 1681, loss is 0.0014162700390443206\n",
      "epoch: 5 step: 1682, loss is 0.46496647596359253\n",
      "epoch: 5 step: 1683, loss is 0.06206522136926651\n",
      "epoch: 5 step: 1684, loss is 0.022818317636847496\n",
      "epoch: 5 step: 1685, loss is 0.002789916004985571\n",
      "epoch: 5 step: 1686, loss is 0.0006463705212809145\n",
      "epoch: 5 step: 1687, loss is 0.004576072562485933\n",
      "epoch: 5 step: 1688, loss is 0.0016514582093805075\n",
      "epoch: 5 step: 1689, loss is 0.010934463702142239\n",
      "epoch: 5 step: 1690, loss is 0.0015040879370644689\n",
      "epoch: 5 step: 1691, loss is 0.0006499264272861183\n",
      "epoch: 5 step: 1692, loss is 0.050382573157548904\n",
      "epoch: 5 step: 1693, loss is 0.03333456069231033\n",
      "epoch: 5 step: 1694, loss is 0.0319492481648922\n",
      "epoch: 5 step: 1695, loss is 0.002742783399298787\n",
      "epoch: 5 step: 1696, loss is 0.04215674102306366\n",
      "epoch: 5 step: 1697, loss is 0.022744929417967796\n",
      "epoch: 5 step: 1698, loss is 0.002149689942598343\n",
      "epoch: 5 step: 1699, loss is 0.003599615301936865\n",
      "epoch: 5 step: 1700, loss is 0.0016671176999807358\n",
      "epoch: 5 step: 1701, loss is 0.00024187573581002653\n",
      "epoch: 5 step: 1702, loss is 0.007054449990391731\n",
      "epoch: 5 step: 1703, loss is 0.05355047062039375\n",
      "epoch: 5 step: 1704, loss is 0.04576447233557701\n",
      "epoch: 5 step: 1705, loss is 0.0012570968829095364\n",
      "epoch: 5 step: 1706, loss is 0.124799445271492\n",
      "epoch: 5 step: 1707, loss is 0.00016238178068306297\n",
      "epoch: 5 step: 1708, loss is 0.000330232986016199\n",
      "epoch: 5 step: 1709, loss is 0.004341950640082359\n",
      "epoch: 5 step: 1710, loss is 0.0005656119901686907\n",
      "epoch: 5 step: 1711, loss is 0.10051348805427551\n",
      "epoch: 5 step: 1712, loss is 0.00013498768385034055\n",
      "epoch: 5 step: 1713, loss is 0.015295117162168026\n",
      "epoch: 5 step: 1714, loss is 0.0058859712444245815\n",
      "epoch: 5 step: 1715, loss is 0.07504913210868835\n",
      "epoch: 5 step: 1716, loss is 0.004881117958575487\n",
      "epoch: 5 step: 1717, loss is 0.004070490598678589\n",
      "epoch: 5 step: 1718, loss is 0.0019541350193321705\n",
      "epoch: 5 step: 1719, loss is 0.012366287410259247\n",
      "epoch: 5 step: 1720, loss is 0.0010426630033180118\n",
      "epoch: 5 step: 1721, loss is 0.003594247857108712\n",
      "epoch: 5 step: 1722, loss is 0.0001668764161877334\n",
      "epoch: 5 step: 1723, loss is 0.0036133790854364634\n",
      "epoch: 5 step: 1724, loss is 0.014237687923014164\n",
      "epoch: 5 step: 1725, loss is 0.10461145639419556\n",
      "epoch: 5 step: 1726, loss is 0.004040178842842579\n",
      "epoch: 5 step: 1727, loss is 0.0012899970170110464\n",
      "epoch: 5 step: 1728, loss is 0.027608297765254974\n",
      "epoch: 5 step: 1729, loss is 0.0195565577596426\n",
      "epoch: 5 step: 1730, loss is 0.016185808926820755\n",
      "epoch: 5 step: 1731, loss is 0.0011550522176548839\n",
      "epoch: 5 step: 1732, loss is 0.00013468280667439103\n",
      "epoch: 5 step: 1733, loss is 0.019122058525681496\n",
      "epoch: 5 step: 1734, loss is 0.0010354039259254932\n",
      "epoch: 5 step: 1735, loss is 0.006160188931971788\n",
      "epoch: 5 step: 1736, loss is 0.06330792605876923\n",
      "epoch: 5 step: 1737, loss is 0.014233788475394249\n",
      "epoch: 5 step: 1738, loss is 0.0024804938584566116\n",
      "epoch: 5 step: 1739, loss is 0.004286691080778837\n",
      "epoch: 5 step: 1740, loss is 0.17855757474899292\n",
      "epoch: 5 step: 1741, loss is 0.00716329226270318\n",
      "epoch: 5 step: 1742, loss is 0.0019840889144688845\n",
      "epoch: 5 step: 1743, loss is 0.0047938404604792595\n",
      "epoch: 5 step: 1744, loss is 0.0010601236717775464\n",
      "epoch: 5 step: 1745, loss is 0.0007165367132984102\n",
      "epoch: 5 step: 1746, loss is 0.1122848242521286\n",
      "epoch: 5 step: 1747, loss is 0.0015902809100225568\n",
      "epoch: 5 step: 1748, loss is 0.002256407169625163\n",
      "epoch: 5 step: 1749, loss is 0.004247389268130064\n",
      "epoch: 5 step: 1750, loss is 0.04789763689041138\n",
      "epoch: 5 step: 1751, loss is 0.15349003672599792\n",
      "epoch: 5 step: 1752, loss is 0.0003869339998345822\n",
      "epoch: 5 step: 1753, loss is 0.0069280280731618404\n",
      "epoch: 5 step: 1754, loss is 0.016348548233509064\n",
      "epoch: 5 step: 1755, loss is 0.006169192027300596\n",
      "epoch: 5 step: 1756, loss is 0.1306154876947403\n",
      "epoch: 5 step: 1757, loss is 0.031144071370363235\n",
      "epoch: 5 step: 1758, loss is 0.0011370399734005332\n",
      "epoch: 5 step: 1759, loss is 0.07326698303222656\n",
      "epoch: 5 step: 1760, loss is 0.0019297670805826783\n",
      "epoch: 5 step: 1761, loss is 0.1485319882631302\n",
      "epoch: 5 step: 1762, loss is 0.01924179308116436\n",
      "epoch: 5 step: 1763, loss is 0.008226140402257442\n",
      "epoch: 5 step: 1764, loss is 0.07618699967861176\n",
      "epoch: 5 step: 1765, loss is 0.017167747020721436\n",
      "epoch: 5 step: 1766, loss is 0.002658305922523141\n",
      "epoch: 5 step: 1767, loss is 0.01377240102738142\n",
      "epoch: 5 step: 1768, loss is 0.15808992087841034\n",
      "epoch: 5 step: 1769, loss is 0.005274917930364609\n",
      "epoch: 5 step: 1770, loss is 0.00017841866065282375\n",
      "epoch: 5 step: 1771, loss is 0.05323221534490585\n",
      "epoch: 5 step: 1772, loss is 0.00129197898786515\n",
      "epoch: 5 step: 1773, loss is 0.05947982147336006\n",
      "epoch: 5 step: 1774, loss is 0.2082299441099167\n",
      "epoch: 5 step: 1775, loss is 0.003051074920222163\n",
      "epoch: 5 step: 1776, loss is 0.009144668467342854\n",
      "epoch: 5 step: 1777, loss is 0.032651543617248535\n",
      "epoch: 5 step: 1778, loss is 0.002846010960638523\n",
      "epoch: 5 step: 1779, loss is 0.04680214822292328\n",
      "epoch: 5 step: 1780, loss is 0.00043021320016123354\n",
      "epoch: 5 step: 1781, loss is 0.002055293181911111\n",
      "epoch: 5 step: 1782, loss is 0.000926057284232229\n",
      "epoch: 5 step: 1783, loss is 0.04371378570795059\n",
      "epoch: 5 step: 1784, loss is 0.00029167026514187455\n",
      "epoch: 5 step: 1785, loss is 0.0008115164237096906\n",
      "epoch: 5 step: 1786, loss is 0.0006696037598885596\n",
      "epoch: 5 step: 1787, loss is 0.005121162161231041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1788, loss is 0.0013233334757387638\n",
      "epoch: 5 step: 1789, loss is 0.00037246994907036424\n",
      "epoch: 5 step: 1790, loss is 0.0047182347625494\n",
      "epoch: 5 step: 1791, loss is 0.0001614639477338642\n",
      "epoch: 5 step: 1792, loss is 0.050879281014204025\n",
      "epoch: 5 step: 1793, loss is 0.007345279213041067\n",
      "epoch: 5 step: 1794, loss is 0.0008174647809937596\n",
      "epoch: 5 step: 1795, loss is 0.0970975011587143\n",
      "epoch: 5 step: 1796, loss is 0.0013437881134450436\n",
      "epoch: 5 step: 1797, loss is 0.006500488147139549\n",
      "epoch: 5 step: 1798, loss is 0.020495520904660225\n",
      "epoch: 5 step: 1799, loss is 0.012314426712691784\n",
      "epoch: 5 step: 1800, loss is 0.0267312154173851\n",
      "epoch: 5 step: 1801, loss is 0.04066097363829613\n",
      "epoch: 5 step: 1802, loss is 0.02121134288609028\n",
      "epoch: 5 step: 1803, loss is 0.058923959732055664\n",
      "epoch: 5 step: 1804, loss is 0.004369608126580715\n",
      "epoch: 5 step: 1805, loss is 0.0014190251240506768\n",
      "epoch: 5 step: 1806, loss is 0.0013418023008853197\n",
      "epoch: 5 step: 1807, loss is 0.0008022404508665204\n",
      "epoch: 5 step: 1808, loss is 0.002604380715638399\n",
      "epoch: 5 step: 1809, loss is 0.0384371280670166\n",
      "epoch: 5 step: 1810, loss is 0.1531689316034317\n",
      "epoch: 5 step: 1811, loss is 0.0007332180393859744\n",
      "epoch: 5 step: 1812, loss is 0.03234034776687622\n",
      "epoch: 5 step: 1813, loss is 0.0016951579600572586\n",
      "epoch: 5 step: 1814, loss is 0.0032879593782126904\n",
      "epoch: 5 step: 1815, loss is 0.007342244032770395\n",
      "epoch: 5 step: 1816, loss is 0.16330352425575256\n",
      "epoch: 5 step: 1817, loss is 0.04119740054011345\n",
      "epoch: 5 step: 1818, loss is 0.007415012922137976\n",
      "epoch: 5 step: 1819, loss is 0.010996740311384201\n",
      "epoch: 5 step: 1820, loss is 0.03552216291427612\n",
      "epoch: 5 step: 1821, loss is 0.21177250146865845\n",
      "epoch: 5 step: 1822, loss is 0.022935770452022552\n",
      "epoch: 5 step: 1823, loss is 0.0038622207939624786\n",
      "epoch: 5 step: 1824, loss is 0.00037776745739392936\n",
      "epoch: 5 step: 1825, loss is 0.0003704578848555684\n",
      "epoch: 5 step: 1826, loss is 0.006211187690496445\n",
      "epoch: 5 step: 1827, loss is 0.057226795703172684\n",
      "epoch: 5 step: 1828, loss is 0.15167193114757538\n",
      "epoch: 5 step: 1829, loss is 0.0006765032885596156\n",
      "epoch: 5 step: 1830, loss is 0.003721697721630335\n",
      "epoch: 5 step: 1831, loss is 0.0004274211241863668\n",
      "epoch: 5 step: 1832, loss is 0.005623907316476107\n",
      "epoch: 5 step: 1833, loss is 0.010647453367710114\n",
      "epoch: 5 step: 1834, loss is 0.001051587169058621\n",
      "epoch: 5 step: 1835, loss is 0.01215394213795662\n",
      "epoch: 5 step: 1836, loss is 0.00025389291113242507\n",
      "epoch: 5 step: 1837, loss is 0.01972815953195095\n",
      "epoch: 5 step: 1838, loss is 0.006107470486313105\n",
      "epoch: 5 step: 1839, loss is 0.0006616357713937759\n",
      "epoch: 5 step: 1840, loss is 0.0017401145305484533\n",
      "epoch: 5 step: 1841, loss is 0.0894443690776825\n",
      "epoch: 5 step: 1842, loss is 0.024422185495495796\n",
      "epoch: 5 step: 1843, loss is 0.02483947202563286\n",
      "epoch: 5 step: 1844, loss is 0.0032382532954216003\n",
      "epoch: 5 step: 1845, loss is 0.0011029340093955398\n",
      "epoch: 5 step: 1846, loss is 0.02101539447903633\n",
      "epoch: 5 step: 1847, loss is 0.01143411360681057\n",
      "epoch: 5 step: 1848, loss is 0.11068428307771683\n",
      "epoch: 5 step: 1849, loss is 0.005175319965928793\n",
      "epoch: 5 step: 1850, loss is 0.010998984798789024\n",
      "epoch: 5 step: 1851, loss is 0.0015162492636591196\n",
      "epoch: 5 step: 1852, loss is 0.06660263985395432\n",
      "epoch: 5 step: 1853, loss is 0.003610339481383562\n",
      "epoch: 5 step: 1854, loss is 0.012990409508347511\n",
      "epoch: 5 step: 1855, loss is 0.014048325829207897\n",
      "epoch: 5 step: 1856, loss is 0.004458779469132423\n",
      "epoch: 5 step: 1857, loss is 0.0004606075235642493\n",
      "epoch: 5 step: 1858, loss is 0.010761283338069916\n",
      "epoch: 5 step: 1859, loss is 0.011857674457132816\n",
      "epoch: 5 step: 1860, loss is 0.015698973089456558\n",
      "epoch: 5 step: 1861, loss is 0.004631893243640661\n",
      "epoch: 5 step: 1862, loss is 0.00417049927636981\n",
      "epoch: 5 step: 1863, loss is 0.0033884544391185045\n",
      "epoch: 5 step: 1864, loss is 0.10243590176105499\n",
      "epoch: 5 step: 1865, loss is 0.15271702408790588\n",
      "epoch: 5 step: 1866, loss is 0.004340068902820349\n",
      "epoch: 5 step: 1867, loss is 0.0017593097873032093\n",
      "epoch: 5 step: 1868, loss is 0.0006538945599459112\n",
      "epoch: 5 step: 1869, loss is 0.04592146724462509\n",
      "epoch: 5 step: 1870, loss is 0.0030145617201924324\n",
      "epoch: 5 step: 1871, loss is 0.0002668035158421844\n",
      "epoch: 5 step: 1872, loss is 0.00025497161550447345\n",
      "epoch: 5 step: 1873, loss is 0.008058251813054085\n",
      "epoch: 5 step: 1874, loss is 0.00457816943526268\n",
      "epoch: 5 step: 1875, loss is 0.00887314509600401\n",
      "epoch: 5 step: 1876, loss is 0.0013737308327108622\n",
      "epoch: 5 step: 1877, loss is 0.0022990393918007612\n",
      "epoch: 5 step: 1878, loss is 0.007176869083195925\n",
      "epoch: 5 step: 1879, loss is 8.970208000391722e-05\n",
      "epoch: 5 step: 1880, loss is 0.00014152078074403107\n",
      "epoch: 5 step: 1881, loss is 0.00929213222116232\n",
      "epoch: 5 step: 1882, loss is 0.05475357919931412\n",
      "epoch: 5 step: 1883, loss is 0.15531378984451294\n",
      "epoch: 5 step: 1884, loss is 0.05755408853292465\n",
      "epoch: 5 step: 1885, loss is 0.02396772988140583\n",
      "epoch: 5 step: 1886, loss is 0.00778648816049099\n",
      "epoch: 5 step: 1887, loss is 0.00032718380680307746\n",
      "epoch: 5 step: 1888, loss is 0.0013268108014017344\n",
      "epoch: 5 step: 1889, loss is 0.00883956253528595\n",
      "epoch: 5 step: 1890, loss is 0.000816164945717901\n",
      "epoch: 5 step: 1891, loss is 0.0008534732041880488\n",
      "epoch: 5 step: 1892, loss is 0.03582436591386795\n",
      "epoch: 5 step: 1893, loss is 0.19290873408317566\n",
      "epoch: 5 step: 1894, loss is 0.01345293689519167\n",
      "epoch: 5 step: 1895, loss is 0.003405715338885784\n",
      "epoch: 5 step: 1896, loss is 0.0016244057333096862\n",
      "epoch: 5 step: 1897, loss is 0.0004041349748149514\n",
      "epoch: 5 step: 1898, loss is 0.13591666519641876\n",
      "epoch: 5 step: 1899, loss is 0.01806838996708393\n",
      "epoch: 5 step: 1900, loss is 0.008098751306533813\n",
      "epoch: 5 step: 1901, loss is 0.0009790124604478478\n",
      "epoch: 5 step: 1902, loss is 0.013104196637868881\n",
      "epoch: 5 step: 1903, loss is 0.17212966084480286\n",
      "epoch: 5 step: 1904, loss is 0.00029471059679053724\n",
      "epoch: 5 step: 1905, loss is 0.0019964545499533415\n",
      "epoch: 5 step: 1906, loss is 0.004437622148543596\n",
      "epoch: 5 step: 1907, loss is 0.000288307957816869\n",
      "epoch: 5 step: 1908, loss is 0.0006029470241628587\n",
      "epoch: 5 step: 1909, loss is 0.013238462619483471\n",
      "epoch: 5 step: 1910, loss is 0.06418675184249878\n",
      "epoch: 5 step: 1911, loss is 0.003658585250377655\n",
      "epoch: 5 step: 1912, loss is 0.021188130602240562\n",
      "epoch: 5 step: 1913, loss is 0.029746340587735176\n",
      "epoch: 5 step: 1914, loss is 0.0012654300080612302\n",
      "epoch: 5 step: 1915, loss is 0.029176784679293633\n",
      "epoch: 5 step: 1916, loss is 0.019491786137223244\n",
      "epoch: 5 step: 1917, loss is 0.0017976287053897977\n",
      "epoch: 5 step: 1918, loss is 0.0005918641691096127\n",
      "epoch: 5 step: 1919, loss is 0.0040486338548362255\n",
      "epoch: 5 step: 1920, loss is 0.014379397965967655\n",
      "epoch: 5 step: 1921, loss is 0.0007387202349491417\n",
      "epoch: 5 step: 1922, loss is 0.14703573286533356\n",
      "epoch: 5 step: 1923, loss is 0.05213275924324989\n",
      "epoch: 5 step: 1924, loss is 0.18209433555603027\n",
      "epoch: 5 step: 1925, loss is 0.0017856667982414365\n",
      "epoch: 5 step: 1926, loss is 0.0001723817113088444\n",
      "epoch: 5 step: 1927, loss is 0.0008429507142864168\n",
      "epoch: 5 step: 1928, loss is 0.059237800538539886\n",
      "epoch: 5 step: 1929, loss is 0.000839424435980618\n",
      "epoch: 5 step: 1930, loss is 0.003063006093725562\n",
      "epoch: 5 step: 1931, loss is 0.0018840079428628087\n",
      "epoch: 5 step: 1932, loss is 0.013607081957161427\n",
      "epoch: 5 step: 1933, loss is 0.005150892771780491\n",
      "epoch: 5 step: 1934, loss is 0.00709522282704711\n",
      "epoch: 5 step: 1935, loss is 0.0013736006803810596\n",
      "epoch: 5 step: 1936, loss is 0.07415664941072464\n",
      "epoch: 5 step: 1937, loss is 0.000530964694917202\n",
      "epoch: 5 step: 1938, loss is 0.003847848391160369\n",
      "epoch: 5 step: 1939, loss is 0.035557013005018234\n",
      "epoch: 5 step: 1940, loss is 0.0005777558544650674\n",
      "epoch: 5 step: 1941, loss is 0.0010684082517400384\n",
      "epoch: 5 step: 1942, loss is 0.008852214552462101\n",
      "epoch: 5 step: 1943, loss is 0.020643236115574837\n",
      "epoch: 5 step: 1944, loss is 0.06696026027202606\n",
      "epoch: 5 step: 1945, loss is 0.017065079882740974\n",
      "epoch: 5 step: 1946, loss is 0.12564431130886078\n",
      "epoch: 5 step: 1947, loss is 0.00790355820208788\n",
      "epoch: 5 step: 1948, loss is 0.07241091877222061\n",
      "epoch: 5 step: 1949, loss is 0.0034417554270476103\n",
      "epoch: 5 step: 1950, loss is 0.0011406850535422564\n",
      "epoch: 5 step: 1951, loss is 0.0001685483439359814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1952, loss is 0.002268874319270253\n",
      "epoch: 5 step: 1953, loss is 0.010265680029988289\n",
      "epoch: 5 step: 1954, loss is 0.008026211522519588\n",
      "epoch: 5 step: 1955, loss is 0.10559074580669403\n",
      "epoch: 5 step: 1956, loss is 0.011496652849018574\n",
      "epoch: 5 step: 1957, loss is 0.028607888147234917\n",
      "epoch: 5 step: 1958, loss is 0.0008871215977706015\n",
      "epoch: 5 step: 1959, loss is 0.0005940819974057376\n",
      "epoch: 5 step: 1960, loss is 0.0006868904456496239\n",
      "epoch: 5 step: 1961, loss is 0.005151061341166496\n",
      "epoch: 5 step: 1962, loss is 0.0005524783045984805\n",
      "epoch: 5 step: 1963, loss is 0.02766314521431923\n",
      "epoch: 5 step: 1964, loss is 0.0012621904024854302\n",
      "epoch: 5 step: 1965, loss is 0.013595315627753735\n",
      "epoch: 5 step: 1966, loss is 0.000729482329916209\n",
      "epoch: 5 step: 1967, loss is 0.03408239409327507\n",
      "epoch: 5 step: 1968, loss is 0.000212421320611611\n",
      "epoch: 5 step: 1969, loss is 0.03756652772426605\n",
      "epoch: 5 step: 1970, loss is 0.0012457857374101877\n",
      "epoch: 5 step: 1971, loss is 0.0005388186546042562\n",
      "epoch: 5 step: 1972, loss is 0.0005041704280301929\n",
      "epoch: 5 step: 1973, loss is 0.1463487297296524\n",
      "epoch: 5 step: 1974, loss is 0.12496865540742874\n",
      "epoch: 5 step: 1975, loss is 0.13837595283985138\n",
      "epoch: 5 step: 1976, loss is 0.030179521068930626\n",
      "epoch: 5 step: 1977, loss is 0.0015759770758450031\n",
      "epoch: 5 step: 1978, loss is 0.0029851370491087437\n",
      "epoch: 5 step: 1979, loss is 0.0013787145726382732\n",
      "epoch: 5 step: 1980, loss is 0.00035910215228796005\n",
      "epoch: 5 step: 1981, loss is 0.018977079540491104\n",
      "epoch: 5 step: 1982, loss is 0.13447576761245728\n",
      "epoch: 5 step: 1983, loss is 0.05419674888253212\n",
      "epoch: 5 step: 1984, loss is 0.00017509503231849521\n",
      "epoch: 5 step: 1985, loss is 0.09773337095975876\n",
      "epoch: 5 step: 1986, loss is 0.033864594995975494\n",
      "epoch: 5 step: 1987, loss is 0.002454966539517045\n",
      "epoch: 5 step: 1988, loss is 0.008435647003352642\n",
      "epoch: 5 step: 1989, loss is 0.003374973777681589\n",
      "epoch: 5 step: 1990, loss is 0.00017534209473524243\n",
      "epoch: 5 step: 1991, loss is 0.0007990127196535468\n",
      "epoch: 5 step: 1992, loss is 0.0013156543718650937\n",
      "epoch: 5 step: 1993, loss is 0.008996594697237015\n",
      "epoch: 5 step: 1994, loss is 0.03243790194392204\n",
      "epoch: 5 step: 1995, loss is 0.0038437778130173683\n",
      "epoch: 5 step: 1996, loss is 0.000517701671924442\n",
      "epoch: 5 step: 1997, loss is 0.0010015075094997883\n",
      "epoch: 5 step: 1998, loss is 0.000746279489248991\n",
      "epoch: 5 step: 1999, loss is 0.0006664898828603327\n",
      "epoch: 5 step: 2000, loss is 0.027585532516241074\n",
      "epoch: 5 step: 2001, loss is 0.014195955358445644\n",
      "epoch: 5 step: 2002, loss is 0.0037479856982827187\n",
      "epoch: 5 step: 2003, loss is 0.00016656234220135957\n",
      "epoch: 5 step: 2004, loss is 0.05105320364236832\n",
      "epoch: 5 step: 2005, loss is 0.09712538123130798\n",
      "epoch: 5 step: 2006, loss is 0.07618247717618942\n",
      "epoch: 5 step: 2007, loss is 0.0003341942501720041\n",
      "epoch: 5 step: 2008, loss is 0.005432666279375553\n",
      "epoch: 5 step: 2009, loss is 0.00667976401746273\n",
      "epoch: 5 step: 2010, loss is 0.0042414916679263115\n",
      "epoch: 5 step: 2011, loss is 0.11359567195177078\n",
      "epoch: 5 step: 2012, loss is 0.17101244628429413\n",
      "epoch: 5 step: 2013, loss is 0.14705859124660492\n",
      "epoch: 5 step: 2014, loss is 0.011326163075864315\n",
      "epoch: 5 step: 2015, loss is 0.0652238205075264\n",
      "epoch: 5 step: 2016, loss is 0.006300246808677912\n",
      "epoch: 5 step: 2017, loss is 0.036363691091537476\n",
      "epoch: 5 step: 2018, loss is 0.014407070353627205\n",
      "epoch: 5 step: 2019, loss is 0.007417625747621059\n",
      "epoch: 5 step: 2020, loss is 0.0018825758015736938\n",
      "epoch: 5 step: 2021, loss is 0.008952600881457329\n",
      "epoch: 5 step: 2022, loss is 0.005964732728898525\n",
      "epoch: 5 step: 2023, loss is 0.010897119529545307\n",
      "epoch: 5 step: 2024, loss is 0.005637393333017826\n",
      "epoch: 5 step: 2025, loss is 0.007433694321662188\n",
      "epoch: 5 step: 2026, loss is 0.0022656931541860104\n",
      "epoch: 5 step: 2027, loss is 0.005847540218383074\n",
      "epoch: 5 step: 2028, loss is 0.017407981678843498\n",
      "epoch: 5 step: 2029, loss is 1.5315148630179465e-05\n",
      "epoch: 5 step: 2030, loss is 0.014107825234532356\n",
      "epoch: 5 step: 2031, loss is 0.015312496572732925\n",
      "epoch: 5 step: 2032, loss is 0.019569002091884613\n",
      "epoch: 5 step: 2033, loss is 0.0031979146879166365\n",
      "epoch: 5 step: 2034, loss is 0.04887813329696655\n",
      "epoch: 5 step: 2035, loss is 0.0005541060818359256\n",
      "epoch: 5 step: 2036, loss is 0.007627012208104134\n",
      "epoch: 5 step: 2037, loss is 0.039555296301841736\n",
      "epoch: 5 step: 2038, loss is 0.00019994625472463667\n",
      "epoch: 5 step: 2039, loss is 0.0006105359643697739\n",
      "epoch: 5 step: 2040, loss is 0.005478911101818085\n",
      "epoch: 5 step: 2041, loss is 0.0040223607793450356\n",
      "epoch: 5 step: 2042, loss is 0.010744119994342327\n",
      "epoch: 5 step: 2043, loss is 0.027839820832014084\n",
      "epoch: 5 step: 2044, loss is 0.029252182692289352\n",
      "epoch: 5 step: 2045, loss is 0.0021448954939842224\n",
      "epoch: 5 step: 2046, loss is 0.0001728174975141883\n",
      "epoch: 5 step: 2047, loss is 0.0014935302315279841\n",
      "epoch: 5 step: 2048, loss is 0.07691338658332825\n",
      "epoch: 5 step: 2049, loss is 0.0005128434859216213\n",
      "epoch: 5 step: 2050, loss is 0.06737374514341354\n",
      "epoch: 5 step: 2051, loss is 0.008114589378237724\n",
      "epoch: 5 step: 2052, loss is 0.07690133154392242\n",
      "epoch: 5 step: 2053, loss is 0.04011458903551102\n",
      "epoch: 5 step: 2054, loss is 0.00010376200953032821\n",
      "epoch: 5 step: 2055, loss is 0.0054890247993171215\n",
      "epoch: 5 step: 2056, loss is 0.0007783565088175237\n",
      "epoch: 5 step: 2057, loss is 0.004167459439486265\n",
      "epoch: 5 step: 2058, loss is 0.0014882059767842293\n",
      "epoch: 5 step: 2059, loss is 0.036563266068696976\n",
      "epoch: 5 step: 2060, loss is 0.04008433222770691\n",
      "epoch: 5 step: 2061, loss is 0.012282546609640121\n",
      "epoch: 5 step: 2062, loss is 0.0012414356460794806\n",
      "epoch: 5 step: 2063, loss is 0.018363460898399353\n",
      "epoch: 5 step: 2064, loss is 0.020243672654032707\n",
      "epoch: 5 step: 2065, loss is 0.02928617224097252\n",
      "epoch: 5 step: 2066, loss is 0.019071906805038452\n",
      "epoch: 5 step: 2067, loss is 0.28899532556533813\n",
      "epoch: 5 step: 2068, loss is 0.0005382825620472431\n",
      "epoch: 5 step: 2069, loss is 0.0001277256233152002\n",
      "epoch: 5 step: 2070, loss is 0.0007640246767550707\n",
      "epoch: 5 step: 2071, loss is 0.00010490899148862809\n",
      "epoch: 5 step: 2072, loss is 0.0007691523060202599\n",
      "epoch: 5 step: 2073, loss is 0.001679978216998279\n",
      "epoch: 5 step: 2074, loss is 0.008197341114282608\n",
      "epoch: 5 step: 2075, loss is 0.0037752739153802395\n",
      "epoch: 5 step: 2076, loss is 0.03355475887656212\n",
      "epoch: 5 step: 2077, loss is 0.048248957842588425\n",
      "epoch: 5 step: 2078, loss is 0.0005328187253326178\n",
      "epoch: 5 step: 2079, loss is 0.07418284565210342\n",
      "epoch: 5 step: 2080, loss is 0.026299547404050827\n",
      "epoch: 5 step: 2081, loss is 0.00042438667151145637\n",
      "epoch: 5 step: 2082, loss is 0.005056560039520264\n",
      "epoch: 5 step: 2083, loss is 0.19593121111392975\n",
      "epoch: 5 step: 2084, loss is 0.0034646200947463512\n",
      "epoch: 5 step: 2085, loss is 0.0009022982558235526\n",
      "epoch: 5 step: 2086, loss is 0.07851015776395798\n",
      "epoch: 5 step: 2087, loss is 0.01795501820743084\n",
      "epoch: 5 step: 2088, loss is 0.010889064520597458\n",
      "epoch: 5 step: 2089, loss is 0.04090557619929314\n",
      "epoch: 5 step: 2090, loss is 0.01818796806037426\n",
      "epoch: 5 step: 2091, loss is 0.0008341077482327819\n",
      "epoch: 5 step: 2092, loss is 0.0005882750847376883\n",
      "epoch: 5 step: 2093, loss is 0.03337419778108597\n",
      "epoch: 5 step: 2094, loss is 0.06633457541465759\n",
      "epoch: 5 step: 2095, loss is 0.006243516691029072\n",
      "epoch: 5 step: 2096, loss is 0.00230387388728559\n",
      "epoch: 5 step: 2097, loss is 0.0012320656096562743\n",
      "epoch: 5 step: 2098, loss is 0.03962927311658859\n",
      "epoch: 5 step: 2099, loss is 0.00036408190499059856\n",
      "epoch: 5 step: 2100, loss is 0.1977989226579666\n",
      "epoch: 5 step: 2101, loss is 0.0027899008709937334\n",
      "epoch: 5 step: 2102, loss is 0.031104357913136482\n",
      "epoch: 5 step: 2103, loss is 0.0005539479316212237\n",
      "epoch: 5 step: 2104, loss is 0.0010082508670166135\n",
      "epoch: 5 step: 2105, loss is 0.02546197548508644\n",
      "epoch: 5 step: 2106, loss is 0.0017260806635022163\n",
      "epoch: 5 step: 2107, loss is 0.0008326277020387352\n",
      "epoch: 5 step: 2108, loss is 0.009514817968010902\n",
      "epoch: 5 step: 2109, loss is 0.005681012757122517\n",
      "epoch: 5 step: 2110, loss is 0.0009709557052701712\n",
      "epoch: 5 step: 2111, loss is 0.0008607538184151053\n",
      "epoch: 5 step: 2112, loss is 0.11773104965686798\n",
      "epoch: 5 step: 2113, loss is 0.0032463609240949154\n",
      "epoch: 5 step: 2114, loss is 0.00040084432112053037\n",
      "epoch: 5 step: 2115, loss is 0.0009834434604272246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 2116, loss is 0.024160465225577354\n",
      "epoch: 5 step: 2117, loss is 0.0045380317606031895\n",
      "epoch: 5 step: 2118, loss is 0.0014727578964084387\n",
      "epoch: 5 step: 2119, loss is 0.2763710618019104\n",
      "epoch: 5 step: 2120, loss is 0.010049760341644287\n",
      "epoch: 5 step: 2121, loss is 0.0018879554700106382\n",
      "epoch: 5 step: 2122, loss is 0.0009679057984612882\n",
      "epoch: 5 step: 2123, loss is 0.03981543704867363\n",
      "epoch: 5 step: 2124, loss is 0.084697425365448\n",
      "epoch: 5 step: 2125, loss is 0.026846520602703094\n",
      "epoch: 5 step: 2126, loss is 0.0024985193740576506\n",
      "epoch: 5 step: 2127, loss is 0.006633525714278221\n",
      "epoch: 5 step: 2128, loss is 0.19642013311386108\n",
      "epoch: 5 step: 2129, loss is 0.02105562761425972\n",
      "epoch: 5 step: 2130, loss is 0.00024400300753768533\n",
      "epoch: 5 step: 2131, loss is 0.06189620867371559\n",
      "epoch: 5 step: 2132, loss is 0.07474080473184586\n",
      "epoch: 5 step: 2133, loss is 0.00958155281841755\n",
      "epoch: 5 step: 2134, loss is 0.0030639891047030687\n",
      "epoch: 5 step: 2135, loss is 0.0034425323829054832\n",
      "epoch: 5 step: 2136, loss is 0.025297455489635468\n",
      "epoch: 5 step: 2137, loss is 0.0018609147518873215\n",
      "epoch: 5 step: 2138, loss is 0.0036488266196101904\n",
      "epoch: 5 step: 2139, loss is 0.0013028397224843502\n",
      "epoch: 5 step: 2140, loss is 0.0002946361491922289\n",
      "epoch: 5 step: 2141, loss is 0.18229450285434723\n",
      "epoch: 5 step: 2142, loss is 0.0017284065252169967\n",
      "epoch: 5 step: 2143, loss is 0.09138427674770355\n",
      "epoch: 5 step: 2144, loss is 0.020833348855376244\n",
      "epoch: 5 step: 2145, loss is 0.009347671642899513\n",
      "epoch: 5 step: 2146, loss is 0.028598342090845108\n",
      "epoch: 5 step: 2147, loss is 0.11816921830177307\n",
      "epoch: 5 step: 2148, loss is 0.004118736367672682\n",
      "epoch: 5 step: 2149, loss is 0.005781549494713545\n",
      "epoch: 5 step: 2150, loss is 0.0009484659531153738\n",
      "epoch: 5 step: 2151, loss is 0.04612204059958458\n",
      "epoch: 5 step: 2152, loss is 0.0002918984682764858\n",
      "epoch: 5 step: 2153, loss is 0.0012737098149955273\n",
      "epoch: 5 step: 2154, loss is 0.0009510025847703218\n",
      "epoch: 5 step: 2155, loss is 0.29146161675453186\n",
      "epoch: 5 step: 2156, loss is 0.000363845843821764\n",
      "epoch: 5 step: 2157, loss is 0.07969950139522552\n",
      "epoch: 5 step: 2158, loss is 0.0010768474312499166\n",
      "epoch: 5 step: 2159, loss is 0.08082035928964615\n",
      "epoch: 5 step: 2160, loss is 0.03339804708957672\n",
      "epoch: 5 step: 2161, loss is 0.12245189398527145\n",
      "epoch: 5 step: 2162, loss is 0.06972939521074295\n",
      "epoch: 5 step: 2163, loss is 0.09947099536657333\n",
      "epoch: 5 step: 2164, loss is 0.058274589478969574\n",
      "epoch: 5 step: 2165, loss is 0.046804845333099365\n",
      "epoch: 5 step: 2166, loss is 0.014658093452453613\n",
      "epoch: 5 step: 2167, loss is 0.0050250813364982605\n",
      "epoch: 5 step: 2168, loss is 0.11414212733507156\n",
      "epoch: 5 step: 2169, loss is 0.05435403436422348\n",
      "epoch: 5 step: 2170, loss is 0.04729314148426056\n",
      "epoch: 5 step: 2171, loss is 0.0433882512152195\n",
      "epoch: 5 step: 2172, loss is 0.0005549245979636908\n",
      "epoch: 5 step: 2173, loss is 0.0040333387441933155\n",
      "epoch: 5 step: 2174, loss is 0.044549569487571716\n",
      "epoch: 5 step: 2175, loss is 0.004137668292969465\n",
      "epoch: 5 step: 2176, loss is 0.009062274359166622\n",
      "epoch: 5 step: 2177, loss is 0.010282067582011223\n",
      "epoch: 5 step: 2178, loss is 0.011537092737853527\n",
      "epoch: 5 step: 2179, loss is 0.05247993394732475\n",
      "epoch: 5 step: 2180, loss is 0.06690428406000137\n",
      "epoch: 5 step: 2181, loss is 0.005016545299440622\n",
      "epoch: 5 step: 2182, loss is 0.00212881900370121\n",
      "epoch: 5 step: 2183, loss is 0.0004014419100712985\n",
      "epoch: 5 step: 2184, loss is 0.006141203455626965\n",
      "epoch: 5 step: 2185, loss is 0.0037196900229901075\n",
      "epoch: 5 step: 2186, loss is 0.005438074003905058\n",
      "epoch: 5 step: 2187, loss is 0.030877629294991493\n",
      "epoch: 6 step: 1, loss is 0.062000907957553864\n",
      "epoch: 6 step: 2, loss is 0.0010778708383440971\n",
      "epoch: 6 step: 3, loss is 0.0009243622189387679\n",
      "epoch: 6 step: 4, loss is 0.024703094735741615\n",
      "epoch: 6 step: 5, loss is 0.0025051780976355076\n",
      "epoch: 6 step: 6, loss is 0.029148399829864502\n",
      "epoch: 6 step: 7, loss is 0.16834905743598938\n",
      "epoch: 6 step: 8, loss is 0.08451906591653824\n",
      "epoch: 6 step: 9, loss is 0.04891533777117729\n",
      "epoch: 6 step: 10, loss is 0.034665293991565704\n",
      "epoch: 6 step: 11, loss is 0.0036982703022658825\n",
      "epoch: 6 step: 12, loss is 0.0072189560160040855\n",
      "epoch: 6 step: 13, loss is 0.08638344705104828\n",
      "epoch: 6 step: 14, loss is 0.0010941331274807453\n",
      "epoch: 6 step: 15, loss is 0.001756076468154788\n",
      "epoch: 6 step: 16, loss is 0.00015719070506747812\n",
      "epoch: 6 step: 17, loss is 0.007970146834850311\n",
      "epoch: 6 step: 18, loss is 0.0029983599670231342\n",
      "epoch: 6 step: 19, loss is 0.10597161948680878\n",
      "epoch: 6 step: 20, loss is 0.0009794675279408693\n",
      "epoch: 6 step: 21, loss is 0.12806358933448792\n",
      "epoch: 6 step: 22, loss is 0.05449168011546135\n",
      "epoch: 6 step: 23, loss is 0.0020965568255633116\n",
      "epoch: 6 step: 24, loss is 0.0017116684466600418\n",
      "epoch: 6 step: 25, loss is 0.022360999137163162\n",
      "epoch: 6 step: 26, loss is 0.0292081106454134\n",
      "epoch: 6 step: 27, loss is 0.021643968299031258\n",
      "epoch: 6 step: 28, loss is 0.0003010063956025988\n",
      "epoch: 6 step: 29, loss is 0.0009720526868477464\n",
      "epoch: 6 step: 30, loss is 0.0762118473649025\n",
      "epoch: 6 step: 31, loss is 0.0003449156356509775\n",
      "epoch: 6 step: 32, loss is 0.010282381437718868\n",
      "epoch: 6 step: 33, loss is 0.004186967387795448\n",
      "epoch: 6 step: 34, loss is 0.0050301081500947475\n",
      "epoch: 6 step: 35, loss is 0.0013603715924546123\n",
      "epoch: 6 step: 36, loss is 0.007057346869260073\n",
      "epoch: 6 step: 37, loss is 0.004696446470916271\n",
      "epoch: 6 step: 38, loss is 0.012786511331796646\n",
      "epoch: 6 step: 39, loss is 0.0007443548529408872\n",
      "epoch: 6 step: 40, loss is 0.001011043437756598\n",
      "epoch: 6 step: 41, loss is 0.005752590950578451\n",
      "epoch: 6 step: 42, loss is 0.001058032619766891\n",
      "epoch: 6 step: 43, loss is 0.0010025189258158207\n",
      "epoch: 6 step: 44, loss is 0.002829697448760271\n",
      "epoch: 6 step: 45, loss is 0.004410949535667896\n",
      "epoch: 6 step: 46, loss is 0.0010821458417922258\n",
      "epoch: 6 step: 47, loss is 0.020158935338258743\n",
      "epoch: 6 step: 48, loss is 0.013768081553280354\n",
      "epoch: 6 step: 49, loss is 0.011592649854719639\n",
      "epoch: 6 step: 50, loss is 0.0006446888437494636\n",
      "epoch: 6 step: 51, loss is 0.004622275475412607\n",
      "epoch: 6 step: 52, loss is 0.004173025488853455\n",
      "epoch: 6 step: 53, loss is 0.005596276372671127\n",
      "epoch: 6 step: 54, loss is 0.005664958618581295\n",
      "epoch: 6 step: 55, loss is 0.0013048697728663683\n",
      "epoch: 6 step: 56, loss is 0.0006379738915711641\n",
      "epoch: 6 step: 57, loss is 0.002888406626880169\n",
      "epoch: 6 step: 58, loss is 0.00031269557075574994\n",
      "epoch: 6 step: 59, loss is 9.493852849118412e-05\n",
      "epoch: 6 step: 60, loss is 0.011937452480196953\n",
      "epoch: 6 step: 61, loss is 0.010129822418093681\n",
      "epoch: 6 step: 62, loss is 0.005388947203755379\n",
      "epoch: 6 step: 63, loss is 0.015032735653221607\n",
      "epoch: 6 step: 64, loss is 0.0020963402930647135\n",
      "epoch: 6 step: 65, loss is 0.0012017607223242521\n",
      "epoch: 6 step: 66, loss is 0.01860670931637287\n",
      "epoch: 6 step: 67, loss is 0.01263196486979723\n",
      "epoch: 6 step: 68, loss is 0.030656421557068825\n",
      "epoch: 6 step: 69, loss is 0.019386621192097664\n",
      "epoch: 6 step: 70, loss is 0.0013662559213116765\n",
      "epoch: 6 step: 71, loss is 0.015241059474647045\n",
      "epoch: 6 step: 72, loss is 0.02426266483962536\n",
      "epoch: 6 step: 73, loss is 0.07880440354347229\n",
      "epoch: 6 step: 74, loss is 0.013733635656535625\n",
      "epoch: 6 step: 75, loss is 0.000608905334956944\n",
      "epoch: 6 step: 76, loss is 0.02551463432610035\n",
      "epoch: 6 step: 77, loss is 0.0006363349384628236\n",
      "epoch: 6 step: 78, loss is 0.0005366370314732194\n",
      "epoch: 6 step: 79, loss is 0.0420452281832695\n",
      "epoch: 6 step: 80, loss is 0.01122675184160471\n",
      "epoch: 6 step: 81, loss is 0.0011056201765313745\n",
      "epoch: 6 step: 82, loss is 0.0002799337962642312\n",
      "epoch: 6 step: 83, loss is 0.003410340752452612\n",
      "epoch: 6 step: 84, loss is 0.00038269427022896707\n",
      "epoch: 6 step: 85, loss is 0.0010638654930517077\n",
      "epoch: 6 step: 86, loss is 0.003039321396499872\n",
      "epoch: 6 step: 87, loss is 0.01285291463136673\n",
      "epoch: 6 step: 88, loss is 0.03999962657690048\n",
      "epoch: 6 step: 89, loss is 0.0002529642079025507\n",
      "epoch: 6 step: 90, loss is 0.00011437215289333835\n",
      "epoch: 6 step: 91, loss is 0.004054438788443804\n",
      "epoch: 6 step: 92, loss is 0.05443406105041504\n",
      "epoch: 6 step: 93, loss is 0.00031899005989544094\n",
      "epoch: 6 step: 94, loss is 3.4527725802036e-05\n",
      "epoch: 6 step: 95, loss is 0.08211935311555862\n",
      "epoch: 6 step: 96, loss is 0.0021826864685863256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 97, loss is 0.008381729945540428\n",
      "epoch: 6 step: 98, loss is 0.003537857672199607\n",
      "epoch: 6 step: 99, loss is 0.005542451981455088\n",
      "epoch: 6 step: 100, loss is 0.0017011051531881094\n",
      "epoch: 6 step: 101, loss is 0.0003774815413635224\n",
      "epoch: 6 step: 102, loss is 0.00047506860573776066\n",
      "epoch: 6 step: 103, loss is 4.56584311905317e-05\n",
      "epoch: 6 step: 104, loss is 0.12858836352825165\n",
      "epoch: 6 step: 105, loss is 8.278548921225592e-05\n",
      "epoch: 6 step: 106, loss is 0.028313830494880676\n",
      "epoch: 6 step: 107, loss is 0.003284948179498315\n",
      "epoch: 6 step: 108, loss is 0.008197659626603127\n",
      "epoch: 6 step: 109, loss is 0.011084763333201408\n",
      "epoch: 6 step: 110, loss is 7.61530754971318e-05\n",
      "epoch: 6 step: 111, loss is 0.0025532194413244724\n",
      "epoch: 6 step: 112, loss is 0.019549133256077766\n",
      "epoch: 6 step: 113, loss is 0.002229012083262205\n",
      "epoch: 6 step: 114, loss is 0.00020280381431803107\n",
      "epoch: 6 step: 115, loss is 0.0013790101511403918\n",
      "epoch: 6 step: 116, loss is 0.008500535041093826\n",
      "epoch: 6 step: 117, loss is 0.05001243203878403\n",
      "epoch: 6 step: 118, loss is 0.023471347987651825\n",
      "epoch: 6 step: 119, loss is 0.012918415479362011\n",
      "epoch: 6 step: 120, loss is 0.00037660589441657066\n",
      "epoch: 6 step: 121, loss is 0.000678149692248553\n",
      "epoch: 6 step: 122, loss is 0.039438776671886444\n",
      "epoch: 6 step: 123, loss is 0.0009782107081264257\n",
      "epoch: 6 step: 124, loss is 0.000995545880869031\n",
      "epoch: 6 step: 125, loss is 0.003587648505344987\n",
      "epoch: 6 step: 126, loss is 0.001278995885513723\n",
      "epoch: 6 step: 127, loss is 5.385384429246187e-05\n",
      "epoch: 6 step: 128, loss is 0.003326922422274947\n",
      "epoch: 6 step: 129, loss is 0.0034134190063923597\n",
      "epoch: 6 step: 130, loss is 0.007261544466018677\n",
      "epoch: 6 step: 131, loss is 0.00041097725625149906\n",
      "epoch: 6 step: 132, loss is 1.499871814303333e-05\n",
      "epoch: 6 step: 133, loss is 0.0007717665866948664\n",
      "epoch: 6 step: 134, loss is 0.0020792861469089985\n",
      "epoch: 6 step: 135, loss is 0.04438565671443939\n",
      "epoch: 6 step: 136, loss is 0.0003120728943031281\n",
      "epoch: 6 step: 137, loss is 0.00013416551519185305\n",
      "epoch: 6 step: 138, loss is 0.005518525838851929\n",
      "epoch: 6 step: 139, loss is 0.001299937954172492\n",
      "epoch: 6 step: 140, loss is 0.05631641298532486\n",
      "epoch: 6 step: 141, loss is 0.06136645749211311\n",
      "epoch: 6 step: 142, loss is 1.484211315982975e-05\n",
      "epoch: 6 step: 143, loss is 0.07366723567247391\n",
      "epoch: 6 step: 144, loss is 0.0004986533895134926\n",
      "epoch: 6 step: 145, loss is 0.0014232613611966372\n",
      "epoch: 6 step: 146, loss is 0.0013412450207397342\n",
      "epoch: 6 step: 147, loss is 0.0012816390953958035\n",
      "epoch: 6 step: 148, loss is 7.398578600259498e-05\n",
      "epoch: 6 step: 149, loss is 0.0006916048587299883\n",
      "epoch: 6 step: 150, loss is 0.0003335115034133196\n",
      "epoch: 6 step: 151, loss is 0.00010708074842114002\n",
      "epoch: 6 step: 152, loss is 0.017543017864227295\n",
      "epoch: 6 step: 153, loss is 0.001673392252996564\n",
      "epoch: 6 step: 154, loss is 0.0013345233164727688\n",
      "epoch: 6 step: 155, loss is 0.14187973737716675\n",
      "epoch: 6 step: 156, loss is 0.007371002808213234\n",
      "epoch: 6 step: 157, loss is 0.003230780130252242\n",
      "epoch: 6 step: 158, loss is 0.1777467578649521\n",
      "epoch: 6 step: 159, loss is 0.00031800178112462163\n",
      "epoch: 6 step: 160, loss is 0.004606918897479773\n",
      "epoch: 6 step: 161, loss is 0.00019229279132559896\n",
      "epoch: 6 step: 162, loss is 0.00015598032041452825\n",
      "epoch: 6 step: 163, loss is 0.0015855238307267427\n",
      "epoch: 6 step: 164, loss is 6.714832852594554e-05\n",
      "epoch: 6 step: 165, loss is 0.00902064424008131\n",
      "epoch: 6 step: 166, loss is 0.0026452788151800632\n",
      "epoch: 6 step: 167, loss is 0.03364424407482147\n",
      "epoch: 6 step: 168, loss is 0.003282333491370082\n",
      "epoch: 6 step: 169, loss is 0.0001321624149568379\n",
      "epoch: 6 step: 170, loss is 0.0006249355501495302\n",
      "epoch: 6 step: 171, loss is 0.003556344425305724\n",
      "epoch: 6 step: 172, loss is 0.0419236458837986\n",
      "epoch: 6 step: 173, loss is 0.011893409304320812\n",
      "epoch: 6 step: 174, loss is 0.04538608342409134\n",
      "epoch: 6 step: 175, loss is 0.05435942858457565\n",
      "epoch: 6 step: 176, loss is 0.0013796923449262977\n",
      "epoch: 6 step: 177, loss is 4.405898289405741e-05\n",
      "epoch: 6 step: 178, loss is 0.0009796315571293235\n",
      "epoch: 6 step: 179, loss is 0.07558237016201019\n",
      "epoch: 6 step: 180, loss is 0.0028192331083118916\n",
      "epoch: 6 step: 181, loss is 0.0036609643138945103\n",
      "epoch: 6 step: 182, loss is 0.0013333118986338377\n",
      "epoch: 6 step: 183, loss is 0.00028346534236334264\n",
      "epoch: 6 step: 184, loss is 0.007240215316414833\n",
      "epoch: 6 step: 185, loss is 0.025152141228318214\n",
      "epoch: 6 step: 186, loss is 0.0007779868901707232\n",
      "epoch: 6 step: 187, loss is 0.0005666693905368447\n",
      "epoch: 6 step: 188, loss is 0.00355683546513319\n",
      "epoch: 6 step: 189, loss is 0.016665097326040268\n",
      "epoch: 6 step: 190, loss is 0.0003165441448800266\n",
      "epoch: 6 step: 191, loss is 0.0186738520860672\n",
      "epoch: 6 step: 192, loss is 0.0003394894301891327\n",
      "epoch: 6 step: 193, loss is 0.0028767953626811504\n",
      "epoch: 6 step: 194, loss is 0.0014597333502024412\n",
      "epoch: 6 step: 195, loss is 0.021034471690654755\n",
      "epoch: 6 step: 196, loss is 0.0012341664405539632\n",
      "epoch: 6 step: 197, loss is 0.00018348947924096137\n",
      "epoch: 6 step: 198, loss is 0.010032699443399906\n",
      "epoch: 6 step: 199, loss is 0.03936660289764404\n",
      "epoch: 6 step: 200, loss is 0.0006231252336874604\n",
      "epoch: 6 step: 201, loss is 0.03121558390557766\n",
      "epoch: 6 step: 202, loss is 3.732014010893181e-05\n",
      "epoch: 6 step: 203, loss is 0.014299849979579449\n",
      "epoch: 6 step: 204, loss is 0.010081039741635323\n",
      "epoch: 6 step: 205, loss is 0.006578194908797741\n",
      "epoch: 6 step: 206, loss is 0.0032447604462504387\n",
      "epoch: 6 step: 207, loss is 0.03474947810173035\n",
      "epoch: 6 step: 208, loss is 0.009046238847076893\n",
      "epoch: 6 step: 209, loss is 0.018102379515767097\n",
      "epoch: 6 step: 210, loss is 5.55043516214937e-05\n",
      "epoch: 6 step: 211, loss is 0.0005934903165325522\n",
      "epoch: 6 step: 212, loss is 2.067348214040976e-05\n",
      "epoch: 6 step: 213, loss is 0.06687188893556595\n",
      "epoch: 6 step: 214, loss is 0.0006678328500129282\n",
      "epoch: 6 step: 215, loss is 0.033806998282670975\n",
      "epoch: 6 step: 216, loss is 0.00045434755156747997\n",
      "epoch: 6 step: 217, loss is 0.003585086902603507\n",
      "epoch: 6 step: 218, loss is 0.005033324472606182\n",
      "epoch: 6 step: 219, loss is 0.0004927800036966801\n",
      "epoch: 6 step: 220, loss is 0.00012001700815744698\n",
      "epoch: 6 step: 221, loss is 0.048738181591033936\n",
      "epoch: 6 step: 222, loss is 0.0012595504522323608\n",
      "epoch: 6 step: 223, loss is 0.07887270301580429\n",
      "epoch: 6 step: 224, loss is 0.052545297890901566\n",
      "epoch: 6 step: 225, loss is 0.00029737773002125323\n",
      "epoch: 6 step: 226, loss is 0.017746184021234512\n",
      "epoch: 6 step: 227, loss is 0.00045426757424138486\n",
      "epoch: 6 step: 228, loss is 7.585890125483274e-05\n",
      "epoch: 6 step: 229, loss is 0.0031582240480929613\n",
      "epoch: 6 step: 230, loss is 0.0003198578779119998\n",
      "epoch: 6 step: 231, loss is 0.004189408849924803\n",
      "epoch: 6 step: 232, loss is 0.000838397303596139\n",
      "epoch: 6 step: 233, loss is 0.0009451634832657874\n",
      "epoch: 6 step: 234, loss is 0.0001859480544226244\n",
      "epoch: 6 step: 235, loss is 0.010549831204116344\n",
      "epoch: 6 step: 236, loss is 0.1389409303665161\n",
      "epoch: 6 step: 237, loss is 0.0014218940632417798\n",
      "epoch: 6 step: 238, loss is 0.0001991056778933853\n",
      "epoch: 6 step: 239, loss is 0.12000424414873123\n",
      "epoch: 6 step: 240, loss is 4.8063309805002064e-05\n",
      "epoch: 6 step: 241, loss is 0.0009009484201669693\n",
      "epoch: 6 step: 242, loss is 0.00048097388935275376\n",
      "epoch: 6 step: 243, loss is 0.017503712326288223\n",
      "epoch: 6 step: 244, loss is 0.115729920566082\n",
      "epoch: 6 step: 245, loss is 0.06755942851305008\n",
      "epoch: 6 step: 246, loss is 0.008012419566512108\n",
      "epoch: 6 step: 247, loss is 0.02679910697042942\n",
      "epoch: 6 step: 248, loss is 0.0020064169075340033\n",
      "epoch: 6 step: 249, loss is 0.0004997450159862638\n",
      "epoch: 6 step: 250, loss is 0.06971750408411026\n",
      "epoch: 6 step: 251, loss is 0.0001786157808965072\n",
      "epoch: 6 step: 252, loss is 0.0003311290347483009\n",
      "epoch: 6 step: 253, loss is 0.04589967802166939\n",
      "epoch: 6 step: 254, loss is 0.0011669908417388797\n",
      "epoch: 6 step: 255, loss is 0.10378368198871613\n",
      "epoch: 6 step: 256, loss is 0.00439696479588747\n",
      "epoch: 6 step: 257, loss is 0.0030753675382584333\n",
      "epoch: 6 step: 258, loss is 0.012748250737786293\n",
      "epoch: 6 step: 259, loss is 5.705053263227455e-05\n",
      "epoch: 6 step: 260, loss is 0.006939768325537443\n",
      "epoch: 6 step: 261, loss is 0.007114684674888849\n",
      "epoch: 6 step: 262, loss is 0.0767650306224823\n",
      "epoch: 6 step: 263, loss is 0.00019894061551894993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 264, loss is 0.05515401065349579\n",
      "epoch: 6 step: 265, loss is 0.00043640975491143763\n",
      "epoch: 6 step: 266, loss is 0.1547662615776062\n",
      "epoch: 6 step: 267, loss is 0.013439705595374107\n",
      "epoch: 6 step: 268, loss is 0.07623131573200226\n",
      "epoch: 6 step: 269, loss is 0.030623584985733032\n",
      "epoch: 6 step: 270, loss is 0.034196995198726654\n",
      "epoch: 6 step: 271, loss is 0.004545324016362429\n",
      "epoch: 6 step: 272, loss is 0.0018969121156260371\n",
      "epoch: 6 step: 273, loss is 0.011675454676151276\n",
      "epoch: 6 step: 274, loss is 0.0011868015863001347\n",
      "epoch: 6 step: 275, loss is 0.011396916583180428\n",
      "epoch: 6 step: 276, loss is 0.00031347075127996504\n",
      "epoch: 6 step: 277, loss is 0.005161077715456486\n",
      "epoch: 6 step: 278, loss is 0.00010258281690767035\n",
      "epoch: 6 step: 279, loss is 0.09328874200582504\n",
      "epoch: 6 step: 280, loss is 0.17703025043010712\n",
      "epoch: 6 step: 281, loss is 0.0036179404705762863\n",
      "epoch: 6 step: 282, loss is 0.00504701305180788\n",
      "epoch: 6 step: 283, loss is 0.0021534778643399477\n",
      "epoch: 6 step: 284, loss is 0.00016487471293658018\n",
      "epoch: 6 step: 285, loss is 0.15411710739135742\n",
      "epoch: 6 step: 286, loss is 0.007651252206414938\n",
      "epoch: 6 step: 287, loss is 0.04474041983485222\n",
      "epoch: 6 step: 288, loss is 0.00017690955428406596\n",
      "epoch: 6 step: 289, loss is 0.000809205521363765\n",
      "epoch: 6 step: 290, loss is 0.00038816023152321577\n",
      "epoch: 6 step: 291, loss is 0.0042683822102844715\n",
      "epoch: 6 step: 292, loss is 0.2215900421142578\n",
      "epoch: 6 step: 293, loss is 0.002691625850275159\n",
      "epoch: 6 step: 294, loss is 0.0026505901478230953\n",
      "epoch: 6 step: 295, loss is 0.0018972293473780155\n",
      "epoch: 6 step: 296, loss is 0.08754117786884308\n",
      "epoch: 6 step: 297, loss is 0.005175562109798193\n",
      "epoch: 6 step: 298, loss is 0.007729490287601948\n",
      "epoch: 6 step: 299, loss is 0.020771749317646027\n",
      "epoch: 6 step: 300, loss is 0.0008446325082331896\n",
      "epoch: 6 step: 301, loss is 0.006890155840665102\n",
      "epoch: 6 step: 302, loss is 0.01593398116528988\n",
      "epoch: 6 step: 303, loss is 0.0004728565691038966\n",
      "epoch: 6 step: 304, loss is 0.004106930922716856\n",
      "epoch: 6 step: 305, loss is 0.0006331056356430054\n",
      "epoch: 6 step: 306, loss is 0.11371192336082458\n",
      "epoch: 6 step: 307, loss is 0.0027554293628782034\n",
      "epoch: 6 step: 308, loss is 0.01819963939487934\n",
      "epoch: 6 step: 309, loss is 0.0017109316540881991\n",
      "epoch: 6 step: 310, loss is 0.0014276562724262476\n",
      "epoch: 6 step: 311, loss is 0.03724316507577896\n",
      "epoch: 6 step: 312, loss is 0.008935365825891495\n",
      "epoch: 6 step: 313, loss is 0.003472551004961133\n",
      "epoch: 6 step: 314, loss is 0.01286392379552126\n",
      "epoch: 6 step: 315, loss is 0.32455381751060486\n",
      "epoch: 6 step: 316, loss is 0.00024321644741576165\n",
      "epoch: 6 step: 317, loss is 0.0004117543576285243\n",
      "epoch: 6 step: 318, loss is 0.03838286176323891\n",
      "epoch: 6 step: 319, loss is 0.039389751851558685\n",
      "epoch: 6 step: 320, loss is 0.00026149663608521223\n",
      "epoch: 6 step: 321, loss is 0.03809627890586853\n",
      "epoch: 6 step: 322, loss is 0.10217045992612839\n",
      "epoch: 6 step: 323, loss is 0.0018408781616017222\n",
      "epoch: 6 step: 324, loss is 0.06152022257447243\n",
      "epoch: 6 step: 325, loss is 0.09398926794528961\n",
      "epoch: 6 step: 326, loss is 0.008822165429592133\n",
      "epoch: 6 step: 327, loss is 0.037362705916166306\n",
      "epoch: 6 step: 328, loss is 0.044710464775562286\n",
      "epoch: 6 step: 329, loss is 0.004095085430890322\n",
      "epoch: 6 step: 330, loss is 0.006328817922621965\n",
      "epoch: 6 step: 331, loss is 0.0011136200046166778\n",
      "epoch: 6 step: 332, loss is 0.011770106852054596\n",
      "epoch: 6 step: 333, loss is 0.003009202191606164\n",
      "epoch: 6 step: 334, loss is 0.1398703008890152\n",
      "epoch: 6 step: 335, loss is 0.019811293110251427\n",
      "epoch: 6 step: 336, loss is 0.02315688505768776\n",
      "epoch: 6 step: 337, loss is 0.0027226919773966074\n",
      "epoch: 6 step: 338, loss is 0.0003117548767477274\n",
      "epoch: 6 step: 339, loss is 0.040721263736486435\n",
      "epoch: 6 step: 340, loss is 0.023742347955703735\n",
      "epoch: 6 step: 341, loss is 0.0003063652548007667\n",
      "epoch: 6 step: 342, loss is 0.01260882057249546\n",
      "epoch: 6 step: 343, loss is 0.001725469483062625\n",
      "epoch: 6 step: 344, loss is 0.034820057451725006\n",
      "epoch: 6 step: 345, loss is 0.01278721448034048\n",
      "epoch: 6 step: 346, loss is 0.0006333680357784033\n",
      "epoch: 6 step: 347, loss is 0.011075833812355995\n",
      "epoch: 6 step: 348, loss is 0.0007700062706135213\n",
      "epoch: 6 step: 349, loss is 0.011124802753329277\n",
      "epoch: 6 step: 350, loss is 0.004923325963318348\n",
      "epoch: 6 step: 351, loss is 0.00021801564435008913\n",
      "epoch: 6 step: 352, loss is 0.0013887924142181873\n",
      "epoch: 6 step: 353, loss is 0.0015108983498066664\n",
      "epoch: 6 step: 354, loss is 0.00046720169484615326\n",
      "epoch: 6 step: 355, loss is 0.006183489225804806\n",
      "epoch: 6 step: 356, loss is 0.0012733959592878819\n",
      "epoch: 6 step: 357, loss is 0.10219284892082214\n",
      "epoch: 6 step: 358, loss is 0.0002780549111776054\n",
      "epoch: 6 step: 359, loss is 0.0005283762002363801\n",
      "epoch: 6 step: 360, loss is 0.0032280830200761557\n",
      "epoch: 6 step: 361, loss is 0.0021286492701619864\n",
      "epoch: 6 step: 362, loss is 0.049704257398843765\n",
      "epoch: 6 step: 363, loss is 0.004401123151183128\n",
      "epoch: 6 step: 364, loss is 0.008401017636060715\n",
      "epoch: 6 step: 365, loss is 0.14350350201129913\n",
      "epoch: 6 step: 366, loss is 0.015686534345149994\n",
      "epoch: 6 step: 367, loss is 0.023168982937932014\n",
      "epoch: 6 step: 368, loss is 0.02555938810110092\n",
      "epoch: 6 step: 369, loss is 0.011733403429389\n",
      "epoch: 6 step: 370, loss is 0.004593740217387676\n",
      "epoch: 6 step: 371, loss is 0.0019860328175127506\n",
      "epoch: 6 step: 372, loss is 0.00022819297737441957\n",
      "epoch: 6 step: 373, loss is 0.018547091633081436\n",
      "epoch: 6 step: 374, loss is 0.005691065452992916\n",
      "epoch: 6 step: 375, loss is 0.15040546655654907\n",
      "epoch: 6 step: 376, loss is 0.006251527927815914\n",
      "epoch: 6 step: 377, loss is 0.009460476227104664\n",
      "epoch: 6 step: 378, loss is 0.05345696210861206\n",
      "epoch: 6 step: 379, loss is 0.0005542995641008019\n",
      "epoch: 6 step: 380, loss is 0.09174815565347672\n",
      "epoch: 6 step: 381, loss is 6.451116496464238e-05\n",
      "epoch: 6 step: 382, loss is 0.0017544985748827457\n",
      "epoch: 6 step: 383, loss is 0.0005924823926761746\n",
      "epoch: 6 step: 384, loss is 0.0007508780108764768\n",
      "epoch: 6 step: 385, loss is 0.0006150169647298753\n",
      "epoch: 6 step: 386, loss is 0.0007600590470246971\n",
      "epoch: 6 step: 387, loss is 0.010282222181558609\n",
      "epoch: 6 step: 388, loss is 0.038249872624874115\n",
      "epoch: 6 step: 389, loss is 0.00020815509196836501\n",
      "epoch: 6 step: 390, loss is 0.017420224845409393\n",
      "epoch: 6 step: 391, loss is 0.005806583911180496\n",
      "epoch: 6 step: 392, loss is 0.12421394884586334\n",
      "epoch: 6 step: 393, loss is 0.000654869363643229\n",
      "epoch: 6 step: 394, loss is 0.002099899807944894\n",
      "epoch: 6 step: 395, loss is 0.00024640513584017754\n",
      "epoch: 6 step: 396, loss is 0.01209544949233532\n",
      "epoch: 6 step: 397, loss is 0.0005384669057093561\n",
      "epoch: 6 step: 398, loss is 0.01052374392747879\n",
      "epoch: 6 step: 399, loss is 0.017485739663243294\n",
      "epoch: 6 step: 400, loss is 0.001107558375224471\n",
      "epoch: 6 step: 401, loss is 0.08245430886745453\n",
      "epoch: 6 step: 402, loss is 0.0004428850661497563\n",
      "epoch: 6 step: 403, loss is 0.0006698655779473484\n",
      "epoch: 6 step: 404, loss is 0.0038696120027452707\n",
      "epoch: 6 step: 405, loss is 0.01720227301120758\n",
      "epoch: 6 step: 406, loss is 0.002418121788650751\n",
      "epoch: 6 step: 407, loss is 0.002710753120481968\n",
      "epoch: 6 step: 408, loss is 0.01170096080750227\n",
      "epoch: 6 step: 409, loss is 0.0031590107828378677\n",
      "epoch: 6 step: 410, loss is 0.16702498495578766\n",
      "epoch: 6 step: 411, loss is 0.0003860565775539726\n",
      "epoch: 6 step: 412, loss is 0.0034066676162183285\n",
      "epoch: 6 step: 413, loss is 3.3013529900927097e-05\n",
      "epoch: 6 step: 414, loss is 0.04966123774647713\n",
      "epoch: 6 step: 415, loss is 0.005475544836372137\n",
      "epoch: 6 step: 416, loss is 0.10373064130544662\n",
      "epoch: 6 step: 417, loss is 0.00011020985402865335\n",
      "epoch: 6 step: 418, loss is 0.0313531719148159\n",
      "epoch: 6 step: 419, loss is 0.00033751490991562605\n",
      "epoch: 6 step: 420, loss is 0.04863286018371582\n",
      "epoch: 6 step: 421, loss is 0.0005998341366648674\n",
      "epoch: 6 step: 422, loss is 0.006847325246781111\n",
      "epoch: 6 step: 423, loss is 0.00017787283286452293\n",
      "epoch: 6 step: 424, loss is 0.09130575507879257\n",
      "epoch: 6 step: 425, loss is 0.008008635602891445\n",
      "epoch: 6 step: 426, loss is 0.01042217668145895\n",
      "epoch: 6 step: 427, loss is 0.02044891193509102\n",
      "epoch: 6 step: 428, loss is 9.50695393839851e-05\n",
      "epoch: 6 step: 429, loss is 0.001976171974092722\n",
      "epoch: 6 step: 430, loss is 0.004178384318947792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 431, loss is 0.0043802689760923386\n",
      "epoch: 6 step: 432, loss is 0.011942184530198574\n",
      "epoch: 6 step: 433, loss is 0.007147309370338917\n",
      "epoch: 6 step: 434, loss is 0.020548410713672638\n",
      "epoch: 6 step: 435, loss is 0.0006144419894553721\n",
      "epoch: 6 step: 436, loss is 0.001495671458542347\n",
      "epoch: 6 step: 437, loss is 0.06043655425310135\n",
      "epoch: 6 step: 438, loss is 0.01241485308855772\n",
      "epoch: 6 step: 439, loss is 0.002484402619302273\n",
      "epoch: 6 step: 440, loss is 0.002011893317103386\n",
      "epoch: 6 step: 441, loss is 0.008371192961931229\n",
      "epoch: 6 step: 442, loss is 0.001504305168054998\n",
      "epoch: 6 step: 443, loss is 0.0017501042457297444\n",
      "epoch: 6 step: 444, loss is 0.1906982809305191\n",
      "epoch: 6 step: 445, loss is 0.07445881515741348\n",
      "epoch: 6 step: 446, loss is 0.0006979210302233696\n",
      "epoch: 6 step: 447, loss is 0.07242599874734879\n",
      "epoch: 6 step: 448, loss is 0.0014822317752987146\n",
      "epoch: 6 step: 449, loss is 0.0034406865015625954\n",
      "epoch: 6 step: 450, loss is 4.3807929614558816e-05\n",
      "epoch: 6 step: 451, loss is 0.02625197544693947\n",
      "epoch: 6 step: 452, loss is 0.03138105943799019\n",
      "epoch: 6 step: 453, loss is 0.0078031099401414394\n",
      "epoch: 6 step: 454, loss is 0.0010465526720508933\n",
      "epoch: 6 step: 455, loss is 0.06218283250927925\n",
      "epoch: 6 step: 456, loss is 0.040124040096998215\n",
      "epoch: 6 step: 457, loss is 0.002958016935735941\n",
      "epoch: 6 step: 458, loss is 0.0009558324818499386\n",
      "epoch: 6 step: 459, loss is 0.024813968688249588\n",
      "epoch: 6 step: 460, loss is 0.0019175027264282107\n",
      "epoch: 6 step: 461, loss is 0.0027984606567770243\n",
      "epoch: 6 step: 462, loss is 0.0012899520806968212\n",
      "epoch: 6 step: 463, loss is 0.00012560162576846778\n",
      "epoch: 6 step: 464, loss is 0.07173413038253784\n",
      "epoch: 6 step: 465, loss is 0.0005497679812833667\n",
      "epoch: 6 step: 466, loss is 0.00012128188245696947\n",
      "epoch: 6 step: 467, loss is 0.0030672831926494837\n",
      "epoch: 6 step: 468, loss is 0.0013426764635369182\n",
      "epoch: 6 step: 469, loss is 0.06284183263778687\n",
      "epoch: 6 step: 470, loss is 0.0005599093856289983\n",
      "epoch: 6 step: 471, loss is 0.0010553878964856267\n",
      "epoch: 6 step: 472, loss is 0.00038105319254100323\n",
      "epoch: 6 step: 473, loss is 0.10303962230682373\n",
      "epoch: 6 step: 474, loss is 0.0005443781265057623\n",
      "epoch: 6 step: 475, loss is 0.002249601762741804\n",
      "epoch: 6 step: 476, loss is 4.229508340358734e-05\n",
      "epoch: 6 step: 477, loss is 0.00014970224583521485\n",
      "epoch: 6 step: 478, loss is 0.08646968007087708\n",
      "epoch: 6 step: 479, loss is 0.007569226436316967\n",
      "epoch: 6 step: 480, loss is 0.001279380638152361\n",
      "epoch: 6 step: 481, loss is 0.014992104843258858\n",
      "epoch: 6 step: 482, loss is 0.17750369012355804\n",
      "epoch: 6 step: 483, loss is 0.0008187099010683596\n",
      "epoch: 6 step: 484, loss is 0.00042251177364960313\n",
      "epoch: 6 step: 485, loss is 0.0019982634112238884\n",
      "epoch: 6 step: 486, loss is 0.000774452171754092\n",
      "epoch: 6 step: 487, loss is 0.01417104434221983\n",
      "epoch: 6 step: 488, loss is 0.0012124739587306976\n",
      "epoch: 6 step: 489, loss is 0.0535736009478569\n",
      "epoch: 6 step: 490, loss is 4.835195795749314e-05\n",
      "epoch: 6 step: 491, loss is 0.001938417088240385\n",
      "epoch: 6 step: 492, loss is 0.03182139992713928\n",
      "epoch: 6 step: 493, loss is 0.004885478876531124\n",
      "epoch: 6 step: 494, loss is 0.024287356063723564\n",
      "epoch: 6 step: 495, loss is 0.022513659670948982\n",
      "epoch: 6 step: 496, loss is 0.0028649240266531706\n",
      "epoch: 6 step: 497, loss is 0.0042144907638430595\n",
      "epoch: 6 step: 498, loss is 0.0172526054084301\n",
      "epoch: 6 step: 499, loss is 0.0067662266083061695\n",
      "epoch: 6 step: 500, loss is 0.005909640807658434\n",
      "epoch: 6 step: 501, loss is 0.004122493788599968\n",
      "epoch: 6 step: 502, loss is 0.0021133015397936106\n",
      "epoch: 6 step: 503, loss is 5.536614480661228e-05\n",
      "epoch: 6 step: 504, loss is 0.00025090755661949515\n",
      "epoch: 6 step: 505, loss is 0.0011062676785513759\n",
      "epoch: 6 step: 506, loss is 0.0002672488917596638\n",
      "epoch: 6 step: 507, loss is 0.0023239548318088055\n",
      "epoch: 6 step: 508, loss is 0.0012430566130205989\n",
      "epoch: 6 step: 509, loss is 0.008763515390455723\n",
      "epoch: 6 step: 510, loss is 0.00040359230479225516\n",
      "epoch: 6 step: 511, loss is 0.00024810631293803453\n",
      "epoch: 6 step: 512, loss is 0.0033453532960265875\n",
      "epoch: 6 step: 513, loss is 0.032492078840732574\n",
      "epoch: 6 step: 514, loss is 0.004792789928615093\n",
      "epoch: 6 step: 515, loss is 0.0027309192810207605\n",
      "epoch: 6 step: 516, loss is 0.0007684067240916193\n",
      "epoch: 6 step: 517, loss is 0.00013189933088142425\n",
      "epoch: 6 step: 518, loss is 0.00014216986892279238\n",
      "epoch: 6 step: 519, loss is 0.039140734821558\n",
      "epoch: 6 step: 520, loss is 0.0006188878905959427\n",
      "epoch: 6 step: 521, loss is 6.109325477154925e-05\n",
      "epoch: 6 step: 522, loss is 0.003202492371201515\n",
      "epoch: 6 step: 523, loss is 4.9180998757947236e-05\n",
      "epoch: 6 step: 524, loss is 0.00033428461756557226\n",
      "epoch: 6 step: 525, loss is 0.21651825308799744\n",
      "epoch: 6 step: 526, loss is 0.0018304630648344755\n",
      "epoch: 6 step: 527, loss is 0.004725063219666481\n",
      "epoch: 6 step: 528, loss is 0.08289841562509537\n",
      "epoch: 6 step: 529, loss is 0.003595677437260747\n",
      "epoch: 6 step: 530, loss is 0.12897375226020813\n",
      "epoch: 6 step: 531, loss is 0.0010436685988679528\n",
      "epoch: 6 step: 532, loss is 0.00021938436839263886\n",
      "epoch: 6 step: 533, loss is 0.00237827654927969\n",
      "epoch: 6 step: 534, loss is 7.44155840948224e-05\n",
      "epoch: 6 step: 535, loss is 0.00019215296197216958\n",
      "epoch: 6 step: 536, loss is 0.0008621541783213615\n",
      "epoch: 6 step: 537, loss is 0.01074892096221447\n",
      "epoch: 6 step: 538, loss is 0.0031923006754368544\n",
      "epoch: 6 step: 539, loss is 0.000711871893145144\n",
      "epoch: 6 step: 540, loss is 0.06183929741382599\n",
      "epoch: 6 step: 541, loss is 0.022669248282909393\n",
      "epoch: 6 step: 542, loss is 0.0022812443785369396\n",
      "epoch: 6 step: 543, loss is 0.015318701043725014\n",
      "epoch: 6 step: 544, loss is 0.03960246965289116\n",
      "epoch: 6 step: 545, loss is 0.00020930026948917657\n",
      "epoch: 6 step: 546, loss is 0.0003187033871654421\n",
      "epoch: 6 step: 547, loss is 0.015152708627283573\n",
      "epoch: 6 step: 548, loss is 0.0019204289419576526\n",
      "epoch: 6 step: 549, loss is 0.005740758962929249\n",
      "epoch: 6 step: 550, loss is 0.0008145798346959054\n",
      "epoch: 6 step: 551, loss is 0.08061524480581284\n",
      "epoch: 6 step: 552, loss is 0.0014094465877860785\n",
      "epoch: 6 step: 553, loss is 0.003309400985017419\n",
      "epoch: 6 step: 554, loss is 0.003503254381939769\n",
      "epoch: 6 step: 555, loss is 0.0029852879233658314\n",
      "epoch: 6 step: 556, loss is 0.094630166888237\n",
      "epoch: 6 step: 557, loss is 0.2825242578983307\n",
      "epoch: 6 step: 558, loss is 0.00019174649787601084\n",
      "epoch: 6 step: 559, loss is 9.245909313904122e-05\n",
      "epoch: 6 step: 560, loss is 0.052808646112680435\n",
      "epoch: 6 step: 561, loss is 0.03445987030863762\n",
      "epoch: 6 step: 562, loss is 0.0007436062442138791\n",
      "epoch: 6 step: 563, loss is 0.008321573957800865\n",
      "epoch: 6 step: 564, loss is 0.014054108411073685\n",
      "epoch: 6 step: 565, loss is 0.0028259640093892813\n",
      "epoch: 6 step: 566, loss is 0.0012201715726405382\n",
      "epoch: 6 step: 567, loss is 0.0008302775677293539\n",
      "epoch: 6 step: 568, loss is 0.0022014095447957516\n",
      "epoch: 6 step: 569, loss is 0.06954898685216904\n",
      "epoch: 6 step: 570, loss is 0.03479141741991043\n",
      "epoch: 6 step: 571, loss is 0.0004982365062460303\n",
      "epoch: 6 step: 572, loss is 0.012471118941903114\n",
      "epoch: 6 step: 573, loss is 0.010850317776203156\n",
      "epoch: 6 step: 574, loss is 0.00038372419658116996\n",
      "epoch: 6 step: 575, loss is 0.030880901962518692\n",
      "epoch: 6 step: 576, loss is 0.018321674317121506\n",
      "epoch: 6 step: 577, loss is 0.2637902498245239\n",
      "epoch: 6 step: 578, loss is 0.0007571371970698237\n",
      "epoch: 6 step: 579, loss is 0.0032347317319363356\n",
      "epoch: 6 step: 580, loss is 0.03209581598639488\n",
      "epoch: 6 step: 581, loss is 0.001626842305995524\n",
      "epoch: 6 step: 582, loss is 0.0004422398342285305\n",
      "epoch: 6 step: 583, loss is 0.019153323024511337\n",
      "epoch: 6 step: 584, loss is 0.0096137635409832\n",
      "epoch: 6 step: 585, loss is 0.03638741374015808\n",
      "epoch: 6 step: 586, loss is 0.21022158861160278\n",
      "epoch: 6 step: 587, loss is 0.013474185019731522\n",
      "epoch: 6 step: 588, loss is 0.002412404865026474\n",
      "epoch: 6 step: 589, loss is 0.0005430743331089616\n",
      "epoch: 6 step: 590, loss is 0.0002474052016623318\n",
      "epoch: 6 step: 591, loss is 0.00018089885998051614\n",
      "epoch: 6 step: 592, loss is 0.0034150558058172464\n",
      "epoch: 6 step: 593, loss is 0.0008861428359523416\n",
      "epoch: 6 step: 594, loss is 0.016179993748664856\n",
      "epoch: 6 step: 595, loss is 0.010139967314898968\n",
      "epoch: 6 step: 596, loss is 0.001906233956106007\n",
      "epoch: 6 step: 597, loss is 0.058239758014678955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 598, loss is 0.023782355710864067\n",
      "epoch: 6 step: 599, loss is 0.10155247896909714\n",
      "epoch: 6 step: 600, loss is 0.006430500652641058\n",
      "epoch: 6 step: 601, loss is 0.04844170808792114\n",
      "epoch: 6 step: 602, loss is 0.001370635349303484\n",
      "epoch: 6 step: 603, loss is 0.0004967778804711998\n",
      "epoch: 6 step: 604, loss is 0.1406586915254593\n",
      "epoch: 6 step: 605, loss is 0.00010708665649872273\n",
      "epoch: 6 step: 606, loss is 0.01499185711145401\n",
      "epoch: 6 step: 607, loss is 0.0019870614632964134\n",
      "epoch: 6 step: 608, loss is 0.0015692997258156538\n",
      "epoch: 6 step: 609, loss is 0.0530841089785099\n",
      "epoch: 6 step: 610, loss is 0.01779266819357872\n",
      "epoch: 6 step: 611, loss is 0.012051754631102085\n",
      "epoch: 6 step: 612, loss is 0.0056890505366027355\n",
      "epoch: 6 step: 613, loss is 0.012853538617491722\n",
      "epoch: 6 step: 614, loss is 0.007920215837657452\n",
      "epoch: 6 step: 615, loss is 0.006413882132619619\n",
      "epoch: 6 step: 616, loss is 0.0007221066043712199\n",
      "epoch: 6 step: 617, loss is 0.0015030470676720142\n",
      "epoch: 6 step: 618, loss is 0.0030371397733688354\n",
      "epoch: 6 step: 619, loss is 0.0005786622641608119\n",
      "epoch: 6 step: 620, loss is 0.0002884749264921993\n",
      "epoch: 6 step: 621, loss is 0.0024424989242106676\n",
      "epoch: 6 step: 622, loss is 0.03666877746582031\n",
      "epoch: 6 step: 623, loss is 0.0009894343093037605\n",
      "epoch: 6 step: 624, loss is 0.012274167500436306\n",
      "epoch: 6 step: 625, loss is 0.12061024457216263\n",
      "epoch: 6 step: 626, loss is 0.07090479135513306\n",
      "epoch: 6 step: 627, loss is 0.0024303069803863764\n",
      "epoch: 6 step: 628, loss is 0.07271258533000946\n",
      "epoch: 6 step: 629, loss is 0.018367264419794083\n",
      "epoch: 6 step: 630, loss is 0.004348967224359512\n",
      "epoch: 6 step: 631, loss is 0.006212611682713032\n",
      "epoch: 6 step: 632, loss is 0.004130078945308924\n",
      "epoch: 6 step: 633, loss is 0.008189069107174873\n",
      "epoch: 6 step: 634, loss is 0.009734043851494789\n",
      "epoch: 6 step: 635, loss is 0.005903568584471941\n",
      "epoch: 6 step: 636, loss is 0.011144387535750866\n",
      "epoch: 6 step: 637, loss is 0.0003756046062335372\n",
      "epoch: 6 step: 638, loss is 0.02200961299240589\n",
      "epoch: 6 step: 639, loss is 0.0011050866451114416\n",
      "epoch: 6 step: 640, loss is 0.000483205309137702\n",
      "epoch: 6 step: 641, loss is 0.08928334712982178\n",
      "epoch: 6 step: 642, loss is 0.022277848795056343\n",
      "epoch: 6 step: 643, loss is 0.00124836852774024\n",
      "epoch: 6 step: 644, loss is 0.014718006365001202\n",
      "epoch: 6 step: 645, loss is 0.0015057220589369535\n",
      "epoch: 6 step: 646, loss is 0.024296747520565987\n",
      "epoch: 6 step: 647, loss is 0.0006175515009090304\n",
      "epoch: 6 step: 648, loss is 0.00027881914866156876\n",
      "epoch: 6 step: 649, loss is 0.0001677915279287845\n",
      "epoch: 6 step: 650, loss is 0.0007209227769635618\n",
      "epoch: 6 step: 651, loss is 0.008847001940011978\n",
      "epoch: 6 step: 652, loss is 0.00046296956134028733\n",
      "epoch: 6 step: 653, loss is 0.011687313206493855\n",
      "epoch: 6 step: 654, loss is 0.05729714408516884\n",
      "epoch: 6 step: 655, loss is 0.004607051610946655\n",
      "epoch: 6 step: 656, loss is 0.00023248746583703905\n",
      "epoch: 6 step: 657, loss is 0.020566415041685104\n",
      "epoch: 6 step: 658, loss is 0.00016958020569290966\n",
      "epoch: 6 step: 659, loss is 0.0006082985200919211\n",
      "epoch: 6 step: 660, loss is 0.00012682647502515465\n",
      "epoch: 6 step: 661, loss is 0.006543813273310661\n",
      "epoch: 6 step: 662, loss is 0.011908300220966339\n",
      "epoch: 6 step: 663, loss is 0.125568225979805\n",
      "epoch: 6 step: 664, loss is 0.09877163171768188\n",
      "epoch: 6 step: 665, loss is 0.012274406850337982\n",
      "epoch: 6 step: 666, loss is 0.036083757877349854\n",
      "epoch: 6 step: 667, loss is 0.0010405763750895858\n",
      "epoch: 6 step: 668, loss is 0.0060780467465519905\n",
      "epoch: 6 step: 669, loss is 0.003892553271725774\n",
      "epoch: 6 step: 670, loss is 0.01771433651447296\n",
      "epoch: 6 step: 671, loss is 0.002963337581604719\n",
      "epoch: 6 step: 672, loss is 0.008323661983013153\n",
      "epoch: 6 step: 673, loss is 0.010679446160793304\n",
      "epoch: 6 step: 674, loss is 4.43137287220452e-05\n",
      "epoch: 6 step: 675, loss is 0.011402111500501633\n",
      "epoch: 6 step: 676, loss is 0.13370457291603088\n",
      "epoch: 6 step: 677, loss is 0.0005614717956632376\n",
      "epoch: 6 step: 678, loss is 0.0002287774987053126\n",
      "epoch: 6 step: 679, loss is 0.0004169500607531518\n",
      "epoch: 6 step: 680, loss is 0.052181895822286606\n",
      "epoch: 6 step: 681, loss is 0.043699540197849274\n",
      "epoch: 6 step: 682, loss is 0.020812539383769035\n",
      "epoch: 6 step: 683, loss is 0.0032443501986563206\n",
      "epoch: 6 step: 684, loss is 0.0052498397417366505\n",
      "epoch: 6 step: 685, loss is 0.028141092509031296\n",
      "epoch: 6 step: 686, loss is 0.0001045056851580739\n",
      "epoch: 6 step: 687, loss is 0.013588236644864082\n",
      "epoch: 6 step: 688, loss is 0.007227037567645311\n",
      "epoch: 6 step: 689, loss is 0.009633422829210758\n",
      "epoch: 6 step: 690, loss is 0.005635169800370932\n",
      "epoch: 6 step: 691, loss is 0.007752582430839539\n",
      "epoch: 6 step: 692, loss is 0.05578099563717842\n",
      "epoch: 6 step: 693, loss is 0.07290242612361908\n",
      "epoch: 6 step: 694, loss is 0.0015738680958747864\n",
      "epoch: 6 step: 695, loss is 0.010089247487485409\n",
      "epoch: 6 step: 696, loss is 0.12934640049934387\n",
      "epoch: 6 step: 697, loss is 0.011424707248806953\n",
      "epoch: 6 step: 698, loss is 0.013018541038036346\n",
      "epoch: 6 step: 699, loss is 0.0007203748682513833\n",
      "epoch: 6 step: 700, loss is 0.0013240814441815019\n",
      "epoch: 6 step: 701, loss is 0.0005237839068286121\n",
      "epoch: 6 step: 702, loss is 0.0011391752632334828\n",
      "epoch: 6 step: 703, loss is 0.00469785975292325\n",
      "epoch: 6 step: 704, loss is 0.03563655540347099\n",
      "epoch: 6 step: 705, loss is 0.1190628781914711\n",
      "epoch: 6 step: 706, loss is 0.09348969906568527\n",
      "epoch: 6 step: 707, loss is 0.08021555095911026\n",
      "epoch: 6 step: 708, loss is 0.0038274433463811874\n",
      "epoch: 6 step: 709, loss is 0.0002683255879674107\n",
      "epoch: 6 step: 710, loss is 0.0034076704178005457\n",
      "epoch: 6 step: 711, loss is 0.0006695993361063302\n",
      "epoch: 6 step: 712, loss is 0.022901102900505066\n",
      "epoch: 6 step: 713, loss is 0.04020247980952263\n",
      "epoch: 6 step: 714, loss is 0.0005876036593690515\n",
      "epoch: 6 step: 715, loss is 0.005650617647916079\n",
      "epoch: 6 step: 716, loss is 0.009830232709646225\n",
      "epoch: 6 step: 717, loss is 0.00803549587726593\n",
      "epoch: 6 step: 718, loss is 0.004664189647883177\n",
      "epoch: 6 step: 719, loss is 0.0010349963558837771\n",
      "epoch: 6 step: 720, loss is 0.06398455798625946\n",
      "epoch: 6 step: 721, loss is 0.005868259817361832\n",
      "epoch: 6 step: 722, loss is 7.299623393919319e-05\n",
      "epoch: 6 step: 723, loss is 0.019814016297459602\n",
      "epoch: 6 step: 724, loss is 0.07592026889324188\n",
      "epoch: 6 step: 725, loss is 0.022154664620757103\n",
      "epoch: 6 step: 726, loss is 0.008255203254520893\n",
      "epoch: 6 step: 727, loss is 0.00852627120912075\n",
      "epoch: 6 step: 728, loss is 0.11833074688911438\n",
      "epoch: 6 step: 729, loss is 0.00053475919412449\n",
      "epoch: 6 step: 730, loss is 0.00033234705915674567\n",
      "epoch: 6 step: 731, loss is 0.15557096898555756\n",
      "epoch: 6 step: 732, loss is 0.008137316443026066\n",
      "epoch: 6 step: 733, loss is 0.0009666107944212854\n",
      "epoch: 6 step: 734, loss is 0.003685170551761985\n",
      "epoch: 6 step: 735, loss is 0.0049081165343523026\n",
      "epoch: 6 step: 736, loss is 0.06312885880470276\n",
      "epoch: 6 step: 737, loss is 0.002721860771998763\n",
      "epoch: 6 step: 738, loss is 0.0027899371925741434\n",
      "epoch: 6 step: 739, loss is 0.042430274188518524\n",
      "epoch: 6 step: 740, loss is 0.0024176205042749643\n",
      "epoch: 6 step: 741, loss is 0.010881348513066769\n",
      "epoch: 6 step: 742, loss is 0.004162202589213848\n",
      "epoch: 6 step: 743, loss is 0.06071314588189125\n",
      "epoch: 6 step: 744, loss is 0.0009900639997795224\n",
      "epoch: 6 step: 745, loss is 0.0015690360451117158\n",
      "epoch: 6 step: 746, loss is 0.009219587780535221\n",
      "epoch: 6 step: 747, loss is 0.18959490954875946\n",
      "epoch: 6 step: 748, loss is 0.002235212130472064\n",
      "epoch: 6 step: 749, loss is 0.0006293242913670838\n",
      "epoch: 6 step: 750, loss is 0.0005689404206350446\n",
      "epoch: 6 step: 751, loss is 0.016404343768954277\n",
      "epoch: 6 step: 752, loss is 0.0040885889902710915\n",
      "epoch: 6 step: 753, loss is 0.025095682591199875\n",
      "epoch: 6 step: 754, loss is 0.03074226714670658\n",
      "epoch: 6 step: 755, loss is 0.0014678320148959756\n",
      "epoch: 6 step: 756, loss is 0.0016138541977852583\n",
      "epoch: 6 step: 757, loss is 0.1732769012451172\n",
      "epoch: 6 step: 758, loss is 0.16262121498584747\n",
      "epoch: 6 step: 759, loss is 0.0012729635927826166\n",
      "epoch: 6 step: 760, loss is 0.0003720320528373122\n",
      "epoch: 6 step: 761, loss is 0.005828771740198135\n",
      "epoch: 6 step: 762, loss is 0.0030899771954864264\n",
      "epoch: 6 step: 763, loss is 0.003116206731647253\n",
      "epoch: 6 step: 764, loss is 0.03065069578588009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 765, loss is 0.09916450083255768\n",
      "epoch: 6 step: 766, loss is 0.0214563999325037\n",
      "epoch: 6 step: 767, loss is 0.00010878287866944447\n",
      "epoch: 6 step: 768, loss is 0.0031432807445526123\n",
      "epoch: 6 step: 769, loss is 0.0037705169524997473\n",
      "epoch: 6 step: 770, loss is 0.0004006297676824033\n",
      "epoch: 6 step: 771, loss is 0.1065831333398819\n",
      "epoch: 6 step: 772, loss is 0.0034300200641155243\n",
      "epoch: 6 step: 773, loss is 0.025194933637976646\n",
      "epoch: 6 step: 774, loss is 0.0026949094608426094\n",
      "epoch: 6 step: 775, loss is 0.04711446166038513\n",
      "epoch: 6 step: 776, loss is 0.0056105791591107845\n",
      "epoch: 6 step: 777, loss is 0.008449885062873363\n",
      "epoch: 6 step: 778, loss is 0.0773174837231636\n",
      "epoch: 6 step: 779, loss is 0.0029525146819651127\n",
      "epoch: 6 step: 780, loss is 0.00531220156699419\n",
      "epoch: 6 step: 781, loss is 0.0005608474602922797\n",
      "epoch: 6 step: 782, loss is 0.0008878347580321133\n",
      "epoch: 6 step: 783, loss is 0.0012247641570866108\n",
      "epoch: 6 step: 784, loss is 0.0014337495667859912\n",
      "epoch: 6 step: 785, loss is 0.001113104517571628\n",
      "epoch: 6 step: 786, loss is 0.0006775217480026186\n",
      "epoch: 6 step: 787, loss is 0.003372996812686324\n",
      "epoch: 6 step: 788, loss is 0.0010437378659844398\n",
      "epoch: 6 step: 789, loss is 0.007914268411695957\n",
      "epoch: 6 step: 790, loss is 0.0011872283648699522\n",
      "epoch: 6 step: 791, loss is 0.004165132064372301\n",
      "epoch: 6 step: 792, loss is 0.0003024192701559514\n",
      "epoch: 6 step: 793, loss is 0.01157680619508028\n",
      "epoch: 6 step: 794, loss is 0.0011986353201791644\n",
      "epoch: 6 step: 795, loss is 0.044425565749406815\n",
      "epoch: 6 step: 796, loss is 0.00044882649672217667\n",
      "epoch: 6 step: 797, loss is 0.052694860845804214\n",
      "epoch: 6 step: 798, loss is 0.038348667323589325\n",
      "epoch: 6 step: 799, loss is 0.003171399235725403\n",
      "epoch: 6 step: 800, loss is 0.007227757014334202\n",
      "epoch: 6 step: 801, loss is 0.012137552723288536\n",
      "epoch: 6 step: 802, loss is 0.008261403068900108\n",
      "epoch: 6 step: 803, loss is 0.0005211431416682899\n",
      "epoch: 6 step: 804, loss is 0.006431177724152803\n",
      "epoch: 6 step: 805, loss is 0.0021512529347091913\n",
      "epoch: 6 step: 806, loss is 0.0013528666459023952\n",
      "epoch: 6 step: 807, loss is 0.014225516468286514\n",
      "epoch: 6 step: 808, loss is 0.02174069918692112\n",
      "epoch: 6 step: 809, loss is 0.005550002679228783\n",
      "epoch: 6 step: 810, loss is 0.0008719058241695166\n",
      "epoch: 6 step: 811, loss is 0.00019471127598080784\n",
      "epoch: 6 step: 812, loss is 0.0006551587139256299\n",
      "epoch: 6 step: 813, loss is 0.008739323355257511\n",
      "epoch: 6 step: 814, loss is 0.007003748323768377\n",
      "epoch: 6 step: 815, loss is 0.0012030372163280845\n",
      "epoch: 6 step: 816, loss is 0.00115635572001338\n",
      "epoch: 6 step: 817, loss is 0.007404864765703678\n",
      "epoch: 6 step: 818, loss is 0.026377256959676743\n",
      "epoch: 6 step: 819, loss is 0.0011968630133196712\n",
      "epoch: 6 step: 820, loss is 0.027350932359695435\n",
      "epoch: 6 step: 821, loss is 8.929346222430468e-05\n",
      "epoch: 6 step: 822, loss is 0.0005266807856969535\n",
      "epoch: 6 step: 823, loss is 0.0004467392573133111\n",
      "epoch: 6 step: 824, loss is 0.001086386851966381\n",
      "epoch: 6 step: 825, loss is 0.04281369224190712\n",
      "epoch: 6 step: 826, loss is 0.007282630540430546\n",
      "epoch: 6 step: 827, loss is 0.1362893432378769\n",
      "epoch: 6 step: 828, loss is 0.0009303658152930439\n",
      "epoch: 6 step: 829, loss is 0.06000662222504616\n",
      "epoch: 6 step: 830, loss is 0.01916820928454399\n",
      "epoch: 6 step: 831, loss is 0.002469778759405017\n",
      "epoch: 6 step: 832, loss is 0.018603762611746788\n",
      "epoch: 6 step: 833, loss is 0.0031216463539749384\n",
      "epoch: 6 step: 834, loss is 0.10153655707836151\n",
      "epoch: 6 step: 835, loss is 0.0006997042219154537\n",
      "epoch: 6 step: 836, loss is 0.003369380719959736\n",
      "epoch: 6 step: 837, loss is 0.00014897763321641833\n",
      "epoch: 6 step: 838, loss is 0.002791664795950055\n",
      "epoch: 6 step: 839, loss is 0.015338472090661526\n",
      "epoch: 6 step: 840, loss is 0.017909567803144455\n",
      "epoch: 6 step: 841, loss is 0.005050022155046463\n",
      "epoch: 6 step: 842, loss is 0.0006273488397710025\n",
      "epoch: 6 step: 843, loss is 0.003986021038144827\n",
      "epoch: 6 step: 844, loss is 0.1092846691608429\n",
      "epoch: 6 step: 845, loss is 4.6806213504169136e-05\n",
      "epoch: 6 step: 846, loss is 0.00029331305995583534\n",
      "epoch: 6 step: 847, loss is 0.0013182430993765593\n",
      "epoch: 6 step: 848, loss is 1.4119485967967194e-05\n",
      "epoch: 6 step: 849, loss is 0.0034011416137218475\n",
      "epoch: 6 step: 850, loss is 0.10702991485595703\n",
      "epoch: 6 step: 851, loss is 0.0006473992834798992\n",
      "epoch: 6 step: 852, loss is 0.0003079232410527766\n",
      "epoch: 6 step: 853, loss is 0.022134041413664818\n",
      "epoch: 6 step: 854, loss is 7.772001845296472e-05\n",
      "epoch: 6 step: 855, loss is 0.1161234974861145\n",
      "epoch: 6 step: 856, loss is 0.01212820690125227\n",
      "epoch: 6 step: 857, loss is 0.036798540502786636\n",
      "epoch: 6 step: 858, loss is 0.026997586712241173\n",
      "epoch: 6 step: 859, loss is 0.008681105449795723\n",
      "epoch: 6 step: 860, loss is 0.0025509896222501993\n",
      "epoch: 6 step: 861, loss is 0.04566827043890953\n",
      "epoch: 6 step: 862, loss is 0.00015747660654596984\n",
      "epoch: 6 step: 863, loss is 0.0023084941785782576\n",
      "epoch: 6 step: 864, loss is 9.320470417151228e-05\n",
      "epoch: 6 step: 865, loss is 0.008217651396989822\n",
      "epoch: 6 step: 866, loss is 0.05756453052163124\n",
      "epoch: 6 step: 867, loss is 0.006761210039258003\n",
      "epoch: 6 step: 868, loss is 0.00030666490783914924\n",
      "epoch: 6 step: 869, loss is 0.025777069851756096\n",
      "epoch: 6 step: 870, loss is 0.002363208681344986\n",
      "epoch: 6 step: 871, loss is 0.01684536226093769\n",
      "epoch: 6 step: 872, loss is 0.0027131515089422464\n",
      "epoch: 6 step: 873, loss is 0.0007752255187369883\n",
      "epoch: 6 step: 874, loss is 0.00508534349501133\n",
      "epoch: 6 step: 875, loss is 0.0004609604075085372\n",
      "epoch: 6 step: 876, loss is 0.00010047811520053074\n",
      "epoch: 6 step: 877, loss is 0.0028010811656713486\n",
      "epoch: 6 step: 878, loss is 0.003311475971713662\n",
      "epoch: 6 step: 879, loss is 0.0028557106852531433\n",
      "epoch: 6 step: 880, loss is 0.012047858908772469\n",
      "epoch: 6 step: 881, loss is 0.006872010882943869\n",
      "epoch: 6 step: 882, loss is 0.005106092896312475\n",
      "epoch: 6 step: 883, loss is 0.0009475405677221715\n",
      "epoch: 6 step: 884, loss is 0.01613433286547661\n",
      "epoch: 6 step: 885, loss is 0.016668401658535004\n",
      "epoch: 6 step: 886, loss is 0.011767938733100891\n",
      "epoch: 6 step: 887, loss is 0.005176234990358353\n",
      "epoch: 6 step: 888, loss is 0.0008790182764641941\n",
      "epoch: 6 step: 889, loss is 0.0019474830478429794\n",
      "epoch: 6 step: 890, loss is 0.00010500123607926071\n",
      "epoch: 6 step: 891, loss is 0.00019151966262143105\n",
      "epoch: 6 step: 892, loss is 0.14727890491485596\n",
      "epoch: 6 step: 893, loss is 0.004895064979791641\n",
      "epoch: 6 step: 894, loss is 0.01077321171760559\n",
      "epoch: 6 step: 895, loss is 0.005055894143879414\n",
      "epoch: 6 step: 896, loss is 0.0027966764755547047\n",
      "epoch: 6 step: 897, loss is 0.0017978270770981908\n",
      "epoch: 6 step: 898, loss is 0.0014064224669709802\n",
      "epoch: 6 step: 899, loss is 0.02277444489300251\n",
      "epoch: 6 step: 900, loss is 0.001783131156116724\n",
      "epoch: 6 step: 901, loss is 0.12153548002243042\n",
      "epoch: 6 step: 902, loss is 0.0028113857842981815\n",
      "epoch: 6 step: 903, loss is 0.00023900925589259714\n",
      "epoch: 6 step: 904, loss is 0.0009486803319305182\n",
      "epoch: 6 step: 905, loss is 0.08973678201436996\n",
      "epoch: 6 step: 906, loss is 3.849912900477648e-05\n",
      "epoch: 6 step: 907, loss is 0.03828159719705582\n",
      "epoch: 6 step: 908, loss is 0.02319798246026039\n",
      "epoch: 6 step: 909, loss is 0.004698449280112982\n",
      "epoch: 6 step: 910, loss is 0.0008591520600020885\n",
      "epoch: 6 step: 911, loss is 0.019812582060694695\n",
      "epoch: 6 step: 912, loss is 4.8872803745325655e-05\n",
      "epoch: 6 step: 913, loss is 0.033173490315675735\n",
      "epoch: 6 step: 914, loss is 0.018733996897935867\n",
      "epoch: 6 step: 915, loss is 0.0002614968689158559\n",
      "epoch: 6 step: 916, loss is 0.06442909687757492\n",
      "epoch: 6 step: 917, loss is 0.0004744778561871499\n",
      "epoch: 6 step: 918, loss is 0.0041035315953195095\n",
      "epoch: 6 step: 919, loss is 0.0022073457948863506\n",
      "epoch: 6 step: 920, loss is 0.0006775620277039707\n",
      "epoch: 6 step: 921, loss is 0.005263858009129763\n",
      "epoch: 6 step: 922, loss is 0.044638581573963165\n",
      "epoch: 6 step: 923, loss is 0.04046853631734848\n",
      "epoch: 6 step: 924, loss is 0.0008317818865180016\n",
      "epoch: 6 step: 925, loss is 0.00027524802135303617\n",
      "epoch: 6 step: 926, loss is 0.0002848446019925177\n",
      "epoch: 6 step: 927, loss is 0.00015467537741642445\n",
      "epoch: 6 step: 928, loss is 0.0013609265442937613\n",
      "epoch: 6 step: 929, loss is 0.006073188968002796\n",
      "epoch: 6 step: 930, loss is 0.0037660461384803057\n",
      "epoch: 6 step: 931, loss is 2.965258499898482e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 932, loss is 0.0005363494856283069\n",
      "epoch: 6 step: 933, loss is 0.017933476716279984\n",
      "epoch: 6 step: 934, loss is 0.00013468465476762503\n",
      "epoch: 6 step: 935, loss is 0.03505619615316391\n",
      "epoch: 6 step: 936, loss is 0.0005470272735692561\n",
      "epoch: 6 step: 937, loss is 0.0019694920629262924\n",
      "epoch: 6 step: 938, loss is 0.00014494160132016987\n",
      "epoch: 6 step: 939, loss is 0.003572799265384674\n",
      "epoch: 6 step: 940, loss is 0.00034534247242845595\n",
      "epoch: 6 step: 941, loss is 0.0004522491944953799\n",
      "epoch: 6 step: 942, loss is 0.005352908279746771\n",
      "epoch: 6 step: 943, loss is 0.03567750006914139\n",
      "epoch: 6 step: 944, loss is 0.0015641044592484832\n",
      "epoch: 6 step: 945, loss is 0.0029932919424027205\n",
      "epoch: 6 step: 946, loss is 0.012211035005748272\n",
      "epoch: 6 step: 947, loss is 0.0006407481851056218\n",
      "epoch: 6 step: 948, loss is 0.0006160723860375583\n",
      "epoch: 6 step: 949, loss is 0.0008356171892955899\n",
      "epoch: 6 step: 950, loss is 0.0024233346339315176\n",
      "epoch: 6 step: 951, loss is 0.00010158165969187394\n",
      "epoch: 6 step: 952, loss is 0.0034195708576589823\n",
      "epoch: 6 step: 953, loss is 0.0002920088591054082\n",
      "epoch: 6 step: 954, loss is 2.908352507802192e-05\n",
      "epoch: 6 step: 955, loss is 0.006461771205067635\n",
      "epoch: 6 step: 956, loss is 0.01249662321060896\n",
      "epoch: 6 step: 957, loss is 9.208088158629835e-05\n",
      "epoch: 6 step: 958, loss is 0.0001627219025976956\n",
      "epoch: 6 step: 959, loss is 0.00034169034915976226\n",
      "epoch: 6 step: 960, loss is 0.0064279246143996716\n",
      "epoch: 6 step: 961, loss is 0.001339384471066296\n",
      "epoch: 6 step: 962, loss is 0.0009359515970572829\n",
      "epoch: 6 step: 963, loss is 0.07763274013996124\n",
      "epoch: 6 step: 964, loss is 0.0396137498319149\n",
      "epoch: 6 step: 965, loss is 0.145894855260849\n",
      "epoch: 6 step: 966, loss is 0.0005600645090453327\n",
      "epoch: 6 step: 967, loss is 0.004531421698629856\n",
      "epoch: 6 step: 968, loss is 0.00032511926838196814\n",
      "epoch: 6 step: 969, loss is 0.003245655447244644\n",
      "epoch: 6 step: 970, loss is 7.427508535329252e-05\n",
      "epoch: 6 step: 971, loss is 0.0022798923309892416\n",
      "epoch: 6 step: 972, loss is 0.0001731147785903886\n",
      "epoch: 6 step: 973, loss is 0.009705941192805767\n",
      "epoch: 6 step: 974, loss is 0.0008099687402136624\n",
      "epoch: 6 step: 975, loss is 6.363763532135636e-05\n",
      "epoch: 6 step: 976, loss is 0.010388555005192757\n",
      "epoch: 6 step: 977, loss is 0.06498316675424576\n",
      "epoch: 6 step: 978, loss is 0.00047918836935423315\n",
      "epoch: 6 step: 979, loss is 0.00012327914009802043\n",
      "epoch: 6 step: 980, loss is 0.02665708214044571\n",
      "epoch: 6 step: 981, loss is 0.0003451306838542223\n",
      "epoch: 6 step: 982, loss is 0.00012919881555717438\n",
      "epoch: 6 step: 983, loss is 0.0008283136994577944\n",
      "epoch: 6 step: 984, loss is 0.006327836308628321\n",
      "epoch: 6 step: 985, loss is 0.0006075858836993575\n",
      "epoch: 6 step: 986, loss is 0.0020117193926125765\n",
      "epoch: 6 step: 987, loss is 0.002051240997388959\n",
      "epoch: 6 step: 988, loss is 0.07648171484470367\n",
      "epoch: 6 step: 989, loss is 0.001189746311865747\n",
      "epoch: 6 step: 990, loss is 0.00037624628748744726\n",
      "epoch: 6 step: 991, loss is 8.178936695912853e-05\n",
      "epoch: 6 step: 992, loss is 0.00638157082721591\n",
      "epoch: 6 step: 993, loss is 0.000787243596278131\n",
      "epoch: 6 step: 994, loss is 0.002815954852849245\n",
      "epoch: 6 step: 995, loss is 0.008155576884746552\n",
      "epoch: 6 step: 996, loss is 0.008394233882427216\n",
      "epoch: 6 step: 997, loss is 0.032188814133405685\n",
      "epoch: 6 step: 998, loss is 0.0005968048935756087\n",
      "epoch: 6 step: 999, loss is 0.00039903889410197735\n",
      "epoch: 6 step: 1000, loss is 0.03616437688469887\n",
      "epoch: 6 step: 1001, loss is 0.04879356920719147\n",
      "epoch: 6 step: 1002, loss is 0.005272789858281612\n",
      "epoch: 6 step: 1003, loss is 0.013176788575947285\n",
      "epoch: 6 step: 1004, loss is 0.009472551755607128\n",
      "epoch: 6 step: 1005, loss is 0.04093189537525177\n",
      "epoch: 6 step: 1006, loss is 0.049625180661678314\n",
      "epoch: 6 step: 1007, loss is 1.6547539416933432e-05\n",
      "epoch: 6 step: 1008, loss is 0.018939731642603874\n",
      "epoch: 6 step: 1009, loss is 0.0034706536680459976\n",
      "epoch: 6 step: 1010, loss is 0.13384127616882324\n",
      "epoch: 6 step: 1011, loss is 0.008810666389763355\n",
      "epoch: 6 step: 1012, loss is 0.00508774584159255\n",
      "epoch: 6 step: 1013, loss is 0.0003233911993447691\n",
      "epoch: 6 step: 1014, loss is 0.013539373874664307\n",
      "epoch: 6 step: 1015, loss is 0.013472282327711582\n",
      "epoch: 6 step: 1016, loss is 0.0001227621833095327\n",
      "epoch: 6 step: 1017, loss is 0.0013554025208577514\n",
      "epoch: 6 step: 1018, loss is 0.001449105329811573\n",
      "epoch: 6 step: 1019, loss is 0.017400385811924934\n",
      "epoch: 6 step: 1020, loss is 0.002238882938399911\n",
      "epoch: 6 step: 1021, loss is 0.016956398263573647\n",
      "epoch: 6 step: 1022, loss is 0.00041239510755985975\n",
      "epoch: 6 step: 1023, loss is 3.440168802626431e-05\n",
      "epoch: 6 step: 1024, loss is 0.027461163699626923\n",
      "epoch: 6 step: 1025, loss is 0.00034954064176417887\n",
      "epoch: 6 step: 1026, loss is 0.04395649954676628\n",
      "epoch: 6 step: 1027, loss is 0.129041388630867\n",
      "epoch: 6 step: 1028, loss is 0.03817076236009598\n",
      "epoch: 6 step: 1029, loss is 0.03568216785788536\n",
      "epoch: 6 step: 1030, loss is 0.0011224456829950213\n",
      "epoch: 6 step: 1031, loss is 0.0014294191496446729\n",
      "epoch: 6 step: 1032, loss is 0.0053001451306045055\n",
      "epoch: 6 step: 1033, loss is 1.5265239198924974e-05\n",
      "epoch: 6 step: 1034, loss is 0.04183834418654442\n",
      "epoch: 6 step: 1035, loss is 0.0010665800655260682\n",
      "epoch: 6 step: 1036, loss is 0.034183673560619354\n",
      "epoch: 6 step: 1037, loss is 0.0016678499523550272\n",
      "epoch: 6 step: 1038, loss is 0.0003821177233476192\n",
      "epoch: 6 step: 1039, loss is 0.012456302531063557\n",
      "epoch: 6 step: 1040, loss is 8.304804214276373e-05\n",
      "epoch: 6 step: 1041, loss is 0.02175135351717472\n",
      "epoch: 6 step: 1042, loss is 0.0008947263122536242\n",
      "epoch: 6 step: 1043, loss is 0.001938653877004981\n",
      "epoch: 6 step: 1044, loss is 0.09499674290418625\n",
      "epoch: 6 step: 1045, loss is 0.0007215948426164687\n",
      "epoch: 6 step: 1046, loss is 0.022769104689359665\n",
      "epoch: 6 step: 1047, loss is 0.16485822200775146\n",
      "epoch: 6 step: 1048, loss is 0.0023877075873315334\n",
      "epoch: 6 step: 1049, loss is 2.3821525246603414e-05\n",
      "epoch: 6 step: 1050, loss is 0.001633055624552071\n",
      "epoch: 6 step: 1051, loss is 0.03560902550816536\n",
      "epoch: 6 step: 1052, loss is 0.002175569301471114\n",
      "epoch: 6 step: 1053, loss is 0.22327269613742828\n",
      "epoch: 6 step: 1054, loss is 0.012566177174448967\n",
      "epoch: 6 step: 1055, loss is 0.0070287929847836494\n",
      "epoch: 6 step: 1056, loss is 0.008240018971264362\n",
      "epoch: 6 step: 1057, loss is 0.009713306091725826\n",
      "epoch: 6 step: 1058, loss is 0.052403632551431656\n",
      "epoch: 6 step: 1059, loss is 0.05860811471939087\n",
      "epoch: 6 step: 1060, loss is 0.0015303759137168527\n",
      "epoch: 6 step: 1061, loss is 0.16636066138744354\n",
      "epoch: 6 step: 1062, loss is 0.0014652576064690948\n",
      "epoch: 6 step: 1063, loss is 0.20434395968914032\n",
      "epoch: 6 step: 1064, loss is 0.007632284890860319\n",
      "epoch: 6 step: 1065, loss is 0.20845694839954376\n",
      "epoch: 6 step: 1066, loss is 0.006101509556174278\n",
      "epoch: 6 step: 1067, loss is 0.0018441701540723443\n",
      "epoch: 6 step: 1068, loss is 0.08466336131095886\n",
      "epoch: 6 step: 1069, loss is 0.0003823194419965148\n",
      "epoch: 6 step: 1070, loss is 0.0006642937078140676\n",
      "epoch: 6 step: 1071, loss is 0.013457716442644596\n",
      "epoch: 6 step: 1072, loss is 0.009816224686801434\n",
      "epoch: 6 step: 1073, loss is 0.026013825088739395\n",
      "epoch: 6 step: 1074, loss is 0.001757846213877201\n",
      "epoch: 6 step: 1075, loss is 0.051015034317970276\n",
      "epoch: 6 step: 1076, loss is 0.004648631904274225\n",
      "epoch: 6 step: 1077, loss is 0.000596625788602978\n",
      "epoch: 6 step: 1078, loss is 0.0005176553386263549\n",
      "epoch: 6 step: 1079, loss is 0.0002586250484455377\n",
      "epoch: 6 step: 1080, loss is 0.0011389157734811306\n",
      "epoch: 6 step: 1081, loss is 0.015104744583368301\n",
      "epoch: 6 step: 1082, loss is 0.034916382282972336\n",
      "epoch: 6 step: 1083, loss is 0.00794162880629301\n",
      "epoch: 6 step: 1084, loss is 0.010715672746300697\n",
      "epoch: 6 step: 1085, loss is 0.009341510944068432\n",
      "epoch: 6 step: 1086, loss is 0.0075351158156991005\n",
      "epoch: 6 step: 1087, loss is 0.00860476866364479\n",
      "epoch: 6 step: 1088, loss is 9.629283886170015e-05\n",
      "epoch: 6 step: 1089, loss is 0.0013161925598978996\n",
      "epoch: 6 step: 1090, loss is 0.02023189701139927\n",
      "epoch: 6 step: 1091, loss is 0.0013423159252852201\n",
      "epoch: 6 step: 1092, loss is 0.02614631876349449\n",
      "epoch: 6 step: 1093, loss is 0.022765591740608215\n",
      "epoch: 6 step: 1094, loss is 0.0005401796079240739\n",
      "epoch: 6 step: 1095, loss is 0.14888931810855865\n",
      "epoch: 6 step: 1096, loss is 0.018010014668107033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1097, loss is 0.0003976905718445778\n",
      "epoch: 6 step: 1098, loss is 0.058530647307634354\n",
      "epoch: 6 step: 1099, loss is 5.6497356126783416e-05\n",
      "epoch: 6 step: 1100, loss is 0.0187783595174551\n",
      "epoch: 6 step: 1101, loss is 0.002998743671923876\n",
      "epoch: 6 step: 1102, loss is 0.0002757807669695467\n",
      "epoch: 6 step: 1103, loss is 0.00026649737264961004\n",
      "epoch: 6 step: 1104, loss is 0.00014606531476601958\n",
      "epoch: 6 step: 1105, loss is 0.0005141861038282514\n",
      "epoch: 6 step: 1106, loss is 0.0011799228377640247\n",
      "epoch: 6 step: 1107, loss is 0.004724771250039339\n",
      "epoch: 6 step: 1108, loss is 0.039723873138427734\n",
      "epoch: 6 step: 1109, loss is 0.003158119274303317\n",
      "epoch: 6 step: 1110, loss is 0.0004065932589583099\n",
      "epoch: 6 step: 1111, loss is 0.010839271359145641\n",
      "epoch: 6 step: 1112, loss is 0.006409002933651209\n",
      "epoch: 6 step: 1113, loss is 0.04170304164290428\n",
      "epoch: 6 step: 1114, loss is 0.0010786782950162888\n",
      "epoch: 6 step: 1115, loss is 0.004527668468654156\n",
      "epoch: 6 step: 1116, loss is 0.00010310434299753979\n",
      "epoch: 6 step: 1117, loss is 0.014223789796233177\n",
      "epoch: 6 step: 1118, loss is 0.011198810301721096\n",
      "epoch: 6 step: 1119, loss is 0.0011694420827552676\n",
      "epoch: 6 step: 1120, loss is 0.000288930197712034\n",
      "epoch: 6 step: 1121, loss is 0.003663745941594243\n",
      "epoch: 6 step: 1122, loss is 0.009778361767530441\n",
      "epoch: 6 step: 1123, loss is 0.0020172304939478636\n",
      "epoch: 6 step: 1124, loss is 0.0002571325749158859\n",
      "epoch: 6 step: 1125, loss is 0.027601338922977448\n",
      "epoch: 6 step: 1126, loss is 0.0002887406444642693\n",
      "epoch: 6 step: 1127, loss is 0.005500368308275938\n",
      "epoch: 6 step: 1128, loss is 0.006856889463961124\n",
      "epoch: 6 step: 1129, loss is 0.0007999817607924342\n",
      "epoch: 6 step: 1130, loss is 0.00023382389917969704\n",
      "epoch: 6 step: 1131, loss is 0.0007052088039927185\n",
      "epoch: 6 step: 1132, loss is 0.005273271817713976\n",
      "epoch: 6 step: 1133, loss is 0.00019878936291206628\n",
      "epoch: 6 step: 1134, loss is 0.0002066710585495457\n",
      "epoch: 6 step: 1135, loss is 0.001118666143156588\n",
      "epoch: 6 step: 1136, loss is 0.03684215620160103\n",
      "epoch: 6 step: 1137, loss is 0.004748974926769733\n",
      "epoch: 6 step: 1138, loss is 0.0032869847491383553\n",
      "epoch: 6 step: 1139, loss is 0.005171674769371748\n",
      "epoch: 6 step: 1140, loss is 0.008000936359167099\n",
      "epoch: 6 step: 1141, loss is 0.009276368655264378\n",
      "epoch: 6 step: 1142, loss is 0.009194131940603256\n",
      "epoch: 6 step: 1143, loss is 0.00692294305190444\n",
      "epoch: 6 step: 1144, loss is 0.009729426354169846\n",
      "epoch: 6 step: 1145, loss is 0.02319900505244732\n",
      "epoch: 6 step: 1146, loss is 0.0013604604173451662\n",
      "epoch: 6 step: 1147, loss is 0.004339656792581081\n",
      "epoch: 6 step: 1148, loss is 0.00017402505909558386\n",
      "epoch: 6 step: 1149, loss is 4.188346065348014e-05\n",
      "epoch: 6 step: 1150, loss is 0.0018287530401721597\n",
      "epoch: 6 step: 1151, loss is 0.0001611767365830019\n",
      "epoch: 6 step: 1152, loss is 0.029349468648433685\n",
      "epoch: 6 step: 1153, loss is 9.949030936695635e-05\n",
      "epoch: 6 step: 1154, loss is 1.498856636317214e-05\n",
      "epoch: 6 step: 1155, loss is 0.007902484387159348\n",
      "epoch: 6 step: 1156, loss is 0.007390155456960201\n",
      "epoch: 6 step: 1157, loss is 0.003885975806042552\n",
      "epoch: 6 step: 1158, loss is 0.0030234158039093018\n",
      "epoch: 6 step: 1159, loss is 0.00217980844900012\n",
      "epoch: 6 step: 1160, loss is 0.0005932246567681432\n",
      "epoch: 6 step: 1161, loss is 0.0005618269206024706\n",
      "epoch: 6 step: 1162, loss is 0.0006885114125907421\n",
      "epoch: 6 step: 1163, loss is 0.00016850051179062575\n",
      "epoch: 6 step: 1164, loss is 0.005663954187184572\n",
      "epoch: 6 step: 1165, loss is 0.0006368581089191139\n",
      "epoch: 6 step: 1166, loss is 0.07879078388214111\n",
      "epoch: 6 step: 1167, loss is 0.00045911193592473865\n",
      "epoch: 6 step: 1168, loss is 0.000659605604596436\n",
      "epoch: 6 step: 1169, loss is 0.024394378066062927\n",
      "epoch: 6 step: 1170, loss is 0.001015783054754138\n",
      "epoch: 6 step: 1171, loss is 0.006275206338614225\n",
      "epoch: 6 step: 1172, loss is 0.005079586990177631\n",
      "epoch: 6 step: 1173, loss is 0.003118044463917613\n",
      "epoch: 6 step: 1174, loss is 0.019244780763983727\n",
      "epoch: 6 step: 1175, loss is 0.00039544622995890677\n",
      "epoch: 6 step: 1176, loss is 0.1567276269197464\n",
      "epoch: 6 step: 1177, loss is 0.0022404694464057684\n",
      "epoch: 6 step: 1178, loss is 0.021483084186911583\n",
      "epoch: 6 step: 1179, loss is 7.089648715918884e-05\n",
      "epoch: 6 step: 1180, loss is 0.02545955218374729\n",
      "epoch: 6 step: 1181, loss is 0.00038655009120702744\n",
      "epoch: 6 step: 1182, loss is 0.05381901562213898\n",
      "epoch: 6 step: 1183, loss is 0.1052846908569336\n",
      "epoch: 6 step: 1184, loss is 0.0025320693384855986\n",
      "epoch: 6 step: 1185, loss is 0.0033504958264529705\n",
      "epoch: 6 step: 1186, loss is 0.0015640000347048044\n",
      "epoch: 6 step: 1187, loss is 0.01633371412754059\n",
      "epoch: 6 step: 1188, loss is 1.1062901648983825e-05\n",
      "epoch: 6 step: 1189, loss is 0.038864996284246445\n",
      "epoch: 6 step: 1190, loss is 3.250016015954316e-05\n",
      "epoch: 6 step: 1191, loss is 0.00742205698043108\n",
      "epoch: 6 step: 1192, loss is 0.0003444908943492919\n",
      "epoch: 6 step: 1193, loss is 0.00142422947101295\n",
      "epoch: 6 step: 1194, loss is 0.03903583064675331\n",
      "epoch: 6 step: 1195, loss is 0.04157397523522377\n",
      "epoch: 6 step: 1196, loss is 0.0006201154319569468\n",
      "epoch: 6 step: 1197, loss is 0.0005403825780376792\n",
      "epoch: 6 step: 1198, loss is 9.550810500513762e-05\n",
      "epoch: 6 step: 1199, loss is 0.000507772492710501\n",
      "epoch: 6 step: 1200, loss is 0.00036533144884742796\n",
      "epoch: 6 step: 1201, loss is 0.03220526501536369\n",
      "epoch: 6 step: 1202, loss is 5.997743573971093e-05\n",
      "epoch: 6 step: 1203, loss is 0.0001073557577910833\n",
      "epoch: 6 step: 1204, loss is 0.3005184531211853\n",
      "epoch: 6 step: 1205, loss is 0.00010069687414215878\n",
      "epoch: 6 step: 1206, loss is 0.001194137497805059\n",
      "epoch: 6 step: 1207, loss is 0.019564401358366013\n",
      "epoch: 6 step: 1208, loss is 2.8491136617958546e-05\n",
      "epoch: 6 step: 1209, loss is 0.0007600999670103192\n",
      "epoch: 6 step: 1210, loss is 0.0017348801484331489\n",
      "epoch: 6 step: 1211, loss is 0.00013741386646870524\n",
      "epoch: 6 step: 1212, loss is 0.00909555796533823\n",
      "epoch: 6 step: 1213, loss is 0.0026165901217609644\n",
      "epoch: 6 step: 1214, loss is 0.0012865468161180615\n",
      "epoch: 6 step: 1215, loss is 0.03886574134230614\n",
      "epoch: 6 step: 1216, loss is 0.008169624023139477\n",
      "epoch: 6 step: 1217, loss is 0.006911910139024258\n",
      "epoch: 6 step: 1218, loss is 0.0032631848007440567\n",
      "epoch: 6 step: 1219, loss is 0.005784659646451473\n",
      "epoch: 6 step: 1220, loss is 0.0005125789903104305\n",
      "epoch: 6 step: 1221, loss is 0.12983734905719757\n",
      "epoch: 6 step: 1222, loss is 0.0005023232661187649\n",
      "epoch: 6 step: 1223, loss is 0.0006042111781425774\n",
      "epoch: 6 step: 1224, loss is 0.2087344080209732\n",
      "epoch: 6 step: 1225, loss is 0.06162406876683235\n",
      "epoch: 6 step: 1226, loss is 0.00010438075696583837\n",
      "epoch: 6 step: 1227, loss is 0.0012675324687734246\n",
      "epoch: 6 step: 1228, loss is 0.07196716964244843\n",
      "epoch: 6 step: 1229, loss is 0.0064553082920610905\n",
      "epoch: 6 step: 1230, loss is 0.005158351268619299\n",
      "epoch: 6 step: 1231, loss is 0.0035738961305469275\n",
      "epoch: 6 step: 1232, loss is 0.023452114313840866\n",
      "epoch: 6 step: 1233, loss is 0.00013106886763125658\n",
      "epoch: 6 step: 1234, loss is 0.00012307790166232735\n",
      "epoch: 6 step: 1235, loss is 0.0035924986004829407\n",
      "epoch: 6 step: 1236, loss is 0.0641256794333458\n",
      "epoch: 6 step: 1237, loss is 0.00010613298218231648\n",
      "epoch: 6 step: 1238, loss is 0.038889359682798386\n",
      "epoch: 6 step: 1239, loss is 0.3538263142108917\n",
      "epoch: 6 step: 1240, loss is 0.0013081826036795974\n",
      "epoch: 6 step: 1241, loss is 0.004022903740406036\n",
      "epoch: 6 step: 1242, loss is 0.01795010268688202\n",
      "epoch: 6 step: 1243, loss is 0.018500905483961105\n",
      "epoch: 6 step: 1244, loss is 0.0016904837684705853\n",
      "epoch: 6 step: 1245, loss is 0.031339287757873535\n",
      "epoch: 6 step: 1246, loss is 0.13376225531101227\n",
      "epoch: 6 step: 1247, loss is 0.006031057797372341\n",
      "epoch: 6 step: 1248, loss is 0.002528153592720628\n",
      "epoch: 6 step: 1249, loss is 0.00724647706374526\n",
      "epoch: 6 step: 1250, loss is 0.040552545338869095\n",
      "epoch: 6 step: 1251, loss is 0.0012272491585463285\n",
      "epoch: 6 step: 1252, loss is 0.011879026889801025\n",
      "epoch: 6 step: 1253, loss is 0.027223126962780952\n",
      "epoch: 6 step: 1254, loss is 0.021660007536411285\n",
      "epoch: 6 step: 1255, loss is 0.0022731448989361525\n",
      "epoch: 6 step: 1256, loss is 0.01430011261254549\n",
      "epoch: 6 step: 1257, loss is 0.00014999260019976646\n",
      "epoch: 6 step: 1258, loss is 0.015208806842565536\n",
      "epoch: 6 step: 1259, loss is 0.131352037191391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1260, loss is 0.008246202021837234\n",
      "epoch: 6 step: 1261, loss is 0.08796371519565582\n",
      "epoch: 6 step: 1262, loss is 0.09617379307746887\n",
      "epoch: 6 step: 1263, loss is 0.00011922145495191216\n",
      "epoch: 6 step: 1264, loss is 0.017609702423214912\n",
      "epoch: 6 step: 1265, loss is 0.008073361590504646\n",
      "epoch: 6 step: 1266, loss is 0.005299510434269905\n",
      "epoch: 6 step: 1267, loss is 0.010249961167573929\n",
      "epoch: 6 step: 1268, loss is 0.0005612664390355349\n",
      "epoch: 6 step: 1269, loss is 0.000220859597902745\n",
      "epoch: 6 step: 1270, loss is 0.0002763147640507668\n",
      "epoch: 6 step: 1271, loss is 0.0007788603543303907\n",
      "epoch: 6 step: 1272, loss is 0.0001748076465446502\n",
      "epoch: 6 step: 1273, loss is 0.004087656736373901\n",
      "epoch: 6 step: 1274, loss is 0.000248286611167714\n",
      "epoch: 6 step: 1275, loss is 0.003456728532910347\n",
      "epoch: 6 step: 1276, loss is 0.0004697756958194077\n",
      "epoch: 6 step: 1277, loss is 0.06255431473255157\n",
      "epoch: 6 step: 1278, loss is 0.0025910555850714445\n",
      "epoch: 6 step: 1279, loss is 0.00566431600600481\n",
      "epoch: 6 step: 1280, loss is 0.011406941339373589\n",
      "epoch: 6 step: 1281, loss is 0.0012793679488822818\n",
      "epoch: 6 step: 1282, loss is 0.002126839943230152\n",
      "epoch: 6 step: 1283, loss is 0.12815403938293457\n",
      "epoch: 6 step: 1284, loss is 0.005817362107336521\n",
      "epoch: 6 step: 1285, loss is 0.001824295031838119\n",
      "epoch: 6 step: 1286, loss is 0.026387671008706093\n",
      "epoch: 6 step: 1287, loss is 0.003977976273745298\n",
      "epoch: 6 step: 1288, loss is 0.005117662716656923\n",
      "epoch: 6 step: 1289, loss is 0.0034587187692523003\n",
      "epoch: 6 step: 1290, loss is 0.07699649780988693\n",
      "epoch: 6 step: 1291, loss is 0.11151742935180664\n",
      "epoch: 6 step: 1292, loss is 0.007442852482199669\n",
      "epoch: 6 step: 1293, loss is 0.1011379212141037\n",
      "epoch: 6 step: 1294, loss is 0.002520860405638814\n",
      "epoch: 6 step: 1295, loss is 0.00047992978943511844\n",
      "epoch: 6 step: 1296, loss is 0.0725787803530693\n",
      "epoch: 6 step: 1297, loss is 0.003314028726890683\n",
      "epoch: 6 step: 1298, loss is 0.0009929741499945521\n",
      "epoch: 6 step: 1299, loss is 0.007028523366898298\n",
      "epoch: 6 step: 1300, loss is 0.002375194802880287\n",
      "epoch: 6 step: 1301, loss is 0.05117179825901985\n",
      "epoch: 6 step: 1302, loss is 0.03523074835538864\n",
      "epoch: 6 step: 1303, loss is 0.019792161881923676\n",
      "epoch: 6 step: 1304, loss is 0.004737639334052801\n",
      "epoch: 6 step: 1305, loss is 0.0010392609983682632\n",
      "epoch: 6 step: 1306, loss is 0.0019192032050341368\n",
      "epoch: 6 step: 1307, loss is 0.03516869992017746\n",
      "epoch: 6 step: 1308, loss is 0.005601769313216209\n",
      "epoch: 6 step: 1309, loss is 6.030002987245098e-05\n",
      "epoch: 6 step: 1310, loss is 0.007396349683403969\n",
      "epoch: 6 step: 1311, loss is 0.14803540706634521\n",
      "epoch: 6 step: 1312, loss is 0.017846139147877693\n",
      "epoch: 6 step: 1313, loss is 0.05895555391907692\n",
      "epoch: 6 step: 1314, loss is 0.00991051271557808\n",
      "epoch: 6 step: 1315, loss is 0.00609159329906106\n",
      "epoch: 6 step: 1316, loss is 0.0001229182817041874\n",
      "epoch: 6 step: 1317, loss is 0.0009487076895311475\n",
      "epoch: 6 step: 1318, loss is 0.07034724205732346\n",
      "epoch: 6 step: 1319, loss is 0.0016348109347745776\n",
      "epoch: 6 step: 1320, loss is 0.002009265124797821\n",
      "epoch: 6 step: 1321, loss is 0.020986974239349365\n",
      "epoch: 6 step: 1322, loss is 0.0040394640527665615\n",
      "epoch: 6 step: 1323, loss is 0.2524767518043518\n",
      "epoch: 6 step: 1324, loss is 6.928243965376168e-05\n",
      "epoch: 6 step: 1325, loss is 0.004299205262213945\n",
      "epoch: 6 step: 1326, loss is 0.010213165543973446\n",
      "epoch: 6 step: 1327, loss is 0.00011444871051935479\n",
      "epoch: 6 step: 1328, loss is 0.10374701768159866\n",
      "epoch: 6 step: 1329, loss is 0.09258850663900375\n",
      "epoch: 6 step: 1330, loss is 0.0020541702397167683\n",
      "epoch: 6 step: 1331, loss is 0.0010879503097385168\n",
      "epoch: 6 step: 1332, loss is 0.0735013484954834\n",
      "epoch: 6 step: 1333, loss is 0.004702417645603418\n",
      "epoch: 6 step: 1334, loss is 0.0012592258863151073\n",
      "epoch: 6 step: 1335, loss is 0.00014022596587892622\n",
      "epoch: 6 step: 1336, loss is 0.005448988638818264\n",
      "epoch: 6 step: 1337, loss is 0.001211863593198359\n",
      "epoch: 6 step: 1338, loss is 0.14057505130767822\n",
      "epoch: 6 step: 1339, loss is 0.023241451010107994\n",
      "epoch: 6 step: 1340, loss is 0.0883515328168869\n",
      "epoch: 6 step: 1341, loss is 0.011223312467336655\n",
      "epoch: 6 step: 1342, loss is 0.00077168078860268\n",
      "epoch: 6 step: 1343, loss is 0.00528777576982975\n",
      "epoch: 6 step: 1344, loss is 0.006747440434992313\n",
      "epoch: 6 step: 1345, loss is 0.005174849182367325\n",
      "epoch: 6 step: 1346, loss is 0.08679764717817307\n",
      "epoch: 6 step: 1347, loss is 0.003626856952905655\n",
      "epoch: 6 step: 1348, loss is 0.04691634327173233\n",
      "epoch: 6 step: 1349, loss is 0.0183483324944973\n",
      "epoch: 6 step: 1350, loss is 0.0009155412553809583\n",
      "epoch: 6 step: 1351, loss is 0.025926340371370316\n",
      "epoch: 6 step: 1352, loss is 0.013871151022613049\n",
      "epoch: 6 step: 1353, loss is 0.00939927063882351\n",
      "epoch: 6 step: 1354, loss is 0.1556350141763687\n",
      "epoch: 6 step: 1355, loss is 0.019590994343161583\n",
      "epoch: 6 step: 1356, loss is 0.0009453704115003347\n",
      "epoch: 6 step: 1357, loss is 0.013818987645208836\n",
      "epoch: 6 step: 1358, loss is 0.0140631552785635\n",
      "epoch: 6 step: 1359, loss is 0.0023911618627607822\n",
      "epoch: 6 step: 1360, loss is 0.00040075407014228404\n",
      "epoch: 6 step: 1361, loss is 0.0018909653881564736\n",
      "epoch: 6 step: 1362, loss is 0.00029285799246281385\n",
      "epoch: 6 step: 1363, loss is 0.0008497170056216419\n",
      "epoch: 6 step: 1364, loss is 0.0052551645785570145\n",
      "epoch: 6 step: 1365, loss is 0.03695567324757576\n",
      "epoch: 6 step: 1366, loss is 0.008814550936222076\n",
      "epoch: 6 step: 1367, loss is 0.10039287060499191\n",
      "epoch: 6 step: 1368, loss is 0.08545958995819092\n",
      "epoch: 6 step: 1369, loss is 0.0030675583984702826\n",
      "epoch: 6 step: 1370, loss is 3.9040896808728576e-05\n",
      "epoch: 6 step: 1371, loss is 0.0013208709424361587\n",
      "epoch: 6 step: 1372, loss is 0.0023957444354891777\n",
      "epoch: 6 step: 1373, loss is 0.0038820712361484766\n",
      "epoch: 6 step: 1374, loss is 0.001243963255546987\n",
      "epoch: 6 step: 1375, loss is 0.006255266256630421\n",
      "epoch: 6 step: 1376, loss is 0.00688601890578866\n",
      "epoch: 6 step: 1377, loss is 0.00028031814144924283\n",
      "epoch: 6 step: 1378, loss is 0.003517587436363101\n",
      "epoch: 6 step: 1379, loss is 0.0210553165525198\n",
      "epoch: 6 step: 1380, loss is 0.00031673835474066436\n",
      "epoch: 6 step: 1381, loss is 0.1480255424976349\n",
      "epoch: 6 step: 1382, loss is 1.8866729078581557e-05\n",
      "epoch: 6 step: 1383, loss is 0.009165965020656586\n",
      "epoch: 6 step: 1384, loss is 0.0007194859790615737\n",
      "epoch: 6 step: 1385, loss is 0.006910727359354496\n",
      "epoch: 6 step: 1386, loss is 0.0011416416382417083\n",
      "epoch: 6 step: 1387, loss is 0.009721064940094948\n",
      "epoch: 6 step: 1388, loss is 0.004416132811456919\n",
      "epoch: 6 step: 1389, loss is 0.0021222473587840796\n",
      "epoch: 6 step: 1390, loss is 0.018317390233278275\n",
      "epoch: 6 step: 1391, loss is 0.00023055348719935864\n",
      "epoch: 6 step: 1392, loss is 0.001029058126732707\n",
      "epoch: 6 step: 1393, loss is 0.01135510765016079\n",
      "epoch: 6 step: 1394, loss is 0.018658816814422607\n",
      "epoch: 6 step: 1395, loss is 0.29058215022087097\n",
      "epoch: 6 step: 1396, loss is 0.00017032244068104774\n",
      "epoch: 6 step: 1397, loss is 0.0014079953543841839\n",
      "epoch: 6 step: 1398, loss is 0.0062986998818814754\n",
      "epoch: 6 step: 1399, loss is 0.0028938367031514645\n",
      "epoch: 6 step: 1400, loss is 0.01860874332487583\n",
      "epoch: 6 step: 1401, loss is 0.0006977225420996547\n",
      "epoch: 6 step: 1402, loss is 0.00013199345266912133\n",
      "epoch: 6 step: 1403, loss is 0.00029278642614372075\n",
      "epoch: 6 step: 1404, loss is 0.00478666415438056\n",
      "epoch: 6 step: 1405, loss is 0.025286104530096054\n",
      "epoch: 6 step: 1406, loss is 0.0035568815656006336\n",
      "epoch: 6 step: 1407, loss is 0.010983235202729702\n",
      "epoch: 6 step: 1408, loss is 0.0002044645370915532\n",
      "epoch: 6 step: 1409, loss is 0.0032779406756162643\n",
      "epoch: 6 step: 1410, loss is 0.008089649491012096\n",
      "epoch: 6 step: 1411, loss is 0.0036387306172400713\n",
      "epoch: 6 step: 1412, loss is 0.007913216017186642\n",
      "epoch: 6 step: 1413, loss is 0.017293546348810196\n",
      "epoch: 6 step: 1414, loss is 1.4132718206383288e-05\n",
      "epoch: 6 step: 1415, loss is 0.006026311777532101\n",
      "epoch: 6 step: 1416, loss is 0.010202077217400074\n",
      "epoch: 6 step: 1417, loss is 0.00017825377290137112\n",
      "epoch: 6 step: 1418, loss is 0.0003264254191890359\n",
      "epoch: 6 step: 1419, loss is 0.0007924374076537788\n",
      "epoch: 6 step: 1420, loss is 0.00014739122707396746\n",
      "epoch: 6 step: 1421, loss is 0.0017548541072756052\n",
      "epoch: 6 step: 1422, loss is 0.09011960029602051\n",
      "epoch: 6 step: 1423, loss is 0.0031301456037908792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1424, loss is 0.0006342654814943671\n",
      "epoch: 6 step: 1425, loss is 0.0011181477457284927\n",
      "epoch: 6 step: 1426, loss is 0.00024803957785479724\n",
      "epoch: 6 step: 1427, loss is 0.01137431338429451\n",
      "epoch: 6 step: 1428, loss is 0.0012204350205138326\n",
      "epoch: 6 step: 1429, loss is 0.0017537305830046535\n",
      "epoch: 6 step: 1430, loss is 0.001769990660250187\n",
      "epoch: 6 step: 1431, loss is 4.0690396417630836e-05\n",
      "epoch: 6 step: 1432, loss is 0.002864197827875614\n",
      "epoch: 6 step: 1433, loss is 0.0006290242308750749\n",
      "epoch: 6 step: 1434, loss is 6.649995339103043e-05\n",
      "epoch: 6 step: 1435, loss is 0.0030670897103846073\n",
      "epoch: 6 step: 1436, loss is 0.0001688086922513321\n",
      "epoch: 6 step: 1437, loss is 0.0006739059463143349\n",
      "epoch: 6 step: 1438, loss is 0.00035600009141489863\n",
      "epoch: 6 step: 1439, loss is 0.0290495827794075\n",
      "epoch: 6 step: 1440, loss is 4.8287733079632744e-05\n",
      "epoch: 6 step: 1441, loss is 0.08071418106555939\n",
      "epoch: 6 step: 1442, loss is 0.006109063513576984\n",
      "epoch: 6 step: 1443, loss is 0.015235374681651592\n",
      "epoch: 6 step: 1444, loss is 0.0003336849622428417\n",
      "epoch: 6 step: 1445, loss is 0.0006942873005755246\n",
      "epoch: 6 step: 1446, loss is 0.004773352295160294\n",
      "epoch: 6 step: 1447, loss is 8.365368557861075e-05\n",
      "epoch: 6 step: 1448, loss is 0.006993137765675783\n",
      "epoch: 6 step: 1449, loss is 0.004550047218799591\n",
      "epoch: 6 step: 1450, loss is 5.240581958787516e-05\n",
      "epoch: 6 step: 1451, loss is 0.011783050373196602\n",
      "epoch: 6 step: 1452, loss is 0.0003018106799572706\n",
      "epoch: 6 step: 1453, loss is 0.0007042594952508807\n",
      "epoch: 6 step: 1454, loss is 0.0030820630490779877\n",
      "epoch: 6 step: 1455, loss is 0.016058355569839478\n",
      "epoch: 6 step: 1456, loss is 4.544527473626658e-05\n",
      "epoch: 6 step: 1457, loss is 0.0031303579453378916\n",
      "epoch: 6 step: 1458, loss is 0.026394514366984367\n",
      "epoch: 6 step: 1459, loss is 0.011534971185028553\n",
      "epoch: 6 step: 1460, loss is 1.3575466255133506e-05\n",
      "epoch: 6 step: 1461, loss is 0.0009641559445299208\n",
      "epoch: 6 step: 1462, loss is 9.955538553185761e-05\n",
      "epoch: 6 step: 1463, loss is 0.003625001758337021\n",
      "epoch: 6 step: 1464, loss is 0.030710408464074135\n",
      "epoch: 6 step: 1465, loss is 0.0008516436791978776\n",
      "epoch: 6 step: 1466, loss is 0.0018894427921622992\n",
      "epoch: 6 step: 1467, loss is 0.09826385229825974\n",
      "epoch: 6 step: 1468, loss is 0.004665528889745474\n",
      "epoch: 6 step: 1469, loss is 0.0008934017387218773\n",
      "epoch: 6 step: 1470, loss is 0.022485068067908287\n",
      "epoch: 6 step: 1471, loss is 0.09988726675510406\n",
      "epoch: 6 step: 1472, loss is 0.03307601064443588\n",
      "epoch: 6 step: 1473, loss is 0.0014278626767918468\n",
      "epoch: 6 step: 1474, loss is 8.215334673877805e-05\n",
      "epoch: 6 step: 1475, loss is 7.460446795448661e-05\n",
      "epoch: 6 step: 1476, loss is 0.029785120859742165\n",
      "epoch: 6 step: 1477, loss is 0.00010365168418502435\n",
      "epoch: 6 step: 1478, loss is 0.005229882430285215\n",
      "epoch: 6 step: 1479, loss is 6.149394175736234e-05\n",
      "epoch: 6 step: 1480, loss is 0.14963045716285706\n",
      "epoch: 6 step: 1481, loss is 0.006291735917329788\n",
      "epoch: 6 step: 1482, loss is 0.08696070313453674\n",
      "epoch: 6 step: 1483, loss is 9.554437565384433e-05\n",
      "epoch: 6 step: 1484, loss is 0.001877877744846046\n",
      "epoch: 6 step: 1485, loss is 0.008560744114220142\n",
      "epoch: 6 step: 1486, loss is 0.0006517938454635441\n",
      "epoch: 6 step: 1487, loss is 0.0004928804119117558\n",
      "epoch: 6 step: 1488, loss is 0.0009057686547748744\n",
      "epoch: 6 step: 1489, loss is 0.0007343616452999413\n",
      "epoch: 6 step: 1490, loss is 0.09090649336576462\n",
      "epoch: 6 step: 1491, loss is 0.0021703201346099377\n",
      "epoch: 6 step: 1492, loss is 0.0016846152720972896\n",
      "epoch: 6 step: 1493, loss is 2.794018291751854e-05\n",
      "epoch: 6 step: 1494, loss is 0.0046173520386219025\n",
      "epoch: 6 step: 1495, loss is 0.0004345784545876086\n",
      "epoch: 6 step: 1496, loss is 0.008677300997078419\n",
      "epoch: 6 step: 1497, loss is 0.00045605143532156944\n",
      "epoch: 6 step: 1498, loss is 0.2844930589199066\n",
      "epoch: 6 step: 1499, loss is 2.812628554238472e-05\n",
      "epoch: 6 step: 1500, loss is 0.0007931026048026979\n",
      "epoch: 6 step: 1501, loss is 0.006723730359226465\n",
      "epoch: 6 step: 1502, loss is 0.00014042579277884215\n",
      "epoch: 6 step: 1503, loss is 0.00583958625793457\n",
      "epoch: 6 step: 1504, loss is 0.07771018892526627\n",
      "epoch: 6 step: 1505, loss is 0.0002255473518744111\n",
      "epoch: 6 step: 1506, loss is 0.055629756301641464\n",
      "epoch: 6 step: 1507, loss is 0.017842406406998634\n",
      "epoch: 6 step: 1508, loss is 0.01423337310552597\n",
      "epoch: 6 step: 1509, loss is 0.004373366478830576\n",
      "epoch: 6 step: 1510, loss is 0.05631287395954132\n",
      "epoch: 6 step: 1511, loss is 0.003951690159738064\n",
      "epoch: 6 step: 1512, loss is 0.0001300887524848804\n",
      "epoch: 6 step: 1513, loss is 0.0006161300698295236\n",
      "epoch: 6 step: 1514, loss is 0.07283689826726913\n",
      "epoch: 6 step: 1515, loss is 0.018913252279162407\n",
      "epoch: 6 step: 1516, loss is 0.0011741418857127428\n",
      "epoch: 6 step: 1517, loss is 0.0026482860557734966\n",
      "epoch: 6 step: 1518, loss is 0.001333763124421239\n",
      "epoch: 6 step: 1519, loss is 0.16550768911838531\n",
      "epoch: 6 step: 1520, loss is 0.0014010651502758265\n",
      "epoch: 6 step: 1521, loss is 0.013866500928997993\n",
      "epoch: 6 step: 1522, loss is 0.0015629347180947661\n",
      "epoch: 6 step: 1523, loss is 0.003713196376338601\n",
      "epoch: 6 step: 1524, loss is 0.0031412180978804827\n",
      "epoch: 6 step: 1525, loss is 0.0007077931077219546\n",
      "epoch: 6 step: 1526, loss is 0.004652905277907848\n",
      "epoch: 6 step: 1527, loss is 0.028243573382496834\n",
      "epoch: 6 step: 1528, loss is 0.0007087222766131163\n",
      "epoch: 6 step: 1529, loss is 0.002209943253546953\n",
      "epoch: 6 step: 1530, loss is 0.037468407303094864\n",
      "epoch: 6 step: 1531, loss is 0.00011983107833657414\n",
      "epoch: 6 step: 1532, loss is 0.10563898831605911\n",
      "epoch: 6 step: 1533, loss is 0.08006580173969269\n",
      "epoch: 6 step: 1534, loss is 0.00021126450155861676\n",
      "epoch: 6 step: 1535, loss is 4.752285167342052e-05\n",
      "epoch: 6 step: 1536, loss is 0.04175699129700661\n",
      "epoch: 6 step: 1537, loss is 0.0005200732266530395\n",
      "epoch: 6 step: 1538, loss is 7.762618770357221e-05\n",
      "epoch: 6 step: 1539, loss is 0.01760086603462696\n",
      "epoch: 6 step: 1540, loss is 0.0006700577796436846\n",
      "epoch: 6 step: 1541, loss is 0.038104623556137085\n",
      "epoch: 6 step: 1542, loss is 0.0027141249738633633\n",
      "epoch: 6 step: 1543, loss is 0.0009754033526405692\n",
      "epoch: 6 step: 1544, loss is 0.00045751812285743654\n",
      "epoch: 6 step: 1545, loss is 0.0002470707695465535\n",
      "epoch: 6 step: 1546, loss is 6.105841021053493e-05\n",
      "epoch: 6 step: 1547, loss is 0.001905547920614481\n",
      "epoch: 6 step: 1548, loss is 0.009182445704936981\n",
      "epoch: 6 step: 1549, loss is 3.8120997487567365e-05\n",
      "epoch: 6 step: 1550, loss is 0.0003222526574973017\n",
      "epoch: 6 step: 1551, loss is 0.020860465243458748\n",
      "epoch: 6 step: 1552, loss is 0.04851173982024193\n",
      "epoch: 6 step: 1553, loss is 0.0015508062206208706\n",
      "epoch: 6 step: 1554, loss is 0.0007078146445564926\n",
      "epoch: 6 step: 1555, loss is 0.02546755224466324\n",
      "epoch: 6 step: 1556, loss is 0.07989296317100525\n",
      "epoch: 6 step: 1557, loss is 0.027509240433573723\n",
      "epoch: 6 step: 1558, loss is 0.02036336436867714\n",
      "epoch: 6 step: 1559, loss is 0.004953992087393999\n",
      "epoch: 6 step: 1560, loss is 0.004231193568557501\n",
      "epoch: 6 step: 1561, loss is 0.011036986485123634\n",
      "epoch: 6 step: 1562, loss is 0.000696464441716671\n",
      "epoch: 6 step: 1563, loss is 0.02003714069724083\n",
      "epoch: 6 step: 1564, loss is 0.0005461036344058812\n",
      "epoch: 6 step: 1565, loss is 0.05740676447749138\n",
      "epoch: 6 step: 1566, loss is 0.03140740469098091\n",
      "epoch: 6 step: 1567, loss is 0.0014237788273021579\n",
      "epoch: 6 step: 1568, loss is 0.19297343492507935\n",
      "epoch: 6 step: 1569, loss is 0.04088287428021431\n",
      "epoch: 6 step: 1570, loss is 0.00038250090437941253\n",
      "epoch: 6 step: 1571, loss is 0.0001796601718524471\n",
      "epoch: 6 step: 1572, loss is 0.0007743191672489047\n",
      "epoch: 6 step: 1573, loss is 0.0015488992212340236\n",
      "epoch: 6 step: 1574, loss is 0.018564065918326378\n",
      "epoch: 6 step: 1575, loss is 0.19015464186668396\n",
      "epoch: 6 step: 1576, loss is 0.002770983148366213\n",
      "epoch: 6 step: 1577, loss is 0.0059220572002232075\n",
      "epoch: 6 step: 1578, loss is 0.04395327717065811\n",
      "epoch: 6 step: 1579, loss is 4.244181764079258e-05\n",
      "epoch: 6 step: 1580, loss is 9.234558820025995e-05\n",
      "epoch: 6 step: 1581, loss is 0.002234730636700988\n",
      "epoch: 6 step: 1582, loss is 0.010842283256351948\n",
      "epoch: 6 step: 1583, loss is 0.0018051849910989404\n",
      "epoch: 6 step: 1584, loss is 0.034661490470170975\n",
      "epoch: 6 step: 1585, loss is 0.009697044268250465\n",
      "epoch: 6 step: 1586, loss is 0.17594604194164276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1587, loss is 0.00858574640005827\n",
      "epoch: 6 step: 1588, loss is 0.24871449172496796\n",
      "epoch: 6 step: 1589, loss is 0.004922174848616123\n",
      "epoch: 6 step: 1590, loss is 0.0005036554066464305\n",
      "epoch: 6 step: 1591, loss is 0.009034346789121628\n",
      "epoch: 6 step: 1592, loss is 0.13874433934688568\n",
      "epoch: 6 step: 1593, loss is 0.0009735453641042113\n",
      "epoch: 6 step: 1594, loss is 0.0515141487121582\n",
      "epoch: 6 step: 1595, loss is 0.4904383420944214\n",
      "epoch: 6 step: 1596, loss is 0.0023512172047048807\n",
      "epoch: 6 step: 1597, loss is 0.003406388685107231\n",
      "epoch: 6 step: 1598, loss is 0.028489572927355766\n",
      "epoch: 6 step: 1599, loss is 0.08498553186655045\n",
      "epoch: 6 step: 1600, loss is 0.005821714643388987\n",
      "epoch: 6 step: 1601, loss is 0.00036051133065484464\n",
      "epoch: 6 step: 1602, loss is 0.3047128915786743\n",
      "epoch: 6 step: 1603, loss is 0.0021704332903027534\n",
      "epoch: 6 step: 1604, loss is 0.044714879244565964\n",
      "epoch: 6 step: 1605, loss is 0.09261570125818253\n",
      "epoch: 6 step: 1606, loss is 0.037536293268203735\n",
      "epoch: 6 step: 1607, loss is 0.019184619188308716\n",
      "epoch: 6 step: 1608, loss is 0.0047461893409490585\n",
      "epoch: 6 step: 1609, loss is 0.005894475616514683\n",
      "epoch: 6 step: 1610, loss is 0.0052824500016868114\n",
      "epoch: 6 step: 1611, loss is 0.0006508531514555216\n",
      "epoch: 6 step: 1612, loss is 0.028252072632312775\n",
      "epoch: 6 step: 1613, loss is 0.002476930385455489\n",
      "epoch: 6 step: 1614, loss is 0.0037593941669911146\n",
      "epoch: 6 step: 1615, loss is 0.0005371656152419746\n",
      "epoch: 6 step: 1616, loss is 0.1279221922159195\n",
      "epoch: 6 step: 1617, loss is 0.00299115595407784\n",
      "epoch: 6 step: 1618, loss is 0.0017482086550444365\n",
      "epoch: 6 step: 1619, loss is 0.0004578392836265266\n",
      "epoch: 6 step: 1620, loss is 0.007777244783937931\n",
      "epoch: 6 step: 1621, loss is 0.03963923826813698\n",
      "epoch: 6 step: 1622, loss is 0.0008297463646158576\n",
      "epoch: 6 step: 1623, loss is 0.0011677999282255769\n",
      "epoch: 6 step: 1624, loss is 0.0001337675203103572\n",
      "epoch: 6 step: 1625, loss is 0.0010470319539308548\n",
      "epoch: 6 step: 1626, loss is 0.16257645189762115\n",
      "epoch: 6 step: 1627, loss is 0.002155385911464691\n",
      "epoch: 6 step: 1628, loss is 0.0022176261991262436\n",
      "epoch: 6 step: 1629, loss is 0.002549021039158106\n",
      "epoch: 6 step: 1630, loss is 0.014817916788160801\n",
      "epoch: 6 step: 1631, loss is 0.05636581405997276\n",
      "epoch: 6 step: 1632, loss is 0.03334391862154007\n",
      "epoch: 6 step: 1633, loss is 0.0002010362222790718\n",
      "epoch: 6 step: 1634, loss is 0.0013023152714595199\n",
      "epoch: 6 step: 1635, loss is 0.06866218149662018\n",
      "epoch: 6 step: 1636, loss is 0.10246723145246506\n",
      "epoch: 6 step: 1637, loss is 0.0014539307449012995\n",
      "epoch: 6 step: 1638, loss is 0.004056064877659082\n",
      "epoch: 6 step: 1639, loss is 0.07240252196788788\n",
      "epoch: 6 step: 1640, loss is 0.0004659299738705158\n",
      "epoch: 6 step: 1641, loss is 0.00038246551412157714\n",
      "epoch: 6 step: 1642, loss is 0.14374639093875885\n",
      "epoch: 6 step: 1643, loss is 0.003435396123677492\n",
      "epoch: 6 step: 1644, loss is 0.07230997085571289\n",
      "epoch: 6 step: 1645, loss is 0.00769048510119319\n",
      "epoch: 6 step: 1646, loss is 0.0016150964656844735\n",
      "epoch: 6 step: 1647, loss is 0.01547296717762947\n",
      "epoch: 6 step: 1648, loss is 0.0001280050491914153\n",
      "epoch: 6 step: 1649, loss is 0.022967979311943054\n",
      "epoch: 6 step: 1650, loss is 0.022385360673069954\n",
      "epoch: 6 step: 1651, loss is 0.0013239523395895958\n",
      "epoch: 6 step: 1652, loss is 0.0028022672049701214\n",
      "epoch: 6 step: 1653, loss is 0.00013659395335707814\n",
      "epoch: 6 step: 1654, loss is 0.011794442310929298\n",
      "epoch: 6 step: 1655, loss is 0.0014999903505668044\n",
      "epoch: 6 step: 1656, loss is 0.0005350523861125112\n",
      "epoch: 6 step: 1657, loss is 0.007519335951656103\n",
      "epoch: 6 step: 1658, loss is 0.010777062736451626\n",
      "epoch: 6 step: 1659, loss is 0.046668972820043564\n",
      "epoch: 6 step: 1660, loss is 0.0041042510420084\n",
      "epoch: 6 step: 1661, loss is 0.0344422310590744\n",
      "epoch: 6 step: 1662, loss is 0.00023525464348495007\n",
      "epoch: 6 step: 1663, loss is 0.0065940977074205875\n",
      "epoch: 6 step: 1664, loss is 0.0005692183622159064\n",
      "epoch: 6 step: 1665, loss is 0.010336888022720814\n",
      "epoch: 6 step: 1666, loss is 6.433139787986875e-05\n",
      "epoch: 6 step: 1667, loss is 0.03013860620558262\n",
      "epoch: 6 step: 1668, loss is 0.00576429208740592\n",
      "epoch: 6 step: 1669, loss is 0.012863860465586185\n",
      "epoch: 6 step: 1670, loss is 0.04543166607618332\n",
      "epoch: 6 step: 1671, loss is 0.0007389367092400789\n",
      "epoch: 6 step: 1672, loss is 0.0008388219284825027\n",
      "epoch: 6 step: 1673, loss is 0.00183507998008281\n",
      "epoch: 6 step: 1674, loss is 0.0009124617790803313\n",
      "epoch: 6 step: 1675, loss is 0.001827297848649323\n",
      "epoch: 6 step: 1676, loss is 0.003633257932960987\n",
      "epoch: 6 step: 1677, loss is 0.0008401790983043611\n",
      "epoch: 6 step: 1678, loss is 0.0003322371921967715\n",
      "epoch: 6 step: 1679, loss is 0.00039649836253374815\n",
      "epoch: 6 step: 1680, loss is 0.0011173257371410728\n",
      "epoch: 6 step: 1681, loss is 0.021185757592320442\n",
      "epoch: 6 step: 1682, loss is 0.004272391088306904\n",
      "epoch: 6 step: 1683, loss is 0.0013745914911851287\n",
      "epoch: 6 step: 1684, loss is 0.004870575852692127\n",
      "epoch: 6 step: 1685, loss is 0.0001906837715068832\n",
      "epoch: 6 step: 1686, loss is 0.015721773728728294\n",
      "epoch: 6 step: 1687, loss is 0.05382923781871796\n",
      "epoch: 6 step: 1688, loss is 0.0009282768005505204\n",
      "epoch: 6 step: 1689, loss is 0.0002025096764555201\n",
      "epoch: 6 step: 1690, loss is 0.00046135022421367466\n",
      "epoch: 6 step: 1691, loss is 0.004475060384720564\n",
      "epoch: 6 step: 1692, loss is 0.0008900458342395723\n",
      "epoch: 6 step: 1693, loss is 0.000993302441202104\n",
      "epoch: 6 step: 1694, loss is 0.007003963924944401\n",
      "epoch: 6 step: 1695, loss is 0.002725093625485897\n",
      "epoch: 6 step: 1696, loss is 1.743898610584438e-05\n",
      "epoch: 6 step: 1697, loss is 0.000630874652415514\n",
      "epoch: 6 step: 1698, loss is 0.003113459562882781\n",
      "epoch: 6 step: 1699, loss is 0.005403705406934023\n",
      "epoch: 6 step: 1700, loss is 0.00019929099653381854\n",
      "epoch: 6 step: 1701, loss is 0.0017708914820104837\n",
      "epoch: 6 step: 1702, loss is 0.003903368953615427\n",
      "epoch: 6 step: 1703, loss is 0.0032141050323843956\n",
      "epoch: 6 step: 1704, loss is 0.0029489079024642706\n",
      "epoch: 6 step: 1705, loss is 0.00891850609332323\n",
      "epoch: 6 step: 1706, loss is 0.02513851970434189\n",
      "epoch: 6 step: 1707, loss is 0.0010538831120356917\n",
      "epoch: 6 step: 1708, loss is 0.001244412618689239\n",
      "epoch: 6 step: 1709, loss is 0.0011552531505003572\n",
      "epoch: 6 step: 1710, loss is 0.000753026339225471\n",
      "epoch: 6 step: 1711, loss is 0.020949840545654297\n",
      "epoch: 6 step: 1712, loss is 0.00012826346210204065\n",
      "epoch: 6 step: 1713, loss is 0.0002258547319797799\n",
      "epoch: 6 step: 1714, loss is 0.00013639984535984695\n",
      "epoch: 6 step: 1715, loss is 0.0020401061046868563\n",
      "epoch: 6 step: 1716, loss is 0.012784971855580807\n",
      "epoch: 6 step: 1717, loss is 0.005908372811973095\n",
      "epoch: 6 step: 1718, loss is 7.557942444691435e-05\n",
      "epoch: 6 step: 1719, loss is 0.03270130604505539\n",
      "epoch: 6 step: 1720, loss is 0.1144232377409935\n",
      "epoch: 6 step: 1721, loss is 7.676160021219403e-05\n",
      "epoch: 6 step: 1722, loss is 0.045957986265420914\n",
      "epoch: 6 step: 1723, loss is 0.0004082554951310158\n",
      "epoch: 6 step: 1724, loss is 0.00028154844767414033\n",
      "epoch: 6 step: 1725, loss is 0.003754216246306896\n",
      "epoch: 6 step: 1726, loss is 0.0001773523836163804\n",
      "epoch: 6 step: 1727, loss is 0.03588458150625229\n",
      "epoch: 6 step: 1728, loss is 0.0020642844028770924\n",
      "epoch: 6 step: 1729, loss is 0.00022925663506612182\n",
      "epoch: 6 step: 1730, loss is 0.012780535034835339\n",
      "epoch: 6 step: 1731, loss is 0.000433735636761412\n",
      "epoch: 6 step: 1732, loss is 0.0002505420125089586\n",
      "epoch: 6 step: 1733, loss is 0.004780655261129141\n",
      "epoch: 6 step: 1734, loss is 0.0007612476474605501\n",
      "epoch: 6 step: 1735, loss is 0.001518081990070641\n",
      "epoch: 6 step: 1736, loss is 0.0018846549792215228\n",
      "epoch: 6 step: 1737, loss is 0.0004991915193386376\n",
      "epoch: 6 step: 1738, loss is 0.0030323241371661425\n",
      "epoch: 6 step: 1739, loss is 0.0004270870122127235\n",
      "epoch: 6 step: 1740, loss is 0.0025498936884105206\n",
      "epoch: 6 step: 1741, loss is 0.007922546938061714\n",
      "epoch: 6 step: 1742, loss is 0.1514556109905243\n",
      "epoch: 6 step: 1743, loss is 0.09108854085206985\n",
      "epoch: 6 step: 1744, loss is 0.007944706827402115\n",
      "epoch: 6 step: 1745, loss is 0.012677323073148727\n",
      "epoch: 6 step: 1746, loss is 0.014878896996378899\n",
      "epoch: 6 step: 1747, loss is 0.006231027189642191\n",
      "epoch: 6 step: 1748, loss is 0.001815610215999186\n",
      "epoch: 6 step: 1749, loss is 0.12408837676048279\n",
      "epoch: 6 step: 1750, loss is 0.013082829304039478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1751, loss is 0.00035068747820332646\n",
      "epoch: 6 step: 1752, loss is 0.004714310634881258\n",
      "epoch: 6 step: 1753, loss is 0.0020016536582261324\n",
      "epoch: 6 step: 1754, loss is 0.003675845917314291\n",
      "epoch: 6 step: 1755, loss is 0.002179704373702407\n",
      "epoch: 6 step: 1756, loss is 0.025869373232126236\n",
      "epoch: 6 step: 1757, loss is 0.00047061871737241745\n",
      "epoch: 6 step: 1758, loss is 0.007669023238122463\n",
      "epoch: 6 step: 1759, loss is 0.010137042962014675\n",
      "epoch: 6 step: 1760, loss is 0.0048813181929290295\n",
      "epoch: 6 step: 1761, loss is 0.005364764016121626\n",
      "epoch: 6 step: 1762, loss is 0.0036956495605409145\n",
      "epoch: 6 step: 1763, loss is 0.003398809116333723\n",
      "epoch: 6 step: 1764, loss is 0.0008047574665397406\n",
      "epoch: 6 step: 1765, loss is 0.00339583121240139\n",
      "epoch: 6 step: 1766, loss is 0.00022545257525052875\n",
      "epoch: 6 step: 1767, loss is 0.08356957882642746\n",
      "epoch: 6 step: 1768, loss is 0.005774850491434336\n",
      "epoch: 6 step: 1769, loss is 0.00031076461891643703\n",
      "epoch: 6 step: 1770, loss is 0.21926189959049225\n",
      "epoch: 6 step: 1771, loss is 0.0030067237094044685\n",
      "epoch: 6 step: 1772, loss is 0.16554173827171326\n",
      "epoch: 6 step: 1773, loss is 0.0005583141464740038\n",
      "epoch: 6 step: 1774, loss is 0.0006160010234452784\n",
      "epoch: 6 step: 1775, loss is 0.04035987704992294\n",
      "epoch: 6 step: 1776, loss is 0.00025551184080541134\n",
      "epoch: 6 step: 1777, loss is 0.0010414018761366606\n",
      "epoch: 6 step: 1778, loss is 0.02221367321908474\n",
      "epoch: 6 step: 1779, loss is 0.0013268645852804184\n",
      "epoch: 6 step: 1780, loss is 0.0015321121318265796\n",
      "epoch: 6 step: 1781, loss is 0.00011290347174508497\n",
      "epoch: 6 step: 1782, loss is 0.00032946871942840517\n",
      "epoch: 6 step: 1783, loss is 0.001038647722452879\n",
      "epoch: 6 step: 1784, loss is 0.05082162097096443\n",
      "epoch: 6 step: 1785, loss is 0.0002102943108184263\n",
      "epoch: 6 step: 1786, loss is 0.0008337095496244729\n",
      "epoch: 6 step: 1787, loss is 0.021058356389403343\n",
      "epoch: 6 step: 1788, loss is 0.00029030904988758266\n",
      "epoch: 6 step: 1789, loss is 4.695809548138641e-05\n",
      "epoch: 6 step: 1790, loss is 0.0016926631797105074\n",
      "epoch: 6 step: 1791, loss is 0.0003809938207268715\n",
      "epoch: 6 step: 1792, loss is 0.0010804713238030672\n",
      "epoch: 6 step: 1793, loss is 0.006350263021886349\n",
      "epoch: 6 step: 1794, loss is 0.0004908693372271955\n",
      "epoch: 6 step: 1795, loss is 0.0004079192294739187\n",
      "epoch: 6 step: 1796, loss is 0.02187572978436947\n",
      "epoch: 6 step: 1797, loss is 0.015145952813327312\n",
      "epoch: 6 step: 1798, loss is 0.04388124868273735\n",
      "epoch: 6 step: 1799, loss is 0.02077297493815422\n",
      "epoch: 6 step: 1800, loss is 0.0012969011440873146\n",
      "epoch: 6 step: 1801, loss is 0.0015049307839944959\n",
      "epoch: 6 step: 1802, loss is 0.0005120011628605425\n",
      "epoch: 6 step: 1803, loss is 0.04983070492744446\n",
      "epoch: 6 step: 1804, loss is 0.0854053795337677\n",
      "epoch: 6 step: 1805, loss is 0.0024629023391753435\n",
      "epoch: 6 step: 1806, loss is 0.0025591186713427305\n",
      "epoch: 6 step: 1807, loss is 0.0003223057428840548\n",
      "epoch: 6 step: 1808, loss is 0.009217229671776295\n",
      "epoch: 6 step: 1809, loss is 0.009776969440281391\n",
      "epoch: 6 step: 1810, loss is 0.0007679246482439339\n",
      "epoch: 6 step: 1811, loss is 0.002118652919307351\n",
      "epoch: 6 step: 1812, loss is 0.3893432021141052\n",
      "epoch: 6 step: 1813, loss is 0.00011335499584674835\n",
      "epoch: 6 step: 1814, loss is 0.0015635439194738865\n",
      "epoch: 6 step: 1815, loss is 0.05870649218559265\n",
      "epoch: 6 step: 1816, loss is 0.010352002456784248\n",
      "epoch: 6 step: 1817, loss is 0.013764223083853722\n",
      "epoch: 6 step: 1818, loss is 0.012292250990867615\n",
      "epoch: 6 step: 1819, loss is 0.09377765655517578\n",
      "epoch: 6 step: 1820, loss is 0.0007389110396616161\n",
      "epoch: 6 step: 1821, loss is 0.004281807225197554\n",
      "epoch: 6 step: 1822, loss is 0.0015711493324488401\n",
      "epoch: 6 step: 1823, loss is 6.265001866267994e-05\n",
      "epoch: 6 step: 1824, loss is 0.036961428821086884\n",
      "epoch: 6 step: 1825, loss is 0.007004988845437765\n",
      "epoch: 6 step: 1826, loss is 0.0035176542587578297\n",
      "epoch: 6 step: 1827, loss is 0.023507706820964813\n",
      "epoch: 6 step: 1828, loss is 0.003940569702535868\n",
      "epoch: 6 step: 1829, loss is 0.011972613632678986\n",
      "epoch: 6 step: 1830, loss is 0.016168411821126938\n",
      "epoch: 6 step: 1831, loss is 0.00019522967340890318\n",
      "epoch: 6 step: 1832, loss is 0.02042365074157715\n",
      "epoch: 6 step: 1833, loss is 0.0005480135441757739\n",
      "epoch: 6 step: 1834, loss is 0.0015100858872756362\n",
      "epoch: 6 step: 1835, loss is 0.01394798792898655\n",
      "epoch: 6 step: 1836, loss is 0.0067475466057658195\n",
      "epoch: 6 step: 1837, loss is 0.0008719501784071326\n",
      "epoch: 6 step: 1838, loss is 0.11404404044151306\n",
      "epoch: 6 step: 1839, loss is 0.006395446136593819\n",
      "epoch: 6 step: 1840, loss is 0.0064627681858837605\n",
      "epoch: 6 step: 1841, loss is 6.366646266542375e-05\n",
      "epoch: 6 step: 1842, loss is 0.012694688513875008\n",
      "epoch: 6 step: 1843, loss is 0.01242801919579506\n",
      "epoch: 6 step: 1844, loss is 0.006438222713768482\n",
      "epoch: 6 step: 1845, loss is 0.07968264073133469\n",
      "epoch: 6 step: 1846, loss is 0.0067548491060733795\n",
      "epoch: 6 step: 1847, loss is 0.016912324354052544\n",
      "epoch: 6 step: 1848, loss is 0.00010901852510869503\n",
      "epoch: 6 step: 1849, loss is 4.6183289668988436e-05\n",
      "epoch: 6 step: 1850, loss is 0.020310429856181145\n",
      "epoch: 6 step: 1851, loss is 0.0008464212878607213\n",
      "epoch: 6 step: 1852, loss is 1.030841849569697e-05\n",
      "epoch: 6 step: 1853, loss is 0.0036354265175759792\n",
      "epoch: 6 step: 1854, loss is 0.22487232089042664\n",
      "epoch: 6 step: 1855, loss is 0.00578627735376358\n",
      "epoch: 6 step: 1856, loss is 7.06166320014745e-05\n",
      "epoch: 6 step: 1857, loss is 0.00012174115545349196\n",
      "epoch: 6 step: 1858, loss is 0.1262010782957077\n",
      "epoch: 6 step: 1859, loss is 0.18940047919750214\n",
      "epoch: 6 step: 1860, loss is 0.007168617099523544\n",
      "epoch: 6 step: 1861, loss is 0.0005601726588793099\n",
      "epoch: 6 step: 1862, loss is 0.003327698213979602\n",
      "epoch: 6 step: 1863, loss is 0.0020933635532855988\n",
      "epoch: 6 step: 1864, loss is 0.0005162335000932217\n",
      "epoch: 6 step: 1865, loss is 0.12501640617847443\n",
      "epoch: 6 step: 1866, loss is 0.006674829870462418\n",
      "epoch: 6 step: 1867, loss is 0.0027185785584151745\n",
      "epoch: 6 step: 1868, loss is 0.017073800787329674\n",
      "epoch: 6 step: 1869, loss is 0.008808881044387817\n",
      "epoch: 6 step: 1870, loss is 0.14569532871246338\n",
      "epoch: 6 step: 1871, loss is 0.012673371471464634\n",
      "epoch: 6 step: 1872, loss is 0.0038100581150501966\n",
      "epoch: 6 step: 1873, loss is 0.0005479037063196301\n",
      "epoch: 6 step: 1874, loss is 0.1269836574792862\n",
      "epoch: 6 step: 1875, loss is 0.03414416313171387\n",
      "epoch: 6 step: 1876, loss is 0.0019100714707747102\n",
      "epoch: 6 step: 1877, loss is 0.04363744705915451\n",
      "epoch: 6 step: 1878, loss is 0.0006894918624311686\n",
      "epoch: 6 step: 1879, loss is 0.0005290855187922716\n",
      "epoch: 6 step: 1880, loss is 0.14770524203777313\n",
      "epoch: 6 step: 1881, loss is 0.06048273295164108\n",
      "epoch: 6 step: 1882, loss is 0.0025525307282805443\n",
      "epoch: 6 step: 1883, loss is 0.0014992767246440053\n",
      "epoch: 6 step: 1884, loss is 0.0008893139893189073\n",
      "epoch: 6 step: 1885, loss is 0.024430427700281143\n",
      "epoch: 6 step: 1886, loss is 0.0020310566760599613\n",
      "epoch: 6 step: 1887, loss is 0.0014761068159714341\n",
      "epoch: 6 step: 1888, loss is 0.09906302392482758\n",
      "epoch: 6 step: 1889, loss is 0.047322362661361694\n",
      "epoch: 6 step: 1890, loss is 0.00022089233971200883\n",
      "epoch: 6 step: 1891, loss is 0.002747462596744299\n",
      "epoch: 6 step: 1892, loss is 0.00012365511793177575\n",
      "epoch: 6 step: 1893, loss is 0.00033066311152651906\n",
      "epoch: 6 step: 1894, loss is 0.0001353735278826207\n",
      "epoch: 6 step: 1895, loss is 0.0034577578771859407\n",
      "epoch: 6 step: 1896, loss is 0.22076138854026794\n",
      "epoch: 6 step: 1897, loss is 0.008020353503525257\n",
      "epoch: 6 step: 1898, loss is 0.007584018632769585\n",
      "epoch: 6 step: 1899, loss is 0.003333061933517456\n",
      "epoch: 6 step: 1900, loss is 0.04210413619875908\n",
      "epoch: 6 step: 1901, loss is 0.0031649251468479633\n",
      "epoch: 6 step: 1902, loss is 0.0004745754413306713\n",
      "epoch: 6 step: 1903, loss is 0.0005487503949552774\n",
      "epoch: 6 step: 1904, loss is 0.013033038005232811\n",
      "epoch: 6 step: 1905, loss is 0.0003016953414771706\n",
      "epoch: 6 step: 1906, loss is 0.0006270753801800311\n",
      "epoch: 6 step: 1907, loss is 0.0002659087476786226\n",
      "epoch: 6 step: 1908, loss is 0.0031168016139417887\n",
      "epoch: 6 step: 1909, loss is 0.004051562864333391\n",
      "epoch: 6 step: 1910, loss is 0.14888110756874084\n",
      "epoch: 6 step: 1911, loss is 0.00985134206712246\n",
      "epoch: 6 step: 1912, loss is 0.059968508780002594\n",
      "epoch: 6 step: 1913, loss is 0.0027732192538678646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1914, loss is 0.011082187294960022\n",
      "epoch: 6 step: 1915, loss is 0.013485964387655258\n",
      "epoch: 6 step: 1916, loss is 0.0008629020303487778\n",
      "epoch: 6 step: 1917, loss is 0.00440451642498374\n",
      "epoch: 6 step: 1918, loss is 0.00077523646177724\n",
      "epoch: 6 step: 1919, loss is 0.009510746225714684\n",
      "epoch: 6 step: 1920, loss is 0.0005237485747784376\n",
      "epoch: 6 step: 1921, loss is 0.009036771953105927\n",
      "epoch: 6 step: 1922, loss is 0.00149122707080096\n",
      "epoch: 6 step: 1923, loss is 0.09613257646560669\n",
      "epoch: 6 step: 1924, loss is 0.02750980667769909\n",
      "epoch: 6 step: 1925, loss is 0.005420111119747162\n",
      "epoch: 6 step: 1926, loss is 0.0006967562949284911\n",
      "epoch: 6 step: 1927, loss is 0.11011827737092972\n",
      "epoch: 6 step: 1928, loss is 0.0013503709342330694\n",
      "epoch: 6 step: 1929, loss is 0.005022686440497637\n",
      "epoch: 6 step: 1930, loss is 0.018669353798031807\n",
      "epoch: 6 step: 1931, loss is 0.00037679544766433537\n",
      "epoch: 6 step: 1932, loss is 0.021792786195874214\n",
      "epoch: 6 step: 1933, loss is 0.001947564771398902\n",
      "epoch: 6 step: 1934, loss is 0.024330003187060356\n",
      "epoch: 6 step: 1935, loss is 0.08979695290327072\n",
      "epoch: 6 step: 1936, loss is 7.36253205104731e-05\n",
      "epoch: 6 step: 1937, loss is 0.0005153488600626588\n",
      "epoch: 6 step: 1938, loss is 0.0005849663866683841\n",
      "epoch: 6 step: 1939, loss is 0.0019073683070018888\n",
      "epoch: 6 step: 1940, loss is 0.003471506293863058\n",
      "epoch: 6 step: 1941, loss is 0.13216552138328552\n",
      "epoch: 6 step: 1942, loss is 0.0008569772471673787\n",
      "epoch: 6 step: 1943, loss is 0.005483883433043957\n",
      "epoch: 6 step: 1944, loss is 0.06112438067793846\n",
      "epoch: 6 step: 1945, loss is 0.005551764275878668\n",
      "epoch: 6 step: 1946, loss is 0.0032989615574479103\n",
      "epoch: 6 step: 1947, loss is 0.0016011130064725876\n",
      "epoch: 6 step: 1948, loss is 0.0004513298626989126\n",
      "epoch: 6 step: 1949, loss is 0.00790236983448267\n",
      "epoch: 6 step: 1950, loss is 0.00690038874745369\n",
      "epoch: 6 step: 1951, loss is 0.014766408130526543\n",
      "epoch: 6 step: 1952, loss is 0.0006559470202773809\n",
      "epoch: 6 step: 1953, loss is 0.042170796543359756\n",
      "epoch: 6 step: 1954, loss is 0.016323691233992577\n",
      "epoch: 6 step: 1955, loss is 0.06540980190038681\n",
      "epoch: 6 step: 1956, loss is 0.0009582773200236261\n",
      "epoch: 6 step: 1957, loss is 0.11449813097715378\n",
      "epoch: 6 step: 1958, loss is 0.000506601994857192\n",
      "epoch: 6 step: 1959, loss is 0.024429544806480408\n",
      "epoch: 6 step: 1960, loss is 0.008261127397418022\n",
      "epoch: 6 step: 1961, loss is 0.012951512821018696\n",
      "epoch: 6 step: 1962, loss is 0.00552797457203269\n",
      "epoch: 6 step: 1963, loss is 0.00016722492000553757\n",
      "epoch: 6 step: 1964, loss is 0.00246449070982635\n",
      "epoch: 6 step: 1965, loss is 0.00041827166569419205\n",
      "epoch: 6 step: 1966, loss is 0.006975583732128143\n",
      "epoch: 6 step: 1967, loss is 0.01811770163476467\n",
      "epoch: 6 step: 1968, loss is 0.0035488407593220472\n",
      "epoch: 6 step: 1969, loss is 0.001832572859711945\n",
      "epoch: 6 step: 1970, loss is 0.22597502171993256\n",
      "epoch: 6 step: 1971, loss is 0.000548581825569272\n",
      "epoch: 6 step: 1972, loss is 0.0018655371386557817\n",
      "epoch: 6 step: 1973, loss is 0.012793358415365219\n",
      "epoch: 6 step: 1974, loss is 0.010295660234987736\n",
      "epoch: 6 step: 1975, loss is 0.0021792054176330566\n",
      "epoch: 6 step: 1976, loss is 0.0003150213451590389\n",
      "epoch: 6 step: 1977, loss is 0.000788659555837512\n",
      "epoch: 6 step: 1978, loss is 0.0009301265235990286\n",
      "epoch: 6 step: 1979, loss is 0.027415651828050613\n",
      "epoch: 6 step: 1980, loss is 0.03876601532101631\n",
      "epoch: 6 step: 1981, loss is 0.0012209482956677675\n",
      "epoch: 6 step: 1982, loss is 6.255586049519479e-05\n",
      "epoch: 6 step: 1983, loss is 0.0170671958476305\n",
      "epoch: 6 step: 1984, loss is 0.00031269469764083624\n",
      "epoch: 6 step: 1985, loss is 0.0035537038929760456\n",
      "epoch: 6 step: 1986, loss is 0.03986501321196556\n",
      "epoch: 6 step: 1987, loss is 0.010966356843709946\n",
      "epoch: 6 step: 1988, loss is 0.0032590958289802074\n",
      "epoch: 6 step: 1989, loss is 0.020575610920786858\n",
      "epoch: 6 step: 1990, loss is 0.03522399812936783\n",
      "epoch: 6 step: 1991, loss is 0.010948695242404938\n",
      "epoch: 6 step: 1992, loss is 0.0005072258063592017\n",
      "epoch: 6 step: 1993, loss is 0.03915068134665489\n",
      "epoch: 6 step: 1994, loss is 0.00466959411278367\n",
      "epoch: 6 step: 1995, loss is 0.0028817204292863607\n",
      "epoch: 6 step: 1996, loss is 0.05095219239592552\n",
      "epoch: 6 step: 1997, loss is 0.00511219073086977\n",
      "epoch: 6 step: 1998, loss is 0.00886177085340023\n",
      "epoch: 6 step: 1999, loss is 0.0017208100762218237\n",
      "epoch: 6 step: 2000, loss is 0.044827863574028015\n",
      "epoch: 6 step: 2001, loss is 0.0043510375544428825\n",
      "epoch: 6 step: 2002, loss is 0.005340928211808205\n",
      "epoch: 6 step: 2003, loss is 0.000262920162640512\n",
      "epoch: 6 step: 2004, loss is 0.007826761342585087\n",
      "epoch: 6 step: 2005, loss is 0.0074653420597314835\n",
      "epoch: 6 step: 2006, loss is 0.0031875306740403175\n",
      "epoch: 6 step: 2007, loss is 0.003648853860795498\n",
      "epoch: 6 step: 2008, loss is 0.004371738992631435\n",
      "epoch: 6 step: 2009, loss is 0.00039786906563676894\n",
      "epoch: 6 step: 2010, loss is 0.06635618209838867\n",
      "epoch: 6 step: 2011, loss is 0.20209187269210815\n",
      "epoch: 6 step: 2012, loss is 8.95206267159665e-06\n",
      "epoch: 6 step: 2013, loss is 0.0025451716501265764\n",
      "epoch: 6 step: 2014, loss is 0.004469381179660559\n",
      "epoch: 6 step: 2015, loss is 0.00019387301290407777\n",
      "epoch: 6 step: 2016, loss is 0.08308054506778717\n",
      "epoch: 6 step: 2017, loss is 0.01843707635998726\n",
      "epoch: 6 step: 2018, loss is 3.471851232461631e-05\n",
      "epoch: 6 step: 2019, loss is 0.0005883460398763418\n",
      "epoch: 6 step: 2020, loss is 2.252457124995999e-05\n",
      "epoch: 6 step: 2021, loss is 0.003353280480951071\n",
      "epoch: 6 step: 2022, loss is 0.00037882401375100017\n",
      "epoch: 6 step: 2023, loss is 0.0007361730677075684\n",
      "epoch: 6 step: 2024, loss is 0.0019623753614723682\n",
      "epoch: 6 step: 2025, loss is 0.001367922523058951\n",
      "epoch: 6 step: 2026, loss is 0.0030460550915449858\n",
      "epoch: 6 step: 2027, loss is 0.01805013045668602\n",
      "epoch: 6 step: 2028, loss is 0.12314510345458984\n",
      "epoch: 6 step: 2029, loss is 0.00010611807374516502\n",
      "epoch: 6 step: 2030, loss is 0.0004427004896569997\n",
      "epoch: 6 step: 2031, loss is 0.017786169424653053\n",
      "epoch: 6 step: 2032, loss is 0.04772188887000084\n",
      "epoch: 6 step: 2033, loss is 0.03790518641471863\n",
      "epoch: 6 step: 2034, loss is 0.01343186479061842\n",
      "epoch: 6 step: 2035, loss is 9.851669165072963e-05\n",
      "epoch: 6 step: 2036, loss is 0.002428351901471615\n",
      "epoch: 6 step: 2037, loss is 0.001028616214171052\n",
      "epoch: 6 step: 2038, loss is 0.059524647891521454\n",
      "epoch: 6 step: 2039, loss is 0.011250044219195843\n",
      "epoch: 6 step: 2040, loss is 0.0005771999713033438\n",
      "epoch: 6 step: 2041, loss is 0.006632612552493811\n",
      "epoch: 6 step: 2042, loss is 0.01784198358654976\n",
      "epoch: 6 step: 2043, loss is 0.005592587869614363\n",
      "epoch: 6 step: 2044, loss is 0.07571188360452652\n",
      "epoch: 6 step: 2045, loss is 0.0011878141667693853\n",
      "epoch: 6 step: 2046, loss is 0.0010357071878388524\n",
      "epoch: 6 step: 2047, loss is 0.004240422509610653\n",
      "epoch: 6 step: 2048, loss is 0.00010149014997296035\n",
      "epoch: 6 step: 2049, loss is 0.00045327539555728436\n",
      "epoch: 6 step: 2050, loss is 0.0011083862045779824\n",
      "epoch: 6 step: 2051, loss is 9.445584146305919e-05\n",
      "epoch: 6 step: 2052, loss is 0.1303817480802536\n",
      "epoch: 6 step: 2053, loss is 0.0398680604994297\n",
      "epoch: 6 step: 2054, loss is 0.0003361570416018367\n",
      "epoch: 6 step: 2055, loss is 0.0007776367128826678\n",
      "epoch: 6 step: 2056, loss is 0.08160839974880219\n",
      "epoch: 6 step: 2057, loss is 0.027119968086481094\n",
      "epoch: 6 step: 2058, loss is 0.014879945665597916\n",
      "epoch: 6 step: 2059, loss is 0.00044114887714385986\n",
      "epoch: 6 step: 2060, loss is 0.00130639155395329\n",
      "epoch: 6 step: 2061, loss is 0.0011853653704747558\n",
      "epoch: 6 step: 2062, loss is 0.0008347979746758938\n",
      "epoch: 6 step: 2063, loss is 0.007424245588481426\n",
      "epoch: 6 step: 2064, loss is 0.000830816978123039\n",
      "epoch: 6 step: 2065, loss is 0.0819484144449234\n",
      "epoch: 6 step: 2066, loss is 0.00014132284559309483\n",
      "epoch: 6 step: 2067, loss is 0.01985759846866131\n",
      "epoch: 6 step: 2068, loss is 0.007139555644243956\n",
      "epoch: 6 step: 2069, loss is 0.0006414771196432412\n",
      "epoch: 6 step: 2070, loss is 0.02543051727116108\n",
      "epoch: 6 step: 2071, loss is 0.002246046904474497\n",
      "epoch: 6 step: 2072, loss is 3.7131874705664814e-05\n",
      "epoch: 6 step: 2073, loss is 0.05209412798285484\n",
      "epoch: 6 step: 2074, loss is 0.002818983281031251\n",
      "epoch: 6 step: 2075, loss is 0.031063225120306015\n",
      "epoch: 6 step: 2076, loss is 0.013628695160150528\n",
      "epoch: 6 step: 2077, loss is 0.02577224001288414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 2078, loss is 0.006011787801980972\n",
      "epoch: 6 step: 2079, loss is 0.0012236351612955332\n",
      "epoch: 6 step: 2080, loss is 0.009676230140030384\n",
      "epoch: 6 step: 2081, loss is 0.00016622585826553404\n",
      "epoch: 6 step: 2082, loss is 0.0011032713809981942\n",
      "epoch: 6 step: 2083, loss is 0.018748242408037186\n",
      "epoch: 6 step: 2084, loss is 0.003174732206389308\n",
      "epoch: 6 step: 2085, loss is 0.03596893697977066\n",
      "epoch: 6 step: 2086, loss is 0.005233734380453825\n",
      "epoch: 6 step: 2087, loss is 0.00037776367389597\n",
      "epoch: 6 step: 2088, loss is 0.0006508402875624597\n",
      "epoch: 6 step: 2089, loss is 0.005301196128129959\n",
      "epoch: 6 step: 2090, loss is 0.0007323760073632002\n",
      "epoch: 6 step: 2091, loss is 0.006187063176184893\n",
      "epoch: 6 step: 2092, loss is 0.002165386453270912\n",
      "epoch: 6 step: 2093, loss is 0.00019491063721943647\n",
      "epoch: 6 step: 2094, loss is 0.0009586732485331595\n",
      "epoch: 6 step: 2095, loss is 0.06946467608213425\n",
      "epoch: 6 step: 2096, loss is 0.0014236101415008307\n",
      "epoch: 6 step: 2097, loss is 0.011474806815385818\n",
      "epoch: 6 step: 2098, loss is 0.11137492954730988\n",
      "epoch: 6 step: 2099, loss is 0.0019328498747199774\n",
      "epoch: 6 step: 2100, loss is 6.920612941030413e-05\n",
      "epoch: 6 step: 2101, loss is 0.002120339311659336\n",
      "epoch: 6 step: 2102, loss is 0.009085236117243767\n",
      "epoch: 6 step: 2103, loss is 0.00016347301425412297\n",
      "epoch: 6 step: 2104, loss is 0.0013509419513866305\n",
      "epoch: 6 step: 2105, loss is 0.02003815583884716\n",
      "epoch: 6 step: 2106, loss is 0.0034594140015542507\n",
      "epoch: 6 step: 2107, loss is 0.01396652776747942\n",
      "epoch: 6 step: 2108, loss is 0.0035823993384838104\n",
      "epoch: 6 step: 2109, loss is 0.002789172576740384\n",
      "epoch: 6 step: 2110, loss is 0.00670541450381279\n",
      "epoch: 6 step: 2111, loss is 0.08988265693187714\n",
      "epoch: 6 step: 2112, loss is 0.0013183271512389183\n",
      "epoch: 6 step: 2113, loss is 0.02770976535975933\n",
      "epoch: 6 step: 2114, loss is 0.0011054683709517121\n",
      "epoch: 6 step: 2115, loss is 0.002639814279973507\n",
      "epoch: 6 step: 2116, loss is 0.0009015492396429181\n",
      "epoch: 6 step: 2117, loss is 0.005416615400463343\n",
      "epoch: 6 step: 2118, loss is 0.0033973976969718933\n",
      "epoch: 6 step: 2119, loss is 0.007880184799432755\n",
      "epoch: 6 step: 2120, loss is 0.06881634891033173\n",
      "epoch: 6 step: 2121, loss is 0.10263931006193161\n",
      "epoch: 6 step: 2122, loss is 0.011338915675878525\n",
      "epoch: 6 step: 2123, loss is 0.0498637855052948\n",
      "epoch: 6 step: 2124, loss is 0.008721341378986835\n",
      "epoch: 6 step: 2125, loss is 7.571368769276887e-05\n",
      "epoch: 6 step: 2126, loss is 0.050715964287519455\n",
      "epoch: 6 step: 2127, loss is 8.677808364154771e-05\n",
      "epoch: 6 step: 2128, loss is 0.022958187386393547\n",
      "epoch: 6 step: 2129, loss is 0.0018549143569543958\n",
      "epoch: 6 step: 2130, loss is 0.0001665569725446403\n",
      "epoch: 6 step: 2131, loss is 0.009198012761771679\n",
      "epoch: 6 step: 2132, loss is 0.007997511886060238\n",
      "epoch: 6 step: 2133, loss is 0.0267866812646389\n",
      "epoch: 6 step: 2134, loss is 0.0003567625826690346\n",
      "epoch: 6 step: 2135, loss is 0.00011395628825994208\n",
      "epoch: 6 step: 2136, loss is 0.023518245667219162\n",
      "epoch: 6 step: 2137, loss is 0.0004340636951383203\n",
      "epoch: 6 step: 2138, loss is 0.036508478224277496\n",
      "epoch: 6 step: 2139, loss is 0.08478999137878418\n",
      "epoch: 6 step: 2140, loss is 0.1233835443854332\n",
      "epoch: 6 step: 2141, loss is 0.007476072758436203\n",
      "epoch: 6 step: 2142, loss is 0.1018650233745575\n",
      "epoch: 6 step: 2143, loss is 0.006004702765494585\n",
      "epoch: 6 step: 2144, loss is 0.005872504319995642\n",
      "epoch: 6 step: 2145, loss is 0.01414929423481226\n",
      "epoch: 6 step: 2146, loss is 0.017450442537665367\n",
      "epoch: 6 step: 2147, loss is 0.003778176149353385\n",
      "epoch: 6 step: 2148, loss is 0.0009482114692218602\n",
      "epoch: 6 step: 2149, loss is 0.03232689946889877\n",
      "epoch: 6 step: 2150, loss is 0.04478586092591286\n",
      "epoch: 6 step: 2151, loss is 0.005704458337277174\n",
      "epoch: 6 step: 2152, loss is 0.005746733397245407\n",
      "epoch: 6 step: 2153, loss is 4.1873314330587164e-05\n",
      "epoch: 6 step: 2154, loss is 0.021056262776255608\n",
      "epoch: 6 step: 2155, loss is 0.0006602221401408315\n",
      "epoch: 6 step: 2156, loss is 0.011957411654293537\n",
      "epoch: 6 step: 2157, loss is 7.373589323833585e-05\n",
      "epoch: 6 step: 2158, loss is 6.054413825040683e-05\n",
      "epoch: 6 step: 2159, loss is 0.3271460235118866\n",
      "epoch: 6 step: 2160, loss is 0.0011557182297110558\n",
      "epoch: 6 step: 2161, loss is 0.0006562889320775867\n",
      "epoch: 6 step: 2162, loss is 0.129072904586792\n",
      "epoch: 6 step: 2163, loss is 0.022991321980953217\n",
      "epoch: 6 step: 2164, loss is 0.0035404583904892206\n",
      "epoch: 6 step: 2165, loss is 0.0008130368660204113\n",
      "epoch: 6 step: 2166, loss is 0.00019493253785185516\n",
      "epoch: 6 step: 2167, loss is 0.09037643671035767\n",
      "epoch: 6 step: 2168, loss is 0.05293191596865654\n",
      "epoch: 6 step: 2169, loss is 0.0003589748521335423\n",
      "epoch: 6 step: 2170, loss is 0.0009116028086282313\n",
      "epoch: 6 step: 2171, loss is 0.0026503955014050007\n",
      "epoch: 6 step: 2172, loss is 0.01889481022953987\n",
      "epoch: 6 step: 2173, loss is 0.025481820106506348\n",
      "epoch: 6 step: 2174, loss is 0.020478978753089905\n",
      "epoch: 6 step: 2175, loss is 0.006810723803937435\n",
      "epoch: 6 step: 2176, loss is 0.008205359801650047\n",
      "epoch: 6 step: 2177, loss is 0.0005589637439697981\n",
      "epoch: 6 step: 2178, loss is 0.00029204002930782735\n",
      "epoch: 6 step: 2179, loss is 0.0060166725888848305\n",
      "epoch: 6 step: 2180, loss is 0.05439479649066925\n",
      "epoch: 6 step: 2181, loss is 0.0002757542533800006\n",
      "epoch: 6 step: 2182, loss is 0.002498718909919262\n",
      "epoch: 6 step: 2183, loss is 0.01227451954036951\n",
      "epoch: 6 step: 2184, loss is 0.0005824493709951639\n",
      "epoch: 6 step: 2185, loss is 0.0016879012109711766\n",
      "epoch: 6 step: 2186, loss is 0.00579479057341814\n",
      "epoch: 6 step: 2187, loss is 0.0014374711317941546\n",
      "epoch: 7 step: 1, loss is 9.794885409064591e-05\n",
      "epoch: 7 step: 2, loss is 0.0014570584753528237\n",
      "epoch: 7 step: 3, loss is 0.026618236675858498\n",
      "epoch: 7 step: 4, loss is 0.0013023419305682182\n",
      "epoch: 7 step: 5, loss is 0.0002560168213676661\n",
      "epoch: 7 step: 6, loss is 5.6050295825116336e-05\n",
      "epoch: 7 step: 7, loss is 0.0002265918446937576\n",
      "epoch: 7 step: 8, loss is 0.00031680299434810877\n",
      "epoch: 7 step: 9, loss is 0.02786041609942913\n",
      "epoch: 7 step: 10, loss is 0.0007470606942661107\n",
      "epoch: 7 step: 11, loss is 0.0001934362226165831\n",
      "epoch: 7 step: 12, loss is 0.021414589136838913\n",
      "epoch: 7 step: 13, loss is 0.0001689861819613725\n",
      "epoch: 7 step: 14, loss is 0.0026903008110821247\n",
      "epoch: 7 step: 15, loss is 0.0007176997023634613\n",
      "epoch: 7 step: 16, loss is 0.0006685085245408118\n",
      "epoch: 7 step: 17, loss is 0.03116973675787449\n",
      "epoch: 7 step: 18, loss is 0.0015038646524772048\n",
      "epoch: 7 step: 19, loss is 0.002661975799128413\n",
      "epoch: 7 step: 20, loss is 0.0002194062399212271\n",
      "epoch: 7 step: 21, loss is 0.022574961185455322\n",
      "epoch: 7 step: 22, loss is 0.021634357050061226\n",
      "epoch: 7 step: 23, loss is 0.009137335233390331\n",
      "epoch: 7 step: 24, loss is 0.05134684592485428\n",
      "epoch: 7 step: 25, loss is 0.0004285758186597377\n",
      "epoch: 7 step: 26, loss is 0.00044180898112244904\n",
      "epoch: 7 step: 27, loss is 0.06381455808877945\n",
      "epoch: 7 step: 28, loss is 0.00226439512334764\n",
      "epoch: 7 step: 29, loss is 0.005836206488311291\n",
      "epoch: 7 step: 30, loss is 0.0005116687971167266\n",
      "epoch: 7 step: 31, loss is 0.0016700862906873226\n",
      "epoch: 7 step: 32, loss is 0.10065124928951263\n",
      "epoch: 7 step: 33, loss is 0.0016634673811495304\n",
      "epoch: 7 step: 34, loss is 0.001769743743352592\n",
      "epoch: 7 step: 35, loss is 0.15201400220394135\n",
      "epoch: 7 step: 36, loss is 7.574062328785658e-05\n",
      "epoch: 7 step: 37, loss is 0.025934701785445213\n",
      "epoch: 7 step: 38, loss is 0.0039468323811888695\n",
      "epoch: 7 step: 39, loss is 0.00032097159419208765\n",
      "epoch: 7 step: 40, loss is 0.11230005323886871\n",
      "epoch: 7 step: 41, loss is 8.41684959596023e-05\n",
      "epoch: 7 step: 42, loss is 0.00011749770055757836\n",
      "epoch: 7 step: 43, loss is 0.005656637251377106\n",
      "epoch: 7 step: 44, loss is 0.00028978753834962845\n",
      "epoch: 7 step: 45, loss is 0.0045481096021831036\n",
      "epoch: 7 step: 46, loss is 0.014088972471654415\n",
      "epoch: 7 step: 47, loss is 0.01390073075890541\n",
      "epoch: 7 step: 48, loss is 0.06919369846582413\n",
      "epoch: 7 step: 49, loss is 0.003296456066891551\n",
      "epoch: 7 step: 50, loss is 0.0008380720391869545\n",
      "epoch: 7 step: 51, loss is 0.0001631547202123329\n",
      "epoch: 7 step: 52, loss is 0.0005825560656376183\n",
      "epoch: 7 step: 53, loss is 0.0015975042479112744\n",
      "epoch: 7 step: 54, loss is 0.0004689016495831311\n",
      "epoch: 7 step: 55, loss is 0.003860792610794306\n",
      "epoch: 7 step: 56, loss is 0.0006895629921928048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 57, loss is 0.0004092292510904372\n",
      "epoch: 7 step: 58, loss is 0.004465295933187008\n",
      "epoch: 7 step: 59, loss is 0.00046483881305903196\n",
      "epoch: 7 step: 60, loss is 5.237782170297578e-05\n",
      "epoch: 7 step: 61, loss is 0.004343531560152769\n",
      "epoch: 7 step: 62, loss is 0.005302842240780592\n",
      "epoch: 7 step: 63, loss is 0.005415725987404585\n",
      "epoch: 7 step: 64, loss is 0.000735576031729579\n",
      "epoch: 7 step: 65, loss is 0.0005064081051386893\n",
      "epoch: 7 step: 66, loss is 0.051847320050001144\n",
      "epoch: 7 step: 67, loss is 0.015020701102912426\n",
      "epoch: 7 step: 68, loss is 0.00036306248512119055\n",
      "epoch: 7 step: 69, loss is 0.0052267746068537235\n",
      "epoch: 7 step: 70, loss is 0.004703313112258911\n",
      "epoch: 7 step: 71, loss is 9.414361556991935e-06\n",
      "epoch: 7 step: 72, loss is 0.0068551781587302685\n",
      "epoch: 7 step: 73, loss is 0.008247233927249908\n",
      "epoch: 7 step: 74, loss is 0.00036535284016281366\n",
      "epoch: 7 step: 75, loss is 0.0018629113910719752\n",
      "epoch: 7 step: 76, loss is 0.023733660578727722\n",
      "epoch: 7 step: 77, loss is 0.07209733128547668\n",
      "epoch: 7 step: 78, loss is 0.0001606234727660194\n",
      "epoch: 7 step: 79, loss is 0.0006427880725823343\n",
      "epoch: 7 step: 80, loss is 0.00677820248529315\n",
      "epoch: 7 step: 81, loss is 0.0036944421008229256\n",
      "epoch: 7 step: 82, loss is 0.0008057511877268553\n",
      "epoch: 7 step: 83, loss is 5.936684101470746e-05\n",
      "epoch: 7 step: 84, loss is 0.0006509432569146156\n",
      "epoch: 7 step: 85, loss is 3.9496939280070364e-05\n",
      "epoch: 7 step: 86, loss is 0.011783147230744362\n",
      "epoch: 7 step: 87, loss is 0.006713171023875475\n",
      "epoch: 7 step: 88, loss is 0.006620137020945549\n",
      "epoch: 7 step: 89, loss is 0.020144687965512276\n",
      "epoch: 7 step: 90, loss is 0.00250450661405921\n",
      "epoch: 7 step: 91, loss is 0.00018075077969115227\n",
      "epoch: 7 step: 92, loss is 0.00010544944962020963\n",
      "epoch: 7 step: 93, loss is 4.1294857510365546e-05\n",
      "epoch: 7 step: 94, loss is 0.0003091262769885361\n",
      "epoch: 7 step: 95, loss is 0.001085046329535544\n",
      "epoch: 7 step: 96, loss is 0.023068688809871674\n",
      "epoch: 7 step: 97, loss is 0.00017196836415678263\n",
      "epoch: 7 step: 98, loss is 0.03928934037685394\n",
      "epoch: 7 step: 99, loss is 0.0006900118314661086\n",
      "epoch: 7 step: 100, loss is 0.00014362254296429455\n",
      "epoch: 7 step: 101, loss is 0.11033044010400772\n",
      "epoch: 7 step: 102, loss is 2.0152430806774646e-05\n",
      "epoch: 7 step: 103, loss is 0.034110795706510544\n",
      "epoch: 7 step: 104, loss is 0.0005804951069876552\n",
      "epoch: 7 step: 105, loss is 0.00010421696788398549\n",
      "epoch: 7 step: 106, loss is 0.0025336039252579212\n",
      "epoch: 7 step: 107, loss is 0.0005033420748077333\n",
      "epoch: 7 step: 108, loss is 0.004496301524341106\n",
      "epoch: 7 step: 109, loss is 0.0005254863062873483\n",
      "epoch: 7 step: 110, loss is 0.040063150227069855\n",
      "epoch: 7 step: 111, loss is 0.0034092033747583628\n",
      "epoch: 7 step: 112, loss is 0.000335887772962451\n",
      "epoch: 7 step: 113, loss is 0.011036464013159275\n",
      "epoch: 7 step: 114, loss is 0.06922633945941925\n",
      "epoch: 7 step: 115, loss is 0.0028628152795135975\n",
      "epoch: 7 step: 116, loss is 0.00040973760769702494\n",
      "epoch: 7 step: 117, loss is 0.026037683710455894\n",
      "epoch: 7 step: 118, loss is 0.006928869988769293\n",
      "epoch: 7 step: 119, loss is 0.00013467339158523828\n",
      "epoch: 7 step: 120, loss is 0.005916649475693703\n",
      "epoch: 7 step: 121, loss is 0.0025013245176523924\n",
      "epoch: 7 step: 122, loss is 0.009373792447149754\n",
      "epoch: 7 step: 123, loss is 0.010492892004549503\n",
      "epoch: 7 step: 124, loss is 5.550617788685486e-05\n",
      "epoch: 7 step: 125, loss is 0.03769093006849289\n",
      "epoch: 7 step: 126, loss is 0.006778493523597717\n",
      "epoch: 7 step: 127, loss is 0.0007348082726821303\n",
      "epoch: 7 step: 128, loss is 0.00011946754239033908\n",
      "epoch: 7 step: 129, loss is 0.007286510430276394\n",
      "epoch: 7 step: 130, loss is 0.001956949010491371\n",
      "epoch: 7 step: 131, loss is 0.0054025775752961636\n",
      "epoch: 7 step: 132, loss is 0.0001743940229061991\n",
      "epoch: 7 step: 133, loss is 0.0004181138938292861\n",
      "epoch: 7 step: 134, loss is 0.007016654126346111\n",
      "epoch: 7 step: 135, loss is 3.247128915973008e-05\n",
      "epoch: 7 step: 136, loss is 0.0010349588701501489\n",
      "epoch: 7 step: 137, loss is 0.0002273223508382216\n",
      "epoch: 7 step: 138, loss is 0.0006289242301136255\n",
      "epoch: 7 step: 139, loss is 0.027778491377830505\n",
      "epoch: 7 step: 140, loss is 0.05695111304521561\n",
      "epoch: 7 step: 141, loss is 0.037775661796331406\n",
      "epoch: 7 step: 142, loss is 0.00032435261528007686\n",
      "epoch: 7 step: 143, loss is 0.015164713375270367\n",
      "epoch: 7 step: 144, loss is 0.07954232394695282\n",
      "epoch: 7 step: 145, loss is 0.001659800997003913\n",
      "epoch: 7 step: 146, loss is 0.00018667806580197066\n",
      "epoch: 7 step: 147, loss is 0.0003375019005034119\n",
      "epoch: 7 step: 148, loss is 0.0005764483939856291\n",
      "epoch: 7 step: 149, loss is 0.004647477529942989\n",
      "epoch: 7 step: 150, loss is 0.01626189798116684\n",
      "epoch: 7 step: 151, loss is 0.024226289242506027\n",
      "epoch: 7 step: 152, loss is 0.13251878321170807\n",
      "epoch: 7 step: 153, loss is 0.05162205547094345\n",
      "epoch: 7 step: 154, loss is 0.036709558218717575\n",
      "epoch: 7 step: 155, loss is 0.05077878758311272\n",
      "epoch: 7 step: 156, loss is 0.13247284293174744\n",
      "epoch: 7 step: 157, loss is 0.0007174533675424755\n",
      "epoch: 7 step: 158, loss is 0.2701510488986969\n",
      "epoch: 7 step: 159, loss is 0.00037665333366021514\n",
      "epoch: 7 step: 160, loss is 0.08345102518796921\n",
      "epoch: 7 step: 161, loss is 0.0002685533545445651\n",
      "epoch: 7 step: 162, loss is 0.049405086785554886\n",
      "epoch: 7 step: 163, loss is 0.0004963069222867489\n",
      "epoch: 7 step: 164, loss is 0.0002875210193451494\n",
      "epoch: 7 step: 165, loss is 0.005238932557404041\n",
      "epoch: 7 step: 166, loss is 0.015851804986596107\n",
      "epoch: 7 step: 167, loss is 0.05380485579371452\n",
      "epoch: 7 step: 168, loss is 0.0011276358272880316\n",
      "epoch: 7 step: 169, loss is 0.003472851123660803\n",
      "epoch: 7 step: 170, loss is 0.04446158930659294\n",
      "epoch: 7 step: 171, loss is 0.001936452928930521\n",
      "epoch: 7 step: 172, loss is 0.002293149009346962\n",
      "epoch: 7 step: 173, loss is 0.001502590486779809\n",
      "epoch: 7 step: 174, loss is 0.0026292777620255947\n",
      "epoch: 7 step: 175, loss is 0.01620103418827057\n",
      "epoch: 7 step: 176, loss is 0.0015716890338808298\n",
      "epoch: 7 step: 177, loss is 0.006459523923695087\n",
      "epoch: 7 step: 178, loss is 0.01041899248957634\n",
      "epoch: 7 step: 179, loss is 5.1405826525297016e-05\n",
      "epoch: 7 step: 180, loss is 0.004188003949820995\n",
      "epoch: 7 step: 181, loss is 2.468344973749481e-05\n",
      "epoch: 7 step: 182, loss is 0.0001161221953225322\n",
      "epoch: 7 step: 183, loss is 0.00117562897503376\n",
      "epoch: 7 step: 184, loss is 0.0019400690216571093\n",
      "epoch: 7 step: 185, loss is 0.0003035101108253002\n",
      "epoch: 7 step: 186, loss is 9.479439904680476e-05\n",
      "epoch: 7 step: 187, loss is 0.0008242239709943533\n",
      "epoch: 7 step: 188, loss is 0.004286581184715033\n",
      "epoch: 7 step: 189, loss is 0.01763424649834633\n",
      "epoch: 7 step: 190, loss is 0.009361526928842068\n",
      "epoch: 7 step: 191, loss is 0.004033609293401241\n",
      "epoch: 7 step: 192, loss is 0.006244382821023464\n",
      "epoch: 7 step: 193, loss is 0.1310078203678131\n",
      "epoch: 7 step: 194, loss is 0.001213854760862887\n",
      "epoch: 7 step: 195, loss is 0.05759989470243454\n",
      "epoch: 7 step: 196, loss is 0.0002640409511514008\n",
      "epoch: 7 step: 197, loss is 0.011734637431800365\n",
      "epoch: 7 step: 198, loss is 2.235928513982799e-05\n",
      "epoch: 7 step: 199, loss is 0.09199916571378708\n",
      "epoch: 7 step: 200, loss is 0.026954006403684616\n",
      "epoch: 7 step: 201, loss is 0.0006583546637557447\n",
      "epoch: 7 step: 202, loss is 0.0034141705837100744\n",
      "epoch: 7 step: 203, loss is 0.005454724188894033\n",
      "epoch: 7 step: 204, loss is 4.413847273099236e-05\n",
      "epoch: 7 step: 205, loss is 0.0022639757953584194\n",
      "epoch: 7 step: 206, loss is 0.0019291929202154279\n",
      "epoch: 7 step: 207, loss is 4.305973925511353e-05\n",
      "epoch: 7 step: 208, loss is 0.0025433674454689026\n",
      "epoch: 7 step: 209, loss is 0.006497567053884268\n",
      "epoch: 7 step: 210, loss is 0.00019396324933040887\n",
      "epoch: 7 step: 211, loss is 0.0007766098133288324\n",
      "epoch: 7 step: 212, loss is 0.06049531698226929\n",
      "epoch: 7 step: 213, loss is 0.00917349848896265\n",
      "epoch: 7 step: 214, loss is 0.006569122429937124\n",
      "epoch: 7 step: 215, loss is 0.013744588941335678\n",
      "epoch: 7 step: 216, loss is 0.0008877422660589218\n",
      "epoch: 7 step: 217, loss is 0.06701730191707611\n",
      "epoch: 7 step: 218, loss is 0.0007545922417193651\n",
      "epoch: 7 step: 219, loss is 0.0003292378969490528\n",
      "epoch: 7 step: 220, loss is 0.006974057760089636\n",
      "epoch: 7 step: 221, loss is 0.05534912273287773\n",
      "epoch: 7 step: 222, loss is 6.024134563631378e-05\n",
      "epoch: 7 step: 223, loss is 0.0001664471928961575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 224, loss is 0.009662728756666183\n",
      "epoch: 7 step: 225, loss is 0.008976947516202927\n",
      "epoch: 7 step: 226, loss is 0.03874506428837776\n",
      "epoch: 7 step: 227, loss is 0.007120535708963871\n",
      "epoch: 7 step: 228, loss is 0.002255744766443968\n",
      "epoch: 7 step: 229, loss is 0.0049845874309539795\n",
      "epoch: 7 step: 230, loss is 0.012102097272872925\n",
      "epoch: 7 step: 231, loss is 0.000939693592954427\n",
      "epoch: 7 step: 232, loss is 0.00038918067002668977\n",
      "epoch: 7 step: 233, loss is 0.0020025221165269613\n",
      "epoch: 7 step: 234, loss is 0.049840811640024185\n",
      "epoch: 7 step: 235, loss is 0.0033035073429346085\n",
      "epoch: 7 step: 236, loss is 7.689270205446519e-06\n",
      "epoch: 7 step: 237, loss is 0.042356960475444794\n",
      "epoch: 7 step: 238, loss is 0.00437817582860589\n",
      "epoch: 7 step: 239, loss is 0.0021460470743477345\n",
      "epoch: 7 step: 240, loss is 0.004246702417731285\n",
      "epoch: 7 step: 241, loss is 0.00017318299796897918\n",
      "epoch: 7 step: 242, loss is 0.0002671743859536946\n",
      "epoch: 7 step: 243, loss is 0.0002975461829919368\n",
      "epoch: 7 step: 244, loss is 0.01302589476108551\n",
      "epoch: 7 step: 245, loss is 0.024160262197256088\n",
      "epoch: 7 step: 246, loss is 0.0002123560116160661\n",
      "epoch: 7 step: 247, loss is 0.002824031747877598\n",
      "epoch: 7 step: 248, loss is 0.013068892061710358\n",
      "epoch: 7 step: 249, loss is 0.0002036621590377763\n",
      "epoch: 7 step: 250, loss is 0.011870778165757656\n",
      "epoch: 7 step: 251, loss is 0.00018974466365762055\n",
      "epoch: 7 step: 252, loss is 0.0009391208877786994\n",
      "epoch: 7 step: 253, loss is 0.0026080862153321505\n",
      "epoch: 7 step: 254, loss is 1.3597751603811048e-05\n",
      "epoch: 7 step: 255, loss is 0.0009945888305082917\n",
      "epoch: 7 step: 256, loss is 0.0005622125463560224\n",
      "epoch: 7 step: 257, loss is 0.0007800362654961646\n",
      "epoch: 7 step: 258, loss is 7.124279363779351e-05\n",
      "epoch: 7 step: 259, loss is 0.011460459791123867\n",
      "epoch: 7 step: 260, loss is 0.0153371412307024\n",
      "epoch: 7 step: 261, loss is 0.0021325326524674892\n",
      "epoch: 7 step: 262, loss is 0.00014802024816162884\n",
      "epoch: 7 step: 263, loss is 0.00010619925160426646\n",
      "epoch: 7 step: 264, loss is 9.699443762656301e-05\n",
      "epoch: 7 step: 265, loss is 0.0002699850301723927\n",
      "epoch: 7 step: 266, loss is 0.0034304680302739143\n",
      "epoch: 7 step: 267, loss is 4.3660911615006626e-05\n",
      "epoch: 7 step: 268, loss is 0.00016651967598591\n",
      "epoch: 7 step: 269, loss is 0.01055788155645132\n",
      "epoch: 7 step: 270, loss is 0.02311992645263672\n",
      "epoch: 7 step: 271, loss is 0.0005529580521397293\n",
      "epoch: 7 step: 272, loss is 7.052289583953097e-05\n",
      "epoch: 7 step: 273, loss is 0.00020478447549976408\n",
      "epoch: 7 step: 274, loss is 0.15914547443389893\n",
      "epoch: 7 step: 275, loss is 8.262927622126881e-06\n",
      "epoch: 7 step: 276, loss is 0.013663641177117825\n",
      "epoch: 7 step: 277, loss is 0.0003635954635683447\n",
      "epoch: 7 step: 278, loss is 4.8359797801822424e-05\n",
      "epoch: 7 step: 279, loss is 0.02026546373963356\n",
      "epoch: 7 step: 280, loss is 0.007375956978648901\n",
      "epoch: 7 step: 281, loss is 0.0034162632655352354\n",
      "epoch: 7 step: 282, loss is 0.0018030203646048903\n",
      "epoch: 7 step: 283, loss is 0.0008378042257390916\n",
      "epoch: 7 step: 284, loss is 0.01788823865354061\n",
      "epoch: 7 step: 285, loss is 0.011578201316297054\n",
      "epoch: 7 step: 286, loss is 0.0042792209424078465\n",
      "epoch: 7 step: 287, loss is 0.00014786618703510612\n",
      "epoch: 7 step: 288, loss is 0.0004277299449313432\n",
      "epoch: 7 step: 289, loss is 0.001392335630953312\n",
      "epoch: 7 step: 290, loss is 0.14046117663383484\n",
      "epoch: 7 step: 291, loss is 0.0013249729527160525\n",
      "epoch: 7 step: 292, loss is 0.015383029356598854\n",
      "epoch: 7 step: 293, loss is 0.016527209430933\n",
      "epoch: 7 step: 294, loss is 0.001054698950611055\n",
      "epoch: 7 step: 295, loss is 0.05049576610326767\n",
      "epoch: 7 step: 296, loss is 0.0003168139955960214\n",
      "epoch: 7 step: 297, loss is 0.02574848383665085\n",
      "epoch: 7 step: 298, loss is 0.0021087639033794403\n",
      "epoch: 7 step: 299, loss is 0.023763692006468773\n",
      "epoch: 7 step: 300, loss is 0.002041734755039215\n",
      "epoch: 7 step: 301, loss is 0.0016069869743660092\n",
      "epoch: 7 step: 302, loss is 0.12772944569587708\n",
      "epoch: 7 step: 303, loss is 0.004000845830887556\n",
      "epoch: 7 step: 304, loss is 0.0020920189563184977\n",
      "epoch: 7 step: 305, loss is 0.0012502921745181084\n",
      "epoch: 7 step: 306, loss is 0.0011194179533049464\n",
      "epoch: 7 step: 307, loss is 0.0014239427400752902\n",
      "epoch: 7 step: 308, loss is 0.0003585302329156548\n",
      "epoch: 7 step: 309, loss is 0.0004199792165309191\n",
      "epoch: 7 step: 310, loss is 0.0031614694744348526\n",
      "epoch: 7 step: 311, loss is 0.00017368540284223855\n",
      "epoch: 7 step: 312, loss is 0.03024921379983425\n",
      "epoch: 7 step: 313, loss is 0.03962244465947151\n",
      "epoch: 7 step: 314, loss is 0.00015451481158379465\n",
      "epoch: 7 step: 315, loss is 0.0006326533039100468\n",
      "epoch: 7 step: 316, loss is 0.02566598355770111\n",
      "epoch: 7 step: 317, loss is 0.0010880355257540941\n",
      "epoch: 7 step: 318, loss is 0.0012928139185532928\n",
      "epoch: 7 step: 319, loss is 0.0024155168794095516\n",
      "epoch: 7 step: 320, loss is 0.00012742989929392934\n",
      "epoch: 7 step: 321, loss is 0.0026730848476290703\n",
      "epoch: 7 step: 322, loss is 6.136559386504814e-05\n",
      "epoch: 7 step: 323, loss is 0.004036317579448223\n",
      "epoch: 7 step: 324, loss is 0.0016280817799270153\n",
      "epoch: 7 step: 325, loss is 0.005262112244963646\n",
      "epoch: 7 step: 326, loss is 0.00120845518540591\n",
      "epoch: 7 step: 327, loss is 0.0041899653151631355\n",
      "epoch: 7 step: 328, loss is 0.002456375863403082\n",
      "epoch: 7 step: 329, loss is 0.008011306636035442\n",
      "epoch: 7 step: 330, loss is 0.11640322208404541\n",
      "epoch: 7 step: 331, loss is 0.00024962396128103137\n",
      "epoch: 7 step: 332, loss is 0.010146040469408035\n",
      "epoch: 7 step: 333, loss is 0.0005764606175944209\n",
      "epoch: 7 step: 334, loss is 0.0005103919538669288\n",
      "epoch: 7 step: 335, loss is 0.16047503054141998\n",
      "epoch: 7 step: 336, loss is 0.03925032168626785\n",
      "epoch: 7 step: 337, loss is 0.08994974941015244\n",
      "epoch: 7 step: 338, loss is 0.00028505895170383155\n",
      "epoch: 7 step: 339, loss is 0.09056112170219421\n",
      "epoch: 7 step: 340, loss is 0.00020046927966177464\n",
      "epoch: 7 step: 341, loss is 0.00035165532608516514\n",
      "epoch: 7 step: 342, loss is 0.0007373110856860876\n",
      "epoch: 7 step: 343, loss is 0.05958488583564758\n",
      "epoch: 7 step: 344, loss is 0.0002323762164451182\n",
      "epoch: 7 step: 345, loss is 0.0009083984768949449\n",
      "epoch: 7 step: 346, loss is 0.011256374418735504\n",
      "epoch: 7 step: 347, loss is 0.024513844400644302\n",
      "epoch: 7 step: 348, loss is 0.0008836198830977082\n",
      "epoch: 7 step: 349, loss is 0.004124550614506006\n",
      "epoch: 7 step: 350, loss is 0.010311604477465153\n",
      "epoch: 7 step: 351, loss is 0.0002734377922024578\n",
      "epoch: 7 step: 352, loss is 7.566841668449342e-05\n",
      "epoch: 7 step: 353, loss is 0.06226341426372528\n",
      "epoch: 7 step: 354, loss is 0.0007302709855139256\n",
      "epoch: 7 step: 355, loss is 0.0001627944002393633\n",
      "epoch: 7 step: 356, loss is 0.009690641425549984\n",
      "epoch: 7 step: 357, loss is 5.4888485465198755e-05\n",
      "epoch: 7 step: 358, loss is 0.00039993913378566504\n",
      "epoch: 7 step: 359, loss is 0.00039022357668727636\n",
      "epoch: 7 step: 360, loss is 0.0031000834424048662\n",
      "epoch: 7 step: 361, loss is 0.0009174811420962214\n",
      "epoch: 7 step: 362, loss is 0.0051271868869662285\n",
      "epoch: 7 step: 363, loss is 0.00016040397167671472\n",
      "epoch: 7 step: 364, loss is 0.00014940297114662826\n",
      "epoch: 7 step: 365, loss is 0.007844474166631699\n",
      "epoch: 7 step: 366, loss is 0.00034678290830925107\n",
      "epoch: 7 step: 367, loss is 0.0006823253352195024\n",
      "epoch: 7 step: 368, loss is 0.00016104915994219482\n",
      "epoch: 7 step: 369, loss is 0.006592644844204187\n",
      "epoch: 7 step: 370, loss is 0.0005182524328120053\n",
      "epoch: 7 step: 371, loss is 0.0008197647402994335\n",
      "epoch: 7 step: 372, loss is 2.7483454687171616e-05\n",
      "epoch: 7 step: 373, loss is 0.003543115220963955\n",
      "epoch: 7 step: 374, loss is 0.0011126560857519507\n",
      "epoch: 7 step: 375, loss is 0.001453078119084239\n",
      "epoch: 7 step: 376, loss is 0.00011261129111517221\n",
      "epoch: 7 step: 377, loss is 0.00021209860278759152\n",
      "epoch: 7 step: 378, loss is 0.0014723954955115914\n",
      "epoch: 7 step: 379, loss is 0.001154051860794425\n",
      "epoch: 7 step: 380, loss is 0.001071039354428649\n",
      "epoch: 7 step: 381, loss is 0.0013043800136074424\n",
      "epoch: 7 step: 382, loss is 0.00965105276554823\n",
      "epoch: 7 step: 383, loss is 0.0005614840192720294\n",
      "epoch: 7 step: 384, loss is 0.00013771108933724463\n",
      "epoch: 7 step: 385, loss is 0.03628639131784439\n",
      "epoch: 7 step: 386, loss is 0.004685745108872652\n",
      "epoch: 7 step: 387, loss is 0.00010016428859671578\n",
      "epoch: 7 step: 388, loss is 0.0006402608123607934\n",
      "epoch: 7 step: 389, loss is 0.003092039842158556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 390, loss is 7.894927693996578e-05\n",
      "epoch: 7 step: 391, loss is 0.0003846618055831641\n",
      "epoch: 7 step: 392, loss is 0.00043262209510430694\n",
      "epoch: 7 step: 393, loss is 0.006630514282733202\n",
      "epoch: 7 step: 394, loss is 0.003956445027142763\n",
      "epoch: 7 step: 395, loss is 0.11084303259849548\n",
      "epoch: 7 step: 396, loss is 0.025379030033946037\n",
      "epoch: 7 step: 397, loss is 0.00044402058119885623\n",
      "epoch: 7 step: 398, loss is 0.0006949265371076763\n",
      "epoch: 7 step: 399, loss is 0.0014424278633669019\n",
      "epoch: 7 step: 400, loss is 0.0011621264275163412\n",
      "epoch: 7 step: 401, loss is 0.00010667987953638658\n",
      "epoch: 7 step: 402, loss is 0.00015366179286502302\n",
      "epoch: 7 step: 403, loss is 0.009532179683446884\n",
      "epoch: 7 step: 404, loss is 0.0009201045613735914\n",
      "epoch: 7 step: 405, loss is 0.0027681542560458183\n",
      "epoch: 7 step: 406, loss is 0.025632914155721664\n",
      "epoch: 7 step: 407, loss is 0.006777246482670307\n",
      "epoch: 7 step: 408, loss is 0.0008446623105555773\n",
      "epoch: 7 step: 409, loss is 0.000672082242090255\n",
      "epoch: 7 step: 410, loss is 0.00025583538808859885\n",
      "epoch: 7 step: 411, loss is 0.0013459414476528764\n",
      "epoch: 7 step: 412, loss is 0.0001328436628682539\n",
      "epoch: 7 step: 413, loss is 0.015605670399963856\n",
      "epoch: 7 step: 414, loss is 0.03380328044295311\n",
      "epoch: 7 step: 415, loss is 0.036360736936330795\n",
      "epoch: 7 step: 416, loss is 9.643613884691149e-05\n",
      "epoch: 7 step: 417, loss is 0.004857172723859549\n",
      "epoch: 7 step: 418, loss is 0.00016036178567446768\n",
      "epoch: 7 step: 419, loss is 0.026440469548106194\n",
      "epoch: 7 step: 420, loss is 0.02785443514585495\n",
      "epoch: 7 step: 421, loss is 0.09746699780225754\n",
      "epoch: 7 step: 422, loss is 5.8139001339441165e-05\n",
      "epoch: 7 step: 423, loss is 0.0006250021979212761\n",
      "epoch: 7 step: 424, loss is 0.007918719202280045\n",
      "epoch: 7 step: 425, loss is 0.0005494318320415914\n",
      "epoch: 7 step: 426, loss is 0.009699462912976742\n",
      "epoch: 7 step: 427, loss is 0.0006537983426824212\n",
      "epoch: 7 step: 428, loss is 0.0015485960757359862\n",
      "epoch: 7 step: 429, loss is 0.014857645146548748\n",
      "epoch: 7 step: 430, loss is 0.00029223249293863773\n",
      "epoch: 7 step: 431, loss is 0.10501199960708618\n",
      "epoch: 7 step: 432, loss is 0.04329292103648186\n",
      "epoch: 7 step: 433, loss is 0.20965375006198883\n",
      "epoch: 7 step: 434, loss is 0.0002771180006675422\n",
      "epoch: 7 step: 435, loss is 0.006614172365516424\n",
      "epoch: 7 step: 436, loss is 0.003100502770394087\n",
      "epoch: 7 step: 437, loss is 0.003548399545252323\n",
      "epoch: 7 step: 438, loss is 0.005306572187691927\n",
      "epoch: 7 step: 439, loss is 4.270690624252893e-05\n",
      "epoch: 7 step: 440, loss is 0.033868733793497086\n",
      "epoch: 7 step: 441, loss is 0.0002826901327352971\n",
      "epoch: 7 step: 442, loss is 0.0018136086873710155\n",
      "epoch: 7 step: 443, loss is 0.0002870777389034629\n",
      "epoch: 7 step: 444, loss is 0.004907752852886915\n",
      "epoch: 7 step: 445, loss is 0.031562440097332\n",
      "epoch: 7 step: 446, loss is 0.00019528121629264206\n",
      "epoch: 7 step: 447, loss is 5.994020466459915e-05\n",
      "epoch: 7 step: 448, loss is 0.00782738532871008\n",
      "epoch: 7 step: 449, loss is 0.0003449401701800525\n",
      "epoch: 7 step: 450, loss is 0.0018854986410588026\n",
      "epoch: 7 step: 451, loss is 0.022505061700940132\n",
      "epoch: 7 step: 452, loss is 0.0036077648401260376\n",
      "epoch: 7 step: 453, loss is 0.003310964908450842\n",
      "epoch: 7 step: 454, loss is 0.007452800869941711\n",
      "epoch: 7 step: 455, loss is 0.004066180437803268\n",
      "epoch: 7 step: 456, loss is 0.01872289925813675\n",
      "epoch: 7 step: 457, loss is 0.0015259748324751854\n",
      "epoch: 7 step: 458, loss is 0.002920196857303381\n",
      "epoch: 7 step: 459, loss is 0.00043489970266819\n",
      "epoch: 7 step: 460, loss is 0.00015878370322752744\n",
      "epoch: 7 step: 461, loss is 0.0008366244146600366\n",
      "epoch: 7 step: 462, loss is 0.01230995450168848\n",
      "epoch: 7 step: 463, loss is 0.001796836731955409\n",
      "epoch: 7 step: 464, loss is 0.0191357359290123\n",
      "epoch: 7 step: 465, loss is 0.0027599812019616365\n",
      "epoch: 7 step: 466, loss is 0.0005844103288836777\n",
      "epoch: 7 step: 467, loss is 0.0004949973081238568\n",
      "epoch: 7 step: 468, loss is 0.010171144269406796\n",
      "epoch: 7 step: 469, loss is 0.022018402814865112\n",
      "epoch: 7 step: 470, loss is 0.0047125378623604774\n",
      "epoch: 7 step: 471, loss is 0.0009659268544055521\n",
      "epoch: 7 step: 472, loss is 0.0024286722764372826\n",
      "epoch: 7 step: 473, loss is 0.0005726038943976164\n",
      "epoch: 7 step: 474, loss is 4.1579602111596614e-05\n",
      "epoch: 7 step: 475, loss is 0.007688359823077917\n",
      "epoch: 7 step: 476, loss is 0.00020699271408375353\n",
      "epoch: 7 step: 477, loss is 0.15585418045520782\n",
      "epoch: 7 step: 478, loss is 0.023802071809768677\n",
      "epoch: 7 step: 479, loss is 0.0004909049603156745\n",
      "epoch: 7 step: 480, loss is 5.757425969932228e-05\n",
      "epoch: 7 step: 481, loss is 0.0003286795108579099\n",
      "epoch: 7 step: 482, loss is 0.0016608339501544833\n",
      "epoch: 7 step: 483, loss is 0.0011527620954439044\n",
      "epoch: 7 step: 484, loss is 0.004103566519916058\n",
      "epoch: 7 step: 485, loss is 5.6227661843877286e-05\n",
      "epoch: 7 step: 486, loss is 0.04582912474870682\n",
      "epoch: 7 step: 487, loss is 0.00012388225877657533\n",
      "epoch: 7 step: 488, loss is 0.011971421539783478\n",
      "epoch: 7 step: 489, loss is 0.012120918370783329\n",
      "epoch: 7 step: 490, loss is 0.027670172974467278\n",
      "epoch: 7 step: 491, loss is 0.00019481146591715515\n",
      "epoch: 7 step: 492, loss is 0.0052219582721591\n",
      "epoch: 7 step: 493, loss is 0.011547872796654701\n",
      "epoch: 7 step: 494, loss is 0.00013011082774028182\n",
      "epoch: 7 step: 495, loss is 0.2315789759159088\n",
      "epoch: 7 step: 496, loss is 0.07172883301973343\n",
      "epoch: 7 step: 497, loss is 0.00041477748891338706\n",
      "epoch: 7 step: 498, loss is 0.0008851766469888389\n",
      "epoch: 7 step: 499, loss is 7.16906797606498e-05\n",
      "epoch: 7 step: 500, loss is 0.0002486875746399164\n",
      "epoch: 7 step: 501, loss is 0.00037930652615614235\n",
      "epoch: 7 step: 502, loss is 0.027283400297164917\n",
      "epoch: 7 step: 503, loss is 0.00014683186600450426\n",
      "epoch: 7 step: 504, loss is 0.007562914397567511\n",
      "epoch: 7 step: 505, loss is 0.004337167367339134\n",
      "epoch: 7 step: 506, loss is 0.08298900723457336\n",
      "epoch: 7 step: 507, loss is 0.0006347412709146738\n",
      "epoch: 7 step: 508, loss is 0.0026158287655562162\n",
      "epoch: 7 step: 509, loss is 0.0032770491670817137\n",
      "epoch: 7 step: 510, loss is 0.009636261500418186\n",
      "epoch: 7 step: 511, loss is 0.0019918244797736406\n",
      "epoch: 7 step: 512, loss is 0.0003479743318166584\n",
      "epoch: 7 step: 513, loss is 0.0015115217538550496\n",
      "epoch: 7 step: 514, loss is 0.0005760452477261424\n",
      "epoch: 7 step: 515, loss is 3.859187199850567e-05\n",
      "epoch: 7 step: 516, loss is 0.0008331593126058578\n",
      "epoch: 7 step: 517, loss is 0.004502164199948311\n",
      "epoch: 7 step: 518, loss is 8.918633830035105e-05\n",
      "epoch: 7 step: 519, loss is 5.713139398721978e-05\n",
      "epoch: 7 step: 520, loss is 0.01738237962126732\n",
      "epoch: 7 step: 521, loss is 0.00025109894340857863\n",
      "epoch: 7 step: 522, loss is 0.011125561781227589\n",
      "epoch: 7 step: 523, loss is 0.002054328564554453\n",
      "epoch: 7 step: 524, loss is 9.446278272662312e-05\n",
      "epoch: 7 step: 525, loss is 0.00010760805889731273\n",
      "epoch: 7 step: 526, loss is 0.017775772139430046\n",
      "epoch: 7 step: 527, loss is 6.523995398310944e-05\n",
      "epoch: 7 step: 528, loss is 0.041884176433086395\n",
      "epoch: 7 step: 529, loss is 0.007736228406429291\n",
      "epoch: 7 step: 530, loss is 0.00013012843555770814\n",
      "epoch: 7 step: 531, loss is 0.005240961443632841\n",
      "epoch: 7 step: 532, loss is 0.01969251036643982\n",
      "epoch: 7 step: 533, loss is 0.0006736068753525615\n",
      "epoch: 7 step: 534, loss is 0.0013581322273239493\n",
      "epoch: 7 step: 535, loss is 0.0053527685813605785\n",
      "epoch: 7 step: 536, loss is 0.11034002900123596\n",
      "epoch: 7 step: 537, loss is 0.00189246388617903\n",
      "epoch: 7 step: 538, loss is 9.537203004583716e-05\n",
      "epoch: 7 step: 539, loss is 0.002043758053332567\n",
      "epoch: 7 step: 540, loss is 2.1661266146111302e-05\n",
      "epoch: 7 step: 541, loss is 0.0006084330379962921\n",
      "epoch: 7 step: 542, loss is 0.00012704895925708115\n",
      "epoch: 7 step: 543, loss is 0.0033650326076895\n",
      "epoch: 7 step: 544, loss is 9.159444744000211e-06\n",
      "epoch: 7 step: 545, loss is 0.0031278368551284075\n",
      "epoch: 7 step: 546, loss is 5.9283389418851584e-05\n",
      "epoch: 7 step: 547, loss is 0.00021934347751084715\n",
      "epoch: 7 step: 548, loss is 0.0077443355694413185\n",
      "epoch: 7 step: 549, loss is 0.08726565539836884\n",
      "epoch: 7 step: 550, loss is 0.00010292421939084306\n",
      "epoch: 7 step: 551, loss is 0.00025230366736650467\n",
      "epoch: 7 step: 552, loss is 0.1267029494047165\n",
      "epoch: 7 step: 553, loss is 0.14206142723560333\n",
      "epoch: 7 step: 554, loss is 0.0005087608005851507\n",
      "epoch: 7 step: 555, loss is 0.006501924246549606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 556, loss is 0.0002994842070620507\n",
      "epoch: 7 step: 557, loss is 0.004450957756489515\n",
      "epoch: 7 step: 558, loss is 0.006897383835166693\n",
      "epoch: 7 step: 559, loss is 0.001007018145173788\n",
      "epoch: 7 step: 560, loss is 0.00023794957087375224\n",
      "epoch: 7 step: 561, loss is 0.0033384861890226603\n",
      "epoch: 7 step: 562, loss is 2.757049151114188e-05\n",
      "epoch: 7 step: 563, loss is 0.1256057769060135\n",
      "epoch: 7 step: 564, loss is 0.12409573793411255\n",
      "epoch: 7 step: 565, loss is 0.00012319082452449948\n",
      "epoch: 7 step: 566, loss is 0.0005508086760528386\n",
      "epoch: 7 step: 567, loss is 0.0002815366897266358\n",
      "epoch: 7 step: 568, loss is 0.0001405081566190347\n",
      "epoch: 7 step: 569, loss is 0.027586305513978004\n",
      "epoch: 7 step: 570, loss is 0.07790766656398773\n",
      "epoch: 7 step: 571, loss is 0.001063343952409923\n",
      "epoch: 7 step: 572, loss is 0.0010433479910716414\n",
      "epoch: 7 step: 573, loss is 0.028701430186629295\n",
      "epoch: 7 step: 574, loss is 0.0025845735799521208\n",
      "epoch: 7 step: 575, loss is 0.1353013962507248\n",
      "epoch: 7 step: 576, loss is 0.0007847698288969696\n",
      "epoch: 7 step: 577, loss is 0.0011664143530651927\n",
      "epoch: 7 step: 578, loss is 0.010012819431722164\n",
      "epoch: 7 step: 579, loss is 0.13247165083885193\n",
      "epoch: 7 step: 580, loss is 0.0031171117443591356\n",
      "epoch: 7 step: 581, loss is 0.0010150503367185593\n",
      "epoch: 7 step: 582, loss is 0.0046532247215509415\n",
      "epoch: 7 step: 583, loss is 0.1441454142332077\n",
      "epoch: 7 step: 584, loss is 0.04782237112522125\n",
      "epoch: 7 step: 585, loss is 0.00010817521979333833\n",
      "epoch: 7 step: 586, loss is 0.0027284356765449047\n",
      "epoch: 7 step: 587, loss is 0.00018470648501534015\n",
      "epoch: 7 step: 588, loss is 0.00021899618150200695\n",
      "epoch: 7 step: 589, loss is 0.00035799836041405797\n",
      "epoch: 7 step: 590, loss is 0.0016195880016312003\n",
      "epoch: 7 step: 591, loss is 0.0037871687673032284\n",
      "epoch: 7 step: 592, loss is 0.0001551905443193391\n",
      "epoch: 7 step: 593, loss is 0.00024972998653538525\n",
      "epoch: 7 step: 594, loss is 0.001130484975874424\n",
      "epoch: 7 step: 595, loss is 0.003107029013335705\n",
      "epoch: 7 step: 596, loss is 0.005460765212774277\n",
      "epoch: 7 step: 597, loss is 0.0012066331692039967\n",
      "epoch: 7 step: 598, loss is 0.03976026177406311\n",
      "epoch: 7 step: 599, loss is 0.018377935513854027\n",
      "epoch: 7 step: 600, loss is 0.028890859335660934\n",
      "epoch: 7 step: 601, loss is 0.001639871159568429\n",
      "epoch: 7 step: 602, loss is 0.0551273375749588\n",
      "epoch: 7 step: 603, loss is 0.10882832854986191\n",
      "epoch: 7 step: 604, loss is 0.016804255545139313\n",
      "epoch: 7 step: 605, loss is 0.00011304908548481762\n",
      "epoch: 7 step: 606, loss is 0.0009385207085870206\n",
      "epoch: 7 step: 607, loss is 0.005789787508547306\n",
      "epoch: 7 step: 608, loss is 0.005493628792464733\n",
      "epoch: 7 step: 609, loss is 0.04238897189497948\n",
      "epoch: 7 step: 610, loss is 0.0010845162905752659\n",
      "epoch: 7 step: 611, loss is 0.0003042822063434869\n",
      "epoch: 7 step: 612, loss is 0.0002247499505756423\n",
      "epoch: 7 step: 613, loss is 0.0029315194115042686\n",
      "epoch: 7 step: 614, loss is 0.010312988422811031\n",
      "epoch: 7 step: 615, loss is 0.000645884545519948\n",
      "epoch: 7 step: 616, loss is 0.012892140075564384\n",
      "epoch: 7 step: 617, loss is 0.02509409561753273\n",
      "epoch: 7 step: 618, loss is 0.00036137798451818526\n",
      "epoch: 7 step: 619, loss is 0.034002140164375305\n",
      "epoch: 7 step: 620, loss is 0.0005296106683090329\n",
      "epoch: 7 step: 621, loss is 0.06457021087408066\n",
      "epoch: 7 step: 622, loss is 0.005658071022480726\n",
      "epoch: 7 step: 623, loss is 0.05859776958823204\n",
      "epoch: 7 step: 624, loss is 0.0015598302707076073\n",
      "epoch: 7 step: 625, loss is 4.4588854507310316e-05\n",
      "epoch: 7 step: 626, loss is 0.00033460426493547857\n",
      "epoch: 7 step: 627, loss is 0.010264270938932896\n",
      "epoch: 7 step: 628, loss is 0.007021831814199686\n",
      "epoch: 7 step: 629, loss is 0.041941337287425995\n",
      "epoch: 7 step: 630, loss is 0.00045219954336062074\n",
      "epoch: 7 step: 631, loss is 0.00251606828533113\n",
      "epoch: 7 step: 632, loss is 0.0007062103832140565\n",
      "epoch: 7 step: 633, loss is 0.003369140438735485\n",
      "epoch: 7 step: 634, loss is 0.003788428846746683\n",
      "epoch: 7 step: 635, loss is 0.12838007509708405\n",
      "epoch: 7 step: 636, loss is 1.1183630704181269e-05\n",
      "epoch: 7 step: 637, loss is 0.00024214510631281883\n",
      "epoch: 7 step: 638, loss is 1.2985261491849087e-05\n",
      "epoch: 7 step: 639, loss is 0.006694595329463482\n",
      "epoch: 7 step: 640, loss is 0.043504081666469574\n",
      "epoch: 7 step: 641, loss is 0.00021904661844018847\n",
      "epoch: 7 step: 642, loss is 0.00015836674720048904\n",
      "epoch: 7 step: 643, loss is 0.0001618034002603963\n",
      "epoch: 7 step: 644, loss is 2.733533074206207e-05\n",
      "epoch: 7 step: 645, loss is 0.0003784167638514191\n",
      "epoch: 7 step: 646, loss is 0.0002919216931331903\n",
      "epoch: 7 step: 647, loss is 0.0006148061947897077\n",
      "epoch: 7 step: 648, loss is 0.08736038953065872\n",
      "epoch: 7 step: 649, loss is 0.0005713828140869737\n",
      "epoch: 7 step: 650, loss is 0.00023999933910090476\n",
      "epoch: 7 step: 651, loss is 0.07756975293159485\n",
      "epoch: 7 step: 652, loss is 0.000251273944741115\n",
      "epoch: 7 step: 653, loss is 0.0007357457070611417\n",
      "epoch: 7 step: 654, loss is 0.08100206404924393\n",
      "epoch: 7 step: 655, loss is 0.029789745807647705\n",
      "epoch: 7 step: 656, loss is 0.002972043352201581\n",
      "epoch: 7 step: 657, loss is 0.2071901112794876\n",
      "epoch: 7 step: 658, loss is 0.0008201876189559698\n",
      "epoch: 7 step: 659, loss is 0.00020235679403413087\n",
      "epoch: 7 step: 660, loss is 1.7413858586223796e-05\n",
      "epoch: 7 step: 661, loss is 0.0037614789325743914\n",
      "epoch: 7 step: 662, loss is 0.010438250377774239\n",
      "epoch: 7 step: 663, loss is 0.004860759247094393\n",
      "epoch: 7 step: 664, loss is 0.006715224590152502\n",
      "epoch: 7 step: 665, loss is 0.015707559883594513\n",
      "epoch: 7 step: 666, loss is 0.01708066649734974\n",
      "epoch: 7 step: 667, loss is 0.22237500548362732\n",
      "epoch: 7 step: 668, loss is 0.006732256151735783\n",
      "epoch: 7 step: 669, loss is 0.020005833357572556\n",
      "epoch: 7 step: 670, loss is 0.00968086440116167\n",
      "epoch: 7 step: 671, loss is 0.14832477271556854\n",
      "epoch: 7 step: 672, loss is 0.00017769196711014956\n",
      "epoch: 7 step: 673, loss is 0.15933023393154144\n",
      "epoch: 7 step: 674, loss is 0.006027014460414648\n",
      "epoch: 7 step: 675, loss is 0.1397155523300171\n",
      "epoch: 7 step: 676, loss is 0.25984951853752136\n",
      "epoch: 7 step: 677, loss is 0.0025448950473219156\n",
      "epoch: 7 step: 678, loss is 0.0036033731885254383\n",
      "epoch: 7 step: 679, loss is 0.046164922416210175\n",
      "epoch: 7 step: 680, loss is 0.0004175255016889423\n",
      "epoch: 7 step: 681, loss is 0.007153917104005814\n",
      "epoch: 7 step: 682, loss is 0.0007000298937782645\n",
      "epoch: 7 step: 683, loss is 0.00012864837481174618\n",
      "epoch: 7 step: 684, loss is 0.09193423390388489\n",
      "epoch: 7 step: 685, loss is 0.1481943130493164\n",
      "epoch: 7 step: 686, loss is 0.008046833798289299\n",
      "epoch: 7 step: 687, loss is 0.0048454334028065205\n",
      "epoch: 7 step: 688, loss is 0.07422713190317154\n",
      "epoch: 7 step: 689, loss is 0.00017583930457476526\n",
      "epoch: 7 step: 690, loss is 0.011982401832938194\n",
      "epoch: 7 step: 691, loss is 0.012812300585210323\n",
      "epoch: 7 step: 692, loss is 0.008832346647977829\n",
      "epoch: 7 step: 693, loss is 0.06888850033283234\n",
      "epoch: 7 step: 694, loss is 0.17595019936561584\n",
      "epoch: 7 step: 695, loss is 0.03516088053584099\n",
      "epoch: 7 step: 696, loss is 0.008909063413739204\n",
      "epoch: 7 step: 697, loss is 0.003872415516525507\n",
      "epoch: 7 step: 698, loss is 0.0016615729546174407\n",
      "epoch: 7 step: 699, loss is 0.0089919064193964\n",
      "epoch: 7 step: 700, loss is 0.00044129870366305113\n",
      "epoch: 7 step: 701, loss is 0.0012531244428828359\n",
      "epoch: 7 step: 702, loss is 0.1313135325908661\n",
      "epoch: 7 step: 703, loss is 0.08375221490859985\n",
      "epoch: 7 step: 704, loss is 0.0031590715516358614\n",
      "epoch: 7 step: 705, loss is 0.0006479009171016514\n",
      "epoch: 7 step: 706, loss is 0.007156958803534508\n",
      "epoch: 7 step: 707, loss is 0.0020762737840414047\n",
      "epoch: 7 step: 708, loss is 0.00012352816702332348\n",
      "epoch: 7 step: 709, loss is 0.013920597732067108\n",
      "epoch: 7 step: 710, loss is 0.005040943156927824\n",
      "epoch: 7 step: 711, loss is 0.002278994768857956\n",
      "epoch: 7 step: 712, loss is 0.00638187862932682\n",
      "epoch: 7 step: 713, loss is 0.015339639037847519\n",
      "epoch: 7 step: 714, loss is 0.005786751862615347\n",
      "epoch: 7 step: 715, loss is 0.02725560963153839\n",
      "epoch: 7 step: 716, loss is 0.014883005991578102\n",
      "epoch: 7 step: 717, loss is 0.00024309605942107737\n",
      "epoch: 7 step: 718, loss is 0.0024075903929769993\n",
      "epoch: 7 step: 719, loss is 0.0020720004104077816\n",
      "epoch: 7 step: 720, loss is 0.000444887817138806\n",
      "epoch: 7 step: 721, loss is 0.005921255797147751\n",
      "epoch: 7 step: 722, loss is 0.21680058538913727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 723, loss is 0.01432808581739664\n",
      "epoch: 7 step: 724, loss is 0.0007445061346516013\n",
      "epoch: 7 step: 725, loss is 0.0022245431318879128\n",
      "epoch: 7 step: 726, loss is 0.003892923006787896\n",
      "epoch: 7 step: 727, loss is 0.00016868746024556458\n",
      "epoch: 7 step: 728, loss is 0.01820141077041626\n",
      "epoch: 7 step: 729, loss is 0.027334291487932205\n",
      "epoch: 7 step: 730, loss is 0.013719672337174416\n",
      "epoch: 7 step: 731, loss is 0.005127054639160633\n",
      "epoch: 7 step: 732, loss is 0.0384712815284729\n",
      "epoch: 7 step: 733, loss is 0.0037831689696758986\n",
      "epoch: 7 step: 734, loss is 0.005466314498335123\n",
      "epoch: 7 step: 735, loss is 0.025967171415686607\n",
      "epoch: 7 step: 736, loss is 0.0002596579142846167\n",
      "epoch: 7 step: 737, loss is 0.042877405881881714\n",
      "epoch: 7 step: 738, loss is 0.05043094605207443\n",
      "epoch: 7 step: 739, loss is 0.00027301651425659657\n",
      "epoch: 7 step: 740, loss is 0.04670821130275726\n",
      "epoch: 7 step: 741, loss is 0.11888010054826736\n",
      "epoch: 7 step: 742, loss is 0.009016809053719044\n",
      "epoch: 7 step: 743, loss is 0.0007809140370227396\n",
      "epoch: 7 step: 744, loss is 0.06411048024892807\n",
      "epoch: 7 step: 745, loss is 0.0011451808968558908\n",
      "epoch: 7 step: 746, loss is 0.14383095502853394\n",
      "epoch: 7 step: 747, loss is 0.008033495396375656\n",
      "epoch: 7 step: 748, loss is 0.0002001849643420428\n",
      "epoch: 7 step: 749, loss is 0.0004124317201785743\n",
      "epoch: 7 step: 750, loss is 0.002857539104297757\n",
      "epoch: 7 step: 751, loss is 0.013456332497298717\n",
      "epoch: 7 step: 752, loss is 0.05671309307217598\n",
      "epoch: 7 step: 753, loss is 0.01453530415892601\n",
      "epoch: 7 step: 754, loss is 0.002522204304113984\n",
      "epoch: 7 step: 755, loss is 0.1564510315656662\n",
      "epoch: 7 step: 756, loss is 0.002885640598833561\n",
      "epoch: 7 step: 757, loss is 0.026779452338814735\n",
      "epoch: 7 step: 758, loss is 0.04340957850217819\n",
      "epoch: 7 step: 759, loss is 0.055618636310100555\n",
      "epoch: 7 step: 760, loss is 0.006313937250524759\n",
      "epoch: 7 step: 761, loss is 0.00572123983874917\n",
      "epoch: 7 step: 762, loss is 0.0014224163023754954\n",
      "epoch: 7 step: 763, loss is 0.0006364007713273168\n",
      "epoch: 7 step: 764, loss is 0.007435353472828865\n",
      "epoch: 7 step: 765, loss is 0.017024023458361626\n",
      "epoch: 7 step: 766, loss is 0.0006730938912369311\n",
      "epoch: 7 step: 767, loss is 0.005850835703313351\n",
      "epoch: 7 step: 768, loss is 0.04130004346370697\n",
      "epoch: 7 step: 769, loss is 0.03307957574725151\n",
      "epoch: 7 step: 770, loss is 0.02500448375940323\n",
      "epoch: 7 step: 771, loss is 0.006591737736016512\n",
      "epoch: 7 step: 772, loss is 0.00045844566193409264\n",
      "epoch: 7 step: 773, loss is 0.0042281802743673325\n",
      "epoch: 7 step: 774, loss is 0.03322592005133629\n",
      "epoch: 7 step: 775, loss is 0.005242191255092621\n",
      "epoch: 7 step: 776, loss is 0.0004339350271038711\n",
      "epoch: 7 step: 777, loss is 0.0012301936512812972\n",
      "epoch: 7 step: 778, loss is 0.00848320871591568\n",
      "epoch: 7 step: 779, loss is 0.05577285960316658\n",
      "epoch: 7 step: 780, loss is 0.002018429571762681\n",
      "epoch: 7 step: 781, loss is 1.4559048395312857e-05\n",
      "epoch: 7 step: 782, loss is 0.013879099860787392\n",
      "epoch: 7 step: 783, loss is 0.023820742964744568\n",
      "epoch: 7 step: 784, loss is 0.0014436815399676561\n",
      "epoch: 7 step: 785, loss is 0.11663196235895157\n",
      "epoch: 7 step: 786, loss is 0.0002385775587754324\n",
      "epoch: 7 step: 787, loss is 0.002164300065487623\n",
      "epoch: 7 step: 788, loss is 0.0007290570647455752\n",
      "epoch: 7 step: 789, loss is 0.011895634233951569\n",
      "epoch: 7 step: 790, loss is 0.08224982023239136\n",
      "epoch: 7 step: 791, loss is 0.004293559119105339\n",
      "epoch: 7 step: 792, loss is 0.00026017770869657397\n",
      "epoch: 7 step: 793, loss is 0.0021569759119302034\n",
      "epoch: 7 step: 794, loss is 0.027284730225801468\n",
      "epoch: 7 step: 795, loss is 0.0002091157657559961\n",
      "epoch: 7 step: 796, loss is 0.2576397657394409\n",
      "epoch: 7 step: 797, loss is 0.04612121731042862\n",
      "epoch: 7 step: 798, loss is 0.006147028878331184\n",
      "epoch: 7 step: 799, loss is 0.022873681038618088\n",
      "epoch: 7 step: 800, loss is 0.023948457092046738\n",
      "epoch: 7 step: 801, loss is 0.004223750904202461\n",
      "epoch: 7 step: 802, loss is 0.013291195034980774\n",
      "epoch: 7 step: 803, loss is 0.14204831421375275\n",
      "epoch: 7 step: 804, loss is 0.0009120992617681623\n",
      "epoch: 7 step: 805, loss is 0.0007736292900517583\n",
      "epoch: 7 step: 806, loss is 0.017251305282115936\n",
      "epoch: 7 step: 807, loss is 0.030422277748584747\n",
      "epoch: 7 step: 808, loss is 0.003685723291710019\n",
      "epoch: 7 step: 809, loss is 0.01400055456906557\n",
      "epoch: 7 step: 810, loss is 0.016658969223499298\n",
      "epoch: 7 step: 811, loss is 0.000701053359080106\n",
      "epoch: 7 step: 812, loss is 0.23426489531993866\n",
      "epoch: 7 step: 813, loss is 0.013937692157924175\n",
      "epoch: 7 step: 814, loss is 0.00012775925279129297\n",
      "epoch: 7 step: 815, loss is 0.058712031692266464\n",
      "epoch: 7 step: 816, loss is 0.000262882502283901\n",
      "epoch: 7 step: 817, loss is 0.022445667535066605\n",
      "epoch: 7 step: 818, loss is 0.01352393627166748\n",
      "epoch: 7 step: 819, loss is 0.0055114892311394215\n",
      "epoch: 7 step: 820, loss is 0.002672633621841669\n",
      "epoch: 7 step: 821, loss is 0.0009607446845620871\n",
      "epoch: 7 step: 822, loss is 0.0185637716203928\n",
      "epoch: 7 step: 823, loss is 0.00021419253607746214\n",
      "epoch: 7 step: 824, loss is 0.005590486340224743\n",
      "epoch: 7 step: 825, loss is 0.10757944732904434\n",
      "epoch: 7 step: 826, loss is 0.00026257371064275503\n",
      "epoch: 7 step: 827, loss is 0.0001253542141057551\n",
      "epoch: 7 step: 828, loss is 0.003420562483370304\n",
      "epoch: 7 step: 829, loss is 0.0013714521192014217\n",
      "epoch: 7 step: 830, loss is 0.0009749359451234341\n",
      "epoch: 7 step: 831, loss is 0.011898753233253956\n",
      "epoch: 7 step: 832, loss is 0.0007786688511259854\n",
      "epoch: 7 step: 833, loss is 0.04066680371761322\n",
      "epoch: 7 step: 834, loss is 0.0003657353518065065\n",
      "epoch: 7 step: 835, loss is 0.0032728882506489754\n",
      "epoch: 7 step: 836, loss is 0.0045897383242845535\n",
      "epoch: 7 step: 837, loss is 0.00029371463460847735\n",
      "epoch: 7 step: 838, loss is 0.0006641319487243891\n",
      "epoch: 7 step: 839, loss is 0.005840828642249107\n",
      "epoch: 7 step: 840, loss is 0.00042871455661952496\n",
      "epoch: 7 step: 841, loss is 0.003222001250833273\n",
      "epoch: 7 step: 842, loss is 0.0003223912790417671\n",
      "epoch: 7 step: 843, loss is 0.008645941503345966\n",
      "epoch: 7 step: 844, loss is 0.00923772994428873\n",
      "epoch: 7 step: 845, loss is 0.0005235003773123026\n",
      "epoch: 7 step: 846, loss is 0.002177877351641655\n",
      "epoch: 7 step: 847, loss is 0.0004872927675023675\n",
      "epoch: 7 step: 848, loss is 0.0016387745272368193\n",
      "epoch: 7 step: 849, loss is 0.0009562836494296789\n",
      "epoch: 7 step: 850, loss is 0.0031455131247639656\n",
      "epoch: 7 step: 851, loss is 0.010079613886773586\n",
      "epoch: 7 step: 852, loss is 0.00032208493212237954\n",
      "epoch: 7 step: 853, loss is 0.00427132798358798\n",
      "epoch: 7 step: 854, loss is 0.0007069234852679074\n",
      "epoch: 7 step: 855, loss is 0.0005162492161616683\n",
      "epoch: 7 step: 856, loss is 0.0017197771230712533\n",
      "epoch: 7 step: 857, loss is 0.01706601120531559\n",
      "epoch: 7 step: 858, loss is 0.0002230524696642533\n",
      "epoch: 7 step: 859, loss is 0.0014626282500103116\n",
      "epoch: 7 step: 860, loss is 0.0035267916973680258\n",
      "epoch: 7 step: 861, loss is 0.00015260315558407456\n",
      "epoch: 7 step: 862, loss is 0.005675959400832653\n",
      "epoch: 7 step: 863, loss is 0.1539742797613144\n",
      "epoch: 7 step: 864, loss is 0.000267196970526129\n",
      "epoch: 7 step: 865, loss is 2.8136106266174465e-05\n",
      "epoch: 7 step: 866, loss is 0.08255945891141891\n",
      "epoch: 7 step: 867, loss is 0.0026643401943147182\n",
      "epoch: 7 step: 868, loss is 0.008124850690364838\n",
      "epoch: 7 step: 869, loss is 0.00010726927575888112\n",
      "epoch: 7 step: 870, loss is 0.01921721361577511\n",
      "epoch: 7 step: 871, loss is 0.0001307185593759641\n",
      "epoch: 7 step: 872, loss is 0.0012662208173424006\n",
      "epoch: 7 step: 873, loss is 0.001569889485836029\n",
      "epoch: 7 step: 874, loss is 3.777996244025417e-05\n",
      "epoch: 7 step: 875, loss is 7.275238749571145e-05\n",
      "epoch: 7 step: 876, loss is 0.0012988077942281961\n",
      "epoch: 7 step: 877, loss is 0.009961473755538464\n",
      "epoch: 7 step: 878, loss is 0.07626625150442123\n",
      "epoch: 7 step: 879, loss is 0.0009310613968409598\n",
      "epoch: 7 step: 880, loss is 0.020572341978549957\n",
      "epoch: 7 step: 881, loss is 0.0004024713416583836\n",
      "epoch: 7 step: 882, loss is 0.0013696147361770272\n",
      "epoch: 7 step: 883, loss is 0.0027928927447646856\n",
      "epoch: 7 step: 884, loss is 0.002946442924439907\n",
      "epoch: 7 step: 885, loss is 0.06528212130069733\n",
      "epoch: 7 step: 886, loss is 0.0012491005472838879\n",
      "epoch: 7 step: 887, loss is 0.03484383597970009\n",
      "epoch: 7 step: 888, loss is 0.17428714036941528\n",
      "epoch: 7 step: 889, loss is 0.0013389913365244865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 890, loss is 0.09076210856437683\n",
      "epoch: 7 step: 891, loss is 0.0010780392913147807\n",
      "epoch: 7 step: 892, loss is 0.004119380377233028\n",
      "epoch: 7 step: 893, loss is 0.010556797496974468\n",
      "epoch: 7 step: 894, loss is 0.0016041048802435398\n",
      "epoch: 7 step: 895, loss is 0.018917197361588478\n",
      "epoch: 7 step: 896, loss is 0.0019571208395063877\n",
      "epoch: 7 step: 897, loss is 0.0010411725379526615\n",
      "epoch: 7 step: 898, loss is 0.001933358609676361\n",
      "epoch: 7 step: 899, loss is 0.00029740339959971607\n",
      "epoch: 7 step: 900, loss is 0.00012811089982278645\n",
      "epoch: 7 step: 901, loss is 0.0003303307748865336\n",
      "epoch: 7 step: 902, loss is 0.16492559015750885\n",
      "epoch: 7 step: 903, loss is 0.03008405864238739\n",
      "epoch: 7 step: 904, loss is 0.010737370699644089\n",
      "epoch: 7 step: 905, loss is 0.003154266392812133\n",
      "epoch: 7 step: 906, loss is 0.004550352226942778\n",
      "epoch: 7 step: 907, loss is 0.008989939466118813\n",
      "epoch: 7 step: 908, loss is 0.005504348315298557\n",
      "epoch: 7 step: 909, loss is 0.029679065570235252\n",
      "epoch: 7 step: 910, loss is 0.003932005260139704\n",
      "epoch: 7 step: 911, loss is 0.008429771289229393\n",
      "epoch: 7 step: 912, loss is 0.0010543637908995152\n",
      "epoch: 7 step: 913, loss is 0.12927255034446716\n",
      "epoch: 7 step: 914, loss is 0.001991875469684601\n",
      "epoch: 7 step: 915, loss is 0.08276031166315079\n",
      "epoch: 7 step: 916, loss is 0.12733086943626404\n",
      "epoch: 7 step: 917, loss is 0.002642377046868205\n",
      "epoch: 7 step: 918, loss is 0.014748437330126762\n",
      "epoch: 7 step: 919, loss is 0.012906117364764214\n",
      "epoch: 7 step: 920, loss is 0.002473880536854267\n",
      "epoch: 7 step: 921, loss is 0.006608146242797375\n",
      "epoch: 7 step: 922, loss is 0.0014830469153821468\n",
      "epoch: 7 step: 923, loss is 0.0004693754599429667\n",
      "epoch: 7 step: 924, loss is 0.0003865528851747513\n",
      "epoch: 7 step: 925, loss is 0.016584059223532677\n",
      "epoch: 7 step: 926, loss is 0.001756031415425241\n",
      "epoch: 7 step: 927, loss is 0.0034320191480219364\n",
      "epoch: 7 step: 928, loss is 0.06649813055992126\n",
      "epoch: 7 step: 929, loss is 0.0049474891275167465\n",
      "epoch: 7 step: 930, loss is 0.0284581258893013\n",
      "epoch: 7 step: 931, loss is 0.00023878335196059197\n",
      "epoch: 7 step: 932, loss is 0.00765717588365078\n",
      "epoch: 7 step: 933, loss is 0.007463441230356693\n",
      "epoch: 7 step: 934, loss is 0.0023843946401029825\n",
      "epoch: 7 step: 935, loss is 0.056236062198877335\n",
      "epoch: 7 step: 936, loss is 0.035811372101306915\n",
      "epoch: 7 step: 937, loss is 0.006319278851151466\n",
      "epoch: 7 step: 938, loss is 0.21411705017089844\n",
      "epoch: 7 step: 939, loss is 0.00016638028318993747\n",
      "epoch: 7 step: 940, loss is 0.00046401904546655715\n",
      "epoch: 7 step: 941, loss is 0.00033639188040979207\n",
      "epoch: 7 step: 942, loss is 0.00027686843532137573\n",
      "epoch: 7 step: 943, loss is 1.9750728824874386e-05\n",
      "epoch: 7 step: 944, loss is 0.0002662161714397371\n",
      "epoch: 7 step: 945, loss is 0.001195751130580902\n",
      "epoch: 7 step: 946, loss is 0.0018543710466474295\n",
      "epoch: 7 step: 947, loss is 0.0009836609242483974\n",
      "epoch: 7 step: 948, loss is 0.03369855135679245\n",
      "epoch: 7 step: 949, loss is 0.0059100063517689705\n",
      "epoch: 7 step: 950, loss is 0.08348715305328369\n",
      "epoch: 7 step: 951, loss is 0.017377037554979324\n",
      "epoch: 7 step: 952, loss is 0.0003294138005003333\n",
      "epoch: 7 step: 953, loss is 0.0028112041763961315\n",
      "epoch: 7 step: 954, loss is 0.001326097990386188\n",
      "epoch: 7 step: 955, loss is 0.00039238008321262896\n",
      "epoch: 7 step: 956, loss is 0.009130935184657574\n",
      "epoch: 7 step: 957, loss is 0.032497331500053406\n",
      "epoch: 7 step: 958, loss is 0.015239865519106388\n",
      "epoch: 7 step: 959, loss is 6.772374763386324e-05\n",
      "epoch: 7 step: 960, loss is 0.011366121470928192\n",
      "epoch: 7 step: 961, loss is 0.0008509185281582177\n",
      "epoch: 7 step: 962, loss is 0.00010171625763177872\n",
      "epoch: 7 step: 963, loss is 0.0003277533105574548\n",
      "epoch: 7 step: 964, loss is 0.00014109056792221963\n",
      "epoch: 7 step: 965, loss is 0.04728337749838829\n",
      "epoch: 7 step: 966, loss is 0.005776261445134878\n",
      "epoch: 7 step: 967, loss is 0.09855248779058456\n",
      "epoch: 7 step: 968, loss is 0.002165691228583455\n",
      "epoch: 7 step: 969, loss is 0.0001600121904630214\n",
      "epoch: 7 step: 970, loss is 0.0009791026823222637\n",
      "epoch: 7 step: 971, loss is 0.0005316860042512417\n",
      "epoch: 7 step: 972, loss is 0.048594675958156586\n",
      "epoch: 7 step: 973, loss is 0.00025463165366090834\n",
      "epoch: 7 step: 974, loss is 0.0003048877988476306\n",
      "epoch: 7 step: 975, loss is 9.37379154493101e-05\n",
      "epoch: 7 step: 976, loss is 0.020994501188397408\n",
      "epoch: 7 step: 977, loss is 8.520061237504706e-05\n",
      "epoch: 7 step: 978, loss is 0.0027085058391094208\n",
      "epoch: 7 step: 979, loss is 0.000333567411871627\n",
      "epoch: 7 step: 980, loss is 0.0372333861887455\n",
      "epoch: 7 step: 981, loss is 0.046219129115343094\n",
      "epoch: 7 step: 982, loss is 0.042058080434799194\n",
      "epoch: 7 step: 983, loss is 0.0023814027663320303\n",
      "epoch: 7 step: 984, loss is 0.0005491251358762383\n",
      "epoch: 7 step: 985, loss is 0.047787364572286606\n",
      "epoch: 7 step: 986, loss is 0.000741037423722446\n",
      "epoch: 7 step: 987, loss is 0.002482061041519046\n",
      "epoch: 7 step: 988, loss is 0.0001781268510967493\n",
      "epoch: 7 step: 989, loss is 0.00016259406402241439\n",
      "epoch: 7 step: 990, loss is 0.007585391867905855\n",
      "epoch: 7 step: 991, loss is 0.0029362491331994534\n",
      "epoch: 7 step: 992, loss is 0.0005618596915155649\n",
      "epoch: 7 step: 993, loss is 0.002394949086010456\n",
      "epoch: 7 step: 994, loss is 0.001235684147104621\n",
      "epoch: 7 step: 995, loss is 0.1137237474322319\n",
      "epoch: 7 step: 996, loss is 0.00036671964335255325\n",
      "epoch: 7 step: 997, loss is 0.0063650826923549175\n",
      "epoch: 7 step: 998, loss is 0.0021188471000641584\n",
      "epoch: 7 step: 999, loss is 0.056552860885858536\n",
      "epoch: 7 step: 1000, loss is 0.0003604987286962569\n",
      "epoch: 7 step: 1001, loss is 0.002235114574432373\n",
      "epoch: 7 step: 1002, loss is 0.007075591012835503\n",
      "epoch: 7 step: 1003, loss is 0.04331317916512489\n",
      "epoch: 7 step: 1004, loss is 0.04507536068558693\n",
      "epoch: 7 step: 1005, loss is 0.009104217402637005\n",
      "epoch: 7 step: 1006, loss is 0.0016445934306830168\n",
      "epoch: 7 step: 1007, loss is 0.07915201783180237\n",
      "epoch: 7 step: 1008, loss is 0.043274376541376114\n",
      "epoch: 7 step: 1009, loss is 0.001931512262672186\n",
      "epoch: 7 step: 1010, loss is 0.003690640674903989\n",
      "epoch: 7 step: 1011, loss is 0.053321417421102524\n",
      "epoch: 7 step: 1012, loss is 0.002418980235233903\n",
      "epoch: 7 step: 1013, loss is 0.011972514912486076\n",
      "epoch: 7 step: 1014, loss is 0.00668193306773901\n",
      "epoch: 7 step: 1015, loss is 0.001270062755793333\n",
      "epoch: 7 step: 1016, loss is 0.03689134493470192\n",
      "epoch: 7 step: 1017, loss is 0.07883879542350769\n",
      "epoch: 7 step: 1018, loss is 0.0005996575346216559\n",
      "epoch: 7 step: 1019, loss is 0.0009815855883061886\n",
      "epoch: 7 step: 1020, loss is 4.257098044035956e-05\n",
      "epoch: 7 step: 1021, loss is 0.0016362142050638795\n",
      "epoch: 7 step: 1022, loss is 0.0006296489736996591\n",
      "epoch: 7 step: 1023, loss is 0.01985527016222477\n",
      "epoch: 7 step: 1024, loss is 3.962593473261222e-05\n",
      "epoch: 7 step: 1025, loss is 0.0012670039432123303\n",
      "epoch: 7 step: 1026, loss is 0.000298987899441272\n",
      "epoch: 7 step: 1027, loss is 0.0009287380962632596\n",
      "epoch: 7 step: 1028, loss is 0.0006308723823167384\n",
      "epoch: 7 step: 1029, loss is 0.1771569848060608\n",
      "epoch: 7 step: 1030, loss is 0.009726325049996376\n",
      "epoch: 7 step: 1031, loss is 0.1930147111415863\n",
      "epoch: 7 step: 1032, loss is 0.004453294910490513\n",
      "epoch: 7 step: 1033, loss is 0.0032620569691061974\n",
      "epoch: 7 step: 1034, loss is 0.00018480863946024328\n",
      "epoch: 7 step: 1035, loss is 0.06444592773914337\n",
      "epoch: 7 step: 1036, loss is 0.0003100369649473578\n",
      "epoch: 7 step: 1037, loss is 0.012263497337698936\n",
      "epoch: 7 step: 1038, loss is 0.07943827658891678\n",
      "epoch: 7 step: 1039, loss is 0.00038520610542036593\n",
      "epoch: 7 step: 1040, loss is 0.14172475039958954\n",
      "epoch: 7 step: 1041, loss is 0.01621459797024727\n",
      "epoch: 7 step: 1042, loss is 0.000779798487201333\n",
      "epoch: 7 step: 1043, loss is 0.0005499181570485234\n",
      "epoch: 7 step: 1044, loss is 0.05139582231640816\n",
      "epoch: 7 step: 1045, loss is 8.049311873037368e-05\n",
      "epoch: 7 step: 1046, loss is 0.00017625483451411128\n",
      "epoch: 7 step: 1047, loss is 0.0013237918028607965\n",
      "epoch: 7 step: 1048, loss is 0.017640836536884308\n",
      "epoch: 7 step: 1049, loss is 0.007909756153821945\n",
      "epoch: 7 step: 1050, loss is 0.003938914276659489\n",
      "epoch: 7 step: 1051, loss is 0.01281712669879198\n",
      "epoch: 7 step: 1052, loss is 0.000597944890614599\n",
      "epoch: 7 step: 1053, loss is 0.1398778110742569\n",
      "epoch: 7 step: 1054, loss is 0.0009078463772311807\n",
      "epoch: 7 step: 1055, loss is 0.004233870189636946\n",
      "epoch: 7 step: 1056, loss is 0.0009471318335272372\n",
      "epoch: 7 step: 1057, loss is 0.0018011757638305426\n",
      "epoch: 7 step: 1058, loss is 0.023910334333777428\n",
      "epoch: 7 step: 1059, loss is 0.00216065626591444\n",
      "epoch: 7 step: 1060, loss is 0.00022498206817544997\n",
      "epoch: 7 step: 1061, loss is 0.0016560099320486188\n",
      "epoch: 7 step: 1062, loss is 0.001577518880367279\n",
      "epoch: 7 step: 1063, loss is 0.005332217551767826\n",
      "epoch: 7 step: 1064, loss is 0.0009095382411032915\n",
      "epoch: 7 step: 1065, loss is 3.3691496355459094e-05\n",
      "epoch: 7 step: 1066, loss is 0.0019348831847310066\n",
      "epoch: 7 step: 1067, loss is 0.005893467925488949\n",
      "epoch: 7 step: 1068, loss is 0.08798669278621674\n",
      "epoch: 7 step: 1069, loss is 0.003471269039437175\n",
      "epoch: 7 step: 1070, loss is 0.00028883162303827703\n",
      "epoch: 7 step: 1071, loss is 0.022305628284811974\n",
      "epoch: 7 step: 1072, loss is 0.004379113204777241\n",
      "epoch: 7 step: 1073, loss is 0.0029031771700829268\n",
      "epoch: 7 step: 1074, loss is 0.0012792983325198293\n",
      "epoch: 7 step: 1075, loss is 0.001358406851068139\n",
      "epoch: 7 step: 1076, loss is 0.00024776210193522274\n",
      "epoch: 7 step: 1077, loss is 0.01121559925377369\n",
      "epoch: 7 step: 1078, loss is 0.0008531687781214714\n",
      "epoch: 7 step: 1079, loss is 0.0003557914460543543\n",
      "epoch: 7 step: 1080, loss is 0.0017070723697543144\n",
      "epoch: 7 step: 1081, loss is 0.014516133815050125\n",
      "epoch: 7 step: 1082, loss is 8.39695621834835e-06\n",
      "epoch: 7 step: 1083, loss is 0.00061778788222\n",
      "epoch: 7 step: 1084, loss is 0.00025571309379301965\n",
      "epoch: 7 step: 1085, loss is 0.016125163063406944\n",
      "epoch: 7 step: 1086, loss is 0.003099666675552726\n",
      "epoch: 7 step: 1087, loss is 0.0005968200275674462\n",
      "epoch: 7 step: 1088, loss is 0.091114841401577\n",
      "epoch: 7 step: 1089, loss is 0.006720144301652908\n",
      "epoch: 7 step: 1090, loss is 0.009528343565762043\n",
      "epoch: 7 step: 1091, loss is 8.618475840194151e-05\n",
      "epoch: 7 step: 1092, loss is 0.00028309732442721725\n",
      "epoch: 7 step: 1093, loss is 0.025754006579518318\n",
      "epoch: 7 step: 1094, loss is 0.0008102309657260776\n",
      "epoch: 7 step: 1095, loss is 0.00042186392238363624\n",
      "epoch: 7 step: 1096, loss is 0.009331172332167625\n",
      "epoch: 7 step: 1097, loss is 0.0028178575448691845\n",
      "epoch: 7 step: 1098, loss is 0.010696029290556908\n",
      "epoch: 7 step: 1099, loss is 0.006878220941871405\n",
      "epoch: 7 step: 1100, loss is 0.02776506170630455\n",
      "epoch: 7 step: 1101, loss is 0.0014715978177264333\n",
      "epoch: 7 step: 1102, loss is 0.06597966700792313\n",
      "epoch: 7 step: 1103, loss is 0.00021218053007032722\n",
      "epoch: 7 step: 1104, loss is 0.016437649726867676\n",
      "epoch: 7 step: 1105, loss is 0.001660570502281189\n",
      "epoch: 7 step: 1106, loss is 0.016065465286374092\n",
      "epoch: 7 step: 1107, loss is 4.553552935249172e-05\n",
      "epoch: 7 step: 1108, loss is 0.0010982423555105925\n",
      "epoch: 7 step: 1109, loss is 0.029355287551879883\n",
      "epoch: 7 step: 1110, loss is 0.0007920680218376219\n",
      "epoch: 7 step: 1111, loss is 0.040204524993896484\n",
      "epoch: 7 step: 1112, loss is 0.0008402599487453699\n",
      "epoch: 7 step: 1113, loss is 0.000925285741686821\n",
      "epoch: 7 step: 1114, loss is 0.003980246838182211\n",
      "epoch: 7 step: 1115, loss is 7.900057244114578e-05\n",
      "epoch: 7 step: 1116, loss is 0.039439648389816284\n",
      "epoch: 7 step: 1117, loss is 7.885420200182125e-05\n",
      "epoch: 7 step: 1118, loss is 0.00413379305973649\n",
      "epoch: 7 step: 1119, loss is 0.04303616285324097\n",
      "epoch: 7 step: 1120, loss is 0.0035901207011193037\n",
      "epoch: 7 step: 1121, loss is 0.002230178564786911\n",
      "epoch: 7 step: 1122, loss is 0.008568725548684597\n",
      "epoch: 7 step: 1123, loss is 0.003870225977152586\n",
      "epoch: 7 step: 1124, loss is 0.0435611754655838\n",
      "epoch: 7 step: 1125, loss is 0.02089330367743969\n",
      "epoch: 7 step: 1126, loss is 0.034649334847927094\n",
      "epoch: 7 step: 1127, loss is 0.08664033561944962\n",
      "epoch: 7 step: 1128, loss is 0.012553650885820389\n",
      "epoch: 7 step: 1129, loss is 0.011218339204788208\n",
      "epoch: 7 step: 1130, loss is 0.06852354854345322\n",
      "epoch: 7 step: 1131, loss is 0.12095746397972107\n",
      "epoch: 7 step: 1132, loss is 0.001620511175133288\n",
      "epoch: 7 step: 1133, loss is 7.88911638665013e-05\n",
      "epoch: 7 step: 1134, loss is 0.0004219177644699812\n",
      "epoch: 7 step: 1135, loss is 0.0007821035105735064\n",
      "epoch: 7 step: 1136, loss is 0.00022570785949938\n",
      "epoch: 7 step: 1137, loss is 0.0018868029583245516\n",
      "epoch: 7 step: 1138, loss is 0.002637651516124606\n",
      "epoch: 7 step: 1139, loss is 0.00016739952843636274\n",
      "epoch: 7 step: 1140, loss is 0.0006344584980979562\n",
      "epoch: 7 step: 1141, loss is 0.07009679079055786\n",
      "epoch: 7 step: 1142, loss is 0.08709936589002609\n",
      "epoch: 7 step: 1143, loss is 0.0016821130411699414\n",
      "epoch: 7 step: 1144, loss is 0.00017111445777118206\n",
      "epoch: 7 step: 1145, loss is 0.005417277105152607\n",
      "epoch: 7 step: 1146, loss is 0.0022204527631402016\n",
      "epoch: 7 step: 1147, loss is 0.0007539309444837272\n",
      "epoch: 7 step: 1148, loss is 0.0002527642354834825\n",
      "epoch: 7 step: 1149, loss is 0.09227100014686584\n",
      "epoch: 7 step: 1150, loss is 0.00023082213010638952\n",
      "epoch: 7 step: 1151, loss is 0.008179991506040096\n",
      "epoch: 7 step: 1152, loss is 0.002876252867281437\n",
      "epoch: 7 step: 1153, loss is 0.1077675148844719\n",
      "epoch: 7 step: 1154, loss is 0.0005926546873524785\n",
      "epoch: 7 step: 1155, loss is 0.0002620279265101999\n",
      "epoch: 7 step: 1156, loss is 3.737771839951165e-05\n",
      "epoch: 7 step: 1157, loss is 8.110128874250222e-06\n",
      "epoch: 7 step: 1158, loss is 0.00882126297801733\n",
      "epoch: 7 step: 1159, loss is 0.06642632186412811\n",
      "epoch: 7 step: 1160, loss is 0.016700122505426407\n",
      "epoch: 7 step: 1161, loss is 0.004416726529598236\n",
      "epoch: 7 step: 1162, loss is 0.1312166452407837\n",
      "epoch: 7 step: 1163, loss is 3.6084442399442196e-05\n",
      "epoch: 7 step: 1164, loss is 5.911667176405899e-05\n",
      "epoch: 7 step: 1165, loss is 0.00024394632782787085\n",
      "epoch: 7 step: 1166, loss is 0.00042944104643538594\n",
      "epoch: 7 step: 1167, loss is 0.0001146847935160622\n",
      "epoch: 7 step: 1168, loss is 1.0069912605104037e-05\n",
      "epoch: 7 step: 1169, loss is 0.00016184487321879715\n",
      "epoch: 7 step: 1170, loss is 0.0017098243115469813\n",
      "epoch: 7 step: 1171, loss is 0.010415744967758656\n",
      "epoch: 7 step: 1172, loss is 0.0010762366000562906\n",
      "epoch: 7 step: 1173, loss is 0.0034531839191913605\n",
      "epoch: 7 step: 1174, loss is 0.004480260889977217\n",
      "epoch: 7 step: 1175, loss is 0.007147240452468395\n",
      "epoch: 7 step: 1176, loss is 0.0008369164424948394\n",
      "epoch: 7 step: 1177, loss is 9.573205898050219e-05\n",
      "epoch: 7 step: 1178, loss is 0.008078834973275661\n",
      "epoch: 7 step: 1179, loss is 0.0016667690360918641\n",
      "epoch: 7 step: 1180, loss is 0.008494308218359947\n",
      "epoch: 7 step: 1181, loss is 0.014960532076656818\n",
      "epoch: 7 step: 1182, loss is 0.0005126907490193844\n",
      "epoch: 7 step: 1183, loss is 0.002825820352882147\n",
      "epoch: 7 step: 1184, loss is 0.0013103070668876171\n",
      "epoch: 7 step: 1185, loss is 0.00303235393948853\n",
      "epoch: 7 step: 1186, loss is 9.82718265731819e-05\n",
      "epoch: 7 step: 1187, loss is 0.007292531430721283\n",
      "epoch: 7 step: 1188, loss is 0.016352852806448936\n",
      "epoch: 7 step: 1189, loss is 0.0010379975428804755\n",
      "epoch: 7 step: 1190, loss is 0.03510916233062744\n",
      "epoch: 7 step: 1191, loss is 0.026613252237439156\n",
      "epoch: 7 step: 1192, loss is 0.0012821233831346035\n",
      "epoch: 7 step: 1193, loss is 0.001211221911944449\n",
      "epoch: 7 step: 1194, loss is 8.782069926382974e-05\n",
      "epoch: 7 step: 1195, loss is 7.336277485592291e-05\n",
      "epoch: 7 step: 1196, loss is 0.0026355283334851265\n",
      "epoch: 7 step: 1197, loss is 0.14313280582427979\n",
      "epoch: 7 step: 1198, loss is 0.00011778826592490077\n",
      "epoch: 7 step: 1199, loss is 0.004385972395539284\n",
      "epoch: 7 step: 1200, loss is 0.0047143991105258465\n",
      "epoch: 7 step: 1201, loss is 5.767939001088962e-05\n",
      "epoch: 7 step: 1202, loss is 2.726432285271585e-05\n",
      "epoch: 7 step: 1203, loss is 0.005798953585326672\n",
      "epoch: 7 step: 1204, loss is 0.000746395904570818\n",
      "epoch: 7 step: 1205, loss is 0.0006614598096348345\n",
      "epoch: 7 step: 1206, loss is 6.527930963784456e-05\n",
      "epoch: 7 step: 1207, loss is 0.017268836498260498\n",
      "epoch: 7 step: 1208, loss is 0.028526773676276207\n",
      "epoch: 7 step: 1209, loss is 0.10660647600889206\n",
      "epoch: 7 step: 1210, loss is 0.0019942736253142357\n",
      "epoch: 7 step: 1211, loss is 0.05379908159375191\n",
      "epoch: 7 step: 1212, loss is 0.006103295832872391\n",
      "epoch: 7 step: 1213, loss is 0.0012476922711357474\n",
      "epoch: 7 step: 1214, loss is 0.09941849857568741\n",
      "epoch: 7 step: 1215, loss is 0.00021936681878287345\n",
      "epoch: 7 step: 1216, loss is 0.008070835843682289\n",
      "epoch: 7 step: 1217, loss is 0.0030463135335594416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1218, loss is 0.09210539609193802\n",
      "epoch: 7 step: 1219, loss is 0.2318515032529831\n",
      "epoch: 7 step: 1220, loss is 0.00031585307442583144\n",
      "epoch: 7 step: 1221, loss is 0.024981696158647537\n",
      "epoch: 7 step: 1222, loss is 0.0006633377633988857\n",
      "epoch: 7 step: 1223, loss is 0.0016364709008485079\n",
      "epoch: 7 step: 1224, loss is 0.07315466552972794\n",
      "epoch: 7 step: 1225, loss is 0.00014984422887209803\n",
      "epoch: 7 step: 1226, loss is 0.0379800908267498\n",
      "epoch: 7 step: 1227, loss is 0.0030346510466188192\n",
      "epoch: 7 step: 1228, loss is 0.0029368659015744925\n",
      "epoch: 7 step: 1229, loss is 5.317914474289864e-05\n",
      "epoch: 7 step: 1230, loss is 0.00013975633191876113\n",
      "epoch: 7 step: 1231, loss is 0.05000580847263336\n",
      "epoch: 7 step: 1232, loss is 0.0005592789384536445\n",
      "epoch: 7 step: 1233, loss is 0.0012471415102481842\n",
      "epoch: 7 step: 1234, loss is 0.0005470750038512051\n",
      "epoch: 7 step: 1235, loss is 0.0005740021006204188\n",
      "epoch: 7 step: 1236, loss is 0.07657106965780258\n",
      "epoch: 7 step: 1237, loss is 0.01668657548725605\n",
      "epoch: 7 step: 1238, loss is 0.00038667014450766146\n",
      "epoch: 7 step: 1239, loss is 0.1246272623538971\n",
      "epoch: 7 step: 1240, loss is 0.05029731243848801\n",
      "epoch: 7 step: 1241, loss is 0.019237203523516655\n",
      "epoch: 7 step: 1242, loss is 5.272344424156472e-05\n",
      "epoch: 7 step: 1243, loss is 0.0029875566251575947\n",
      "epoch: 7 step: 1244, loss is 0.0015038305427879095\n",
      "epoch: 7 step: 1245, loss is 0.0013019077014178038\n",
      "epoch: 7 step: 1246, loss is 0.017458969727158546\n",
      "epoch: 7 step: 1247, loss is 0.04652881994843483\n",
      "epoch: 7 step: 1248, loss is 0.17830336093902588\n",
      "epoch: 7 step: 1249, loss is 0.0034832078963518143\n",
      "epoch: 7 step: 1250, loss is 0.003480857238173485\n",
      "epoch: 7 step: 1251, loss is 0.0003398484841454774\n",
      "epoch: 7 step: 1252, loss is 0.00036056930548511446\n",
      "epoch: 7 step: 1253, loss is 0.00041834585135802627\n",
      "epoch: 7 step: 1254, loss is 0.0997283086180687\n",
      "epoch: 7 step: 1255, loss is 0.00016901304479688406\n",
      "epoch: 7 step: 1256, loss is 0.03740273043513298\n",
      "epoch: 7 step: 1257, loss is 0.01425028033554554\n",
      "epoch: 7 step: 1258, loss is 0.005109043791890144\n",
      "epoch: 7 step: 1259, loss is 0.005557547323405743\n",
      "epoch: 7 step: 1260, loss is 0.003933961037546396\n",
      "epoch: 7 step: 1261, loss is 0.023932788521051407\n",
      "epoch: 7 step: 1262, loss is 0.07756871730089188\n",
      "epoch: 7 step: 1263, loss is 0.0028749057091772556\n",
      "epoch: 7 step: 1264, loss is 0.005666518118232489\n",
      "epoch: 7 step: 1265, loss is 0.0010035004233941436\n",
      "epoch: 7 step: 1266, loss is 0.19244542717933655\n",
      "epoch: 7 step: 1267, loss is 0.0014805826358497143\n",
      "epoch: 7 step: 1268, loss is 0.004952958784997463\n",
      "epoch: 7 step: 1269, loss is 0.03037109225988388\n",
      "epoch: 7 step: 1270, loss is 8.56441620271653e-05\n",
      "epoch: 7 step: 1271, loss is 0.001844623009674251\n",
      "epoch: 7 step: 1272, loss is 3.598017792683095e-05\n",
      "epoch: 7 step: 1273, loss is 3.236551128793508e-05\n",
      "epoch: 7 step: 1274, loss is 0.0010589966550469398\n",
      "epoch: 7 step: 1275, loss is 0.0004902571672573686\n",
      "epoch: 7 step: 1276, loss is 2.720727388805244e-05\n",
      "epoch: 7 step: 1277, loss is 0.016420166939496994\n",
      "epoch: 7 step: 1278, loss is 0.0012321569956839085\n",
      "epoch: 7 step: 1279, loss is 2.6380894269095734e-05\n",
      "epoch: 7 step: 1280, loss is 0.0026649869978427887\n",
      "epoch: 7 step: 1281, loss is 0.12208222597837448\n",
      "epoch: 7 step: 1282, loss is 0.007180929649621248\n",
      "epoch: 7 step: 1283, loss is 0.0031674131751060486\n",
      "epoch: 7 step: 1284, loss is 0.15986575186252594\n",
      "epoch: 7 step: 1285, loss is 0.004764936864376068\n",
      "epoch: 7 step: 1286, loss is 0.02156437560915947\n",
      "epoch: 7 step: 1287, loss is 0.0009805667214095592\n",
      "epoch: 7 step: 1288, loss is 0.001268127467483282\n",
      "epoch: 7 step: 1289, loss is 0.0003093591658398509\n",
      "epoch: 7 step: 1290, loss is 0.001001157215796411\n",
      "epoch: 7 step: 1291, loss is 0.0014466874999925494\n",
      "epoch: 7 step: 1292, loss is 0.0019872074481099844\n",
      "epoch: 7 step: 1293, loss is 0.0080686304718256\n",
      "epoch: 7 step: 1294, loss is 0.06483366340398788\n",
      "epoch: 7 step: 1295, loss is 0.00992544461041689\n",
      "epoch: 7 step: 1296, loss is 0.002875157631933689\n",
      "epoch: 7 step: 1297, loss is 0.054065246134996414\n",
      "epoch: 7 step: 1298, loss is 0.09272807836532593\n",
      "epoch: 7 step: 1299, loss is 0.015057273209095001\n",
      "epoch: 7 step: 1300, loss is 0.00038361508632078767\n",
      "epoch: 7 step: 1301, loss is 0.04925377294421196\n",
      "epoch: 7 step: 1302, loss is 0.0010099727660417557\n",
      "epoch: 7 step: 1303, loss is 0.0001998136576730758\n",
      "epoch: 7 step: 1304, loss is 0.11369460821151733\n",
      "epoch: 7 step: 1305, loss is 0.03359396383166313\n",
      "epoch: 7 step: 1306, loss is 0.0044738720171153545\n",
      "epoch: 7 step: 1307, loss is 0.00016892685380298644\n",
      "epoch: 7 step: 1308, loss is 0.007554975338280201\n",
      "epoch: 7 step: 1309, loss is 0.0009834440425038338\n",
      "epoch: 7 step: 1310, loss is 0.06669427454471588\n",
      "epoch: 7 step: 1311, loss is 0.1932535320520401\n",
      "epoch: 7 step: 1312, loss is 0.04232556372880936\n",
      "epoch: 7 step: 1313, loss is 0.00017958111129701138\n",
      "epoch: 7 step: 1314, loss is 0.010433542542159557\n",
      "epoch: 7 step: 1315, loss is 0.0005199071601964533\n",
      "epoch: 7 step: 1316, loss is 0.007471881341189146\n",
      "epoch: 7 step: 1317, loss is 0.008655629120767117\n",
      "epoch: 7 step: 1318, loss is 0.010624200105667114\n",
      "epoch: 7 step: 1319, loss is 0.0267815962433815\n",
      "epoch: 7 step: 1320, loss is 0.0851224735379219\n",
      "epoch: 7 step: 1321, loss is 0.027443023398518562\n",
      "epoch: 7 step: 1322, loss is 0.011244211345911026\n",
      "epoch: 7 step: 1323, loss is 0.027912558987736702\n",
      "epoch: 7 step: 1324, loss is 0.001215553842484951\n",
      "epoch: 7 step: 1325, loss is 0.07844755798578262\n",
      "epoch: 7 step: 1326, loss is 0.0010074955644086003\n",
      "epoch: 7 step: 1327, loss is 0.00035988097079098225\n",
      "epoch: 7 step: 1328, loss is 0.006301185116171837\n",
      "epoch: 7 step: 1329, loss is 0.009836667217314243\n",
      "epoch: 7 step: 1330, loss is 0.006028641480952501\n",
      "epoch: 7 step: 1331, loss is 0.00024268552078865469\n",
      "epoch: 7 step: 1332, loss is 0.021827558055520058\n",
      "epoch: 7 step: 1333, loss is 0.0007481294451281428\n",
      "epoch: 7 step: 1334, loss is 0.06722971796989441\n",
      "epoch: 7 step: 1335, loss is 0.002373657189309597\n",
      "epoch: 7 step: 1336, loss is 0.00020968039461877197\n",
      "epoch: 7 step: 1337, loss is 0.012019257061183453\n",
      "epoch: 7 step: 1338, loss is 0.004330815747380257\n",
      "epoch: 7 step: 1339, loss is 0.016018971800804138\n",
      "epoch: 7 step: 1340, loss is 0.005041579250246286\n",
      "epoch: 7 step: 1341, loss is 0.022910110652446747\n",
      "epoch: 7 step: 1342, loss is 0.0018575433641672134\n",
      "epoch: 7 step: 1343, loss is 0.0007080741925165057\n",
      "epoch: 7 step: 1344, loss is 0.00331893190741539\n",
      "epoch: 7 step: 1345, loss is 0.008662656880915165\n",
      "epoch: 7 step: 1346, loss is 0.05449797958135605\n",
      "epoch: 7 step: 1347, loss is 0.001740808947943151\n",
      "epoch: 7 step: 1348, loss is 0.00023802775831427425\n",
      "epoch: 7 step: 1349, loss is 0.00896724034100771\n",
      "epoch: 7 step: 1350, loss is 0.0050767213106155396\n",
      "epoch: 7 step: 1351, loss is 0.011013341136276722\n",
      "epoch: 7 step: 1352, loss is 0.1923576146364212\n",
      "epoch: 7 step: 1353, loss is 0.0003649764694273472\n",
      "epoch: 7 step: 1354, loss is 0.0005044900462962687\n",
      "epoch: 7 step: 1355, loss is 0.06969266384840012\n",
      "epoch: 7 step: 1356, loss is 0.00226230057887733\n",
      "epoch: 7 step: 1357, loss is 0.0006860862486064434\n",
      "epoch: 7 step: 1358, loss is 0.001915734144859016\n",
      "epoch: 7 step: 1359, loss is 0.02169189602136612\n",
      "epoch: 7 step: 1360, loss is 4.506696859607473e-05\n",
      "epoch: 7 step: 1361, loss is 0.006754617672413588\n",
      "epoch: 7 step: 1362, loss is 9.876037438516505e-06\n",
      "epoch: 7 step: 1363, loss is 0.0006555971340276301\n",
      "epoch: 7 step: 1364, loss is 0.0015209332341328263\n",
      "epoch: 7 step: 1365, loss is 0.01310410350561142\n",
      "epoch: 7 step: 1366, loss is 0.00694017019122839\n",
      "epoch: 7 step: 1367, loss is 1.7493557606940158e-05\n",
      "epoch: 7 step: 1368, loss is 0.07240395992994308\n",
      "epoch: 7 step: 1369, loss is 9.202690125675872e-05\n",
      "epoch: 7 step: 1370, loss is 0.023960376158356667\n",
      "epoch: 7 step: 1371, loss is 0.0016294410452246666\n",
      "epoch: 7 step: 1372, loss is 0.01652243547141552\n",
      "epoch: 7 step: 1373, loss is 0.003298278898000717\n",
      "epoch: 7 step: 1374, loss is 0.00444976007565856\n",
      "epoch: 7 step: 1375, loss is 0.0021370965987443924\n",
      "epoch: 7 step: 1376, loss is 0.00116255646571517\n",
      "epoch: 7 step: 1377, loss is 0.25577017664909363\n",
      "epoch: 7 step: 1378, loss is 0.06059521064162254\n",
      "epoch: 7 step: 1379, loss is 0.0003701866080518812\n",
      "epoch: 7 step: 1380, loss is 0.0012436896795406938\n",
      "epoch: 7 step: 1381, loss is 0.0005520914564840496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1382, loss is 0.028246285393834114\n",
      "epoch: 7 step: 1383, loss is 0.05179382115602493\n",
      "epoch: 7 step: 1384, loss is 0.003089748788625002\n",
      "epoch: 7 step: 1385, loss is 0.008233626373112202\n",
      "epoch: 7 step: 1386, loss is 0.007730837445706129\n",
      "epoch: 7 step: 1387, loss is 0.04264755919575691\n",
      "epoch: 7 step: 1388, loss is 0.0008027951116673648\n",
      "epoch: 7 step: 1389, loss is 0.046547312289476395\n",
      "epoch: 7 step: 1390, loss is 0.0013258903054520488\n",
      "epoch: 7 step: 1391, loss is 0.043212417513132095\n",
      "epoch: 7 step: 1392, loss is 0.0014021380338817835\n",
      "epoch: 7 step: 1393, loss is 0.021591760218143463\n",
      "epoch: 7 step: 1394, loss is 0.24047398567199707\n",
      "epoch: 7 step: 1395, loss is 0.023640958592295647\n",
      "epoch: 7 step: 1396, loss is 0.10877758264541626\n",
      "epoch: 7 step: 1397, loss is 0.01778126321732998\n",
      "epoch: 7 step: 1398, loss is 0.001004945719614625\n",
      "epoch: 7 step: 1399, loss is 0.0051836431957781315\n",
      "epoch: 7 step: 1400, loss is 0.02598254382610321\n",
      "epoch: 7 step: 1401, loss is 0.11566762626171112\n",
      "epoch: 7 step: 1402, loss is 0.002835433231666684\n",
      "epoch: 7 step: 1403, loss is 0.00026449610595591366\n",
      "epoch: 7 step: 1404, loss is 0.013936404138803482\n",
      "epoch: 7 step: 1405, loss is 0.0006699945079162717\n",
      "epoch: 7 step: 1406, loss is 6.357936217682436e-05\n",
      "epoch: 7 step: 1407, loss is 0.002002677647396922\n",
      "epoch: 7 step: 1408, loss is 0.00410065334290266\n",
      "epoch: 7 step: 1409, loss is 0.0018426222959533334\n",
      "epoch: 7 step: 1410, loss is 0.00032991511397995055\n",
      "epoch: 7 step: 1411, loss is 0.015219911932945251\n",
      "epoch: 7 step: 1412, loss is 0.011744748800992966\n",
      "epoch: 7 step: 1413, loss is 0.04046080633997917\n",
      "epoch: 7 step: 1414, loss is 0.00011480650573503226\n",
      "epoch: 7 step: 1415, loss is 0.003235421609133482\n",
      "epoch: 7 step: 1416, loss is 0.0005517984391190112\n",
      "epoch: 7 step: 1417, loss is 0.0024895763490349054\n",
      "epoch: 7 step: 1418, loss is 0.0326969213783741\n",
      "epoch: 7 step: 1419, loss is 0.00048267797683365643\n",
      "epoch: 7 step: 1420, loss is 0.01968291588127613\n",
      "epoch: 7 step: 1421, loss is 0.11662959307432175\n",
      "epoch: 7 step: 1422, loss is 0.08495362848043442\n",
      "epoch: 7 step: 1423, loss is 0.020735351368784904\n",
      "epoch: 7 step: 1424, loss is 0.09450789541006088\n",
      "epoch: 7 step: 1425, loss is 0.0015375141520053148\n",
      "epoch: 7 step: 1426, loss is 0.0026885217521339655\n",
      "epoch: 7 step: 1427, loss is 0.007514371536672115\n",
      "epoch: 7 step: 1428, loss is 0.042438726872205734\n",
      "epoch: 7 step: 1429, loss is 0.14230753481388092\n",
      "epoch: 7 step: 1430, loss is 0.00014198519056662917\n",
      "epoch: 7 step: 1431, loss is 0.0007785221678204834\n",
      "epoch: 7 step: 1432, loss is 0.012193472124636173\n",
      "epoch: 7 step: 1433, loss is 0.2740720510482788\n",
      "epoch: 7 step: 1434, loss is 0.0012504477053880692\n",
      "epoch: 7 step: 1435, loss is 0.0020103324204683304\n",
      "epoch: 7 step: 1436, loss is 0.0008399734506383538\n",
      "epoch: 7 step: 1437, loss is 0.00853852927684784\n",
      "epoch: 7 step: 1438, loss is 0.0021650874987244606\n",
      "epoch: 7 step: 1439, loss is 0.04721004143357277\n",
      "epoch: 7 step: 1440, loss is 7.582797843497247e-05\n",
      "epoch: 7 step: 1441, loss is 0.0570271760225296\n",
      "epoch: 7 step: 1442, loss is 0.0012281349627301097\n",
      "epoch: 7 step: 1443, loss is 0.09365466982126236\n",
      "epoch: 7 step: 1444, loss is 0.2396865040063858\n",
      "epoch: 7 step: 1445, loss is 0.014912538230419159\n",
      "epoch: 7 step: 1446, loss is 0.0005974088562652469\n",
      "epoch: 7 step: 1447, loss is 0.004930752795189619\n",
      "epoch: 7 step: 1448, loss is 0.0027191368862986565\n",
      "epoch: 7 step: 1449, loss is 0.0013366849161684513\n",
      "epoch: 7 step: 1450, loss is 0.0009635361493565142\n",
      "epoch: 7 step: 1451, loss is 0.000990255386568606\n",
      "epoch: 7 step: 1452, loss is 0.017603712156414986\n",
      "epoch: 7 step: 1453, loss is 0.018091343343257904\n",
      "epoch: 7 step: 1454, loss is 0.0005435936618596315\n",
      "epoch: 7 step: 1455, loss is 0.0013577905483543873\n",
      "epoch: 7 step: 1456, loss is 0.004930785857141018\n",
      "epoch: 7 step: 1457, loss is 0.030049528926610947\n",
      "epoch: 7 step: 1458, loss is 0.0016196293290704489\n",
      "epoch: 7 step: 1459, loss is 0.00016817841969896108\n",
      "epoch: 7 step: 1460, loss is 0.0028625705745071173\n",
      "epoch: 7 step: 1461, loss is 0.06579697877168655\n",
      "epoch: 7 step: 1462, loss is 0.0005045383586548269\n",
      "epoch: 7 step: 1463, loss is 0.022291559725999832\n",
      "epoch: 7 step: 1464, loss is 0.00695300055667758\n",
      "epoch: 7 step: 1465, loss is 0.024190831929445267\n",
      "epoch: 7 step: 1466, loss is 0.0008085389854386449\n",
      "epoch: 7 step: 1467, loss is 0.0002752330037765205\n",
      "epoch: 7 step: 1468, loss is 8.511221676599234e-05\n",
      "epoch: 7 step: 1469, loss is 0.02527637407183647\n",
      "epoch: 7 step: 1470, loss is 8.327218529302627e-05\n",
      "epoch: 7 step: 1471, loss is 0.004818340763449669\n",
      "epoch: 7 step: 1472, loss is 0.0006960724131204188\n",
      "epoch: 7 step: 1473, loss is 0.024430247023701668\n",
      "epoch: 7 step: 1474, loss is 0.0011154749663546681\n",
      "epoch: 7 step: 1475, loss is 0.030462205410003662\n",
      "epoch: 7 step: 1476, loss is 0.005233719013631344\n",
      "epoch: 7 step: 1477, loss is 0.0003581777564249933\n",
      "epoch: 7 step: 1478, loss is 0.021549763157963753\n",
      "epoch: 7 step: 1479, loss is 0.0001992712204810232\n",
      "epoch: 7 step: 1480, loss is 0.07866256684064865\n",
      "epoch: 7 step: 1481, loss is 0.042604971677064896\n",
      "epoch: 7 step: 1482, loss is 0.010129746049642563\n",
      "epoch: 7 step: 1483, loss is 0.0007644223514944315\n",
      "epoch: 7 step: 1484, loss is 0.0010808666702359915\n",
      "epoch: 7 step: 1485, loss is 0.001878444105386734\n",
      "epoch: 7 step: 1486, loss is 0.0006047628121450543\n",
      "epoch: 7 step: 1487, loss is 0.0449368953704834\n",
      "epoch: 7 step: 1488, loss is 0.05821195989847183\n",
      "epoch: 7 step: 1489, loss is 0.01320187933743\n",
      "epoch: 7 step: 1490, loss is 0.0019897569436579943\n",
      "epoch: 7 step: 1491, loss is 0.002950370544567704\n",
      "epoch: 7 step: 1492, loss is 0.004664439707994461\n",
      "epoch: 7 step: 1493, loss is 0.0012121753534302115\n",
      "epoch: 7 step: 1494, loss is 0.0008645486668683589\n",
      "epoch: 7 step: 1495, loss is 0.007218100130558014\n",
      "epoch: 7 step: 1496, loss is 0.00015502836322411895\n",
      "epoch: 7 step: 1497, loss is 0.0013725620228797197\n",
      "epoch: 7 step: 1498, loss is 4.828190867556259e-05\n",
      "epoch: 7 step: 1499, loss is 0.026552924886345863\n",
      "epoch: 7 step: 1500, loss is 0.0004831259429920465\n",
      "epoch: 7 step: 1501, loss is 0.019950760528445244\n",
      "epoch: 7 step: 1502, loss is 0.17289894819259644\n",
      "epoch: 7 step: 1503, loss is 0.025053218007087708\n",
      "epoch: 7 step: 1504, loss is 0.029487937688827515\n",
      "epoch: 7 step: 1505, loss is 0.0002270443510496989\n",
      "epoch: 7 step: 1506, loss is 0.004679848439991474\n",
      "epoch: 7 step: 1507, loss is 0.00012349485768936574\n",
      "epoch: 7 step: 1508, loss is 0.3951040506362915\n",
      "epoch: 7 step: 1509, loss is 0.024669388309121132\n",
      "epoch: 7 step: 1510, loss is 0.0016043917275965214\n",
      "epoch: 7 step: 1511, loss is 0.015591898001730442\n",
      "epoch: 7 step: 1512, loss is 0.061400387436151505\n",
      "epoch: 7 step: 1513, loss is 0.008562738075852394\n",
      "epoch: 7 step: 1514, loss is 0.015650292858481407\n",
      "epoch: 7 step: 1515, loss is 0.04513097181916237\n",
      "epoch: 7 step: 1516, loss is 0.003028652397915721\n",
      "epoch: 7 step: 1517, loss is 0.003808309556916356\n",
      "epoch: 7 step: 1518, loss is 0.0030143919866532087\n",
      "epoch: 7 step: 1519, loss is 0.01230493001639843\n",
      "epoch: 7 step: 1520, loss is 0.013286463916301727\n",
      "epoch: 7 step: 1521, loss is 0.0016691392520442605\n",
      "epoch: 7 step: 1522, loss is 0.000991734443232417\n",
      "epoch: 7 step: 1523, loss is 0.009277989156544209\n",
      "epoch: 7 step: 1524, loss is 0.048466045409440994\n",
      "epoch: 7 step: 1525, loss is 0.0014447603607550263\n",
      "epoch: 7 step: 1526, loss is 0.016697289422154427\n",
      "epoch: 7 step: 1527, loss is 0.18176744878292084\n",
      "epoch: 7 step: 1528, loss is 0.0071358527056872845\n",
      "epoch: 7 step: 1529, loss is 0.0034693190827965736\n",
      "epoch: 7 step: 1530, loss is 0.0023471894674003124\n",
      "epoch: 7 step: 1531, loss is 0.00028807928902097046\n",
      "epoch: 7 step: 1532, loss is 0.12099143862724304\n",
      "epoch: 7 step: 1533, loss is 0.00023933238117024302\n",
      "epoch: 7 step: 1534, loss is 0.0006054475088603795\n",
      "epoch: 7 step: 1535, loss is 0.0014435278717428446\n",
      "epoch: 7 step: 1536, loss is 0.0038779033347964287\n",
      "epoch: 7 step: 1537, loss is 0.11258959025144577\n",
      "epoch: 7 step: 1538, loss is 0.0004303116584196687\n",
      "epoch: 7 step: 1539, loss is 0.03226368501782417\n",
      "epoch: 7 step: 1540, loss is 0.0021976183634251356\n",
      "epoch: 7 step: 1541, loss is 0.0038134963251650333\n",
      "epoch: 7 step: 1542, loss is 0.021717065945267677\n",
      "epoch: 7 step: 1543, loss is 0.013777608051896095\n",
      "epoch: 7 step: 1544, loss is 0.17547781765460968\n",
      "epoch: 7 step: 1545, loss is 0.0010488000698387623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1546, loss is 0.0006191559368744493\n",
      "epoch: 7 step: 1547, loss is 0.011498727835714817\n",
      "epoch: 7 step: 1548, loss is 0.004076859448105097\n",
      "epoch: 7 step: 1549, loss is 0.0010333806276321411\n",
      "epoch: 7 step: 1550, loss is 0.00031976267928257585\n",
      "epoch: 7 step: 1551, loss is 0.00031727907480672\n",
      "epoch: 7 step: 1552, loss is 0.0008326507522724569\n",
      "epoch: 7 step: 1553, loss is 0.045668020844459534\n",
      "epoch: 7 step: 1554, loss is 0.0020760789047926664\n",
      "epoch: 7 step: 1555, loss is 0.00027526760823093355\n",
      "epoch: 7 step: 1556, loss is 0.0027920864522457123\n",
      "epoch: 7 step: 1557, loss is 0.00030638230964541435\n",
      "epoch: 7 step: 1558, loss is 0.0017449415754526854\n",
      "epoch: 7 step: 1559, loss is 0.06926049292087555\n",
      "epoch: 7 step: 1560, loss is 0.0014911192702129483\n",
      "epoch: 7 step: 1561, loss is 0.011372880078852177\n",
      "epoch: 7 step: 1562, loss is 0.005012515000998974\n",
      "epoch: 7 step: 1563, loss is 0.0008605981711298227\n",
      "epoch: 7 step: 1564, loss is 0.0005000384408049285\n",
      "epoch: 7 step: 1565, loss is 0.0044074589386582375\n",
      "epoch: 7 step: 1566, loss is 0.06317871063947678\n",
      "epoch: 7 step: 1567, loss is 0.014327912591397762\n",
      "epoch: 7 step: 1568, loss is 0.0024614727590233088\n",
      "epoch: 7 step: 1569, loss is 0.0052492255344986916\n",
      "epoch: 7 step: 1570, loss is 0.0031330178026109934\n",
      "epoch: 7 step: 1571, loss is 0.0017620017752051353\n",
      "epoch: 7 step: 1572, loss is 0.0009886850602924824\n",
      "epoch: 7 step: 1573, loss is 0.0010676516685634851\n",
      "epoch: 7 step: 1574, loss is 3.701322202687152e-05\n",
      "epoch: 7 step: 1575, loss is 0.0018264295067638159\n",
      "epoch: 7 step: 1576, loss is 0.005313691217452288\n",
      "epoch: 7 step: 1577, loss is 0.3031885027885437\n",
      "epoch: 7 step: 1578, loss is 0.002209857339039445\n",
      "epoch: 7 step: 1579, loss is 0.014756979420781136\n",
      "epoch: 7 step: 1580, loss is 0.006103919818997383\n",
      "epoch: 7 step: 1581, loss is 0.01238306611776352\n",
      "epoch: 7 step: 1582, loss is 0.18298417329788208\n",
      "epoch: 7 step: 1583, loss is 0.1473606824874878\n",
      "epoch: 7 step: 1584, loss is 0.015374178066849709\n",
      "epoch: 7 step: 1585, loss is 0.11968957632780075\n",
      "epoch: 7 step: 1586, loss is 0.007278223987668753\n",
      "epoch: 7 step: 1587, loss is 0.29920491576194763\n",
      "epoch: 7 step: 1588, loss is 0.005561701487749815\n",
      "epoch: 7 step: 1589, loss is 0.11015838384628296\n",
      "epoch: 7 step: 1590, loss is 0.0029841847717761993\n",
      "epoch: 7 step: 1591, loss is 0.025918589904904366\n",
      "epoch: 7 step: 1592, loss is 9.662233787821606e-05\n",
      "epoch: 7 step: 1593, loss is 0.009215818718075752\n",
      "epoch: 7 step: 1594, loss is 0.0021653661970049143\n",
      "epoch: 7 step: 1595, loss is 0.0018330286256968975\n",
      "epoch: 7 step: 1596, loss is 0.0006128450622782111\n",
      "epoch: 7 step: 1597, loss is 0.003558867610991001\n",
      "epoch: 7 step: 1598, loss is 0.0006959928432479501\n",
      "epoch: 7 step: 1599, loss is 0.1263652741909027\n",
      "epoch: 7 step: 1600, loss is 0.01501226145774126\n",
      "epoch: 7 step: 1601, loss is 0.1257641762495041\n",
      "epoch: 7 step: 1602, loss is 0.022186920046806335\n",
      "epoch: 7 step: 1603, loss is 0.0034465882927179337\n",
      "epoch: 7 step: 1604, loss is 0.006200852338224649\n",
      "epoch: 7 step: 1605, loss is 0.00018150819232687354\n",
      "epoch: 7 step: 1606, loss is 0.005061245057731867\n",
      "epoch: 7 step: 1607, loss is 0.007405679672956467\n",
      "epoch: 7 step: 1608, loss is 0.007493471726775169\n",
      "epoch: 7 step: 1609, loss is 0.012357719242572784\n",
      "epoch: 7 step: 1610, loss is 0.020270034670829773\n",
      "epoch: 7 step: 1611, loss is 0.0012955953134223819\n",
      "epoch: 7 step: 1612, loss is 0.05032781511545181\n",
      "epoch: 7 step: 1613, loss is 0.012198441661894321\n",
      "epoch: 7 step: 1614, loss is 4.0109491237672046e-05\n",
      "epoch: 7 step: 1615, loss is 0.03630718216300011\n",
      "epoch: 7 step: 1616, loss is 0.05835545435547829\n",
      "epoch: 7 step: 1617, loss is 0.0015668324194848537\n",
      "epoch: 7 step: 1618, loss is 0.005210737232118845\n",
      "epoch: 7 step: 1619, loss is 0.0072283074259757996\n",
      "epoch: 7 step: 1620, loss is 0.1556999534368515\n",
      "epoch: 7 step: 1621, loss is 0.00443244818598032\n",
      "epoch: 7 step: 1622, loss is 0.016502030193805695\n",
      "epoch: 7 step: 1623, loss is 0.0011962830321863294\n",
      "epoch: 7 step: 1624, loss is 0.002570933662354946\n",
      "epoch: 7 step: 1625, loss is 0.02307353913784027\n",
      "epoch: 7 step: 1626, loss is 0.010266288183629513\n",
      "epoch: 7 step: 1627, loss is 0.02730402536690235\n",
      "epoch: 7 step: 1628, loss is 0.053760237991809845\n",
      "epoch: 7 step: 1629, loss is 0.20854023098945618\n",
      "epoch: 7 step: 1630, loss is 0.014710322953760624\n",
      "epoch: 7 step: 1631, loss is 0.008028768934309483\n",
      "epoch: 7 step: 1632, loss is 0.0005843156250193715\n",
      "epoch: 7 step: 1633, loss is 0.02702099271118641\n",
      "epoch: 7 step: 1634, loss is 0.013078667223453522\n",
      "epoch: 7 step: 1635, loss is 0.011512259021401405\n",
      "epoch: 7 step: 1636, loss is 0.0008088746690191329\n",
      "epoch: 7 step: 1637, loss is 0.0002144161844626069\n",
      "epoch: 7 step: 1638, loss is 0.00021250516874715686\n",
      "epoch: 7 step: 1639, loss is 2.419668817310594e-05\n",
      "epoch: 7 step: 1640, loss is 0.2591918408870697\n",
      "epoch: 7 step: 1641, loss is 0.00027027743635699153\n",
      "epoch: 7 step: 1642, loss is 0.0002872509940061718\n",
      "epoch: 7 step: 1643, loss is 0.003974258899688721\n",
      "epoch: 7 step: 1644, loss is 0.0018018529517576098\n",
      "epoch: 7 step: 1645, loss is 0.04045473039150238\n",
      "epoch: 7 step: 1646, loss is 0.0028674155473709106\n",
      "epoch: 7 step: 1647, loss is 0.021980755031108856\n",
      "epoch: 7 step: 1648, loss is 0.00023424420214723796\n",
      "epoch: 7 step: 1649, loss is 0.003315230831503868\n",
      "epoch: 7 step: 1650, loss is 0.042173586785793304\n",
      "epoch: 7 step: 1651, loss is 0.00023818323097657412\n",
      "epoch: 7 step: 1652, loss is 0.0011454886989668012\n",
      "epoch: 7 step: 1653, loss is 0.016257692128419876\n",
      "epoch: 7 step: 1654, loss is 0.007841928862035275\n",
      "epoch: 7 step: 1655, loss is 0.1770467311143875\n",
      "epoch: 7 step: 1656, loss is 0.000805477611720562\n",
      "epoch: 7 step: 1657, loss is 0.006904745940119028\n",
      "epoch: 7 step: 1658, loss is 0.01504599954932928\n",
      "epoch: 7 step: 1659, loss is 0.0010190570028498769\n",
      "epoch: 7 step: 1660, loss is 0.018108585849404335\n",
      "epoch: 7 step: 1661, loss is 0.0017114211805164814\n",
      "epoch: 7 step: 1662, loss is 0.0007941738585941494\n",
      "epoch: 7 step: 1663, loss is 0.07415997982025146\n",
      "epoch: 7 step: 1664, loss is 0.0006849170313216746\n",
      "epoch: 7 step: 1665, loss is 0.001413225196301937\n",
      "epoch: 7 step: 1666, loss is 0.12943579256534576\n",
      "epoch: 7 step: 1667, loss is 0.004375405143946409\n",
      "epoch: 7 step: 1668, loss is 0.00036046115565113723\n",
      "epoch: 7 step: 1669, loss is 0.05812050402164459\n",
      "epoch: 7 step: 1670, loss is 0.0004902116488665342\n",
      "epoch: 7 step: 1671, loss is 0.018294522538781166\n",
      "epoch: 7 step: 1672, loss is 0.009830759838223457\n",
      "epoch: 7 step: 1673, loss is 9.199087071465328e-05\n",
      "epoch: 7 step: 1674, loss is 0.029421649873256683\n",
      "epoch: 7 step: 1675, loss is 0.0022707567550241947\n",
      "epoch: 7 step: 1676, loss is 0.00023536475782748312\n",
      "epoch: 7 step: 1677, loss is 0.001506761647760868\n",
      "epoch: 7 step: 1678, loss is 0.06631981581449509\n",
      "epoch: 7 step: 1679, loss is 0.001492649782449007\n",
      "epoch: 7 step: 1680, loss is 0.0007507011760026217\n",
      "epoch: 7 step: 1681, loss is 5.793684613308869e-05\n",
      "epoch: 7 step: 1682, loss is 0.0002907105954363942\n",
      "epoch: 7 step: 1683, loss is 0.012684810906648636\n",
      "epoch: 7 step: 1684, loss is 0.011653553694486618\n",
      "epoch: 7 step: 1685, loss is 0.006920299958437681\n",
      "epoch: 7 step: 1686, loss is 0.0015969459200277925\n",
      "epoch: 7 step: 1687, loss is 0.03575300797820091\n",
      "epoch: 7 step: 1688, loss is 0.004635755438357592\n",
      "epoch: 7 step: 1689, loss is 0.010233690962195396\n",
      "epoch: 7 step: 1690, loss is 0.006863381713628769\n",
      "epoch: 7 step: 1691, loss is 0.0013550638686865568\n",
      "epoch: 7 step: 1692, loss is 0.012081135995686054\n",
      "epoch: 7 step: 1693, loss is 0.008944821543991566\n",
      "epoch: 7 step: 1694, loss is 0.0010426809312775731\n",
      "epoch: 7 step: 1695, loss is 0.003291678847745061\n",
      "epoch: 7 step: 1696, loss is 0.01973962038755417\n",
      "epoch: 7 step: 1697, loss is 0.006807546131312847\n",
      "epoch: 7 step: 1698, loss is 0.00025439728051424026\n",
      "epoch: 7 step: 1699, loss is 0.004283077549189329\n",
      "epoch: 7 step: 1700, loss is 0.1104826107621193\n",
      "epoch: 7 step: 1701, loss is 0.0009504244662821293\n",
      "epoch: 7 step: 1702, loss is 0.007194769103080034\n",
      "epoch: 7 step: 1703, loss is 0.00023704330669716\n",
      "epoch: 7 step: 1704, loss is 0.004316490143537521\n",
      "epoch: 7 step: 1705, loss is 0.000524973263964057\n",
      "epoch: 7 step: 1706, loss is 0.0008521327399648726\n",
      "epoch: 7 step: 1707, loss is 0.0005350972060114145\n",
      "epoch: 7 step: 1708, loss is 0.010474137030541897\n",
      "epoch: 7 step: 1709, loss is 0.004418863449245691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1710, loss is 0.0005093252984806895\n",
      "epoch: 7 step: 1711, loss is 0.003957164473831654\n",
      "epoch: 7 step: 1712, loss is 0.0014202401507645845\n",
      "epoch: 7 step: 1713, loss is 0.00011012264440068975\n",
      "epoch: 7 step: 1714, loss is 0.004860961344093084\n",
      "epoch: 7 step: 1715, loss is 0.001971979858353734\n",
      "epoch: 7 step: 1716, loss is 0.00521398801356554\n",
      "epoch: 7 step: 1717, loss is 0.023325622081756592\n",
      "epoch: 7 step: 1718, loss is 0.028421834111213684\n",
      "epoch: 7 step: 1719, loss is 0.002202288480475545\n",
      "epoch: 7 step: 1720, loss is 0.00044288759818300605\n",
      "epoch: 7 step: 1721, loss is 0.0007941951625980437\n",
      "epoch: 7 step: 1722, loss is 0.017083412036299706\n",
      "epoch: 7 step: 1723, loss is 0.0048385863192379475\n",
      "epoch: 7 step: 1724, loss is 0.0021610644180327654\n",
      "epoch: 7 step: 1725, loss is 0.0021970432717353106\n",
      "epoch: 7 step: 1726, loss is 0.0017936872318387032\n",
      "epoch: 7 step: 1727, loss is 0.0010913170408457518\n",
      "epoch: 7 step: 1728, loss is 0.0036404491402208805\n",
      "epoch: 7 step: 1729, loss is 0.0020861520897597075\n",
      "epoch: 7 step: 1730, loss is 0.0003999743494205177\n",
      "epoch: 7 step: 1731, loss is 0.012805032543838024\n",
      "epoch: 7 step: 1732, loss is 0.0004972752067260444\n",
      "epoch: 7 step: 1733, loss is 0.03446449339389801\n",
      "epoch: 7 step: 1734, loss is 0.0009510362287983298\n",
      "epoch: 7 step: 1735, loss is 0.0006824126467108727\n",
      "epoch: 7 step: 1736, loss is 0.0007523271488025784\n",
      "epoch: 7 step: 1737, loss is 0.0003261773381382227\n",
      "epoch: 7 step: 1738, loss is 0.002347272355109453\n",
      "epoch: 7 step: 1739, loss is 0.0056906891986727715\n",
      "epoch: 7 step: 1740, loss is 0.0003328132152091712\n",
      "epoch: 7 step: 1741, loss is 0.003894300200045109\n",
      "epoch: 7 step: 1742, loss is 0.0014627747004851699\n",
      "epoch: 7 step: 1743, loss is 0.0010897991014644504\n",
      "epoch: 7 step: 1744, loss is 3.52782808477059e-05\n",
      "epoch: 7 step: 1745, loss is 0.02040037326514721\n",
      "epoch: 7 step: 1746, loss is 0.0014172402443364263\n",
      "epoch: 7 step: 1747, loss is 6.235965702217072e-05\n",
      "epoch: 7 step: 1748, loss is 0.013125024735927582\n",
      "epoch: 7 step: 1749, loss is 0.0734543576836586\n",
      "epoch: 7 step: 1750, loss is 0.012386423535645008\n",
      "epoch: 7 step: 1751, loss is 0.0001821615151129663\n",
      "epoch: 7 step: 1752, loss is 0.004882283508777618\n",
      "epoch: 7 step: 1753, loss is 0.0005082167917862535\n",
      "epoch: 7 step: 1754, loss is 3.046729034394957e-05\n",
      "epoch: 7 step: 1755, loss is 0.00414495961740613\n",
      "epoch: 7 step: 1756, loss is 0.000432262837421149\n",
      "epoch: 7 step: 1757, loss is 0.00018624993390403688\n",
      "epoch: 7 step: 1758, loss is 0.006070007104426622\n",
      "epoch: 7 step: 1759, loss is 0.0025119499769061804\n",
      "epoch: 7 step: 1760, loss is 0.0005649036611430347\n",
      "epoch: 7 step: 1761, loss is 0.0014333007857203484\n",
      "epoch: 7 step: 1762, loss is 0.0010319079738110304\n",
      "epoch: 7 step: 1763, loss is 0.00032758392626419663\n",
      "epoch: 7 step: 1764, loss is 0.056023139506578445\n",
      "epoch: 7 step: 1765, loss is 0.0030038452241569757\n",
      "epoch: 7 step: 1766, loss is 0.0003006101178470999\n",
      "epoch: 7 step: 1767, loss is 0.02032577060163021\n",
      "epoch: 7 step: 1768, loss is 0.00020725256763398647\n",
      "epoch: 7 step: 1769, loss is 0.0005213080439716578\n",
      "epoch: 7 step: 1770, loss is 2.8119855414843187e-05\n",
      "epoch: 7 step: 1771, loss is 0.04330803453922272\n",
      "epoch: 7 step: 1772, loss is 0.002223934745416045\n",
      "epoch: 7 step: 1773, loss is 0.00021526329510379583\n",
      "epoch: 7 step: 1774, loss is 0.013462083414196968\n",
      "epoch: 7 step: 1775, loss is 0.0021961061283946037\n",
      "epoch: 7 step: 1776, loss is 8.606407209299505e-05\n",
      "epoch: 7 step: 1777, loss is 0.00627535954117775\n",
      "epoch: 7 step: 1778, loss is 0.00029509543674066663\n",
      "epoch: 7 step: 1779, loss is 0.10445589572191238\n",
      "epoch: 7 step: 1780, loss is 0.0024399664252996445\n",
      "epoch: 7 step: 1781, loss is 0.00028038679738529027\n",
      "epoch: 7 step: 1782, loss is 0.0003328192688059062\n",
      "epoch: 7 step: 1783, loss is 0.00014406336413230747\n",
      "epoch: 7 step: 1784, loss is 0.0007470729178749025\n",
      "epoch: 7 step: 1785, loss is 0.00022442563204094768\n",
      "epoch: 7 step: 1786, loss is 0.0012385603040456772\n",
      "epoch: 7 step: 1787, loss is 0.0016874405555427074\n",
      "epoch: 7 step: 1788, loss is 0.0006227648700587451\n",
      "epoch: 7 step: 1789, loss is 0.0025523086078464985\n",
      "epoch: 7 step: 1790, loss is 0.00025325690512545407\n",
      "epoch: 7 step: 1791, loss is 0.1201511099934578\n",
      "epoch: 7 step: 1792, loss is 0.0016234214417636395\n",
      "epoch: 7 step: 1793, loss is 0.0007331840461120009\n",
      "epoch: 7 step: 1794, loss is 0.0024523574393242598\n",
      "epoch: 7 step: 1795, loss is 0.0015671788714826107\n",
      "epoch: 7 step: 1796, loss is 0.0077252136543393135\n",
      "epoch: 7 step: 1797, loss is 0.00046021907473914325\n",
      "epoch: 7 step: 1798, loss is 0.00045456993393599987\n",
      "epoch: 7 step: 1799, loss is 0.0015047489432618022\n",
      "epoch: 7 step: 1800, loss is 0.11833321303129196\n",
      "epoch: 7 step: 1801, loss is 0.00021751821623183787\n",
      "epoch: 7 step: 1802, loss is 0.0042349486611783504\n",
      "epoch: 7 step: 1803, loss is 0.0005917996168136597\n",
      "epoch: 7 step: 1804, loss is 0.0004138442745897919\n",
      "epoch: 7 step: 1805, loss is 0.14096437394618988\n",
      "epoch: 7 step: 1806, loss is 6.079759987187572e-05\n",
      "epoch: 7 step: 1807, loss is 0.006196347996592522\n",
      "epoch: 7 step: 1808, loss is 0.017789971083402634\n",
      "epoch: 7 step: 1809, loss is 2.5000565074151382e-05\n",
      "epoch: 7 step: 1810, loss is 0.00018977202125824988\n",
      "epoch: 7 step: 1811, loss is 0.00010031875717686489\n",
      "epoch: 7 step: 1812, loss is 0.008983314968645573\n",
      "epoch: 7 step: 1813, loss is 0.018421785905957222\n",
      "epoch: 7 step: 1814, loss is 0.012355650775134563\n",
      "epoch: 7 step: 1815, loss is 0.009314160794019699\n",
      "epoch: 7 step: 1816, loss is 0.0005877565708942711\n",
      "epoch: 7 step: 1817, loss is 0.0015866458415985107\n",
      "epoch: 7 step: 1818, loss is 0.1416761577129364\n",
      "epoch: 7 step: 1819, loss is 7.912932051112875e-05\n",
      "epoch: 7 step: 1820, loss is 0.0023491482716053724\n",
      "epoch: 7 step: 1821, loss is 0.008723007515072823\n",
      "epoch: 7 step: 1822, loss is 0.00011191683734068647\n",
      "epoch: 7 step: 1823, loss is 0.00022982252994552255\n",
      "epoch: 7 step: 1824, loss is 0.0017025466077029705\n",
      "epoch: 7 step: 1825, loss is 0.002848355332389474\n",
      "epoch: 7 step: 1826, loss is 0.03645472973585129\n",
      "epoch: 7 step: 1827, loss is 0.0009000244317576289\n",
      "epoch: 7 step: 1828, loss is 0.001208636211231351\n",
      "epoch: 7 step: 1829, loss is 0.004291201010346413\n",
      "epoch: 7 step: 1830, loss is 0.000483541312860325\n",
      "epoch: 7 step: 1831, loss is 0.01593557745218277\n",
      "epoch: 7 step: 1832, loss is 0.015871349722146988\n",
      "epoch: 7 step: 1833, loss is 0.003289448097348213\n",
      "epoch: 7 step: 1834, loss is 0.0021255342289805412\n",
      "epoch: 7 step: 1835, loss is 0.02181042544543743\n",
      "epoch: 7 step: 1836, loss is 0.006751555949449539\n",
      "epoch: 7 step: 1837, loss is 0.01364782266318798\n",
      "epoch: 7 step: 1838, loss is 0.00025559848290868104\n",
      "epoch: 7 step: 1839, loss is 0.005877980496734381\n",
      "epoch: 7 step: 1840, loss is 0.0027462830767035484\n",
      "epoch: 7 step: 1841, loss is 0.00013441282499115914\n",
      "epoch: 7 step: 1842, loss is 0.006185401696711779\n",
      "epoch: 7 step: 1843, loss is 0.060041215270757675\n",
      "epoch: 7 step: 1844, loss is 0.015448443591594696\n",
      "epoch: 7 step: 1845, loss is 0.02649141475558281\n",
      "epoch: 7 step: 1846, loss is 0.0003918258589692414\n",
      "epoch: 7 step: 1847, loss is 0.0029118978418409824\n",
      "epoch: 7 step: 1848, loss is 2.5064489818760194e-05\n",
      "epoch: 7 step: 1849, loss is 0.011068055406212807\n",
      "epoch: 7 step: 1850, loss is 0.00012231196160428226\n",
      "epoch: 7 step: 1851, loss is 0.0012415099190548062\n",
      "epoch: 7 step: 1852, loss is 0.009499551728367805\n",
      "epoch: 7 step: 1853, loss is 0.02043982408940792\n",
      "epoch: 7 step: 1854, loss is 3.0623948987340555e-05\n",
      "epoch: 7 step: 1855, loss is 0.005729518365114927\n",
      "epoch: 7 step: 1856, loss is 0.0005642942269332707\n",
      "epoch: 7 step: 1857, loss is 0.0004276264226064086\n",
      "epoch: 7 step: 1858, loss is 0.2580717206001282\n",
      "epoch: 7 step: 1859, loss is 0.017990177497267723\n",
      "epoch: 7 step: 1860, loss is 0.08254389464855194\n",
      "epoch: 7 step: 1861, loss is 0.0001825621584430337\n",
      "epoch: 7 step: 1862, loss is 0.00022806975175626576\n",
      "epoch: 7 step: 1863, loss is 0.0017922327388077974\n",
      "epoch: 7 step: 1864, loss is 0.00097512302454561\n",
      "epoch: 7 step: 1865, loss is 0.00021088693756610155\n",
      "epoch: 7 step: 1866, loss is 0.00043674130574800074\n",
      "epoch: 7 step: 1867, loss is 0.01691594161093235\n",
      "epoch: 7 step: 1868, loss is 2.2321615688269958e-05\n",
      "epoch: 7 step: 1869, loss is 0.032280292361974716\n",
      "epoch: 7 step: 1870, loss is 0.00010177049989579245\n",
      "epoch: 7 step: 1871, loss is 9.688970021670684e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1872, loss is 0.0016938778571784496\n",
      "epoch: 7 step: 1873, loss is 4.798404188477434e-05\n",
      "epoch: 7 step: 1874, loss is 0.03581617400050163\n",
      "epoch: 7 step: 1875, loss is 0.001019329996779561\n",
      "epoch: 7 step: 1876, loss is 0.0004970520967617631\n",
      "epoch: 7 step: 1877, loss is 3.6911827919539064e-05\n",
      "epoch: 7 step: 1878, loss is 2.308693183294963e-05\n",
      "epoch: 7 step: 1879, loss is 0.010048910044133663\n",
      "epoch: 7 step: 1880, loss is 0.00354521325789392\n",
      "epoch: 7 step: 1881, loss is 0.01763826608657837\n",
      "epoch: 7 step: 1882, loss is 0.02395791932940483\n",
      "epoch: 7 step: 1883, loss is 0.0012991048861294985\n",
      "epoch: 7 step: 1884, loss is 4.297003761166707e-05\n",
      "epoch: 7 step: 1885, loss is 0.0016390448436141014\n",
      "epoch: 7 step: 1886, loss is 0.0008385325782001019\n",
      "epoch: 7 step: 1887, loss is 0.182110995054245\n",
      "epoch: 7 step: 1888, loss is 0.001190954353660345\n",
      "epoch: 7 step: 1889, loss is 0.0003108664241153747\n",
      "epoch: 7 step: 1890, loss is 0.39563220739364624\n",
      "epoch: 7 step: 1891, loss is 0.0007702713483013213\n",
      "epoch: 7 step: 1892, loss is 0.04573327675461769\n",
      "epoch: 7 step: 1893, loss is 0.006271750200539827\n",
      "epoch: 7 step: 1894, loss is 0.0024103098548948765\n",
      "epoch: 7 step: 1895, loss is 0.00020746744121424854\n",
      "epoch: 7 step: 1896, loss is 0.002601850079372525\n",
      "epoch: 7 step: 1897, loss is 9.397174289915711e-05\n",
      "epoch: 7 step: 1898, loss is 0.000207558783586137\n",
      "epoch: 7 step: 1899, loss is 0.00011483646812848747\n",
      "epoch: 7 step: 1900, loss is 0.004438009113073349\n",
      "epoch: 7 step: 1901, loss is 0.008445847779512405\n",
      "epoch: 7 step: 1902, loss is 0.004573877900838852\n",
      "epoch: 7 step: 1903, loss is 0.001508014160208404\n",
      "epoch: 7 step: 1904, loss is 0.025645192712545395\n",
      "epoch: 7 step: 1905, loss is 0.007617298047989607\n",
      "epoch: 7 step: 1906, loss is 0.00034325552405789495\n",
      "epoch: 7 step: 1907, loss is 0.0012153774732723832\n",
      "epoch: 7 step: 1908, loss is 0.01149927731603384\n",
      "epoch: 7 step: 1909, loss is 0.00548679381608963\n",
      "epoch: 7 step: 1910, loss is 0.03756483271718025\n",
      "epoch: 7 step: 1911, loss is 0.005709350109100342\n",
      "epoch: 7 step: 1912, loss is 0.001848924090154469\n",
      "epoch: 7 step: 1913, loss is 0.018431449308991432\n",
      "epoch: 7 step: 1914, loss is 0.001400364562869072\n",
      "epoch: 7 step: 1915, loss is 0.0044357613660395145\n",
      "epoch: 7 step: 1916, loss is 0.0004612369230017066\n",
      "epoch: 7 step: 1917, loss is 0.010491067543625832\n",
      "epoch: 7 step: 1918, loss is 0.0051675899885594845\n",
      "epoch: 7 step: 1919, loss is 0.004074550233781338\n",
      "epoch: 7 step: 1920, loss is 9.08517322386615e-05\n",
      "epoch: 7 step: 1921, loss is 0.0024920948781073093\n",
      "epoch: 7 step: 1922, loss is 0.0005424996488727629\n",
      "epoch: 7 step: 1923, loss is 0.001242027967236936\n",
      "epoch: 7 step: 1924, loss is 0.0011655298294499516\n",
      "epoch: 7 step: 1925, loss is 0.000762500858400017\n",
      "epoch: 7 step: 1926, loss is 0.10010198503732681\n",
      "epoch: 7 step: 1927, loss is 0.0013232717756181955\n",
      "epoch: 7 step: 1928, loss is 0.05038345977663994\n",
      "epoch: 7 step: 1929, loss is 0.04648957401514053\n",
      "epoch: 7 step: 1930, loss is 0.0020016885828226805\n",
      "epoch: 7 step: 1931, loss is 0.00040364975575357676\n",
      "epoch: 7 step: 1932, loss is 0.0013501648791134357\n",
      "epoch: 7 step: 1933, loss is 0.010527808219194412\n",
      "epoch: 7 step: 1934, loss is 0.026785502210259438\n",
      "epoch: 7 step: 1935, loss is 0.004974015057086945\n",
      "epoch: 7 step: 1936, loss is 0.0021418852265924215\n",
      "epoch: 7 step: 1937, loss is 0.002592657692730427\n",
      "epoch: 7 step: 1938, loss is 0.048558592796325684\n",
      "epoch: 7 step: 1939, loss is 0.0003275031631346792\n",
      "epoch: 7 step: 1940, loss is 0.0009178122272714972\n",
      "epoch: 7 step: 1941, loss is 0.014814196154475212\n",
      "epoch: 7 step: 1942, loss is 0.00048031326150521636\n",
      "epoch: 7 step: 1943, loss is 0.002629708731546998\n",
      "epoch: 7 step: 1944, loss is 1.780384627636522e-05\n",
      "epoch: 7 step: 1945, loss is 0.004700886085629463\n",
      "epoch: 7 step: 1946, loss is 0.0005242816987447441\n",
      "epoch: 7 step: 1947, loss is 0.0002479232207406312\n",
      "epoch: 7 step: 1948, loss is 0.0185925904661417\n",
      "epoch: 7 step: 1949, loss is 0.00435082521289587\n",
      "epoch: 7 step: 1950, loss is 0.0007663053111173213\n",
      "epoch: 7 step: 1951, loss is 0.0018985854694619775\n",
      "epoch: 7 step: 1952, loss is 0.05851159244775772\n",
      "epoch: 7 step: 1953, loss is 0.023273173719644547\n",
      "epoch: 7 step: 1954, loss is 0.0027916859835386276\n",
      "epoch: 7 step: 1955, loss is 0.001867176964879036\n",
      "epoch: 7 step: 1956, loss is 4.22839802922681e-05\n",
      "epoch: 7 step: 1957, loss is 0.016521070152521133\n",
      "epoch: 7 step: 1958, loss is 0.0913357138633728\n",
      "epoch: 7 step: 1959, loss is 0.0013555972836911678\n",
      "epoch: 7 step: 1960, loss is 0.0008159816497936845\n",
      "epoch: 7 step: 1961, loss is 0.004191228654235601\n",
      "epoch: 7 step: 1962, loss is 0.001746675930917263\n",
      "epoch: 7 step: 1963, loss is 0.0008935552905313671\n",
      "epoch: 7 step: 1964, loss is 0.008945254608988762\n",
      "epoch: 7 step: 1965, loss is 0.0020118714310228825\n",
      "epoch: 7 step: 1966, loss is 7.805541099514812e-05\n",
      "epoch: 7 step: 1967, loss is 0.00016825401689857244\n",
      "epoch: 7 step: 1968, loss is 5.549565321416594e-05\n",
      "epoch: 7 step: 1969, loss is 0.01947411149740219\n",
      "epoch: 7 step: 1970, loss is 0.0004466524987947196\n",
      "epoch: 7 step: 1971, loss is 4.268759221304208e-05\n",
      "epoch: 7 step: 1972, loss is 0.018021371215581894\n",
      "epoch: 7 step: 1973, loss is 0.018459849059581757\n",
      "epoch: 7 step: 1974, loss is 0.00020090634643565863\n",
      "epoch: 7 step: 1975, loss is 0.021395225077867508\n",
      "epoch: 7 step: 1976, loss is 0.020456979051232338\n",
      "epoch: 7 step: 1977, loss is 0.0006315879290923476\n",
      "epoch: 7 step: 1978, loss is 0.0015041586011648178\n",
      "epoch: 7 step: 1979, loss is 0.0019262266578152776\n",
      "epoch: 7 step: 1980, loss is 0.00036755827022716403\n",
      "epoch: 7 step: 1981, loss is 0.18844562768936157\n",
      "epoch: 7 step: 1982, loss is 7.52808409743011e-05\n",
      "epoch: 7 step: 1983, loss is 0.0036754922475665808\n",
      "epoch: 7 step: 1984, loss is 0.09512930363416672\n",
      "epoch: 7 step: 1985, loss is 0.0006060062441974878\n",
      "epoch: 7 step: 1986, loss is 0.0021377000957727432\n",
      "epoch: 7 step: 1987, loss is 0.00040686127613298595\n",
      "epoch: 7 step: 1988, loss is 0.011225259862840176\n",
      "epoch: 7 step: 1989, loss is 0.005586169194430113\n",
      "epoch: 7 step: 1990, loss is 0.009001387283205986\n",
      "epoch: 7 step: 1991, loss is 0.00399680994451046\n",
      "epoch: 7 step: 1992, loss is 0.0016879779286682606\n",
      "epoch: 7 step: 1993, loss is 0.00037330083432607353\n",
      "epoch: 7 step: 1994, loss is 0.00011509622709127143\n",
      "epoch: 7 step: 1995, loss is 0.023639384657144547\n",
      "epoch: 7 step: 1996, loss is 0.012304658070206642\n",
      "epoch: 7 step: 1997, loss is 0.017692426219582558\n",
      "epoch: 7 step: 1998, loss is 0.012837323360145092\n",
      "epoch: 7 step: 1999, loss is 0.00698841130360961\n",
      "epoch: 7 step: 2000, loss is 0.0004189386672805995\n",
      "epoch: 7 step: 2001, loss is 0.031525589525699615\n",
      "epoch: 7 step: 2002, loss is 0.00021470419596880674\n",
      "epoch: 7 step: 2003, loss is 0.21316753327846527\n",
      "epoch: 7 step: 2004, loss is 4.225322118145414e-05\n",
      "epoch: 7 step: 2005, loss is 0.018686791881918907\n",
      "epoch: 7 step: 2006, loss is 5.447103103506379e-05\n",
      "epoch: 7 step: 2007, loss is 0.0003155743470415473\n",
      "epoch: 7 step: 2008, loss is 0.10705781728029251\n",
      "epoch: 7 step: 2009, loss is 0.01689169742166996\n",
      "epoch: 7 step: 2010, loss is 0.009855780750513077\n",
      "epoch: 7 step: 2011, loss is 0.0023026985581964254\n",
      "epoch: 7 step: 2012, loss is 0.003443747293204069\n",
      "epoch: 7 step: 2013, loss is 0.005846276879310608\n",
      "epoch: 7 step: 2014, loss is 0.03409695252776146\n",
      "epoch: 7 step: 2015, loss is 0.00017709123494569212\n",
      "epoch: 7 step: 2016, loss is 0.0030210192780941725\n",
      "epoch: 7 step: 2017, loss is 0.0015947395004332066\n",
      "epoch: 7 step: 2018, loss is 0.17559969425201416\n",
      "epoch: 7 step: 2019, loss is 0.0007945711258798838\n",
      "epoch: 7 step: 2020, loss is 0.006240886636078358\n",
      "epoch: 7 step: 2021, loss is 0.11921229213476181\n",
      "epoch: 7 step: 2022, loss is 0.0055463737808167934\n",
      "epoch: 7 step: 2023, loss is 0.0021113643888384104\n",
      "epoch: 7 step: 2024, loss is 0.028013847768306732\n",
      "epoch: 7 step: 2025, loss is 0.0025232492480427027\n",
      "epoch: 7 step: 2026, loss is 0.08689925819635391\n",
      "epoch: 7 step: 2027, loss is 0.015437315218150616\n",
      "epoch: 7 step: 2028, loss is 0.12184491753578186\n",
      "epoch: 7 step: 2029, loss is 6.297760410234332e-05\n",
      "epoch: 7 step: 2030, loss is 0.0026609962806105614\n",
      "epoch: 7 step: 2031, loss is 0.0328657329082489\n",
      "epoch: 7 step: 2032, loss is 0.0008048369199968874\n",
      "epoch: 7 step: 2033, loss is 0.002445167861878872\n",
      "epoch: 7 step: 2034, loss is 0.0002450858009979129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 2035, loss is 0.012901515699923038\n",
      "epoch: 7 step: 2036, loss is 0.0002672494447324425\n",
      "epoch: 7 step: 2037, loss is 0.0021290697623044252\n",
      "epoch: 7 step: 2038, loss is 0.00075946981087327\n",
      "epoch: 7 step: 2039, loss is 0.00025927770184352994\n",
      "epoch: 7 step: 2040, loss is 0.02068304270505905\n",
      "epoch: 7 step: 2041, loss is 0.002428986830636859\n",
      "epoch: 7 step: 2042, loss is 0.04129410535097122\n",
      "epoch: 7 step: 2043, loss is 0.07272515445947647\n",
      "epoch: 7 step: 2044, loss is 0.0012307176366448402\n",
      "epoch: 7 step: 2045, loss is 0.07639680802822113\n",
      "epoch: 7 step: 2046, loss is 0.015406632795929909\n",
      "epoch: 7 step: 2047, loss is 0.008662747219204903\n",
      "epoch: 7 step: 2048, loss is 0.1978999227285385\n",
      "epoch: 7 step: 2049, loss is 1.8922884919447824e-05\n",
      "epoch: 7 step: 2050, loss is 0.00039726911927573383\n",
      "epoch: 7 step: 2051, loss is 0.011465783230960369\n",
      "epoch: 7 step: 2052, loss is 0.16254450380802155\n",
      "epoch: 7 step: 2053, loss is 0.00031998424674384296\n",
      "epoch: 7 step: 2054, loss is 0.0072998059913516045\n",
      "epoch: 7 step: 2055, loss is 0.0034765952732414007\n",
      "epoch: 7 step: 2056, loss is 0.0003335562360007316\n",
      "epoch: 7 step: 2057, loss is 0.0757802426815033\n",
      "epoch: 7 step: 2058, loss is 0.03620779141783714\n",
      "epoch: 7 step: 2059, loss is 0.09554282575845718\n",
      "epoch: 7 step: 2060, loss is 0.020209267735481262\n",
      "epoch: 7 step: 2061, loss is 0.004100572317838669\n",
      "epoch: 7 step: 2062, loss is 0.005824722349643707\n",
      "epoch: 7 step: 2063, loss is 0.0006746255676262081\n",
      "epoch: 7 step: 2064, loss is 0.057468343526124954\n",
      "epoch: 7 step: 2065, loss is 0.0064450534991919994\n",
      "epoch: 7 step: 2066, loss is 0.20220668613910675\n",
      "epoch: 7 step: 2067, loss is 0.009795344434678555\n",
      "epoch: 7 step: 2068, loss is 0.004566472489386797\n",
      "epoch: 7 step: 2069, loss is 0.011594824492931366\n",
      "epoch: 7 step: 2070, loss is 0.0013457415625452995\n",
      "epoch: 7 step: 2071, loss is 0.00019093659648206085\n",
      "epoch: 7 step: 2072, loss is 0.006667735520750284\n",
      "epoch: 7 step: 2073, loss is 0.059663325548172\n",
      "epoch: 7 step: 2074, loss is 0.0012804417638108134\n",
      "epoch: 7 step: 2075, loss is 0.0024990784004330635\n",
      "epoch: 7 step: 2076, loss is 0.12199283391237259\n",
      "epoch: 7 step: 2077, loss is 0.00027637853054329753\n",
      "epoch: 7 step: 2078, loss is 0.00015317140787374228\n",
      "epoch: 7 step: 2079, loss is 0.044519104063510895\n",
      "epoch: 7 step: 2080, loss is 0.0021345424465835094\n",
      "epoch: 7 step: 2081, loss is 0.0001828497479436919\n",
      "epoch: 7 step: 2082, loss is 0.0005120810237713158\n",
      "epoch: 7 step: 2083, loss is 0.010518432594835758\n",
      "epoch: 7 step: 2084, loss is 0.06355786323547363\n",
      "epoch: 7 step: 2085, loss is 0.008428497239947319\n",
      "epoch: 7 step: 2086, loss is 0.002857001032680273\n",
      "epoch: 7 step: 2087, loss is 0.0319732166826725\n",
      "epoch: 7 step: 2088, loss is 0.005792082287371159\n",
      "epoch: 7 step: 2089, loss is 0.0055331699550151825\n",
      "epoch: 7 step: 2090, loss is 0.002806101692840457\n",
      "epoch: 7 step: 2091, loss is 0.0003741716791409999\n",
      "epoch: 7 step: 2092, loss is 0.000879161583725363\n",
      "epoch: 7 step: 2093, loss is 0.008374227210879326\n",
      "epoch: 7 step: 2094, loss is 0.021875297650694847\n",
      "epoch: 7 step: 2095, loss is 0.0006648391135968268\n",
      "epoch: 7 step: 2096, loss is 0.0005812727613374591\n",
      "epoch: 7 step: 2097, loss is 0.0007001403137110174\n",
      "epoch: 7 step: 2098, loss is 0.0006339677493087947\n",
      "epoch: 7 step: 2099, loss is 0.04367342218756676\n",
      "epoch: 7 step: 2100, loss is 0.12263477593660355\n",
      "epoch: 7 step: 2101, loss is 0.009924011304974556\n",
      "epoch: 7 step: 2102, loss is 0.02011161297559738\n",
      "epoch: 7 step: 2103, loss is 0.004088624846190214\n",
      "epoch: 7 step: 2104, loss is 0.0011617899872362614\n",
      "epoch: 7 step: 2105, loss is 0.0005169599899090827\n",
      "epoch: 7 step: 2106, loss is 0.00044388597598299384\n",
      "epoch: 7 step: 2107, loss is 0.01826116256415844\n",
      "epoch: 7 step: 2108, loss is 0.001191282644867897\n",
      "epoch: 7 step: 2109, loss is 0.009959484450519085\n",
      "epoch: 7 step: 2110, loss is 0.0026858460623770952\n",
      "epoch: 7 step: 2111, loss is 0.07011290639638901\n",
      "epoch: 7 step: 2112, loss is 0.0004565572598949075\n",
      "epoch: 7 step: 2113, loss is 0.039846789091825485\n",
      "epoch: 7 step: 2114, loss is 0.0003529353707563132\n",
      "epoch: 7 step: 2115, loss is 0.04818381369113922\n",
      "epoch: 7 step: 2116, loss is 0.00022347160847857594\n",
      "epoch: 7 step: 2117, loss is 0.0011421097442507744\n",
      "epoch: 7 step: 2118, loss is 0.13404375314712524\n",
      "epoch: 7 step: 2119, loss is 0.005890669301152229\n",
      "epoch: 7 step: 2120, loss is 0.0029097103979438543\n",
      "epoch: 7 step: 2121, loss is 0.030846549198031425\n",
      "epoch: 7 step: 2122, loss is 0.07423032075166702\n",
      "epoch: 7 step: 2123, loss is 0.0005663990159519017\n",
      "epoch: 7 step: 2124, loss is 0.0004612055199686438\n",
      "epoch: 7 step: 2125, loss is 0.021113229915499687\n",
      "epoch: 7 step: 2126, loss is 0.001509571447968483\n",
      "epoch: 7 step: 2127, loss is 0.050279419869184494\n",
      "epoch: 7 step: 2128, loss is 0.00014247922808863223\n",
      "epoch: 7 step: 2129, loss is 0.05269382894039154\n",
      "epoch: 7 step: 2130, loss is 0.01560763269662857\n",
      "epoch: 7 step: 2131, loss is 0.0026491116732358932\n",
      "epoch: 7 step: 2132, loss is 0.0006750788306817412\n",
      "epoch: 7 step: 2133, loss is 0.03591843321919441\n",
      "epoch: 7 step: 2134, loss is 0.0027899490669369698\n",
      "epoch: 7 step: 2135, loss is 0.0006245276308618486\n",
      "epoch: 7 step: 2136, loss is 0.03434492275118828\n",
      "epoch: 7 step: 2137, loss is 0.00010231626947643235\n",
      "epoch: 7 step: 2138, loss is 0.028481949120759964\n",
      "epoch: 7 step: 2139, loss is 0.026322904974222183\n",
      "epoch: 7 step: 2140, loss is 0.0009376846137456596\n",
      "epoch: 7 step: 2141, loss is 0.00031524852965958416\n",
      "epoch: 7 step: 2142, loss is 0.003992858808487654\n",
      "epoch: 7 step: 2143, loss is 0.030472643673419952\n",
      "epoch: 7 step: 2144, loss is 0.050466544926166534\n",
      "epoch: 7 step: 2145, loss is 0.009070944972336292\n",
      "epoch: 7 step: 2146, loss is 0.021606124937534332\n",
      "epoch: 7 step: 2147, loss is 0.016318516805768013\n",
      "epoch: 7 step: 2148, loss is 0.0018518490251153708\n",
      "epoch: 7 step: 2149, loss is 0.00027114106342196465\n",
      "epoch: 7 step: 2150, loss is 0.021611472591757774\n",
      "epoch: 7 step: 2151, loss is 0.011170072481036186\n",
      "epoch: 7 step: 2152, loss is 0.013076992705464363\n",
      "epoch: 7 step: 2153, loss is 0.0006068825023248792\n",
      "epoch: 7 step: 2154, loss is 0.002130708657205105\n",
      "epoch: 7 step: 2155, loss is 0.053232233971357346\n",
      "epoch: 7 step: 2156, loss is 0.007441436871886253\n",
      "epoch: 7 step: 2157, loss is 0.02756483294069767\n",
      "epoch: 7 step: 2158, loss is 0.00023621729633305222\n",
      "epoch: 7 step: 2159, loss is 0.00018258702766615897\n",
      "epoch: 7 step: 2160, loss is 0.024856699630618095\n",
      "epoch: 7 step: 2161, loss is 0.022100046277046204\n",
      "epoch: 7 step: 2162, loss is 0.0010495840106159449\n",
      "epoch: 7 step: 2163, loss is 0.0003116305742878467\n",
      "epoch: 7 step: 2164, loss is 0.007307830732315779\n",
      "epoch: 7 step: 2165, loss is 0.00013999328075442463\n",
      "epoch: 7 step: 2166, loss is 0.001441202242858708\n",
      "epoch: 7 step: 2167, loss is 0.0002879382227547467\n",
      "epoch: 7 step: 2168, loss is 0.0004845813673455268\n",
      "epoch: 7 step: 2169, loss is 0.01544257439672947\n",
      "epoch: 7 step: 2170, loss is 0.013758405111730099\n",
      "epoch: 7 step: 2171, loss is 0.0006585884257219732\n",
      "epoch: 7 step: 2172, loss is 0.0001045486715156585\n",
      "epoch: 7 step: 2173, loss is 0.055643901228904724\n",
      "epoch: 7 step: 2174, loss is 0.0033695371821522713\n",
      "epoch: 7 step: 2175, loss is 0.00835702195763588\n",
      "epoch: 7 step: 2176, loss is 0.009684528224170208\n",
      "epoch: 7 step: 2177, loss is 0.00661767041310668\n",
      "epoch: 7 step: 2178, loss is 0.00015316222561523318\n",
      "epoch: 7 step: 2179, loss is 0.02281052991747856\n",
      "epoch: 7 step: 2180, loss is 0.0023966790176928043\n",
      "epoch: 7 step: 2181, loss is 0.0002823580871336162\n",
      "epoch: 7 step: 2182, loss is 1.8776519937091507e-05\n",
      "epoch: 7 step: 2183, loss is 0.00012336739746388048\n",
      "epoch: 7 step: 2184, loss is 0.0016032306011766195\n",
      "epoch: 7 step: 2185, loss is 9.332923946203664e-05\n",
      "epoch: 7 step: 2186, loss is 0.00045246066292747855\n",
      "epoch: 7 step: 2187, loss is 0.0837985947728157\n",
      "epoch: 8 step: 1, loss is 0.0076949717476964\n",
      "epoch: 8 step: 2, loss is 2.6791101845446974e-05\n",
      "epoch: 8 step: 3, loss is 0.0005168640054762363\n",
      "epoch: 8 step: 4, loss is 0.003908261191099882\n",
      "epoch: 8 step: 5, loss is 2.6731871912488714e-05\n",
      "epoch: 8 step: 6, loss is 0.0008482700795866549\n",
      "epoch: 8 step: 7, loss is 0.021071113646030426\n",
      "epoch: 8 step: 8, loss is 0.00013034188305027783\n",
      "epoch: 8 step: 9, loss is 0.028122004121541977\n",
      "epoch: 8 step: 10, loss is 0.0001828727254178375\n",
      "epoch: 8 step: 11, loss is 0.024935992434620857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 12, loss is 0.0001371465768897906\n",
      "epoch: 8 step: 13, loss is 0.0010047953110188246\n",
      "epoch: 8 step: 14, loss is 0.02876090444624424\n",
      "epoch: 8 step: 15, loss is 0.002320040948688984\n",
      "epoch: 8 step: 16, loss is 0.005722964648157358\n",
      "epoch: 8 step: 17, loss is 5.7289689721073955e-05\n",
      "epoch: 8 step: 18, loss is 0.006279833614826202\n",
      "epoch: 8 step: 19, loss is 0.005174627993255854\n",
      "epoch: 8 step: 20, loss is 0.009367181919515133\n",
      "epoch: 8 step: 21, loss is 0.05346628278493881\n",
      "epoch: 8 step: 22, loss is 0.0019790991209447384\n",
      "epoch: 8 step: 23, loss is 0.00010707984620239586\n",
      "epoch: 8 step: 24, loss is 0.0006306756404228508\n",
      "epoch: 8 step: 25, loss is 0.00017068586021196097\n",
      "epoch: 8 step: 26, loss is 0.020218610763549805\n",
      "epoch: 8 step: 27, loss is 0.00015722925309091806\n",
      "epoch: 8 step: 28, loss is 0.0012491918168962002\n",
      "epoch: 8 step: 29, loss is 2.1308828763721976e-06\n",
      "epoch: 8 step: 30, loss is 0.00025616056518629193\n",
      "epoch: 8 step: 31, loss is 0.0007712559308856726\n",
      "epoch: 8 step: 32, loss is 0.00019365786283742636\n",
      "epoch: 8 step: 33, loss is 2.0757577658514492e-05\n",
      "epoch: 8 step: 34, loss is 0.019718481227755547\n",
      "epoch: 8 step: 35, loss is 0.08105321228504181\n",
      "epoch: 8 step: 36, loss is 0.0017083226703107357\n",
      "epoch: 8 step: 37, loss is 0.0005101269343867898\n",
      "epoch: 8 step: 38, loss is 0.002719095442444086\n",
      "epoch: 8 step: 39, loss is 0.0011791785946115851\n",
      "epoch: 8 step: 40, loss is 0.008954734541475773\n",
      "epoch: 8 step: 41, loss is 8.012937905732542e-05\n",
      "epoch: 8 step: 42, loss is 0.0006762371631339192\n",
      "epoch: 8 step: 43, loss is 0.0011098879622295499\n",
      "epoch: 8 step: 44, loss is 0.004275359679013491\n",
      "epoch: 8 step: 45, loss is 0.0008564044255763292\n",
      "epoch: 8 step: 46, loss is 0.004773022141307592\n",
      "epoch: 8 step: 47, loss is 0.03394988924264908\n",
      "epoch: 8 step: 48, loss is 0.0002652078401297331\n",
      "epoch: 8 step: 49, loss is 0.06096760928630829\n",
      "epoch: 8 step: 50, loss is 0.013661769218742847\n",
      "epoch: 8 step: 51, loss is 0.00036508694756776094\n",
      "epoch: 8 step: 52, loss is 0.002840090775862336\n",
      "epoch: 8 step: 53, loss is 0.003032013075426221\n",
      "epoch: 8 step: 54, loss is 3.0079179850872606e-05\n",
      "epoch: 8 step: 55, loss is 9.468187636230141e-05\n",
      "epoch: 8 step: 56, loss is 0.0004073016461916268\n",
      "epoch: 8 step: 57, loss is 0.00010809526429511607\n",
      "epoch: 8 step: 58, loss is 0.00019971057190559804\n",
      "epoch: 8 step: 59, loss is 0.0029996889643371105\n",
      "epoch: 8 step: 60, loss is 0.0051518636755645275\n",
      "epoch: 8 step: 61, loss is 4.563386391964741e-05\n",
      "epoch: 8 step: 62, loss is 0.025354640558362007\n",
      "epoch: 8 step: 63, loss is 3.573431968106888e-05\n",
      "epoch: 8 step: 64, loss is 0.005641825497150421\n",
      "epoch: 8 step: 65, loss is 9.793567005544901e-05\n",
      "epoch: 8 step: 66, loss is 0.022945461794734\n",
      "epoch: 8 step: 67, loss is 0.00010937949264189228\n",
      "epoch: 8 step: 68, loss is 9.935606612998527e-06\n",
      "epoch: 8 step: 69, loss is 0.001145214308053255\n",
      "epoch: 8 step: 70, loss is 0.003937235102057457\n",
      "epoch: 8 step: 71, loss is 0.000949766137637198\n",
      "epoch: 8 step: 72, loss is 4.605283902492374e-05\n",
      "epoch: 8 step: 73, loss is 0.0005958951078355312\n",
      "epoch: 8 step: 74, loss is 0.0008451443281956017\n",
      "epoch: 8 step: 75, loss is 0.0008110528578981757\n",
      "epoch: 8 step: 76, loss is 0.0036945794709026814\n",
      "epoch: 8 step: 77, loss is 0.016492292284965515\n",
      "epoch: 8 step: 78, loss is 0.11659719794988632\n",
      "epoch: 8 step: 79, loss is 0.0011194577673450112\n",
      "epoch: 8 step: 80, loss is 0.01053980365395546\n",
      "epoch: 8 step: 81, loss is 0.01126931607723236\n",
      "epoch: 8 step: 82, loss is 0.00011163498857058585\n",
      "epoch: 8 step: 83, loss is 2.692373345780652e-05\n",
      "epoch: 8 step: 84, loss is 0.0016979784704744816\n",
      "epoch: 8 step: 85, loss is 0.0009288883884437382\n",
      "epoch: 8 step: 86, loss is 6.0623468016274273e-05\n",
      "epoch: 8 step: 87, loss is 0.0005890639149583876\n",
      "epoch: 8 step: 88, loss is 6.344478606479242e-05\n",
      "epoch: 8 step: 89, loss is 5.189434432395501e-06\n",
      "epoch: 8 step: 90, loss is 0.0001604659773875028\n",
      "epoch: 8 step: 91, loss is 0.0002562195004429668\n",
      "epoch: 8 step: 92, loss is 0.00026868563145399094\n",
      "epoch: 8 step: 93, loss is 0.001011691871099174\n",
      "epoch: 8 step: 94, loss is 0.013210768811404705\n",
      "epoch: 8 step: 95, loss is 1.8775563148665242e-06\n",
      "epoch: 8 step: 96, loss is 0.005935869179666042\n",
      "epoch: 8 step: 97, loss is 0.011046642437577248\n",
      "epoch: 8 step: 98, loss is 4.4035219616489485e-05\n",
      "epoch: 8 step: 99, loss is 0.011979704722762108\n",
      "epoch: 8 step: 100, loss is 0.06094435974955559\n",
      "epoch: 8 step: 101, loss is 0.009040569886565208\n",
      "epoch: 8 step: 102, loss is 1.796319156710524e-05\n",
      "epoch: 8 step: 103, loss is 0.0014028942678123713\n",
      "epoch: 8 step: 104, loss is 6.072087853681296e-05\n",
      "epoch: 8 step: 105, loss is 0.07054997235536575\n",
      "epoch: 8 step: 106, loss is 7.302279846044257e-05\n",
      "epoch: 8 step: 107, loss is 0.0012350288452580571\n",
      "epoch: 8 step: 108, loss is 0.00018158432794734836\n",
      "epoch: 8 step: 109, loss is 0.0002169611252611503\n",
      "epoch: 8 step: 110, loss is 3.744445712072775e-05\n",
      "epoch: 8 step: 111, loss is 0.00015286565758287907\n",
      "epoch: 8 step: 112, loss is 6.354093784466386e-05\n",
      "epoch: 8 step: 113, loss is 0.0002914567885454744\n",
      "epoch: 8 step: 114, loss is 0.00010359232692280784\n",
      "epoch: 8 step: 115, loss is 0.0016636847285553813\n",
      "epoch: 8 step: 116, loss is 3.452185046626255e-05\n",
      "epoch: 8 step: 117, loss is 0.005539403762668371\n",
      "epoch: 8 step: 118, loss is 0.0001371811085846275\n",
      "epoch: 8 step: 119, loss is 0.00037649014848284423\n",
      "epoch: 8 step: 120, loss is 0.0042371591553092\n",
      "epoch: 8 step: 121, loss is 0.0002751873398665339\n",
      "epoch: 8 step: 122, loss is 0.001408223295584321\n",
      "epoch: 8 step: 123, loss is 0.00015050219371914864\n",
      "epoch: 8 step: 124, loss is 0.00025561987422406673\n",
      "epoch: 8 step: 125, loss is 0.011648748070001602\n",
      "epoch: 8 step: 126, loss is 0.016911327838897705\n",
      "epoch: 8 step: 127, loss is 5.222881736699492e-05\n",
      "epoch: 8 step: 128, loss is 0.000561429827939719\n",
      "epoch: 8 step: 129, loss is 1.9416485883994028e-05\n",
      "epoch: 8 step: 130, loss is 0.03379380330443382\n",
      "epoch: 8 step: 131, loss is 0.0002930906193796545\n",
      "epoch: 8 step: 132, loss is 0.0038828253746032715\n",
      "epoch: 8 step: 133, loss is 0.05330473929643631\n",
      "epoch: 8 step: 134, loss is 9.651171421865001e-05\n",
      "epoch: 8 step: 135, loss is 0.0001872729480965063\n",
      "epoch: 8 step: 136, loss is 3.980158726335503e-05\n",
      "epoch: 8 step: 137, loss is 0.0006326822913251817\n",
      "epoch: 8 step: 138, loss is 0.21173085272312164\n",
      "epoch: 8 step: 139, loss is 0.0003029312938451767\n",
      "epoch: 8 step: 140, loss is 0.00012645682727452368\n",
      "epoch: 8 step: 141, loss is 0.007930180989205837\n",
      "epoch: 8 step: 142, loss is 0.00039657665183767676\n",
      "epoch: 8 step: 143, loss is 0.010324639268219471\n",
      "epoch: 8 step: 144, loss is 0.00041558523662388325\n",
      "epoch: 8 step: 145, loss is 0.016890833154320717\n",
      "epoch: 8 step: 146, loss is 0.0008495998336002231\n",
      "epoch: 8 step: 147, loss is 0.0009617783944122493\n",
      "epoch: 8 step: 148, loss is 0.013517419807612896\n",
      "epoch: 8 step: 149, loss is 0.08307517319917679\n",
      "epoch: 8 step: 150, loss is 2.8323327569523826e-05\n",
      "epoch: 8 step: 151, loss is 0.004692299757152796\n",
      "epoch: 8 step: 152, loss is 0.0003229288849979639\n",
      "epoch: 8 step: 153, loss is 0.011917500756680965\n",
      "epoch: 8 step: 154, loss is 6.795248282287503e-06\n",
      "epoch: 8 step: 155, loss is 0.0003894642577506602\n",
      "epoch: 8 step: 156, loss is 0.0009252580348402262\n",
      "epoch: 8 step: 157, loss is 0.006062799133360386\n",
      "epoch: 8 step: 158, loss is 0.00012664965470321476\n",
      "epoch: 8 step: 159, loss is 0.004128582775592804\n",
      "epoch: 8 step: 160, loss is 0.0015823689755052328\n",
      "epoch: 8 step: 161, loss is 0.02179093286395073\n",
      "epoch: 8 step: 162, loss is 8.010522287804633e-05\n",
      "epoch: 8 step: 163, loss is 5.517301906365901e-05\n",
      "epoch: 8 step: 164, loss is 0.004987701307982206\n",
      "epoch: 8 step: 165, loss is 0.0004417582240421325\n",
      "epoch: 8 step: 166, loss is 0.0007224708097055554\n",
      "epoch: 8 step: 167, loss is 0.001397808431647718\n",
      "epoch: 8 step: 168, loss is 0.0019169907318428159\n",
      "epoch: 8 step: 169, loss is 0.04999062046408653\n",
      "epoch: 8 step: 170, loss is 0.007687553763389587\n",
      "epoch: 8 step: 171, loss is 0.007629069034010172\n",
      "epoch: 8 step: 172, loss is 0.00018344484851695597\n",
      "epoch: 8 step: 173, loss is 0.006160417106002569\n",
      "epoch: 8 step: 174, loss is 5.688633336831117e-06\n",
      "epoch: 8 step: 175, loss is 0.02404831349849701\n",
      "epoch: 8 step: 176, loss is 0.036807239055633545\n",
      "epoch: 8 step: 177, loss is 0.018277768045663834\n",
      "epoch: 8 step: 178, loss is 0.0005982432048767805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 179, loss is 0.012042728252708912\n",
      "epoch: 8 step: 180, loss is 0.07190565764904022\n",
      "epoch: 8 step: 181, loss is 0.0001455613091820851\n",
      "epoch: 8 step: 182, loss is 0.016950545832514763\n",
      "epoch: 8 step: 183, loss is 0.0011866462882608175\n",
      "epoch: 8 step: 184, loss is 0.00035925774136558175\n",
      "epoch: 8 step: 185, loss is 0.0006114958086982369\n",
      "epoch: 8 step: 186, loss is 0.0001165478170150891\n",
      "epoch: 8 step: 187, loss is 0.013876081444323063\n",
      "epoch: 8 step: 188, loss is 4.682350481743924e-05\n",
      "epoch: 8 step: 189, loss is 0.001845056191086769\n",
      "epoch: 8 step: 190, loss is 1.6924728697631508e-05\n",
      "epoch: 8 step: 191, loss is 4.559867193165701e-06\n",
      "epoch: 8 step: 192, loss is 0.0002326728863408789\n",
      "epoch: 8 step: 193, loss is 0.017323996871709824\n",
      "epoch: 8 step: 194, loss is 0.0008282954804599285\n",
      "epoch: 8 step: 195, loss is 0.004245185758918524\n",
      "epoch: 8 step: 196, loss is 0.019497526809573174\n",
      "epoch: 8 step: 197, loss is 0.0005423796828836203\n",
      "epoch: 8 step: 198, loss is 0.04837127402424812\n",
      "epoch: 8 step: 199, loss is 0.0002231418911833316\n",
      "epoch: 8 step: 200, loss is 0.09813956171274185\n",
      "epoch: 8 step: 201, loss is 0.012273017317056656\n",
      "epoch: 8 step: 202, loss is 0.012774721719324589\n",
      "epoch: 8 step: 203, loss is 0.0002476225490681827\n",
      "epoch: 8 step: 204, loss is 3.1961422791937366e-05\n",
      "epoch: 8 step: 205, loss is 0.00866179820150137\n",
      "epoch: 8 step: 206, loss is 9.58174769039033e-06\n",
      "epoch: 8 step: 207, loss is 0.00028288931935094297\n",
      "epoch: 8 step: 208, loss is 0.0006884623435325921\n",
      "epoch: 8 step: 209, loss is 0.19284440577030182\n",
      "epoch: 8 step: 210, loss is 0.000180925359018147\n",
      "epoch: 8 step: 211, loss is 0.005084537900984287\n",
      "epoch: 8 step: 212, loss is 0.0002318855986231938\n",
      "epoch: 8 step: 213, loss is 0.029320012778043747\n",
      "epoch: 8 step: 214, loss is 0.00038248623604886234\n",
      "epoch: 8 step: 215, loss is 0.024601414799690247\n",
      "epoch: 8 step: 216, loss is 7.604462734889239e-05\n",
      "epoch: 8 step: 217, loss is 0.0011139592388644814\n",
      "epoch: 8 step: 218, loss is 0.00018597849702928215\n",
      "epoch: 8 step: 219, loss is 0.0012843518052250147\n",
      "epoch: 8 step: 220, loss is 0.004270749632269144\n",
      "epoch: 8 step: 221, loss is 0.0014204723993316293\n",
      "epoch: 8 step: 222, loss is 0.005716617219150066\n",
      "epoch: 8 step: 223, loss is 0.004759431350976229\n",
      "epoch: 8 step: 224, loss is 0.02352495677769184\n",
      "epoch: 8 step: 225, loss is 0.005338264629244804\n",
      "epoch: 8 step: 226, loss is 0.00613202853128314\n",
      "epoch: 8 step: 227, loss is 0.060380324721336365\n",
      "epoch: 8 step: 228, loss is 4.7382342017954215e-05\n",
      "epoch: 8 step: 229, loss is 0.08476759493350983\n",
      "epoch: 8 step: 230, loss is 0.00016160258383024484\n",
      "epoch: 8 step: 231, loss is 0.001580186653882265\n",
      "epoch: 8 step: 232, loss is 0.00015142644406296313\n",
      "epoch: 8 step: 233, loss is 7.871663547120988e-05\n",
      "epoch: 8 step: 234, loss is 0.00016353355022147298\n",
      "epoch: 8 step: 235, loss is 0.045751187950372696\n",
      "epoch: 8 step: 236, loss is 3.1195271731121466e-05\n",
      "epoch: 8 step: 237, loss is 0.051486432552337646\n",
      "epoch: 8 step: 238, loss is 7.27370788808912e-05\n",
      "epoch: 8 step: 239, loss is 0.01605384610593319\n",
      "epoch: 8 step: 240, loss is 0.04505221173167229\n",
      "epoch: 8 step: 241, loss is 0.05297354608774185\n",
      "epoch: 8 step: 242, loss is 0.0005825217231176794\n",
      "epoch: 8 step: 243, loss is 0.013105749152600765\n",
      "epoch: 8 step: 244, loss is 0.008780759759247303\n",
      "epoch: 8 step: 245, loss is 0.05378282442688942\n",
      "epoch: 8 step: 246, loss is 0.05448131263256073\n",
      "epoch: 8 step: 247, loss is 0.01576370559632778\n",
      "epoch: 8 step: 248, loss is 0.005363017320632935\n",
      "epoch: 8 step: 249, loss is 0.05562850087881088\n",
      "epoch: 8 step: 250, loss is 0.2633780539035797\n",
      "epoch: 8 step: 251, loss is 0.005338470451533794\n",
      "epoch: 8 step: 252, loss is 3.162569191772491e-05\n",
      "epoch: 8 step: 253, loss is 0.00015819011605344713\n",
      "epoch: 8 step: 254, loss is 7.503556116716936e-05\n",
      "epoch: 8 step: 255, loss is 0.04100172966718674\n",
      "epoch: 8 step: 256, loss is 0.00048210201202891767\n",
      "epoch: 8 step: 257, loss is 0.0028455825522542\n",
      "epoch: 8 step: 258, loss is 0.002989522647112608\n",
      "epoch: 8 step: 259, loss is 0.0009229961433447897\n",
      "epoch: 8 step: 260, loss is 0.004238520283252001\n",
      "epoch: 8 step: 261, loss is 0.0029683876782655716\n",
      "epoch: 8 step: 262, loss is 0.0007556005730293691\n",
      "epoch: 8 step: 263, loss is 0.017981503158807755\n",
      "epoch: 8 step: 264, loss is 0.0008025796851143241\n",
      "epoch: 8 step: 265, loss is 0.24824629724025726\n",
      "epoch: 8 step: 266, loss is 0.01250173058360815\n",
      "epoch: 8 step: 267, loss is 0.10525228828191757\n",
      "epoch: 8 step: 268, loss is 0.00031977042090147734\n",
      "epoch: 8 step: 269, loss is 0.09371540695428848\n",
      "epoch: 8 step: 270, loss is 0.00047641590936109424\n",
      "epoch: 8 step: 271, loss is 0.0017679068259894848\n",
      "epoch: 8 step: 272, loss is 0.04157128930091858\n",
      "epoch: 8 step: 273, loss is 0.0004457338072825223\n",
      "epoch: 8 step: 274, loss is 0.004670658614486456\n",
      "epoch: 8 step: 275, loss is 2.098662116623018e-05\n",
      "epoch: 8 step: 276, loss is 0.0021121781319379807\n",
      "epoch: 8 step: 277, loss is 0.006367173045873642\n",
      "epoch: 8 step: 278, loss is 9.840173152042553e-05\n",
      "epoch: 8 step: 279, loss is 5.409917503129691e-05\n",
      "epoch: 8 step: 280, loss is 0.01208585686981678\n",
      "epoch: 8 step: 281, loss is 0.005430988501757383\n",
      "epoch: 8 step: 282, loss is 0.0011781906941905618\n",
      "epoch: 8 step: 283, loss is 0.025447430089116096\n",
      "epoch: 8 step: 284, loss is 0.1976223737001419\n",
      "epoch: 8 step: 285, loss is 0.004918936640024185\n",
      "epoch: 8 step: 286, loss is 0.021612845361232758\n",
      "epoch: 8 step: 287, loss is 0.030455362051725388\n",
      "epoch: 8 step: 288, loss is 0.0009703713585622609\n",
      "epoch: 8 step: 289, loss is 0.0004195943765807897\n",
      "epoch: 8 step: 290, loss is 0.004270739853382111\n",
      "epoch: 8 step: 291, loss is 0.003955080173909664\n",
      "epoch: 8 step: 292, loss is 0.012741475366055965\n",
      "epoch: 8 step: 293, loss is 0.0018241660436615348\n",
      "epoch: 8 step: 294, loss is 0.029391853138804436\n",
      "epoch: 8 step: 295, loss is 0.1503816694021225\n",
      "epoch: 8 step: 296, loss is 0.25237396359443665\n",
      "epoch: 8 step: 297, loss is 0.0002859695232473314\n",
      "epoch: 8 step: 298, loss is 0.035860829055309296\n",
      "epoch: 8 step: 299, loss is 0.00021657974866684526\n",
      "epoch: 8 step: 300, loss is 7.879435725044459e-05\n",
      "epoch: 8 step: 301, loss is 0.0034564926754683256\n",
      "epoch: 8 step: 302, loss is 0.001028259634040296\n",
      "epoch: 8 step: 303, loss is 0.0012206658720970154\n",
      "epoch: 8 step: 304, loss is 0.0026555408257991076\n",
      "epoch: 8 step: 305, loss is 0.0029442221857607365\n",
      "epoch: 8 step: 306, loss is 0.0005317936302162707\n",
      "epoch: 8 step: 307, loss is 0.01416862290352583\n",
      "epoch: 8 step: 308, loss is 0.0018135493155568838\n",
      "epoch: 8 step: 309, loss is 0.0005321369972079992\n",
      "epoch: 8 step: 310, loss is 6.194578600116074e-05\n",
      "epoch: 8 step: 311, loss is 0.0002450068132020533\n",
      "epoch: 8 step: 312, loss is 0.0009417898254469037\n",
      "epoch: 8 step: 313, loss is 0.0006007188349030912\n",
      "epoch: 8 step: 314, loss is 0.0005112863145768642\n",
      "epoch: 8 step: 315, loss is 0.016269110143184662\n",
      "epoch: 8 step: 316, loss is 0.011078202165663242\n",
      "epoch: 8 step: 317, loss is 0.009407063946127892\n",
      "epoch: 8 step: 318, loss is 3.727995135704987e-05\n",
      "epoch: 8 step: 319, loss is 0.00025788339553400874\n",
      "epoch: 8 step: 320, loss is 0.019118227064609528\n",
      "epoch: 8 step: 321, loss is 0.0010950318537652493\n",
      "epoch: 8 step: 322, loss is 0.0033188790548592806\n",
      "epoch: 8 step: 323, loss is 0.0009693271713331342\n",
      "epoch: 8 step: 324, loss is 0.00015545917267445475\n",
      "epoch: 8 step: 325, loss is 0.0002763373777270317\n",
      "epoch: 8 step: 326, loss is 0.0003032602835446596\n",
      "epoch: 8 step: 327, loss is 0.021909356117248535\n",
      "epoch: 8 step: 328, loss is 0.0004077971098013222\n",
      "epoch: 8 step: 329, loss is 0.07388591766357422\n",
      "epoch: 8 step: 330, loss is 0.14494584500789642\n",
      "epoch: 8 step: 331, loss is 0.06505731493234634\n",
      "epoch: 8 step: 332, loss is 0.0009150387486442924\n",
      "epoch: 8 step: 333, loss is 0.09417083859443665\n",
      "epoch: 8 step: 334, loss is 0.003798208897933364\n",
      "epoch: 8 step: 335, loss is 0.0003470462979748845\n",
      "epoch: 8 step: 336, loss is 0.007050801534205675\n",
      "epoch: 8 step: 337, loss is 0.0037071839906275272\n",
      "epoch: 8 step: 338, loss is 0.02662978507578373\n",
      "epoch: 8 step: 339, loss is 0.0003304911369923502\n",
      "epoch: 8 step: 340, loss is 0.02027421072125435\n",
      "epoch: 8 step: 341, loss is 0.10909555852413177\n",
      "epoch: 8 step: 342, loss is 0.002678020391613245\n",
      "epoch: 8 step: 343, loss is 0.11216381937265396\n",
      "epoch: 8 step: 344, loss is 0.039249520748853683\n",
      "epoch: 8 step: 345, loss is 0.009051022119820118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 346, loss is 0.00208841310814023\n",
      "epoch: 8 step: 347, loss is 0.00477009080350399\n",
      "epoch: 8 step: 348, loss is 0.013991196639835835\n",
      "epoch: 8 step: 349, loss is 0.033563148230314255\n",
      "epoch: 8 step: 350, loss is 0.001123593421652913\n",
      "epoch: 8 step: 351, loss is 0.035084281116724014\n",
      "epoch: 8 step: 352, loss is 0.005486416630446911\n",
      "epoch: 8 step: 353, loss is 0.001277091447263956\n",
      "epoch: 8 step: 354, loss is 0.013429406099021435\n",
      "epoch: 8 step: 355, loss is 0.001955961575731635\n",
      "epoch: 8 step: 356, loss is 0.0001275614049518481\n",
      "epoch: 8 step: 357, loss is 0.0008343156659975648\n",
      "epoch: 8 step: 358, loss is 0.0017383990343660116\n",
      "epoch: 8 step: 359, loss is 0.08796258270740509\n",
      "epoch: 8 step: 360, loss is 0.11816376447677612\n",
      "epoch: 8 step: 361, loss is 0.003354695625603199\n",
      "epoch: 8 step: 362, loss is 0.01100388914346695\n",
      "epoch: 8 step: 363, loss is 7.56855879444629e-05\n",
      "epoch: 8 step: 364, loss is 0.0003593758156057447\n",
      "epoch: 8 step: 365, loss is 0.00015322522085625678\n",
      "epoch: 8 step: 366, loss is 0.00019583091489039361\n",
      "epoch: 8 step: 367, loss is 0.002531426725909114\n",
      "epoch: 8 step: 368, loss is 0.00010880903573706746\n",
      "epoch: 8 step: 369, loss is 0.021485352888703346\n",
      "epoch: 8 step: 370, loss is 0.009169208817183971\n",
      "epoch: 8 step: 371, loss is 0.03553974628448486\n",
      "epoch: 8 step: 372, loss is 0.0008370227878913283\n",
      "epoch: 8 step: 373, loss is 0.0014468120643869042\n",
      "epoch: 8 step: 374, loss is 0.008655398152768612\n",
      "epoch: 8 step: 375, loss is 6.755950016668066e-05\n",
      "epoch: 8 step: 376, loss is 0.009682412259280682\n",
      "epoch: 8 step: 377, loss is 0.059852343052625656\n",
      "epoch: 8 step: 378, loss is 0.00015683758829254657\n",
      "epoch: 8 step: 379, loss is 0.00016966258408501744\n",
      "epoch: 8 step: 380, loss is 0.0011478252708911896\n",
      "epoch: 8 step: 381, loss is 0.02702086605131626\n",
      "epoch: 8 step: 382, loss is 0.0002771978033706546\n",
      "epoch: 8 step: 383, loss is 0.0005114175146445632\n",
      "epoch: 8 step: 384, loss is 0.0006916309939697385\n",
      "epoch: 8 step: 385, loss is 0.05662676319479942\n",
      "epoch: 8 step: 386, loss is 5.164116373634897e-05\n",
      "epoch: 8 step: 387, loss is 0.01194625161588192\n",
      "epoch: 8 step: 388, loss is 0.14262710511684418\n",
      "epoch: 8 step: 389, loss is 0.03525066748261452\n",
      "epoch: 8 step: 390, loss is 0.00046269671292975545\n",
      "epoch: 8 step: 391, loss is 0.030198493972420692\n",
      "epoch: 8 step: 392, loss is 0.0012251856969669461\n",
      "epoch: 8 step: 393, loss is 0.030425235629081726\n",
      "epoch: 8 step: 394, loss is 0.00011834972974611446\n",
      "epoch: 8 step: 395, loss is 0.005009343847632408\n",
      "epoch: 8 step: 396, loss is 0.014727624133229256\n",
      "epoch: 8 step: 397, loss is 0.02834472432732582\n",
      "epoch: 8 step: 398, loss is 0.027836235240101814\n",
      "epoch: 8 step: 399, loss is 0.15690283477306366\n",
      "epoch: 8 step: 400, loss is 0.07577826827764511\n",
      "epoch: 8 step: 401, loss is 0.00025887993979267776\n",
      "epoch: 8 step: 402, loss is 0.00035108375595882535\n",
      "epoch: 8 step: 403, loss is 0.02284816838800907\n",
      "epoch: 8 step: 404, loss is 0.011576890014111996\n",
      "epoch: 8 step: 405, loss is 2.616273741296027e-05\n",
      "epoch: 8 step: 406, loss is 0.007403598167002201\n",
      "epoch: 8 step: 407, loss is 0.021836886182427406\n",
      "epoch: 8 step: 408, loss is 0.0052217342890799046\n",
      "epoch: 8 step: 409, loss is 0.000134432761115022\n",
      "epoch: 8 step: 410, loss is 0.0037308454047888517\n",
      "epoch: 8 step: 411, loss is 0.021793071180582047\n",
      "epoch: 8 step: 412, loss is 0.0026809212286025286\n",
      "epoch: 8 step: 413, loss is 6.161737110232934e-05\n",
      "epoch: 8 step: 414, loss is 0.017783857882022858\n",
      "epoch: 8 step: 415, loss is 0.02004983276128769\n",
      "epoch: 8 step: 416, loss is 0.003943985793739557\n",
      "epoch: 8 step: 417, loss is 8.877717482391745e-05\n",
      "epoch: 8 step: 418, loss is 0.022429607808589935\n",
      "epoch: 8 step: 419, loss is 0.0010394526179879904\n",
      "epoch: 8 step: 420, loss is 0.008979428559541702\n",
      "epoch: 8 step: 421, loss is 6.604212831007317e-05\n",
      "epoch: 8 step: 422, loss is 0.00022965186508372426\n",
      "epoch: 8 step: 423, loss is 0.00010805394413182512\n",
      "epoch: 8 step: 424, loss is 5.6982818932738155e-05\n",
      "epoch: 8 step: 425, loss is 0.0006575601873919368\n",
      "epoch: 8 step: 426, loss is 0.003106570802628994\n",
      "epoch: 8 step: 427, loss is 0.004842482972890139\n",
      "epoch: 8 step: 428, loss is 0.06148814409971237\n",
      "epoch: 8 step: 429, loss is 0.0009645906393416226\n",
      "epoch: 8 step: 430, loss is 0.0022162969689816236\n",
      "epoch: 8 step: 431, loss is 0.00034516630694270134\n",
      "epoch: 8 step: 432, loss is 0.0015203794464468956\n",
      "epoch: 8 step: 433, loss is 0.000907809124328196\n",
      "epoch: 8 step: 434, loss is 0.0001443181827198714\n",
      "epoch: 8 step: 435, loss is 0.004630551673471928\n",
      "epoch: 8 step: 436, loss is 0.0013102205703034997\n",
      "epoch: 8 step: 437, loss is 0.011102847754955292\n",
      "epoch: 8 step: 438, loss is 0.00014579507114831358\n",
      "epoch: 8 step: 439, loss is 0.0018693391466513276\n",
      "epoch: 8 step: 440, loss is 0.00457752263173461\n",
      "epoch: 8 step: 441, loss is 0.0013452998828142881\n",
      "epoch: 8 step: 442, loss is 0.024555476382374763\n",
      "epoch: 8 step: 443, loss is 0.06557755172252655\n",
      "epoch: 8 step: 444, loss is 0.001861400785855949\n",
      "epoch: 8 step: 445, loss is 0.002079422352835536\n",
      "epoch: 8 step: 446, loss is 0.0005756539758294821\n",
      "epoch: 8 step: 447, loss is 0.012950802221894264\n",
      "epoch: 8 step: 448, loss is 0.08404766768217087\n",
      "epoch: 8 step: 449, loss is 0.0007450111443176866\n",
      "epoch: 8 step: 450, loss is 0.029421266168355942\n",
      "epoch: 8 step: 451, loss is 4.6396631660172716e-05\n",
      "epoch: 8 step: 452, loss is 0.0930863693356514\n",
      "epoch: 8 step: 453, loss is 0.11476139724254608\n",
      "epoch: 8 step: 454, loss is 0.0007217660895548761\n",
      "epoch: 8 step: 455, loss is 0.00786906760185957\n",
      "epoch: 8 step: 456, loss is 0.006787961348891258\n",
      "epoch: 8 step: 457, loss is 2.465645047777798e-05\n",
      "epoch: 8 step: 458, loss is 1.488059206167236e-05\n",
      "epoch: 8 step: 459, loss is 0.0011182668386027217\n",
      "epoch: 8 step: 460, loss is 0.0008832509047351778\n",
      "epoch: 8 step: 461, loss is 0.0011815974721685052\n",
      "epoch: 8 step: 462, loss is 0.0026843238156288862\n",
      "epoch: 8 step: 463, loss is 0.0005930338520556688\n",
      "epoch: 8 step: 464, loss is 0.21225722134113312\n",
      "epoch: 8 step: 465, loss is 0.0029985939618200064\n",
      "epoch: 8 step: 466, loss is 0.002672862960025668\n",
      "epoch: 8 step: 467, loss is 0.0007866331725381315\n",
      "epoch: 8 step: 468, loss is 0.0023421174846589565\n",
      "epoch: 8 step: 469, loss is 0.022112756967544556\n",
      "epoch: 8 step: 470, loss is 0.024072807282209396\n",
      "epoch: 8 step: 471, loss is 0.12602336704730988\n",
      "epoch: 8 step: 472, loss is 0.04171755909919739\n",
      "epoch: 8 step: 473, loss is 0.0007493466255255044\n",
      "epoch: 8 step: 474, loss is 0.0008115482050925493\n",
      "epoch: 8 step: 475, loss is 0.00844328198581934\n",
      "epoch: 8 step: 476, loss is 0.0015659448690712452\n",
      "epoch: 8 step: 477, loss is 0.0009947593789547682\n",
      "epoch: 8 step: 478, loss is 0.007673508487641811\n",
      "epoch: 8 step: 479, loss is 0.00019865257490891963\n",
      "epoch: 8 step: 480, loss is 5.3375184506876394e-05\n",
      "epoch: 8 step: 481, loss is 0.00019833154510706663\n",
      "epoch: 8 step: 482, loss is 5.693347338819876e-05\n",
      "epoch: 8 step: 483, loss is 0.00543988449499011\n",
      "epoch: 8 step: 484, loss is 0.0001307093189097941\n",
      "epoch: 8 step: 485, loss is 0.0001933482853928581\n",
      "epoch: 8 step: 486, loss is 5.9142948884982616e-05\n",
      "epoch: 8 step: 487, loss is 0.0008071959600783885\n",
      "epoch: 8 step: 488, loss is 0.003569347085431218\n",
      "epoch: 8 step: 489, loss is 0.0004521263763308525\n",
      "epoch: 8 step: 490, loss is 0.032300688326358795\n",
      "epoch: 8 step: 491, loss is 0.0010002631461247802\n",
      "epoch: 8 step: 492, loss is 0.0006683104438707232\n",
      "epoch: 8 step: 493, loss is 0.14609433710575104\n",
      "epoch: 8 step: 494, loss is 0.0005851569003425539\n",
      "epoch: 8 step: 495, loss is 0.00013876601587980986\n",
      "epoch: 8 step: 496, loss is 0.00019616282952483743\n",
      "epoch: 8 step: 497, loss is 0.0007131180609576404\n",
      "epoch: 8 step: 498, loss is 0.00030692879226990044\n",
      "epoch: 8 step: 499, loss is 0.00023591105127707124\n",
      "epoch: 8 step: 500, loss is 0.0005937052774243057\n",
      "epoch: 8 step: 501, loss is 0.00036807404831051826\n",
      "epoch: 8 step: 502, loss is 0.0006060950108803809\n",
      "epoch: 8 step: 503, loss is 0.0015002931468188763\n",
      "epoch: 8 step: 504, loss is 0.028742708265781403\n",
      "epoch: 8 step: 505, loss is 0.025674041360616684\n",
      "epoch: 8 step: 506, loss is 3.417955304030329e-05\n",
      "epoch: 8 step: 507, loss is 0.0001273204543394968\n",
      "epoch: 8 step: 508, loss is 0.0028018420562148094\n",
      "epoch: 8 step: 509, loss is 0.00044387613888829947\n",
      "epoch: 8 step: 510, loss is 0.004199428018182516\n",
      "epoch: 8 step: 511, loss is 0.008784917183220387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 512, loss is 0.0005416267085820436\n",
      "epoch: 8 step: 513, loss is 0.00011538239778019488\n",
      "epoch: 8 step: 514, loss is 0.0004455014131963253\n",
      "epoch: 8 step: 515, loss is 0.0014924181159585714\n",
      "epoch: 8 step: 516, loss is 0.0007510001305490732\n",
      "epoch: 8 step: 517, loss is 0.0004983717808499932\n",
      "epoch: 8 step: 518, loss is 0.0005985167226754129\n",
      "epoch: 8 step: 519, loss is 0.0004652909410651773\n",
      "epoch: 8 step: 520, loss is 0.05327967181801796\n",
      "epoch: 8 step: 521, loss is 0.00022714851365890354\n",
      "epoch: 8 step: 522, loss is 0.17949610948562622\n",
      "epoch: 8 step: 523, loss is 0.00018114937120117247\n",
      "epoch: 8 step: 524, loss is 0.001790044130757451\n",
      "epoch: 8 step: 525, loss is 0.0003654437605291605\n",
      "epoch: 8 step: 526, loss is 0.004895065911114216\n",
      "epoch: 8 step: 527, loss is 0.0005781542859040201\n",
      "epoch: 8 step: 528, loss is 0.16183921694755554\n",
      "epoch: 8 step: 529, loss is 3.647348057711497e-05\n",
      "epoch: 8 step: 530, loss is 0.0007418525055982172\n",
      "epoch: 8 step: 531, loss is 0.0018482134910300374\n",
      "epoch: 8 step: 532, loss is 0.0005152184749022126\n",
      "epoch: 8 step: 533, loss is 0.006970476359128952\n",
      "epoch: 8 step: 534, loss is 0.00562044233083725\n",
      "epoch: 8 step: 535, loss is 0.008090421557426453\n",
      "epoch: 8 step: 536, loss is 0.0018259527860209346\n",
      "epoch: 8 step: 537, loss is 6.169560219859704e-05\n",
      "epoch: 8 step: 538, loss is 0.018867310136556625\n",
      "epoch: 8 step: 539, loss is 0.0011622103629633784\n",
      "epoch: 8 step: 540, loss is 0.0016938978806138039\n",
      "epoch: 8 step: 541, loss is 1.4657070096291136e-05\n",
      "epoch: 8 step: 542, loss is 0.0013068608241155744\n",
      "epoch: 8 step: 543, loss is 0.0015110421227291226\n",
      "epoch: 8 step: 544, loss is 1.7949307220987976e-05\n",
      "epoch: 8 step: 545, loss is 0.0013723064912483096\n",
      "epoch: 8 step: 546, loss is 0.14501895010471344\n",
      "epoch: 8 step: 547, loss is 0.008901138789951801\n",
      "epoch: 8 step: 548, loss is 0.0002781258663162589\n",
      "epoch: 8 step: 549, loss is 0.033127374947071075\n",
      "epoch: 8 step: 550, loss is 6.176235910970718e-05\n",
      "epoch: 8 step: 551, loss is 0.03955064341425896\n",
      "epoch: 8 step: 552, loss is 0.002226885175332427\n",
      "epoch: 8 step: 553, loss is 0.009273137897253036\n",
      "epoch: 8 step: 554, loss is 0.0006946967332623899\n",
      "epoch: 8 step: 555, loss is 0.0012588804820552468\n",
      "epoch: 8 step: 556, loss is 9.407941251993179e-05\n",
      "epoch: 8 step: 557, loss is 0.0016706936294212937\n",
      "epoch: 8 step: 558, loss is 0.0026880810037255287\n",
      "epoch: 8 step: 559, loss is 0.004399364348500967\n",
      "epoch: 8 step: 560, loss is 0.0004782517207786441\n",
      "epoch: 8 step: 561, loss is 0.0002319952182006091\n",
      "epoch: 8 step: 562, loss is 0.00029138123500160873\n",
      "epoch: 8 step: 563, loss is 0.024235382676124573\n",
      "epoch: 8 step: 564, loss is 0.00031259108800441027\n",
      "epoch: 8 step: 565, loss is 0.004718022886663675\n",
      "epoch: 8 step: 566, loss is 0.002227683551609516\n",
      "epoch: 8 step: 567, loss is 0.00013839629536960274\n",
      "epoch: 8 step: 568, loss is 0.00022816011914983392\n",
      "epoch: 8 step: 569, loss is 4.106776032131165e-05\n",
      "epoch: 8 step: 570, loss is 0.045239586383104324\n",
      "epoch: 8 step: 571, loss is 0.08577967435121536\n",
      "epoch: 8 step: 572, loss is 0.0011866475688293576\n",
      "epoch: 8 step: 573, loss is 7.118179928511381e-05\n",
      "epoch: 8 step: 574, loss is 3.2548534363741055e-05\n",
      "epoch: 8 step: 575, loss is 0.0012776731746271253\n",
      "epoch: 8 step: 576, loss is 0.0014113264624029398\n",
      "epoch: 8 step: 577, loss is 0.044823385775089264\n",
      "epoch: 8 step: 578, loss is 0.0029956207145005465\n",
      "epoch: 8 step: 579, loss is 0.011592474766075611\n",
      "epoch: 8 step: 580, loss is 0.002939879894256592\n",
      "epoch: 8 step: 581, loss is 0.00301212421618402\n",
      "epoch: 8 step: 582, loss is 2.0151363059994765e-05\n",
      "epoch: 8 step: 583, loss is 0.029612287878990173\n",
      "epoch: 8 step: 584, loss is 1.484606764279306e-05\n",
      "epoch: 8 step: 585, loss is 0.0006342869601212442\n",
      "epoch: 8 step: 586, loss is 0.06446195393800735\n",
      "epoch: 8 step: 587, loss is 2.342079642403405e-05\n",
      "epoch: 8 step: 588, loss is 0.0003447425551712513\n",
      "epoch: 8 step: 589, loss is 0.0021681920625269413\n",
      "epoch: 8 step: 590, loss is 0.04483605921268463\n",
      "epoch: 8 step: 591, loss is 0.00042057837708853185\n",
      "epoch: 8 step: 592, loss is 0.001277825445868075\n",
      "epoch: 8 step: 593, loss is 0.0003234910545870662\n",
      "epoch: 8 step: 594, loss is 0.01582050509750843\n",
      "epoch: 8 step: 595, loss is 0.006543116644024849\n",
      "epoch: 8 step: 596, loss is 0.012126710265874863\n",
      "epoch: 8 step: 597, loss is 2.570226206444204e-05\n",
      "epoch: 8 step: 598, loss is 0.008605992421507835\n",
      "epoch: 8 step: 599, loss is 0.08069824427366257\n",
      "epoch: 8 step: 600, loss is 0.000351336580934003\n",
      "epoch: 8 step: 601, loss is 0.00022269213513936847\n",
      "epoch: 8 step: 602, loss is 0.10414065420627594\n",
      "epoch: 8 step: 603, loss is 0.004205226898193359\n",
      "epoch: 8 step: 604, loss is 0.05042032524943352\n",
      "epoch: 8 step: 605, loss is 0.00010917239706031978\n",
      "epoch: 8 step: 606, loss is 0.0004055216850247234\n",
      "epoch: 8 step: 607, loss is 0.0038024834357202053\n",
      "epoch: 8 step: 608, loss is 0.0007549304282292724\n",
      "epoch: 8 step: 609, loss is 0.005479110404849052\n",
      "epoch: 8 step: 610, loss is 0.002441135933622718\n",
      "epoch: 8 step: 611, loss is 0.00010405842476757243\n",
      "epoch: 8 step: 612, loss is 1.2178187716926914e-05\n",
      "epoch: 8 step: 613, loss is 0.0024558398872613907\n",
      "epoch: 8 step: 614, loss is 0.002333234064280987\n",
      "epoch: 8 step: 615, loss is 0.007114325184375048\n",
      "epoch: 8 step: 616, loss is 0.003911025356501341\n",
      "epoch: 8 step: 617, loss is 0.028954608365893364\n",
      "epoch: 8 step: 618, loss is 0.011929584667086601\n",
      "epoch: 8 step: 619, loss is 0.0035426083486527205\n",
      "epoch: 8 step: 620, loss is 0.004603397101163864\n",
      "epoch: 8 step: 621, loss is 0.0282034520059824\n",
      "epoch: 8 step: 622, loss is 0.00020390914869494736\n",
      "epoch: 8 step: 623, loss is 0.00011148305929964408\n",
      "epoch: 8 step: 624, loss is 0.0013493600999936461\n",
      "epoch: 8 step: 625, loss is 0.0018014069646596909\n",
      "epoch: 8 step: 626, loss is 5.374311513151042e-05\n",
      "epoch: 8 step: 627, loss is 3.4488395613152534e-05\n",
      "epoch: 8 step: 628, loss is 0.0002629940863698721\n",
      "epoch: 8 step: 629, loss is 0.0021769495215266943\n",
      "epoch: 8 step: 630, loss is 0.0021343636326491833\n",
      "epoch: 8 step: 631, loss is 0.003314570290967822\n",
      "epoch: 8 step: 632, loss is 0.00509754940867424\n",
      "epoch: 8 step: 633, loss is 0.00028237735386937857\n",
      "epoch: 8 step: 634, loss is 0.0032107001170516014\n",
      "epoch: 8 step: 635, loss is 0.00010010013647843152\n",
      "epoch: 8 step: 636, loss is 0.0013263407163321972\n",
      "epoch: 8 step: 637, loss is 0.029015500098466873\n",
      "epoch: 8 step: 638, loss is 0.0006079670856706798\n",
      "epoch: 8 step: 639, loss is 0.0001837881573010236\n",
      "epoch: 8 step: 640, loss is 0.0064750243909657\n",
      "epoch: 8 step: 641, loss is 0.0003265506820753217\n",
      "epoch: 8 step: 642, loss is 0.0006369954789988697\n",
      "epoch: 8 step: 643, loss is 0.05775807052850723\n",
      "epoch: 8 step: 644, loss is 0.000483921030536294\n",
      "epoch: 8 step: 645, loss is 2.557018888182938e-05\n",
      "epoch: 8 step: 646, loss is 0.01133598480373621\n",
      "epoch: 8 step: 647, loss is 0.02999134175479412\n",
      "epoch: 8 step: 648, loss is 0.225240096449852\n",
      "epoch: 8 step: 649, loss is 0.0027164118364453316\n",
      "epoch: 8 step: 650, loss is 0.00870048813521862\n",
      "epoch: 8 step: 651, loss is 0.0012778474483639002\n",
      "epoch: 8 step: 652, loss is 0.008310445584356785\n",
      "epoch: 8 step: 653, loss is 0.024873897433280945\n",
      "epoch: 8 step: 654, loss is 0.03563948720693588\n",
      "epoch: 8 step: 655, loss is 0.02443542890250683\n",
      "epoch: 8 step: 656, loss is 0.01993316225707531\n",
      "epoch: 8 step: 657, loss is 0.007954392582178116\n",
      "epoch: 8 step: 658, loss is 0.0011098869144916534\n",
      "epoch: 8 step: 659, loss is 0.0012320487294346094\n",
      "epoch: 8 step: 660, loss is 0.04524281620979309\n",
      "epoch: 8 step: 661, loss is 0.1108514815568924\n",
      "epoch: 8 step: 662, loss is 0.0015444016316905618\n",
      "epoch: 8 step: 663, loss is 0.06452395766973495\n",
      "epoch: 8 step: 664, loss is 0.002857300452888012\n",
      "epoch: 8 step: 665, loss is 0.0059523629024624825\n",
      "epoch: 8 step: 666, loss is 0.017344282940030098\n",
      "epoch: 8 step: 667, loss is 0.000277823448413983\n",
      "epoch: 8 step: 668, loss is 0.03460998088121414\n",
      "epoch: 8 step: 669, loss is 0.004557638429105282\n",
      "epoch: 8 step: 670, loss is 0.13709399104118347\n",
      "epoch: 8 step: 671, loss is 0.00028817515703849494\n",
      "epoch: 8 step: 672, loss is 0.00930957030504942\n",
      "epoch: 8 step: 673, loss is 0.006289994809776545\n",
      "epoch: 8 step: 674, loss is 0.0012178056640550494\n",
      "epoch: 8 step: 675, loss is 0.001136390259489417\n",
      "epoch: 8 step: 676, loss is 0.010134227573871613\n",
      "epoch: 8 step: 677, loss is 0.002340895589441061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 678, loss is 0.001032415428198874\n",
      "epoch: 8 step: 679, loss is 0.000164903758559376\n",
      "epoch: 8 step: 680, loss is 0.0202624648809433\n",
      "epoch: 8 step: 681, loss is 0.0016020287293940783\n",
      "epoch: 8 step: 682, loss is 0.004471154417842627\n",
      "epoch: 8 step: 683, loss is 0.0018749407026916742\n",
      "epoch: 8 step: 684, loss is 0.001005938625894487\n",
      "epoch: 8 step: 685, loss is 0.0002189358347095549\n",
      "epoch: 8 step: 686, loss is 0.0004134728806093335\n",
      "epoch: 8 step: 687, loss is 0.016745340079069138\n",
      "epoch: 8 step: 688, loss is 0.0025624968111515045\n",
      "epoch: 8 step: 689, loss is 0.021294889971613884\n",
      "epoch: 8 step: 690, loss is 0.014784155413508415\n",
      "epoch: 8 step: 691, loss is 0.026844263076782227\n",
      "epoch: 8 step: 692, loss is 0.00040574936429038644\n",
      "epoch: 8 step: 693, loss is 0.15455006062984467\n",
      "epoch: 8 step: 694, loss is 0.015398794785141945\n",
      "epoch: 8 step: 695, loss is 0.0001338236907031387\n",
      "epoch: 8 step: 696, loss is 0.18258036673069\n",
      "epoch: 8 step: 697, loss is 0.0015680575743317604\n",
      "epoch: 8 step: 698, loss is 0.003203943371772766\n",
      "epoch: 8 step: 699, loss is 0.00018153036944568157\n",
      "epoch: 8 step: 700, loss is 0.013756792061030865\n",
      "epoch: 8 step: 701, loss is 0.010721063241362572\n",
      "epoch: 8 step: 702, loss is 0.0014261725591495633\n",
      "epoch: 8 step: 703, loss is 0.0022275119554251432\n",
      "epoch: 8 step: 704, loss is 0.011613478884100914\n",
      "epoch: 8 step: 705, loss is 0.004547514952719212\n",
      "epoch: 8 step: 706, loss is 0.049956176429986954\n",
      "epoch: 8 step: 707, loss is 0.002305363304913044\n",
      "epoch: 8 step: 708, loss is 0.0007915805908851326\n",
      "epoch: 8 step: 709, loss is 1.9359100406290963e-05\n",
      "epoch: 8 step: 710, loss is 0.04051557928323746\n",
      "epoch: 8 step: 711, loss is 0.00011179139983141795\n",
      "epoch: 8 step: 712, loss is 0.004311090335249901\n",
      "epoch: 8 step: 713, loss is 0.043458156287670135\n",
      "epoch: 8 step: 714, loss is 0.04747198894619942\n",
      "epoch: 8 step: 715, loss is 0.005319759249687195\n",
      "epoch: 8 step: 716, loss is 3.00911287922645e-05\n",
      "epoch: 8 step: 717, loss is 0.0002582663728389889\n",
      "epoch: 8 step: 718, loss is 0.00838708970695734\n",
      "epoch: 8 step: 719, loss is 0.035911716520786285\n",
      "epoch: 8 step: 720, loss is 0.04312049597501755\n",
      "epoch: 8 step: 721, loss is 0.00014206659398041666\n",
      "epoch: 8 step: 722, loss is 0.0035740940365940332\n",
      "epoch: 8 step: 723, loss is 0.0004443861835170537\n",
      "epoch: 8 step: 724, loss is 0.128604918718338\n",
      "epoch: 8 step: 725, loss is 0.004001281689852476\n",
      "epoch: 8 step: 726, loss is 0.02022925578057766\n",
      "epoch: 8 step: 727, loss is 0.0008768748957663774\n",
      "epoch: 8 step: 728, loss is 0.026286287233233452\n",
      "epoch: 8 step: 729, loss is 0.08998900651931763\n",
      "epoch: 8 step: 730, loss is 0.00036639306927099824\n",
      "epoch: 8 step: 731, loss is 0.0011821474181488156\n",
      "epoch: 8 step: 732, loss is 0.0003058590227738023\n",
      "epoch: 8 step: 733, loss is 0.0030664848163723946\n",
      "epoch: 8 step: 734, loss is 0.0007946843979880214\n",
      "epoch: 8 step: 735, loss is 0.0005097967805340886\n",
      "epoch: 8 step: 736, loss is 0.004983533639460802\n",
      "epoch: 8 step: 737, loss is 0.0019270055927336216\n",
      "epoch: 8 step: 738, loss is 0.000374599767383188\n",
      "epoch: 8 step: 739, loss is 0.015539517626166344\n",
      "epoch: 8 step: 740, loss is 0.0005797048797830939\n",
      "epoch: 8 step: 741, loss is 0.0016531440196558833\n",
      "epoch: 8 step: 742, loss is 0.0051830243319272995\n",
      "epoch: 8 step: 743, loss is 0.008702351711690426\n",
      "epoch: 8 step: 744, loss is 0.0014050949830561876\n",
      "epoch: 8 step: 745, loss is 0.0017545769223943353\n",
      "epoch: 8 step: 746, loss is 0.0018435767851769924\n",
      "epoch: 8 step: 747, loss is 0.09497907012701035\n",
      "epoch: 8 step: 748, loss is 1.26499780890299e-05\n",
      "epoch: 8 step: 749, loss is 1.607380181667395e-05\n",
      "epoch: 8 step: 750, loss is 3.517710501910187e-05\n",
      "epoch: 8 step: 751, loss is 0.0056634461507201195\n",
      "epoch: 8 step: 752, loss is 3.327745071146637e-05\n",
      "epoch: 8 step: 753, loss is 0.002901341300457716\n",
      "epoch: 8 step: 754, loss is 0.03858962282538414\n",
      "epoch: 8 step: 755, loss is 0.02335342951118946\n",
      "epoch: 8 step: 756, loss is 3.6276418541092426e-05\n",
      "epoch: 8 step: 757, loss is 0.0002074476651614532\n",
      "epoch: 8 step: 758, loss is 0.03190405294299126\n",
      "epoch: 8 step: 759, loss is 0.001431833254173398\n",
      "epoch: 8 step: 760, loss is 0.07977207005023956\n",
      "epoch: 8 step: 761, loss is 0.3963581323623657\n",
      "epoch: 8 step: 762, loss is 0.0006247645360417664\n",
      "epoch: 8 step: 763, loss is 0.03761782869696617\n",
      "epoch: 8 step: 764, loss is 0.0005305572412908077\n",
      "epoch: 8 step: 765, loss is 0.0032083638943731785\n",
      "epoch: 8 step: 766, loss is 2.8991244107601233e-05\n",
      "epoch: 8 step: 767, loss is 0.0001400792971253395\n",
      "epoch: 8 step: 768, loss is 0.009437919594347477\n",
      "epoch: 8 step: 769, loss is 4.553280450636521e-05\n",
      "epoch: 8 step: 770, loss is 0.05010466277599335\n",
      "epoch: 8 step: 771, loss is 0.004711522255092859\n",
      "epoch: 8 step: 772, loss is 0.0298033207654953\n",
      "epoch: 8 step: 773, loss is 0.0015624985098838806\n",
      "epoch: 8 step: 774, loss is 0.016866691410541534\n",
      "epoch: 8 step: 775, loss is 0.0001279526186408475\n",
      "epoch: 8 step: 776, loss is 0.0008455445058643818\n",
      "epoch: 8 step: 777, loss is 0.0064590079709887505\n",
      "epoch: 8 step: 778, loss is 0.013614383526146412\n",
      "epoch: 8 step: 779, loss is 0.0007012846763245761\n",
      "epoch: 8 step: 780, loss is 0.00022564016398973763\n",
      "epoch: 8 step: 781, loss is 0.0004883286892436445\n",
      "epoch: 8 step: 782, loss is 0.11525674909353256\n",
      "epoch: 8 step: 783, loss is 0.00020732042321469635\n",
      "epoch: 8 step: 784, loss is 0.0044632903300225735\n",
      "epoch: 8 step: 785, loss is 0.029846342280507088\n",
      "epoch: 8 step: 786, loss is 0.0010975339682772756\n",
      "epoch: 8 step: 787, loss is 0.02122039534151554\n",
      "epoch: 8 step: 788, loss is 0.01121280062943697\n",
      "epoch: 8 step: 789, loss is 0.0007786979549564421\n",
      "epoch: 8 step: 790, loss is 0.0006520913448184729\n",
      "epoch: 8 step: 791, loss is 0.003511400194838643\n",
      "epoch: 8 step: 792, loss is 0.06710952520370483\n",
      "epoch: 8 step: 793, loss is 0.10334508866071701\n",
      "epoch: 8 step: 794, loss is 0.0015449144411832094\n",
      "epoch: 8 step: 795, loss is 0.00012576307926792651\n",
      "epoch: 8 step: 796, loss is 0.0015897051198408008\n",
      "epoch: 8 step: 797, loss is 0.00030724878888577223\n",
      "epoch: 8 step: 798, loss is 0.005128607153892517\n",
      "epoch: 8 step: 799, loss is 0.0015836161328479648\n",
      "epoch: 8 step: 800, loss is 0.00028693178319372237\n",
      "epoch: 8 step: 801, loss is 0.003490957897156477\n",
      "epoch: 8 step: 802, loss is 0.01383853517472744\n",
      "epoch: 8 step: 803, loss is 0.022084984928369522\n",
      "epoch: 8 step: 804, loss is 0.0056602442637085915\n",
      "epoch: 8 step: 805, loss is 0.0040279473178088665\n",
      "epoch: 8 step: 806, loss is 0.016866156831383705\n",
      "epoch: 8 step: 807, loss is 0.006919072475284338\n",
      "epoch: 8 step: 808, loss is 0.000282308115856722\n",
      "epoch: 8 step: 809, loss is 0.0002607974165584892\n",
      "epoch: 8 step: 810, loss is 0.0329296737909317\n",
      "epoch: 8 step: 811, loss is 0.0008778364863246679\n",
      "epoch: 8 step: 812, loss is 0.01453995518386364\n",
      "epoch: 8 step: 813, loss is 3.6172230466036126e-05\n",
      "epoch: 8 step: 814, loss is 0.0014442183310166001\n",
      "epoch: 8 step: 815, loss is 0.00479560112580657\n",
      "epoch: 8 step: 816, loss is 0.0017828821437433362\n",
      "epoch: 8 step: 817, loss is 0.0020455578342080116\n",
      "epoch: 8 step: 818, loss is 0.0006127202068455517\n",
      "epoch: 8 step: 819, loss is 0.0008947974420152605\n",
      "epoch: 8 step: 820, loss is 0.0017867062706500292\n",
      "epoch: 8 step: 821, loss is 5.8834713854594156e-05\n",
      "epoch: 8 step: 822, loss is 0.00856858491897583\n",
      "epoch: 8 step: 823, loss is 0.0005181743181310594\n",
      "epoch: 8 step: 824, loss is 0.06155087426304817\n",
      "epoch: 8 step: 825, loss is 0.00020940173999406397\n",
      "epoch: 8 step: 826, loss is 9.786442387849092e-05\n",
      "epoch: 8 step: 827, loss is 0.015971163287758827\n",
      "epoch: 8 step: 828, loss is 0.0036279873456805944\n",
      "epoch: 8 step: 829, loss is 0.002361526247113943\n",
      "epoch: 8 step: 830, loss is 0.00042037415551021695\n",
      "epoch: 8 step: 831, loss is 9.112266707234085e-05\n",
      "epoch: 8 step: 832, loss is 0.2998071312904358\n",
      "epoch: 8 step: 833, loss is 0.00024043049779720604\n",
      "epoch: 8 step: 834, loss is 0.01494247280061245\n",
      "epoch: 8 step: 835, loss is 0.001572406617924571\n",
      "epoch: 8 step: 836, loss is 0.003300057491287589\n",
      "epoch: 8 step: 837, loss is 0.0008029788732528687\n",
      "epoch: 8 step: 838, loss is 0.0005436659557744861\n",
      "epoch: 8 step: 839, loss is 0.0009742443799041212\n",
      "epoch: 8 step: 840, loss is 0.0009597837342880666\n",
      "epoch: 8 step: 841, loss is 0.0002358839410590008\n",
      "epoch: 8 step: 842, loss is 9.559475984133314e-06\n",
      "epoch: 8 step: 843, loss is 0.0012171247508376837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 844, loss is 0.001124922069720924\n",
      "epoch: 8 step: 845, loss is 3.673957326100208e-05\n",
      "epoch: 8 step: 846, loss is 0.0006723101832903922\n",
      "epoch: 8 step: 847, loss is 0.007218648679554462\n",
      "epoch: 8 step: 848, loss is 0.02145770937204361\n",
      "epoch: 8 step: 849, loss is 0.0003527496592141688\n",
      "epoch: 8 step: 850, loss is 0.0002095987874781713\n",
      "epoch: 8 step: 851, loss is 0.0002215788117609918\n",
      "epoch: 8 step: 852, loss is 0.002883374923840165\n",
      "epoch: 8 step: 853, loss is 0.0005168019561097026\n",
      "epoch: 8 step: 854, loss is 0.0009838740807026625\n",
      "epoch: 8 step: 855, loss is 0.016671955585479736\n",
      "epoch: 8 step: 856, loss is 0.0002784340758807957\n",
      "epoch: 8 step: 857, loss is 0.0007298945565707982\n",
      "epoch: 8 step: 858, loss is 0.0006859026616439223\n",
      "epoch: 8 step: 859, loss is 0.000570396485272795\n",
      "epoch: 8 step: 860, loss is 0.0021902944426983595\n",
      "epoch: 8 step: 861, loss is 0.020568756386637688\n",
      "epoch: 8 step: 862, loss is 0.004018763080239296\n",
      "epoch: 8 step: 863, loss is 0.001313340268097818\n",
      "epoch: 8 step: 864, loss is 0.004745289217680693\n",
      "epoch: 8 step: 865, loss is 0.002229016739875078\n",
      "epoch: 8 step: 866, loss is 0.013205011375248432\n",
      "epoch: 8 step: 867, loss is 0.018744448199868202\n",
      "epoch: 8 step: 868, loss is 0.03666238114237785\n",
      "epoch: 8 step: 869, loss is 0.0004068140115123242\n",
      "epoch: 8 step: 870, loss is 0.0005382278468459845\n",
      "epoch: 8 step: 871, loss is 0.002317794831469655\n",
      "epoch: 8 step: 872, loss is 0.00018262374214828014\n",
      "epoch: 8 step: 873, loss is 0.0008238137234002352\n",
      "epoch: 8 step: 874, loss is 0.00029319876921363175\n",
      "epoch: 8 step: 875, loss is 0.00031503697391599417\n",
      "epoch: 8 step: 876, loss is 0.006506155710667372\n",
      "epoch: 8 step: 877, loss is 0.01144635770469904\n",
      "epoch: 8 step: 878, loss is 0.00010385294444859028\n",
      "epoch: 8 step: 879, loss is 0.0015587140806019306\n",
      "epoch: 8 step: 880, loss is 0.011569689027965069\n",
      "epoch: 8 step: 881, loss is 0.000966015039011836\n",
      "epoch: 8 step: 882, loss is 0.0009449158678762615\n",
      "epoch: 8 step: 883, loss is 0.04217524826526642\n",
      "epoch: 8 step: 884, loss is 0.018483899533748627\n",
      "epoch: 8 step: 885, loss is 0.03759950399398804\n",
      "epoch: 8 step: 886, loss is 0.00046496433787979186\n",
      "epoch: 8 step: 887, loss is 0.0004319261643104255\n",
      "epoch: 8 step: 888, loss is 0.002067518886178732\n",
      "epoch: 8 step: 889, loss is 0.0010592289036139846\n",
      "epoch: 8 step: 890, loss is 0.0008744957740418613\n",
      "epoch: 8 step: 891, loss is 0.14145104587078094\n",
      "epoch: 8 step: 892, loss is 0.046515949070453644\n",
      "epoch: 8 step: 893, loss is 0.00013187696458771825\n",
      "epoch: 8 step: 894, loss is 0.041636377573013306\n",
      "epoch: 8 step: 895, loss is 0.000949245470110327\n",
      "epoch: 8 step: 896, loss is 0.0010270520579069853\n",
      "epoch: 8 step: 897, loss is 8.69761934154667e-05\n",
      "epoch: 8 step: 898, loss is 2.787664925563149e-05\n",
      "epoch: 8 step: 899, loss is 0.000697474111802876\n",
      "epoch: 8 step: 900, loss is 0.001083806506358087\n",
      "epoch: 8 step: 901, loss is 0.002529577352106571\n",
      "epoch: 8 step: 902, loss is 0.005243949592113495\n",
      "epoch: 8 step: 903, loss is 0.03262842819094658\n",
      "epoch: 8 step: 904, loss is 0.0006604810478165746\n",
      "epoch: 8 step: 905, loss is 0.002736868569627404\n",
      "epoch: 8 step: 906, loss is 0.006974149961024523\n",
      "epoch: 8 step: 907, loss is 0.008794079534709454\n",
      "epoch: 8 step: 908, loss is 0.011122282594442368\n",
      "epoch: 8 step: 909, loss is 0.0029670498333871365\n",
      "epoch: 8 step: 910, loss is 0.026827573776245117\n",
      "epoch: 8 step: 911, loss is 0.004052160307765007\n",
      "epoch: 8 step: 912, loss is 0.001562547986395657\n",
      "epoch: 8 step: 913, loss is 0.0004758185241371393\n",
      "epoch: 8 step: 914, loss is 0.004460613243281841\n",
      "epoch: 8 step: 915, loss is 0.0026568882167339325\n",
      "epoch: 8 step: 916, loss is 2.5485420337645337e-05\n",
      "epoch: 8 step: 917, loss is 0.02378096431493759\n",
      "epoch: 8 step: 918, loss is 0.00048769445857033134\n",
      "epoch: 8 step: 919, loss is 1.343768963124603e-05\n",
      "epoch: 8 step: 920, loss is 0.00139104132540524\n",
      "epoch: 8 step: 921, loss is 0.0007234200602397323\n",
      "epoch: 8 step: 922, loss is 0.01316626276820898\n",
      "epoch: 8 step: 923, loss is 0.0010670260526239872\n",
      "epoch: 8 step: 924, loss is 0.0002488777390681207\n",
      "epoch: 8 step: 925, loss is 7.231289055198431e-05\n",
      "epoch: 8 step: 926, loss is 0.004313280805945396\n",
      "epoch: 8 step: 927, loss is 0.0001937485212692991\n",
      "epoch: 8 step: 928, loss is 0.061596594750881195\n",
      "epoch: 8 step: 929, loss is 0.04672407731413841\n",
      "epoch: 8 step: 930, loss is 0.001136367442086339\n",
      "epoch: 8 step: 931, loss is 2.3532846171292476e-05\n",
      "epoch: 8 step: 932, loss is 1.8442404325469397e-05\n",
      "epoch: 8 step: 933, loss is 0.00011021528916899115\n",
      "epoch: 8 step: 934, loss is 0.00010552319145062938\n",
      "epoch: 8 step: 935, loss is 0.004750832915306091\n",
      "epoch: 8 step: 936, loss is 0.0015178238973021507\n",
      "epoch: 8 step: 937, loss is 0.0006454206886701286\n",
      "epoch: 8 step: 938, loss is 0.0035538850352168083\n",
      "epoch: 8 step: 939, loss is 0.00023685167252551764\n",
      "epoch: 8 step: 940, loss is 1.256606810784433e-05\n",
      "epoch: 8 step: 941, loss is 0.004170401953160763\n",
      "epoch: 8 step: 942, loss is 0.00012818380491808057\n",
      "epoch: 8 step: 943, loss is 8.575200627092272e-05\n",
      "epoch: 8 step: 944, loss is 0.0005990869831293821\n",
      "epoch: 8 step: 945, loss is 0.005915616173297167\n",
      "epoch: 8 step: 946, loss is 0.006614784710109234\n",
      "epoch: 8 step: 947, loss is 0.00039756399928592145\n",
      "epoch: 8 step: 948, loss is 0.007050621788948774\n",
      "epoch: 8 step: 949, loss is 0.0007095211767591536\n",
      "epoch: 8 step: 950, loss is 0.0031525546219199896\n",
      "epoch: 8 step: 951, loss is 0.013875750824809074\n",
      "epoch: 8 step: 952, loss is 0.0009074939298443496\n",
      "epoch: 8 step: 953, loss is 0.041933994740247726\n",
      "epoch: 8 step: 954, loss is 0.0951457992196083\n",
      "epoch: 8 step: 955, loss is 0.0001399737666361034\n",
      "epoch: 8 step: 956, loss is 6.025655966368504e-05\n",
      "epoch: 8 step: 957, loss is 6.187721010064706e-05\n",
      "epoch: 8 step: 958, loss is 0.006973057519644499\n",
      "epoch: 8 step: 959, loss is 0.0006942644831724465\n",
      "epoch: 8 step: 960, loss is 0.035455234348773956\n",
      "epoch: 8 step: 961, loss is 0.0005297248135320842\n",
      "epoch: 8 step: 962, loss is 0.003199429716914892\n",
      "epoch: 8 step: 963, loss is 0.005666566547006369\n",
      "epoch: 8 step: 964, loss is 0.05054374784231186\n",
      "epoch: 8 step: 965, loss is 0.0001363275951007381\n",
      "epoch: 8 step: 966, loss is 0.026740679517388344\n",
      "epoch: 8 step: 967, loss is 0.001282577170059085\n",
      "epoch: 8 step: 968, loss is 0.0013023565988987684\n",
      "epoch: 8 step: 969, loss is 0.0004717429983429611\n",
      "epoch: 8 step: 970, loss is 0.0004800434107892215\n",
      "epoch: 8 step: 971, loss is 0.020803725346922874\n",
      "epoch: 8 step: 972, loss is 0.007678702939301729\n",
      "epoch: 8 step: 973, loss is 0.006812207400798798\n",
      "epoch: 8 step: 974, loss is 0.010572613216936588\n",
      "epoch: 8 step: 975, loss is 0.0005385751719586551\n",
      "epoch: 8 step: 976, loss is 0.00010198956442764029\n",
      "epoch: 8 step: 977, loss is 0.04530663788318634\n",
      "epoch: 8 step: 978, loss is 0.029883544892072678\n",
      "epoch: 8 step: 979, loss is 7.025171362329274e-05\n",
      "epoch: 8 step: 980, loss is 0.004343478940427303\n",
      "epoch: 8 step: 981, loss is 0.00012449690257199109\n",
      "epoch: 8 step: 982, loss is 0.011477399617433548\n",
      "epoch: 8 step: 983, loss is 0.002576851285994053\n",
      "epoch: 8 step: 984, loss is 4.606604125001468e-05\n",
      "epoch: 8 step: 985, loss is 0.0005995727842673659\n",
      "epoch: 8 step: 986, loss is 0.0011609685607254505\n",
      "epoch: 8 step: 987, loss is 9.199681517202407e-05\n",
      "epoch: 8 step: 988, loss is 0.00264900759793818\n",
      "epoch: 8 step: 989, loss is 0.00013719355047214776\n",
      "epoch: 8 step: 990, loss is 0.05319187790155411\n",
      "epoch: 8 step: 991, loss is 0.15554414689540863\n",
      "epoch: 8 step: 992, loss is 0.0006721823592670262\n",
      "epoch: 8 step: 993, loss is 0.0006982546183280647\n",
      "epoch: 8 step: 994, loss is 0.040103502571582794\n",
      "epoch: 8 step: 995, loss is 0.03279245272278786\n",
      "epoch: 8 step: 996, loss is 0.01767566241323948\n",
      "epoch: 8 step: 997, loss is 8.671466639498249e-05\n",
      "epoch: 8 step: 998, loss is 0.0017598140984773636\n",
      "epoch: 8 step: 999, loss is 6.86902494635433e-05\n",
      "epoch: 8 step: 1000, loss is 0.013494503684341908\n",
      "epoch: 8 step: 1001, loss is 0.0641169473528862\n",
      "epoch: 8 step: 1002, loss is 0.0013784072361886501\n",
      "epoch: 8 step: 1003, loss is 0.015297257341444492\n",
      "epoch: 8 step: 1004, loss is 0.0013978355564177036\n",
      "epoch: 8 step: 1005, loss is 9.110283281188458e-05\n",
      "epoch: 8 step: 1006, loss is 0.0006810600752942264\n",
      "epoch: 8 step: 1007, loss is 0.08603692054748535\n",
      "epoch: 8 step: 1008, loss is 0.0010118166683241725\n",
      "epoch: 8 step: 1009, loss is 0.00019252525817137212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1010, loss is 0.0045953113585710526\n",
      "epoch: 8 step: 1011, loss is 0.00018064389587379992\n",
      "epoch: 8 step: 1012, loss is 0.003970050252974033\n",
      "epoch: 8 step: 1013, loss is 0.0024061379954218864\n",
      "epoch: 8 step: 1014, loss is 0.003563348203897476\n",
      "epoch: 8 step: 1015, loss is 0.0003432838711887598\n",
      "epoch: 8 step: 1016, loss is 0.0023368571419268847\n",
      "epoch: 8 step: 1017, loss is 5.743365181842819e-05\n",
      "epoch: 8 step: 1018, loss is 0.020143119618296623\n",
      "epoch: 8 step: 1019, loss is 0.02374587580561638\n",
      "epoch: 8 step: 1020, loss is 0.007163024973124266\n",
      "epoch: 8 step: 1021, loss is 0.001068406505510211\n",
      "epoch: 8 step: 1022, loss is 0.00020304019562900066\n",
      "epoch: 8 step: 1023, loss is 0.029654335230588913\n",
      "epoch: 8 step: 1024, loss is 0.007417287211865187\n",
      "epoch: 8 step: 1025, loss is 0.003856611903756857\n",
      "epoch: 8 step: 1026, loss is 0.003000440075993538\n",
      "epoch: 8 step: 1027, loss is 0.001040649600327015\n",
      "epoch: 8 step: 1028, loss is 2.6467390853213146e-05\n",
      "epoch: 8 step: 1029, loss is 0.017938975244760513\n",
      "epoch: 8 step: 1030, loss is 0.015757374465465546\n",
      "epoch: 8 step: 1031, loss is 0.003972445148974657\n",
      "epoch: 8 step: 1032, loss is 0.0005040945252403617\n",
      "epoch: 8 step: 1033, loss is 0.0005740039050579071\n",
      "epoch: 8 step: 1034, loss is 0.016399823129177094\n",
      "epoch: 8 step: 1035, loss is 0.0002820098015945405\n",
      "epoch: 8 step: 1036, loss is 1.7839911379269324e-05\n",
      "epoch: 8 step: 1037, loss is 0.0009415800450369716\n",
      "epoch: 8 step: 1038, loss is 2.371976188442204e-05\n",
      "epoch: 8 step: 1039, loss is 0.09953181445598602\n",
      "epoch: 8 step: 1040, loss is 0.0004896938917227089\n",
      "epoch: 8 step: 1041, loss is 0.0005571848596446216\n",
      "epoch: 8 step: 1042, loss is 6.070623567211442e-05\n",
      "epoch: 8 step: 1043, loss is 0.0010053830919787288\n",
      "epoch: 8 step: 1044, loss is 4.666984750656411e-05\n",
      "epoch: 8 step: 1045, loss is 0.0022827687207609415\n",
      "epoch: 8 step: 1046, loss is 0.10246162861585617\n",
      "epoch: 8 step: 1047, loss is 0.011290617287158966\n",
      "epoch: 8 step: 1048, loss is 0.00017559799016453326\n",
      "epoch: 8 step: 1049, loss is 4.910684947390109e-05\n",
      "epoch: 8 step: 1050, loss is 0.019750211387872696\n",
      "epoch: 8 step: 1051, loss is 6.624742673011497e-05\n",
      "epoch: 8 step: 1052, loss is 0.0001548391446704045\n",
      "epoch: 8 step: 1053, loss is 0.0029742131009697914\n",
      "epoch: 8 step: 1054, loss is 0.0011217562714591622\n",
      "epoch: 8 step: 1055, loss is 0.0001523991668364033\n",
      "epoch: 8 step: 1056, loss is 0.010323545895516872\n",
      "epoch: 8 step: 1057, loss is 0.005922026466578245\n",
      "epoch: 8 step: 1058, loss is 8.154031092999503e-05\n",
      "epoch: 8 step: 1059, loss is 3.438097701291554e-05\n",
      "epoch: 8 step: 1060, loss is 0.00022717792307958007\n",
      "epoch: 8 step: 1061, loss is 0.02298928052186966\n",
      "epoch: 8 step: 1062, loss is 2.7925445465371013e-05\n",
      "epoch: 8 step: 1063, loss is 0.0642201155424118\n",
      "epoch: 8 step: 1064, loss is 0.129720076918602\n",
      "epoch: 8 step: 1065, loss is 0.0025189598090946674\n",
      "epoch: 8 step: 1066, loss is 0.0003279020602349192\n",
      "epoch: 8 step: 1067, loss is 0.004428402055054903\n",
      "epoch: 8 step: 1068, loss is 0.109523244202137\n",
      "epoch: 8 step: 1069, loss is 0.0004937451449222863\n",
      "epoch: 8 step: 1070, loss is 0.002319700550287962\n",
      "epoch: 8 step: 1071, loss is 0.0055891587398946285\n",
      "epoch: 8 step: 1072, loss is 0.0015313121257349849\n",
      "epoch: 8 step: 1073, loss is 0.0007345627527683973\n",
      "epoch: 8 step: 1074, loss is 0.07709664106369019\n",
      "epoch: 8 step: 1075, loss is 0.09928859025239944\n",
      "epoch: 8 step: 1076, loss is 0.004576100967824459\n",
      "epoch: 8 step: 1077, loss is 0.004736755043268204\n",
      "epoch: 8 step: 1078, loss is 0.0003040646843146533\n",
      "epoch: 8 step: 1079, loss is 0.002274692989885807\n",
      "epoch: 8 step: 1080, loss is 0.002503078430891037\n",
      "epoch: 8 step: 1081, loss is 0.0385943278670311\n",
      "epoch: 8 step: 1082, loss is 0.0015859416453167796\n",
      "epoch: 8 step: 1083, loss is 0.009948979131877422\n",
      "epoch: 8 step: 1084, loss is 0.00046178611228242517\n",
      "epoch: 8 step: 1085, loss is 0.0011817271588370204\n",
      "epoch: 8 step: 1086, loss is 0.03904679790139198\n",
      "epoch: 8 step: 1087, loss is 0.0003667044220492244\n",
      "epoch: 8 step: 1088, loss is 0.000299211562378332\n",
      "epoch: 8 step: 1089, loss is 3.745837966562249e-05\n",
      "epoch: 8 step: 1090, loss is 0.0010476295137777925\n",
      "epoch: 8 step: 1091, loss is 0.0017928655724972486\n",
      "epoch: 8 step: 1092, loss is 0.00446697324514389\n",
      "epoch: 8 step: 1093, loss is 0.00027456250973045826\n",
      "epoch: 8 step: 1094, loss is 0.005826752632856369\n",
      "epoch: 8 step: 1095, loss is 0.00027026113821193576\n",
      "epoch: 8 step: 1096, loss is 0.02622126415371895\n",
      "epoch: 8 step: 1097, loss is 0.08218041807413101\n",
      "epoch: 8 step: 1098, loss is 0.0007941175135783851\n",
      "epoch: 8 step: 1099, loss is 0.00027028698241338134\n",
      "epoch: 8 step: 1100, loss is 0.0007977942586876452\n",
      "epoch: 8 step: 1101, loss is 0.008276277221739292\n",
      "epoch: 8 step: 1102, loss is 0.0015599846374243498\n",
      "epoch: 8 step: 1103, loss is 0.3458581268787384\n",
      "epoch: 8 step: 1104, loss is 0.005582611542195082\n",
      "epoch: 8 step: 1105, loss is 0.00035047210985794663\n",
      "epoch: 8 step: 1106, loss is 0.015106535516679287\n",
      "epoch: 8 step: 1107, loss is 0.0006162215140648186\n",
      "epoch: 8 step: 1108, loss is 2.9868520869058557e-05\n",
      "epoch: 8 step: 1109, loss is 3.8129630411276594e-05\n",
      "epoch: 8 step: 1110, loss is 0.00015820864064153284\n",
      "epoch: 8 step: 1111, loss is 0.007860686630010605\n",
      "epoch: 8 step: 1112, loss is 2.2393103790818714e-05\n",
      "epoch: 8 step: 1113, loss is 0.0030708517879247665\n",
      "epoch: 8 step: 1114, loss is 0.00013854725693818182\n",
      "epoch: 8 step: 1115, loss is 0.0001679064880590886\n",
      "epoch: 8 step: 1116, loss is 0.05178872495889664\n",
      "epoch: 8 step: 1117, loss is 0.0034383777529001236\n",
      "epoch: 8 step: 1118, loss is 0.027952024713158607\n",
      "epoch: 8 step: 1119, loss is 0.0030287697445601225\n",
      "epoch: 8 step: 1120, loss is 0.004746244288980961\n",
      "epoch: 8 step: 1121, loss is 0.0013369538355618715\n",
      "epoch: 8 step: 1122, loss is 0.0013694360386580229\n",
      "epoch: 8 step: 1123, loss is 5.741233326261863e-05\n",
      "epoch: 8 step: 1124, loss is 0.08335305005311966\n",
      "epoch: 8 step: 1125, loss is 0.0021365699358284473\n",
      "epoch: 8 step: 1126, loss is 6.655694596702233e-05\n",
      "epoch: 8 step: 1127, loss is 0.13184109330177307\n",
      "epoch: 8 step: 1128, loss is 0.0005818843492306769\n",
      "epoch: 8 step: 1129, loss is 3.431935328990221e-05\n",
      "epoch: 8 step: 1130, loss is 6.962983206904028e-06\n",
      "epoch: 8 step: 1131, loss is 2.8402695534168743e-05\n",
      "epoch: 8 step: 1132, loss is 0.08203556388616562\n",
      "epoch: 8 step: 1133, loss is 0.001605343190021813\n",
      "epoch: 8 step: 1134, loss is 0.011311087757349014\n",
      "epoch: 8 step: 1135, loss is 0.0006628925912082195\n",
      "epoch: 8 step: 1136, loss is 0.1369321197271347\n",
      "epoch: 8 step: 1137, loss is 0.013889351859688759\n",
      "epoch: 8 step: 1138, loss is 8.599010470788926e-05\n",
      "epoch: 8 step: 1139, loss is 0.10473030060529709\n",
      "epoch: 8 step: 1140, loss is 0.03277871757745743\n",
      "epoch: 8 step: 1141, loss is 0.11427175253629684\n",
      "epoch: 8 step: 1142, loss is 0.0006486570928245783\n",
      "epoch: 8 step: 1143, loss is 8.336709288414568e-05\n",
      "epoch: 8 step: 1144, loss is 0.0659051463007927\n",
      "epoch: 8 step: 1145, loss is 5.695899744750932e-05\n",
      "epoch: 8 step: 1146, loss is 0.00014273246051743627\n",
      "epoch: 8 step: 1147, loss is 0.00021124347404111177\n",
      "epoch: 8 step: 1148, loss is 0.004175117239356041\n",
      "epoch: 8 step: 1149, loss is 0.000804619980044663\n",
      "epoch: 8 step: 1150, loss is 0.07558166980743408\n",
      "epoch: 8 step: 1151, loss is 2.5194789486704394e-05\n",
      "epoch: 8 step: 1152, loss is 6.140890036476776e-05\n",
      "epoch: 8 step: 1153, loss is 0.0015794287901371717\n",
      "epoch: 8 step: 1154, loss is 0.015516387298703194\n",
      "epoch: 8 step: 1155, loss is 0.0012287788558751345\n",
      "epoch: 8 step: 1156, loss is 0.013154072687029839\n",
      "epoch: 8 step: 1157, loss is 0.0031405624467879534\n",
      "epoch: 8 step: 1158, loss is 0.00010703649604693055\n",
      "epoch: 8 step: 1159, loss is 0.00016145221889019012\n",
      "epoch: 8 step: 1160, loss is 0.003703037044033408\n",
      "epoch: 8 step: 1161, loss is 0.08524835854768753\n",
      "epoch: 8 step: 1162, loss is 0.03875289857387543\n",
      "epoch: 8 step: 1163, loss is 0.0002794296888168901\n",
      "epoch: 8 step: 1164, loss is 0.0007197056547738612\n",
      "epoch: 8 step: 1165, loss is 0.00047492666635662317\n",
      "epoch: 8 step: 1166, loss is 0.0030001045670360327\n",
      "epoch: 8 step: 1167, loss is 0.005451550707221031\n",
      "epoch: 8 step: 1168, loss is 0.0013450499391183257\n",
      "epoch: 8 step: 1169, loss is 0.07258868217468262\n",
      "epoch: 8 step: 1170, loss is 0.00017741171177476645\n",
      "epoch: 8 step: 1171, loss is 0.083286352455616\n",
      "epoch: 8 step: 1172, loss is 0.001661015092395246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1173, loss is 0.011766830459237099\n",
      "epoch: 8 step: 1174, loss is 0.0008844069670885801\n",
      "epoch: 8 step: 1175, loss is 0.0006626935792155564\n",
      "epoch: 8 step: 1176, loss is 0.0004095822514500469\n",
      "epoch: 8 step: 1177, loss is 0.0011650394881144166\n",
      "epoch: 8 step: 1178, loss is 0.003065624972805381\n",
      "epoch: 8 step: 1179, loss is 0.0002769464335869998\n",
      "epoch: 8 step: 1180, loss is 0.0054915244691073895\n",
      "epoch: 8 step: 1181, loss is 0.04165825620293617\n",
      "epoch: 8 step: 1182, loss is 7.167650437622797e-06\n",
      "epoch: 8 step: 1183, loss is 0.0006471822271123528\n",
      "epoch: 8 step: 1184, loss is 0.0002797223278321326\n",
      "epoch: 8 step: 1185, loss is 0.0008312084246426821\n",
      "epoch: 8 step: 1186, loss is 0.016509464010596275\n",
      "epoch: 8 step: 1187, loss is 0.0012628288241103292\n",
      "epoch: 8 step: 1188, loss is 0.0017115053487941623\n",
      "epoch: 8 step: 1189, loss is 0.0005086880992166698\n",
      "epoch: 8 step: 1190, loss is 3.2731302781030536e-05\n",
      "epoch: 8 step: 1191, loss is 0.04459907114505768\n",
      "epoch: 8 step: 1192, loss is 0.08861272782087326\n",
      "epoch: 8 step: 1193, loss is 0.417420893907547\n",
      "epoch: 8 step: 1194, loss is 7.595975330332294e-05\n",
      "epoch: 8 step: 1195, loss is 0.004450267646461725\n",
      "epoch: 8 step: 1196, loss is 0.0009194730082526803\n",
      "epoch: 8 step: 1197, loss is 0.0006943101761862636\n",
      "epoch: 8 step: 1198, loss is 0.000846308539621532\n",
      "epoch: 8 step: 1199, loss is 0.0005609766812995076\n",
      "epoch: 8 step: 1200, loss is 0.0001386995572829619\n",
      "epoch: 8 step: 1201, loss is 4.468009865377098e-05\n",
      "epoch: 8 step: 1202, loss is 0.0016703919973224401\n",
      "epoch: 8 step: 1203, loss is 0.00010723291779868305\n",
      "epoch: 8 step: 1204, loss is 0.007298920303583145\n",
      "epoch: 8 step: 1205, loss is 0.01348970178514719\n",
      "epoch: 8 step: 1206, loss is 0.00533033674582839\n",
      "epoch: 8 step: 1207, loss is 0.000474545027827844\n",
      "epoch: 8 step: 1208, loss is 0.0026295529678463936\n",
      "epoch: 8 step: 1209, loss is 0.019274162128567696\n",
      "epoch: 8 step: 1210, loss is 8.030934986891225e-05\n",
      "epoch: 8 step: 1211, loss is 0.0014701002510264516\n",
      "epoch: 8 step: 1212, loss is 0.0017670491943135858\n",
      "epoch: 8 step: 1213, loss is 0.0010416426230221987\n",
      "epoch: 8 step: 1214, loss is 0.03451623022556305\n",
      "epoch: 8 step: 1215, loss is 0.09983864426612854\n",
      "epoch: 8 step: 1216, loss is 0.030557220801711082\n",
      "epoch: 8 step: 1217, loss is 0.07058984041213989\n",
      "epoch: 8 step: 1218, loss is 0.09932122379541397\n",
      "epoch: 8 step: 1219, loss is 0.007045336067676544\n",
      "epoch: 8 step: 1220, loss is 0.0001365356147289276\n",
      "epoch: 8 step: 1221, loss is 9.59502358455211e-06\n",
      "epoch: 8 step: 1222, loss is 0.0004211380728520453\n",
      "epoch: 8 step: 1223, loss is 0.05347573384642601\n",
      "epoch: 8 step: 1224, loss is 0.02899348735809326\n",
      "epoch: 8 step: 1225, loss is 0.00211196206510067\n",
      "epoch: 8 step: 1226, loss is 0.0006212659063749015\n",
      "epoch: 8 step: 1227, loss is 0.00014989700866863132\n",
      "epoch: 8 step: 1228, loss is 0.1335536539554596\n",
      "epoch: 8 step: 1229, loss is 0.0012766428990289569\n",
      "epoch: 8 step: 1230, loss is 0.001861486118286848\n",
      "epoch: 8 step: 1231, loss is 0.0162337776273489\n",
      "epoch: 8 step: 1232, loss is 0.0005834713811054826\n",
      "epoch: 8 step: 1233, loss is 0.016488593071699142\n",
      "epoch: 8 step: 1234, loss is 9.630154818296432e-05\n",
      "epoch: 8 step: 1235, loss is 0.05389709770679474\n",
      "epoch: 8 step: 1236, loss is 0.0008270143298432231\n",
      "epoch: 8 step: 1237, loss is 0.0018473692471161485\n",
      "epoch: 8 step: 1238, loss is 0.006389388348907232\n",
      "epoch: 8 step: 1239, loss is 0.00432167574763298\n",
      "epoch: 8 step: 1240, loss is 0.0001286818296648562\n",
      "epoch: 8 step: 1241, loss is 0.008606716990470886\n",
      "epoch: 8 step: 1242, loss is 0.003576515708118677\n",
      "epoch: 8 step: 1243, loss is 0.00010887130338232964\n",
      "epoch: 8 step: 1244, loss is 0.01328252162784338\n",
      "epoch: 8 step: 1245, loss is 0.0019326343899592757\n",
      "epoch: 8 step: 1246, loss is 0.00010747173655545339\n",
      "epoch: 8 step: 1247, loss is 0.02790389023721218\n",
      "epoch: 8 step: 1248, loss is 0.0008638726430945098\n",
      "epoch: 8 step: 1249, loss is 0.08612460643053055\n",
      "epoch: 8 step: 1250, loss is 0.0054544745944440365\n",
      "epoch: 8 step: 1251, loss is 0.0008570575155317783\n",
      "epoch: 8 step: 1252, loss is 0.009149760007858276\n",
      "epoch: 8 step: 1253, loss is 0.13968980312347412\n",
      "epoch: 8 step: 1254, loss is 1.3752727682003751e-05\n",
      "epoch: 8 step: 1255, loss is 0.0005248608067631721\n",
      "epoch: 8 step: 1256, loss is 0.010388653725385666\n",
      "epoch: 8 step: 1257, loss is 0.0023493291810154915\n",
      "epoch: 8 step: 1258, loss is 0.007657909765839577\n",
      "epoch: 8 step: 1259, loss is 0.0012551441323012114\n",
      "epoch: 8 step: 1260, loss is 0.0028622313402593136\n",
      "epoch: 8 step: 1261, loss is 0.0017171690706163645\n",
      "epoch: 8 step: 1262, loss is 0.3331414461135864\n",
      "epoch: 8 step: 1263, loss is 0.06319992989301682\n",
      "epoch: 8 step: 1264, loss is 0.03330383449792862\n",
      "epoch: 8 step: 1265, loss is 0.0028039871249347925\n",
      "epoch: 8 step: 1266, loss is 0.007323184981942177\n",
      "epoch: 8 step: 1267, loss is 0.02574259415268898\n",
      "epoch: 8 step: 1268, loss is 0.0014556547394022346\n",
      "epoch: 8 step: 1269, loss is 0.002607649425044656\n",
      "epoch: 8 step: 1270, loss is 7.30618994566612e-05\n",
      "epoch: 8 step: 1271, loss is 0.00029258339782245457\n",
      "epoch: 8 step: 1272, loss is 0.0035824007354676723\n",
      "epoch: 8 step: 1273, loss is 0.0002334272430744022\n",
      "epoch: 8 step: 1274, loss is 3.402720540179871e-05\n",
      "epoch: 8 step: 1275, loss is 0.011675067245960236\n",
      "epoch: 8 step: 1276, loss is 0.0004493917222134769\n",
      "epoch: 8 step: 1277, loss is 0.023063985630869865\n",
      "epoch: 8 step: 1278, loss is 0.0013723979936912656\n",
      "epoch: 8 step: 1279, loss is 0.0012987146619707346\n",
      "epoch: 8 step: 1280, loss is 0.024792514741420746\n",
      "epoch: 8 step: 1281, loss is 0.0024133066181093454\n",
      "epoch: 8 step: 1282, loss is 0.00011810605792561546\n",
      "epoch: 8 step: 1283, loss is 0.11527933925390244\n",
      "epoch: 8 step: 1284, loss is 0.03073030896484852\n",
      "epoch: 8 step: 1285, loss is 0.0006415030220523477\n",
      "epoch: 8 step: 1286, loss is 0.0028932050336152315\n",
      "epoch: 8 step: 1287, loss is 0.0007751878583803773\n",
      "epoch: 8 step: 1288, loss is 0.00023455001064576209\n",
      "epoch: 8 step: 1289, loss is 0.002522108843550086\n",
      "epoch: 8 step: 1290, loss is 0.0002382938691880554\n",
      "epoch: 8 step: 1291, loss is 0.06250710785388947\n",
      "epoch: 8 step: 1292, loss is 0.072025828063488\n",
      "epoch: 8 step: 1293, loss is 0.00022921555500943214\n",
      "epoch: 8 step: 1294, loss is 0.001014126930385828\n",
      "epoch: 8 step: 1295, loss is 0.0014410644071176648\n",
      "epoch: 8 step: 1296, loss is 0.020424025133252144\n",
      "epoch: 8 step: 1297, loss is 0.0064077493734657764\n",
      "epoch: 8 step: 1298, loss is 0.0028388104401528835\n",
      "epoch: 8 step: 1299, loss is 0.009482866153120995\n",
      "epoch: 8 step: 1300, loss is 0.00024836527882143855\n",
      "epoch: 8 step: 1301, loss is 0.0003108894161414355\n",
      "epoch: 8 step: 1302, loss is 0.0441170334815979\n",
      "epoch: 8 step: 1303, loss is 0.0018375851213932037\n",
      "epoch: 8 step: 1304, loss is 0.0013011805713176727\n",
      "epoch: 8 step: 1305, loss is 0.0009744382696226239\n",
      "epoch: 8 step: 1306, loss is 0.013489007018506527\n",
      "epoch: 8 step: 1307, loss is 0.00016883463831618428\n",
      "epoch: 8 step: 1308, loss is 0.012279273942112923\n",
      "epoch: 8 step: 1309, loss is 1.8804677893058397e-05\n",
      "epoch: 8 step: 1310, loss is 0.0018587782979011536\n",
      "epoch: 8 step: 1311, loss is 0.17350473999977112\n",
      "epoch: 8 step: 1312, loss is 0.12462400645017624\n",
      "epoch: 8 step: 1313, loss is 0.0025936325546354055\n",
      "epoch: 8 step: 1314, loss is 0.016307855024933815\n",
      "epoch: 8 step: 1315, loss is 0.0027433393988758326\n",
      "epoch: 8 step: 1316, loss is 0.0032179271802306175\n",
      "epoch: 8 step: 1317, loss is 0.00013400634634308517\n",
      "epoch: 8 step: 1318, loss is 0.0009498699801042676\n",
      "epoch: 8 step: 1319, loss is 0.0006752854096703231\n",
      "epoch: 8 step: 1320, loss is 0.00286464998498559\n",
      "epoch: 8 step: 1321, loss is 0.000793228973634541\n",
      "epoch: 8 step: 1322, loss is 0.0022048288956284523\n",
      "epoch: 8 step: 1323, loss is 0.0020917647052556276\n",
      "epoch: 8 step: 1324, loss is 0.0009452109807170928\n",
      "epoch: 8 step: 1325, loss is 0.0005594220128841698\n",
      "epoch: 8 step: 1326, loss is 0.0039657652378082275\n",
      "epoch: 8 step: 1327, loss is 0.0005570616922341287\n",
      "epoch: 8 step: 1328, loss is 0.005674073006957769\n",
      "epoch: 8 step: 1329, loss is 0.00027891420177184045\n",
      "epoch: 8 step: 1330, loss is 0.04115757346153259\n",
      "epoch: 8 step: 1331, loss is 0.0013598700752481818\n",
      "epoch: 8 step: 1332, loss is 0.0019814097322523594\n",
      "epoch: 8 step: 1333, loss is 0.005206233821809292\n",
      "epoch: 8 step: 1334, loss is 0.01987900584936142\n",
      "epoch: 8 step: 1335, loss is 0.003041960531845689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1336, loss is 0.0034637730568647385\n",
      "epoch: 8 step: 1337, loss is 0.00020494908676482737\n",
      "epoch: 8 step: 1338, loss is 0.007787935435771942\n",
      "epoch: 8 step: 1339, loss is 0.023600107058882713\n",
      "epoch: 8 step: 1340, loss is 0.0008077427628450096\n",
      "epoch: 8 step: 1341, loss is 0.000144757199450396\n",
      "epoch: 8 step: 1342, loss is 0.01700347103178501\n",
      "epoch: 8 step: 1343, loss is 0.00030168212833814323\n",
      "epoch: 8 step: 1344, loss is 0.0010357239516451955\n",
      "epoch: 8 step: 1345, loss is 0.014804075472056866\n",
      "epoch: 8 step: 1346, loss is 0.0024145874194800854\n",
      "epoch: 8 step: 1347, loss is 7.128831384761725e-06\n",
      "epoch: 8 step: 1348, loss is 0.0005455594509840012\n",
      "epoch: 8 step: 1349, loss is 0.00012826075544580817\n",
      "epoch: 8 step: 1350, loss is 0.00020865298574790359\n",
      "epoch: 8 step: 1351, loss is 0.0007172783371061087\n",
      "epoch: 8 step: 1352, loss is 0.0016345266485586762\n",
      "epoch: 8 step: 1353, loss is 0.0006579512264579535\n",
      "epoch: 8 step: 1354, loss is 0.0005499114631675184\n",
      "epoch: 8 step: 1355, loss is 0.004868749529123306\n",
      "epoch: 8 step: 1356, loss is 0.00023624161258339882\n",
      "epoch: 8 step: 1357, loss is 0.00020356752793304622\n",
      "epoch: 8 step: 1358, loss is 0.008544949814677238\n",
      "epoch: 8 step: 1359, loss is 0.00012972876720596105\n",
      "epoch: 8 step: 1360, loss is 4.291058939998038e-05\n",
      "epoch: 8 step: 1361, loss is 0.006935570389032364\n",
      "epoch: 8 step: 1362, loss is 0.06311613321304321\n",
      "epoch: 8 step: 1363, loss is 0.0002468283346388489\n",
      "epoch: 8 step: 1364, loss is 7.0525573391933e-05\n",
      "epoch: 8 step: 1365, loss is 5.83414439461194e-05\n",
      "epoch: 8 step: 1366, loss is 0.025540560483932495\n",
      "epoch: 8 step: 1367, loss is 0.0003438870480749756\n",
      "epoch: 8 step: 1368, loss is 0.0027121754828840494\n",
      "epoch: 8 step: 1369, loss is 4.378927769721486e-05\n",
      "epoch: 8 step: 1370, loss is 0.0008679940947331488\n",
      "epoch: 8 step: 1371, loss is 0.01771606132388115\n",
      "epoch: 8 step: 1372, loss is 0.12865717709064484\n",
      "epoch: 8 step: 1373, loss is 0.05303504317998886\n",
      "epoch: 8 step: 1374, loss is 5.8193254517391324e-05\n",
      "epoch: 8 step: 1375, loss is 0.030577925965189934\n",
      "epoch: 8 step: 1376, loss is 0.00360110797919333\n",
      "epoch: 8 step: 1377, loss is 0.0004416783631313592\n",
      "epoch: 8 step: 1378, loss is 0.07226775586605072\n",
      "epoch: 8 step: 1379, loss is 0.001056111534126103\n",
      "epoch: 8 step: 1380, loss is 0.00024406614829786122\n",
      "epoch: 8 step: 1381, loss is 0.06608593463897705\n",
      "epoch: 8 step: 1382, loss is 0.00036812934558838606\n",
      "epoch: 8 step: 1383, loss is 0.0005952226347289979\n",
      "epoch: 8 step: 1384, loss is 0.0020013561006635427\n",
      "epoch: 8 step: 1385, loss is 0.017947407439351082\n",
      "epoch: 8 step: 1386, loss is 5.203066029935144e-05\n",
      "epoch: 8 step: 1387, loss is 0.0347694456577301\n",
      "epoch: 8 step: 1388, loss is 0.00046365702291950583\n",
      "epoch: 8 step: 1389, loss is 0.014947522431612015\n",
      "epoch: 8 step: 1390, loss is 0.004489635117352009\n",
      "epoch: 8 step: 1391, loss is 0.044168226420879364\n",
      "epoch: 8 step: 1392, loss is 8.074565266724676e-05\n",
      "epoch: 8 step: 1393, loss is 1.0975293662340846e-05\n",
      "epoch: 8 step: 1394, loss is 0.014390656724572182\n",
      "epoch: 8 step: 1395, loss is 0.000269196490989998\n",
      "epoch: 8 step: 1396, loss is 0.002980762394145131\n",
      "epoch: 8 step: 1397, loss is 0.0004172329790890217\n",
      "epoch: 8 step: 1398, loss is 0.025395454838871956\n",
      "epoch: 8 step: 1399, loss is 0.00055815459927544\n",
      "epoch: 8 step: 1400, loss is 0.0038681491278111935\n",
      "epoch: 8 step: 1401, loss is 0.0015867917099967599\n",
      "epoch: 8 step: 1402, loss is 0.00015578239981550723\n",
      "epoch: 8 step: 1403, loss is 0.00012257928028702736\n",
      "epoch: 8 step: 1404, loss is 0.0005031768814660609\n",
      "epoch: 8 step: 1405, loss is 0.028231486678123474\n",
      "epoch: 8 step: 1406, loss is 9.905973456625361e-06\n",
      "epoch: 8 step: 1407, loss is 0.0004162178374826908\n",
      "epoch: 8 step: 1408, loss is 0.027428966015577316\n",
      "epoch: 8 step: 1409, loss is 0.001891377498395741\n",
      "epoch: 8 step: 1410, loss is 0.0017793040024116635\n",
      "epoch: 8 step: 1411, loss is 0.00020532688358798623\n",
      "epoch: 8 step: 1412, loss is 0.015853343531489372\n",
      "epoch: 8 step: 1413, loss is 3.605572055676021e-05\n",
      "epoch: 8 step: 1414, loss is 0.00022980070207268\n",
      "epoch: 8 step: 1415, loss is 0.0035835900343954563\n",
      "epoch: 8 step: 1416, loss is 9.542971383780241e-06\n",
      "epoch: 8 step: 1417, loss is 0.0005586667102761567\n",
      "epoch: 8 step: 1418, loss is 0.003822677070274949\n",
      "epoch: 8 step: 1419, loss is 0.044272471219301224\n",
      "epoch: 8 step: 1420, loss is 0.014073478057980537\n",
      "epoch: 8 step: 1421, loss is 0.019037025049328804\n",
      "epoch: 8 step: 1422, loss is 0.001101078581996262\n",
      "epoch: 8 step: 1423, loss is 2.904814937210176e-05\n",
      "epoch: 8 step: 1424, loss is 0.0003003160236403346\n",
      "epoch: 8 step: 1425, loss is 0.00815983209758997\n",
      "epoch: 8 step: 1426, loss is 0.00022925835219211876\n",
      "epoch: 8 step: 1427, loss is 8.705290383659303e-05\n",
      "epoch: 8 step: 1428, loss is 0.0005338227492757142\n",
      "epoch: 8 step: 1429, loss is 1.485549637436634e-05\n",
      "epoch: 8 step: 1430, loss is 0.0010010272962972522\n",
      "epoch: 8 step: 1431, loss is 0.004456025548279285\n",
      "epoch: 8 step: 1432, loss is 0.00018652727885637432\n",
      "epoch: 8 step: 1433, loss is 0.0019881739281117916\n",
      "epoch: 8 step: 1434, loss is 0.0004845932126045227\n",
      "epoch: 8 step: 1435, loss is 0.051676250994205475\n",
      "epoch: 8 step: 1436, loss is 2.0066730940015987e-05\n",
      "epoch: 8 step: 1437, loss is 9.567898086970672e-05\n",
      "epoch: 8 step: 1438, loss is 0.051567476242780685\n",
      "epoch: 8 step: 1439, loss is 0.00026169224292971194\n",
      "epoch: 8 step: 1440, loss is 0.0007024580845609307\n",
      "epoch: 8 step: 1441, loss is 0.000413645087974146\n",
      "epoch: 8 step: 1442, loss is 0.001601533847860992\n",
      "epoch: 8 step: 1443, loss is 0.033441562205553055\n",
      "epoch: 8 step: 1444, loss is 0.0021045852918177843\n",
      "epoch: 8 step: 1445, loss is 0.0006631853757426143\n",
      "epoch: 8 step: 1446, loss is 0.002657047938555479\n",
      "epoch: 8 step: 1447, loss is 4.592572076944634e-05\n",
      "epoch: 8 step: 1448, loss is 0.009858694858849049\n",
      "epoch: 8 step: 1449, loss is 0.00028093025321140885\n",
      "epoch: 8 step: 1450, loss is 0.05792774260044098\n",
      "epoch: 8 step: 1451, loss is 0.0003502689069136977\n",
      "epoch: 8 step: 1452, loss is 0.056260861456394196\n",
      "epoch: 8 step: 1453, loss is 0.0007416150765493512\n",
      "epoch: 8 step: 1454, loss is 0.0001927601551869884\n",
      "epoch: 8 step: 1455, loss is 3.578723772079684e-05\n",
      "epoch: 8 step: 1456, loss is 0.21330124139785767\n",
      "epoch: 8 step: 1457, loss is 3.0082333978498355e-05\n",
      "epoch: 8 step: 1458, loss is 7.030158303678036e-05\n",
      "epoch: 8 step: 1459, loss is 0.0001638359244680032\n",
      "epoch: 8 step: 1460, loss is 0.0016093768645077944\n",
      "epoch: 8 step: 1461, loss is 0.0023219825234264135\n",
      "epoch: 8 step: 1462, loss is 0.0011663454351946712\n",
      "epoch: 8 step: 1463, loss is 0.00436442531645298\n",
      "epoch: 8 step: 1464, loss is 0.0028761422727257013\n",
      "epoch: 8 step: 1465, loss is 0.02946152724325657\n",
      "epoch: 8 step: 1466, loss is 0.016452202573418617\n",
      "epoch: 8 step: 1467, loss is 0.00034294382203370333\n",
      "epoch: 8 step: 1468, loss is 0.3003677427768707\n",
      "epoch: 8 step: 1469, loss is 0.03432886675000191\n",
      "epoch: 8 step: 1470, loss is 0.00037724943831562996\n",
      "epoch: 8 step: 1471, loss is 0.025163929909467697\n",
      "epoch: 8 step: 1472, loss is 0.00980758760124445\n",
      "epoch: 8 step: 1473, loss is 0.0014729825779795647\n",
      "epoch: 8 step: 1474, loss is 0.005447018891572952\n",
      "epoch: 8 step: 1475, loss is 0.0028692660853266716\n",
      "epoch: 8 step: 1476, loss is 4.007857569376938e-05\n",
      "epoch: 8 step: 1477, loss is 0.0006850628415122628\n",
      "epoch: 8 step: 1478, loss is 0.0006348511669784784\n",
      "epoch: 8 step: 1479, loss is 0.0010943050729110837\n",
      "epoch: 8 step: 1480, loss is 0.031108643859624863\n",
      "epoch: 8 step: 1481, loss is 0.00045108768972568214\n",
      "epoch: 8 step: 1482, loss is 0.05179458484053612\n",
      "epoch: 8 step: 1483, loss is 0.005495999939739704\n",
      "epoch: 8 step: 1484, loss is 0.002922060200944543\n",
      "epoch: 8 step: 1485, loss is 0.005192618351429701\n",
      "epoch: 8 step: 1486, loss is 0.00016804189363028854\n",
      "epoch: 8 step: 1487, loss is 0.11330900341272354\n",
      "epoch: 8 step: 1488, loss is 8.243927732110023e-05\n",
      "epoch: 8 step: 1489, loss is 0.01590581238269806\n",
      "epoch: 8 step: 1490, loss is 0.11630526930093765\n",
      "epoch: 8 step: 1491, loss is 0.0004629494796972722\n",
      "epoch: 8 step: 1492, loss is 0.015388068743050098\n",
      "epoch: 8 step: 1493, loss is 0.00023546699958387762\n",
      "epoch: 8 step: 1494, loss is 0.004390587564557791\n",
      "epoch: 8 step: 1495, loss is 0.01660097949206829\n",
      "epoch: 8 step: 1496, loss is 0.003909670282155275\n",
      "epoch: 8 step: 1497, loss is 0.009572146460413933\n",
      "epoch: 8 step: 1498, loss is 0.10510143637657166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1499, loss is 0.00024454412050545216\n",
      "epoch: 8 step: 1500, loss is 0.009093568660318851\n",
      "epoch: 8 step: 1501, loss is 0.0014155165990814567\n",
      "epoch: 8 step: 1502, loss is 0.009336697869002819\n",
      "epoch: 8 step: 1503, loss is 0.010370484553277493\n",
      "epoch: 8 step: 1504, loss is 0.0010200536344200373\n",
      "epoch: 8 step: 1505, loss is 0.0314926914870739\n",
      "epoch: 8 step: 1506, loss is 3.942625698982738e-05\n",
      "epoch: 8 step: 1507, loss is 0.00806478876620531\n",
      "epoch: 8 step: 1508, loss is 0.0010508957784622908\n",
      "epoch: 8 step: 1509, loss is 0.00016468421381432563\n",
      "epoch: 8 step: 1510, loss is 0.00013239319378044456\n",
      "epoch: 8 step: 1511, loss is 2.9688302674912848e-05\n",
      "epoch: 8 step: 1512, loss is 0.00020104508439544588\n",
      "epoch: 8 step: 1513, loss is 0.00042238071910105646\n",
      "epoch: 8 step: 1514, loss is 0.017721230164170265\n",
      "epoch: 8 step: 1515, loss is 2.215893800894264e-05\n",
      "epoch: 8 step: 1516, loss is 0.06482192128896713\n",
      "epoch: 8 step: 1517, loss is 0.002459299750626087\n",
      "epoch: 8 step: 1518, loss is 0.16522715985774994\n",
      "epoch: 8 step: 1519, loss is 2.941200182249304e-05\n",
      "epoch: 8 step: 1520, loss is 0.0005452540935948491\n",
      "epoch: 8 step: 1521, loss is 0.000641435501165688\n",
      "epoch: 8 step: 1522, loss is 0.002016960410401225\n",
      "epoch: 8 step: 1523, loss is 0.0017172006191685796\n",
      "epoch: 8 step: 1524, loss is 0.0019258278189226985\n",
      "epoch: 8 step: 1525, loss is 3.180954809067771e-05\n",
      "epoch: 8 step: 1526, loss is 0.00228351098485291\n",
      "epoch: 8 step: 1527, loss is 0.001277290633879602\n",
      "epoch: 8 step: 1528, loss is 1.7625847249291837e-05\n",
      "epoch: 8 step: 1529, loss is 0.00317854480817914\n",
      "epoch: 8 step: 1530, loss is 0.0018430392956361175\n",
      "epoch: 8 step: 1531, loss is 9.080409654416144e-05\n",
      "epoch: 8 step: 1532, loss is 0.0007494014571420848\n",
      "epoch: 8 step: 1533, loss is 0.00010164110426558182\n",
      "epoch: 8 step: 1534, loss is 4.168043233221397e-05\n",
      "epoch: 8 step: 1535, loss is 0.09570983797311783\n",
      "epoch: 8 step: 1536, loss is 0.012262123636901379\n",
      "epoch: 8 step: 1537, loss is 0.008511846885085106\n",
      "epoch: 8 step: 1538, loss is 0.04398130252957344\n",
      "epoch: 8 step: 1539, loss is 0.11924061179161072\n",
      "epoch: 8 step: 1540, loss is 0.0013088297564536333\n",
      "epoch: 8 step: 1541, loss is 0.0010941711952909827\n",
      "epoch: 8 step: 1542, loss is 0.010748184286057949\n",
      "epoch: 8 step: 1543, loss is 6.421531725209206e-05\n",
      "epoch: 8 step: 1544, loss is 0.03298376873135567\n",
      "epoch: 8 step: 1545, loss is 0.020055649802088737\n",
      "epoch: 8 step: 1546, loss is 0.2209225445985794\n",
      "epoch: 8 step: 1547, loss is 3.1278083042707294e-05\n",
      "epoch: 8 step: 1548, loss is 0.1603054702281952\n",
      "epoch: 8 step: 1549, loss is 0.003243554849177599\n",
      "epoch: 8 step: 1550, loss is 0.0007662464631721377\n",
      "epoch: 8 step: 1551, loss is 0.026037180796265602\n",
      "epoch: 8 step: 1552, loss is 0.005197648890316486\n",
      "epoch: 8 step: 1553, loss is 0.00029386411188170314\n",
      "epoch: 8 step: 1554, loss is 0.0003634549502748996\n",
      "epoch: 8 step: 1555, loss is 0.0039488147012889385\n",
      "epoch: 8 step: 1556, loss is 0.060954827815294266\n",
      "epoch: 8 step: 1557, loss is 0.00033361013629473746\n",
      "epoch: 8 step: 1558, loss is 0.00026364965015091\n",
      "epoch: 8 step: 1559, loss is 0.037733159959316254\n",
      "epoch: 8 step: 1560, loss is 0.030241921544075012\n",
      "epoch: 8 step: 1561, loss is 0.007076778449118137\n",
      "epoch: 8 step: 1562, loss is 0.001567131606861949\n",
      "epoch: 8 step: 1563, loss is 0.0746224895119667\n",
      "epoch: 8 step: 1564, loss is 0.0004412689304444939\n",
      "epoch: 8 step: 1565, loss is 0.002584298374131322\n",
      "epoch: 8 step: 1566, loss is 0.0017336858436465263\n",
      "epoch: 8 step: 1567, loss is 0.01380041055381298\n",
      "epoch: 8 step: 1568, loss is 0.018477842211723328\n",
      "epoch: 8 step: 1569, loss is 0.0004218930844217539\n",
      "epoch: 8 step: 1570, loss is 0.009894239716231823\n",
      "epoch: 8 step: 1571, loss is 0.000330545095494017\n",
      "epoch: 8 step: 1572, loss is 0.008865856565535069\n",
      "epoch: 8 step: 1573, loss is 0.002955604810267687\n",
      "epoch: 8 step: 1574, loss is 0.00021908702910877764\n",
      "epoch: 8 step: 1575, loss is 0.008100800216197968\n",
      "epoch: 8 step: 1576, loss is 0.020215503871440887\n",
      "epoch: 8 step: 1577, loss is 0.04348244145512581\n",
      "epoch: 8 step: 1578, loss is 0.4281454086303711\n",
      "epoch: 8 step: 1579, loss is 0.005193638615310192\n",
      "epoch: 8 step: 1580, loss is 0.01431211456656456\n",
      "epoch: 8 step: 1581, loss is 0.006457851734012365\n",
      "epoch: 8 step: 1582, loss is 0.0038057726342231035\n",
      "epoch: 8 step: 1583, loss is 0.008627582341432571\n",
      "epoch: 8 step: 1584, loss is 0.13838998973369598\n",
      "epoch: 8 step: 1585, loss is 0.007490303833037615\n",
      "epoch: 8 step: 1586, loss is 0.0015610507689416409\n",
      "epoch: 8 step: 1587, loss is 0.003901083255186677\n",
      "epoch: 8 step: 1588, loss is 0.0025581917725503445\n",
      "epoch: 8 step: 1589, loss is 0.005177872721105814\n",
      "epoch: 8 step: 1590, loss is 7.56717927288264e-05\n",
      "epoch: 8 step: 1591, loss is 0.0651632696390152\n",
      "epoch: 8 step: 1592, loss is 0.0027019537519663572\n",
      "epoch: 8 step: 1593, loss is 0.0011366670951247215\n",
      "epoch: 8 step: 1594, loss is 0.0005336253670975566\n",
      "epoch: 8 step: 1595, loss is 0.00047906459076330066\n",
      "epoch: 8 step: 1596, loss is 0.0017653040122240782\n",
      "epoch: 8 step: 1597, loss is 0.0002471180632710457\n",
      "epoch: 8 step: 1598, loss is 0.0001313739048782736\n",
      "epoch: 8 step: 1599, loss is 0.0025249093305319548\n",
      "epoch: 8 step: 1600, loss is 0.0006386601598933339\n",
      "epoch: 8 step: 1601, loss is 0.00021895584359299392\n",
      "epoch: 8 step: 1602, loss is 0.001515777432359755\n",
      "epoch: 8 step: 1603, loss is 0.0003335059736855328\n",
      "epoch: 8 step: 1604, loss is 0.2569040060043335\n",
      "epoch: 8 step: 1605, loss is 0.0005047564627602696\n",
      "epoch: 8 step: 1606, loss is 0.0010631547775119543\n",
      "epoch: 8 step: 1607, loss is 0.018268268555402756\n",
      "epoch: 8 step: 1608, loss is 0.0073048705235123634\n",
      "epoch: 8 step: 1609, loss is 0.019374089315533638\n",
      "epoch: 8 step: 1610, loss is 2.721698911045678e-05\n",
      "epoch: 8 step: 1611, loss is 0.0004139925877097994\n",
      "epoch: 8 step: 1612, loss is 8.086178422672674e-05\n",
      "epoch: 8 step: 1613, loss is 2.526263597246725e-05\n",
      "epoch: 8 step: 1614, loss is 0.0005167233175598085\n",
      "epoch: 8 step: 1615, loss is 0.0035933791659772396\n",
      "epoch: 8 step: 1616, loss is 0.0006908088107593358\n",
      "epoch: 8 step: 1617, loss is 0.0071335844695568085\n",
      "epoch: 8 step: 1618, loss is 0.000136401824420318\n",
      "epoch: 8 step: 1619, loss is 0.007070245686918497\n",
      "epoch: 8 step: 1620, loss is 0.0007895772578194737\n",
      "epoch: 8 step: 1621, loss is 0.03601504862308502\n",
      "epoch: 8 step: 1622, loss is 0.01822073571383953\n",
      "epoch: 8 step: 1623, loss is 0.00018880852439906448\n",
      "epoch: 8 step: 1624, loss is 0.01746705174446106\n",
      "epoch: 8 step: 1625, loss is 0.00027314337785355747\n",
      "epoch: 8 step: 1626, loss is 0.001529822126030922\n",
      "epoch: 8 step: 1627, loss is 0.0004365253262221813\n",
      "epoch: 8 step: 1628, loss is 0.08152755349874496\n",
      "epoch: 8 step: 1629, loss is 0.017460908740758896\n",
      "epoch: 8 step: 1630, loss is 0.006943184416741133\n",
      "epoch: 8 step: 1631, loss is 0.0011779459891840816\n",
      "epoch: 8 step: 1632, loss is 0.001120277913287282\n",
      "epoch: 8 step: 1633, loss is 0.011341127566993237\n",
      "epoch: 8 step: 1634, loss is 0.00018948945216834545\n",
      "epoch: 8 step: 1635, loss is 0.013131897896528244\n",
      "epoch: 8 step: 1636, loss is 0.007213858421891928\n",
      "epoch: 8 step: 1637, loss is 0.0003585604135878384\n",
      "epoch: 8 step: 1638, loss is 0.021009355783462524\n",
      "epoch: 8 step: 1639, loss is 0.002562736626714468\n",
      "epoch: 8 step: 1640, loss is 0.0009454097598791122\n",
      "epoch: 8 step: 1641, loss is 0.0008196213748306036\n",
      "epoch: 8 step: 1642, loss is 0.001394541934132576\n",
      "epoch: 8 step: 1643, loss is 0.00034873015829361975\n",
      "epoch: 8 step: 1644, loss is 0.00017163011943921447\n",
      "epoch: 8 step: 1645, loss is 2.6462425012141466e-05\n",
      "epoch: 8 step: 1646, loss is 0.00281973066739738\n",
      "epoch: 8 step: 1647, loss is 0.0006982845370657742\n",
      "epoch: 8 step: 1648, loss is 0.013447635807096958\n",
      "epoch: 8 step: 1649, loss is 0.00296301138587296\n",
      "epoch: 8 step: 1650, loss is 0.0006319585372693837\n",
      "epoch: 8 step: 1651, loss is 0.007717860862612724\n",
      "epoch: 8 step: 1652, loss is 0.002957744523882866\n",
      "epoch: 8 step: 1653, loss is 0.0001908647536765784\n",
      "epoch: 8 step: 1654, loss is 0.0017171381041407585\n",
      "epoch: 8 step: 1655, loss is 3.8208399928407744e-05\n",
      "epoch: 8 step: 1656, loss is 0.17806097865104675\n",
      "epoch: 8 step: 1657, loss is 0.004505659453570843\n",
      "epoch: 8 step: 1658, loss is 8.85731351445429e-05\n",
      "epoch: 8 step: 1659, loss is 0.004025245551019907\n",
      "epoch: 8 step: 1660, loss is 0.006694809999316931\n",
      "epoch: 8 step: 1661, loss is 0.001351440791040659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1662, loss is 0.005450048018246889\n",
      "epoch: 8 step: 1663, loss is 1.48385479405988e-05\n",
      "epoch: 8 step: 1664, loss is 0.00028422579634934664\n",
      "epoch: 8 step: 1665, loss is 0.0031740600243210793\n",
      "epoch: 8 step: 1666, loss is 0.0003666484262794256\n",
      "epoch: 8 step: 1667, loss is 0.019223321229219437\n",
      "epoch: 8 step: 1668, loss is 0.002564972499385476\n",
      "epoch: 8 step: 1669, loss is 0.0365091934800148\n",
      "epoch: 8 step: 1670, loss is 0.022151483222842216\n",
      "epoch: 8 step: 1671, loss is 0.12442047148942947\n",
      "epoch: 8 step: 1672, loss is 0.013022453524172306\n",
      "epoch: 8 step: 1673, loss is 5.081420385977253e-05\n",
      "epoch: 8 step: 1674, loss is 0.002562687499448657\n",
      "epoch: 8 step: 1675, loss is 0.005321758799254894\n",
      "epoch: 8 step: 1676, loss is 0.0007242219871841371\n",
      "epoch: 8 step: 1677, loss is 0.005325745325535536\n",
      "epoch: 8 step: 1678, loss is 0.0025492303539067507\n",
      "epoch: 8 step: 1679, loss is 0.0004234377120155841\n",
      "epoch: 8 step: 1680, loss is 3.5947170545114204e-05\n",
      "epoch: 8 step: 1681, loss is 0.00023587221221532673\n",
      "epoch: 8 step: 1682, loss is 0.00012118097947677597\n",
      "epoch: 8 step: 1683, loss is 0.0027122360188513994\n",
      "epoch: 8 step: 1684, loss is 0.0005727945826947689\n",
      "epoch: 8 step: 1685, loss is 0.0003209113492630422\n",
      "epoch: 8 step: 1686, loss is 0.013823088258504868\n",
      "epoch: 8 step: 1687, loss is 0.000853748235385865\n",
      "epoch: 8 step: 1688, loss is 0.05987144261598587\n",
      "epoch: 8 step: 1689, loss is 1.259573946299497e-05\n",
      "epoch: 8 step: 1690, loss is 0.0023761906195431948\n",
      "epoch: 8 step: 1691, loss is 0.0012126812944188714\n",
      "epoch: 8 step: 1692, loss is 0.09987064450979233\n",
      "epoch: 8 step: 1693, loss is 0.03670435771346092\n",
      "epoch: 8 step: 1694, loss is 0.04990896210074425\n",
      "epoch: 8 step: 1695, loss is 0.00038611385389231145\n",
      "epoch: 8 step: 1696, loss is 0.018049389123916626\n",
      "epoch: 8 step: 1697, loss is 0.05075410380959511\n",
      "epoch: 8 step: 1698, loss is 0.0002958876430056989\n",
      "epoch: 8 step: 1699, loss is 0.0011341585777699947\n",
      "epoch: 8 step: 1700, loss is 0.002470843493938446\n",
      "epoch: 8 step: 1701, loss is 0.0003886024933308363\n",
      "epoch: 8 step: 1702, loss is 0.011968596838414669\n",
      "epoch: 8 step: 1703, loss is 0.0031254568602889776\n",
      "epoch: 8 step: 1704, loss is 0.015510240569710732\n",
      "epoch: 8 step: 1705, loss is 0.00018195979646407068\n",
      "epoch: 8 step: 1706, loss is 0.004162830300629139\n",
      "epoch: 8 step: 1707, loss is 4.514297324931249e-05\n",
      "epoch: 8 step: 1708, loss is 0.030153751373291016\n",
      "epoch: 8 step: 1709, loss is 0.0008067049202509224\n",
      "epoch: 8 step: 1710, loss is 0.00030903550214134157\n",
      "epoch: 8 step: 1711, loss is 0.00019294345111120492\n",
      "epoch: 8 step: 1712, loss is 0.0030896137468516827\n",
      "epoch: 8 step: 1713, loss is 0.00032312353141605854\n",
      "epoch: 8 step: 1714, loss is 0.010537715628743172\n",
      "epoch: 8 step: 1715, loss is 0.0013364930637180805\n",
      "epoch: 8 step: 1716, loss is 0.08775709569454193\n",
      "epoch: 8 step: 1717, loss is 0.046443141996860504\n",
      "epoch: 8 step: 1718, loss is 0.024813363328576088\n",
      "epoch: 8 step: 1719, loss is 0.2633734345436096\n",
      "epoch: 8 step: 1720, loss is 0.00014749958063475788\n",
      "epoch: 8 step: 1721, loss is 0.06859522312879562\n",
      "epoch: 8 step: 1722, loss is 0.0034426648635417223\n",
      "epoch: 8 step: 1723, loss is 0.0007089748978614807\n",
      "epoch: 8 step: 1724, loss is 0.04943213611841202\n",
      "epoch: 8 step: 1725, loss is 0.000295083416858688\n",
      "epoch: 8 step: 1726, loss is 0.00015050967340357602\n",
      "epoch: 8 step: 1727, loss is 0.0005802467348985374\n",
      "epoch: 8 step: 1728, loss is 0.00443677045404911\n",
      "epoch: 8 step: 1729, loss is 0.010331682860851288\n",
      "epoch: 8 step: 1730, loss is 0.003776881378144026\n",
      "epoch: 8 step: 1731, loss is 0.0008363552624359727\n",
      "epoch: 8 step: 1732, loss is 0.004228994250297546\n",
      "epoch: 8 step: 1733, loss is 0.0003427534829825163\n",
      "epoch: 8 step: 1734, loss is 0.002061730483546853\n",
      "epoch: 8 step: 1735, loss is 7.326180639211088e-05\n",
      "epoch: 8 step: 1736, loss is 0.013106622733175755\n",
      "epoch: 8 step: 1737, loss is 0.00250790873542428\n",
      "epoch: 8 step: 1738, loss is 0.005072310566902161\n",
      "epoch: 8 step: 1739, loss is 0.0035368776880204678\n",
      "epoch: 8 step: 1740, loss is 1.1951161468459759e-05\n",
      "epoch: 8 step: 1741, loss is 0.01021782960742712\n",
      "epoch: 8 step: 1742, loss is 0.002263000700622797\n",
      "epoch: 8 step: 1743, loss is 0.004737764596939087\n",
      "epoch: 8 step: 1744, loss is 0.004957388620823622\n",
      "epoch: 8 step: 1745, loss is 0.0001039105118252337\n",
      "epoch: 8 step: 1746, loss is 0.01523075345903635\n",
      "epoch: 8 step: 1747, loss is 0.0010501836659386754\n",
      "epoch: 8 step: 1748, loss is 0.0010630895849317312\n",
      "epoch: 8 step: 1749, loss is 0.0007206590962596238\n",
      "epoch: 8 step: 1750, loss is 0.0002331910509383306\n",
      "epoch: 8 step: 1751, loss is 0.017951758578419685\n",
      "epoch: 8 step: 1752, loss is 0.0003725843271240592\n",
      "epoch: 8 step: 1753, loss is 0.00047829741379246116\n",
      "epoch: 8 step: 1754, loss is 0.0013764894101768732\n",
      "epoch: 8 step: 1755, loss is 0.0363553985953331\n",
      "epoch: 8 step: 1756, loss is 0.044875066727399826\n",
      "epoch: 8 step: 1757, loss is 0.011447359807789326\n",
      "epoch: 8 step: 1758, loss is 0.00019374953990336508\n",
      "epoch: 8 step: 1759, loss is 0.028720613569021225\n",
      "epoch: 8 step: 1760, loss is 0.003227558685466647\n",
      "epoch: 8 step: 1761, loss is 8.764550875639543e-05\n",
      "epoch: 8 step: 1762, loss is 0.010586880147457123\n",
      "epoch: 8 step: 1763, loss is 0.014829105697572231\n",
      "epoch: 8 step: 1764, loss is 0.00023242278257384896\n",
      "epoch: 8 step: 1765, loss is 0.05121190473437309\n",
      "epoch: 8 step: 1766, loss is 0.008191103115677834\n",
      "epoch: 8 step: 1767, loss is 0.0004891303251497447\n",
      "epoch: 8 step: 1768, loss is 5.216106728767045e-05\n",
      "epoch: 8 step: 1769, loss is 0.04507812485098839\n",
      "epoch: 8 step: 1770, loss is 0.01868046261370182\n",
      "epoch: 8 step: 1771, loss is 0.000556267739739269\n",
      "epoch: 8 step: 1772, loss is 0.004884996451437473\n",
      "epoch: 8 step: 1773, loss is 0.07168872654438019\n",
      "epoch: 8 step: 1774, loss is 0.0007185359136201441\n",
      "epoch: 8 step: 1775, loss is 0.02396310120820999\n",
      "epoch: 8 step: 1776, loss is 4.688220360549167e-05\n",
      "epoch: 8 step: 1777, loss is 0.00879353005439043\n",
      "epoch: 8 step: 1778, loss is 0.00024846423184499145\n",
      "epoch: 8 step: 1779, loss is 0.000941199716180563\n",
      "epoch: 8 step: 1780, loss is 0.0017947221640497446\n",
      "epoch: 8 step: 1781, loss is 0.00954983476549387\n",
      "epoch: 8 step: 1782, loss is 6.863580347271636e-05\n",
      "epoch: 8 step: 1783, loss is 0.09189164638519287\n",
      "epoch: 8 step: 1784, loss is 0.0003523936029523611\n",
      "epoch: 8 step: 1785, loss is 0.017901021987199783\n",
      "epoch: 8 step: 1786, loss is 0.0002950729976873845\n",
      "epoch: 8 step: 1787, loss is 0.0023614305537194014\n",
      "epoch: 8 step: 1788, loss is 0.00244374037720263\n",
      "epoch: 8 step: 1789, loss is 0.05155935138463974\n",
      "epoch: 8 step: 1790, loss is 0.00019500475900713354\n",
      "epoch: 8 step: 1791, loss is 0.000159753137268126\n",
      "epoch: 8 step: 1792, loss is 0.0028386812191456556\n",
      "epoch: 8 step: 1793, loss is 3.122477210126817e-05\n",
      "epoch: 8 step: 1794, loss is 5.399941801442765e-05\n",
      "epoch: 8 step: 1795, loss is 0.006810375954955816\n",
      "epoch: 8 step: 1796, loss is 6.802775169489905e-05\n",
      "epoch: 8 step: 1797, loss is 0.000683894322719425\n",
      "epoch: 8 step: 1798, loss is 0.0002123540180036798\n",
      "epoch: 8 step: 1799, loss is 0.0003068398800678551\n",
      "epoch: 8 step: 1800, loss is 0.00980474054813385\n",
      "epoch: 8 step: 1801, loss is 0.014717398211359978\n",
      "epoch: 8 step: 1802, loss is 0.00019738395349122584\n",
      "epoch: 8 step: 1803, loss is 0.0003044740005861968\n",
      "epoch: 8 step: 1804, loss is 0.0003956671862397343\n",
      "epoch: 8 step: 1805, loss is 0.22303010523319244\n",
      "epoch: 8 step: 1806, loss is 0.000847373332362622\n",
      "epoch: 8 step: 1807, loss is 0.0009681283263489604\n",
      "epoch: 8 step: 1808, loss is 0.0004600185784511268\n",
      "epoch: 8 step: 1809, loss is 2.01754410227295e-05\n",
      "epoch: 8 step: 1810, loss is 0.08216764032840729\n",
      "epoch: 8 step: 1811, loss is 5.8606325183063745e-05\n",
      "epoch: 8 step: 1812, loss is 0.02034137398004532\n",
      "epoch: 8 step: 1813, loss is 0.0019366105552762747\n",
      "epoch: 8 step: 1814, loss is 0.0005790835712105036\n",
      "epoch: 8 step: 1815, loss is 6.516480061691254e-05\n",
      "epoch: 8 step: 1816, loss is 0.0001356688590021804\n",
      "epoch: 8 step: 1817, loss is 1.9942361177527346e-05\n",
      "epoch: 8 step: 1818, loss is 0.0008117867400869727\n",
      "epoch: 8 step: 1819, loss is 0.0001089691577362828\n",
      "epoch: 8 step: 1820, loss is 0.0022504900116473436\n",
      "epoch: 8 step: 1821, loss is 0.00024593828129582107\n",
      "epoch: 8 step: 1822, loss is 0.00046379328705370426\n",
      "epoch: 8 step: 1823, loss is 2.522622889955528e-05\n",
      "epoch: 8 step: 1824, loss is 0.0006713189650326967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1825, loss is 0.02087157592177391\n",
      "epoch: 8 step: 1826, loss is 4.108864959562197e-05\n",
      "epoch: 8 step: 1827, loss is 1.2379678992147092e-05\n",
      "epoch: 8 step: 1828, loss is 0.02915564365684986\n",
      "epoch: 8 step: 1829, loss is 0.06915941834449768\n",
      "epoch: 8 step: 1830, loss is 0.0016516773030161858\n",
      "epoch: 8 step: 1831, loss is 0.001271235872991383\n",
      "epoch: 8 step: 1832, loss is 0.2239920049905777\n",
      "epoch: 8 step: 1833, loss is 0.0013736551627516747\n",
      "epoch: 8 step: 1834, loss is 0.0005487115122377872\n",
      "epoch: 8 step: 1835, loss is 0.10613226890563965\n",
      "epoch: 8 step: 1836, loss is 2.948474866570905e-05\n",
      "epoch: 8 step: 1837, loss is 0.00805068202316761\n",
      "epoch: 8 step: 1838, loss is 0.0007311654626391828\n",
      "epoch: 8 step: 1839, loss is 0.022004472091794014\n",
      "epoch: 8 step: 1840, loss is 0.015997543931007385\n",
      "epoch: 8 step: 1841, loss is 0.0013866833178326488\n",
      "epoch: 8 step: 1842, loss is 0.010548226535320282\n",
      "epoch: 8 step: 1843, loss is 0.049275562167167664\n",
      "epoch: 8 step: 1844, loss is 0.01541865523904562\n",
      "epoch: 8 step: 1845, loss is 0.03329959884285927\n",
      "epoch: 8 step: 1846, loss is 0.0006032490637153387\n",
      "epoch: 8 step: 1847, loss is 0.02739511802792549\n",
      "epoch: 8 step: 1848, loss is 0.000588498602155596\n",
      "epoch: 8 step: 1849, loss is 0.00010658262181095779\n",
      "epoch: 8 step: 1850, loss is 0.015607560984790325\n",
      "epoch: 8 step: 1851, loss is 0.13641603291034698\n",
      "epoch: 8 step: 1852, loss is 0.00039244414074346423\n",
      "epoch: 8 step: 1853, loss is 0.04911147058010101\n",
      "epoch: 8 step: 1854, loss is 3.941572504118085e-05\n",
      "epoch: 8 step: 1855, loss is 0.0010654942598193884\n",
      "epoch: 8 step: 1856, loss is 0.003310937900096178\n",
      "epoch: 8 step: 1857, loss is 0.0015405918238684535\n",
      "epoch: 8 step: 1858, loss is 0.004464765544980764\n",
      "epoch: 8 step: 1859, loss is 0.044709447771310806\n",
      "epoch: 8 step: 1860, loss is 0.001814632210880518\n",
      "epoch: 8 step: 1861, loss is 0.000884253007825464\n",
      "epoch: 8 step: 1862, loss is 0.0037560192868113518\n",
      "epoch: 8 step: 1863, loss is 0.3601166307926178\n",
      "epoch: 8 step: 1864, loss is 0.0001455244782846421\n",
      "epoch: 8 step: 1865, loss is 0.0004907372058369219\n",
      "epoch: 8 step: 1866, loss is 0.00016086209507193416\n",
      "epoch: 8 step: 1867, loss is 0.0007460025954060256\n",
      "epoch: 8 step: 1868, loss is 0.02985510602593422\n",
      "epoch: 8 step: 1869, loss is 0.0005428001168183982\n",
      "epoch: 8 step: 1870, loss is 0.04661932587623596\n",
      "epoch: 8 step: 1871, loss is 0.13438917696475983\n",
      "epoch: 8 step: 1872, loss is 0.031008629128336906\n",
      "epoch: 8 step: 1873, loss is 0.0005901188123971224\n",
      "epoch: 8 step: 1874, loss is 0.00016836806025821716\n",
      "epoch: 8 step: 1875, loss is 0.00017637629935052246\n",
      "epoch: 8 step: 1876, loss is 0.00020877955830655992\n",
      "epoch: 8 step: 1877, loss is 0.030406301841139793\n",
      "epoch: 8 step: 1878, loss is 0.0029976465739309788\n",
      "epoch: 8 step: 1879, loss is 0.0006882539018988609\n",
      "epoch: 8 step: 1880, loss is 0.0004571453027892858\n",
      "epoch: 8 step: 1881, loss is 0.004271066281944513\n",
      "epoch: 8 step: 1882, loss is 0.0013293002266436815\n",
      "epoch: 8 step: 1883, loss is 0.00020363691146485507\n",
      "epoch: 8 step: 1884, loss is 0.05359626188874245\n",
      "epoch: 8 step: 1885, loss is 0.006544962525367737\n",
      "epoch: 8 step: 1886, loss is 0.001886869315057993\n",
      "epoch: 8 step: 1887, loss is 0.0076357703655958176\n",
      "epoch: 8 step: 1888, loss is 0.005130312405526638\n",
      "epoch: 8 step: 1889, loss is 0.002543159993365407\n",
      "epoch: 8 step: 1890, loss is 0.022694433107972145\n",
      "epoch: 8 step: 1891, loss is 0.061666715890169144\n",
      "epoch: 8 step: 1892, loss is 0.23533502221107483\n",
      "epoch: 8 step: 1893, loss is 0.005351498257368803\n",
      "epoch: 8 step: 1894, loss is 0.00024149479577317834\n",
      "epoch: 8 step: 1895, loss is 0.02914181537926197\n",
      "epoch: 8 step: 1896, loss is 2.3495511413784698e-05\n",
      "epoch: 8 step: 1897, loss is 0.00022936919413041323\n",
      "epoch: 8 step: 1898, loss is 0.0014292929554358125\n",
      "epoch: 8 step: 1899, loss is 0.09987226873636246\n",
      "epoch: 8 step: 1900, loss is 0.02050654962658882\n",
      "epoch: 8 step: 1901, loss is 0.04476298391819\n",
      "epoch: 8 step: 1902, loss is 0.07545533031225204\n",
      "epoch: 8 step: 1903, loss is 9.47598964557983e-05\n",
      "epoch: 8 step: 1904, loss is 0.07948774099349976\n",
      "epoch: 8 step: 1905, loss is 0.0019618715159595013\n",
      "epoch: 8 step: 1906, loss is 0.0009245484252460301\n",
      "epoch: 8 step: 1907, loss is 0.041131071746349335\n",
      "epoch: 8 step: 1908, loss is 0.02595640905201435\n",
      "epoch: 8 step: 1909, loss is 0.14247414469718933\n",
      "epoch: 8 step: 1910, loss is 0.00031503173522651196\n",
      "epoch: 8 step: 1911, loss is 0.04502434283494949\n",
      "epoch: 8 step: 1912, loss is 0.00029589131008833647\n",
      "epoch: 8 step: 1913, loss is 0.006399448495358229\n",
      "epoch: 8 step: 1914, loss is 0.012174170464277267\n",
      "epoch: 8 step: 1915, loss is 0.000350073300069198\n",
      "epoch: 8 step: 1916, loss is 0.00015554031415376812\n",
      "epoch: 8 step: 1917, loss is 0.0017921627731993794\n",
      "epoch: 8 step: 1918, loss is 0.06278763711452484\n",
      "epoch: 8 step: 1919, loss is 0.00019501270435284823\n",
      "epoch: 8 step: 1920, loss is 0.011153657920658588\n",
      "epoch: 8 step: 1921, loss is 0.00039907178143039346\n",
      "epoch: 8 step: 1922, loss is 0.03140074387192726\n",
      "epoch: 8 step: 1923, loss is 0.0003713949990924448\n",
      "epoch: 8 step: 1924, loss is 0.0009207829716615379\n",
      "epoch: 8 step: 1925, loss is 0.002941147657111287\n",
      "epoch: 8 step: 1926, loss is 0.000967974541708827\n",
      "epoch: 8 step: 1927, loss is 0.001790159847587347\n",
      "epoch: 8 step: 1928, loss is 0.05252275988459587\n",
      "epoch: 8 step: 1929, loss is 0.021426012739539146\n",
      "epoch: 8 step: 1930, loss is 0.004692378919571638\n",
      "epoch: 8 step: 1931, loss is 0.02106868289411068\n",
      "epoch: 8 step: 1932, loss is 0.07476833462715149\n",
      "epoch: 8 step: 1933, loss is 0.00035775190917775035\n",
      "epoch: 8 step: 1934, loss is 0.0071382890455424786\n",
      "epoch: 8 step: 1935, loss is 0.0004154552589170635\n",
      "epoch: 8 step: 1936, loss is 0.0037532011047005653\n",
      "epoch: 8 step: 1937, loss is 0.00012099170999135822\n",
      "epoch: 8 step: 1938, loss is 9.04533953871578e-06\n",
      "epoch: 8 step: 1939, loss is 0.002186998724937439\n",
      "epoch: 8 step: 1940, loss is 0.0015089581720530987\n",
      "epoch: 8 step: 1941, loss is 0.0001675644307397306\n",
      "epoch: 8 step: 1942, loss is 0.0036028637550771236\n",
      "epoch: 8 step: 1943, loss is 0.3121193051338196\n",
      "epoch: 8 step: 1944, loss is 0.00041304860496893525\n",
      "epoch: 8 step: 1945, loss is 0.0024050623178482056\n",
      "epoch: 8 step: 1946, loss is 0.0037805342581123114\n",
      "epoch: 8 step: 1947, loss is 0.00020233273971825838\n",
      "epoch: 8 step: 1948, loss is 4.2123254388570786e-05\n",
      "epoch: 8 step: 1949, loss is 0.004605581052601337\n",
      "epoch: 8 step: 1950, loss is 0.009883591905236244\n",
      "epoch: 8 step: 1951, loss is 0.0005491378251463175\n",
      "epoch: 8 step: 1952, loss is 0.0011915673967450857\n",
      "epoch: 8 step: 1953, loss is 3.3190859539899975e-05\n",
      "epoch: 8 step: 1954, loss is 0.005343714728951454\n",
      "epoch: 8 step: 1955, loss is 0.003972964361310005\n",
      "epoch: 8 step: 1956, loss is 0.03911199793219566\n",
      "epoch: 8 step: 1957, loss is 0.00019072197028435767\n",
      "epoch: 8 step: 1958, loss is 0.0005942968418821692\n",
      "epoch: 8 step: 1959, loss is 0.00026445367257110775\n",
      "epoch: 8 step: 1960, loss is 0.0018242101650685072\n",
      "epoch: 8 step: 1961, loss is 0.00023830399732105434\n",
      "epoch: 8 step: 1962, loss is 0.04011436924338341\n",
      "epoch: 8 step: 1963, loss is 0.022584596648812294\n",
      "epoch: 8 step: 1964, loss is 0.055606190115213394\n",
      "epoch: 8 step: 1965, loss is 8.93908945727162e-05\n",
      "epoch: 8 step: 1966, loss is 0.0002909271861426532\n",
      "epoch: 8 step: 1967, loss is 0.009596512652933598\n",
      "epoch: 8 step: 1968, loss is 0.035424549132585526\n",
      "epoch: 8 step: 1969, loss is 0.025580210611224174\n",
      "epoch: 8 step: 1970, loss is 0.0010423860512673855\n",
      "epoch: 8 step: 1971, loss is 0.06537369638681412\n",
      "epoch: 8 step: 1972, loss is 0.0006274127517826855\n",
      "epoch: 8 step: 1973, loss is 0.01311404723674059\n",
      "epoch: 8 step: 1974, loss is 0.003420008812099695\n",
      "epoch: 8 step: 1975, loss is 0.0009673826862126589\n",
      "epoch: 8 step: 1976, loss is 0.011701276525855064\n",
      "epoch: 8 step: 1977, loss is 0.03295193612575531\n",
      "epoch: 8 step: 1978, loss is 0.0006052806274965405\n",
      "epoch: 8 step: 1979, loss is 0.0002429717715131119\n",
      "epoch: 8 step: 1980, loss is 0.0007038134499453008\n",
      "epoch: 8 step: 1981, loss is 0.007310195825994015\n",
      "epoch: 8 step: 1982, loss is 0.0019165141275152564\n",
      "epoch: 8 step: 1983, loss is 0.025402994826436043\n",
      "epoch: 8 step: 1984, loss is 0.0014624092727899551\n",
      "epoch: 8 step: 1985, loss is 0.0006906449561938643\n",
      "epoch: 8 step: 1986, loss is 0.0020295120775699615\n",
      "epoch: 8 step: 1987, loss is 0.0031211315654218197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1988, loss is 0.007127983029931784\n",
      "epoch: 8 step: 1989, loss is 8.597604028182104e-05\n",
      "epoch: 8 step: 1990, loss is 0.004320589359849691\n",
      "epoch: 8 step: 1991, loss is 0.012340674176812172\n",
      "epoch: 8 step: 1992, loss is 0.00011524988076416776\n",
      "epoch: 8 step: 1993, loss is 0.03507809340953827\n",
      "epoch: 8 step: 1994, loss is 0.01741374470293522\n",
      "epoch: 8 step: 1995, loss is 0.00010452375136082992\n",
      "epoch: 8 step: 1996, loss is 0.0002704031066969037\n",
      "epoch: 8 step: 1997, loss is 1.2051674275426194e-05\n",
      "epoch: 8 step: 1998, loss is 0.0002687532687559724\n",
      "epoch: 8 step: 1999, loss is 0.0007145149284042418\n",
      "epoch: 8 step: 2000, loss is 0.008860844187438488\n",
      "epoch: 8 step: 2001, loss is 0.09905251115560532\n",
      "epoch: 8 step: 2002, loss is 0.015221036039292812\n",
      "epoch: 8 step: 2003, loss is 0.035424914211034775\n",
      "epoch: 8 step: 2004, loss is 0.12328691780567169\n",
      "epoch: 8 step: 2005, loss is 1.6503956430824474e-05\n",
      "epoch: 8 step: 2006, loss is 0.001999608241021633\n",
      "epoch: 8 step: 2007, loss is 0.010074064135551453\n",
      "epoch: 8 step: 2008, loss is 8.411810995312408e-05\n",
      "epoch: 8 step: 2009, loss is 7.07823783159256e-05\n",
      "epoch: 8 step: 2010, loss is 0.005555459763854742\n",
      "epoch: 8 step: 2011, loss is 0.00039725645910948515\n",
      "epoch: 8 step: 2012, loss is 0.004611106589436531\n",
      "epoch: 8 step: 2013, loss is 0.004567040596157312\n",
      "epoch: 8 step: 2014, loss is 0.0001798329467419535\n",
      "epoch: 8 step: 2015, loss is 0.0027723214589059353\n",
      "epoch: 8 step: 2016, loss is 6.573112477781251e-05\n",
      "epoch: 8 step: 2017, loss is 0.0004024494846817106\n",
      "epoch: 8 step: 2018, loss is 0.009908303618431091\n",
      "epoch: 8 step: 2019, loss is 0.000740395684260875\n",
      "epoch: 8 step: 2020, loss is 0.011420122347772121\n",
      "epoch: 8 step: 2021, loss is 0.022274192422628403\n",
      "epoch: 8 step: 2022, loss is 0.0014135647797957063\n",
      "epoch: 8 step: 2023, loss is 0.0019385218620300293\n",
      "epoch: 8 step: 2024, loss is 2.6686595447245054e-05\n",
      "epoch: 8 step: 2025, loss is 0.001255100010894239\n",
      "epoch: 8 step: 2026, loss is 0.01564321480691433\n",
      "epoch: 8 step: 2027, loss is 0.004927743226289749\n",
      "epoch: 8 step: 2028, loss is 0.00014394632307812572\n",
      "epoch: 8 step: 2029, loss is 0.00024664716329425573\n",
      "epoch: 8 step: 2030, loss is 0.0011439445661380887\n",
      "epoch: 8 step: 2031, loss is 9.020621655508876e-05\n",
      "epoch: 8 step: 2032, loss is 0.00014883637777529657\n",
      "epoch: 8 step: 2033, loss is 0.015740402042865753\n",
      "epoch: 8 step: 2034, loss is 0.011346984654664993\n",
      "epoch: 8 step: 2035, loss is 0.027112968266010284\n",
      "epoch: 8 step: 2036, loss is 0.06812012195587158\n",
      "epoch: 8 step: 2037, loss is 0.005584084894508123\n",
      "epoch: 8 step: 2038, loss is 7.474670564988628e-05\n",
      "epoch: 8 step: 2039, loss is 0.0010127131827175617\n",
      "epoch: 8 step: 2040, loss is 0.00239903898909688\n",
      "epoch: 8 step: 2041, loss is 4.00157950934954e-05\n",
      "epoch: 8 step: 2042, loss is 0.006022939924150705\n",
      "epoch: 8 step: 2043, loss is 0.025402182713150978\n",
      "epoch: 8 step: 2044, loss is 0.000300361163681373\n",
      "epoch: 8 step: 2045, loss is 0.049182385206222534\n",
      "epoch: 8 step: 2046, loss is 0.0008238211157731712\n",
      "epoch: 8 step: 2047, loss is 0.00033817876828834414\n",
      "epoch: 8 step: 2048, loss is 0.07459325343370438\n",
      "epoch: 8 step: 2049, loss is 0.0048750825226306915\n",
      "epoch: 8 step: 2050, loss is 0.00011462172551546246\n",
      "epoch: 8 step: 2051, loss is 0.04383332282304764\n",
      "epoch: 8 step: 2052, loss is 0.002317465841770172\n",
      "epoch: 8 step: 2053, loss is 0.0005005265702493489\n",
      "epoch: 8 step: 2054, loss is 0.056696824729442596\n",
      "epoch: 8 step: 2055, loss is 0.002613039454445243\n",
      "epoch: 8 step: 2056, loss is 0.0034414164256304502\n",
      "epoch: 8 step: 2057, loss is 0.002372182672843337\n",
      "epoch: 8 step: 2058, loss is 0.0001309950021095574\n",
      "epoch: 8 step: 2059, loss is 0.10232791304588318\n",
      "epoch: 8 step: 2060, loss is 0.000132871326059103\n",
      "epoch: 8 step: 2061, loss is 0.13817287981510162\n",
      "epoch: 8 step: 2062, loss is 0.0002094118535751477\n",
      "epoch: 8 step: 2063, loss is 0.13865862786769867\n",
      "epoch: 8 step: 2064, loss is 0.00016973128367681056\n",
      "epoch: 8 step: 2065, loss is 0.09242503345012665\n",
      "epoch: 8 step: 2066, loss is 0.00025478689349256456\n",
      "epoch: 8 step: 2067, loss is 0.0008714930154383183\n",
      "epoch: 8 step: 2068, loss is 0.13293538987636566\n",
      "epoch: 8 step: 2069, loss is 0.000770522456150502\n",
      "epoch: 8 step: 2070, loss is 0.0005088764009997249\n",
      "epoch: 8 step: 2071, loss is 0.00019132200395688415\n",
      "epoch: 8 step: 2072, loss is 0.13309499621391296\n",
      "epoch: 8 step: 2073, loss is 8.625256305094808e-05\n",
      "epoch: 8 step: 2074, loss is 0.011033526621758938\n",
      "epoch: 8 step: 2075, loss is 0.004445266909897327\n",
      "epoch: 8 step: 2076, loss is 0.00042445873259566724\n",
      "epoch: 8 step: 2077, loss is 0.0008311485289596021\n",
      "epoch: 8 step: 2078, loss is 0.002710760571062565\n",
      "epoch: 8 step: 2079, loss is 0.14235149323940277\n",
      "epoch: 8 step: 2080, loss is 0.0009032392990775406\n",
      "epoch: 8 step: 2081, loss is 0.003591756569221616\n",
      "epoch: 8 step: 2082, loss is 0.0002953821967821568\n",
      "epoch: 8 step: 2083, loss is 0.0038110758177936077\n",
      "epoch: 8 step: 2084, loss is 0.04060124233365059\n",
      "epoch: 8 step: 2085, loss is 0.003105775685980916\n",
      "epoch: 8 step: 2086, loss is 0.0013163917465135455\n",
      "epoch: 8 step: 2087, loss is 0.00039376021595671773\n",
      "epoch: 8 step: 2088, loss is 0.02064100094139576\n",
      "epoch: 8 step: 2089, loss is 0.00014204259787220508\n",
      "epoch: 8 step: 2090, loss is 0.014812744222581387\n",
      "epoch: 8 step: 2091, loss is 0.0011910927714779973\n",
      "epoch: 8 step: 2092, loss is 0.0006099752499721944\n",
      "epoch: 8 step: 2093, loss is 0.0008031775359995663\n",
      "epoch: 8 step: 2094, loss is 0.00011547015310497954\n",
      "epoch: 8 step: 2095, loss is 0.009664911776781082\n",
      "epoch: 8 step: 2096, loss is 0.03883415460586548\n",
      "epoch: 8 step: 2097, loss is 0.012633250094950199\n",
      "epoch: 8 step: 2098, loss is 0.0022211316972970963\n",
      "epoch: 8 step: 2099, loss is 0.019911551848053932\n",
      "epoch: 8 step: 2100, loss is 0.00018760647799354047\n",
      "epoch: 8 step: 2101, loss is 0.0006243522511795163\n",
      "epoch: 8 step: 2102, loss is 0.004335800651460886\n",
      "epoch: 8 step: 2103, loss is 0.0027895558159798384\n",
      "epoch: 8 step: 2104, loss is 0.004370575305074453\n",
      "epoch: 8 step: 2105, loss is 0.0055504352785646915\n",
      "epoch: 8 step: 2106, loss is 0.00016616401262581348\n",
      "epoch: 8 step: 2107, loss is 0.1798793524503708\n",
      "epoch: 8 step: 2108, loss is 0.024662384763360023\n",
      "epoch: 8 step: 2109, loss is 0.17545872926712036\n",
      "epoch: 8 step: 2110, loss is 0.022643066942691803\n",
      "epoch: 8 step: 2111, loss is 0.09505755454301834\n",
      "epoch: 8 step: 2112, loss is 0.00031693748314864933\n",
      "epoch: 8 step: 2113, loss is 0.00027426506858319044\n",
      "epoch: 8 step: 2114, loss is 0.006346970796585083\n",
      "epoch: 8 step: 2115, loss is 0.019274570047855377\n",
      "epoch: 8 step: 2116, loss is 0.000539537169970572\n",
      "epoch: 8 step: 2117, loss is 0.004294290207326412\n",
      "epoch: 8 step: 2118, loss is 0.0013535046018660069\n",
      "epoch: 8 step: 2119, loss is 0.001947937998920679\n",
      "epoch: 8 step: 2120, loss is 0.001034331158734858\n",
      "epoch: 8 step: 2121, loss is 0.02438562922179699\n",
      "epoch: 8 step: 2122, loss is 0.0032891544979065657\n",
      "epoch: 8 step: 2123, loss is 0.0036702968645840883\n",
      "epoch: 8 step: 2124, loss is 0.0065361433662474155\n",
      "epoch: 8 step: 2125, loss is 0.04304325208067894\n",
      "epoch: 8 step: 2126, loss is 0.0021095527336001396\n",
      "epoch: 8 step: 2127, loss is 0.04514382779598236\n",
      "epoch: 8 step: 2128, loss is 0.0005296356976032257\n",
      "epoch: 8 step: 2129, loss is 0.019598137587308884\n",
      "epoch: 8 step: 2130, loss is 0.17679233849048615\n",
      "epoch: 8 step: 2131, loss is 0.012686747126281261\n",
      "epoch: 8 step: 2132, loss is 0.010389979928731918\n",
      "epoch: 8 step: 2133, loss is 0.03652198612689972\n",
      "epoch: 8 step: 2134, loss is 0.0008887509466148913\n",
      "epoch: 8 step: 2135, loss is 0.0014034740161150694\n",
      "epoch: 8 step: 2136, loss is 0.004356519319117069\n",
      "epoch: 8 step: 2137, loss is 0.001045105280354619\n",
      "epoch: 8 step: 2138, loss is 0.006831542123109102\n",
      "epoch: 8 step: 2139, loss is 0.016553184017539024\n",
      "epoch: 8 step: 2140, loss is 0.00020338896138127893\n",
      "epoch: 8 step: 2141, loss is 0.00040683153201825917\n",
      "epoch: 8 step: 2142, loss is 0.0024637936148792505\n",
      "epoch: 8 step: 2143, loss is 0.0009080417221412063\n",
      "epoch: 8 step: 2144, loss is 0.01884521171450615\n",
      "epoch: 8 step: 2145, loss is 0.0002297747996635735\n",
      "epoch: 8 step: 2146, loss is 0.0013499186607077718\n",
      "epoch: 8 step: 2147, loss is 0.15312358736991882\n",
      "epoch: 8 step: 2148, loss is 0.0015666268300265074\n",
      "epoch: 8 step: 2149, loss is 0.08451879024505615\n",
      "epoch: 8 step: 2150, loss is 0.0004626648733392358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 2151, loss is 0.0026053886394947767\n",
      "epoch: 8 step: 2152, loss is 8.840137888910249e-05\n",
      "epoch: 8 step: 2153, loss is 0.0034521659836173058\n",
      "epoch: 8 step: 2154, loss is 0.049729373306035995\n",
      "epoch: 8 step: 2155, loss is 0.0002034986246144399\n",
      "epoch: 8 step: 2156, loss is 0.0017253676196560264\n",
      "epoch: 8 step: 2157, loss is 0.004485637415200472\n",
      "epoch: 8 step: 2158, loss is 0.004880872555077076\n",
      "epoch: 8 step: 2159, loss is 0.0002772677398752421\n",
      "epoch: 8 step: 2160, loss is 0.006165204104036093\n",
      "epoch: 8 step: 2161, loss is 0.0011872815666720271\n",
      "epoch: 8 step: 2162, loss is 0.004313481505960226\n",
      "epoch: 8 step: 2163, loss is 0.0005551623180508614\n",
      "epoch: 8 step: 2164, loss is 0.0012666676193475723\n",
      "epoch: 8 step: 2165, loss is 0.016744717955589294\n",
      "epoch: 8 step: 2166, loss is 0.04235866665840149\n",
      "epoch: 8 step: 2167, loss is 0.0037760736886411905\n",
      "epoch: 8 step: 2168, loss is 0.0010133133037015796\n",
      "epoch: 8 step: 2169, loss is 0.000794844760093838\n",
      "epoch: 8 step: 2170, loss is 0.0029837321490049362\n",
      "epoch: 8 step: 2171, loss is 0.003236451419070363\n",
      "epoch: 8 step: 2172, loss is 0.0013206496369093657\n",
      "epoch: 8 step: 2173, loss is 0.004943097475916147\n",
      "epoch: 8 step: 2174, loss is 0.0001259569253306836\n",
      "epoch: 8 step: 2175, loss is 0.00013162862160243094\n",
      "epoch: 8 step: 2176, loss is 0.0021385394502431154\n",
      "epoch: 8 step: 2177, loss is 2.0979417968192138e-05\n",
      "epoch: 8 step: 2178, loss is 0.0008982804138213396\n",
      "epoch: 8 step: 2179, loss is 0.19722604751586914\n",
      "epoch: 8 step: 2180, loss is 0.0009046961204148829\n",
      "epoch: 8 step: 2181, loss is 0.001611302956007421\n",
      "epoch: 8 step: 2182, loss is 0.0902608260512352\n",
      "epoch: 8 step: 2183, loss is 0.003942335024476051\n",
      "epoch: 8 step: 2184, loss is 0.00021032345830462873\n",
      "epoch: 8 step: 2185, loss is 0.003713697660714388\n",
      "epoch: 8 step: 2186, loss is 0.005057108588516712\n",
      "epoch: 8 step: 2187, loss is 0.10149471461772919\n",
      "epoch: 9 step: 1, loss is 0.018472861498594284\n",
      "epoch: 9 step: 2, loss is 0.005407275632023811\n",
      "epoch: 9 step: 3, loss is 0.0002408321452094242\n",
      "epoch: 9 step: 4, loss is 0.0004367802175693214\n",
      "epoch: 9 step: 5, loss is 0.053983114659786224\n",
      "epoch: 9 step: 6, loss is 0.00037480282480828464\n",
      "epoch: 9 step: 7, loss is 0.0028214340563863516\n",
      "epoch: 9 step: 8, loss is 0.006701777223497629\n",
      "epoch: 9 step: 9, loss is 0.005511792842298746\n",
      "epoch: 9 step: 10, loss is 0.0026150960475206375\n",
      "epoch: 9 step: 11, loss is 0.0004548959550447762\n",
      "epoch: 9 step: 12, loss is 0.00036031039780937135\n",
      "epoch: 9 step: 13, loss is 0.00044832154526375234\n",
      "epoch: 9 step: 14, loss is 0.0016349562210962176\n",
      "epoch: 9 step: 15, loss is 0.0002505468437448144\n",
      "epoch: 9 step: 16, loss is 0.00023891878663562238\n",
      "epoch: 9 step: 17, loss is 0.00456557422876358\n",
      "epoch: 9 step: 18, loss is 0.0010377964936196804\n",
      "epoch: 9 step: 19, loss is 0.00688940891996026\n",
      "epoch: 9 step: 20, loss is 0.0001602107658982277\n",
      "epoch: 9 step: 21, loss is 0.01871972158551216\n",
      "epoch: 9 step: 22, loss is 0.01744767650961876\n",
      "epoch: 9 step: 23, loss is 0.0017199781723320484\n",
      "epoch: 9 step: 24, loss is 0.03812183812260628\n",
      "epoch: 9 step: 25, loss is 0.002727157436311245\n",
      "epoch: 9 step: 26, loss is 0.11459778249263763\n",
      "epoch: 9 step: 27, loss is 0.0063342321664094925\n",
      "epoch: 9 step: 28, loss is 0.0020290629472583532\n",
      "epoch: 9 step: 29, loss is 0.0002543664595577866\n",
      "epoch: 9 step: 30, loss is 0.00464597949758172\n",
      "epoch: 9 step: 31, loss is 0.0031378231942653656\n",
      "epoch: 9 step: 32, loss is 0.0014164845924824476\n",
      "epoch: 9 step: 33, loss is 0.00016456074081361294\n",
      "epoch: 9 step: 34, loss is 0.034883931279182434\n",
      "epoch: 9 step: 35, loss is 0.000655492942314595\n",
      "epoch: 9 step: 36, loss is 0.021078424528241158\n",
      "epoch: 9 step: 37, loss is 0.05803656205534935\n",
      "epoch: 9 step: 38, loss is 0.0007003839127719402\n",
      "epoch: 9 step: 39, loss is 0.0722399652004242\n",
      "epoch: 9 step: 40, loss is 0.0012497205752879381\n",
      "epoch: 9 step: 41, loss is 0.001352444407530129\n",
      "epoch: 9 step: 42, loss is 0.12812523543834686\n",
      "epoch: 9 step: 43, loss is 0.008045678026974201\n",
      "epoch: 9 step: 44, loss is 0.0019692436326295137\n",
      "epoch: 9 step: 45, loss is 0.018488887697458267\n",
      "epoch: 9 step: 46, loss is 0.015441951341927052\n",
      "epoch: 9 step: 47, loss is 0.03806914761662483\n",
      "epoch: 9 step: 48, loss is 0.04240665212273598\n",
      "epoch: 9 step: 49, loss is 0.0053358860313892365\n",
      "epoch: 9 step: 50, loss is 0.00046331319026649\n",
      "epoch: 9 step: 51, loss is 0.0043127266690135\n",
      "epoch: 9 step: 52, loss is 0.0005221088649705052\n",
      "epoch: 9 step: 53, loss is 0.000176066008862108\n",
      "epoch: 9 step: 54, loss is 0.00022227289446163923\n",
      "epoch: 9 step: 55, loss is 0.008790896274149418\n",
      "epoch: 9 step: 56, loss is 0.0020076262298971415\n",
      "epoch: 9 step: 57, loss is 0.0013275713426992297\n",
      "epoch: 9 step: 58, loss is 0.00011223051842534915\n",
      "epoch: 9 step: 59, loss is 0.10419851541519165\n",
      "epoch: 9 step: 60, loss is 0.00011608941713348031\n",
      "epoch: 9 step: 61, loss is 0.00010723434388637543\n",
      "epoch: 9 step: 62, loss is 0.00010660717816790566\n",
      "epoch: 9 step: 63, loss is 3.498310979921371e-05\n",
      "epoch: 9 step: 64, loss is 2.8965299861738458e-05\n",
      "epoch: 9 step: 65, loss is 0.005978312809020281\n",
      "epoch: 9 step: 66, loss is 0.0005287613021209836\n",
      "epoch: 9 step: 67, loss is 0.0009302039397880435\n",
      "epoch: 9 step: 68, loss is 0.008462992496788502\n",
      "epoch: 9 step: 69, loss is 0.000523555965628475\n",
      "epoch: 9 step: 70, loss is 0.0005245666834525764\n",
      "epoch: 9 step: 71, loss is 8.510500629199669e-05\n",
      "epoch: 9 step: 72, loss is 0.0007021284545771778\n",
      "epoch: 9 step: 73, loss is 0.12557880580425262\n",
      "epoch: 9 step: 74, loss is 0.001068545039743185\n",
      "epoch: 9 step: 75, loss is 0.004108656197786331\n",
      "epoch: 9 step: 76, loss is 3.791748167714104e-05\n",
      "epoch: 9 step: 77, loss is 0.008176705799996853\n",
      "epoch: 9 step: 78, loss is 5.796999539597891e-05\n",
      "epoch: 9 step: 79, loss is 0.0005637060385197401\n",
      "epoch: 9 step: 80, loss is 0.00011985238961642608\n",
      "epoch: 9 step: 81, loss is 0.00024598962045274675\n",
      "epoch: 9 step: 82, loss is 0.0005785006214864552\n",
      "epoch: 9 step: 83, loss is 0.0006044359761290252\n",
      "epoch: 9 step: 84, loss is 0.040227994322776794\n",
      "epoch: 9 step: 85, loss is 0.00047002965584397316\n",
      "epoch: 9 step: 86, loss is 0.00033195168361999094\n",
      "epoch: 9 step: 87, loss is 0.00012394711666274816\n",
      "epoch: 9 step: 88, loss is 0.0004228560137562454\n",
      "epoch: 9 step: 89, loss is 0.00045269716065376997\n",
      "epoch: 9 step: 90, loss is 0.016464268788695335\n",
      "epoch: 9 step: 91, loss is 0.01613737642765045\n",
      "epoch: 9 step: 92, loss is 0.0005090273334644735\n",
      "epoch: 9 step: 93, loss is 0.0027008247561752796\n",
      "epoch: 9 step: 94, loss is 0.0023570999037474394\n",
      "epoch: 9 step: 95, loss is 0.00024089126964099705\n",
      "epoch: 9 step: 96, loss is 0.0010721542639657855\n",
      "epoch: 9 step: 97, loss is 0.0020766458474099636\n",
      "epoch: 9 step: 98, loss is 0.018262207508087158\n",
      "epoch: 9 step: 99, loss is 0.0032996200025081635\n",
      "epoch: 9 step: 100, loss is 0.00021514763648156077\n",
      "epoch: 9 step: 101, loss is 3.3619769965298474e-05\n",
      "epoch: 9 step: 102, loss is 0.0007629880565218627\n",
      "epoch: 9 step: 103, loss is 0.0010646668961271644\n",
      "epoch: 9 step: 104, loss is 0.007099833805114031\n",
      "epoch: 9 step: 105, loss is 0.0007459050975739956\n",
      "epoch: 9 step: 106, loss is 0.00023712942493148148\n",
      "epoch: 9 step: 107, loss is 0.0011597538832575083\n",
      "epoch: 9 step: 108, loss is 0.009230947121977806\n",
      "epoch: 9 step: 109, loss is 0.00031513217254541814\n",
      "epoch: 9 step: 110, loss is 0.00010045097587862983\n",
      "epoch: 9 step: 111, loss is 1.6567071725148708e-05\n",
      "epoch: 9 step: 112, loss is 0.0536358468234539\n",
      "epoch: 9 step: 113, loss is 0.00012562252231873572\n",
      "epoch: 9 step: 114, loss is 0.004155746195465326\n",
      "epoch: 9 step: 115, loss is 5.3099160140845925e-05\n",
      "epoch: 9 step: 116, loss is 0.001720291213132441\n",
      "epoch: 9 step: 117, loss is 0.00015972000255715102\n",
      "epoch: 9 step: 118, loss is 0.0004119837249163538\n",
      "epoch: 9 step: 119, loss is 0.0013993263710290194\n",
      "epoch: 9 step: 120, loss is 4.749307845486328e-05\n",
      "epoch: 9 step: 121, loss is 0.004741894546896219\n",
      "epoch: 9 step: 122, loss is 0.001637939945794642\n",
      "epoch: 9 step: 123, loss is 0.00970581267029047\n",
      "epoch: 9 step: 124, loss is 0.0010129724396392703\n",
      "epoch: 9 step: 125, loss is 0.025156062096357346\n",
      "epoch: 9 step: 126, loss is 0.027220549061894417\n",
      "epoch: 9 step: 127, loss is 0.06777825206518173\n",
      "epoch: 9 step: 128, loss is 0.0003977366432081908\n",
      "epoch: 9 step: 129, loss is 0.0009172129211947322\n",
      "epoch: 9 step: 130, loss is 0.00035443887463770807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 131, loss is 0.006547859869897366\n",
      "epoch: 9 step: 132, loss is 0.000650206464342773\n",
      "epoch: 9 step: 133, loss is 0.0013149543665349483\n",
      "epoch: 9 step: 134, loss is 0.009651902131736279\n",
      "epoch: 9 step: 135, loss is 0.003147939220070839\n",
      "epoch: 9 step: 136, loss is 0.03605087101459503\n",
      "epoch: 9 step: 137, loss is 0.0157094094902277\n",
      "epoch: 9 step: 138, loss is 0.00013247938477434218\n",
      "epoch: 9 step: 139, loss is 0.00048743817023932934\n",
      "epoch: 9 step: 140, loss is 0.0005579598946496844\n",
      "epoch: 9 step: 141, loss is 0.008545142598450184\n",
      "epoch: 9 step: 142, loss is 0.0008324474911205471\n",
      "epoch: 9 step: 143, loss is 0.013405011966824532\n",
      "epoch: 9 step: 144, loss is 0.0037985490635037422\n",
      "epoch: 9 step: 145, loss is 0.23637869954109192\n",
      "epoch: 9 step: 146, loss is 0.0013444451615214348\n",
      "epoch: 9 step: 147, loss is 0.0007317417184822261\n",
      "epoch: 9 step: 148, loss is 0.0017427181592211127\n",
      "epoch: 9 step: 149, loss is 0.000505783420521766\n",
      "epoch: 9 step: 150, loss is 0.0002644640626385808\n",
      "epoch: 9 step: 151, loss is 0.019921354949474335\n",
      "epoch: 9 step: 152, loss is 0.016127265989780426\n",
      "epoch: 9 step: 153, loss is 0.0003916864807251841\n",
      "epoch: 9 step: 154, loss is 0.0008473820053040981\n",
      "epoch: 9 step: 155, loss is 0.0014556993264704943\n",
      "epoch: 9 step: 156, loss is 0.003193369833752513\n",
      "epoch: 9 step: 157, loss is 0.00032399629708379507\n",
      "epoch: 9 step: 158, loss is 0.007079719565808773\n",
      "epoch: 9 step: 159, loss is 0.00039495632518082857\n",
      "epoch: 9 step: 160, loss is 0.0003440041618887335\n",
      "epoch: 9 step: 161, loss is 0.08019338548183441\n",
      "epoch: 9 step: 162, loss is 0.003239368787035346\n",
      "epoch: 9 step: 163, loss is 0.0006464683101512492\n",
      "epoch: 9 step: 164, loss is 0.0007558375946246088\n",
      "epoch: 9 step: 165, loss is 4.144015838392079e-05\n",
      "epoch: 9 step: 166, loss is 0.024344755336642265\n",
      "epoch: 9 step: 167, loss is 0.00014702115731779486\n",
      "epoch: 9 step: 168, loss is 0.0008481609984301031\n",
      "epoch: 9 step: 169, loss is 0.001384638249874115\n",
      "epoch: 9 step: 170, loss is 0.16320815682411194\n",
      "epoch: 9 step: 171, loss is 4.516033368417993e-05\n",
      "epoch: 9 step: 172, loss is 0.001905182609334588\n",
      "epoch: 9 step: 173, loss is 0.00025799163267947733\n",
      "epoch: 9 step: 174, loss is 0.1198909655213356\n",
      "epoch: 9 step: 175, loss is 0.008963880129158497\n",
      "epoch: 9 step: 176, loss is 0.00017400678189005703\n",
      "epoch: 9 step: 177, loss is 0.02099831961095333\n",
      "epoch: 9 step: 178, loss is 0.0029164908919483423\n",
      "epoch: 9 step: 179, loss is 0.00010086751717608422\n",
      "epoch: 9 step: 180, loss is 0.0011278425808995962\n",
      "epoch: 9 step: 181, loss is 0.0011961954878643155\n",
      "epoch: 9 step: 182, loss is 0.000592809054069221\n",
      "epoch: 9 step: 183, loss is 0.008839553222060204\n",
      "epoch: 9 step: 184, loss is 0.0036638560704886913\n",
      "epoch: 9 step: 185, loss is 8.70514995767735e-05\n",
      "epoch: 9 step: 186, loss is 0.0005626191268675029\n",
      "epoch: 9 step: 187, loss is 1.5360052202595398e-05\n",
      "epoch: 9 step: 188, loss is 0.00045954601955600083\n",
      "epoch: 9 step: 189, loss is 2.7074422177975066e-05\n",
      "epoch: 9 step: 190, loss is 0.006937344558537006\n",
      "epoch: 9 step: 191, loss is 0.0029060421511530876\n",
      "epoch: 9 step: 192, loss is 0.0009510649833828211\n",
      "epoch: 9 step: 193, loss is 0.0004076352925039828\n",
      "epoch: 9 step: 194, loss is 0.05150698870420456\n",
      "epoch: 9 step: 195, loss is 0.017796317115426064\n",
      "epoch: 9 step: 196, loss is 7.543736865045503e-05\n",
      "epoch: 9 step: 197, loss is 0.00246474239975214\n",
      "epoch: 9 step: 198, loss is 0.00019982826779596508\n",
      "epoch: 9 step: 199, loss is 0.0002886697184294462\n",
      "epoch: 9 step: 200, loss is 0.06776048988103867\n",
      "epoch: 9 step: 201, loss is 0.001452374504879117\n",
      "epoch: 9 step: 202, loss is 0.006206497550010681\n",
      "epoch: 9 step: 203, loss is 0.0013095689937472343\n",
      "epoch: 9 step: 204, loss is 2.747278631431982e-05\n",
      "epoch: 9 step: 205, loss is 0.00013959423813503236\n",
      "epoch: 9 step: 206, loss is 0.0018730789888650179\n",
      "epoch: 9 step: 207, loss is 0.0025429963134229183\n",
      "epoch: 9 step: 208, loss is 0.013810397125780582\n",
      "epoch: 9 step: 209, loss is 0.00031356376712210476\n",
      "epoch: 9 step: 210, loss is 0.0002230676618637517\n",
      "epoch: 9 step: 211, loss is 0.0009561332990415394\n",
      "epoch: 9 step: 212, loss is 6.214889435796067e-05\n",
      "epoch: 9 step: 213, loss is 0.0001200624683406204\n",
      "epoch: 9 step: 214, loss is 0.00013355478586163372\n",
      "epoch: 9 step: 215, loss is 0.0011980796698480844\n",
      "epoch: 9 step: 216, loss is 0.00014932300837244838\n",
      "epoch: 9 step: 217, loss is 0.0043027885258197784\n",
      "epoch: 9 step: 218, loss is 0.0009499923326075077\n",
      "epoch: 9 step: 219, loss is 0.00025704698055051267\n",
      "epoch: 9 step: 220, loss is 0.004519806243479252\n",
      "epoch: 9 step: 221, loss is 0.005869455169886351\n",
      "epoch: 9 step: 222, loss is 0.001164891174994409\n",
      "epoch: 9 step: 223, loss is 0.0009277416975237429\n",
      "epoch: 9 step: 224, loss is 0.00027142546605318785\n",
      "epoch: 9 step: 225, loss is 0.016309266909956932\n",
      "epoch: 9 step: 226, loss is 0.007668857928365469\n",
      "epoch: 9 step: 227, loss is 0.0009447559132240713\n",
      "epoch: 9 step: 228, loss is 0.00035505450796335936\n",
      "epoch: 9 step: 229, loss is 0.0006469557993113995\n",
      "epoch: 9 step: 230, loss is 0.0003329543396830559\n",
      "epoch: 9 step: 231, loss is 0.0011773768346756697\n",
      "epoch: 9 step: 232, loss is 0.007965014316141605\n",
      "epoch: 9 step: 233, loss is 0.0002555737446527928\n",
      "epoch: 9 step: 234, loss is 0.0022483416832983494\n",
      "epoch: 9 step: 235, loss is 0.0002983970916830003\n",
      "epoch: 9 step: 236, loss is 0.025630908086895943\n",
      "epoch: 9 step: 237, loss is 0.0001852638233685866\n",
      "epoch: 9 step: 238, loss is 0.00023780390620231628\n",
      "epoch: 9 step: 239, loss is 0.00046971606207080185\n",
      "epoch: 9 step: 240, loss is 0.00021491690131369978\n",
      "epoch: 9 step: 241, loss is 0.013879039324820042\n",
      "epoch: 9 step: 242, loss is 0.06897891312837601\n",
      "epoch: 9 step: 243, loss is 0.00026549852918833494\n",
      "epoch: 9 step: 244, loss is 0.0022014507558196783\n",
      "epoch: 9 step: 245, loss is 0.00821614172309637\n",
      "epoch: 9 step: 246, loss is 0.0015175002627074718\n",
      "epoch: 9 step: 247, loss is 7.689849735470489e-05\n",
      "epoch: 9 step: 248, loss is 0.04920598492026329\n",
      "epoch: 9 step: 249, loss is 0.003476599929854274\n",
      "epoch: 9 step: 250, loss is 0.011745922267436981\n",
      "epoch: 9 step: 251, loss is 0.00019845493079628795\n",
      "epoch: 9 step: 252, loss is 0.0006308294832706451\n",
      "epoch: 9 step: 253, loss is 0.008685484528541565\n",
      "epoch: 9 step: 254, loss is 0.1496313214302063\n",
      "epoch: 9 step: 255, loss is 0.0037409882061183453\n",
      "epoch: 9 step: 256, loss is 0.0002443933335598558\n",
      "epoch: 9 step: 257, loss is 0.028502007946372032\n",
      "epoch: 9 step: 258, loss is 0.00015274329052772373\n",
      "epoch: 9 step: 259, loss is 0.002605204936116934\n",
      "epoch: 9 step: 260, loss is 0.00013805199705529958\n",
      "epoch: 9 step: 261, loss is 0.0023172488436102867\n",
      "epoch: 9 step: 262, loss is 0.001712032244540751\n",
      "epoch: 9 step: 263, loss is 0.04055684432387352\n",
      "epoch: 9 step: 264, loss is 4.812538463738747e-05\n",
      "epoch: 9 step: 265, loss is 0.0018801063997671008\n",
      "epoch: 9 step: 266, loss is 0.000610100687481463\n",
      "epoch: 9 step: 267, loss is 0.002967950189486146\n",
      "epoch: 9 step: 268, loss is 0.0005442919791676104\n",
      "epoch: 9 step: 269, loss is 0.1272774189710617\n",
      "epoch: 9 step: 270, loss is 0.03193008899688721\n",
      "epoch: 9 step: 271, loss is 3.256654235883616e-05\n",
      "epoch: 9 step: 272, loss is 0.009524497203528881\n",
      "epoch: 9 step: 273, loss is 0.0005277810851112008\n",
      "epoch: 9 step: 274, loss is 0.00020504245185293257\n",
      "epoch: 9 step: 275, loss is 0.0019087424734607339\n",
      "epoch: 9 step: 276, loss is 0.016278477385640144\n",
      "epoch: 9 step: 277, loss is 0.0002813741739373654\n",
      "epoch: 9 step: 278, loss is 0.0032452745363116264\n",
      "epoch: 9 step: 279, loss is 0.0021824073046445847\n",
      "epoch: 9 step: 280, loss is 0.0013288049958646297\n",
      "epoch: 9 step: 281, loss is 0.0011455253697931767\n",
      "epoch: 9 step: 282, loss is 0.0010013849241659045\n",
      "epoch: 9 step: 283, loss is 0.042442046105861664\n",
      "epoch: 9 step: 284, loss is 0.00038232392398640513\n",
      "epoch: 9 step: 285, loss is 0.006972795352339745\n",
      "epoch: 9 step: 286, loss is 0.011183343827724457\n",
      "epoch: 9 step: 287, loss is 3.472034222795628e-05\n",
      "epoch: 9 step: 288, loss is 7.210051990114152e-05\n",
      "epoch: 9 step: 289, loss is 0.03881791979074478\n",
      "epoch: 9 step: 290, loss is 0.001475600409321487\n",
      "epoch: 9 step: 291, loss is 0.0005962633294984698\n",
      "epoch: 9 step: 292, loss is 0.03618037328124046\n",
      "epoch: 9 step: 293, loss is 0.0009616177994757891\n",
      "epoch: 9 step: 294, loss is 0.0019285384332761168\n",
      "epoch: 9 step: 295, loss is 0.001031298073939979\n",
      "epoch: 9 step: 296, loss is 0.0003081928298342973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 297, loss is 0.003587181679904461\n",
      "epoch: 9 step: 298, loss is 0.0004144490521866828\n",
      "epoch: 9 step: 299, loss is 6.55636249575764e-05\n",
      "epoch: 9 step: 300, loss is 0.001170068746432662\n",
      "epoch: 9 step: 301, loss is 0.0006305272690951824\n",
      "epoch: 9 step: 302, loss is 0.013856273144483566\n",
      "epoch: 9 step: 303, loss is 2.9186401661718264e-05\n",
      "epoch: 9 step: 304, loss is 0.00013522920198738575\n",
      "epoch: 9 step: 305, loss is 0.05790663883090019\n",
      "epoch: 9 step: 306, loss is 0.00011376685870345682\n",
      "epoch: 9 step: 307, loss is 0.0007668755715712905\n",
      "epoch: 9 step: 308, loss is 3.511616887408309e-05\n",
      "epoch: 9 step: 309, loss is 0.00022332598746288568\n",
      "epoch: 9 step: 310, loss is 0.029952537268400192\n",
      "epoch: 9 step: 311, loss is 0.00012622159556485713\n",
      "epoch: 9 step: 312, loss is 0.0005265271756798029\n",
      "epoch: 9 step: 313, loss is 0.0012135562719777226\n",
      "epoch: 9 step: 314, loss is 0.022208435460925102\n",
      "epoch: 9 step: 315, loss is 0.0001517571072326973\n",
      "epoch: 9 step: 316, loss is 0.012415656819939613\n",
      "epoch: 9 step: 317, loss is 0.00013688651961274445\n",
      "epoch: 9 step: 318, loss is 0.014395221136510372\n",
      "epoch: 9 step: 319, loss is 0.00215890328399837\n",
      "epoch: 9 step: 320, loss is 0.00022502017964143306\n",
      "epoch: 9 step: 321, loss is 0.00458176713436842\n",
      "epoch: 9 step: 322, loss is 0.0007191426120698452\n",
      "epoch: 9 step: 323, loss is 0.002320579718798399\n",
      "epoch: 9 step: 324, loss is 0.025673775002360344\n",
      "epoch: 9 step: 325, loss is 0.0032447651028633118\n",
      "epoch: 9 step: 326, loss is 8.229530067183077e-05\n",
      "epoch: 9 step: 327, loss is 4.998895383323543e-05\n",
      "epoch: 9 step: 328, loss is 0.00016624032286927104\n",
      "epoch: 9 step: 329, loss is 0.06831999868154526\n",
      "epoch: 9 step: 330, loss is 0.0021897307597100735\n",
      "epoch: 9 step: 331, loss is 0.047994472086429596\n",
      "epoch: 9 step: 332, loss is 0.004883336368948221\n",
      "epoch: 9 step: 333, loss is 0.0008917087106965482\n",
      "epoch: 9 step: 334, loss is 0.0010729744099080563\n",
      "epoch: 9 step: 335, loss is 4.995411291019991e-05\n",
      "epoch: 9 step: 336, loss is 0.00010090216528624296\n",
      "epoch: 9 step: 337, loss is 0.009826062247157097\n",
      "epoch: 9 step: 338, loss is 0.0010552980238571763\n",
      "epoch: 9 step: 339, loss is 0.0008042220142669976\n",
      "epoch: 9 step: 340, loss is 0.0006573077407665551\n",
      "epoch: 9 step: 341, loss is 0.00017166673205792904\n",
      "epoch: 9 step: 342, loss is 4.76966961286962e-05\n",
      "epoch: 9 step: 343, loss is 0.006761206313967705\n",
      "epoch: 9 step: 344, loss is 3.631987783592194e-05\n",
      "epoch: 9 step: 345, loss is 0.00046155464951880276\n",
      "epoch: 9 step: 346, loss is 0.000872099946718663\n",
      "epoch: 9 step: 347, loss is 0.00043703432311303914\n",
      "epoch: 9 step: 348, loss is 6.471793312812224e-05\n",
      "epoch: 9 step: 349, loss is 0.00011902637197636068\n",
      "epoch: 9 step: 350, loss is 0.026417477056384087\n",
      "epoch: 9 step: 351, loss is 0.0013963888632133603\n",
      "epoch: 9 step: 352, loss is 0.003277072450146079\n",
      "epoch: 9 step: 353, loss is 0.0029878581408411264\n",
      "epoch: 9 step: 354, loss is 0.0002763280353974551\n",
      "epoch: 9 step: 355, loss is 0.0003100387111771852\n",
      "epoch: 9 step: 356, loss is 0.0003168693510815501\n",
      "epoch: 9 step: 357, loss is 0.004090472124516964\n",
      "epoch: 9 step: 358, loss is 3.8662299630232155e-05\n",
      "epoch: 9 step: 359, loss is 6.282606045715511e-05\n",
      "epoch: 9 step: 360, loss is 0.000341786042554304\n",
      "epoch: 9 step: 361, loss is 0.0001997339422814548\n",
      "epoch: 9 step: 362, loss is 0.043652523308992386\n",
      "epoch: 9 step: 363, loss is 0.0002491158666089177\n",
      "epoch: 9 step: 364, loss is 0.024556169286370277\n",
      "epoch: 9 step: 365, loss is 0.0009822944412007928\n",
      "epoch: 9 step: 366, loss is 0.00034569023409858346\n",
      "epoch: 9 step: 367, loss is 2.661948383320123e-05\n",
      "epoch: 9 step: 368, loss is 0.0008655989659018815\n",
      "epoch: 9 step: 369, loss is 0.0007140101515688002\n",
      "epoch: 9 step: 370, loss is 2.5580075089237653e-05\n",
      "epoch: 9 step: 371, loss is 0.0012871281942352653\n",
      "epoch: 9 step: 372, loss is 0.014245362021028996\n",
      "epoch: 9 step: 373, loss is 0.00011538595572346821\n",
      "epoch: 9 step: 374, loss is 0.003365627024322748\n",
      "epoch: 9 step: 375, loss is 0.000634658383205533\n",
      "epoch: 9 step: 376, loss is 0.018537111580371857\n",
      "epoch: 9 step: 377, loss is 6.8583890424633864e-06\n",
      "epoch: 9 step: 378, loss is 0.000738091126549989\n",
      "epoch: 9 step: 379, loss is 0.001317436690442264\n",
      "epoch: 9 step: 380, loss is 0.029510999098420143\n",
      "epoch: 9 step: 381, loss is 0.0004318574210628867\n",
      "epoch: 9 step: 382, loss is 0.0027330233715474606\n",
      "epoch: 9 step: 383, loss is 0.0003344199212733656\n",
      "epoch: 9 step: 384, loss is 0.0009019791032187641\n",
      "epoch: 9 step: 385, loss is 0.0001141462053055875\n",
      "epoch: 9 step: 386, loss is 0.0001644546864554286\n",
      "epoch: 9 step: 387, loss is 0.010489767417311668\n",
      "epoch: 9 step: 388, loss is 0.029111232608556747\n",
      "epoch: 9 step: 389, loss is 0.037106309086084366\n",
      "epoch: 9 step: 390, loss is 0.0019518608460202813\n",
      "epoch: 9 step: 391, loss is 0.00023975945077836514\n",
      "epoch: 9 step: 392, loss is 1.5667686966480687e-05\n",
      "epoch: 9 step: 393, loss is 2.7466321625979617e-05\n",
      "epoch: 9 step: 394, loss is 0.0020336161833256483\n",
      "epoch: 9 step: 395, loss is 0.0008515500230714679\n",
      "epoch: 9 step: 396, loss is 0.0005686882068403065\n",
      "epoch: 9 step: 397, loss is 0.008112120442092419\n",
      "epoch: 9 step: 398, loss is 0.0011291460832580924\n",
      "epoch: 9 step: 399, loss is 0.00028108127298764884\n",
      "epoch: 9 step: 400, loss is 0.006015409249812365\n",
      "epoch: 9 step: 401, loss is 0.00010394972923677415\n",
      "epoch: 9 step: 402, loss is 0.0005221450701355934\n",
      "epoch: 9 step: 403, loss is 5.5284585869230796e-06\n",
      "epoch: 9 step: 404, loss is 0.001976447179913521\n",
      "epoch: 9 step: 405, loss is 0.027038320899009705\n",
      "epoch: 9 step: 406, loss is 0.00037480221362784505\n",
      "epoch: 9 step: 407, loss is 0.0004937822232022882\n",
      "epoch: 9 step: 408, loss is 0.00032412607106380165\n",
      "epoch: 9 step: 409, loss is 0.0003743184788618237\n",
      "epoch: 9 step: 410, loss is 0.00013513449812307954\n",
      "epoch: 9 step: 411, loss is 0.008968653157353401\n",
      "epoch: 9 step: 412, loss is 9.677445632405579e-06\n",
      "epoch: 9 step: 413, loss is 0.0027422700077295303\n",
      "epoch: 9 step: 414, loss is 0.00014838346396572888\n",
      "epoch: 9 step: 415, loss is 0.0010534373577684164\n",
      "epoch: 9 step: 416, loss is 0.00010273578664055094\n",
      "epoch: 9 step: 417, loss is 0.000319392274832353\n",
      "epoch: 9 step: 418, loss is 6.027140625519678e-05\n",
      "epoch: 9 step: 419, loss is 0.00588820967823267\n",
      "epoch: 9 step: 420, loss is 0.00036929058842360973\n",
      "epoch: 9 step: 421, loss is 0.009297233074903488\n",
      "epoch: 9 step: 422, loss is 0.011374986730515957\n",
      "epoch: 9 step: 423, loss is 0.0015194714069366455\n",
      "epoch: 9 step: 424, loss is 0.01136071141809225\n",
      "epoch: 9 step: 425, loss is 0.00021941389422863722\n",
      "epoch: 9 step: 426, loss is 0.001941655413247645\n",
      "epoch: 9 step: 427, loss is 0.0004631236952263862\n",
      "epoch: 9 step: 428, loss is 4.9586024033487774e-06\n",
      "epoch: 9 step: 429, loss is 0.0021781164687126875\n",
      "epoch: 9 step: 430, loss is 0.00022327086480800062\n",
      "epoch: 9 step: 431, loss is 0.00032940658275038004\n",
      "epoch: 9 step: 432, loss is 0.0003310928586870432\n",
      "epoch: 9 step: 433, loss is 0.0005774697638116777\n",
      "epoch: 9 step: 434, loss is 0.0014325124211609364\n",
      "epoch: 9 step: 435, loss is 0.0014844750985503197\n",
      "epoch: 9 step: 436, loss is 0.00016023933130782098\n",
      "epoch: 9 step: 437, loss is 0.01863780990242958\n",
      "epoch: 9 step: 438, loss is 0.00039646661025471985\n",
      "epoch: 9 step: 439, loss is 0.005860299803316593\n",
      "epoch: 9 step: 440, loss is 0.022871503606438637\n",
      "epoch: 9 step: 441, loss is 0.01527500431984663\n",
      "epoch: 9 step: 442, loss is 0.008912753313779831\n",
      "epoch: 9 step: 443, loss is 0.0005719431210309267\n",
      "epoch: 9 step: 444, loss is 0.0016083710361272097\n",
      "epoch: 9 step: 445, loss is 0.0001369170204270631\n",
      "epoch: 9 step: 446, loss is 0.01641857624053955\n",
      "epoch: 9 step: 447, loss is 0.0011537206592038274\n",
      "epoch: 9 step: 448, loss is 6.768888124497607e-05\n",
      "epoch: 9 step: 449, loss is 0.0016458564205095172\n",
      "epoch: 9 step: 450, loss is 0.0757608711719513\n",
      "epoch: 9 step: 451, loss is 2.1209913029451855e-05\n",
      "epoch: 9 step: 452, loss is 0.11770958453416824\n",
      "epoch: 9 step: 453, loss is 5.116901593282819e-05\n",
      "epoch: 9 step: 454, loss is 4.348336369730532e-05\n",
      "epoch: 9 step: 455, loss is 0.043385881930589676\n",
      "epoch: 9 step: 456, loss is 7.615894719492644e-05\n",
      "epoch: 9 step: 457, loss is 0.00012519456504378468\n",
      "epoch: 9 step: 458, loss is 0.05289441719651222\n",
      "epoch: 9 step: 459, loss is 0.002086132997646928\n",
      "epoch: 9 step: 460, loss is 0.00016482893261127174\n",
      "epoch: 9 step: 461, loss is 0.00019308304763399065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 462, loss is 1.9939732737839222e-05\n",
      "epoch: 9 step: 463, loss is 0.0003640193026512861\n",
      "epoch: 9 step: 464, loss is 0.01891556940972805\n",
      "epoch: 9 step: 465, loss is 0.005316249094903469\n",
      "epoch: 9 step: 466, loss is 2.4978908186312765e-05\n",
      "epoch: 9 step: 467, loss is 8.33320154924877e-05\n",
      "epoch: 9 step: 468, loss is 0.004523308016359806\n",
      "epoch: 9 step: 469, loss is 0.00017695077985990793\n",
      "epoch: 9 step: 470, loss is 0.0027408944442868233\n",
      "epoch: 9 step: 471, loss is 1.1466760042821988e-05\n",
      "epoch: 9 step: 472, loss is 0.049584392458200455\n",
      "epoch: 9 step: 473, loss is 4.387836088426411e-05\n",
      "epoch: 9 step: 474, loss is 2.4660119379404932e-05\n",
      "epoch: 9 step: 475, loss is 0.00036842169356532395\n",
      "epoch: 9 step: 476, loss is 0.02032114751636982\n",
      "epoch: 9 step: 477, loss is 0.004250925965607166\n",
      "epoch: 9 step: 478, loss is 0.0010232736822217703\n",
      "epoch: 9 step: 479, loss is 0.0008170733926817775\n",
      "epoch: 9 step: 480, loss is 0.0001771982351783663\n",
      "epoch: 9 step: 481, loss is 0.0022353928070515394\n",
      "epoch: 9 step: 482, loss is 0.00039948103949427605\n",
      "epoch: 9 step: 483, loss is 9.202852379530668e-05\n",
      "epoch: 9 step: 484, loss is 0.0020541378762573004\n",
      "epoch: 9 step: 485, loss is 0.0015442477306351066\n",
      "epoch: 9 step: 486, loss is 0.0005001433310098946\n",
      "epoch: 9 step: 487, loss is 0.0010117903584614396\n",
      "epoch: 9 step: 488, loss is 0.003206832567229867\n",
      "epoch: 9 step: 489, loss is 0.0018491536611691117\n",
      "epoch: 9 step: 490, loss is 0.0014916680520400405\n",
      "epoch: 9 step: 491, loss is 0.0019253544742241502\n",
      "epoch: 9 step: 492, loss is 0.007414412684738636\n",
      "epoch: 9 step: 493, loss is 0.02664990723133087\n",
      "epoch: 9 step: 494, loss is 3.108828968834132e-05\n",
      "epoch: 9 step: 495, loss is 0.00037655612686648965\n",
      "epoch: 9 step: 496, loss is 4.246326716383919e-05\n",
      "epoch: 9 step: 497, loss is 0.019631095230579376\n",
      "epoch: 9 step: 498, loss is 1.1948688552365638e-05\n",
      "epoch: 9 step: 499, loss is 0.0087074413895607\n",
      "epoch: 9 step: 500, loss is 9.763460184331052e-06\n",
      "epoch: 9 step: 501, loss is 0.00017397226474713534\n",
      "epoch: 9 step: 502, loss is 3.9466605812776834e-05\n",
      "epoch: 9 step: 503, loss is 0.0033376237843185663\n",
      "epoch: 9 step: 504, loss is 4.719362550531514e-05\n",
      "epoch: 9 step: 505, loss is 0.025064688175916672\n",
      "epoch: 9 step: 506, loss is 0.00030951632652431726\n",
      "epoch: 9 step: 507, loss is 0.0032786864321678877\n",
      "epoch: 9 step: 508, loss is 0.0011628331849351525\n",
      "epoch: 9 step: 509, loss is 0.002743298886343837\n",
      "epoch: 9 step: 510, loss is 0.0005119487177580595\n",
      "epoch: 9 step: 511, loss is 0.00048714649165049195\n",
      "epoch: 9 step: 512, loss is 0.0001768705842550844\n",
      "epoch: 9 step: 513, loss is 0.04187984764575958\n",
      "epoch: 9 step: 514, loss is 0.00010038915934273973\n",
      "epoch: 9 step: 515, loss is 0.0003972680715378374\n",
      "epoch: 9 step: 516, loss is 0.005106314085423946\n",
      "epoch: 9 step: 517, loss is 0.0006474045221693814\n",
      "epoch: 9 step: 518, loss is 0.002316658152267337\n",
      "epoch: 9 step: 519, loss is 0.0019931686110794544\n",
      "epoch: 9 step: 520, loss is 0.000329991162288934\n",
      "epoch: 9 step: 521, loss is 0.005765855778008699\n",
      "epoch: 9 step: 522, loss is 0.0007761364104226232\n",
      "epoch: 9 step: 523, loss is 0.00022845619241707027\n",
      "epoch: 9 step: 524, loss is 5.8325800637248904e-05\n",
      "epoch: 9 step: 525, loss is 0.014412078075110912\n",
      "epoch: 9 step: 526, loss is 0.00038810516707599163\n",
      "epoch: 9 step: 527, loss is 0.005465115420520306\n",
      "epoch: 9 step: 528, loss is 3.7589215935440734e-06\n",
      "epoch: 9 step: 529, loss is 0.00020007761486340314\n",
      "epoch: 9 step: 530, loss is 0.001705204020254314\n",
      "epoch: 9 step: 531, loss is 0.0004865126102231443\n",
      "epoch: 9 step: 532, loss is 0.001065797172486782\n",
      "epoch: 9 step: 533, loss is 0.010607283562421799\n",
      "epoch: 9 step: 534, loss is 0.005832164082676172\n",
      "epoch: 9 step: 535, loss is 2.3500670067733154e-05\n",
      "epoch: 9 step: 536, loss is 0.003592688823118806\n",
      "epoch: 9 step: 537, loss is 0.04314135015010834\n",
      "epoch: 9 step: 538, loss is 0.021224137395620346\n",
      "epoch: 9 step: 539, loss is 0.0723312720656395\n",
      "epoch: 9 step: 540, loss is 0.00011427398567320779\n",
      "epoch: 9 step: 541, loss is 0.0001934674073709175\n",
      "epoch: 9 step: 542, loss is 2.957945298476261e-06\n",
      "epoch: 9 step: 543, loss is 0.012893257662653923\n",
      "epoch: 9 step: 544, loss is 3.123062924714759e-05\n",
      "epoch: 9 step: 545, loss is 0.000183405150892213\n",
      "epoch: 9 step: 546, loss is 0.00020150865020696074\n",
      "epoch: 9 step: 547, loss is 0.00020655700063798577\n",
      "epoch: 9 step: 548, loss is 0.0005281030898913741\n",
      "epoch: 9 step: 549, loss is 0.003720469307154417\n",
      "epoch: 9 step: 550, loss is 0.04565208777785301\n",
      "epoch: 9 step: 551, loss is 0.015668118372559547\n",
      "epoch: 9 step: 552, loss is 3.0063949907344067e-06\n",
      "epoch: 9 step: 553, loss is 7.707819349889178e-06\n",
      "epoch: 9 step: 554, loss is 0.0005378389614634216\n",
      "epoch: 9 step: 555, loss is 0.001865077530965209\n",
      "epoch: 9 step: 556, loss is 7.865602674428374e-05\n",
      "epoch: 9 step: 557, loss is 0.0006823438452556729\n",
      "epoch: 9 step: 558, loss is 0.0063153719529509544\n",
      "epoch: 9 step: 559, loss is 0.005962824914604425\n",
      "epoch: 9 step: 560, loss is 0.07599242776632309\n",
      "epoch: 9 step: 561, loss is 8.194877591449767e-05\n",
      "epoch: 9 step: 562, loss is 0.0013794393744319677\n",
      "epoch: 9 step: 563, loss is 0.0002377932978561148\n",
      "epoch: 9 step: 564, loss is 0.00011417105270083994\n",
      "epoch: 9 step: 565, loss is 0.029985472559928894\n",
      "epoch: 9 step: 566, loss is 0.00032345965155400336\n",
      "epoch: 9 step: 567, loss is 0.0009205550304614007\n",
      "epoch: 9 step: 568, loss is 0.013056734576821327\n",
      "epoch: 9 step: 569, loss is 0.0003506257780827582\n",
      "epoch: 9 step: 570, loss is 0.013302178122103214\n",
      "epoch: 9 step: 571, loss is 0.004676179960370064\n",
      "epoch: 9 step: 572, loss is 0.0005669370293617249\n",
      "epoch: 9 step: 573, loss is 0.0009224907262250781\n",
      "epoch: 9 step: 574, loss is 1.8799786630552262e-05\n",
      "epoch: 9 step: 575, loss is 0.001301801996305585\n",
      "epoch: 9 step: 576, loss is 0.00013899985060561448\n",
      "epoch: 9 step: 577, loss is 0.0675588846206665\n",
      "epoch: 9 step: 578, loss is 0.0001367898948956281\n",
      "epoch: 9 step: 579, loss is 4.537724453257397e-05\n",
      "epoch: 9 step: 580, loss is 5.2906681958120316e-05\n",
      "epoch: 9 step: 581, loss is 2.6712434191722423e-05\n",
      "epoch: 9 step: 582, loss is 0.0001540921803098172\n",
      "epoch: 9 step: 583, loss is 4.3381500290706754e-05\n",
      "epoch: 9 step: 584, loss is 0.000718176132068038\n",
      "epoch: 9 step: 585, loss is 0.00011800060019595549\n",
      "epoch: 9 step: 586, loss is 0.0031423375476151705\n",
      "epoch: 9 step: 587, loss is 8.100445847958326e-05\n",
      "epoch: 9 step: 588, loss is 9.399231930729002e-05\n",
      "epoch: 9 step: 589, loss is 0.00018683035159483552\n",
      "epoch: 9 step: 590, loss is 1.2695267287199385e-05\n",
      "epoch: 9 step: 591, loss is 0.00021629159164149314\n",
      "epoch: 9 step: 592, loss is 0.18102683126926422\n",
      "epoch: 9 step: 593, loss is 3.157420360366814e-05\n",
      "epoch: 9 step: 594, loss is 0.00056341418530792\n",
      "epoch: 9 step: 595, loss is 0.004224519710987806\n",
      "epoch: 9 step: 596, loss is 3.3981905289692804e-05\n",
      "epoch: 9 step: 597, loss is 0.09297867119312286\n",
      "epoch: 9 step: 598, loss is 0.001777726924046874\n",
      "epoch: 9 step: 599, loss is 7.096927220118232e-06\n",
      "epoch: 9 step: 600, loss is 3.59909790859092e-05\n",
      "epoch: 9 step: 601, loss is 0.0027860586997121572\n",
      "epoch: 9 step: 602, loss is 0.00855876225978136\n",
      "epoch: 9 step: 603, loss is 0.00012364213762339205\n",
      "epoch: 9 step: 604, loss is 0.07410266250371933\n",
      "epoch: 9 step: 605, loss is 0.00029978129896335304\n",
      "epoch: 9 step: 606, loss is 0.0004963058163411915\n",
      "epoch: 9 step: 607, loss is 0.00015366921434178948\n",
      "epoch: 9 step: 608, loss is 0.006810804363340139\n",
      "epoch: 9 step: 609, loss is 0.00020441679225768894\n",
      "epoch: 9 step: 610, loss is 0.002064415253698826\n",
      "epoch: 9 step: 611, loss is 0.003163460176438093\n",
      "epoch: 9 step: 612, loss is 0.004926213528960943\n",
      "epoch: 9 step: 613, loss is 0.016276968643069267\n",
      "epoch: 9 step: 614, loss is 0.0003376673848833889\n",
      "epoch: 9 step: 615, loss is 7.644508150406182e-05\n",
      "epoch: 9 step: 616, loss is 0.00024378718808293343\n",
      "epoch: 9 step: 617, loss is 0.0003496025165077299\n",
      "epoch: 9 step: 618, loss is 0.001362691167742014\n",
      "epoch: 9 step: 619, loss is 0.008478449657559395\n",
      "epoch: 9 step: 620, loss is 0.0011007414432242513\n",
      "epoch: 9 step: 621, loss is 0.006095986347645521\n",
      "epoch: 9 step: 622, loss is 0.00010320136789232492\n",
      "epoch: 9 step: 623, loss is 0.0011080563999712467\n",
      "epoch: 9 step: 624, loss is 0.006170985288918018\n",
      "epoch: 9 step: 625, loss is 7.21123069524765e-05\n",
      "epoch: 9 step: 626, loss is 0.0004986238782294095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 627, loss is 1.857104871305637e-05\n",
      "epoch: 9 step: 628, loss is 0.00018219620687887073\n",
      "epoch: 9 step: 629, loss is 0.02630256675183773\n",
      "epoch: 9 step: 630, loss is 4.64178629044909e-06\n",
      "epoch: 9 step: 631, loss is 0.0001297804992645979\n",
      "epoch: 9 step: 632, loss is 0.20480382442474365\n",
      "epoch: 9 step: 633, loss is 0.0006249917787499726\n",
      "epoch: 9 step: 634, loss is 2.933206815214362e-05\n",
      "epoch: 9 step: 635, loss is 0.0012070330558344722\n",
      "epoch: 9 step: 636, loss is 0.0312182754278183\n",
      "epoch: 9 step: 637, loss is 0.016962487250566483\n",
      "epoch: 9 step: 638, loss is 0.07771823555231094\n",
      "epoch: 9 step: 639, loss is 0.009330159053206444\n",
      "epoch: 9 step: 640, loss is 0.0003187826951034367\n",
      "epoch: 9 step: 641, loss is 0.00027309238794259727\n",
      "epoch: 9 step: 642, loss is 4.86393146275077e-05\n",
      "epoch: 9 step: 643, loss is 0.03390329331159592\n",
      "epoch: 9 step: 644, loss is 0.0003587193787097931\n",
      "epoch: 9 step: 645, loss is 0.07019754499197006\n",
      "epoch: 9 step: 646, loss is 0.006789627484977245\n",
      "epoch: 9 step: 647, loss is 0.006439782679080963\n",
      "epoch: 9 step: 648, loss is 0.015649566426873207\n",
      "epoch: 9 step: 649, loss is 0.000831843470223248\n",
      "epoch: 9 step: 650, loss is 0.06437948346138\n",
      "epoch: 9 step: 651, loss is 0.0001390083780279383\n",
      "epoch: 9 step: 652, loss is 0.10112632066011429\n",
      "epoch: 9 step: 653, loss is 6.044103793101385e-05\n",
      "epoch: 9 step: 654, loss is 0.24593091011047363\n",
      "epoch: 9 step: 655, loss is 5.845229225087678e-06\n",
      "epoch: 9 step: 656, loss is 0.00048438613885082304\n",
      "epoch: 9 step: 657, loss is 5.271460395306349e-06\n",
      "epoch: 9 step: 658, loss is 0.0022606817074120045\n",
      "epoch: 9 step: 659, loss is 0.00014287246449384838\n",
      "epoch: 9 step: 660, loss is 0.010393471457064152\n",
      "epoch: 9 step: 661, loss is 0.006203694734722376\n",
      "epoch: 9 step: 662, loss is 0.003016802715137601\n",
      "epoch: 9 step: 663, loss is 0.00675297761335969\n",
      "epoch: 9 step: 664, loss is 0.0009551503462716937\n",
      "epoch: 9 step: 665, loss is 0.0017003943212330341\n",
      "epoch: 9 step: 666, loss is 0.0008161792065948248\n",
      "epoch: 9 step: 667, loss is 0.0003583722864277661\n",
      "epoch: 9 step: 668, loss is 0.00016256500384770334\n",
      "epoch: 9 step: 669, loss is 0.00042379111982882023\n",
      "epoch: 9 step: 670, loss is 0.0005013913614675403\n",
      "epoch: 9 step: 671, loss is 0.00036439907853491604\n",
      "epoch: 9 step: 672, loss is 0.0006488515646196902\n",
      "epoch: 9 step: 673, loss is 0.015118800103664398\n",
      "epoch: 9 step: 674, loss is 0.0003478137368801981\n",
      "epoch: 9 step: 675, loss is 0.00023747574596200138\n",
      "epoch: 9 step: 676, loss is 0.009315988048911095\n",
      "epoch: 9 step: 677, loss is 0.09720202535390854\n",
      "epoch: 9 step: 678, loss is 0.008459720760583878\n",
      "epoch: 9 step: 679, loss is 0.11420976370573044\n",
      "epoch: 9 step: 680, loss is 7.089609880495118e-06\n",
      "epoch: 9 step: 681, loss is 0.13550738990306854\n",
      "epoch: 9 step: 682, loss is 0.07899635285139084\n",
      "epoch: 9 step: 683, loss is 0.12623721361160278\n",
      "epoch: 9 step: 684, loss is 0.03456363454461098\n",
      "epoch: 9 step: 685, loss is 0.0016452653799206018\n",
      "epoch: 9 step: 686, loss is 0.0008982956642284989\n",
      "epoch: 9 step: 687, loss is 0.0007371248211711645\n",
      "epoch: 9 step: 688, loss is 4.5839820813853294e-05\n",
      "epoch: 9 step: 689, loss is 0.0018502320162951946\n",
      "epoch: 9 step: 690, loss is 0.10139551758766174\n",
      "epoch: 9 step: 691, loss is 0.00040441061719320714\n",
      "epoch: 9 step: 692, loss is 0.017995191738009453\n",
      "epoch: 9 step: 693, loss is 0.0003644012613222003\n",
      "epoch: 9 step: 694, loss is 0.027271607890725136\n",
      "epoch: 9 step: 695, loss is 0.0004471602733246982\n",
      "epoch: 9 step: 696, loss is 0.0013105588732287288\n",
      "epoch: 9 step: 697, loss is 0.003917294554412365\n",
      "epoch: 9 step: 698, loss is 0.09412168711423874\n",
      "epoch: 9 step: 699, loss is 0.00035955716157332063\n",
      "epoch: 9 step: 700, loss is 0.18945862352848053\n",
      "epoch: 9 step: 701, loss is 0.011186153627932072\n",
      "epoch: 9 step: 702, loss is 0.002241050126031041\n",
      "epoch: 9 step: 703, loss is 7.475426536984742e-05\n",
      "epoch: 9 step: 704, loss is 0.0013633978087455034\n",
      "epoch: 9 step: 705, loss is 0.08985354751348495\n",
      "epoch: 9 step: 706, loss is 0.0010118924546986818\n",
      "epoch: 9 step: 707, loss is 0.00030005117878317833\n",
      "epoch: 9 step: 708, loss is 0.022603467106819153\n",
      "epoch: 9 step: 709, loss is 0.001931076287291944\n",
      "epoch: 9 step: 710, loss is 0.06372044235467911\n",
      "epoch: 9 step: 711, loss is 0.0027015211526304483\n",
      "epoch: 9 step: 712, loss is 0.03449904918670654\n",
      "epoch: 9 step: 713, loss is 0.0005538758705370128\n",
      "epoch: 9 step: 714, loss is 0.007062871940433979\n",
      "epoch: 9 step: 715, loss is 0.00803630892187357\n",
      "epoch: 9 step: 716, loss is 0.07668595016002655\n",
      "epoch: 9 step: 717, loss is 0.05673733726143837\n",
      "epoch: 9 step: 718, loss is 0.015156418085098267\n",
      "epoch: 9 step: 719, loss is 0.012704454362392426\n",
      "epoch: 9 step: 720, loss is 0.00026245706249028444\n",
      "epoch: 9 step: 721, loss is 0.00023440548102371395\n",
      "epoch: 9 step: 722, loss is 0.07940708100795746\n",
      "epoch: 9 step: 723, loss is 0.18962521851062775\n",
      "epoch: 9 step: 724, loss is 0.002099857432767749\n",
      "epoch: 9 step: 725, loss is 7.269575871760026e-05\n",
      "epoch: 9 step: 726, loss is 0.007843957282602787\n",
      "epoch: 9 step: 727, loss is 0.0007032256107777357\n",
      "epoch: 9 step: 728, loss is 0.0022925501689314842\n",
      "epoch: 9 step: 729, loss is 0.0008271434926427901\n",
      "epoch: 9 step: 730, loss is 5.8070527302334085e-05\n",
      "epoch: 9 step: 731, loss is 0.007381371688097715\n",
      "epoch: 9 step: 732, loss is 0.00010854249558178708\n",
      "epoch: 9 step: 733, loss is 0.03845195472240448\n",
      "epoch: 9 step: 734, loss is 0.11743985861539841\n",
      "epoch: 9 step: 735, loss is 0.00010148928413400427\n",
      "epoch: 9 step: 736, loss is 0.0003372336213942617\n",
      "epoch: 9 step: 737, loss is 0.00045998208224773407\n",
      "epoch: 9 step: 738, loss is 0.00367841892875731\n",
      "epoch: 9 step: 739, loss is 0.00014210403605829924\n",
      "epoch: 9 step: 740, loss is 6.817943358328193e-05\n",
      "epoch: 9 step: 741, loss is 0.0024629035033285618\n",
      "epoch: 9 step: 742, loss is 0.019441846758127213\n",
      "epoch: 9 step: 743, loss is 0.0016698497347533703\n",
      "epoch: 9 step: 744, loss is 3.336460576974787e-05\n",
      "epoch: 9 step: 745, loss is 6.736866635037586e-05\n",
      "epoch: 9 step: 746, loss is 0.0005147623596712947\n",
      "epoch: 9 step: 747, loss is 0.0004612885823007673\n",
      "epoch: 9 step: 748, loss is 0.003946822136640549\n",
      "epoch: 9 step: 749, loss is 0.0012074382975697517\n",
      "epoch: 9 step: 750, loss is 0.0014470062451437116\n",
      "epoch: 9 step: 751, loss is 0.05074692517518997\n",
      "epoch: 9 step: 752, loss is 0.0006839688867330551\n",
      "epoch: 9 step: 753, loss is 0.0013446839293465018\n",
      "epoch: 9 step: 754, loss is 0.0035721363965421915\n",
      "epoch: 9 step: 755, loss is 0.001102316309697926\n",
      "epoch: 9 step: 756, loss is 0.005711700301617384\n",
      "epoch: 9 step: 757, loss is 0.00020974034850951284\n",
      "epoch: 9 step: 758, loss is 0.00298922136425972\n",
      "epoch: 9 step: 759, loss is 0.0005050141480751336\n",
      "epoch: 9 step: 760, loss is 0.009699014015495777\n",
      "epoch: 9 step: 761, loss is 0.11568721383810043\n",
      "epoch: 9 step: 762, loss is 0.001429258962161839\n",
      "epoch: 9 step: 763, loss is 9.843885345617309e-05\n",
      "epoch: 9 step: 764, loss is 0.005648651160299778\n",
      "epoch: 9 step: 765, loss is 0.00021022239525336772\n",
      "epoch: 9 step: 766, loss is 0.0162957776337862\n",
      "epoch: 9 step: 767, loss is 1.8577304217615165e-05\n",
      "epoch: 9 step: 768, loss is 0.0001510551228420809\n",
      "epoch: 9 step: 769, loss is 0.12314612418413162\n",
      "epoch: 9 step: 770, loss is 0.0003846937033813447\n",
      "epoch: 9 step: 771, loss is 0.0009436883847229183\n",
      "epoch: 9 step: 772, loss is 0.00030986915226094425\n",
      "epoch: 9 step: 773, loss is 0.003156400518491864\n",
      "epoch: 9 step: 774, loss is 0.0009332709014415741\n",
      "epoch: 9 step: 775, loss is 0.0004965216503478587\n",
      "epoch: 9 step: 776, loss is 0.006512977182865143\n",
      "epoch: 9 step: 777, loss is 0.0013854269636794925\n",
      "epoch: 9 step: 778, loss is 0.0013651482295244932\n",
      "epoch: 9 step: 779, loss is 0.000951681868173182\n",
      "epoch: 9 step: 780, loss is 0.012203659862279892\n",
      "epoch: 9 step: 781, loss is 0.009945087134838104\n",
      "epoch: 9 step: 782, loss is 0.004095669370144606\n",
      "epoch: 9 step: 783, loss is 0.0008612165111117065\n",
      "epoch: 9 step: 784, loss is 0.0008611571392975748\n",
      "epoch: 9 step: 785, loss is 1.9565881302696653e-05\n",
      "epoch: 9 step: 786, loss is 0.0001817799056880176\n",
      "epoch: 9 step: 787, loss is 8.582616283092648e-05\n",
      "epoch: 9 step: 788, loss is 0.0009148320532403886\n",
      "epoch: 9 step: 789, loss is 0.0401352196931839\n",
      "epoch: 9 step: 790, loss is 0.000515501422341913\n",
      "epoch: 9 step: 791, loss is 0.022395191714167595\n",
      "epoch: 9 step: 792, loss is 0.012239580973982811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 793, loss is 0.047741346061229706\n",
      "epoch: 9 step: 794, loss is 0.1265183985233307\n",
      "epoch: 9 step: 795, loss is 0.0004907412803731859\n",
      "epoch: 9 step: 796, loss is 0.07802523672580719\n",
      "epoch: 9 step: 797, loss is 0.002581819659098983\n",
      "epoch: 9 step: 798, loss is 1.94063140952494e-05\n",
      "epoch: 9 step: 799, loss is 0.0034413014072924852\n",
      "epoch: 9 step: 800, loss is 6.366204615915194e-05\n",
      "epoch: 9 step: 801, loss is 0.0007290023495443165\n",
      "epoch: 9 step: 802, loss is 0.0004919478087686002\n",
      "epoch: 9 step: 803, loss is 0.00035754317650571465\n",
      "epoch: 9 step: 804, loss is 0.009945315308868885\n",
      "epoch: 9 step: 805, loss is 0.0015448760241270065\n",
      "epoch: 9 step: 806, loss is 0.009801640175282955\n",
      "epoch: 9 step: 807, loss is 0.00010461748752277344\n",
      "epoch: 9 step: 808, loss is 0.003526050830259919\n",
      "epoch: 9 step: 809, loss is 0.003198113990947604\n",
      "epoch: 9 step: 810, loss is 0.000134641450131312\n",
      "epoch: 9 step: 811, loss is 0.014910134486854076\n",
      "epoch: 9 step: 812, loss is 5.723564754589461e-05\n",
      "epoch: 9 step: 813, loss is 9.798869723454118e-05\n",
      "epoch: 9 step: 814, loss is 0.00034039607271552086\n",
      "epoch: 9 step: 815, loss is 0.001056021312251687\n",
      "epoch: 9 step: 816, loss is 0.0002778666093945503\n",
      "epoch: 9 step: 817, loss is 0.004130261484533548\n",
      "epoch: 9 step: 818, loss is 0.00019225801224820316\n",
      "epoch: 9 step: 819, loss is 0.0027565795462578535\n",
      "epoch: 9 step: 820, loss is 0.0012223399244248867\n",
      "epoch: 9 step: 821, loss is 0.002418669406324625\n",
      "epoch: 9 step: 822, loss is 0.0035322813782840967\n",
      "epoch: 9 step: 823, loss is 0.001121784676797688\n",
      "epoch: 9 step: 824, loss is 0.00013355830742511898\n",
      "epoch: 9 step: 825, loss is 0.0002971052017528564\n",
      "epoch: 9 step: 826, loss is 0.004070577677339315\n",
      "epoch: 9 step: 827, loss is 4.308241113903932e-05\n",
      "epoch: 9 step: 828, loss is 9.856863471213728e-05\n",
      "epoch: 9 step: 829, loss is 0.00010317336273146793\n",
      "epoch: 9 step: 830, loss is 0.0022935441229492426\n",
      "epoch: 9 step: 831, loss is 0.004154387395828962\n",
      "epoch: 9 step: 832, loss is 0.011040114797651768\n",
      "epoch: 9 step: 833, loss is 0.0001449650153517723\n",
      "epoch: 9 step: 834, loss is 1.2937121937284246e-05\n",
      "epoch: 9 step: 835, loss is 6.727515574311838e-05\n",
      "epoch: 9 step: 836, loss is 0.004585282411426306\n",
      "epoch: 9 step: 837, loss is 5.1352377340663224e-05\n",
      "epoch: 9 step: 838, loss is 0.005117921624332666\n",
      "epoch: 9 step: 839, loss is 0.2271575927734375\n",
      "epoch: 9 step: 840, loss is 5.356768815545365e-05\n",
      "epoch: 9 step: 841, loss is 1.62978503794875e-05\n",
      "epoch: 9 step: 842, loss is 0.0003227155830245465\n",
      "epoch: 9 step: 843, loss is 8.389595677726902e-06\n",
      "epoch: 9 step: 844, loss is 0.05394343286752701\n",
      "epoch: 9 step: 845, loss is 0.0003254218026995659\n",
      "epoch: 9 step: 846, loss is 0.005676340311765671\n",
      "epoch: 9 step: 847, loss is 5.4733762226533145e-05\n",
      "epoch: 9 step: 848, loss is 0.0014403531095013022\n",
      "epoch: 9 step: 849, loss is 0.0033097227569669485\n",
      "epoch: 9 step: 850, loss is 0.05503648892045021\n",
      "epoch: 9 step: 851, loss is 0.03360510617494583\n",
      "epoch: 9 step: 852, loss is 0.00941529218107462\n",
      "epoch: 9 step: 853, loss is 0.08918295800685883\n",
      "epoch: 9 step: 854, loss is 0.000942739425227046\n",
      "epoch: 9 step: 855, loss is 0.00023441071971319616\n",
      "epoch: 9 step: 856, loss is 0.04224221035838127\n",
      "epoch: 9 step: 857, loss is 0.00016278056136798114\n",
      "epoch: 9 step: 858, loss is 0.005245920270681381\n",
      "epoch: 9 step: 859, loss is 0.00037145058740861714\n",
      "epoch: 9 step: 860, loss is 0.016643324866890907\n",
      "epoch: 9 step: 861, loss is 0.0003412940714042634\n",
      "epoch: 9 step: 862, loss is 0.001165189896710217\n",
      "epoch: 9 step: 863, loss is 0.03026200830936432\n",
      "epoch: 9 step: 864, loss is 0.0049171228893101215\n",
      "epoch: 9 step: 865, loss is 0.001397605985403061\n",
      "epoch: 9 step: 866, loss is 0.0006114994175732136\n",
      "epoch: 9 step: 867, loss is 0.002915096702054143\n",
      "epoch: 9 step: 868, loss is 0.0006444567115977407\n",
      "epoch: 9 step: 869, loss is 0.000655233976431191\n",
      "epoch: 9 step: 870, loss is 0.00011356148024788126\n",
      "epoch: 9 step: 871, loss is 0.002207300392910838\n",
      "epoch: 9 step: 872, loss is 0.032113976776599884\n",
      "epoch: 9 step: 873, loss is 0.0007309569045901299\n",
      "epoch: 9 step: 874, loss is 0.005613151006400585\n",
      "epoch: 9 step: 875, loss is 3.764099528780207e-05\n",
      "epoch: 9 step: 876, loss is 0.00019517655891831964\n",
      "epoch: 9 step: 877, loss is 0.012664200738072395\n",
      "epoch: 9 step: 878, loss is 8.773520676186308e-06\n",
      "epoch: 9 step: 879, loss is 0.03229173645377159\n",
      "epoch: 9 step: 880, loss is 0.00043290271423757076\n",
      "epoch: 9 step: 881, loss is 0.0006489544757641852\n",
      "epoch: 9 step: 882, loss is 4.203857315587811e-05\n",
      "epoch: 9 step: 883, loss is 0.0016488751862198114\n",
      "epoch: 9 step: 884, loss is 0.02603529393672943\n",
      "epoch: 9 step: 885, loss is 3.2686795748304576e-05\n",
      "epoch: 9 step: 886, loss is 0.00011580778664210811\n",
      "epoch: 9 step: 887, loss is 0.0008120447164401412\n",
      "epoch: 9 step: 888, loss is 4.790551611222327e-05\n",
      "epoch: 9 step: 889, loss is 0.014259308576583862\n",
      "epoch: 9 step: 890, loss is 0.0007881890051066875\n",
      "epoch: 9 step: 891, loss is 0.00018172489944845438\n",
      "epoch: 9 step: 892, loss is 0.005680963862687349\n",
      "epoch: 9 step: 893, loss is 0.00037987419636920094\n",
      "epoch: 9 step: 894, loss is 0.012458980083465576\n",
      "epoch: 9 step: 895, loss is 0.0007724403403699398\n",
      "epoch: 9 step: 896, loss is 0.0006630118587054312\n",
      "epoch: 9 step: 897, loss is 0.00029064714908599854\n",
      "epoch: 9 step: 898, loss is 5.4279083997244015e-05\n",
      "epoch: 9 step: 899, loss is 0.0002803247480187565\n",
      "epoch: 9 step: 900, loss is 0.00023376655008178204\n",
      "epoch: 9 step: 901, loss is 0.0001852386922109872\n",
      "epoch: 9 step: 902, loss is 0.0074780769646167755\n",
      "epoch: 9 step: 903, loss is 0.0007301379228010774\n",
      "epoch: 9 step: 904, loss is 0.012352497316896915\n",
      "epoch: 9 step: 905, loss is 5.094586595077999e-05\n",
      "epoch: 9 step: 906, loss is 0.001197279547341168\n",
      "epoch: 9 step: 907, loss is 0.005821274593472481\n",
      "epoch: 9 step: 908, loss is 0.0031382341403514147\n",
      "epoch: 9 step: 909, loss is 0.0004702387086581439\n",
      "epoch: 9 step: 910, loss is 0.02661227062344551\n",
      "epoch: 9 step: 911, loss is 8.182744204532355e-05\n",
      "epoch: 9 step: 912, loss is 0.0023608591873198748\n",
      "epoch: 9 step: 913, loss is 0.00015379427350126207\n",
      "epoch: 9 step: 914, loss is 0.006767020095139742\n",
      "epoch: 9 step: 915, loss is 8.124201121972874e-05\n",
      "epoch: 9 step: 916, loss is 0.00015190757403615862\n",
      "epoch: 9 step: 917, loss is 0.0026700010057538748\n",
      "epoch: 9 step: 918, loss is 0.012584134936332703\n",
      "epoch: 9 step: 919, loss is 2.3594313461217098e-05\n",
      "epoch: 9 step: 920, loss is 6.354945071507245e-05\n",
      "epoch: 9 step: 921, loss is 7.009549881331623e-05\n",
      "epoch: 9 step: 922, loss is 0.00025591551093384624\n",
      "epoch: 9 step: 923, loss is 0.0014424290275201201\n",
      "epoch: 9 step: 924, loss is 3.724019188666716e-05\n",
      "epoch: 9 step: 925, loss is 2.7054957172367722e-05\n",
      "epoch: 9 step: 926, loss is 0.0003117000451311469\n",
      "epoch: 9 step: 927, loss is 0.0006569844554178417\n",
      "epoch: 9 step: 928, loss is 0.036999620497226715\n",
      "epoch: 9 step: 929, loss is 0.0011330769630149007\n",
      "epoch: 9 step: 930, loss is 0.0022723570000380278\n",
      "epoch: 9 step: 931, loss is 0.020486019551753998\n",
      "epoch: 9 step: 932, loss is 0.0008036228828132153\n",
      "epoch: 9 step: 933, loss is 0.00019676129159051925\n",
      "epoch: 9 step: 934, loss is 0.0012927737552672625\n",
      "epoch: 9 step: 935, loss is 1.8234381059301086e-05\n",
      "epoch: 9 step: 936, loss is 0.0037520742043852806\n",
      "epoch: 9 step: 937, loss is 0.0031977519392967224\n",
      "epoch: 9 step: 938, loss is 0.0007984781987033784\n",
      "epoch: 9 step: 939, loss is 0.02045035921037197\n",
      "epoch: 9 step: 940, loss is 0.02876567840576172\n",
      "epoch: 9 step: 941, loss is 0.008643394336104393\n",
      "epoch: 9 step: 942, loss is 1.2609429177246056e-05\n",
      "epoch: 9 step: 943, loss is 0.0010795812122523785\n",
      "epoch: 9 step: 944, loss is 0.0002499068505130708\n",
      "epoch: 9 step: 945, loss is 0.00046991746057756245\n",
      "epoch: 9 step: 946, loss is 1.5187663848337252e-05\n",
      "epoch: 9 step: 947, loss is 0.007986697368323803\n",
      "epoch: 9 step: 948, loss is 0.0012894723331555724\n",
      "epoch: 9 step: 949, loss is 0.0017679237062111497\n",
      "epoch: 9 step: 950, loss is 0.00038924673572182655\n",
      "epoch: 9 step: 951, loss is 0.009553472511470318\n",
      "epoch: 9 step: 952, loss is 0.006906024180352688\n",
      "epoch: 9 step: 953, loss is 0.0036373597104102373\n",
      "epoch: 9 step: 954, loss is 0.007177327293902636\n",
      "epoch: 9 step: 955, loss is 0.0001272413064725697\n",
      "epoch: 9 step: 956, loss is 0.01852230913937092\n",
      "epoch: 9 step: 957, loss is 9.385441080667078e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 958, loss is 1.2161963240941986e-05\n",
      "epoch: 9 step: 959, loss is 0.0007268796907737851\n",
      "epoch: 9 step: 960, loss is 2.9130358598195016e-05\n",
      "epoch: 9 step: 961, loss is 0.011770918034017086\n",
      "epoch: 9 step: 962, loss is 0.08202173560857773\n",
      "epoch: 9 step: 963, loss is 0.00045167357893660665\n",
      "epoch: 9 step: 964, loss is 0.00029324457864277065\n",
      "epoch: 9 step: 965, loss is 0.00020410532306414098\n",
      "epoch: 9 step: 966, loss is 0.00042803853284567595\n",
      "epoch: 9 step: 967, loss is 2.6361047275713645e-05\n",
      "epoch: 9 step: 968, loss is 0.014182155951857567\n",
      "epoch: 9 step: 969, loss is 0.0004397781449370086\n",
      "epoch: 9 step: 970, loss is 0.000765516422688961\n",
      "epoch: 9 step: 971, loss is 2.045534893113654e-05\n",
      "epoch: 9 step: 972, loss is 0.0007967643905431032\n",
      "epoch: 9 step: 973, loss is 2.546682117099408e-05\n",
      "epoch: 9 step: 974, loss is 0.0001913805608637631\n",
      "epoch: 9 step: 975, loss is 0.018543632701039314\n",
      "epoch: 9 step: 976, loss is 0.0313267707824707\n",
      "epoch: 9 step: 977, loss is 0.00011161286965943873\n",
      "epoch: 9 step: 978, loss is 0.0009025302715599537\n",
      "epoch: 9 step: 979, loss is 0.049738600850105286\n",
      "epoch: 9 step: 980, loss is 0.0005056351656094193\n",
      "epoch: 9 step: 981, loss is 0.0024171217810362577\n",
      "epoch: 9 step: 982, loss is 0.003356377827003598\n",
      "epoch: 9 step: 983, loss is 0.00015553669072687626\n",
      "epoch: 9 step: 984, loss is 0.015747006982564926\n",
      "epoch: 9 step: 985, loss is 0.0005142552545294166\n",
      "epoch: 9 step: 986, loss is 3.185121749993414e-05\n",
      "epoch: 9 step: 987, loss is 0.0002536780957598239\n",
      "epoch: 9 step: 988, loss is 0.00015615303709637374\n",
      "epoch: 9 step: 989, loss is 0.0010229843901470304\n",
      "epoch: 9 step: 990, loss is 0.0054326485842466354\n",
      "epoch: 9 step: 991, loss is 0.0011673815315589309\n",
      "epoch: 9 step: 992, loss is 2.8534253942780197e-05\n",
      "epoch: 9 step: 993, loss is 0.0004840705369133502\n",
      "epoch: 9 step: 994, loss is 0.001965023810043931\n",
      "epoch: 9 step: 995, loss is 0.007965213619172573\n",
      "epoch: 9 step: 996, loss is 0.00011364142847014591\n",
      "epoch: 9 step: 997, loss is 0.0015793748898431659\n",
      "epoch: 9 step: 998, loss is 3.438154817558825e-05\n",
      "epoch: 9 step: 999, loss is 0.00019021374464500695\n",
      "epoch: 9 step: 1000, loss is 8.653680561110377e-05\n",
      "epoch: 9 step: 1001, loss is 0.0013590221060439944\n",
      "epoch: 9 step: 1002, loss is 5.579569551628083e-05\n",
      "epoch: 9 step: 1003, loss is 0.013187193311750889\n",
      "epoch: 9 step: 1004, loss is 7.541203376604244e-05\n",
      "epoch: 9 step: 1005, loss is 0.0004762945754919201\n",
      "epoch: 9 step: 1006, loss is 0.00022503452782984823\n",
      "epoch: 9 step: 1007, loss is 7.156954234233126e-05\n",
      "epoch: 9 step: 1008, loss is 0.0002878321392927319\n",
      "epoch: 9 step: 1009, loss is 5.577687988989055e-05\n",
      "epoch: 9 step: 1010, loss is 0.0009031064109876752\n",
      "epoch: 9 step: 1011, loss is 0.09773991256952286\n",
      "epoch: 9 step: 1012, loss is 0.002059296239167452\n",
      "epoch: 9 step: 1013, loss is 0.012512419372797012\n",
      "epoch: 9 step: 1014, loss is 0.00014738927711732686\n",
      "epoch: 9 step: 1015, loss is 4.476825415622443e-05\n",
      "epoch: 9 step: 1016, loss is 0.04698389023542404\n",
      "epoch: 9 step: 1017, loss is 6.214191671460867e-06\n",
      "epoch: 9 step: 1018, loss is 0.0011965951416641474\n",
      "epoch: 9 step: 1019, loss is 0.03345607593655586\n",
      "epoch: 9 step: 1020, loss is 0.0012859252747148275\n",
      "epoch: 9 step: 1021, loss is 7.431974518112838e-05\n",
      "epoch: 9 step: 1022, loss is 0.00019964846433140337\n",
      "epoch: 9 step: 1023, loss is 0.011525196954607964\n",
      "epoch: 9 step: 1024, loss is 5.251539914752357e-05\n",
      "epoch: 9 step: 1025, loss is 0.0063967015594244\n",
      "epoch: 9 step: 1026, loss is 0.003844867693260312\n",
      "epoch: 9 step: 1027, loss is 0.00019628583686426282\n",
      "epoch: 9 step: 1028, loss is 3.26041154039558e-05\n",
      "epoch: 9 step: 1029, loss is 0.012319718487560749\n",
      "epoch: 9 step: 1030, loss is 1.9557999166863738e-06\n",
      "epoch: 9 step: 1031, loss is 0.0009618723415769637\n",
      "epoch: 9 step: 1032, loss is 0.00045386498095467687\n",
      "epoch: 9 step: 1033, loss is 8.799502211331856e-06\n",
      "epoch: 9 step: 1034, loss is 0.0004526938428170979\n",
      "epoch: 9 step: 1035, loss is 0.002121987286955118\n",
      "epoch: 9 step: 1036, loss is 0.00014143729640636593\n",
      "epoch: 9 step: 1037, loss is 0.0006496130954474211\n",
      "epoch: 9 step: 1038, loss is 0.04072180762887001\n",
      "epoch: 9 step: 1039, loss is 0.12567174434661865\n",
      "epoch: 9 step: 1040, loss is 5.225743734627031e-05\n",
      "epoch: 9 step: 1041, loss is 8.709998655831441e-05\n",
      "epoch: 9 step: 1042, loss is 0.001219418947584927\n",
      "epoch: 9 step: 1043, loss is 6.0078247770434245e-05\n",
      "epoch: 9 step: 1044, loss is 0.06666412204504013\n",
      "epoch: 9 step: 1045, loss is 1.2691249139606953e-05\n",
      "epoch: 9 step: 1046, loss is 0.043383460491895676\n",
      "epoch: 9 step: 1047, loss is 0.00031338652479462326\n",
      "epoch: 9 step: 1048, loss is 0.00013277094694785774\n",
      "epoch: 9 step: 1049, loss is 0.00022545667889062315\n",
      "epoch: 9 step: 1050, loss is 3.250854933867231e-05\n",
      "epoch: 9 step: 1051, loss is 0.000990719418041408\n",
      "epoch: 9 step: 1052, loss is 1.0485499842616264e-05\n",
      "epoch: 9 step: 1053, loss is 0.0016123753739520907\n",
      "epoch: 9 step: 1054, loss is 0.0007934984751045704\n",
      "epoch: 9 step: 1055, loss is 0.0401507243514061\n",
      "epoch: 9 step: 1056, loss is 0.013941165991127491\n",
      "epoch: 9 step: 1057, loss is 8.722117490833625e-05\n",
      "epoch: 9 step: 1058, loss is 8.475837239529938e-05\n",
      "epoch: 9 step: 1059, loss is 0.002291504293680191\n",
      "epoch: 9 step: 1060, loss is 0.15817111730575562\n",
      "epoch: 9 step: 1061, loss is 0.0020814216695725918\n",
      "epoch: 9 step: 1062, loss is 0.0038672140799462795\n",
      "epoch: 9 step: 1063, loss is 0.07574770599603653\n",
      "epoch: 9 step: 1064, loss is 0.005601412151008844\n",
      "epoch: 9 step: 1065, loss is 0.06655832380056381\n",
      "epoch: 9 step: 1066, loss is 0.018203210085630417\n",
      "epoch: 9 step: 1067, loss is 0.00026203025481663644\n",
      "epoch: 9 step: 1068, loss is 0.0006833498482592404\n",
      "epoch: 9 step: 1069, loss is 0.006456249393522739\n",
      "epoch: 9 step: 1070, loss is 8.921997505240142e-05\n",
      "epoch: 9 step: 1071, loss is 0.005111264530569315\n",
      "epoch: 9 step: 1072, loss is 0.006122128572314978\n",
      "epoch: 9 step: 1073, loss is 0.0017023353138938546\n",
      "epoch: 9 step: 1074, loss is 0.013997359201312065\n",
      "epoch: 9 step: 1075, loss is 0.00025547388941049576\n",
      "epoch: 9 step: 1076, loss is 0.0021504953037947416\n",
      "epoch: 9 step: 1077, loss is 0.0005588899366557598\n",
      "epoch: 9 step: 1078, loss is 7.329980871872976e-05\n",
      "epoch: 9 step: 1079, loss is 8.745583181735128e-05\n",
      "epoch: 9 step: 1080, loss is 0.0007456645835191011\n",
      "epoch: 9 step: 1081, loss is 7.293116505024955e-05\n",
      "epoch: 9 step: 1082, loss is 4.626404552254826e-05\n",
      "epoch: 9 step: 1083, loss is 0.00036234856816008687\n",
      "epoch: 9 step: 1084, loss is 0.017444228753447533\n",
      "epoch: 9 step: 1085, loss is 0.0037811705842614174\n",
      "epoch: 9 step: 1086, loss is 0.10316967964172363\n",
      "epoch: 9 step: 1087, loss is 0.0002603069879114628\n",
      "epoch: 9 step: 1088, loss is 0.03467274457216263\n",
      "epoch: 9 step: 1089, loss is 0.00012750709720421582\n",
      "epoch: 9 step: 1090, loss is 5.71373529965058e-05\n",
      "epoch: 9 step: 1091, loss is 3.063764961552806e-05\n",
      "epoch: 9 step: 1092, loss is 0.00012042334128636867\n",
      "epoch: 9 step: 1093, loss is 0.0021521328017115593\n",
      "epoch: 9 step: 1094, loss is 0.00034359251731075346\n",
      "epoch: 9 step: 1095, loss is 0.0004666633321903646\n",
      "epoch: 9 step: 1096, loss is 0.004621804691851139\n",
      "epoch: 9 step: 1097, loss is 1.6370486264349893e-05\n",
      "epoch: 9 step: 1098, loss is 9.622343350201845e-05\n",
      "epoch: 9 step: 1099, loss is 0.00020346316159702837\n",
      "epoch: 9 step: 1100, loss is 0.0001581823598826304\n",
      "epoch: 9 step: 1101, loss is 1.311882988375146e-05\n",
      "epoch: 9 step: 1102, loss is 0.0028465758077800274\n",
      "epoch: 9 step: 1103, loss is 0.00346206221729517\n",
      "epoch: 9 step: 1104, loss is 0.0017151067731902003\n",
      "epoch: 9 step: 1105, loss is 8.129116758937016e-05\n",
      "epoch: 9 step: 1106, loss is 0.00019726624304894358\n",
      "epoch: 9 step: 1107, loss is 0.00010329919314244762\n",
      "epoch: 9 step: 1108, loss is 0.00036222912603989244\n",
      "epoch: 9 step: 1109, loss is 0.006202807184308767\n",
      "epoch: 9 step: 1110, loss is 0.1431654393672943\n",
      "epoch: 9 step: 1111, loss is 0.0021025061141699553\n",
      "epoch: 9 step: 1112, loss is 0.0008514190558344126\n",
      "epoch: 9 step: 1113, loss is 4.6903141992515884e-06\n",
      "epoch: 9 step: 1114, loss is 0.0027922107838094234\n",
      "epoch: 9 step: 1115, loss is 0.002106184372678399\n",
      "epoch: 9 step: 1116, loss is 0.00395527109503746\n",
      "epoch: 9 step: 1117, loss is 2.3336893718806095e-05\n",
      "epoch: 9 step: 1118, loss is 0.0004542813403531909\n",
      "epoch: 9 step: 1119, loss is 0.0048882304690778255\n",
      "epoch: 9 step: 1120, loss is 0.013678274117410183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1121, loss is 3.080331953242421e-05\n",
      "epoch: 9 step: 1122, loss is 7.652756903553382e-05\n",
      "epoch: 9 step: 1123, loss is 0.0002614373224787414\n",
      "epoch: 9 step: 1124, loss is 1.3614447198051494e-05\n",
      "epoch: 9 step: 1125, loss is 0.000955544994212687\n",
      "epoch: 9 step: 1126, loss is 0.00018361772526986897\n",
      "epoch: 9 step: 1127, loss is 0.024780811741948128\n",
      "epoch: 9 step: 1128, loss is 4.373729098006152e-06\n",
      "epoch: 9 step: 1129, loss is 0.00045856653014197946\n",
      "epoch: 9 step: 1130, loss is 0.0003729390155058354\n",
      "epoch: 9 step: 1131, loss is 0.0027524521574378014\n",
      "epoch: 9 step: 1132, loss is 1.0181584002566524e-05\n",
      "epoch: 9 step: 1133, loss is 0.0057495469227433205\n",
      "epoch: 9 step: 1134, loss is 0.0004858759930357337\n",
      "epoch: 9 step: 1135, loss is 0.0002867126895580441\n",
      "epoch: 9 step: 1136, loss is 0.002355583244934678\n",
      "epoch: 9 step: 1137, loss is 0.00027672515716403723\n",
      "epoch: 9 step: 1138, loss is 2.7903179216082208e-06\n",
      "epoch: 9 step: 1139, loss is 0.0007196224760264158\n",
      "epoch: 9 step: 1140, loss is 0.016573596745729446\n",
      "epoch: 9 step: 1141, loss is 0.055658064782619476\n",
      "epoch: 9 step: 1142, loss is 0.0002017555380007252\n",
      "epoch: 9 step: 1143, loss is 8.38696796563454e-05\n",
      "epoch: 9 step: 1144, loss is 9.655776375439018e-05\n",
      "epoch: 9 step: 1145, loss is 3.4289427276235074e-05\n",
      "epoch: 9 step: 1146, loss is 1.0997871868312359e-05\n",
      "epoch: 9 step: 1147, loss is 0.038435738533735275\n",
      "epoch: 9 step: 1148, loss is 0.00012191341375000775\n",
      "epoch: 9 step: 1149, loss is 3.91535104427021e-06\n",
      "epoch: 9 step: 1150, loss is 1.6094627426355146e-05\n",
      "epoch: 9 step: 1151, loss is 7.903676305431873e-05\n",
      "epoch: 9 step: 1152, loss is 1.110923221858684e-05\n",
      "epoch: 9 step: 1153, loss is 0.0006516812718473375\n",
      "epoch: 9 step: 1154, loss is 0.00013831385876983404\n",
      "epoch: 9 step: 1155, loss is 0.011615696363151073\n",
      "epoch: 9 step: 1156, loss is 0.00017998323892243207\n",
      "epoch: 9 step: 1157, loss is 0.008629022166132927\n",
      "epoch: 9 step: 1158, loss is 4.3049632949987426e-05\n",
      "epoch: 9 step: 1159, loss is 3.678528810269199e-05\n",
      "epoch: 9 step: 1160, loss is 0.0027422981802374125\n",
      "epoch: 9 step: 1161, loss is 8.103498112177476e-05\n",
      "epoch: 9 step: 1162, loss is 0.10840197652578354\n",
      "epoch: 9 step: 1163, loss is 0.0006888208445161581\n",
      "epoch: 9 step: 1164, loss is 0.0011177884880453348\n",
      "epoch: 9 step: 1165, loss is 0.07745315879583359\n",
      "epoch: 9 step: 1166, loss is 0.00017893909534905106\n",
      "epoch: 9 step: 1167, loss is 0.001255464507266879\n",
      "epoch: 9 step: 1168, loss is 3.920928793377243e-05\n",
      "epoch: 9 step: 1169, loss is 0.031842026859521866\n",
      "epoch: 9 step: 1170, loss is 0.00014327628014143556\n",
      "epoch: 9 step: 1171, loss is 0.0005405321717262268\n",
      "epoch: 9 step: 1172, loss is 4.017673199996352e-05\n",
      "epoch: 9 step: 1173, loss is 0.0012281867675483227\n",
      "epoch: 9 step: 1174, loss is 2.0167080947430804e-05\n",
      "epoch: 9 step: 1175, loss is 0.0034549348056316376\n",
      "epoch: 9 step: 1176, loss is 0.007995108142495155\n",
      "epoch: 9 step: 1177, loss is 0.02012275718152523\n",
      "epoch: 9 step: 1178, loss is 0.00027035840321332216\n",
      "epoch: 9 step: 1179, loss is 0.0028008429799228907\n",
      "epoch: 9 step: 1180, loss is 0.00017907493747770786\n",
      "epoch: 9 step: 1181, loss is 0.00011122148862341419\n",
      "epoch: 9 step: 1182, loss is 0.003653589403256774\n",
      "epoch: 9 step: 1183, loss is 0.08173717558383942\n",
      "epoch: 9 step: 1184, loss is 0.0010089492425322533\n",
      "epoch: 9 step: 1185, loss is 0.0013486983953043818\n",
      "epoch: 9 step: 1186, loss is 0.0013613298069685698\n",
      "epoch: 9 step: 1187, loss is 0.1237291619181633\n",
      "epoch: 9 step: 1188, loss is 0.0018836549716070294\n",
      "epoch: 9 step: 1189, loss is 0.0001335507695330307\n",
      "epoch: 9 step: 1190, loss is 0.00033715504105202854\n",
      "epoch: 9 step: 1191, loss is 0.0013768563512712717\n",
      "epoch: 9 step: 1192, loss is 0.002989813918247819\n",
      "epoch: 9 step: 1193, loss is 3.158466279273853e-05\n",
      "epoch: 9 step: 1194, loss is 0.01861879602074623\n",
      "epoch: 9 step: 1195, loss is 1.034917113429401e-05\n",
      "epoch: 9 step: 1196, loss is 0.00261661596596241\n",
      "epoch: 9 step: 1197, loss is 1.518667249911232e-05\n",
      "epoch: 9 step: 1198, loss is 0.004817287437617779\n",
      "epoch: 9 step: 1199, loss is 0.00047254806850105524\n",
      "epoch: 9 step: 1200, loss is 0.002719363896176219\n",
      "epoch: 9 step: 1201, loss is 0.06352779269218445\n",
      "epoch: 9 step: 1202, loss is 7.956457557156682e-05\n",
      "epoch: 9 step: 1203, loss is 0.00035004361416213214\n",
      "epoch: 9 step: 1204, loss is 0.00021928615751676261\n",
      "epoch: 9 step: 1205, loss is 0.0013501631328836083\n",
      "epoch: 9 step: 1206, loss is 0.00010413949348730966\n",
      "epoch: 9 step: 1207, loss is 0.0027076173573732376\n",
      "epoch: 9 step: 1208, loss is 0.00835479237139225\n",
      "epoch: 9 step: 1209, loss is 0.00011665679630823433\n",
      "epoch: 9 step: 1210, loss is 5.433860496850684e-05\n",
      "epoch: 9 step: 1211, loss is 0.00018627815006766468\n",
      "epoch: 9 step: 1212, loss is 0.000917966419365257\n",
      "epoch: 9 step: 1213, loss is 0.004540194757282734\n",
      "epoch: 9 step: 1214, loss is 0.00010699436097638682\n",
      "epoch: 9 step: 1215, loss is 0.11011239141225815\n",
      "epoch: 9 step: 1216, loss is 2.391533416812308e-05\n",
      "epoch: 9 step: 1217, loss is 0.0053893993608653545\n",
      "epoch: 9 step: 1218, loss is 7.763374014757574e-05\n",
      "epoch: 9 step: 1219, loss is 2.6710608835855965e-06\n",
      "epoch: 9 step: 1220, loss is 0.002135963412001729\n",
      "epoch: 9 step: 1221, loss is 0.0014033782063052058\n",
      "epoch: 9 step: 1222, loss is 0.0003222742525395006\n",
      "epoch: 9 step: 1223, loss is 0.00226984778419137\n",
      "epoch: 9 step: 1224, loss is 0.0002457547525409609\n",
      "epoch: 9 step: 1225, loss is 7.827267836546525e-05\n",
      "epoch: 9 step: 1226, loss is 0.00017374141316395253\n",
      "epoch: 9 step: 1227, loss is 0.003489557420834899\n",
      "epoch: 9 step: 1228, loss is 0.0020776442252099514\n",
      "epoch: 9 step: 1229, loss is 0.001733022159896791\n",
      "epoch: 9 step: 1230, loss is 1.613500171515625e-05\n",
      "epoch: 9 step: 1231, loss is 7.600471144542098e-05\n",
      "epoch: 9 step: 1232, loss is 0.00019426507060416043\n",
      "epoch: 9 step: 1233, loss is 0.0071555147878825665\n",
      "epoch: 9 step: 1234, loss is 0.0011188506614416838\n",
      "epoch: 9 step: 1235, loss is 0.0003345166624058038\n",
      "epoch: 9 step: 1236, loss is 0.012129717506468296\n",
      "epoch: 9 step: 1237, loss is 4.683625957113691e-05\n",
      "epoch: 9 step: 1238, loss is 0.0025324970483779907\n",
      "epoch: 9 step: 1239, loss is 0.0005216346471570432\n",
      "epoch: 9 step: 1240, loss is 0.02295553870499134\n",
      "epoch: 9 step: 1241, loss is 2.4562186808907427e-05\n",
      "epoch: 9 step: 1242, loss is 0.00010314326209481806\n",
      "epoch: 9 step: 1243, loss is 0.0007275227690115571\n",
      "epoch: 9 step: 1244, loss is 9.656586371420417e-06\n",
      "epoch: 9 step: 1245, loss is 0.0007962853414937854\n",
      "epoch: 9 step: 1246, loss is 0.01702551729977131\n",
      "epoch: 9 step: 1247, loss is 5.9529429563554004e-05\n",
      "epoch: 9 step: 1248, loss is 0.01762067899107933\n",
      "epoch: 9 step: 1249, loss is 0.0002196200512116775\n",
      "epoch: 9 step: 1250, loss is 0.0005411317688412964\n",
      "epoch: 9 step: 1251, loss is 0.0021844017319381237\n",
      "epoch: 9 step: 1252, loss is 0.0014659063890576363\n",
      "epoch: 9 step: 1253, loss is 1.1879166777362116e-05\n",
      "epoch: 9 step: 1254, loss is 0.04818189889192581\n",
      "epoch: 9 step: 1255, loss is 4.9137292080558836e-05\n",
      "epoch: 9 step: 1256, loss is 0.0003879343275912106\n",
      "epoch: 9 step: 1257, loss is 0.0013641428668051958\n",
      "epoch: 9 step: 1258, loss is 1.0132887382496847e-06\n",
      "epoch: 9 step: 1259, loss is 0.0070853447541594505\n",
      "epoch: 9 step: 1260, loss is 5.301239525579149e-06\n",
      "epoch: 9 step: 1261, loss is 0.01277963537722826\n",
      "epoch: 9 step: 1262, loss is 0.0017336849123239517\n",
      "epoch: 9 step: 1263, loss is 0.00019341368169989437\n",
      "epoch: 9 step: 1264, loss is 0.01904933527112007\n",
      "epoch: 9 step: 1265, loss is 0.0006929738447070122\n",
      "epoch: 9 step: 1266, loss is 0.00027569010853767395\n",
      "epoch: 9 step: 1267, loss is 2.0858124116784893e-05\n",
      "epoch: 9 step: 1268, loss is 9.009931818582118e-05\n",
      "epoch: 9 step: 1269, loss is 0.004612463992089033\n",
      "epoch: 9 step: 1270, loss is 0.01042023953050375\n",
      "epoch: 9 step: 1271, loss is 0.0008081773412413895\n",
      "epoch: 9 step: 1272, loss is 0.030001889914274216\n",
      "epoch: 9 step: 1273, loss is 0.00014713994460180402\n",
      "epoch: 9 step: 1274, loss is 0.00038667142507620156\n",
      "epoch: 9 step: 1275, loss is 6.418208067771047e-05\n",
      "epoch: 9 step: 1276, loss is 0.03948087617754936\n",
      "epoch: 9 step: 1277, loss is 0.0022484520450234413\n",
      "epoch: 9 step: 1278, loss is 0.0027361370157450438\n",
      "epoch: 9 step: 1279, loss is 7.655724402866326e-06\n",
      "epoch: 9 step: 1280, loss is 3.4423214856360573e-06\n",
      "epoch: 9 step: 1281, loss is 1.4872248357278295e-05\n",
      "epoch: 9 step: 1282, loss is 0.00018985792121384293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1283, loss is 0.0007121172966435552\n",
      "epoch: 9 step: 1284, loss is 0.01774395816028118\n",
      "epoch: 9 step: 1285, loss is 0.0024347109720110893\n",
      "epoch: 9 step: 1286, loss is 3.3978114515775815e-05\n",
      "epoch: 9 step: 1287, loss is 0.00018956430722028017\n",
      "epoch: 9 step: 1288, loss is 0.0013200759422034025\n",
      "epoch: 9 step: 1289, loss is 0.00040925905341282487\n",
      "epoch: 9 step: 1290, loss is 0.02612622268497944\n",
      "epoch: 9 step: 1291, loss is 0.0007263785810209811\n",
      "epoch: 9 step: 1292, loss is 0.0017065549036487937\n",
      "epoch: 9 step: 1293, loss is 1.5081734090927057e-05\n",
      "epoch: 9 step: 1294, loss is 0.00025958637706935406\n",
      "epoch: 9 step: 1295, loss is 0.00022087864635977894\n",
      "epoch: 9 step: 1296, loss is 0.00032314821146428585\n",
      "epoch: 9 step: 1297, loss is 0.000825977826025337\n",
      "epoch: 9 step: 1298, loss is 0.0016487040556967258\n",
      "epoch: 9 step: 1299, loss is 1.408181219630933e-06\n",
      "epoch: 9 step: 1300, loss is 0.00013034870789851993\n",
      "epoch: 9 step: 1301, loss is 0.0019060500198975205\n",
      "epoch: 9 step: 1302, loss is 0.004784092307090759\n",
      "epoch: 9 step: 1303, loss is 6.187849066918716e-06\n",
      "epoch: 9 step: 1304, loss is 0.0005800333456136286\n",
      "epoch: 9 step: 1305, loss is 0.007004923187196255\n",
      "epoch: 9 step: 1306, loss is 0.005690296646207571\n",
      "epoch: 9 step: 1307, loss is 0.0001349777594441548\n",
      "epoch: 9 step: 1308, loss is 3.151635610265657e-05\n",
      "epoch: 9 step: 1309, loss is 4.563501715892926e-05\n",
      "epoch: 9 step: 1310, loss is 5.267002779874019e-05\n",
      "epoch: 9 step: 1311, loss is 0.048357412219047546\n",
      "epoch: 9 step: 1312, loss is 0.00010035552986664698\n",
      "epoch: 9 step: 1313, loss is 0.0005712130223400891\n",
      "epoch: 9 step: 1314, loss is 2.6355948648415506e-05\n",
      "epoch: 9 step: 1315, loss is 9.242902706319e-06\n",
      "epoch: 9 step: 1316, loss is 0.0010359594598412514\n",
      "epoch: 9 step: 1317, loss is 0.001000064890831709\n",
      "epoch: 9 step: 1318, loss is 0.00019693879585247487\n",
      "epoch: 9 step: 1319, loss is 0.0058936551213264465\n",
      "epoch: 9 step: 1320, loss is 0.005499858874827623\n",
      "epoch: 9 step: 1321, loss is 0.0018046917393803596\n",
      "epoch: 9 step: 1322, loss is 9.977107765735127e-06\n",
      "epoch: 9 step: 1323, loss is 0.00422010337933898\n",
      "epoch: 9 step: 1324, loss is 0.00011816677579190582\n",
      "epoch: 9 step: 1325, loss is 5.737041283282451e-05\n",
      "epoch: 9 step: 1326, loss is 0.0001253516529686749\n",
      "epoch: 9 step: 1327, loss is 0.00020643547759391367\n",
      "epoch: 9 step: 1328, loss is 0.002518201246857643\n",
      "epoch: 9 step: 1329, loss is 1.524131675978424e-05\n",
      "epoch: 9 step: 1330, loss is 0.0023142718710005283\n",
      "epoch: 9 step: 1331, loss is 7.197389641078189e-05\n",
      "epoch: 9 step: 1332, loss is 0.011852549389004707\n",
      "epoch: 9 step: 1333, loss is 1.5135278772504535e-05\n",
      "epoch: 9 step: 1334, loss is 0.015750166028738022\n",
      "epoch: 9 step: 1335, loss is 0.0009406418539583683\n",
      "epoch: 9 step: 1336, loss is 0.0007382102194242179\n",
      "epoch: 9 step: 1337, loss is 0.24839496612548828\n",
      "epoch: 9 step: 1338, loss is 0.0004779876908287406\n",
      "epoch: 9 step: 1339, loss is 1.5124292076507118e-05\n",
      "epoch: 9 step: 1340, loss is 0.031797681003808975\n",
      "epoch: 9 step: 1341, loss is 0.01821155659854412\n",
      "epoch: 9 step: 1342, loss is 0.00727404048666358\n",
      "epoch: 9 step: 1343, loss is 0.0010850413236767054\n",
      "epoch: 9 step: 1344, loss is 4.366139819467207e-06\n",
      "epoch: 9 step: 1345, loss is 0.00010293654486304149\n",
      "epoch: 9 step: 1346, loss is 0.1880989521741867\n",
      "epoch: 9 step: 1347, loss is 0.0003883018798660487\n",
      "epoch: 9 step: 1348, loss is 2.216562097601127e-05\n",
      "epoch: 9 step: 1349, loss is 0.00010893388389376923\n",
      "epoch: 9 step: 1350, loss is 1.9921570128644817e-05\n",
      "epoch: 9 step: 1351, loss is 0.0016488959081470966\n",
      "epoch: 9 step: 1352, loss is 0.00019296740356367081\n",
      "epoch: 9 step: 1353, loss is 6.531295366585255e-05\n",
      "epoch: 9 step: 1354, loss is 0.0025279223918914795\n",
      "epoch: 9 step: 1355, loss is 0.0002308402326889336\n",
      "epoch: 9 step: 1356, loss is 0.011743543669581413\n",
      "epoch: 9 step: 1357, loss is 0.003299911506474018\n",
      "epoch: 9 step: 1358, loss is 0.0019016230944544077\n",
      "epoch: 9 step: 1359, loss is 0.0007297526462934911\n",
      "epoch: 9 step: 1360, loss is 0.006271782331168652\n",
      "epoch: 9 step: 1361, loss is 9.041632438311353e-06\n",
      "epoch: 9 step: 1362, loss is 1.3827826478518546e-05\n",
      "epoch: 9 step: 1363, loss is 0.01911417581140995\n",
      "epoch: 9 step: 1364, loss is 1.0235806257696822e-05\n",
      "epoch: 9 step: 1365, loss is 0.00015574735880363733\n",
      "epoch: 9 step: 1366, loss is 0.0013523524394258857\n",
      "epoch: 9 step: 1367, loss is 0.0003970004618167877\n",
      "epoch: 9 step: 1368, loss is 0.08465797454118729\n",
      "epoch: 9 step: 1369, loss is 0.001441383734345436\n",
      "epoch: 9 step: 1370, loss is 6.276150816120207e-05\n",
      "epoch: 9 step: 1371, loss is 0.0028489157557487488\n",
      "epoch: 9 step: 1372, loss is 5.3020576160633937e-05\n",
      "epoch: 9 step: 1373, loss is 0.07464819401502609\n",
      "epoch: 9 step: 1374, loss is 0.028834186494350433\n",
      "epoch: 9 step: 1375, loss is 0.0003341557167004794\n",
      "epoch: 9 step: 1376, loss is 0.014020453207194805\n",
      "epoch: 9 step: 1377, loss is 0.006644065026193857\n",
      "epoch: 9 step: 1378, loss is 0.00028085883241146803\n",
      "epoch: 9 step: 1379, loss is 0.0008817905909381807\n",
      "epoch: 9 step: 1380, loss is 1.183801214210689e-05\n",
      "epoch: 9 step: 1381, loss is 0.00011653846013359725\n",
      "epoch: 9 step: 1382, loss is 0.04816530644893646\n",
      "epoch: 9 step: 1383, loss is 0.00012061469897162169\n",
      "epoch: 9 step: 1384, loss is 0.0008514877408742905\n",
      "epoch: 9 step: 1385, loss is 0.0008448809385299683\n",
      "epoch: 9 step: 1386, loss is 0.01886744424700737\n",
      "epoch: 9 step: 1387, loss is 3.662550079752691e-05\n",
      "epoch: 9 step: 1388, loss is 0.00036910257767885923\n",
      "epoch: 9 step: 1389, loss is 0.017128553241491318\n",
      "epoch: 9 step: 1390, loss is 0.0005589106003753841\n",
      "epoch: 9 step: 1391, loss is 0.00090902263764292\n",
      "epoch: 9 step: 1392, loss is 0.15068882703781128\n",
      "epoch: 9 step: 1393, loss is 0.0039906431920826435\n",
      "epoch: 9 step: 1394, loss is 0.0012191312853246927\n",
      "epoch: 9 step: 1395, loss is 5.669591701007448e-05\n",
      "epoch: 9 step: 1396, loss is 0.004178243689239025\n",
      "epoch: 9 step: 1397, loss is 0.00040371829527430236\n",
      "epoch: 9 step: 1398, loss is 4.6865206968504936e-06\n",
      "epoch: 9 step: 1399, loss is 0.002007486531510949\n",
      "epoch: 9 step: 1400, loss is 0.010458274744451046\n",
      "epoch: 9 step: 1401, loss is 0.02891978994011879\n",
      "epoch: 9 step: 1402, loss is 0.0022743234876543283\n",
      "epoch: 9 step: 1403, loss is 0.015034472569823265\n",
      "epoch: 9 step: 1404, loss is 8.615383194410242e-06\n",
      "epoch: 9 step: 1405, loss is 3.63906983693596e-05\n",
      "epoch: 9 step: 1406, loss is 0.017540961503982544\n",
      "epoch: 9 step: 1407, loss is 0.00175991072319448\n",
      "epoch: 9 step: 1408, loss is 0.0015499484725296497\n",
      "epoch: 9 step: 1409, loss is 1.580333264428191e-05\n",
      "epoch: 9 step: 1410, loss is 9.407516336068511e-05\n",
      "epoch: 9 step: 1411, loss is 0.0028117042966187\n",
      "epoch: 9 step: 1412, loss is 0.00861633662134409\n",
      "epoch: 9 step: 1413, loss is 7.912887667771429e-06\n",
      "epoch: 9 step: 1414, loss is 0.009893490932881832\n",
      "epoch: 9 step: 1415, loss is 0.044078510254621506\n",
      "epoch: 9 step: 1416, loss is 0.0005084325093775988\n",
      "epoch: 9 step: 1417, loss is 0.0029457733035087585\n",
      "epoch: 9 step: 1418, loss is 0.015450634993612766\n",
      "epoch: 9 step: 1419, loss is 0.00028836907586082816\n",
      "epoch: 9 step: 1420, loss is 0.0010410085087642074\n",
      "epoch: 9 step: 1421, loss is 0.0012190602719783783\n",
      "epoch: 9 step: 1422, loss is 0.0013155497144907713\n",
      "epoch: 9 step: 1423, loss is 0.03773590922355652\n",
      "epoch: 9 step: 1424, loss is 0.009429584257304668\n",
      "epoch: 9 step: 1425, loss is 0.0005609412910416722\n",
      "epoch: 9 step: 1426, loss is 0.0021746158599853516\n",
      "epoch: 9 step: 1427, loss is 0.03247358277440071\n",
      "epoch: 9 step: 1428, loss is 0.001746167428791523\n",
      "epoch: 9 step: 1429, loss is 0.005214402452111244\n",
      "epoch: 9 step: 1430, loss is 0.000603809196036309\n",
      "epoch: 9 step: 1431, loss is 0.037169769406318665\n",
      "epoch: 9 step: 1432, loss is 5.170385702513158e-05\n",
      "epoch: 9 step: 1433, loss is 1.608180537004955e-05\n",
      "epoch: 9 step: 1434, loss is 0.0008307602256536484\n",
      "epoch: 9 step: 1435, loss is 0.023519454523921013\n",
      "epoch: 9 step: 1436, loss is 0.002831208286806941\n",
      "epoch: 9 step: 1437, loss is 0.000790129357483238\n",
      "epoch: 9 step: 1438, loss is 0.11701437830924988\n",
      "epoch: 9 step: 1439, loss is 1.3644827049574815e-05\n",
      "epoch: 9 step: 1440, loss is 0.0003417526895646006\n",
      "epoch: 9 step: 1441, loss is 0.004356075543910265\n",
      "epoch: 9 step: 1442, loss is 0.00019876143778674304\n",
      "epoch: 9 step: 1443, loss is 0.021102819591760635\n",
      "epoch: 9 step: 1444, loss is 0.00022243254352360964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1445, loss is 0.00023941784456837922\n",
      "epoch: 9 step: 1446, loss is 0.0025037750601768494\n",
      "epoch: 9 step: 1447, loss is 5.096291715744883e-06\n",
      "epoch: 9 step: 1448, loss is 0.0004126543353777379\n",
      "epoch: 9 step: 1449, loss is 0.0002121000870829448\n",
      "epoch: 9 step: 1450, loss is 0.021562781184911728\n",
      "epoch: 9 step: 1451, loss is 0.0003674672043416649\n",
      "epoch: 9 step: 1452, loss is 0.0260800588876009\n",
      "epoch: 9 step: 1453, loss is 5.322486686054617e-05\n",
      "epoch: 9 step: 1454, loss is 9.545122156850994e-05\n",
      "epoch: 9 step: 1455, loss is 0.013881364837288857\n",
      "epoch: 9 step: 1456, loss is 0.0034028824884444475\n",
      "epoch: 9 step: 1457, loss is 0.04702680930495262\n",
      "epoch: 9 step: 1458, loss is 7.561154052382335e-05\n",
      "epoch: 9 step: 1459, loss is 0.18343454599380493\n",
      "epoch: 9 step: 1460, loss is 0.00022443020134232938\n",
      "epoch: 9 step: 1461, loss is 0.0020687119103968143\n",
      "epoch: 9 step: 1462, loss is 0.00010216467489954084\n",
      "epoch: 9 step: 1463, loss is 8.022929250728339e-06\n",
      "epoch: 9 step: 1464, loss is 9.473494719713926e-05\n",
      "epoch: 9 step: 1465, loss is 0.0004889254341833293\n",
      "epoch: 9 step: 1466, loss is 0.0374344065785408\n",
      "epoch: 9 step: 1467, loss is 0.086070217192173\n",
      "epoch: 9 step: 1468, loss is 0.0004470236599445343\n",
      "epoch: 9 step: 1469, loss is 0.007753146346658468\n",
      "epoch: 9 step: 1470, loss is 0.08138655126094818\n",
      "epoch: 9 step: 1471, loss is 0.001348772319033742\n",
      "epoch: 9 step: 1472, loss is 0.060736484825611115\n",
      "epoch: 9 step: 1473, loss is 3.006359293067362e-06\n",
      "epoch: 9 step: 1474, loss is 0.0015827241586521268\n",
      "epoch: 9 step: 1475, loss is 0.045277632772922516\n",
      "epoch: 9 step: 1476, loss is 0.0007297335541807115\n",
      "epoch: 9 step: 1477, loss is 0.0016892710700631142\n",
      "epoch: 9 step: 1478, loss is 2.3327214876189828e-05\n",
      "epoch: 9 step: 1479, loss is 0.08352868258953094\n",
      "epoch: 9 step: 1480, loss is 0.12115420401096344\n",
      "epoch: 9 step: 1481, loss is 0.00015473047096747905\n",
      "epoch: 9 step: 1482, loss is 1.4895502317813225e-05\n",
      "epoch: 9 step: 1483, loss is 0.10723377764225006\n",
      "epoch: 9 step: 1484, loss is 7.908591214800254e-05\n",
      "epoch: 9 step: 1485, loss is 3.106512303929776e-05\n",
      "epoch: 9 step: 1486, loss is 0.001076225540600717\n",
      "epoch: 9 step: 1487, loss is 6.806262717873324e-06\n",
      "epoch: 9 step: 1488, loss is 0.05145571380853653\n",
      "epoch: 9 step: 1489, loss is 0.0003853798843920231\n",
      "epoch: 9 step: 1490, loss is 0.004220014438033104\n",
      "epoch: 9 step: 1491, loss is 0.02011481486260891\n",
      "epoch: 9 step: 1492, loss is 0.06264696270227432\n",
      "epoch: 9 step: 1493, loss is 0.012670736759901047\n",
      "epoch: 9 step: 1494, loss is 0.0016047043027356267\n",
      "epoch: 9 step: 1495, loss is 4.690318291977746e-06\n",
      "epoch: 9 step: 1496, loss is 6.792303611291572e-05\n",
      "epoch: 9 step: 1497, loss is 6.81933161104098e-05\n",
      "epoch: 9 step: 1498, loss is 5.1948532927781343e-05\n",
      "epoch: 9 step: 1499, loss is 4.480806092033163e-05\n",
      "epoch: 9 step: 1500, loss is 0.000672649999614805\n",
      "epoch: 9 step: 1501, loss is 0.02196759171783924\n",
      "epoch: 9 step: 1502, loss is 0.02177194133400917\n",
      "epoch: 9 step: 1503, loss is 0.00035903381649404764\n",
      "epoch: 9 step: 1504, loss is 0.0008100265404209495\n",
      "epoch: 9 step: 1505, loss is 0.0012433978263288736\n",
      "epoch: 9 step: 1506, loss is 0.00046579440822824836\n",
      "epoch: 9 step: 1507, loss is 0.0026725998613983393\n",
      "epoch: 9 step: 1508, loss is 0.004555205348879099\n",
      "epoch: 9 step: 1509, loss is 0.006617472507059574\n",
      "epoch: 9 step: 1510, loss is 0.0035284452605992556\n",
      "epoch: 9 step: 1511, loss is 9.178946493193507e-05\n",
      "epoch: 9 step: 1512, loss is 0.00021715594630222768\n",
      "epoch: 9 step: 1513, loss is 0.005938905291259289\n",
      "epoch: 9 step: 1514, loss is 0.001297677750699222\n",
      "epoch: 9 step: 1515, loss is 0.0003856648982036859\n",
      "epoch: 9 step: 1516, loss is 0.02060673199594021\n",
      "epoch: 9 step: 1517, loss is 0.004070485010743141\n",
      "epoch: 9 step: 1518, loss is 1.5782194168423302e-05\n",
      "epoch: 9 step: 1519, loss is 0.004060620907694101\n",
      "epoch: 9 step: 1520, loss is 0.1476457715034485\n",
      "epoch: 9 step: 1521, loss is 1.1387308404664509e-05\n",
      "epoch: 9 step: 1522, loss is 0.011330809444189072\n",
      "epoch: 9 step: 1523, loss is 0.07873591035604477\n",
      "epoch: 9 step: 1524, loss is 0.00032109743915498257\n",
      "epoch: 9 step: 1525, loss is 0.0001593196502653882\n",
      "epoch: 9 step: 1526, loss is 0.0005308634135872126\n",
      "epoch: 9 step: 1527, loss is 0.004806340206414461\n",
      "epoch: 9 step: 1528, loss is 0.0008672254625707865\n",
      "epoch: 9 step: 1529, loss is 9.131067599810194e-06\n",
      "epoch: 9 step: 1530, loss is 0.007661953568458557\n",
      "epoch: 9 step: 1531, loss is 1.2698863429250196e-05\n",
      "epoch: 9 step: 1532, loss is 0.11605759710073471\n",
      "epoch: 9 step: 1533, loss is 0.00013811129610985518\n",
      "epoch: 9 step: 1534, loss is 0.003658549627289176\n",
      "epoch: 9 step: 1535, loss is 0.01641600951552391\n",
      "epoch: 9 step: 1536, loss is 0.00251982850022614\n",
      "epoch: 9 step: 1537, loss is 0.04287376254796982\n",
      "epoch: 9 step: 1538, loss is 8.963832078734413e-05\n",
      "epoch: 9 step: 1539, loss is 6.083205153117888e-05\n",
      "epoch: 9 step: 1540, loss is 0.0006007109768688679\n",
      "epoch: 9 step: 1541, loss is 0.001199654070660472\n",
      "epoch: 9 step: 1542, loss is 0.01894538477063179\n",
      "epoch: 9 step: 1543, loss is 7.69815596868284e-05\n",
      "epoch: 9 step: 1544, loss is 0.0004906996036879718\n",
      "epoch: 9 step: 1545, loss is 0.08976354449987411\n",
      "epoch: 9 step: 1546, loss is 0.002232614438980818\n",
      "epoch: 9 step: 1547, loss is 0.0006611062563024461\n",
      "epoch: 9 step: 1548, loss is 0.00043655000627040863\n",
      "epoch: 9 step: 1549, loss is 0.09016085416078568\n",
      "epoch: 9 step: 1550, loss is 0.10586440563201904\n",
      "epoch: 9 step: 1551, loss is 0.0004598865343723446\n",
      "epoch: 9 step: 1552, loss is 0.004202946554869413\n",
      "epoch: 9 step: 1553, loss is 0.001403630943968892\n",
      "epoch: 9 step: 1554, loss is 0.21055364608764648\n",
      "epoch: 9 step: 1555, loss is 0.020644476637244225\n",
      "epoch: 9 step: 1556, loss is 0.001977583859115839\n",
      "epoch: 9 step: 1557, loss is 0.006218543276190758\n",
      "epoch: 9 step: 1558, loss is 8.959573278843891e-06\n",
      "epoch: 9 step: 1559, loss is 0.05184582993388176\n",
      "epoch: 9 step: 1560, loss is 0.00014872440078761429\n",
      "epoch: 9 step: 1561, loss is 0.04823939874768257\n",
      "epoch: 9 step: 1562, loss is 0.00013995784684084356\n",
      "epoch: 9 step: 1563, loss is 0.0018558934098109603\n",
      "epoch: 9 step: 1564, loss is 0.003230224596336484\n",
      "epoch: 9 step: 1565, loss is 0.000822367612272501\n",
      "epoch: 9 step: 1566, loss is 0.0014598565176129341\n",
      "epoch: 9 step: 1567, loss is 0.0010279265698045492\n",
      "epoch: 9 step: 1568, loss is 0.00013272919750306755\n",
      "epoch: 9 step: 1569, loss is 5.384440009947866e-05\n",
      "epoch: 9 step: 1570, loss is 0.0001361460890620947\n",
      "epoch: 9 step: 1571, loss is 8.574663297622465e-06\n",
      "epoch: 9 step: 1572, loss is 0.03202513977885246\n",
      "epoch: 9 step: 1573, loss is 0.00011627671483438462\n",
      "epoch: 9 step: 1574, loss is 0.0010712638031691313\n",
      "epoch: 9 step: 1575, loss is 5.730580596718937e-05\n",
      "epoch: 9 step: 1576, loss is 4.566801362670958e-05\n",
      "epoch: 9 step: 1577, loss is 0.02901296690106392\n",
      "epoch: 9 step: 1578, loss is 6.105973170633661e-06\n",
      "epoch: 9 step: 1579, loss is 0.0005264464998617768\n",
      "epoch: 9 step: 1580, loss is 3.4370921639492735e-05\n",
      "epoch: 9 step: 1581, loss is 0.07896516472101212\n",
      "epoch: 9 step: 1582, loss is 0.01743130199611187\n",
      "epoch: 9 step: 1583, loss is 0.0012294880580157042\n",
      "epoch: 9 step: 1584, loss is 0.0003575726877897978\n",
      "epoch: 9 step: 1585, loss is 0.01935281604528427\n",
      "epoch: 9 step: 1586, loss is 0.009808557108044624\n",
      "epoch: 9 step: 1587, loss is 0.04584144055843353\n",
      "epoch: 9 step: 1588, loss is 0.14010336995124817\n",
      "epoch: 9 step: 1589, loss is 0.08342243731021881\n",
      "epoch: 9 step: 1590, loss is 0.0038509098812937737\n",
      "epoch: 9 step: 1591, loss is 0.00010587293945718557\n",
      "epoch: 9 step: 1592, loss is 0.0006502731121145189\n",
      "epoch: 9 step: 1593, loss is 0.002055681310594082\n",
      "epoch: 9 step: 1594, loss is 0.03862399235367775\n",
      "epoch: 9 step: 1595, loss is 0.0018063685856759548\n",
      "epoch: 9 step: 1596, loss is 0.0006397692486643791\n",
      "epoch: 9 step: 1597, loss is 0.34801074862480164\n",
      "epoch: 9 step: 1598, loss is 0.00013753441453445703\n",
      "epoch: 9 step: 1599, loss is 0.10148048400878906\n",
      "epoch: 9 step: 1600, loss is 0.002495316555723548\n",
      "epoch: 9 step: 1601, loss is 0.0025650637689977884\n",
      "epoch: 9 step: 1602, loss is 0.011732639744877815\n",
      "epoch: 9 step: 1603, loss is 7.182143599493429e-05\n",
      "epoch: 9 step: 1604, loss is 0.0013625600840896368\n",
      "epoch: 9 step: 1605, loss is 0.0015346449799835682\n",
      "epoch: 9 step: 1606, loss is 0.00036231696140021086\n",
      "epoch: 9 step: 1607, loss is 0.0016023636562749743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1608, loss is 0.0033068587072193623\n",
      "epoch: 9 step: 1609, loss is 0.003550594439730048\n",
      "epoch: 9 step: 1610, loss is 0.07126114517450333\n",
      "epoch: 9 step: 1611, loss is 0.004114414565265179\n",
      "epoch: 9 step: 1612, loss is 0.0050161839462816715\n",
      "epoch: 9 step: 1613, loss is 0.0024344115518033504\n",
      "epoch: 9 step: 1614, loss is 5.685925862053409e-05\n",
      "epoch: 9 step: 1615, loss is 0.0003023177559953183\n",
      "epoch: 9 step: 1616, loss is 0.0022774271201342344\n",
      "epoch: 9 step: 1617, loss is 0.0018774302443489432\n",
      "epoch: 9 step: 1618, loss is 0.0021791609469801188\n",
      "epoch: 9 step: 1619, loss is 0.0009917825227603316\n",
      "epoch: 9 step: 1620, loss is 0.0013649595202878118\n",
      "epoch: 9 step: 1621, loss is 0.057742808014154434\n",
      "epoch: 9 step: 1622, loss is 5.938059985055588e-05\n",
      "epoch: 9 step: 1623, loss is 0.024830490350723267\n",
      "epoch: 9 step: 1624, loss is 0.006980247795581818\n",
      "epoch: 9 step: 1625, loss is 0.027095181867480278\n",
      "epoch: 9 step: 1626, loss is 0.0001517814671387896\n",
      "epoch: 9 step: 1627, loss is 0.00014305436343420297\n",
      "epoch: 9 step: 1628, loss is 0.004877010360360146\n",
      "epoch: 9 step: 1629, loss is 3.868846033583395e-05\n",
      "epoch: 9 step: 1630, loss is 0.00012094654812244698\n",
      "epoch: 9 step: 1631, loss is 0.0004191743500996381\n",
      "epoch: 9 step: 1632, loss is 0.00016569424769841135\n",
      "epoch: 9 step: 1633, loss is 0.00020502299594227225\n",
      "epoch: 9 step: 1634, loss is 0.0002961027785204351\n",
      "epoch: 9 step: 1635, loss is 0.0011855041375383735\n",
      "epoch: 9 step: 1636, loss is 0.002885387744754553\n",
      "epoch: 9 step: 1637, loss is 0.0014193950919434428\n",
      "epoch: 9 step: 1638, loss is 0.00806164275854826\n",
      "epoch: 9 step: 1639, loss is 0.10180746018886566\n",
      "epoch: 9 step: 1640, loss is 0.00029467541025951505\n",
      "epoch: 9 step: 1641, loss is 0.000502761104144156\n",
      "epoch: 9 step: 1642, loss is 0.0008273189887404442\n",
      "epoch: 9 step: 1643, loss is 0.0033684363588690758\n",
      "epoch: 9 step: 1644, loss is 0.06645525991916656\n",
      "epoch: 9 step: 1645, loss is 0.0013180311070755124\n",
      "epoch: 9 step: 1646, loss is 0.00010122093954123557\n",
      "epoch: 9 step: 1647, loss is 0.0036884937435388565\n",
      "epoch: 9 step: 1648, loss is 0.0017473811749368906\n",
      "epoch: 9 step: 1649, loss is 0.00036642025224864483\n",
      "epoch: 9 step: 1650, loss is 0.029834402725100517\n",
      "epoch: 9 step: 1651, loss is 6.444774385272467e-07\n",
      "epoch: 9 step: 1652, loss is 0.001564333913847804\n",
      "epoch: 9 step: 1653, loss is 0.00014247374201659113\n",
      "epoch: 9 step: 1654, loss is 8.030129538383335e-05\n",
      "epoch: 9 step: 1655, loss is 1.2400532796164043e-05\n",
      "epoch: 9 step: 1656, loss is 0.000882965512573719\n",
      "epoch: 9 step: 1657, loss is 0.0014629552606493235\n",
      "epoch: 9 step: 1658, loss is 0.0007584469858556986\n",
      "epoch: 9 step: 1659, loss is 0.015491274185478687\n",
      "epoch: 9 step: 1660, loss is 0.00016888647223822773\n",
      "epoch: 9 step: 1661, loss is 0.019143544137477875\n",
      "epoch: 9 step: 1662, loss is 0.00040929397800937295\n",
      "epoch: 9 step: 1663, loss is 0.0020809071138501167\n",
      "epoch: 9 step: 1664, loss is 0.008050888776779175\n",
      "epoch: 9 step: 1665, loss is 0.0012358243111521006\n",
      "epoch: 9 step: 1666, loss is 0.003379406873136759\n",
      "epoch: 9 step: 1667, loss is 1.537880234536715e-05\n",
      "epoch: 9 step: 1668, loss is 0.0002957014658022672\n",
      "epoch: 9 step: 1669, loss is 0.02601035125553608\n",
      "epoch: 9 step: 1670, loss is 1.3073883565084543e-05\n",
      "epoch: 9 step: 1671, loss is 0.014244992285966873\n",
      "epoch: 9 step: 1672, loss is 0.06283894926309586\n",
      "epoch: 9 step: 1673, loss is 1.06325414890307e-05\n",
      "epoch: 9 step: 1674, loss is 0.00461655855178833\n",
      "epoch: 9 step: 1675, loss is 3.0332335882121697e-05\n",
      "epoch: 9 step: 1676, loss is 0.01909128949046135\n",
      "epoch: 9 step: 1677, loss is 0.0012304030824452639\n",
      "epoch: 9 step: 1678, loss is 0.0006660466897301376\n",
      "epoch: 9 step: 1679, loss is 0.0007938484195619822\n",
      "epoch: 9 step: 1680, loss is 4.024368172395043e-05\n",
      "epoch: 9 step: 1681, loss is 0.0013310760259628296\n",
      "epoch: 9 step: 1682, loss is 0.020507942885160446\n",
      "epoch: 9 step: 1683, loss is 0.03741852194070816\n",
      "epoch: 9 step: 1684, loss is 3.907666905433871e-05\n",
      "epoch: 9 step: 1685, loss is 0.048470187932252884\n",
      "epoch: 9 step: 1686, loss is 0.0018006301252171397\n",
      "epoch: 9 step: 1687, loss is 0.0011281048646196723\n",
      "epoch: 9 step: 1688, loss is 0.009965840727090836\n",
      "epoch: 9 step: 1689, loss is 0.0006516117136925459\n",
      "epoch: 9 step: 1690, loss is 0.004833432380110025\n",
      "epoch: 9 step: 1691, loss is 0.003415194805711508\n",
      "epoch: 9 step: 1692, loss is 0.06879600882530212\n",
      "epoch: 9 step: 1693, loss is 0.0024849316105246544\n",
      "epoch: 9 step: 1694, loss is 5.014162525185384e-05\n",
      "epoch: 9 step: 1695, loss is 0.0006202185759320855\n",
      "epoch: 9 step: 1696, loss is 0.05683029815554619\n",
      "epoch: 9 step: 1697, loss is 0.0001901359937619418\n",
      "epoch: 9 step: 1698, loss is 0.006451609078794718\n",
      "epoch: 9 step: 1699, loss is 3.10696595988702e-05\n",
      "epoch: 9 step: 1700, loss is 0.0017619539285078645\n",
      "epoch: 9 step: 1701, loss is 0.056611452251672745\n",
      "epoch: 9 step: 1702, loss is 0.0028902599588036537\n",
      "epoch: 9 step: 1703, loss is 0.006109932437539101\n",
      "epoch: 9 step: 1704, loss is 0.00290510687045753\n",
      "epoch: 9 step: 1705, loss is 0.0005193788092583418\n",
      "epoch: 9 step: 1706, loss is 0.00025008758530020714\n",
      "epoch: 9 step: 1707, loss is 0.122012659907341\n",
      "epoch: 9 step: 1708, loss is 0.0001021512653096579\n",
      "epoch: 9 step: 1709, loss is 1.3282943655212875e-05\n",
      "epoch: 9 step: 1710, loss is 0.0024392015766352415\n",
      "epoch: 9 step: 1711, loss is 0.0003160964697599411\n",
      "epoch: 9 step: 1712, loss is 7.184439891716465e-05\n",
      "epoch: 9 step: 1713, loss is 8.633504330646247e-05\n",
      "epoch: 9 step: 1714, loss is 0.006217045709490776\n",
      "epoch: 9 step: 1715, loss is 0.17795735597610474\n",
      "epoch: 9 step: 1716, loss is 9.315587521996349e-05\n",
      "epoch: 9 step: 1717, loss is 0.0001405563671141863\n",
      "epoch: 9 step: 1718, loss is 0.018037403002381325\n",
      "epoch: 9 step: 1719, loss is 0.0019112697336822748\n",
      "epoch: 9 step: 1720, loss is 0.07298728823661804\n",
      "epoch: 9 step: 1721, loss is 0.00018929463112726808\n",
      "epoch: 9 step: 1722, loss is 0.015222989022731781\n",
      "epoch: 9 step: 1723, loss is 0.049878496676683426\n",
      "epoch: 9 step: 1724, loss is 0.2165653109550476\n",
      "epoch: 9 step: 1725, loss is 0.0025674335192888975\n",
      "epoch: 9 step: 1726, loss is 0.015198424458503723\n",
      "epoch: 9 step: 1727, loss is 0.0002779884380288422\n",
      "epoch: 9 step: 1728, loss is 5.705167131964117e-05\n",
      "epoch: 9 step: 1729, loss is 6.642833614023402e-05\n",
      "epoch: 9 step: 1730, loss is 0.03419005498290062\n",
      "epoch: 9 step: 1731, loss is 3.848816777463071e-05\n",
      "epoch: 9 step: 1732, loss is 0.00014271578402258456\n",
      "epoch: 9 step: 1733, loss is 0.011668210849165916\n",
      "epoch: 9 step: 1734, loss is 0.0004633219796232879\n",
      "epoch: 9 step: 1735, loss is 0.0021047471091151237\n",
      "epoch: 9 step: 1736, loss is 0.00800943560898304\n",
      "epoch: 9 step: 1737, loss is 0.0036505868192762136\n",
      "epoch: 9 step: 1738, loss is 0.00029845378594473004\n",
      "epoch: 9 step: 1739, loss is 0.05683696269989014\n",
      "epoch: 9 step: 1740, loss is 0.011416970752179623\n",
      "epoch: 9 step: 1741, loss is 0.0004580808454193175\n",
      "epoch: 9 step: 1742, loss is 0.00843129027634859\n",
      "epoch: 9 step: 1743, loss is 2.974146991618909e-05\n",
      "epoch: 9 step: 1744, loss is 0.04054701328277588\n",
      "epoch: 9 step: 1745, loss is 0.0012088492512702942\n",
      "epoch: 9 step: 1746, loss is 0.012889214791357517\n",
      "epoch: 9 step: 1747, loss is 0.0029133602511137724\n",
      "epoch: 9 step: 1748, loss is 0.00011214391997782513\n",
      "epoch: 9 step: 1749, loss is 6.892123928992078e-05\n",
      "epoch: 9 step: 1750, loss is 0.015080214478075504\n",
      "epoch: 9 step: 1751, loss is 0.006502606440335512\n",
      "epoch: 9 step: 1752, loss is 0.0001590187894180417\n",
      "epoch: 9 step: 1753, loss is 8.13341248431243e-05\n",
      "epoch: 9 step: 1754, loss is 9.257238707505167e-05\n",
      "epoch: 9 step: 1755, loss is 0.00036207883385941386\n",
      "epoch: 9 step: 1756, loss is 0.02089434489607811\n",
      "epoch: 9 step: 1757, loss is 0.002994801616296172\n",
      "epoch: 9 step: 1758, loss is 3.952079714508727e-05\n",
      "epoch: 9 step: 1759, loss is 0.0011384825920686126\n",
      "epoch: 9 step: 1760, loss is 0.023464679718017578\n",
      "epoch: 9 step: 1761, loss is 0.00016902991046663374\n",
      "epoch: 9 step: 1762, loss is 9.824294102145359e-05\n",
      "epoch: 9 step: 1763, loss is 0.0015402818098664284\n",
      "epoch: 9 step: 1764, loss is 0.004012818913906813\n",
      "epoch: 9 step: 1765, loss is 0.062040362507104874\n",
      "epoch: 9 step: 1766, loss is 0.037178415805101395\n",
      "epoch: 9 step: 1767, loss is 3.370322156115435e-05\n",
      "epoch: 9 step: 1768, loss is 0.000218328699702397\n",
      "epoch: 9 step: 1769, loss is 0.00040235696360468864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1770, loss is 0.00145138765219599\n",
      "epoch: 9 step: 1771, loss is 0.006941813975572586\n",
      "epoch: 9 step: 1772, loss is 0.0010383209446445107\n",
      "epoch: 9 step: 1773, loss is 0.0005110047641210258\n",
      "epoch: 9 step: 1774, loss is 0.0673428550362587\n",
      "epoch: 9 step: 1775, loss is 0.0027146348729729652\n",
      "epoch: 9 step: 1776, loss is 0.07685501128435135\n",
      "epoch: 9 step: 1777, loss is 0.0003436596889514476\n",
      "epoch: 9 step: 1778, loss is 0.08395267277956009\n",
      "epoch: 9 step: 1779, loss is 6.603258952964097e-05\n",
      "epoch: 9 step: 1780, loss is 0.08863562345504761\n",
      "epoch: 9 step: 1781, loss is 9.877714910544455e-05\n",
      "epoch: 9 step: 1782, loss is 0.10801764577627182\n",
      "epoch: 9 step: 1783, loss is 0.05359506979584694\n",
      "epoch: 9 step: 1784, loss is 0.0004888817202299833\n",
      "epoch: 9 step: 1785, loss is 0.0005726478411816061\n",
      "epoch: 9 step: 1786, loss is 0.020925600081682205\n",
      "epoch: 9 step: 1787, loss is 0.0013203996932134032\n",
      "epoch: 9 step: 1788, loss is 0.14396721124649048\n",
      "epoch: 9 step: 1789, loss is 0.022120276466012\n",
      "epoch: 9 step: 1790, loss is 0.1232432946562767\n",
      "epoch: 9 step: 1791, loss is 0.0018597214948385954\n",
      "epoch: 9 step: 1792, loss is 3.850603025057353e-05\n",
      "epoch: 9 step: 1793, loss is 9.107909863814712e-05\n",
      "epoch: 9 step: 1794, loss is 0.0002482486015651375\n",
      "epoch: 9 step: 1795, loss is 0.0006396335083991289\n",
      "epoch: 9 step: 1796, loss is 0.001428996678441763\n",
      "epoch: 9 step: 1797, loss is 0.00029467520653270185\n",
      "epoch: 9 step: 1798, loss is 0.0014371597208082676\n",
      "epoch: 9 step: 1799, loss is 0.04170162230730057\n",
      "epoch: 9 step: 1800, loss is 0.009615479037165642\n",
      "epoch: 9 step: 1801, loss is 0.005608549807220697\n",
      "epoch: 9 step: 1802, loss is 5.4032683692639694e-05\n",
      "epoch: 9 step: 1803, loss is 0.0023827282711863518\n",
      "epoch: 9 step: 1804, loss is 0.11932169646024704\n",
      "epoch: 9 step: 1805, loss is 6.3780321397644e-06\n",
      "epoch: 9 step: 1806, loss is 0.05445688217878342\n",
      "epoch: 9 step: 1807, loss is 0.014886404387652874\n",
      "epoch: 9 step: 1808, loss is 2.3664477339480072e-05\n",
      "epoch: 9 step: 1809, loss is 0.13334602117538452\n",
      "epoch: 9 step: 1810, loss is 0.002610130701214075\n",
      "epoch: 9 step: 1811, loss is 0.001855836482718587\n",
      "epoch: 9 step: 1812, loss is 0.0030368620064109564\n",
      "epoch: 9 step: 1813, loss is 0.00021107232896611094\n",
      "epoch: 9 step: 1814, loss is 0.0009365155128762126\n",
      "epoch: 9 step: 1815, loss is 0.00039087168988771737\n",
      "epoch: 9 step: 1816, loss is 0.010038799606263638\n",
      "epoch: 9 step: 1817, loss is 0.08039733022451401\n",
      "epoch: 9 step: 1818, loss is 8.737772441236302e-05\n",
      "epoch: 9 step: 1819, loss is 0.09001152217388153\n",
      "epoch: 9 step: 1820, loss is 3.571860725060105e-05\n",
      "epoch: 9 step: 1821, loss is 0.0007411442347802222\n",
      "epoch: 9 step: 1822, loss is 4.902135697193444e-05\n",
      "epoch: 9 step: 1823, loss is 0.15709854662418365\n",
      "epoch: 9 step: 1824, loss is 0.0019805675838142633\n",
      "epoch: 9 step: 1825, loss is 5.358550333767198e-05\n",
      "epoch: 9 step: 1826, loss is 0.0004279082058928907\n",
      "epoch: 9 step: 1827, loss is 4.654306758311577e-05\n",
      "epoch: 9 step: 1828, loss is 0.015586063265800476\n",
      "epoch: 9 step: 1829, loss is 0.00033477379474788904\n",
      "epoch: 9 step: 1830, loss is 1.0483541700523347e-05\n",
      "epoch: 9 step: 1831, loss is 0.0636562928557396\n",
      "epoch: 9 step: 1832, loss is 0.018054740503430367\n",
      "epoch: 9 step: 1833, loss is 0.2527806758880615\n",
      "epoch: 9 step: 1834, loss is 0.03152528777718544\n",
      "epoch: 9 step: 1835, loss is 0.007500304840505123\n",
      "epoch: 9 step: 1836, loss is 0.15923042595386505\n",
      "epoch: 9 step: 1837, loss is 0.02782433107495308\n",
      "epoch: 9 step: 1838, loss is 0.0005324590601958334\n",
      "epoch: 9 step: 1839, loss is 0.002165188081562519\n",
      "epoch: 9 step: 1840, loss is 0.013695234432816505\n",
      "epoch: 9 step: 1841, loss is 0.0013980889925733209\n",
      "epoch: 9 step: 1842, loss is 0.07795067131519318\n",
      "epoch: 9 step: 1843, loss is 0.23498862981796265\n",
      "epoch: 9 step: 1844, loss is 0.41660457849502563\n",
      "epoch: 9 step: 1845, loss is 0.0008379046921618283\n",
      "epoch: 9 step: 1846, loss is 0.0005377703346312046\n",
      "epoch: 9 step: 1847, loss is 0.00020684368791989982\n",
      "epoch: 9 step: 1848, loss is 0.03964966535568237\n",
      "epoch: 9 step: 1849, loss is 0.0005597283598035574\n",
      "epoch: 9 step: 1850, loss is 0.21824860572814941\n",
      "epoch: 9 step: 1851, loss is 0.0004663659492507577\n",
      "epoch: 9 step: 1852, loss is 0.010765680111944675\n",
      "epoch: 9 step: 1853, loss is 0.014638768509030342\n",
      "epoch: 9 step: 1854, loss is 0.0004483716911636293\n",
      "epoch: 9 step: 1855, loss is 0.004631903953850269\n",
      "epoch: 9 step: 1856, loss is 0.0001669062621658668\n",
      "epoch: 9 step: 1857, loss is 0.0027121109887957573\n",
      "epoch: 9 step: 1858, loss is 0.0007824406493455172\n",
      "epoch: 9 step: 1859, loss is 0.01836482062935829\n",
      "epoch: 9 step: 1860, loss is 0.003730406053364277\n",
      "epoch: 9 step: 1861, loss is 0.5079610347747803\n",
      "epoch: 9 step: 1862, loss is 0.008305849507451057\n",
      "epoch: 9 step: 1863, loss is 0.010472356341779232\n",
      "epoch: 9 step: 1864, loss is 0.008288566954433918\n",
      "epoch: 9 step: 1865, loss is 0.02090734988451004\n",
      "epoch: 9 step: 1866, loss is 0.2210143655538559\n",
      "epoch: 9 step: 1867, loss is 0.16482289135456085\n",
      "epoch: 9 step: 1868, loss is 0.001037993817590177\n",
      "epoch: 9 step: 1869, loss is 0.0006305765127763152\n",
      "epoch: 9 step: 1870, loss is 0.0007721345173195004\n",
      "epoch: 9 step: 1871, loss is 0.08401740342378616\n",
      "epoch: 9 step: 1872, loss is 0.08211889863014221\n",
      "epoch: 9 step: 1873, loss is 0.16948240995407104\n",
      "epoch: 9 step: 1874, loss is 0.000421326607465744\n",
      "epoch: 9 step: 1875, loss is 0.002450925298035145\n",
      "epoch: 9 step: 1876, loss is 0.003088951576501131\n",
      "epoch: 9 step: 1877, loss is 0.05025014281272888\n",
      "epoch: 9 step: 1878, loss is 0.031319115310907364\n",
      "epoch: 9 step: 1879, loss is 0.0017330803675577044\n",
      "epoch: 9 step: 1880, loss is 0.0011677806032821536\n",
      "epoch: 9 step: 1881, loss is 0.054475512355566025\n",
      "epoch: 9 step: 1882, loss is 0.14524103701114655\n",
      "epoch: 9 step: 1883, loss is 0.010761543177068233\n",
      "epoch: 9 step: 1884, loss is 0.011501265689730644\n",
      "epoch: 9 step: 1885, loss is 0.09337487071752548\n",
      "epoch: 9 step: 1886, loss is 0.002806191798299551\n",
      "epoch: 9 step: 1887, loss is 0.0023345411755144596\n",
      "epoch: 9 step: 1888, loss is 0.0013535777106881142\n",
      "epoch: 9 step: 1889, loss is 0.006547641009092331\n",
      "epoch: 9 step: 1890, loss is 0.012400091625750065\n",
      "epoch: 9 step: 1891, loss is 0.00876224972307682\n",
      "epoch: 9 step: 1892, loss is 0.01431760098785162\n",
      "epoch: 9 step: 1893, loss is 0.15155307948589325\n",
      "epoch: 9 step: 1894, loss is 0.0016296942485496402\n",
      "epoch: 9 step: 1895, loss is 0.1634994000196457\n",
      "epoch: 9 step: 1896, loss is 0.00213064718991518\n",
      "epoch: 9 step: 1897, loss is 0.013865398243069649\n",
      "epoch: 9 step: 1898, loss is 0.018689831718802452\n",
      "epoch: 9 step: 1899, loss is 0.0029046200215816498\n",
      "epoch: 9 step: 1900, loss is 0.005325159057974815\n",
      "epoch: 9 step: 1901, loss is 0.0016862348420545459\n",
      "epoch: 9 step: 1902, loss is 0.044001612812280655\n",
      "epoch: 9 step: 1903, loss is 0.042099729180336\n",
      "epoch: 9 step: 1904, loss is 0.03306492045521736\n",
      "epoch: 9 step: 1905, loss is 0.028923600912094116\n",
      "epoch: 9 step: 1906, loss is 0.012040095403790474\n",
      "epoch: 9 step: 1907, loss is 0.005768974311649799\n",
      "epoch: 9 step: 1908, loss is 0.0047777737490832806\n",
      "epoch: 9 step: 1909, loss is 0.0002933062787633389\n",
      "epoch: 9 step: 1910, loss is 0.0006852163933217525\n",
      "epoch: 9 step: 1911, loss is 0.006762291770428419\n",
      "epoch: 9 step: 1912, loss is 0.011583076789975166\n",
      "epoch: 9 step: 1913, loss is 0.00011286760855000466\n",
      "epoch: 9 step: 1914, loss is 0.006659046746790409\n",
      "epoch: 9 step: 1915, loss is 0.0015634526498615742\n",
      "epoch: 9 step: 1916, loss is 0.00020058410882484168\n",
      "epoch: 9 step: 1917, loss is 0.06622129678726196\n",
      "epoch: 9 step: 1918, loss is 0.0003868183121085167\n",
      "epoch: 9 step: 1919, loss is 0.000585205212701112\n",
      "epoch: 9 step: 1920, loss is 0.013565367087721825\n",
      "epoch: 9 step: 1921, loss is 0.013912724331021309\n",
      "epoch: 9 step: 1922, loss is 0.0027711153961718082\n",
      "epoch: 9 step: 1923, loss is 0.0019974764436483383\n",
      "epoch: 9 step: 1924, loss is 0.00032907468266785145\n",
      "epoch: 9 step: 1925, loss is 0.013696023263037205\n",
      "epoch: 9 step: 1926, loss is 0.00032977681257762015\n",
      "epoch: 9 step: 1927, loss is 0.000473143212730065\n",
      "epoch: 9 step: 1928, loss is 0.0014157281257212162\n",
      "epoch: 9 step: 1929, loss is 0.02119193971157074\n",
      "epoch: 9 step: 1930, loss is 0.00083490478573367\n",
      "epoch: 9 step: 1931, loss is 0.0020748432725667953\n",
      "epoch: 9 step: 1932, loss is 0.00011249067028984427\n",
      "epoch: 9 step: 1933, loss is 0.001925139338709414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1934, loss is 0.0025613028556108475\n",
      "epoch: 9 step: 1935, loss is 0.00012132401025155559\n",
      "epoch: 9 step: 1936, loss is 0.0160873681306839\n",
      "epoch: 9 step: 1937, loss is 0.0007064471137709916\n",
      "epoch: 9 step: 1938, loss is 0.00019821224850602448\n",
      "epoch: 9 step: 1939, loss is 0.0031461163889616728\n",
      "epoch: 9 step: 1940, loss is 0.0011153591331094503\n",
      "epoch: 9 step: 1941, loss is 0.0008374491590075195\n",
      "epoch: 9 step: 1942, loss is 0.000875825178809464\n",
      "epoch: 9 step: 1943, loss is 0.035549234598875046\n",
      "epoch: 9 step: 1944, loss is 8.011210593394935e-05\n",
      "epoch: 9 step: 1945, loss is 0.02064254693686962\n",
      "epoch: 9 step: 1946, loss is 0.059938620775938034\n",
      "epoch: 9 step: 1947, loss is 0.0006812359788455069\n",
      "epoch: 9 step: 1948, loss is 0.0037726883310824633\n",
      "epoch: 9 step: 1949, loss is 0.042384788393974304\n",
      "epoch: 9 step: 1950, loss is 0.0008506268495693803\n",
      "epoch: 9 step: 1951, loss is 0.020210377871990204\n",
      "epoch: 9 step: 1952, loss is 0.0008164588361978531\n",
      "epoch: 9 step: 1953, loss is 5.2988943934906274e-05\n",
      "epoch: 9 step: 1954, loss is 0.001301097683608532\n",
      "epoch: 9 step: 1955, loss is 0.001297652954235673\n",
      "epoch: 9 step: 1956, loss is 0.00029269931837916374\n",
      "epoch: 9 step: 1957, loss is 0.02417655661702156\n",
      "epoch: 9 step: 1958, loss is 0.008078636601567268\n",
      "epoch: 9 step: 1959, loss is 0.0011128964833915234\n",
      "epoch: 9 step: 1960, loss is 0.006398992612957954\n",
      "epoch: 9 step: 1961, loss is 0.0007717421976849437\n",
      "epoch: 9 step: 1962, loss is 0.00016144677647389472\n",
      "epoch: 9 step: 1963, loss is 0.0493224672973156\n",
      "epoch: 9 step: 1964, loss is 0.0006923937471583486\n",
      "epoch: 9 step: 1965, loss is 0.003459243569523096\n",
      "epoch: 9 step: 1966, loss is 0.012453185394406319\n",
      "epoch: 9 step: 1967, loss is 0.25963911414146423\n",
      "epoch: 9 step: 1968, loss is 0.0016281341668218374\n",
      "epoch: 9 step: 1969, loss is 0.0004843491187784821\n",
      "epoch: 9 step: 1970, loss is 0.001757526071742177\n",
      "epoch: 9 step: 1971, loss is 0.0001239656121470034\n",
      "epoch: 9 step: 1972, loss is 0.02704392559826374\n",
      "epoch: 9 step: 1973, loss is 0.27381575107574463\n",
      "epoch: 9 step: 1974, loss is 0.04157686233520508\n",
      "epoch: 9 step: 1975, loss is 0.010237467475235462\n",
      "epoch: 9 step: 1976, loss is 0.0009121728362515569\n",
      "epoch: 9 step: 1977, loss is 0.001629097037948668\n",
      "epoch: 9 step: 1978, loss is 0.01753450371325016\n",
      "epoch: 9 step: 1979, loss is 0.033575285226106644\n",
      "epoch: 9 step: 1980, loss is 0.012134670279920101\n",
      "epoch: 9 step: 1981, loss is 0.015622700564563274\n",
      "epoch: 9 step: 1982, loss is 0.0681149810552597\n",
      "epoch: 9 step: 1983, loss is 0.008798320777714252\n",
      "epoch: 9 step: 1984, loss is 0.007838353514671326\n",
      "epoch: 9 step: 1985, loss is 0.0015932574169710279\n",
      "epoch: 9 step: 1986, loss is 0.0007334256079047918\n",
      "epoch: 9 step: 1987, loss is 0.0017727488884702325\n",
      "epoch: 9 step: 1988, loss is 0.003809344954788685\n",
      "epoch: 9 step: 1989, loss is 0.0036963848397135735\n",
      "epoch: 9 step: 1990, loss is 0.01992524228990078\n",
      "epoch: 9 step: 1991, loss is 0.009501762688159943\n",
      "epoch: 9 step: 1992, loss is 0.008707632310688496\n",
      "epoch: 9 step: 1993, loss is 0.025072487071156502\n",
      "epoch: 9 step: 1994, loss is 0.004969258792698383\n",
      "epoch: 9 step: 1995, loss is 0.007348483894020319\n",
      "epoch: 9 step: 1996, loss is 0.002694656141102314\n",
      "epoch: 9 step: 1997, loss is 0.002992655849084258\n",
      "epoch: 9 step: 1998, loss is 0.019916249439120293\n",
      "epoch: 9 step: 1999, loss is 0.009226839989423752\n",
      "epoch: 9 step: 2000, loss is 0.0004613888158928603\n",
      "epoch: 9 step: 2001, loss is 0.0018929988145828247\n",
      "epoch: 9 step: 2002, loss is 0.003439518390223384\n",
      "epoch: 9 step: 2003, loss is 0.000594201497733593\n",
      "epoch: 9 step: 2004, loss is 0.010919958353042603\n",
      "epoch: 9 step: 2005, loss is 0.006126553285866976\n",
      "epoch: 9 step: 2006, loss is 0.001231157686561346\n",
      "epoch: 9 step: 2007, loss is 0.026283076032996178\n",
      "epoch: 9 step: 2008, loss is 0.0011630709050223231\n",
      "epoch: 9 step: 2009, loss is 0.073905810713768\n",
      "epoch: 9 step: 2010, loss is 0.0012666763504967093\n",
      "epoch: 9 step: 2011, loss is 0.00024543257313780487\n",
      "epoch: 9 step: 2012, loss is 5.1558312406996265e-05\n",
      "epoch: 9 step: 2013, loss is 0.001076775137335062\n",
      "epoch: 9 step: 2014, loss is 0.0009540836326777935\n",
      "epoch: 9 step: 2015, loss is 0.00067049142671749\n",
      "epoch: 9 step: 2016, loss is 0.004223837051540613\n",
      "epoch: 9 step: 2017, loss is 0.0063307881355285645\n",
      "epoch: 9 step: 2018, loss is 0.0021173767745494843\n",
      "epoch: 9 step: 2019, loss is 0.011046202853322029\n",
      "epoch: 9 step: 2020, loss is 0.02356814593076706\n",
      "epoch: 9 step: 2021, loss is 0.08337674289941788\n",
      "epoch: 9 step: 2022, loss is 0.008689945563673973\n",
      "epoch: 9 step: 2023, loss is 7.018490578047931e-05\n",
      "epoch: 9 step: 2024, loss is 0.003090818412601948\n",
      "epoch: 9 step: 2025, loss is 0.0026069667655974627\n",
      "epoch: 9 step: 2026, loss is 0.006705440580844879\n",
      "epoch: 9 step: 2027, loss is 0.0005324427038431168\n",
      "epoch: 9 step: 2028, loss is 0.012353711761534214\n",
      "epoch: 9 step: 2029, loss is 0.0011733195278793573\n",
      "epoch: 9 step: 2030, loss is 0.0003653620951808989\n",
      "epoch: 9 step: 2031, loss is 0.0010928374249488115\n",
      "epoch: 9 step: 2032, loss is 0.0002335915924049914\n",
      "epoch: 9 step: 2033, loss is 0.00034952975693158805\n",
      "epoch: 9 step: 2034, loss is 0.04348328709602356\n",
      "epoch: 9 step: 2035, loss is 0.030348394066095352\n",
      "epoch: 9 step: 2036, loss is 0.0018932675011456013\n",
      "epoch: 9 step: 2037, loss is 0.004262314643710852\n",
      "epoch: 9 step: 2038, loss is 0.00013119015784468502\n",
      "epoch: 9 step: 2039, loss is 0.005624024663120508\n",
      "epoch: 9 step: 2040, loss is 0.003548786975443363\n",
      "epoch: 9 step: 2041, loss is 0.0004536775522865355\n",
      "epoch: 9 step: 2042, loss is 0.007353432476520538\n",
      "epoch: 9 step: 2043, loss is 0.02060450240969658\n",
      "epoch: 9 step: 2044, loss is 0.007896785624325275\n",
      "epoch: 9 step: 2045, loss is 0.0008790752617642283\n",
      "epoch: 9 step: 2046, loss is 0.0003017779381480068\n",
      "epoch: 9 step: 2047, loss is 0.014913185499608517\n",
      "epoch: 9 step: 2048, loss is 0.0009315696661360562\n",
      "epoch: 9 step: 2049, loss is 0.011243792250752449\n",
      "epoch: 9 step: 2050, loss is 0.06712737679481506\n",
      "epoch: 9 step: 2051, loss is 0.00021428533364087343\n",
      "epoch: 9 step: 2052, loss is 0.0017716449219733477\n",
      "epoch: 9 step: 2053, loss is 0.00993890967220068\n",
      "epoch: 9 step: 2054, loss is 0.0010776515118777752\n",
      "epoch: 9 step: 2055, loss is 0.1719731241464615\n",
      "epoch: 9 step: 2056, loss is 0.003676619380712509\n",
      "epoch: 9 step: 2057, loss is 0.0002681712503544986\n",
      "epoch: 9 step: 2058, loss is 0.0004834798746742308\n",
      "epoch: 9 step: 2059, loss is 0.0013877522433176637\n",
      "epoch: 9 step: 2060, loss is 0.006970881950110197\n",
      "epoch: 9 step: 2061, loss is 0.10483928769826889\n",
      "epoch: 9 step: 2062, loss is 0.002081496175378561\n",
      "epoch: 9 step: 2063, loss is 0.031384870409965515\n",
      "epoch: 9 step: 2064, loss is 0.005353465210646391\n",
      "epoch: 9 step: 2065, loss is 0.009698604233562946\n",
      "epoch: 9 step: 2066, loss is 0.002989077940583229\n",
      "epoch: 9 step: 2067, loss is 0.0022477474994957447\n",
      "epoch: 9 step: 2068, loss is 0.005680058617144823\n",
      "epoch: 9 step: 2069, loss is 0.02562876045703888\n",
      "epoch: 9 step: 2070, loss is 0.13054047524929047\n",
      "epoch: 9 step: 2071, loss is 0.00023544827126897871\n",
      "epoch: 9 step: 2072, loss is 0.03120408207178116\n",
      "epoch: 9 step: 2073, loss is 0.02830313704907894\n",
      "epoch: 9 step: 2074, loss is 0.00031906896037980914\n",
      "epoch: 9 step: 2075, loss is 0.0038774057757109404\n",
      "epoch: 9 step: 2076, loss is 0.005276456940919161\n",
      "epoch: 9 step: 2077, loss is 0.012080376036465168\n",
      "epoch: 9 step: 2078, loss is 0.02317408286035061\n",
      "epoch: 9 step: 2079, loss is 0.10042096674442291\n",
      "epoch: 9 step: 2080, loss is 0.0339864082634449\n",
      "epoch: 9 step: 2081, loss is 0.00025644004927016795\n",
      "epoch: 9 step: 2082, loss is 0.002780770882964134\n",
      "epoch: 9 step: 2083, loss is 0.0003544851497281343\n",
      "epoch: 9 step: 2084, loss is 0.004304730799049139\n",
      "epoch: 9 step: 2085, loss is 0.002389152767136693\n",
      "epoch: 9 step: 2086, loss is 0.009107500314712524\n",
      "epoch: 9 step: 2087, loss is 0.002312050899490714\n",
      "epoch: 9 step: 2088, loss is 0.06199450045824051\n",
      "epoch: 9 step: 2089, loss is 9.00197119335644e-05\n",
      "epoch: 9 step: 2090, loss is 0.061412129551172256\n",
      "epoch: 9 step: 2091, loss is 0.020900271832942963\n",
      "epoch: 9 step: 2092, loss is 0.0011894464259967208\n",
      "epoch: 9 step: 2093, loss is 0.0020009076688438654\n",
      "epoch: 9 step: 2094, loss is 0.11565469950437546\n",
      "epoch: 9 step: 2095, loss is 0.0006220487412065268\n",
      "epoch: 9 step: 2096, loss is 5.67946772207506e-05\n",
      "epoch: 9 step: 2097, loss is 0.017494192346930504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 2098, loss is 0.0738028883934021\n",
      "epoch: 9 step: 2099, loss is 0.0012404860462993383\n",
      "epoch: 9 step: 2100, loss is 0.0019055299926549196\n",
      "epoch: 9 step: 2101, loss is 0.00010034519073087722\n",
      "epoch: 9 step: 2102, loss is 0.001300634117797017\n",
      "epoch: 9 step: 2103, loss is 0.0410333052277565\n",
      "epoch: 9 step: 2104, loss is 0.0013276825193315744\n",
      "epoch: 9 step: 2105, loss is 0.007396540604531765\n",
      "epoch: 9 step: 2106, loss is 0.0006021861918270588\n",
      "epoch: 9 step: 2107, loss is 0.0048584905453026295\n",
      "epoch: 9 step: 2108, loss is 0.006151460576802492\n",
      "epoch: 9 step: 2109, loss is 5.567109110415913e-05\n",
      "epoch: 9 step: 2110, loss is 0.005186447873711586\n",
      "epoch: 9 step: 2111, loss is 0.0004735433903988451\n",
      "epoch: 9 step: 2112, loss is 0.001472820877097547\n",
      "epoch: 9 step: 2113, loss is 0.0004974660114385188\n",
      "epoch: 9 step: 2114, loss is 0.00924626737833023\n",
      "epoch: 9 step: 2115, loss is 0.05666538327932358\n",
      "epoch: 9 step: 2116, loss is 0.003298156661912799\n",
      "epoch: 9 step: 2117, loss is 6.497017693618545e-06\n",
      "epoch: 9 step: 2118, loss is 0.006734767928719521\n",
      "epoch: 9 step: 2119, loss is 8.490254913340323e-06\n",
      "epoch: 9 step: 2120, loss is 4.154041744186543e-05\n",
      "epoch: 9 step: 2121, loss is 0.00010455034498590976\n",
      "epoch: 9 step: 2122, loss is 0.010970458388328552\n",
      "epoch: 9 step: 2123, loss is 0.09040194004774094\n",
      "epoch: 9 step: 2124, loss is 0.00014241848839446902\n",
      "epoch: 9 step: 2125, loss is 0.003083061194047332\n",
      "epoch: 9 step: 2126, loss is 0.006228265352547169\n",
      "epoch: 9 step: 2127, loss is 0.0013998830690979958\n",
      "epoch: 9 step: 2128, loss is 0.0007312948582693934\n",
      "epoch: 9 step: 2129, loss is 0.0072647216729819775\n",
      "epoch: 9 step: 2130, loss is 0.00043909624218940735\n",
      "epoch: 9 step: 2131, loss is 0.04921497777104378\n",
      "epoch: 9 step: 2132, loss is 0.0017434889450669289\n",
      "epoch: 9 step: 2133, loss is 0.00023993921058718115\n",
      "epoch: 9 step: 2134, loss is 0.004565844312310219\n",
      "epoch: 9 step: 2135, loss is 0.0031702108681201935\n",
      "epoch: 9 step: 2136, loss is 0.0008483836427330971\n",
      "epoch: 9 step: 2137, loss is 0.0028840885497629642\n",
      "epoch: 9 step: 2138, loss is 0.004122435115277767\n",
      "epoch: 9 step: 2139, loss is 0.0003353964420966804\n",
      "epoch: 9 step: 2140, loss is 8.670112583786249e-05\n",
      "epoch: 9 step: 2141, loss is 0.004226703196763992\n",
      "epoch: 9 step: 2142, loss is 0.00015020088176243007\n",
      "epoch: 9 step: 2143, loss is 0.0003640678769443184\n",
      "epoch: 9 step: 2144, loss is 0.0004979053628630936\n",
      "epoch: 9 step: 2145, loss is 8.880316454451531e-05\n",
      "epoch: 9 step: 2146, loss is 0.0019225127762183547\n",
      "epoch: 9 step: 2147, loss is 0.00021873170044273138\n",
      "epoch: 9 step: 2148, loss is 0.00028843909967690706\n",
      "epoch: 9 step: 2149, loss is 0.0019029396353289485\n",
      "epoch: 9 step: 2150, loss is 3.246558117098175e-05\n",
      "epoch: 9 step: 2151, loss is 5.2442275773501024e-05\n",
      "epoch: 9 step: 2152, loss is 0.00010327572817914188\n",
      "epoch: 9 step: 2153, loss is 0.0013110493309795856\n",
      "epoch: 9 step: 2154, loss is 0.0003983249480370432\n",
      "epoch: 9 step: 2155, loss is 0.0016143277753144503\n",
      "epoch: 9 step: 2156, loss is 0.0012748525477945805\n",
      "epoch: 9 step: 2157, loss is 3.6032182833878323e-05\n",
      "epoch: 9 step: 2158, loss is 0.0001672083599260077\n",
      "epoch: 9 step: 2159, loss is 0.022254565730690956\n",
      "epoch: 9 step: 2160, loss is 1.4008310245117173e-05\n",
      "epoch: 9 step: 2161, loss is 0.02931635081768036\n",
      "epoch: 9 step: 2162, loss is 0.001560557633638382\n",
      "epoch: 9 step: 2163, loss is 0.011820496059954166\n",
      "epoch: 9 step: 2164, loss is 3.715009370353073e-05\n",
      "epoch: 9 step: 2165, loss is 0.0012499084696173668\n",
      "epoch: 9 step: 2166, loss is 0.00012796830560546368\n",
      "epoch: 9 step: 2167, loss is 0.00024172532721422613\n",
      "epoch: 9 step: 2168, loss is 0.018586402758955956\n",
      "epoch: 9 step: 2169, loss is 0.000597801641561091\n",
      "epoch: 9 step: 2170, loss is 0.022396652027964592\n",
      "epoch: 9 step: 2171, loss is 0.0007319833966903389\n",
      "epoch: 9 step: 2172, loss is 0.031042419373989105\n",
      "epoch: 9 step: 2173, loss is 0.0015823463909327984\n",
      "epoch: 9 step: 2174, loss is 0.0030306156259030104\n",
      "epoch: 9 step: 2175, loss is 0.002880053361877799\n",
      "epoch: 9 step: 2176, loss is 4.377729055704549e-05\n",
      "epoch: 9 step: 2177, loss is 0.006042162422090769\n",
      "epoch: 9 step: 2178, loss is 0.0005190735100768507\n",
      "epoch: 9 step: 2179, loss is 0.11443661898374557\n",
      "epoch: 9 step: 2180, loss is 4.731952503789216e-05\n",
      "epoch: 9 step: 2181, loss is 0.0005430568708106875\n",
      "epoch: 9 step: 2182, loss is 4.9870261136675254e-05\n",
      "epoch: 9 step: 2183, loss is 0.0006656628102064133\n",
      "epoch: 9 step: 2184, loss is 0.006609177682548761\n",
      "epoch: 9 step: 2185, loss is 5.2257979405112565e-05\n",
      "epoch: 9 step: 2186, loss is 0.040036238729953766\n",
      "epoch: 9 step: 2187, loss is 0.002330108778551221\n",
      "epoch: 10 step: 1, loss is 1.9233444618294016e-05\n",
      "epoch: 10 step: 2, loss is 0.01247316412627697\n",
      "epoch: 10 step: 3, loss is 0.014399639330804348\n",
      "epoch: 10 step: 4, loss is 0.001805400475859642\n",
      "epoch: 10 step: 5, loss is 0.0014864453114569187\n",
      "epoch: 10 step: 6, loss is 0.01190098188817501\n",
      "epoch: 10 step: 7, loss is 0.04619130492210388\n",
      "epoch: 10 step: 8, loss is 0.00027749905711971223\n",
      "epoch: 10 step: 9, loss is 0.011887275613844395\n",
      "epoch: 10 step: 10, loss is 0.0018560020253062248\n",
      "epoch: 10 step: 11, loss is 0.006332815159112215\n",
      "epoch: 10 step: 12, loss is 0.002418830757960677\n",
      "epoch: 10 step: 13, loss is 2.8535914680105634e-06\n",
      "epoch: 10 step: 14, loss is 0.1294621378183365\n",
      "epoch: 10 step: 15, loss is 0.022281911224126816\n",
      "epoch: 10 step: 16, loss is 0.0021942518651485443\n",
      "epoch: 10 step: 17, loss is 0.10081038624048233\n",
      "epoch: 10 step: 18, loss is 6.209983257576823e-05\n",
      "epoch: 10 step: 19, loss is 0.0018124178750440478\n",
      "epoch: 10 step: 20, loss is 8.300407898786943e-06\n",
      "epoch: 10 step: 21, loss is 0.0006006130133755505\n",
      "epoch: 10 step: 22, loss is 0.05787253379821777\n",
      "epoch: 10 step: 23, loss is 5.792403680970892e-05\n",
      "epoch: 10 step: 24, loss is 0.00019749820057768375\n",
      "epoch: 10 step: 25, loss is 0.08070945739746094\n",
      "epoch: 10 step: 26, loss is 0.0010427040979266167\n",
      "epoch: 10 step: 27, loss is 0.004894530400633812\n",
      "epoch: 10 step: 28, loss is 0.07325312495231628\n",
      "epoch: 10 step: 29, loss is 0.022306956350803375\n",
      "epoch: 10 step: 30, loss is 0.1679335981607437\n",
      "epoch: 10 step: 31, loss is 0.013690715655684471\n",
      "epoch: 10 step: 32, loss is 0.0016324195312336087\n",
      "epoch: 10 step: 33, loss is 0.00017119289259426296\n",
      "epoch: 10 step: 34, loss is 7.532806193921715e-05\n",
      "epoch: 10 step: 35, loss is 0.036003515124320984\n",
      "epoch: 10 step: 36, loss is 0.00042813882464542985\n",
      "epoch: 10 step: 37, loss is 0.0030627723317593336\n",
      "epoch: 10 step: 38, loss is 0.0004885904490947723\n",
      "epoch: 10 step: 39, loss is 0.08387661725282669\n",
      "epoch: 10 step: 40, loss is 0.029601097106933594\n",
      "epoch: 10 step: 41, loss is 0.0027472253423184156\n",
      "epoch: 10 step: 42, loss is 0.005052690394222736\n",
      "epoch: 10 step: 43, loss is 0.03374505415558815\n",
      "epoch: 10 step: 44, loss is 0.0009881951846182346\n",
      "epoch: 10 step: 45, loss is 0.009648358449339867\n",
      "epoch: 10 step: 46, loss is 0.00020800669153686613\n",
      "epoch: 10 step: 47, loss is 0.00135326967574656\n",
      "epoch: 10 step: 48, loss is 0.003146408125758171\n",
      "epoch: 10 step: 49, loss is 0.0027528603095561266\n",
      "epoch: 10 step: 50, loss is 0.0006572178099304438\n",
      "epoch: 10 step: 51, loss is 0.07498529553413391\n",
      "epoch: 10 step: 52, loss is 0.00579591142013669\n",
      "epoch: 10 step: 53, loss is 0.006729867309331894\n",
      "epoch: 10 step: 54, loss is 0.004544781055301428\n",
      "epoch: 10 step: 55, loss is 0.0002572295197751373\n",
      "epoch: 10 step: 56, loss is 0.10546544939279556\n",
      "epoch: 10 step: 57, loss is 0.00035048421705141664\n",
      "epoch: 10 step: 58, loss is 0.010261891409754753\n",
      "epoch: 10 step: 59, loss is 0.02749478630721569\n",
      "epoch: 10 step: 60, loss is 0.0008201951859518886\n",
      "epoch: 10 step: 61, loss is 0.00013918762851972133\n",
      "epoch: 10 step: 62, loss is 0.003228378714993596\n",
      "epoch: 10 step: 63, loss is 5.734440128435381e-05\n",
      "epoch: 10 step: 64, loss is 0.0004172584740445018\n",
      "epoch: 10 step: 65, loss is 0.029265422374010086\n",
      "epoch: 10 step: 66, loss is 0.0002780153008643538\n",
      "epoch: 10 step: 67, loss is 0.01466187834739685\n",
      "epoch: 10 step: 68, loss is 0.0017003393732011318\n",
      "epoch: 10 step: 69, loss is 0.00014986249152570963\n",
      "epoch: 10 step: 70, loss is 0.001521209953352809\n",
      "epoch: 10 step: 71, loss is 0.031034674495458603\n",
      "epoch: 10 step: 72, loss is 0.00013221011613495648\n",
      "epoch: 10 step: 73, loss is 7.146417920012027e-05\n",
      "epoch: 10 step: 74, loss is 0.0002701743214856833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 75, loss is 0.0006128660752438009\n",
      "epoch: 10 step: 76, loss is 0.07072819024324417\n",
      "epoch: 10 step: 77, loss is 0.0013761825393885374\n",
      "epoch: 10 step: 78, loss is 0.003130721626803279\n",
      "epoch: 10 step: 79, loss is 0.018802275881171227\n",
      "epoch: 10 step: 80, loss is 0.0027623253408819437\n",
      "epoch: 10 step: 81, loss is 0.0017190567450597882\n",
      "epoch: 10 step: 82, loss is 0.003958104643970728\n",
      "epoch: 10 step: 83, loss is 0.04525960236787796\n",
      "epoch: 10 step: 84, loss is 0.09473162144422531\n",
      "epoch: 10 step: 85, loss is 5.123410664964467e-05\n",
      "epoch: 10 step: 86, loss is 3.377264874870889e-05\n",
      "epoch: 10 step: 87, loss is 0.0005737175815738738\n",
      "epoch: 10 step: 88, loss is 0.011161654256284237\n",
      "epoch: 10 step: 89, loss is 0.0031942487694323063\n",
      "epoch: 10 step: 90, loss is 0.009540051221847534\n",
      "epoch: 10 step: 91, loss is 0.00016943090304266661\n",
      "epoch: 10 step: 92, loss is 0.000300336949294433\n",
      "epoch: 10 step: 93, loss is 6.897888852108736e-06\n",
      "epoch: 10 step: 94, loss is 0.000373104092432186\n",
      "epoch: 10 step: 95, loss is 0.0007813159027136862\n",
      "epoch: 10 step: 96, loss is 0.04981331527233124\n",
      "epoch: 10 step: 97, loss is 0.002321729902178049\n",
      "epoch: 10 step: 98, loss is 0.00021718132484238595\n",
      "epoch: 10 step: 99, loss is 0.0021095643751323223\n",
      "epoch: 10 step: 100, loss is 0.0001966735435416922\n",
      "epoch: 10 step: 101, loss is 0.18728508055210114\n",
      "epoch: 10 step: 102, loss is 0.00012298100045882165\n",
      "epoch: 10 step: 103, loss is 9.28196677705273e-05\n",
      "epoch: 10 step: 104, loss is 0.0004964554682374001\n",
      "epoch: 10 step: 105, loss is 0.002926245331764221\n",
      "epoch: 10 step: 106, loss is 0.00013212484191171825\n",
      "epoch: 10 step: 107, loss is 5.618756767944433e-05\n",
      "epoch: 10 step: 108, loss is 0.0005431830650195479\n",
      "epoch: 10 step: 109, loss is 0.0015999539755284786\n",
      "epoch: 10 step: 110, loss is 0.001864016056060791\n",
      "epoch: 10 step: 111, loss is 0.000290682160994038\n",
      "epoch: 10 step: 112, loss is 0.005600903648883104\n",
      "epoch: 10 step: 113, loss is 0.09866217523813248\n",
      "epoch: 10 step: 114, loss is 0.020949751138687134\n",
      "epoch: 10 step: 115, loss is 0.0002302031934959814\n",
      "epoch: 10 step: 116, loss is 0.35386210680007935\n",
      "epoch: 10 step: 117, loss is 0.00043271557660773396\n",
      "epoch: 10 step: 118, loss is 0.00032994296634569764\n",
      "epoch: 10 step: 119, loss is 0.10599520802497864\n",
      "epoch: 10 step: 120, loss is 0.00012875876564066857\n",
      "epoch: 10 step: 121, loss is 9.004426101455465e-05\n",
      "epoch: 10 step: 122, loss is 0.0004451801651157439\n",
      "epoch: 10 step: 123, loss is 0.0009918103460222483\n",
      "epoch: 10 step: 124, loss is 3.2296502467943355e-05\n",
      "epoch: 10 step: 125, loss is 0.04973660781979561\n",
      "epoch: 10 step: 126, loss is 0.15103141963481903\n",
      "epoch: 10 step: 127, loss is 0.0004934378666803241\n",
      "epoch: 10 step: 128, loss is 0.0041062356904149055\n",
      "epoch: 10 step: 129, loss is 4.637184611056e-05\n",
      "epoch: 10 step: 130, loss is 0.07655426114797592\n",
      "epoch: 10 step: 131, loss is 4.722066660178825e-05\n",
      "epoch: 10 step: 132, loss is 0.002082998864352703\n",
      "epoch: 10 step: 133, loss is 0.07587699592113495\n",
      "epoch: 10 step: 134, loss is 0.00043519583414308727\n",
      "epoch: 10 step: 135, loss is 0.0001599010720383376\n",
      "epoch: 10 step: 136, loss is 3.9966740587260574e-05\n",
      "epoch: 10 step: 137, loss is 0.00022037242888472974\n",
      "epoch: 10 step: 138, loss is 0.06896626949310303\n",
      "epoch: 10 step: 139, loss is 0.008271745406091213\n",
      "epoch: 10 step: 140, loss is 0.01077481172978878\n",
      "epoch: 10 step: 141, loss is 0.008650136180222034\n",
      "epoch: 10 step: 142, loss is 0.0016681383131071925\n",
      "epoch: 10 step: 143, loss is 0.00019871113181579858\n",
      "epoch: 10 step: 144, loss is 0.017562735825777054\n",
      "epoch: 10 step: 145, loss is 0.0003020988078787923\n",
      "epoch: 10 step: 146, loss is 0.006983380299061537\n",
      "epoch: 10 step: 147, loss is 0.005014505703002214\n",
      "epoch: 10 step: 148, loss is 0.004797846544533968\n",
      "epoch: 10 step: 149, loss is 0.04157771170139313\n",
      "epoch: 10 step: 150, loss is 0.37574559450149536\n",
      "epoch: 10 step: 151, loss is 0.00457048648968339\n",
      "epoch: 10 step: 152, loss is 0.01728092133998871\n",
      "epoch: 10 step: 153, loss is 0.010936995968222618\n",
      "epoch: 10 step: 154, loss is 0.013097568415105343\n",
      "epoch: 10 step: 155, loss is 1.2475272342271637e-05\n",
      "epoch: 10 step: 156, loss is 0.037679582834243774\n",
      "epoch: 10 step: 157, loss is 0.004158002324402332\n",
      "epoch: 10 step: 158, loss is 0.0028893828857690096\n",
      "epoch: 10 step: 159, loss is 0.04103468731045723\n",
      "epoch: 10 step: 160, loss is 0.07382247596979141\n",
      "epoch: 10 step: 161, loss is 0.0029848141130059958\n",
      "epoch: 10 step: 162, loss is 0.0001320544834015891\n",
      "epoch: 10 step: 163, loss is 0.004736986942589283\n",
      "epoch: 10 step: 164, loss is 0.0708899274468422\n",
      "epoch: 10 step: 165, loss is 0.019467081874608994\n",
      "epoch: 10 step: 166, loss is 0.012853113934397697\n",
      "epoch: 10 step: 167, loss is 0.0026807747781276703\n",
      "epoch: 10 step: 168, loss is 3.030597508768551e-05\n",
      "epoch: 10 step: 169, loss is 0.0010361757595092058\n",
      "epoch: 10 step: 170, loss is 0.0008089362527243793\n",
      "epoch: 10 step: 171, loss is 0.038441430777311325\n",
      "epoch: 10 step: 172, loss is 5.8335768699180335e-05\n",
      "epoch: 10 step: 173, loss is 0.08777080476284027\n",
      "epoch: 10 step: 174, loss is 0.07430671155452728\n",
      "epoch: 10 step: 175, loss is 0.014947185292840004\n",
      "epoch: 10 step: 176, loss is 7.185474532889202e-05\n",
      "epoch: 10 step: 177, loss is 0.0049568586982786655\n",
      "epoch: 10 step: 178, loss is 0.0005412951577454805\n",
      "epoch: 10 step: 179, loss is 8.001794049050659e-05\n",
      "epoch: 10 step: 180, loss is 0.005390019156038761\n",
      "epoch: 10 step: 181, loss is 0.017888832837343216\n",
      "epoch: 10 step: 182, loss is 0.0005437908694148064\n",
      "epoch: 10 step: 183, loss is 0.002538246102631092\n",
      "epoch: 10 step: 184, loss is 0.0008283008937723935\n",
      "epoch: 10 step: 185, loss is 0.2015426903963089\n",
      "epoch: 10 step: 186, loss is 3.7972164136590436e-05\n",
      "epoch: 10 step: 187, loss is 0.003789584618061781\n",
      "epoch: 10 step: 188, loss is 0.011260157451033592\n",
      "epoch: 10 step: 189, loss is 2.031292751780711e-05\n",
      "epoch: 10 step: 190, loss is 0.0005011780303902924\n",
      "epoch: 10 step: 191, loss is 0.00015188691031653434\n",
      "epoch: 10 step: 192, loss is 0.0013080101925879717\n",
      "epoch: 10 step: 193, loss is 0.007479671388864517\n",
      "epoch: 10 step: 194, loss is 0.0011309162946417928\n",
      "epoch: 10 step: 195, loss is 0.0006100457394495606\n",
      "epoch: 10 step: 196, loss is 0.02079576998949051\n",
      "epoch: 10 step: 197, loss is 0.05148858577013016\n",
      "epoch: 10 step: 198, loss is 0.04253040999174118\n",
      "epoch: 10 step: 199, loss is 0.0016885170480236411\n",
      "epoch: 10 step: 200, loss is 0.0004246333264745772\n",
      "epoch: 10 step: 201, loss is 0.06347393989562988\n",
      "epoch: 10 step: 202, loss is 0.001028700266033411\n",
      "epoch: 10 step: 203, loss is 0.0005806609988212585\n",
      "epoch: 10 step: 204, loss is 0.012918050400912762\n",
      "epoch: 10 step: 205, loss is 5.245803913567215e-05\n",
      "epoch: 10 step: 206, loss is 0.1626976877450943\n",
      "epoch: 10 step: 207, loss is 0.00030357876676134765\n",
      "epoch: 10 step: 208, loss is 0.0020069628953933716\n",
      "epoch: 10 step: 209, loss is 0.013183314353227615\n",
      "epoch: 10 step: 210, loss is 0.0012783266138285398\n",
      "epoch: 10 step: 211, loss is 0.0001383354829158634\n",
      "epoch: 10 step: 212, loss is 0.006046186666935682\n",
      "epoch: 10 step: 213, loss is 0.0015772696351632476\n",
      "epoch: 10 step: 214, loss is 0.0006185724050737917\n",
      "epoch: 10 step: 215, loss is 0.0032501607201993465\n",
      "epoch: 10 step: 216, loss is 0.0047964490950107574\n",
      "epoch: 10 step: 217, loss is 0.0027410355396568775\n",
      "epoch: 10 step: 218, loss is 0.0028699589893221855\n",
      "epoch: 10 step: 219, loss is 8.542247815057635e-05\n",
      "epoch: 10 step: 220, loss is 0.0202336385846138\n",
      "epoch: 10 step: 221, loss is 2.1265137547743507e-05\n",
      "epoch: 10 step: 222, loss is 0.006876269355416298\n",
      "epoch: 10 step: 223, loss is 0.0015295209595933557\n",
      "epoch: 10 step: 224, loss is 0.06595037877559662\n",
      "epoch: 10 step: 225, loss is 0.0005864984705112875\n",
      "epoch: 10 step: 226, loss is 0.0002511622151359916\n",
      "epoch: 10 step: 227, loss is 0.0024867907632142305\n",
      "epoch: 10 step: 228, loss is 0.007783101871609688\n",
      "epoch: 10 step: 229, loss is 0.0004642627027351409\n",
      "epoch: 10 step: 230, loss is 0.0013896788004785776\n",
      "epoch: 10 step: 231, loss is 1.778910700522829e-05\n",
      "epoch: 10 step: 232, loss is 0.015488702803850174\n",
      "epoch: 10 step: 233, loss is 0.00019422097830101848\n",
      "epoch: 10 step: 234, loss is 0.00023002586385700852\n",
      "epoch: 10 step: 235, loss is 0.0010219793766736984\n",
      "epoch: 10 step: 236, loss is 0.00010296191612724215\n",
      "epoch: 10 step: 237, loss is 0.009289651177823544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 238, loss is 0.004392295144498348\n",
      "epoch: 10 step: 239, loss is 0.00012224225793033838\n",
      "epoch: 10 step: 240, loss is 0.0002977510157506913\n",
      "epoch: 10 step: 241, loss is 0.000184536402230151\n",
      "epoch: 10 step: 242, loss is 0.01646602153778076\n",
      "epoch: 10 step: 243, loss is 0.022398922592401505\n",
      "epoch: 10 step: 244, loss is 0.11623622477054596\n",
      "epoch: 10 step: 245, loss is 0.0018962920876219869\n",
      "epoch: 10 step: 246, loss is 0.0004590881580952555\n",
      "epoch: 10 step: 247, loss is 0.005733794532716274\n",
      "epoch: 10 step: 248, loss is 0.012492830865085125\n",
      "epoch: 10 step: 249, loss is 0.00030306639382615685\n",
      "epoch: 10 step: 250, loss is 0.0004263872397132218\n",
      "epoch: 10 step: 251, loss is 0.0012856507673859596\n",
      "epoch: 10 step: 252, loss is 0.002632188145071268\n",
      "epoch: 10 step: 253, loss is 0.00034654425689950585\n",
      "epoch: 10 step: 254, loss is 0.001838818658143282\n",
      "epoch: 10 step: 255, loss is 0.03471582010388374\n",
      "epoch: 10 step: 256, loss is 0.0013375793350860476\n",
      "epoch: 10 step: 257, loss is 0.0033904092852026224\n",
      "epoch: 10 step: 258, loss is 0.0032394665759056807\n",
      "epoch: 10 step: 259, loss is 0.020529285073280334\n",
      "epoch: 10 step: 260, loss is 0.20854514837265015\n",
      "epoch: 10 step: 261, loss is 0.008641366846859455\n",
      "epoch: 10 step: 262, loss is 0.002242610789835453\n",
      "epoch: 10 step: 263, loss is 0.016162164509296417\n",
      "epoch: 10 step: 264, loss is 0.0030718916095793247\n",
      "epoch: 10 step: 265, loss is 0.0007318176212720573\n",
      "epoch: 10 step: 266, loss is 0.0010777032002806664\n",
      "epoch: 10 step: 267, loss is 0.0014482138212770224\n",
      "epoch: 10 step: 268, loss is 0.0005207462818361819\n",
      "epoch: 10 step: 269, loss is 0.0014325607335194945\n",
      "epoch: 10 step: 270, loss is 0.00017383633530698717\n",
      "epoch: 10 step: 271, loss is 0.0005263688508421183\n",
      "epoch: 10 step: 272, loss is 0.01630786433815956\n",
      "epoch: 10 step: 273, loss is 0.03050639107823372\n",
      "epoch: 10 step: 274, loss is 5.279454489937052e-05\n",
      "epoch: 10 step: 275, loss is 0.00035092252073809505\n",
      "epoch: 10 step: 276, loss is 7.570491288788617e-05\n",
      "epoch: 10 step: 277, loss is 0.04449714347720146\n",
      "epoch: 10 step: 278, loss is 0.0007955708424560726\n",
      "epoch: 10 step: 279, loss is 0.004081985913217068\n",
      "epoch: 10 step: 280, loss is 0.0006285978015512228\n",
      "epoch: 10 step: 281, loss is 0.004441004246473312\n",
      "epoch: 10 step: 282, loss is 2.369681533309631e-05\n",
      "epoch: 10 step: 283, loss is 0.000734139874111861\n",
      "epoch: 10 step: 284, loss is 0.011641065590083599\n",
      "epoch: 10 step: 285, loss is 0.000912714225705713\n",
      "epoch: 10 step: 286, loss is 5.762282307841815e-05\n",
      "epoch: 10 step: 287, loss is 0.004219286609441042\n",
      "epoch: 10 step: 288, loss is 0.057758629322052\n",
      "epoch: 10 step: 289, loss is 0.006881938315927982\n",
      "epoch: 10 step: 290, loss is 0.003290388500317931\n",
      "epoch: 10 step: 291, loss is 0.0007920858333818614\n",
      "epoch: 10 step: 292, loss is 4.398621604195796e-05\n",
      "epoch: 10 step: 293, loss is 0.001223336555995047\n",
      "epoch: 10 step: 294, loss is 0.0012388612376525998\n",
      "epoch: 10 step: 295, loss is 0.047000378370285034\n",
      "epoch: 10 step: 296, loss is 0.0005677810404449701\n",
      "epoch: 10 step: 297, loss is 0.004945661872625351\n",
      "epoch: 10 step: 298, loss is 0.00013706466415897012\n",
      "epoch: 10 step: 299, loss is 0.0002855575585272163\n",
      "epoch: 10 step: 300, loss is 2.988623054989148e-05\n",
      "epoch: 10 step: 301, loss is 2.8665024728979915e-05\n",
      "epoch: 10 step: 302, loss is 0.0015381058910861611\n",
      "epoch: 10 step: 303, loss is 0.011207245290279388\n",
      "epoch: 10 step: 304, loss is 0.0002001406392082572\n",
      "epoch: 10 step: 305, loss is 0.0006116966833360493\n",
      "epoch: 10 step: 306, loss is 0.0008486479637213051\n",
      "epoch: 10 step: 307, loss is 0.0010757328709587455\n",
      "epoch: 10 step: 308, loss is 0.00022286150488071144\n",
      "epoch: 10 step: 309, loss is 7.966847624629736e-05\n",
      "epoch: 10 step: 310, loss is 0.00019187951693311334\n",
      "epoch: 10 step: 311, loss is 1.351040100416867e-05\n",
      "epoch: 10 step: 312, loss is 5.389546640799381e-05\n",
      "epoch: 10 step: 313, loss is 0.0002920772531069815\n",
      "epoch: 10 step: 314, loss is 0.0009105867939069867\n",
      "epoch: 10 step: 315, loss is 0.00029014761094003916\n",
      "epoch: 10 step: 316, loss is 0.003435458056628704\n",
      "epoch: 10 step: 317, loss is 1.4156158840705757e-06\n",
      "epoch: 10 step: 318, loss is 0.09552372992038727\n",
      "epoch: 10 step: 319, loss is 0.0010955114848911762\n",
      "epoch: 10 step: 320, loss is 0.0027457333635538816\n",
      "epoch: 10 step: 321, loss is 0.0027493315283209085\n",
      "epoch: 10 step: 322, loss is 0.0055123078636825085\n",
      "epoch: 10 step: 323, loss is 0.0012098097940906882\n",
      "epoch: 10 step: 324, loss is 0.025086713954806328\n",
      "epoch: 10 step: 325, loss is 0.0007457358296960592\n",
      "epoch: 10 step: 326, loss is 0.0076060909777879715\n",
      "epoch: 10 step: 327, loss is 0.00010089735587825999\n",
      "epoch: 10 step: 328, loss is 0.0019470714032649994\n",
      "epoch: 10 step: 329, loss is 0.0013255957746878266\n",
      "epoch: 10 step: 330, loss is 0.0007353401160798967\n",
      "epoch: 10 step: 331, loss is 3.362058487255126e-05\n",
      "epoch: 10 step: 332, loss is 0.14282870292663574\n",
      "epoch: 10 step: 333, loss is 0.003921113442629576\n",
      "epoch: 10 step: 334, loss is 2.485139157215599e-05\n",
      "epoch: 10 step: 335, loss is 0.0002704155049286783\n",
      "epoch: 10 step: 336, loss is 0.0008292899001389742\n",
      "epoch: 10 step: 337, loss is 0.12489087134599686\n",
      "epoch: 10 step: 338, loss is 0.0030749966390430927\n",
      "epoch: 10 step: 339, loss is 0.0038507007993757725\n",
      "epoch: 10 step: 340, loss is 0.00015968744992278516\n",
      "epoch: 10 step: 341, loss is 0.049017660319805145\n",
      "epoch: 10 step: 342, loss is 1.5203620023385156e-05\n",
      "epoch: 10 step: 343, loss is 0.0006193867884576321\n",
      "epoch: 10 step: 344, loss is 0.0003073413099627942\n",
      "epoch: 10 step: 345, loss is 0.0004145948914811015\n",
      "epoch: 10 step: 346, loss is 0.00024179345928132534\n",
      "epoch: 10 step: 347, loss is 8.44211972435005e-05\n",
      "epoch: 10 step: 348, loss is 0.0025379578582942486\n",
      "epoch: 10 step: 349, loss is 0.0010489390697330236\n",
      "epoch: 10 step: 350, loss is 0.11049020290374756\n",
      "epoch: 10 step: 351, loss is 0.0016724775778129697\n",
      "epoch: 10 step: 352, loss is 0.01259161438792944\n",
      "epoch: 10 step: 353, loss is 0.026508614420890808\n",
      "epoch: 10 step: 354, loss is 0.002550323260948062\n",
      "epoch: 10 step: 355, loss is 0.004728465806692839\n",
      "epoch: 10 step: 356, loss is 0.000448799371952191\n",
      "epoch: 10 step: 357, loss is 0.017789987847208977\n",
      "epoch: 10 step: 358, loss is 0.00013727591431234032\n",
      "epoch: 10 step: 359, loss is 0.00016870175022631884\n",
      "epoch: 10 step: 360, loss is 5.86039423069451e-05\n",
      "epoch: 10 step: 361, loss is 0.00017523273709230125\n",
      "epoch: 10 step: 362, loss is 0.0005047487211413682\n",
      "epoch: 10 step: 363, loss is 0.0006065757479518652\n",
      "epoch: 10 step: 364, loss is 0.008699881844222546\n",
      "epoch: 10 step: 365, loss is 0.0011636540293693542\n",
      "epoch: 10 step: 366, loss is 0.0007716813124716282\n",
      "epoch: 10 step: 367, loss is 0.008027895353734493\n",
      "epoch: 10 step: 368, loss is 0.003964822739362717\n",
      "epoch: 10 step: 369, loss is 0.000546519469935447\n",
      "epoch: 10 step: 370, loss is 2.5518547772662714e-06\n",
      "epoch: 10 step: 371, loss is 0.021342944353818893\n",
      "epoch: 10 step: 372, loss is 5.513625183084514e-06\n",
      "epoch: 10 step: 373, loss is 0.002856246894225478\n",
      "epoch: 10 step: 374, loss is 0.00031782506266608834\n",
      "epoch: 10 step: 375, loss is 6.872670201119035e-05\n",
      "epoch: 10 step: 376, loss is 0.03538111224770546\n",
      "epoch: 10 step: 377, loss is 8.033253106987104e-05\n",
      "epoch: 10 step: 378, loss is 0.059969089925289154\n",
      "epoch: 10 step: 379, loss is 3.470814772299491e-05\n",
      "epoch: 10 step: 380, loss is 0.00024022355501074344\n",
      "epoch: 10 step: 381, loss is 0.0009442270384170115\n",
      "epoch: 10 step: 382, loss is 0.0013832590775564313\n",
      "epoch: 10 step: 383, loss is 0.0007949272403493524\n",
      "epoch: 10 step: 384, loss is 0.001146788476034999\n",
      "epoch: 10 step: 385, loss is 0.0011215268168598413\n",
      "epoch: 10 step: 386, loss is 0.02616507187485695\n",
      "epoch: 10 step: 387, loss is 0.004921089857816696\n",
      "epoch: 10 step: 388, loss is 0.0010778602445498109\n",
      "epoch: 10 step: 389, loss is 0.000441103707998991\n",
      "epoch: 10 step: 390, loss is 0.0013992942404001951\n",
      "epoch: 10 step: 391, loss is 0.00042837479850277305\n",
      "epoch: 10 step: 392, loss is 0.0001291046937694773\n",
      "epoch: 10 step: 393, loss is 0.05635762959718704\n",
      "epoch: 10 step: 394, loss is 0.0020181527361273766\n",
      "epoch: 10 step: 395, loss is 0.025289379060268402\n",
      "epoch: 10 step: 396, loss is 0.03184019401669502\n",
      "epoch: 10 step: 397, loss is 0.0034311919007450342\n",
      "epoch: 10 step: 398, loss is 0.001085998141206801\n",
      "epoch: 10 step: 399, loss is 0.0035266675986349583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 400, loss is 0.0021611619740724564\n",
      "epoch: 10 step: 401, loss is 0.006968501023948193\n",
      "epoch: 10 step: 402, loss is 0.024306364357471466\n",
      "epoch: 10 step: 403, loss is 0.00020083390700165182\n",
      "epoch: 10 step: 404, loss is 0.003080538474023342\n",
      "epoch: 10 step: 405, loss is 1.5149067621678114e-05\n",
      "epoch: 10 step: 406, loss is 0.0030738902278244495\n",
      "epoch: 10 step: 407, loss is 0.0019207772566005588\n",
      "epoch: 10 step: 408, loss is 0.0016931261634454131\n",
      "epoch: 10 step: 409, loss is 0.019402608275413513\n",
      "epoch: 10 step: 410, loss is 0.0007881702622398734\n",
      "epoch: 10 step: 411, loss is 0.0003232194285374135\n",
      "epoch: 10 step: 412, loss is 0.0014515361981466413\n",
      "epoch: 10 step: 413, loss is 0.1307631880044937\n",
      "epoch: 10 step: 414, loss is 0.00015944868209771812\n",
      "epoch: 10 step: 415, loss is 0.00015249958960339427\n",
      "epoch: 10 step: 416, loss is 0.007605869323015213\n",
      "epoch: 10 step: 417, loss is 0.0020430241711437702\n",
      "epoch: 10 step: 418, loss is 0.00011107415048172697\n",
      "epoch: 10 step: 419, loss is 0.011242492124438286\n",
      "epoch: 10 step: 420, loss is 0.00035526842111721635\n",
      "epoch: 10 step: 421, loss is 1.9273422367405146e-05\n",
      "epoch: 10 step: 422, loss is 6.815782398916781e-05\n",
      "epoch: 10 step: 423, loss is 0.00016380543820559978\n",
      "epoch: 10 step: 424, loss is 0.007505632005631924\n",
      "epoch: 10 step: 425, loss is 0.0002929308684542775\n",
      "epoch: 10 step: 426, loss is 0.07733724266290665\n",
      "epoch: 10 step: 427, loss is 0.005362355150282383\n",
      "epoch: 10 step: 428, loss is 0.0008145833853632212\n",
      "epoch: 10 step: 429, loss is 0.015788758173584938\n",
      "epoch: 10 step: 430, loss is 0.00014327437384054065\n",
      "epoch: 10 step: 431, loss is 0.0001758222933858633\n",
      "epoch: 10 step: 432, loss is 0.0014534270158037543\n",
      "epoch: 10 step: 433, loss is 0.05867480859160423\n",
      "epoch: 10 step: 434, loss is 0.12386917322874069\n",
      "epoch: 10 step: 435, loss is 0.0019989539869129658\n",
      "epoch: 10 step: 436, loss is 2.5415050913579762e-05\n",
      "epoch: 10 step: 437, loss is 0.0002937761601060629\n",
      "epoch: 10 step: 438, loss is 9.096128633245826e-05\n",
      "epoch: 10 step: 439, loss is 0.003876836970448494\n",
      "epoch: 10 step: 440, loss is 0.006157032214105129\n",
      "epoch: 10 step: 441, loss is 0.03066875785589218\n",
      "epoch: 10 step: 442, loss is 0.00019130577857140452\n",
      "epoch: 10 step: 443, loss is 5.848594446433708e-05\n",
      "epoch: 10 step: 444, loss is 2.422764737275429e-05\n",
      "epoch: 10 step: 445, loss is 0.0001927663543028757\n",
      "epoch: 10 step: 446, loss is 0.03441965579986572\n",
      "epoch: 10 step: 447, loss is 0.0016654256032779813\n",
      "epoch: 10 step: 448, loss is 0.0014131556963548064\n",
      "epoch: 10 step: 449, loss is 0.00011818826897069812\n",
      "epoch: 10 step: 450, loss is 0.06726386398077011\n",
      "epoch: 10 step: 451, loss is 5.032082481193356e-05\n",
      "epoch: 10 step: 452, loss is 0.008381536230444908\n",
      "epoch: 10 step: 453, loss is 0.0012725223787128925\n",
      "epoch: 10 step: 454, loss is 0.00025056026061065495\n",
      "epoch: 10 step: 455, loss is 0.02617732249200344\n",
      "epoch: 10 step: 456, loss is 4.563070251606405e-05\n",
      "epoch: 10 step: 457, loss is 0.0011752223363146186\n",
      "epoch: 10 step: 458, loss is 0.000661910860799253\n",
      "epoch: 10 step: 459, loss is 0.013735936023294926\n",
      "epoch: 10 step: 460, loss is 0.05832432210445404\n",
      "epoch: 10 step: 461, loss is 0.005564376711845398\n",
      "epoch: 10 step: 462, loss is 5.446480372484075e-06\n",
      "epoch: 10 step: 463, loss is 0.0005365556571632624\n",
      "epoch: 10 step: 464, loss is 0.003791204420849681\n",
      "epoch: 10 step: 465, loss is 2.3208788206829922e-06\n",
      "epoch: 10 step: 466, loss is 0.034573182463645935\n",
      "epoch: 10 step: 467, loss is 0.0046349442563951015\n",
      "epoch: 10 step: 468, loss is 0.0020792558789253235\n",
      "epoch: 10 step: 469, loss is 0.00011375835310900584\n",
      "epoch: 10 step: 470, loss is 0.00053312728414312\n",
      "epoch: 10 step: 471, loss is 0.0015311097959056497\n",
      "epoch: 10 step: 472, loss is 0.0004889292176812887\n",
      "epoch: 10 step: 473, loss is 0.034553930163383484\n",
      "epoch: 10 step: 474, loss is 0.1332097053527832\n",
      "epoch: 10 step: 475, loss is 1.531545422039926e-05\n",
      "epoch: 10 step: 476, loss is 8.233776316046715e-05\n",
      "epoch: 10 step: 477, loss is 0.00019469451217446476\n",
      "epoch: 10 step: 478, loss is 0.07431425899267197\n",
      "epoch: 10 step: 479, loss is 0.0002222961193183437\n",
      "epoch: 10 step: 480, loss is 0.0014771175337955356\n",
      "epoch: 10 step: 481, loss is 0.0028299703262746334\n",
      "epoch: 10 step: 482, loss is 0.00010824725177371874\n",
      "epoch: 10 step: 483, loss is 0.0019330526702106\n",
      "epoch: 10 step: 484, loss is 0.0029808180406689644\n",
      "epoch: 10 step: 485, loss is 9.314969065599144e-05\n",
      "epoch: 10 step: 486, loss is 0.01992505043745041\n",
      "epoch: 10 step: 487, loss is 0.0018021261785179377\n",
      "epoch: 10 step: 488, loss is 0.0014784988015890121\n",
      "epoch: 10 step: 489, loss is 0.00045583079918287694\n",
      "epoch: 10 step: 490, loss is 5.351642903406173e-05\n",
      "epoch: 10 step: 491, loss is 9.245696128346026e-05\n",
      "epoch: 10 step: 492, loss is 0.05725079029798508\n",
      "epoch: 10 step: 493, loss is 0.0037633967585861683\n",
      "epoch: 10 step: 494, loss is 0.0250686127692461\n",
      "epoch: 10 step: 495, loss is 0.0006566279917024076\n",
      "epoch: 10 step: 496, loss is 9.84199286904186e-05\n",
      "epoch: 10 step: 497, loss is 0.00016327646153513342\n",
      "epoch: 10 step: 498, loss is 0.008919570595026016\n",
      "epoch: 10 step: 499, loss is 2.2947826437302865e-05\n",
      "epoch: 10 step: 500, loss is 0.005245615262538195\n",
      "epoch: 10 step: 501, loss is 0.0007858488825149834\n",
      "epoch: 10 step: 502, loss is 0.00996309332549572\n",
      "epoch: 10 step: 503, loss is 0.00040201935917139053\n",
      "epoch: 10 step: 504, loss is 0.0012824557488784194\n",
      "epoch: 10 step: 505, loss is 0.0007363869226537645\n",
      "epoch: 10 step: 506, loss is 0.015457944013178349\n",
      "epoch: 10 step: 507, loss is 0.0004875481827184558\n",
      "epoch: 10 step: 508, loss is 4.489565981202759e-05\n",
      "epoch: 10 step: 509, loss is 0.0003284515405539423\n",
      "epoch: 10 step: 510, loss is 0.00015236074978020042\n",
      "epoch: 10 step: 511, loss is 0.003485148074105382\n",
      "epoch: 10 step: 512, loss is 0.03663570061326027\n",
      "epoch: 10 step: 513, loss is 0.001289117499254644\n",
      "epoch: 10 step: 514, loss is 1.7301763364230283e-05\n",
      "epoch: 10 step: 515, loss is 0.029596300795674324\n",
      "epoch: 10 step: 516, loss is 0.018515516072511673\n",
      "epoch: 10 step: 517, loss is 2.489211328793317e-05\n",
      "epoch: 10 step: 518, loss is 0.00034099468030035496\n",
      "epoch: 10 step: 519, loss is 0.0001663715811446309\n",
      "epoch: 10 step: 520, loss is 0.003827567445114255\n",
      "epoch: 10 step: 521, loss is 2.6621666620485485e-05\n",
      "epoch: 10 step: 522, loss is 0.03463131934404373\n",
      "epoch: 10 step: 523, loss is 0.007880747318267822\n",
      "epoch: 10 step: 524, loss is 0.0003011610242538154\n",
      "epoch: 10 step: 525, loss is 3.3238844480365515e-05\n",
      "epoch: 10 step: 526, loss is 0.016774486750364304\n",
      "epoch: 10 step: 527, loss is 0.011279680766165257\n",
      "epoch: 10 step: 528, loss is 0.00025779809220694005\n",
      "epoch: 10 step: 529, loss is 0.0009541918989270926\n",
      "epoch: 10 step: 530, loss is 0.0023199652787297964\n",
      "epoch: 10 step: 531, loss is 0.0005275725852698088\n",
      "epoch: 10 step: 532, loss is 0.0873553454875946\n",
      "epoch: 10 step: 533, loss is 0.003585709957405925\n",
      "epoch: 10 step: 534, loss is 0.039685193449258804\n",
      "epoch: 10 step: 535, loss is 0.033114369958639145\n",
      "epoch: 10 step: 536, loss is 0.0016860138857737184\n",
      "epoch: 10 step: 537, loss is 0.004796199034899473\n",
      "epoch: 10 step: 538, loss is 0.0720914900302887\n",
      "epoch: 10 step: 539, loss is 0.00028066319646313787\n",
      "epoch: 10 step: 540, loss is 3.294836642453447e-05\n",
      "epoch: 10 step: 541, loss is 0.000756550463847816\n",
      "epoch: 10 step: 542, loss is 0.028982490301132202\n",
      "epoch: 10 step: 543, loss is 0.0013066428946331143\n",
      "epoch: 10 step: 544, loss is 0.01314254105091095\n",
      "epoch: 10 step: 545, loss is 0.014491325244307518\n",
      "epoch: 10 step: 546, loss is 0.0002446019498165697\n",
      "epoch: 10 step: 547, loss is 0.0003321776748634875\n",
      "epoch: 10 step: 548, loss is 0.007653234526515007\n",
      "epoch: 10 step: 549, loss is 0.0006438224809244275\n",
      "epoch: 10 step: 550, loss is 0.0037318409886211157\n",
      "epoch: 10 step: 551, loss is 0.008054572157561779\n",
      "epoch: 10 step: 552, loss is 2.4037941329879686e-05\n",
      "epoch: 10 step: 553, loss is 0.0001268439955310896\n",
      "epoch: 10 step: 554, loss is 0.0026935888454318047\n",
      "epoch: 10 step: 555, loss is 0.005161892157047987\n",
      "epoch: 10 step: 556, loss is 0.009786893613636494\n",
      "epoch: 10 step: 557, loss is 0.20649904012680054\n",
      "epoch: 10 step: 558, loss is 0.005323668941855431\n",
      "epoch: 10 step: 559, loss is 0.0031311328057199717\n",
      "epoch: 10 step: 560, loss is 0.0015207250835373998\n",
      "epoch: 10 step: 561, loss is 0.010274040512740612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 562, loss is 0.00019329409406054765\n",
      "epoch: 10 step: 563, loss is 0.05007479339838028\n",
      "epoch: 10 step: 564, loss is 0.058661919087171555\n",
      "epoch: 10 step: 565, loss is 0.004887115675956011\n",
      "epoch: 10 step: 566, loss is 0.027034185826778412\n",
      "epoch: 10 step: 567, loss is 8.399533544434234e-05\n",
      "epoch: 10 step: 568, loss is 0.2162785828113556\n",
      "epoch: 10 step: 569, loss is 0.05158565565943718\n",
      "epoch: 10 step: 570, loss is 2.9837372494512238e-05\n",
      "epoch: 10 step: 571, loss is 3.777051097131334e-05\n",
      "epoch: 10 step: 572, loss is 0.1855432391166687\n",
      "epoch: 10 step: 573, loss is 0.0002072857751045376\n",
      "epoch: 10 step: 574, loss is 0.01349946204572916\n",
      "epoch: 10 step: 575, loss is 0.007571069989353418\n",
      "epoch: 10 step: 576, loss is 0.0005147424526512623\n",
      "epoch: 10 step: 577, loss is 0.04107479378581047\n",
      "epoch: 10 step: 578, loss is 0.000986979459412396\n",
      "epoch: 10 step: 579, loss is 3.121847157672164e-06\n",
      "epoch: 10 step: 580, loss is 0.0004793912812601775\n",
      "epoch: 10 step: 581, loss is 0.006414744071662426\n",
      "epoch: 10 step: 582, loss is 2.8312565518717747e-06\n",
      "epoch: 10 step: 583, loss is 0.034140605479478836\n",
      "epoch: 10 step: 584, loss is 0.0002557341067586094\n",
      "epoch: 10 step: 585, loss is 0.014668511226773262\n",
      "epoch: 10 step: 586, loss is 0.21138624846935272\n",
      "epoch: 10 step: 587, loss is 0.003663860261440277\n",
      "epoch: 10 step: 588, loss is 0.0006502450560219586\n",
      "epoch: 10 step: 589, loss is 0.00015109177911654115\n",
      "epoch: 10 step: 590, loss is 0.002928324742242694\n",
      "epoch: 10 step: 591, loss is 0.04236616566777229\n",
      "epoch: 10 step: 592, loss is 0.012934142723679543\n",
      "epoch: 10 step: 593, loss is 0.014575163833796978\n",
      "epoch: 10 step: 594, loss is 0.0045847115106880665\n",
      "epoch: 10 step: 595, loss is 0.0015325072454288602\n",
      "epoch: 10 step: 596, loss is 0.008092372678220272\n",
      "epoch: 10 step: 597, loss is 0.025471100583672523\n",
      "epoch: 10 step: 598, loss is 0.0022353478707373142\n",
      "epoch: 10 step: 599, loss is 0.03675375506281853\n",
      "epoch: 10 step: 600, loss is 0.09197338670492172\n",
      "epoch: 10 step: 601, loss is 0.00047711952356621623\n",
      "epoch: 10 step: 602, loss is 0.002176257548853755\n",
      "epoch: 10 step: 603, loss is 0.009793953038752079\n",
      "epoch: 10 step: 604, loss is 5.460477768792771e-05\n",
      "epoch: 10 step: 605, loss is 0.0006489696679636836\n",
      "epoch: 10 step: 606, loss is 0.09223141521215439\n",
      "epoch: 10 step: 607, loss is 0.0002393600152572617\n",
      "epoch: 10 step: 608, loss is 0.004069077782332897\n",
      "epoch: 10 step: 609, loss is 0.0016012239502742887\n",
      "epoch: 10 step: 610, loss is 0.0010927969124168158\n",
      "epoch: 10 step: 611, loss is 4.8921840061666444e-05\n",
      "epoch: 10 step: 612, loss is 0.0006898571737110615\n",
      "epoch: 10 step: 613, loss is 0.0006819010013714433\n",
      "epoch: 10 step: 614, loss is 0.0003854873648378998\n",
      "epoch: 10 step: 615, loss is 0.015012245625257492\n",
      "epoch: 10 step: 616, loss is 0.002468288177624345\n",
      "epoch: 10 step: 617, loss is 7.512023148592561e-05\n",
      "epoch: 10 step: 618, loss is 0.0001757846330292523\n",
      "epoch: 10 step: 619, loss is 0.002282633911818266\n",
      "epoch: 10 step: 620, loss is 0.00010322711750632152\n",
      "epoch: 10 step: 621, loss is 0.020347105339169502\n",
      "epoch: 10 step: 622, loss is 0.004031808115541935\n",
      "epoch: 10 step: 623, loss is 0.0019919690676033497\n",
      "epoch: 10 step: 624, loss is 0.0746864378452301\n",
      "epoch: 10 step: 625, loss is 5.2043205869267695e-06\n",
      "epoch: 10 step: 626, loss is 3.96374125557486e-05\n",
      "epoch: 10 step: 627, loss is 0.16530847549438477\n",
      "epoch: 10 step: 628, loss is 0.00039970752550289035\n",
      "epoch: 10 step: 629, loss is 8.70597068569623e-05\n",
      "epoch: 10 step: 630, loss is 2.2022419216227718e-05\n",
      "epoch: 10 step: 631, loss is 0.0003082574112340808\n",
      "epoch: 10 step: 632, loss is 0.0005259888712316751\n",
      "epoch: 10 step: 633, loss is 0.0008880952373147011\n",
      "epoch: 10 step: 634, loss is 0.0003559697070159018\n",
      "epoch: 10 step: 635, loss is 0.0013169525191187859\n",
      "epoch: 10 step: 636, loss is 0.0071968683041632175\n",
      "epoch: 10 step: 637, loss is 0.0007539585349150002\n",
      "epoch: 10 step: 638, loss is 0.00052271579625085\n",
      "epoch: 10 step: 639, loss is 0.00020124194270465523\n",
      "epoch: 10 step: 640, loss is 0.028469344601035118\n",
      "epoch: 10 step: 641, loss is 0.09779120236635208\n",
      "epoch: 10 step: 642, loss is 0.0006645335233770311\n",
      "epoch: 10 step: 643, loss is 0.07912569493055344\n",
      "epoch: 10 step: 644, loss is 6.60610239719972e-05\n",
      "epoch: 10 step: 645, loss is 0.03630048781633377\n",
      "epoch: 10 step: 646, loss is 0.0012785298749804497\n",
      "epoch: 10 step: 647, loss is 0.00030571239767596126\n",
      "epoch: 10 step: 648, loss is 0.005152683239430189\n",
      "epoch: 10 step: 649, loss is 0.00256527541205287\n",
      "epoch: 10 step: 650, loss is 0.0007272453512996435\n",
      "epoch: 10 step: 651, loss is 0.03682611510157585\n",
      "epoch: 10 step: 652, loss is 0.003113376908004284\n",
      "epoch: 10 step: 653, loss is 0.0011408246355131269\n",
      "epoch: 10 step: 654, loss is 0.004682830534875393\n",
      "epoch: 10 step: 655, loss is 0.012098057195544243\n",
      "epoch: 10 step: 656, loss is 0.011553015559911728\n",
      "epoch: 10 step: 657, loss is 0.0009443581220693886\n",
      "epoch: 10 step: 658, loss is 0.004787737503647804\n",
      "epoch: 10 step: 659, loss is 7.511118019465357e-05\n",
      "epoch: 10 step: 660, loss is 0.0013606606516987085\n",
      "epoch: 10 step: 661, loss is 0.00044902783702127635\n",
      "epoch: 10 step: 662, loss is 0.014965008944272995\n",
      "epoch: 10 step: 663, loss is 0.0004950835718773305\n",
      "epoch: 10 step: 664, loss is 0.004891876131296158\n",
      "epoch: 10 step: 665, loss is 0.0005226403009146452\n",
      "epoch: 10 step: 666, loss is 9.316462819697335e-05\n",
      "epoch: 10 step: 667, loss is 0.0026601506397128105\n",
      "epoch: 10 step: 668, loss is 0.0002908830938395113\n",
      "epoch: 10 step: 669, loss is 0.0043295579962432384\n",
      "epoch: 10 step: 670, loss is 0.007995618507266045\n",
      "epoch: 10 step: 671, loss is 0.0007135967025533319\n",
      "epoch: 10 step: 672, loss is 0.0006140118930488825\n",
      "epoch: 10 step: 673, loss is 0.0010099667124450207\n",
      "epoch: 10 step: 674, loss is 0.00023432474699802697\n",
      "epoch: 10 step: 675, loss is 0.01787228137254715\n",
      "epoch: 10 step: 676, loss is 0.010850833728909492\n",
      "epoch: 10 step: 677, loss is 0.0030839622486382723\n",
      "epoch: 10 step: 678, loss is 0.002610832452774048\n",
      "epoch: 10 step: 679, loss is 0.001057418528944254\n",
      "epoch: 10 step: 680, loss is 0.011961041018366814\n",
      "epoch: 10 step: 681, loss is 0.008754042908549309\n",
      "epoch: 10 step: 682, loss is 0.06492220610380173\n",
      "epoch: 10 step: 683, loss is 4.319459912949242e-05\n",
      "epoch: 10 step: 684, loss is 0.00021070601360406727\n",
      "epoch: 10 step: 685, loss is 0.005996999330818653\n",
      "epoch: 10 step: 686, loss is 0.009545731358230114\n",
      "epoch: 10 step: 687, loss is 7.00222808518447e-05\n",
      "epoch: 10 step: 688, loss is 0.0001887281541712582\n",
      "epoch: 10 step: 689, loss is 0.0003248102148063481\n",
      "epoch: 10 step: 690, loss is 0.0001091102312784642\n",
      "epoch: 10 step: 691, loss is 0.001104785013012588\n",
      "epoch: 10 step: 692, loss is 0.0005949260084889829\n",
      "epoch: 10 step: 693, loss is 0.0019362346502020955\n",
      "epoch: 10 step: 694, loss is 0.013354313559830189\n",
      "epoch: 10 step: 695, loss is 0.000534556049387902\n",
      "epoch: 10 step: 696, loss is 0.00878809206187725\n",
      "epoch: 10 step: 697, loss is 0.02505853772163391\n",
      "epoch: 10 step: 698, loss is 0.0014625157928094268\n",
      "epoch: 10 step: 699, loss is 0.0006796304951421916\n",
      "epoch: 10 step: 700, loss is 0.018733186647295952\n",
      "epoch: 10 step: 701, loss is 0.08148111402988434\n",
      "epoch: 10 step: 702, loss is 6.51381051284261e-05\n",
      "epoch: 10 step: 703, loss is 0.004316824022680521\n",
      "epoch: 10 step: 704, loss is 0.028772268444299698\n",
      "epoch: 10 step: 705, loss is 0.00013000731996726245\n",
      "epoch: 10 step: 706, loss is 0.0439114049077034\n",
      "epoch: 10 step: 707, loss is 0.021291207522153854\n",
      "epoch: 10 step: 708, loss is 0.04087267071008682\n",
      "epoch: 10 step: 709, loss is 0.006343663204461336\n",
      "epoch: 10 step: 710, loss is 0.00862069521099329\n",
      "epoch: 10 step: 711, loss is 0.0013420332688838243\n",
      "epoch: 10 step: 712, loss is 0.22597365081310272\n",
      "epoch: 10 step: 713, loss is 0.0006307319272309542\n",
      "epoch: 10 step: 714, loss is 0.00011814686877187341\n",
      "epoch: 10 step: 715, loss is 0.008473553694784641\n",
      "epoch: 10 step: 716, loss is 0.02906581573188305\n",
      "epoch: 10 step: 717, loss is 0.0018554870039224625\n",
      "epoch: 10 step: 718, loss is 0.008432145230472088\n",
      "epoch: 10 step: 719, loss is 0.00767340324819088\n",
      "epoch: 10 step: 720, loss is 0.0055862655863165855\n",
      "epoch: 10 step: 721, loss is 0.0008438713266514242\n",
      "epoch: 10 step: 722, loss is 5.826786218676716e-05\n",
      "epoch: 10 step: 723, loss is 0.15987497568130493\n",
      "epoch: 10 step: 724, loss is 0.0013053907314315438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 725, loss is 0.00023704035265836865\n",
      "epoch: 10 step: 726, loss is 0.004626729059964418\n",
      "epoch: 10 step: 727, loss is 0.029097318649291992\n",
      "epoch: 10 step: 728, loss is 0.00033965331385843456\n",
      "epoch: 10 step: 729, loss is 0.00154190044850111\n",
      "epoch: 10 step: 730, loss is 0.0005003585247322917\n",
      "epoch: 10 step: 731, loss is 0.00045045133447274566\n",
      "epoch: 10 step: 732, loss is 0.004997937940061092\n",
      "epoch: 10 step: 733, loss is 7.37610321266402e-07\n",
      "epoch: 10 step: 734, loss is 0.000830686476547271\n",
      "epoch: 10 step: 735, loss is 2.9960723622934893e-05\n",
      "epoch: 10 step: 736, loss is 0.04169031232595444\n",
      "epoch: 10 step: 737, loss is 0.06905725598335266\n",
      "epoch: 10 step: 738, loss is 1.1049757631553803e-05\n",
      "epoch: 10 step: 739, loss is 0.0058323233388364315\n",
      "epoch: 10 step: 740, loss is 0.004178911447525024\n",
      "epoch: 10 step: 741, loss is 0.0011940195690840483\n",
      "epoch: 10 step: 742, loss is 0.00495224678888917\n",
      "epoch: 10 step: 743, loss is 0.00031074354774318635\n",
      "epoch: 10 step: 744, loss is 7.869444380048662e-05\n",
      "epoch: 10 step: 745, loss is 0.0075203124433755875\n",
      "epoch: 10 step: 746, loss is 0.00033094690297730267\n",
      "epoch: 10 step: 747, loss is 6.24654785497114e-05\n",
      "epoch: 10 step: 748, loss is 0.0001014697045320645\n",
      "epoch: 10 step: 749, loss is 3.998868851340376e-05\n",
      "epoch: 10 step: 750, loss is 0.0034328990150243044\n",
      "epoch: 10 step: 751, loss is 2.8196576749905944e-05\n",
      "epoch: 10 step: 752, loss is 0.002891821786761284\n",
      "epoch: 10 step: 753, loss is 0.00026747575611807406\n",
      "epoch: 10 step: 754, loss is 0.021521542221307755\n",
      "epoch: 10 step: 755, loss is 0.0015398698160424829\n",
      "epoch: 10 step: 756, loss is 0.00041249918285757303\n",
      "epoch: 10 step: 757, loss is 0.0027135859709233046\n",
      "epoch: 10 step: 758, loss is 0.04375968500971794\n",
      "epoch: 10 step: 759, loss is 0.00020289470558054745\n",
      "epoch: 10 step: 760, loss is 0.018659064546227455\n",
      "epoch: 10 step: 761, loss is 0.0010493325535207987\n",
      "epoch: 10 step: 762, loss is 0.00012189875269541517\n",
      "epoch: 10 step: 763, loss is 4.049340350320563e-05\n",
      "epoch: 10 step: 764, loss is 0.005768905393779278\n",
      "epoch: 10 step: 765, loss is 0.0008323843940161169\n",
      "epoch: 10 step: 766, loss is 4.4205004087416455e-05\n",
      "epoch: 10 step: 767, loss is 2.808903218465275e-06\n",
      "epoch: 10 step: 768, loss is 0.039911411702632904\n",
      "epoch: 10 step: 769, loss is 0.0005582344601862133\n",
      "epoch: 10 step: 770, loss is 0.0005406341515481472\n",
      "epoch: 10 step: 771, loss is 3.0554547265637666e-05\n",
      "epoch: 10 step: 772, loss is 0.010707968845963478\n",
      "epoch: 10 step: 773, loss is 0.005489180330187082\n",
      "epoch: 10 step: 774, loss is 0.00014493928756564856\n",
      "epoch: 10 step: 775, loss is 4.3133459257660434e-05\n",
      "epoch: 10 step: 776, loss is 1.3723596566705965e-05\n",
      "epoch: 10 step: 777, loss is 0.0734374076128006\n",
      "epoch: 10 step: 778, loss is 6.233232124941424e-05\n",
      "epoch: 10 step: 779, loss is 0.0035730109084397554\n",
      "epoch: 10 step: 780, loss is 6.966663204366341e-05\n",
      "epoch: 10 step: 781, loss is 0.00011985459423158318\n",
      "epoch: 10 step: 782, loss is 0.009062620811164379\n",
      "epoch: 10 step: 783, loss is 4.456112947082147e-05\n",
      "epoch: 10 step: 784, loss is 0.03526021167635918\n",
      "epoch: 10 step: 785, loss is 0.0010141520760953426\n",
      "epoch: 10 step: 786, loss is 0.0018031859071925282\n",
      "epoch: 10 step: 787, loss is 0.0002390617592027411\n",
      "epoch: 10 step: 788, loss is 0.28800976276397705\n",
      "epoch: 10 step: 789, loss is 0.01693214662373066\n",
      "epoch: 10 step: 790, loss is 0.0008450045133940876\n",
      "epoch: 10 step: 791, loss is 0.0012213591253384948\n",
      "epoch: 10 step: 792, loss is 3.514160925988108e-05\n",
      "epoch: 10 step: 793, loss is 0.011180390603840351\n",
      "epoch: 10 step: 794, loss is 0.12497088313102722\n",
      "epoch: 10 step: 795, loss is 0.11868976801633835\n",
      "epoch: 10 step: 796, loss is 0.0007078083581291139\n",
      "epoch: 10 step: 797, loss is 0.0004216124361846596\n",
      "epoch: 10 step: 798, loss is 1.2651616088987794e-05\n",
      "epoch: 10 step: 799, loss is 0.000583746237680316\n",
      "epoch: 10 step: 800, loss is 0.0015954701229929924\n",
      "epoch: 10 step: 801, loss is 0.0024333568289875984\n",
      "epoch: 10 step: 802, loss is 0.0014960413100197911\n",
      "epoch: 10 step: 803, loss is 0.0019380593439564109\n",
      "epoch: 10 step: 804, loss is 0.011806418187916279\n",
      "epoch: 10 step: 805, loss is 0.027161145582795143\n",
      "epoch: 10 step: 806, loss is 0.0005634241970255971\n",
      "epoch: 10 step: 807, loss is 0.008954906836152077\n",
      "epoch: 10 step: 808, loss is 0.001015521353110671\n",
      "epoch: 10 step: 809, loss is 0.003412160323932767\n",
      "epoch: 10 step: 810, loss is 0.0016440480249002576\n",
      "epoch: 10 step: 811, loss is 0.0008327302057296038\n",
      "epoch: 10 step: 812, loss is 0.00017735594883561134\n",
      "epoch: 10 step: 813, loss is 0.008506957441568375\n",
      "epoch: 10 step: 814, loss is 0.006326932460069656\n",
      "epoch: 10 step: 815, loss is 0.009363922290503979\n",
      "epoch: 10 step: 816, loss is 0.0012398881372064352\n",
      "epoch: 10 step: 817, loss is 0.0012016111286357045\n",
      "epoch: 10 step: 818, loss is 0.00016522528312634677\n",
      "epoch: 10 step: 819, loss is 0.0027372792828828096\n",
      "epoch: 10 step: 820, loss is 9.773082274477929e-05\n",
      "epoch: 10 step: 821, loss is 0.0031834044493734837\n",
      "epoch: 10 step: 822, loss is 0.008065890520811081\n",
      "epoch: 10 step: 823, loss is 0.0008896783110685647\n",
      "epoch: 10 step: 824, loss is 0.033392030745744705\n",
      "epoch: 10 step: 825, loss is 0.000610693241469562\n",
      "epoch: 10 step: 826, loss is 0.0021792794577777386\n",
      "epoch: 10 step: 827, loss is 0.018574949353933334\n",
      "epoch: 10 step: 828, loss is 0.0016142386011779308\n",
      "epoch: 10 step: 829, loss is 0.05679081380367279\n",
      "epoch: 10 step: 830, loss is 0.0664227157831192\n",
      "epoch: 10 step: 831, loss is 0.022602954879403114\n",
      "epoch: 10 step: 832, loss is 0.0006014924729242921\n",
      "epoch: 10 step: 833, loss is 0.0009000131394714117\n",
      "epoch: 10 step: 834, loss is 0.002534742932766676\n",
      "epoch: 10 step: 835, loss is 0.004579166881740093\n",
      "epoch: 10 step: 836, loss is 0.00033091730438172817\n",
      "epoch: 10 step: 837, loss is 0.00013735749234911054\n",
      "epoch: 10 step: 838, loss is 0.0002438338124193251\n",
      "epoch: 10 step: 839, loss is 0.00014779878256376833\n",
      "epoch: 10 step: 840, loss is 6.936623321962543e-06\n",
      "epoch: 10 step: 841, loss is 0.027005977928638458\n",
      "epoch: 10 step: 842, loss is 0.0031578929629176855\n",
      "epoch: 10 step: 843, loss is 0.0001248895569005981\n",
      "epoch: 10 step: 844, loss is 0.0019695465452969074\n",
      "epoch: 10 step: 845, loss is 0.00254057627171278\n",
      "epoch: 10 step: 846, loss is 0.020584063604474068\n",
      "epoch: 10 step: 847, loss is 6.71223970130086e-05\n",
      "epoch: 10 step: 848, loss is 0.01420594658702612\n",
      "epoch: 10 step: 849, loss is 0.0008800682262517512\n",
      "epoch: 10 step: 850, loss is 0.0017174056265503168\n",
      "epoch: 10 step: 851, loss is 0.00010038680920843035\n",
      "epoch: 10 step: 852, loss is 0.011342914775013924\n",
      "epoch: 10 step: 853, loss is 0.0001893606677185744\n",
      "epoch: 10 step: 854, loss is 0.00010702303552534431\n",
      "epoch: 10 step: 855, loss is 0.00020803369989152998\n",
      "epoch: 10 step: 856, loss is 0.04207028076052666\n",
      "epoch: 10 step: 857, loss is 0.0016478222096338868\n",
      "epoch: 10 step: 858, loss is 0.0017568240873515606\n",
      "epoch: 10 step: 859, loss is 0.0006156826857477427\n",
      "epoch: 10 step: 860, loss is 0.0026693730615079403\n",
      "epoch: 10 step: 861, loss is 0.0001408834068570286\n",
      "epoch: 10 step: 862, loss is 0.00019235990475863218\n",
      "epoch: 10 step: 863, loss is 1.1537632417457644e-05\n",
      "epoch: 10 step: 864, loss is 4.4318825530353934e-05\n",
      "epoch: 10 step: 865, loss is 0.0002316161699127406\n",
      "epoch: 10 step: 866, loss is 0.0013464103685691953\n",
      "epoch: 10 step: 867, loss is 0.003161034779623151\n",
      "epoch: 10 step: 868, loss is 0.0006582837086170912\n",
      "epoch: 10 step: 869, loss is 0.00018671684665605426\n",
      "epoch: 10 step: 870, loss is 0.0001792802504496649\n",
      "epoch: 10 step: 871, loss is 1.672451980994083e-05\n",
      "epoch: 10 step: 872, loss is 3.3253556466661394e-05\n",
      "epoch: 10 step: 873, loss is 1.7860431398730725e-05\n",
      "epoch: 10 step: 874, loss is 6.819255213486031e-05\n",
      "epoch: 10 step: 875, loss is 0.00013580867380369455\n",
      "epoch: 10 step: 876, loss is 2.258228232676629e-05\n",
      "epoch: 10 step: 877, loss is 0.00040219942457042634\n",
      "epoch: 10 step: 878, loss is 1.0168846529268194e-05\n",
      "epoch: 10 step: 879, loss is 0.0008947243914008141\n",
      "epoch: 10 step: 880, loss is 0.0007110479637049139\n",
      "epoch: 10 step: 881, loss is 0.0004731629742309451\n",
      "epoch: 10 step: 882, loss is 0.0031241709366440773\n",
      "epoch: 10 step: 883, loss is 8.188530046027154e-06\n",
      "epoch: 10 step: 884, loss is 0.0005047338781878352\n",
      "epoch: 10 step: 885, loss is 0.021545996889472008\n",
      "epoch: 10 step: 886, loss is 3.9787332752894145e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 887, loss is 0.0005680133472196758\n",
      "epoch: 10 step: 888, loss is 0.00791159737855196\n",
      "epoch: 10 step: 889, loss is 0.0005517435492947698\n",
      "epoch: 10 step: 890, loss is 9.24880150705576e-05\n",
      "epoch: 10 step: 891, loss is 3.259043296566233e-05\n",
      "epoch: 10 step: 892, loss is 0.01368920598179102\n",
      "epoch: 10 step: 893, loss is 0.03886112943291664\n",
      "epoch: 10 step: 894, loss is 0.0003903293691109866\n",
      "epoch: 10 step: 895, loss is 0.0003646719560492784\n",
      "epoch: 10 step: 896, loss is 0.04293235018849373\n",
      "epoch: 10 step: 897, loss is 0.12642179429531097\n",
      "epoch: 10 step: 898, loss is 0.00015999781317077577\n",
      "epoch: 10 step: 899, loss is 0.0026662324089556932\n",
      "epoch: 10 step: 900, loss is 0.1130453422665596\n",
      "epoch: 10 step: 901, loss is 0.0012577521847561002\n",
      "epoch: 10 step: 902, loss is 0.013373611494898796\n",
      "epoch: 10 step: 903, loss is 0.0003335645596962422\n",
      "epoch: 10 step: 904, loss is 0.0004620364052243531\n",
      "epoch: 10 step: 905, loss is 6.931556526978966e-06\n",
      "epoch: 10 step: 906, loss is 0.004665517248213291\n",
      "epoch: 10 step: 907, loss is 3.7529960536630824e-05\n",
      "epoch: 10 step: 908, loss is 0.00011498927051434293\n",
      "epoch: 10 step: 909, loss is 0.01833566091954708\n",
      "epoch: 10 step: 910, loss is 0.00010219544492429122\n",
      "epoch: 10 step: 911, loss is 5.184857582207769e-05\n",
      "epoch: 10 step: 912, loss is 0.0017794232117012143\n",
      "epoch: 10 step: 913, loss is 5.113910083309747e-05\n",
      "epoch: 10 step: 914, loss is 0.05670371279120445\n",
      "epoch: 10 step: 915, loss is 0.0180494487285614\n",
      "epoch: 10 step: 916, loss is 0.006266003008931875\n",
      "epoch: 10 step: 917, loss is 1.1116864698124118e-05\n",
      "epoch: 10 step: 918, loss is 0.004022093024104834\n",
      "epoch: 10 step: 919, loss is 0.0005892665940336883\n",
      "epoch: 10 step: 920, loss is 0.10049653798341751\n",
      "epoch: 10 step: 921, loss is 0.00020672398386523128\n",
      "epoch: 10 step: 922, loss is 0.062158603221178055\n",
      "epoch: 10 step: 923, loss is 0.19064849615097046\n",
      "epoch: 10 step: 924, loss is 0.004810164216905832\n",
      "epoch: 10 step: 925, loss is 3.705434573930688e-05\n",
      "epoch: 10 step: 926, loss is 0.00015226658433675766\n",
      "epoch: 10 step: 927, loss is 0.03344453498721123\n",
      "epoch: 10 step: 928, loss is 0.00047153502237051725\n",
      "epoch: 10 step: 929, loss is 0.0562073215842247\n",
      "epoch: 10 step: 930, loss is 0.0008838517242111266\n",
      "epoch: 10 step: 931, loss is 0.00586693175137043\n",
      "epoch: 10 step: 932, loss is 0.01431478001177311\n",
      "epoch: 10 step: 933, loss is 0.00022823316976428032\n",
      "epoch: 10 step: 934, loss is 0.0002855375059880316\n",
      "epoch: 10 step: 935, loss is 0.00014709732204210013\n",
      "epoch: 10 step: 936, loss is 0.0013664484722539783\n",
      "epoch: 10 step: 937, loss is 0.07451459020376205\n",
      "epoch: 10 step: 938, loss is 0.0016442399937659502\n",
      "epoch: 10 step: 939, loss is 0.005458774510771036\n",
      "epoch: 10 step: 940, loss is 0.05216037482023239\n",
      "epoch: 10 step: 941, loss is 0.03601691126823425\n",
      "epoch: 10 step: 942, loss is 0.03927979618310928\n",
      "epoch: 10 step: 943, loss is 5.986091127851978e-05\n",
      "epoch: 10 step: 944, loss is 0.0013707155594602227\n",
      "epoch: 10 step: 945, loss is 0.00388595019467175\n",
      "epoch: 10 step: 946, loss is 0.00520770950242877\n",
      "epoch: 10 step: 947, loss is 0.000560976390261203\n",
      "epoch: 10 step: 948, loss is 0.000302873901091516\n",
      "epoch: 10 step: 949, loss is 0.0006608837284147739\n",
      "epoch: 10 step: 950, loss is 9.457483429287095e-06\n",
      "epoch: 10 step: 951, loss is 0.000376182229956612\n",
      "epoch: 10 step: 952, loss is 0.0025814492255449295\n",
      "epoch: 10 step: 953, loss is 2.417744553895318e-06\n",
      "epoch: 10 step: 954, loss is 0.00011249975068494678\n",
      "epoch: 10 step: 955, loss is 6.196996400831267e-05\n",
      "epoch: 10 step: 956, loss is 8.308557153213769e-05\n",
      "epoch: 10 step: 957, loss is 1.8016053218161687e-05\n",
      "epoch: 10 step: 958, loss is 0.001567150349728763\n",
      "epoch: 10 step: 959, loss is 0.024358857423067093\n",
      "epoch: 10 step: 960, loss is 0.003623092779889703\n",
      "epoch: 10 step: 961, loss is 0.010103676468133926\n",
      "epoch: 10 step: 962, loss is 1.5199268545984523e-06\n",
      "epoch: 10 step: 963, loss is 3.2588875910732895e-05\n",
      "epoch: 10 step: 964, loss is 0.023018978536128998\n",
      "epoch: 10 step: 965, loss is 0.00045375715126283467\n",
      "epoch: 10 step: 966, loss is 0.0001316484558628872\n",
      "epoch: 10 step: 967, loss is 0.0005006538121961057\n",
      "epoch: 10 step: 968, loss is 8.827743295114487e-05\n",
      "epoch: 10 step: 969, loss is 0.00048063715803436935\n",
      "epoch: 10 step: 970, loss is 8.776675531407818e-05\n",
      "epoch: 10 step: 971, loss is 0.0010721777798607945\n",
      "epoch: 10 step: 972, loss is 0.01211280282586813\n",
      "epoch: 10 step: 973, loss is 2.35879015235696e-05\n",
      "epoch: 10 step: 974, loss is 0.0028756787069141865\n",
      "epoch: 10 step: 975, loss is 0.12211868911981583\n",
      "epoch: 10 step: 976, loss is 4.621431071427651e-05\n",
      "epoch: 10 step: 977, loss is 8.409073780057952e-05\n",
      "epoch: 10 step: 978, loss is 0.02661067247390747\n",
      "epoch: 10 step: 979, loss is 1.5045474356156774e-05\n",
      "epoch: 10 step: 980, loss is 1.0009351171902381e-05\n",
      "epoch: 10 step: 981, loss is 0.017793411388993263\n",
      "epoch: 10 step: 982, loss is 0.004762440919876099\n",
      "epoch: 10 step: 983, loss is 0.0001867965329438448\n",
      "epoch: 10 step: 984, loss is 0.00023407000117003918\n",
      "epoch: 10 step: 985, loss is 0.00028413013205863535\n",
      "epoch: 10 step: 986, loss is 0.0028182046953588724\n",
      "epoch: 10 step: 987, loss is 0.05483643338084221\n",
      "epoch: 10 step: 988, loss is 2.9802749850205146e-06\n",
      "epoch: 10 step: 989, loss is 3.550780093064532e-05\n",
      "epoch: 10 step: 990, loss is 0.013707014732062817\n",
      "epoch: 10 step: 991, loss is 0.012548086233437061\n",
      "epoch: 10 step: 992, loss is 0.0011912626214325428\n",
      "epoch: 10 step: 993, loss is 0.024025827646255493\n",
      "epoch: 10 step: 994, loss is 0.00011202444147784263\n",
      "epoch: 10 step: 995, loss is 0.001723618246614933\n",
      "epoch: 10 step: 996, loss is 0.0152336610481143\n",
      "epoch: 10 step: 997, loss is 0.09815289080142975\n",
      "epoch: 10 step: 998, loss is 0.0009700896916911006\n",
      "epoch: 10 step: 999, loss is 0.004945291671901941\n",
      "epoch: 10 step: 1000, loss is 8.20790883153677e-05\n",
      "epoch: 10 step: 1001, loss is 1.4894774722051807e-05\n",
      "epoch: 10 step: 1002, loss is 0.0003399053239263594\n",
      "epoch: 10 step: 1003, loss is 0.0005461527034640312\n",
      "epoch: 10 step: 1004, loss is 0.0013686779420822859\n",
      "epoch: 10 step: 1005, loss is 0.0023002622183412313\n",
      "epoch: 10 step: 1006, loss is 0.003220345126464963\n",
      "epoch: 10 step: 1007, loss is 0.1570938676595688\n",
      "epoch: 10 step: 1008, loss is 0.037483394145965576\n",
      "epoch: 10 step: 1009, loss is 0.0010179639793932438\n",
      "epoch: 10 step: 1010, loss is 0.10824514180421829\n",
      "epoch: 10 step: 1011, loss is 5.450236130855046e-06\n",
      "epoch: 10 step: 1012, loss is 0.07105785608291626\n",
      "epoch: 10 step: 1013, loss is 0.0016975286416709423\n",
      "epoch: 10 step: 1014, loss is 0.0005584295722655952\n",
      "epoch: 10 step: 1015, loss is 0.0008148974739015102\n",
      "epoch: 10 step: 1016, loss is 1.5707160855527036e-05\n",
      "epoch: 10 step: 1017, loss is 6.391446368070319e-05\n",
      "epoch: 10 step: 1018, loss is 9.398612746736035e-05\n",
      "epoch: 10 step: 1019, loss is 0.0001364864583592862\n",
      "epoch: 10 step: 1020, loss is 0.07786556333303452\n",
      "epoch: 10 step: 1021, loss is 0.0017764228396117687\n",
      "epoch: 10 step: 1022, loss is 0.03990626707673073\n",
      "epoch: 10 step: 1023, loss is 2.3372505893348716e-05\n",
      "epoch: 10 step: 1024, loss is 0.00046902697067707777\n",
      "epoch: 10 step: 1025, loss is 0.10167843103408813\n",
      "epoch: 10 step: 1026, loss is 2.6430381694808602e-05\n",
      "epoch: 10 step: 1027, loss is 0.0007064082310535014\n",
      "epoch: 10 step: 1028, loss is 0.0004781642637681216\n",
      "epoch: 10 step: 1029, loss is 0.0015113957924768329\n",
      "epoch: 10 step: 1030, loss is 0.00496888579800725\n",
      "epoch: 10 step: 1031, loss is 0.0029688943177461624\n",
      "epoch: 10 step: 1032, loss is 0.19328679144382477\n",
      "epoch: 10 step: 1033, loss is 1.875155976449605e-05\n",
      "epoch: 10 step: 1034, loss is 8.022162364795804e-05\n",
      "epoch: 10 step: 1035, loss is 0.0002717664756346494\n",
      "epoch: 10 step: 1036, loss is 0.010495330207049847\n",
      "epoch: 10 step: 1037, loss is 0.0014547428581863642\n",
      "epoch: 10 step: 1038, loss is 0.02862977609038353\n",
      "epoch: 10 step: 1039, loss is 0.03480125591158867\n",
      "epoch: 10 step: 1040, loss is 1.9070688722422346e-05\n",
      "epoch: 10 step: 1041, loss is 0.006607959046959877\n",
      "epoch: 10 step: 1042, loss is 0.011089613661170006\n",
      "epoch: 10 step: 1043, loss is 0.0647154450416565\n",
      "epoch: 10 step: 1044, loss is 0.0008131162030622363\n",
      "epoch: 10 step: 1045, loss is 0.0022748929914087057\n",
      "epoch: 10 step: 1046, loss is 0.0001766821078490466\n",
      "epoch: 10 step: 1047, loss is 0.000377264223061502\n",
      "epoch: 10 step: 1048, loss is 0.0010010343976318836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1049, loss is 0.10969392210245132\n",
      "epoch: 10 step: 1050, loss is 0.0007235197117552161\n",
      "epoch: 10 step: 1051, loss is 0.0005572580266743898\n",
      "epoch: 10 step: 1052, loss is 0.01153044868260622\n",
      "epoch: 10 step: 1053, loss is 0.0680682584643364\n",
      "epoch: 10 step: 1054, loss is 0.004924796521663666\n",
      "epoch: 10 step: 1055, loss is 0.022043976932764053\n",
      "epoch: 10 step: 1056, loss is 0.03468145802617073\n",
      "epoch: 10 step: 1057, loss is 0.02840454690158367\n",
      "epoch: 10 step: 1058, loss is 0.02420753799378872\n",
      "epoch: 10 step: 1059, loss is 0.0002879386011045426\n",
      "epoch: 10 step: 1060, loss is 0.21812160313129425\n",
      "epoch: 10 step: 1061, loss is 8.855434316501487e-06\n",
      "epoch: 10 step: 1062, loss is 0.011088079772889614\n",
      "epoch: 10 step: 1063, loss is 0.0006230014842003584\n",
      "epoch: 10 step: 1064, loss is 0.0004975590854883194\n",
      "epoch: 10 step: 1065, loss is 0.02391458861529827\n",
      "epoch: 10 step: 1066, loss is 0.0027042091824114323\n",
      "epoch: 10 step: 1067, loss is 0.002325627254322171\n",
      "epoch: 10 step: 1068, loss is 0.06197189912199974\n",
      "epoch: 10 step: 1069, loss is 0.06168191879987717\n",
      "epoch: 10 step: 1070, loss is 0.0011431029997766018\n",
      "epoch: 10 step: 1071, loss is 0.08060596883296967\n",
      "epoch: 10 step: 1072, loss is 0.03633034974336624\n",
      "epoch: 10 step: 1073, loss is 0.0063506243750452995\n",
      "epoch: 10 step: 1074, loss is 0.0014135631499812007\n",
      "epoch: 10 step: 1075, loss is 0.004754981957376003\n",
      "epoch: 10 step: 1076, loss is 0.005443425849080086\n",
      "epoch: 10 step: 1077, loss is 0.00019435871217865497\n",
      "epoch: 10 step: 1078, loss is 0.00028753135120496154\n",
      "epoch: 10 step: 1079, loss is 6.346695590764284e-05\n",
      "epoch: 10 step: 1080, loss is 0.0008258933085016906\n",
      "epoch: 10 step: 1081, loss is 0.00010727976768976077\n",
      "epoch: 10 step: 1082, loss is 0.01226518303155899\n",
      "epoch: 10 step: 1083, loss is 0.016902072355151176\n",
      "epoch: 10 step: 1084, loss is 0.22677971422672272\n",
      "epoch: 10 step: 1085, loss is 0.0004934176104143262\n",
      "epoch: 10 step: 1086, loss is 7.407514203805476e-05\n",
      "epoch: 10 step: 1087, loss is 0.0040947855450212955\n",
      "epoch: 10 step: 1088, loss is 0.0003572024579625577\n",
      "epoch: 10 step: 1089, loss is 0.002687104046344757\n",
      "epoch: 10 step: 1090, loss is 0.051525410264730453\n",
      "epoch: 10 step: 1091, loss is 0.00039301946526393294\n",
      "epoch: 10 step: 1092, loss is 0.0031942485366016626\n",
      "epoch: 10 step: 1093, loss is 0.0004883522051386535\n",
      "epoch: 10 step: 1094, loss is 0.0002032379270531237\n",
      "epoch: 10 step: 1095, loss is 0.0031059239991009235\n",
      "epoch: 10 step: 1096, loss is 0.007532364688813686\n",
      "epoch: 10 step: 1097, loss is 0.017640771344304085\n",
      "epoch: 10 step: 1098, loss is 0.013904466293752193\n",
      "epoch: 10 step: 1099, loss is 0.014309200458228588\n",
      "epoch: 10 step: 1100, loss is 0.0005839779623784125\n",
      "epoch: 10 step: 1101, loss is 0.00010462837235536426\n",
      "epoch: 10 step: 1102, loss is 0.018581535667181015\n",
      "epoch: 10 step: 1103, loss is 0.0027084876783192158\n",
      "epoch: 10 step: 1104, loss is 0.00010748295608209446\n",
      "epoch: 10 step: 1105, loss is 0.013106973841786385\n",
      "epoch: 10 step: 1106, loss is 8.378548045584466e-06\n",
      "epoch: 10 step: 1107, loss is 0.0005488556926138699\n",
      "epoch: 10 step: 1108, loss is 0.00015941853052936494\n",
      "epoch: 10 step: 1109, loss is 0.007230232935398817\n",
      "epoch: 10 step: 1110, loss is 4.688032640842721e-05\n",
      "epoch: 10 step: 1111, loss is 2.657551522133872e-05\n",
      "epoch: 10 step: 1112, loss is 0.013657988049089909\n",
      "epoch: 10 step: 1113, loss is 0.0016422206535935402\n",
      "epoch: 10 step: 1114, loss is 0.0005299224285408854\n",
      "epoch: 10 step: 1115, loss is 0.051838044077157974\n",
      "epoch: 10 step: 1116, loss is 0.017925212159752846\n",
      "epoch: 10 step: 1117, loss is 0.015165436081588268\n",
      "epoch: 10 step: 1118, loss is 0.0005999548593536019\n",
      "epoch: 10 step: 1119, loss is 0.004895630292594433\n",
      "epoch: 10 step: 1120, loss is 0.013057507574558258\n",
      "epoch: 10 step: 1121, loss is 2.3328788302023895e-05\n",
      "epoch: 10 step: 1122, loss is 0.0014926977455615997\n",
      "epoch: 10 step: 1123, loss is 0.02978554554283619\n",
      "epoch: 10 step: 1124, loss is 5.8592653658706695e-05\n",
      "epoch: 10 step: 1125, loss is 0.0001944040704984218\n",
      "epoch: 10 step: 1126, loss is 0.0006473196553997695\n",
      "epoch: 10 step: 1127, loss is 0.004021218977868557\n",
      "epoch: 10 step: 1128, loss is 7.546997221652418e-05\n",
      "epoch: 10 step: 1129, loss is 0.004936781246215105\n",
      "epoch: 10 step: 1130, loss is 0.005973829887807369\n",
      "epoch: 10 step: 1131, loss is 0.0002413188194623217\n",
      "epoch: 10 step: 1132, loss is 0.00047121598618105054\n",
      "epoch: 10 step: 1133, loss is 0.0013658079551532865\n",
      "epoch: 10 step: 1134, loss is 0.0002255777653772384\n",
      "epoch: 10 step: 1135, loss is 0.00035053250030614436\n",
      "epoch: 10 step: 1136, loss is 9.591019625077024e-05\n",
      "epoch: 10 step: 1137, loss is 0.000208631856366992\n",
      "epoch: 10 step: 1138, loss is 0.0009430642821826041\n",
      "epoch: 10 step: 1139, loss is 0.00019249218166805804\n",
      "epoch: 10 step: 1140, loss is 0.0790531188249588\n",
      "epoch: 10 step: 1141, loss is 0.030247148126363754\n",
      "epoch: 10 step: 1142, loss is 0.0012757796794176102\n",
      "epoch: 10 step: 1143, loss is 0.016417186707258224\n",
      "epoch: 10 step: 1144, loss is 0.00044949937728233635\n",
      "epoch: 10 step: 1145, loss is 0.00016694405348971486\n",
      "epoch: 10 step: 1146, loss is 0.013183465227484703\n",
      "epoch: 10 step: 1147, loss is 7.1266367740463465e-06\n",
      "epoch: 10 step: 1148, loss is 0.11379393935203552\n",
      "epoch: 10 step: 1149, loss is 0.005937774665653706\n",
      "epoch: 10 step: 1150, loss is 0.0029750228859484196\n",
      "epoch: 10 step: 1151, loss is 0.02019045688211918\n",
      "epoch: 10 step: 1152, loss is 0.00013619023957289755\n",
      "epoch: 10 step: 1153, loss is 0.0002521146088838577\n",
      "epoch: 10 step: 1154, loss is 1.0449904948472977e-05\n",
      "epoch: 10 step: 1155, loss is 0.0021903221495449543\n",
      "epoch: 10 step: 1156, loss is 0.0019558838102966547\n",
      "epoch: 10 step: 1157, loss is 0.00011758889013435692\n",
      "epoch: 10 step: 1158, loss is 0.12144786864519119\n",
      "epoch: 10 step: 1159, loss is 5.430742749013007e-05\n",
      "epoch: 10 step: 1160, loss is 0.043845802545547485\n",
      "epoch: 10 step: 1161, loss is 0.0016726866597309709\n",
      "epoch: 10 step: 1162, loss is 0.006070660427212715\n",
      "epoch: 10 step: 1163, loss is 0.0006424775347113609\n",
      "epoch: 10 step: 1164, loss is 0.002401202218607068\n",
      "epoch: 10 step: 1165, loss is 5.544393934542313e-05\n",
      "epoch: 10 step: 1166, loss is 0.00011446897406131029\n",
      "epoch: 10 step: 1167, loss is 0.009667610749602318\n",
      "epoch: 10 step: 1168, loss is 0.0001021005300572142\n",
      "epoch: 10 step: 1169, loss is 0.005514376796782017\n",
      "epoch: 10 step: 1170, loss is 0.0007736116531305015\n",
      "epoch: 10 step: 1171, loss is 0.01450332161039114\n",
      "epoch: 10 step: 1172, loss is 3.571168417693116e-05\n",
      "epoch: 10 step: 1173, loss is 0.0004761441086884588\n",
      "epoch: 10 step: 1174, loss is 0.03970637544989586\n",
      "epoch: 10 step: 1175, loss is 0.003908404149115086\n",
      "epoch: 10 step: 1176, loss is 0.00255223480053246\n",
      "epoch: 10 step: 1177, loss is 0.00011519029794726521\n",
      "epoch: 10 step: 1178, loss is 7.1515234594699e-05\n",
      "epoch: 10 step: 1179, loss is 0.007485221605747938\n",
      "epoch: 10 step: 1180, loss is 0.002509176265448332\n",
      "epoch: 10 step: 1181, loss is 0.0006141571793705225\n",
      "epoch: 10 step: 1182, loss is 0.019691547378897667\n",
      "epoch: 10 step: 1183, loss is 8.491403423249722e-05\n",
      "epoch: 10 step: 1184, loss is 0.0005974494270049036\n",
      "epoch: 10 step: 1185, loss is 0.0003776188241317868\n",
      "epoch: 10 step: 1186, loss is 0.0002500051923561841\n",
      "epoch: 10 step: 1187, loss is 0.00037662251270376146\n",
      "epoch: 10 step: 1188, loss is 0.034736718982458115\n",
      "epoch: 10 step: 1189, loss is 0.0013643632410094142\n",
      "epoch: 10 step: 1190, loss is 0.0015474045649170876\n",
      "epoch: 10 step: 1191, loss is 7.04050762578845e-05\n",
      "epoch: 10 step: 1192, loss is 0.0037189151626080275\n",
      "epoch: 10 step: 1193, loss is 0.00010110539733432233\n",
      "epoch: 10 step: 1194, loss is 0.0028805197216570377\n",
      "epoch: 10 step: 1195, loss is 3.5655320971272886e-05\n",
      "epoch: 10 step: 1196, loss is 0.00011734729196177796\n",
      "epoch: 10 step: 1197, loss is 0.001858821022324264\n",
      "epoch: 10 step: 1198, loss is 0.03160787746310234\n",
      "epoch: 10 step: 1199, loss is 6.357301026582718e-05\n",
      "epoch: 10 step: 1200, loss is 7.258768891915679e-05\n",
      "epoch: 10 step: 1201, loss is 0.029820235446095467\n",
      "epoch: 10 step: 1202, loss is 0.0006639872444793582\n",
      "epoch: 10 step: 1203, loss is 0.0033787309657782316\n",
      "epoch: 10 step: 1204, loss is 4.313996214477811e-06\n",
      "epoch: 10 step: 1205, loss is 9.615599265089259e-05\n",
      "epoch: 10 step: 1206, loss is 0.0017669547814875841\n",
      "epoch: 10 step: 1207, loss is 7.385200296994299e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1208, loss is 6.6225795308128e-05\n",
      "epoch: 10 step: 1209, loss is 0.00491706607863307\n",
      "epoch: 10 step: 1210, loss is 0.003535084193572402\n",
      "epoch: 10 step: 1211, loss is 0.0011875084601342678\n",
      "epoch: 10 step: 1212, loss is 0.015207411721348763\n",
      "epoch: 10 step: 1213, loss is 0.0027520067524164915\n",
      "epoch: 10 step: 1214, loss is 2.331384166609496e-05\n",
      "epoch: 10 step: 1215, loss is 0.024176474660634995\n",
      "epoch: 10 step: 1216, loss is 0.011123891919851303\n",
      "epoch: 10 step: 1217, loss is 0.019116198644042015\n",
      "epoch: 10 step: 1218, loss is 0.003445891197770834\n",
      "epoch: 10 step: 1219, loss is 0.008663669228553772\n",
      "epoch: 10 step: 1220, loss is 0.007500713225454092\n",
      "epoch: 10 step: 1221, loss is 0.012926178053021431\n",
      "epoch: 10 step: 1222, loss is 7.735580584267154e-05\n",
      "epoch: 10 step: 1223, loss is 0.0009412862709723413\n",
      "epoch: 10 step: 1224, loss is 1.3324181963980664e-05\n",
      "epoch: 10 step: 1225, loss is 2.8743839720846154e-05\n",
      "epoch: 10 step: 1226, loss is 0.050329916179180145\n",
      "epoch: 10 step: 1227, loss is 0.007513826712965965\n",
      "epoch: 10 step: 1228, loss is 6.741394827258773e-06\n",
      "epoch: 10 step: 1229, loss is 2.0340237369964598e-06\n",
      "epoch: 10 step: 1230, loss is 0.0008176035480573773\n",
      "epoch: 10 step: 1231, loss is 0.00026691326638683677\n",
      "epoch: 10 step: 1232, loss is 0.0008785813115537167\n",
      "epoch: 10 step: 1233, loss is 0.00014908348384778947\n",
      "epoch: 10 step: 1234, loss is 0.009895379655063152\n",
      "epoch: 10 step: 1235, loss is 0.00013255540397949517\n",
      "epoch: 10 step: 1236, loss is 0.0001532723690615967\n",
      "epoch: 10 step: 1237, loss is 0.025875717401504517\n",
      "epoch: 10 step: 1238, loss is 6.890390795888379e-05\n",
      "epoch: 10 step: 1239, loss is 0.0009218741906806827\n",
      "epoch: 10 step: 1240, loss is 0.0001678246189840138\n",
      "epoch: 10 step: 1241, loss is 2.5101693609030917e-05\n",
      "epoch: 10 step: 1242, loss is 0.0005663480842486024\n",
      "epoch: 10 step: 1243, loss is 0.00028809005743823946\n",
      "epoch: 10 step: 1244, loss is 0.00014496674702968448\n",
      "epoch: 10 step: 1245, loss is 0.03409566730260849\n",
      "epoch: 10 step: 1246, loss is 0.0832175686955452\n",
      "epoch: 10 step: 1247, loss is 8.99906808626838e-06\n",
      "epoch: 10 step: 1248, loss is 1.6093433714559069e-06\n",
      "epoch: 10 step: 1249, loss is 0.00011194733087904751\n",
      "epoch: 10 step: 1250, loss is 0.08255007863044739\n",
      "epoch: 10 step: 1251, loss is 7.387561709037982e-06\n",
      "epoch: 10 step: 1252, loss is 0.00010107438720297068\n",
      "epoch: 10 step: 1253, loss is 7.665316843485925e-06\n",
      "epoch: 10 step: 1254, loss is 0.007884264923632145\n",
      "epoch: 10 step: 1255, loss is 0.00799578707665205\n",
      "epoch: 10 step: 1256, loss is 0.0007160863024182618\n",
      "epoch: 10 step: 1257, loss is 0.1567590981721878\n",
      "epoch: 10 step: 1258, loss is 7.244209700729698e-05\n",
      "epoch: 10 step: 1259, loss is 0.13602498173713684\n",
      "epoch: 10 step: 1260, loss is 0.0007743420428596437\n",
      "epoch: 10 step: 1261, loss is 0.0038883250672370195\n",
      "epoch: 10 step: 1262, loss is 0.008050267584621906\n",
      "epoch: 10 step: 1263, loss is 0.0008364699315279722\n",
      "epoch: 10 step: 1264, loss is 0.003152853576466441\n",
      "epoch: 10 step: 1265, loss is 4.8259160394081846e-05\n",
      "epoch: 10 step: 1266, loss is 0.0010157416108995676\n",
      "epoch: 10 step: 1267, loss is 0.0007277987897396088\n",
      "epoch: 10 step: 1268, loss is 4.190137406112626e-05\n",
      "epoch: 10 step: 1269, loss is 0.0005597815033979714\n",
      "epoch: 10 step: 1270, loss is 0.003569019492715597\n",
      "epoch: 10 step: 1271, loss is 0.0016819508746266365\n",
      "epoch: 10 step: 1272, loss is 0.28095743060112\n",
      "epoch: 10 step: 1273, loss is 0.0025764501187950373\n",
      "epoch: 10 step: 1274, loss is 0.0018408478936180472\n",
      "epoch: 10 step: 1275, loss is 0.07504037767648697\n",
      "epoch: 10 step: 1276, loss is 9.720722300698981e-05\n",
      "epoch: 10 step: 1277, loss is 0.00023731229885015637\n",
      "epoch: 10 step: 1278, loss is 0.0013503460213541985\n",
      "epoch: 10 step: 1279, loss is 0.001179325394332409\n",
      "epoch: 10 step: 1280, loss is 0.008501187898218632\n",
      "epoch: 10 step: 1281, loss is 1.9422168406890705e-05\n",
      "epoch: 10 step: 1282, loss is 0.00038190363557077944\n",
      "epoch: 10 step: 1283, loss is 4.0322443965123966e-05\n",
      "epoch: 10 step: 1284, loss is 0.001752148033119738\n",
      "epoch: 10 step: 1285, loss is 4.3096504668937996e-05\n",
      "epoch: 10 step: 1286, loss is 0.013762760907411575\n",
      "epoch: 10 step: 1287, loss is 0.0019205338321626186\n",
      "epoch: 10 step: 1288, loss is 0.0008897773222997785\n",
      "epoch: 10 step: 1289, loss is 0.0014214377151802182\n",
      "epoch: 10 step: 1290, loss is 0.005012382287532091\n",
      "epoch: 10 step: 1291, loss is 5.721033085137606e-05\n",
      "epoch: 10 step: 1292, loss is 0.0006272458704188466\n",
      "epoch: 10 step: 1293, loss is 0.0018910829676315188\n",
      "epoch: 10 step: 1294, loss is 0.002866622991859913\n",
      "epoch: 10 step: 1295, loss is 0.0005222390755079687\n",
      "epoch: 10 step: 1296, loss is 0.00019602464453782886\n",
      "epoch: 10 step: 1297, loss is 0.0032776270527392626\n",
      "epoch: 10 step: 1298, loss is 0.02888006903231144\n",
      "epoch: 10 step: 1299, loss is 0.0024830601178109646\n",
      "epoch: 10 step: 1300, loss is 0.00859204400330782\n",
      "epoch: 10 step: 1301, loss is 0.005594860762357712\n",
      "epoch: 10 step: 1302, loss is 0.0027454884257167578\n",
      "epoch: 10 step: 1303, loss is 7.044161611702293e-05\n",
      "epoch: 10 step: 1304, loss is 0.0002705650113057345\n",
      "epoch: 10 step: 1305, loss is 4.642163548851386e-05\n",
      "epoch: 10 step: 1306, loss is 0.018262920901179314\n",
      "epoch: 10 step: 1307, loss is 0.02207723632454872\n",
      "epoch: 10 step: 1308, loss is 0.00031205109553411603\n",
      "epoch: 10 step: 1309, loss is 0.0013677437091246247\n",
      "epoch: 10 step: 1310, loss is 0.0002591513912193477\n",
      "epoch: 10 step: 1311, loss is 0.011157050728797913\n",
      "epoch: 10 step: 1312, loss is 0.00013522592780645937\n",
      "epoch: 10 step: 1313, loss is 2.2579453798243776e-05\n",
      "epoch: 10 step: 1314, loss is 9.423879237147048e-05\n",
      "epoch: 10 step: 1315, loss is 0.017848916351795197\n",
      "epoch: 10 step: 1316, loss is 0.004874501843005419\n",
      "epoch: 10 step: 1317, loss is 0.0008351041469722986\n",
      "epoch: 10 step: 1318, loss is 6.651593139395118e-05\n",
      "epoch: 10 step: 1319, loss is 2.608683644211851e-05\n",
      "epoch: 10 step: 1320, loss is 0.0001805715583031997\n",
      "epoch: 10 step: 1321, loss is 0.0003158437320962548\n",
      "epoch: 10 step: 1322, loss is 0.00027327839052304626\n",
      "epoch: 10 step: 1323, loss is 0.00012894503015559167\n",
      "epoch: 10 step: 1324, loss is 2.5740750061231665e-05\n",
      "epoch: 10 step: 1325, loss is 0.024693796411156654\n",
      "epoch: 10 step: 1326, loss is 0.0017810227582231164\n",
      "epoch: 10 step: 1327, loss is 0.000792773615103215\n",
      "epoch: 10 step: 1328, loss is 2.9613009246531874e-05\n",
      "epoch: 10 step: 1329, loss is 1.5270943549694493e-05\n",
      "epoch: 10 step: 1330, loss is 0.0013045505620539188\n",
      "epoch: 10 step: 1331, loss is 0.00015840354899410158\n",
      "epoch: 10 step: 1332, loss is 0.0031996467150747776\n",
      "epoch: 10 step: 1333, loss is 0.000692053057719022\n",
      "epoch: 10 step: 1334, loss is 0.0019247772870585322\n",
      "epoch: 10 step: 1335, loss is 0.0004912381991744041\n",
      "epoch: 10 step: 1336, loss is 0.0021448677871376276\n",
      "epoch: 10 step: 1337, loss is 0.006643026601523161\n",
      "epoch: 10 step: 1338, loss is 0.12901140749454498\n",
      "epoch: 10 step: 1339, loss is 0.004735929425805807\n",
      "epoch: 10 step: 1340, loss is 0.0023748839739710093\n",
      "epoch: 10 step: 1341, loss is 0.008814235217869282\n",
      "epoch: 10 step: 1342, loss is 0.0025819202419370413\n",
      "epoch: 10 step: 1343, loss is 0.0011354215675964952\n",
      "epoch: 10 step: 1344, loss is 0.0005976626998744905\n",
      "epoch: 10 step: 1345, loss is 0.002214249921962619\n",
      "epoch: 10 step: 1346, loss is 0.01810692809522152\n",
      "epoch: 10 step: 1347, loss is 0.0008490084437653422\n",
      "epoch: 10 step: 1348, loss is 0.007572379894554615\n",
      "epoch: 10 step: 1349, loss is 8.762334618950263e-05\n",
      "epoch: 10 step: 1350, loss is 0.0016409722156822681\n",
      "epoch: 10 step: 1351, loss is 0.0010041426867246628\n",
      "epoch: 10 step: 1352, loss is 0.0005221884930506349\n",
      "epoch: 10 step: 1353, loss is 6.512483378173783e-05\n",
      "epoch: 10 step: 1354, loss is 0.008886704221367836\n",
      "epoch: 10 step: 1355, loss is 0.0006924016634002328\n",
      "epoch: 10 step: 1356, loss is 0.0018012977670878172\n",
      "epoch: 10 step: 1357, loss is 0.0002759911585599184\n",
      "epoch: 10 step: 1358, loss is 0.00032709940569475293\n",
      "epoch: 10 step: 1359, loss is 0.022604167461395264\n",
      "epoch: 10 step: 1360, loss is 0.0069855279289186\n",
      "epoch: 10 step: 1361, loss is 0.001050640014000237\n",
      "epoch: 10 step: 1362, loss is 1.2839203918701969e-05\n",
      "epoch: 10 step: 1363, loss is 0.010378565639257431\n",
      "epoch: 10 step: 1364, loss is 0.00011880796955665573\n",
      "epoch: 10 step: 1365, loss is 0.019590415060520172\n",
      "epoch: 10 step: 1366, loss is 0.057403214275836945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1367, loss is 4.9702390242600814e-05\n",
      "epoch: 10 step: 1368, loss is 1.5690504369558766e-05\n",
      "epoch: 10 step: 1369, loss is 0.0009788982570171356\n",
      "epoch: 10 step: 1370, loss is 6.788974133087322e-05\n",
      "epoch: 10 step: 1371, loss is 6.6535326368466485e-06\n",
      "epoch: 10 step: 1372, loss is 0.0004239005211275071\n",
      "epoch: 10 step: 1373, loss is 8.62666274770163e-06\n",
      "epoch: 10 step: 1374, loss is 0.00019878278544638306\n",
      "epoch: 10 step: 1375, loss is 0.00020712851255666465\n",
      "epoch: 10 step: 1376, loss is 0.0002265425428049639\n",
      "epoch: 10 step: 1377, loss is 0.0529501810669899\n",
      "epoch: 10 step: 1378, loss is 3.479249789961614e-05\n",
      "epoch: 10 step: 1379, loss is 0.0015939070144668221\n",
      "epoch: 10 step: 1380, loss is 1.3430188118945807e-05\n",
      "epoch: 10 step: 1381, loss is 0.0003208088455721736\n",
      "epoch: 10 step: 1382, loss is 2.0681132809841074e-05\n",
      "epoch: 10 step: 1383, loss is 0.00023803900694474578\n",
      "epoch: 10 step: 1384, loss is 0.0007078100461512804\n",
      "epoch: 10 step: 1385, loss is 0.00016332608356606215\n",
      "epoch: 10 step: 1386, loss is 0.005051241721957922\n",
      "epoch: 10 step: 1387, loss is 0.03401385247707367\n",
      "epoch: 10 step: 1388, loss is 0.009207085706293583\n",
      "epoch: 10 step: 1389, loss is 0.0015570319956168532\n",
      "epoch: 10 step: 1390, loss is 0.003431136254221201\n",
      "epoch: 10 step: 1391, loss is 0.00361144682392478\n",
      "epoch: 10 step: 1392, loss is 6.314546226349194e-06\n",
      "epoch: 10 step: 1393, loss is 0.00015810009790584445\n",
      "epoch: 10 step: 1394, loss is 0.0016188231529667974\n",
      "epoch: 10 step: 1395, loss is 0.0007432708516716957\n",
      "epoch: 10 step: 1396, loss is 0.00014446025306824595\n",
      "epoch: 10 step: 1397, loss is 0.0003542961203493178\n",
      "epoch: 10 step: 1398, loss is 0.04705182835459709\n",
      "epoch: 10 step: 1399, loss is 0.08034399151802063\n",
      "epoch: 10 step: 1400, loss is 0.0027808123268187046\n",
      "epoch: 10 step: 1401, loss is 0.006634783465415239\n",
      "epoch: 10 step: 1402, loss is 7.082028332661139e-06\n",
      "epoch: 10 step: 1403, loss is 0.014699991792440414\n",
      "epoch: 10 step: 1404, loss is 0.004096871241927147\n",
      "epoch: 10 step: 1405, loss is 0.003050665371119976\n",
      "epoch: 10 step: 1406, loss is 2.7723675884772092e-05\n",
      "epoch: 10 step: 1407, loss is 0.0002505438751541078\n",
      "epoch: 10 step: 1408, loss is 0.001883133314549923\n",
      "epoch: 10 step: 1409, loss is 0.00013257133832667023\n",
      "epoch: 10 step: 1410, loss is 0.09875089675188065\n",
      "epoch: 10 step: 1411, loss is 0.004785039462149143\n",
      "epoch: 10 step: 1412, loss is 0.010605956427752972\n",
      "epoch: 10 step: 1413, loss is 0.008729130029678345\n",
      "epoch: 10 step: 1414, loss is 0.01571262814104557\n",
      "epoch: 10 step: 1415, loss is 0.002071811817586422\n",
      "epoch: 10 step: 1416, loss is 0.0001732692908262834\n",
      "epoch: 10 step: 1417, loss is 0.0006255778134800494\n",
      "epoch: 10 step: 1418, loss is 4.218639514874667e-05\n",
      "epoch: 10 step: 1419, loss is 0.00010132860188605264\n",
      "epoch: 10 step: 1420, loss is 7.478461338905618e-05\n",
      "epoch: 10 step: 1421, loss is 0.003521307371556759\n",
      "epoch: 10 step: 1422, loss is 0.07100223004817963\n",
      "epoch: 10 step: 1423, loss is 4.1501207306282595e-06\n",
      "epoch: 10 step: 1424, loss is 0.00010508575360290706\n",
      "epoch: 10 step: 1425, loss is 0.0013566665584221482\n",
      "epoch: 10 step: 1426, loss is 7.904678204795346e-05\n",
      "epoch: 10 step: 1427, loss is 8.519332186551765e-05\n",
      "epoch: 10 step: 1428, loss is 0.0014104024739935994\n",
      "epoch: 10 step: 1429, loss is 0.023559458553791046\n",
      "epoch: 10 step: 1430, loss is 4.659637852455489e-05\n",
      "epoch: 10 step: 1431, loss is 0.07884698361158371\n",
      "epoch: 10 step: 1432, loss is 0.007915861904621124\n",
      "epoch: 10 step: 1433, loss is 0.029515929520130157\n",
      "epoch: 10 step: 1434, loss is 0.0004157188523095101\n",
      "epoch: 10 step: 1435, loss is 0.0008105478482320905\n",
      "epoch: 10 step: 1436, loss is 6.994587602093816e-05\n",
      "epoch: 10 step: 1437, loss is 0.0009383535943925381\n",
      "epoch: 10 step: 1438, loss is 0.03759974241256714\n",
      "epoch: 10 step: 1439, loss is 4.699097917182371e-05\n",
      "epoch: 10 step: 1440, loss is 0.003523849416524172\n",
      "epoch: 10 step: 1441, loss is 0.0008331267163157463\n",
      "epoch: 10 step: 1442, loss is 2.1346204448491335e-06\n",
      "epoch: 10 step: 1443, loss is 5.7259449022240005e-06\n",
      "epoch: 10 step: 1444, loss is 0.00023226179473567754\n",
      "epoch: 10 step: 1445, loss is 7.146662392187864e-05\n",
      "epoch: 10 step: 1446, loss is 0.0018384017748758197\n",
      "epoch: 10 step: 1447, loss is 0.004965055268257856\n",
      "epoch: 10 step: 1448, loss is 0.010257352143526077\n",
      "epoch: 10 step: 1449, loss is 0.020469117909669876\n",
      "epoch: 10 step: 1450, loss is 9.193192090606317e-05\n",
      "epoch: 10 step: 1451, loss is 2.5863631890388206e-05\n",
      "epoch: 10 step: 1452, loss is 0.011376198381185532\n",
      "epoch: 10 step: 1453, loss is 8.103789150482044e-05\n",
      "epoch: 10 step: 1454, loss is 0.00023583599249832332\n",
      "epoch: 10 step: 1455, loss is 0.18450742959976196\n",
      "epoch: 10 step: 1456, loss is 6.542021765199024e-06\n",
      "epoch: 10 step: 1457, loss is 1.613355561858043e-05\n",
      "epoch: 10 step: 1458, loss is 0.000311731273541227\n",
      "epoch: 10 step: 1459, loss is 0.001141812070272863\n",
      "epoch: 10 step: 1460, loss is 6.593943453481188e-06\n",
      "epoch: 10 step: 1461, loss is 0.0016331890365108848\n",
      "epoch: 10 step: 1462, loss is 0.01989789679646492\n",
      "epoch: 10 step: 1463, loss is 0.00018472844385541975\n",
      "epoch: 10 step: 1464, loss is 0.0023524214047938585\n",
      "epoch: 10 step: 1465, loss is 0.00734091317281127\n",
      "epoch: 10 step: 1466, loss is 0.0014685670612379909\n",
      "epoch: 10 step: 1467, loss is 0.03754013776779175\n",
      "epoch: 10 step: 1468, loss is 0.025841882452368736\n",
      "epoch: 10 step: 1469, loss is 0.00018460875435266644\n",
      "epoch: 10 step: 1470, loss is 0.055757295340299606\n",
      "epoch: 10 step: 1471, loss is 0.0001476225588703528\n",
      "epoch: 10 step: 1472, loss is 0.06097061559557915\n",
      "epoch: 10 step: 1473, loss is 0.00045704757212661207\n",
      "epoch: 10 step: 1474, loss is 0.00026227813214063644\n",
      "epoch: 10 step: 1475, loss is 0.0013185564894229174\n",
      "epoch: 10 step: 1476, loss is 8.131394861266017e-05\n",
      "epoch: 10 step: 1477, loss is 0.002158745424821973\n",
      "epoch: 10 step: 1478, loss is 0.04641349986195564\n",
      "epoch: 10 step: 1479, loss is 0.0016884950455278158\n",
      "epoch: 10 step: 1480, loss is 0.0004543208924587816\n",
      "epoch: 10 step: 1481, loss is 0.00011328692198731005\n",
      "epoch: 10 step: 1482, loss is 0.0002344988752156496\n",
      "epoch: 10 step: 1483, loss is 0.0011365738464519382\n",
      "epoch: 10 step: 1484, loss is 0.11998098343610764\n",
      "epoch: 10 step: 1485, loss is 0.000842006818857044\n",
      "epoch: 10 step: 1486, loss is 1.079100911738351e-05\n",
      "epoch: 10 step: 1487, loss is 0.00015455632819794118\n",
      "epoch: 10 step: 1488, loss is 0.035641781985759735\n",
      "epoch: 10 step: 1489, loss is 0.15288986265659332\n",
      "epoch: 10 step: 1490, loss is 0.0008924009744077921\n",
      "epoch: 10 step: 1491, loss is 0.034922029823064804\n",
      "epoch: 10 step: 1492, loss is 0.000837935833260417\n",
      "epoch: 10 step: 1493, loss is 0.0058540282770991325\n",
      "epoch: 10 step: 1494, loss is 1.5250399883370847e-05\n",
      "epoch: 10 step: 1495, loss is 0.0027099577710032463\n",
      "epoch: 10 step: 1496, loss is 0.0017367781838402152\n",
      "epoch: 10 step: 1497, loss is 0.06297298520803452\n",
      "epoch: 10 step: 1498, loss is 0.010710259899497032\n",
      "epoch: 10 step: 1499, loss is 0.004064925014972687\n",
      "epoch: 10 step: 1500, loss is 0.012599188834428787\n",
      "epoch: 10 step: 1501, loss is 0.00048036916996352375\n",
      "epoch: 10 step: 1502, loss is 0.0016301836585626006\n",
      "epoch: 10 step: 1503, loss is 0.002512401668354869\n",
      "epoch: 10 step: 1504, loss is 0.04087107256054878\n",
      "epoch: 10 step: 1505, loss is 0.034019529819488525\n",
      "epoch: 10 step: 1506, loss is 0.0027459135744720697\n",
      "epoch: 10 step: 1507, loss is 0.015495102852582932\n",
      "epoch: 10 step: 1508, loss is 0.05650779977440834\n",
      "epoch: 10 step: 1509, loss is 0.00035142325214110315\n",
      "epoch: 10 step: 1510, loss is 0.014424820430576801\n",
      "epoch: 10 step: 1511, loss is 0.14499078691005707\n",
      "epoch: 10 step: 1512, loss is 0.0016408722149208188\n",
      "epoch: 10 step: 1513, loss is 0.0002782998781185597\n",
      "epoch: 10 step: 1514, loss is 0.0006297786603681743\n",
      "epoch: 10 step: 1515, loss is 0.00038674252573400736\n",
      "epoch: 10 step: 1516, loss is 0.00035338615998625755\n",
      "epoch: 10 step: 1517, loss is 0.03021307848393917\n",
      "epoch: 10 step: 1518, loss is 0.0035776756703853607\n",
      "epoch: 10 step: 1519, loss is 0.039793387055397034\n",
      "epoch: 10 step: 1520, loss is 1.543462167319376e-05\n",
      "epoch: 10 step: 1521, loss is 0.10961845517158508\n",
      "epoch: 10 step: 1522, loss is 0.0029177723918110132\n",
      "epoch: 10 step: 1523, loss is 0.007720936555415392\n",
      "epoch: 10 step: 1524, loss is 7.03366913512582e-06\n",
      "epoch: 10 step: 1525, loss is 0.026664117351174355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1526, loss is 0.0018480997532606125\n",
      "epoch: 10 step: 1527, loss is 0.0005540209240280092\n",
      "epoch: 10 step: 1528, loss is 7.551021553808823e-05\n",
      "epoch: 10 step: 1529, loss is 0.000921394384931773\n",
      "epoch: 10 step: 1530, loss is 0.0006311989272944629\n",
      "epoch: 10 step: 1531, loss is 0.006380179896950722\n",
      "epoch: 10 step: 1532, loss is 4.1798602978815325e-06\n",
      "epoch: 10 step: 1533, loss is 0.0011186552001163363\n",
      "epoch: 10 step: 1534, loss is 0.004282171837985516\n",
      "epoch: 10 step: 1535, loss is 0.0040906872600317\n",
      "epoch: 10 step: 1536, loss is 0.002552263904362917\n",
      "epoch: 10 step: 1537, loss is 3.29432004946284e-05\n",
      "epoch: 10 step: 1538, loss is 0.03056732378900051\n",
      "epoch: 10 step: 1539, loss is 0.0002201333554694429\n",
      "epoch: 10 step: 1540, loss is 0.03582657128572464\n",
      "epoch: 10 step: 1541, loss is 0.0013007521629333496\n",
      "epoch: 10 step: 1542, loss is 0.04475570097565651\n",
      "epoch: 10 step: 1543, loss is 0.003977889660745859\n",
      "epoch: 10 step: 1544, loss is 0.023372262716293335\n",
      "epoch: 10 step: 1545, loss is 0.006757483817636967\n",
      "epoch: 10 step: 1546, loss is 0.040218520909547806\n",
      "epoch: 10 step: 1547, loss is 0.0039553348906338215\n",
      "epoch: 10 step: 1548, loss is 0.0046033114194869995\n",
      "epoch: 10 step: 1549, loss is 0.0006183604709804058\n",
      "epoch: 10 step: 1550, loss is 0.10073135048151016\n",
      "epoch: 10 step: 1551, loss is 0.03255255147814751\n",
      "epoch: 10 step: 1552, loss is 0.00018203046056441963\n",
      "epoch: 10 step: 1553, loss is 1.9616807549027726e-05\n",
      "epoch: 10 step: 1554, loss is 0.003492372576147318\n",
      "epoch: 10 step: 1555, loss is 0.11585050821304321\n",
      "epoch: 10 step: 1556, loss is 5.0940467190230265e-05\n",
      "epoch: 10 step: 1557, loss is 0.0029556495137512684\n",
      "epoch: 10 step: 1558, loss is 0.0023019949439913034\n",
      "epoch: 10 step: 1559, loss is 0.00644377525895834\n",
      "epoch: 10 step: 1560, loss is 0.007257993333041668\n",
      "epoch: 10 step: 1561, loss is 0.0031902086921036243\n",
      "epoch: 10 step: 1562, loss is 0.000986319500952959\n",
      "epoch: 10 step: 1563, loss is 0.02136087976396084\n",
      "epoch: 10 step: 1564, loss is 0.00010032821592176333\n",
      "epoch: 10 step: 1565, loss is 0.003837097901850939\n",
      "epoch: 10 step: 1566, loss is 0.011956922709941864\n",
      "epoch: 10 step: 1567, loss is 0.001073057996109128\n",
      "epoch: 10 step: 1568, loss is 0.00022669996542390436\n",
      "epoch: 10 step: 1569, loss is 0.004632414318621159\n",
      "epoch: 10 step: 1570, loss is 0.00041797099402174354\n",
      "epoch: 10 step: 1571, loss is 0.007494810037314892\n",
      "epoch: 10 step: 1572, loss is 0.004371172282844782\n",
      "epoch: 10 step: 1573, loss is 0.0006391375791281462\n",
      "epoch: 10 step: 1574, loss is 0.00010597556683933362\n",
      "epoch: 10 step: 1575, loss is 0.0002992142690345645\n",
      "epoch: 10 step: 1576, loss is 0.001028887927532196\n",
      "epoch: 10 step: 1577, loss is 0.0025925685185939074\n",
      "epoch: 10 step: 1578, loss is 0.001209898036904633\n",
      "epoch: 10 step: 1579, loss is 1.7716656657285057e-05\n",
      "epoch: 10 step: 1580, loss is 0.006092978175729513\n",
      "epoch: 10 step: 1581, loss is 0.0031543495133519173\n",
      "epoch: 10 step: 1582, loss is 0.009900608099997044\n",
      "epoch: 10 step: 1583, loss is 4.938760685035959e-05\n",
      "epoch: 10 step: 1584, loss is 0.0002175608678953722\n",
      "epoch: 10 step: 1585, loss is 0.00040573306614533067\n",
      "epoch: 10 step: 1586, loss is 0.0002765588869806379\n",
      "epoch: 10 step: 1587, loss is 0.00022209624876268208\n",
      "epoch: 10 step: 1588, loss is 0.0005817816127091646\n",
      "epoch: 10 step: 1589, loss is 0.00035394064616411924\n",
      "epoch: 10 step: 1590, loss is 0.00017572674551047385\n",
      "epoch: 10 step: 1591, loss is 0.0001709020434645936\n",
      "epoch: 10 step: 1592, loss is 0.00042098393896594644\n",
      "epoch: 10 step: 1593, loss is 0.0015005494933575392\n",
      "epoch: 10 step: 1594, loss is 0.001455441932193935\n",
      "epoch: 10 step: 1595, loss is 1.0645748261595145e-05\n",
      "epoch: 10 step: 1596, loss is 0.000251665071118623\n",
      "epoch: 10 step: 1597, loss is 0.0017049935413524508\n",
      "epoch: 10 step: 1598, loss is 0.05066201463341713\n",
      "epoch: 10 step: 1599, loss is 0.0007293125381693244\n",
      "epoch: 10 step: 1600, loss is 0.021859921514987946\n",
      "epoch: 10 step: 1601, loss is 7.422637281706557e-05\n",
      "epoch: 10 step: 1602, loss is 0.002006607363000512\n",
      "epoch: 10 step: 1603, loss is 0.00016350855003111064\n",
      "epoch: 10 step: 1604, loss is 7.504771929234266e-05\n",
      "epoch: 10 step: 1605, loss is 0.00024080293951556087\n",
      "epoch: 10 step: 1606, loss is 0.006316084414720535\n",
      "epoch: 10 step: 1607, loss is 0.01438396330922842\n",
      "epoch: 10 step: 1608, loss is 9.812720236368477e-06\n",
      "epoch: 10 step: 1609, loss is 0.01470098551362753\n",
      "epoch: 10 step: 1610, loss is 0.004941792692989111\n",
      "epoch: 10 step: 1611, loss is 0.0025789018254727125\n",
      "epoch: 10 step: 1612, loss is 0.0019237780943512917\n",
      "epoch: 10 step: 1613, loss is 0.005423588678240776\n",
      "epoch: 10 step: 1614, loss is 0.05169173330068588\n",
      "epoch: 10 step: 1615, loss is 0.0014167539775371552\n",
      "epoch: 10 step: 1616, loss is 0.0002936176024377346\n",
      "epoch: 10 step: 1617, loss is 0.00010998499055858701\n",
      "epoch: 10 step: 1618, loss is 0.012856096029281616\n",
      "epoch: 10 step: 1619, loss is 0.004937135614454746\n",
      "epoch: 10 step: 1620, loss is 4.1590908949729055e-05\n",
      "epoch: 10 step: 1621, loss is 0.00010073345038108528\n",
      "epoch: 10 step: 1622, loss is 0.0008950430201366544\n",
      "epoch: 10 step: 1623, loss is 0.00015986200014594942\n",
      "epoch: 10 step: 1624, loss is 0.003858026349917054\n",
      "epoch: 10 step: 1625, loss is 5.39402462891303e-05\n",
      "epoch: 10 step: 1626, loss is 0.00023064242850523442\n",
      "epoch: 10 step: 1627, loss is 3.824667146545835e-05\n",
      "epoch: 10 step: 1628, loss is 0.0020242840982973576\n",
      "epoch: 10 step: 1629, loss is 0.00086375413229689\n",
      "epoch: 10 step: 1630, loss is 0.00014594077947549522\n",
      "epoch: 10 step: 1631, loss is 2.858841253328137e-05\n",
      "epoch: 10 step: 1632, loss is 0.011323751881718636\n",
      "epoch: 10 step: 1633, loss is 0.002707972889766097\n",
      "epoch: 10 step: 1634, loss is 0.028520172461867332\n",
      "epoch: 10 step: 1635, loss is 0.00040841291774995625\n",
      "epoch: 10 step: 1636, loss is 0.0005291952402330935\n",
      "epoch: 10 step: 1637, loss is 0.0010730233043432236\n",
      "epoch: 10 step: 1638, loss is 0.00027392510673962533\n",
      "epoch: 10 step: 1639, loss is 0.015372312627732754\n",
      "epoch: 10 step: 1640, loss is 0.00041935849003493786\n",
      "epoch: 10 step: 1641, loss is 0.00011606010957621038\n",
      "epoch: 10 step: 1642, loss is 0.009104009717702866\n",
      "epoch: 10 step: 1643, loss is 0.0004511081497184932\n",
      "epoch: 10 step: 1644, loss is 1.4617700799135491e-05\n",
      "epoch: 10 step: 1645, loss is 0.03607998788356781\n",
      "epoch: 10 step: 1646, loss is 0.0005958664696663618\n",
      "epoch: 10 step: 1647, loss is 7.080852810759097e-05\n",
      "epoch: 10 step: 1648, loss is 0.030340252444148064\n",
      "epoch: 10 step: 1649, loss is 0.0007096193148754537\n",
      "epoch: 10 step: 1650, loss is 0.0001611046609468758\n",
      "epoch: 10 step: 1651, loss is 0.005704479292035103\n",
      "epoch: 10 step: 1652, loss is 0.0072428034618496895\n",
      "epoch: 10 step: 1653, loss is 0.023697640746831894\n",
      "epoch: 10 step: 1654, loss is 1.7807849872042425e-05\n",
      "epoch: 10 step: 1655, loss is 2.4017677787924185e-05\n",
      "epoch: 10 step: 1656, loss is 0.00749698793515563\n",
      "epoch: 10 step: 1657, loss is 0.002227215562015772\n",
      "epoch: 10 step: 1658, loss is 0.007620641496032476\n",
      "epoch: 10 step: 1659, loss is 0.0016833876725286245\n",
      "epoch: 10 step: 1660, loss is 0.022326122969388962\n",
      "epoch: 10 step: 1661, loss is 0.002566513605415821\n",
      "epoch: 10 step: 1662, loss is 0.0090352026745677\n",
      "epoch: 10 step: 1663, loss is 0.00011788988194894046\n",
      "epoch: 10 step: 1664, loss is 0.0009414395317435265\n",
      "epoch: 10 step: 1665, loss is 0.03647357225418091\n",
      "epoch: 10 step: 1666, loss is 0.007307836320251226\n",
      "epoch: 10 step: 1667, loss is 0.002174453344196081\n",
      "epoch: 10 step: 1668, loss is 0.003405025927349925\n",
      "epoch: 10 step: 1669, loss is 0.008915579877793789\n",
      "epoch: 10 step: 1670, loss is 0.0018346280558034778\n",
      "epoch: 10 step: 1671, loss is 0.0003459181752987206\n",
      "epoch: 10 step: 1672, loss is 0.0024947593919932842\n",
      "epoch: 10 step: 1673, loss is 6.175191811053082e-05\n",
      "epoch: 10 step: 1674, loss is 0.0036383469123393297\n",
      "epoch: 10 step: 1675, loss is 0.006349740084260702\n",
      "epoch: 10 step: 1676, loss is 0.0002886597940232605\n",
      "epoch: 10 step: 1677, loss is 1.4009316146257333e-05\n",
      "epoch: 10 step: 1678, loss is 0.001114912680350244\n",
      "epoch: 10 step: 1679, loss is 0.0002722772187553346\n",
      "epoch: 10 step: 1680, loss is 0.00012994026474189013\n",
      "epoch: 10 step: 1681, loss is 0.00013147115532774478\n",
      "epoch: 10 step: 1682, loss is 1.1836813428089954e-05\n",
      "epoch: 10 step: 1683, loss is 0.00013814556587021798\n",
      "epoch: 10 step: 1684, loss is 0.00010496743198018521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1685, loss is 0.009120328351855278\n",
      "epoch: 10 step: 1686, loss is 0.005044459365308285\n",
      "epoch: 10 step: 1687, loss is 0.0010453993454575539\n",
      "epoch: 10 step: 1688, loss is 0.004105791449546814\n",
      "epoch: 10 step: 1689, loss is 0.00882199127227068\n",
      "epoch: 10 step: 1690, loss is 0.017083484679460526\n",
      "epoch: 10 step: 1691, loss is 0.0033216685988008976\n",
      "epoch: 10 step: 1692, loss is 5.947398312855512e-05\n",
      "epoch: 10 step: 1693, loss is 0.0006241402588784695\n",
      "epoch: 10 step: 1694, loss is 0.05653172358870506\n",
      "epoch: 10 step: 1695, loss is 0.0017816709587350488\n",
      "epoch: 10 step: 1696, loss is 3.236042175558396e-05\n",
      "epoch: 10 step: 1697, loss is 0.00017570974887348711\n",
      "epoch: 10 step: 1698, loss is 0.0011032960610464215\n",
      "epoch: 10 step: 1699, loss is 0.002448810264468193\n",
      "epoch: 10 step: 1700, loss is 0.00032032912713475525\n",
      "epoch: 10 step: 1701, loss is 0.050008077174425125\n",
      "epoch: 10 step: 1702, loss is 8.862834874889813e-06\n",
      "epoch: 10 step: 1703, loss is 0.0015646148240193725\n",
      "epoch: 10 step: 1704, loss is 0.005367508623749018\n",
      "epoch: 10 step: 1705, loss is 0.04373764246702194\n",
      "epoch: 10 step: 1706, loss is 0.001970346551388502\n",
      "epoch: 10 step: 1707, loss is 2.1986579668009654e-05\n",
      "epoch: 10 step: 1708, loss is 0.001430694479495287\n",
      "epoch: 10 step: 1709, loss is 0.00023638841230422258\n",
      "epoch: 10 step: 1710, loss is 0.04711531475186348\n",
      "epoch: 10 step: 1711, loss is 0.047315746545791626\n",
      "epoch: 10 step: 1712, loss is 0.00011177018313901499\n",
      "epoch: 10 step: 1713, loss is 8.919715764932334e-05\n",
      "epoch: 10 step: 1714, loss is 0.002132898662239313\n",
      "epoch: 10 step: 1715, loss is 0.0018075136467814445\n",
      "epoch: 10 step: 1716, loss is 0.002221806440502405\n",
      "epoch: 10 step: 1717, loss is 3.1147552363108844e-05\n",
      "epoch: 10 step: 1718, loss is 0.14894837141036987\n",
      "epoch: 10 step: 1719, loss is 0.0005673121777363122\n",
      "epoch: 10 step: 1720, loss is 0.0023325677029788494\n",
      "epoch: 10 step: 1721, loss is 0.00255820294842124\n",
      "epoch: 10 step: 1722, loss is 0.004499036818742752\n",
      "epoch: 10 step: 1723, loss is 0.001620705472305417\n",
      "epoch: 10 step: 1724, loss is 0.0011787170078605413\n",
      "epoch: 10 step: 1725, loss is 0.0002505119191482663\n",
      "epoch: 10 step: 1726, loss is 0.008047524839639664\n",
      "epoch: 10 step: 1727, loss is 0.00014953987556509674\n",
      "epoch: 10 step: 1728, loss is 0.00019301573047414422\n",
      "epoch: 10 step: 1729, loss is 0.00010408223897684366\n",
      "epoch: 10 step: 1730, loss is 0.11764681339263916\n",
      "epoch: 10 step: 1731, loss is 0.004038563929498196\n",
      "epoch: 10 step: 1732, loss is 0.008476120419800282\n",
      "epoch: 10 step: 1733, loss is 5.9335226978873834e-05\n",
      "epoch: 10 step: 1734, loss is 0.0034044065978378057\n",
      "epoch: 10 step: 1735, loss is 0.030948791652917862\n",
      "epoch: 10 step: 1736, loss is 2.5785877369344234e-05\n",
      "epoch: 10 step: 1737, loss is 0.001148938899859786\n",
      "epoch: 10 step: 1738, loss is 0.0018120213644579053\n",
      "epoch: 10 step: 1739, loss is 0.06670992821455002\n",
      "epoch: 10 step: 1740, loss is 7.103241659933701e-05\n",
      "epoch: 10 step: 1741, loss is 0.0004599102248903364\n",
      "epoch: 10 step: 1742, loss is 0.0002644567284733057\n",
      "epoch: 10 step: 1743, loss is 3.123663191217929e-05\n",
      "epoch: 10 step: 1744, loss is 0.0033019818365573883\n",
      "epoch: 10 step: 1745, loss is 7.525358796556247e-06\n",
      "epoch: 10 step: 1746, loss is 0.0002199511945946142\n",
      "epoch: 10 step: 1747, loss is 0.000264255068032071\n",
      "epoch: 10 step: 1748, loss is 0.00014874213957227767\n",
      "epoch: 10 step: 1749, loss is 0.002613415475934744\n",
      "epoch: 10 step: 1750, loss is 9.490557567914948e-05\n",
      "epoch: 10 step: 1751, loss is 0.00999237596988678\n",
      "epoch: 10 step: 1752, loss is 0.00039889771142043173\n",
      "epoch: 10 step: 1753, loss is 7.416391599690542e-05\n",
      "epoch: 10 step: 1754, loss is 0.2228410840034485\n",
      "epoch: 10 step: 1755, loss is 2.7369964300305583e-05\n",
      "epoch: 10 step: 1756, loss is 0.0019243640126660466\n",
      "epoch: 10 step: 1757, loss is 0.060054026544094086\n",
      "epoch: 10 step: 1758, loss is 0.013112422078847885\n",
      "epoch: 10 step: 1759, loss is 0.0035966774448752403\n",
      "epoch: 10 step: 1760, loss is 0.001794918323867023\n",
      "epoch: 10 step: 1761, loss is 0.02825959213078022\n",
      "epoch: 10 step: 1762, loss is 0.010226428508758545\n",
      "epoch: 10 step: 1763, loss is 0.014988155104219913\n",
      "epoch: 10 step: 1764, loss is 1.3638983546115924e-05\n",
      "epoch: 10 step: 1765, loss is 0.0017657794523984194\n",
      "epoch: 10 step: 1766, loss is 0.00010592644684948027\n",
      "epoch: 10 step: 1767, loss is 1.699057793302927e-05\n",
      "epoch: 10 step: 1768, loss is 0.001921791466884315\n",
      "epoch: 10 step: 1769, loss is 0.048741091042757034\n",
      "epoch: 10 step: 1770, loss is 0.00013239149120636284\n",
      "epoch: 10 step: 1771, loss is 0.00041147993761114776\n",
      "epoch: 10 step: 1772, loss is 0.03612210974097252\n",
      "epoch: 10 step: 1773, loss is 1.2270122169866227e-05\n",
      "epoch: 10 step: 1774, loss is 0.0697050616145134\n",
      "epoch: 10 step: 1775, loss is 3.073035986744799e-05\n",
      "epoch: 10 step: 1776, loss is 0.02132182940840721\n",
      "epoch: 10 step: 1777, loss is 0.0026936077047139406\n",
      "epoch: 10 step: 1778, loss is 0.003969546407461166\n",
      "epoch: 10 step: 1779, loss is 0.07436195760965347\n",
      "epoch: 10 step: 1780, loss is 0.031574562191963196\n",
      "epoch: 10 step: 1781, loss is 0.004158230498433113\n",
      "epoch: 10 step: 1782, loss is 0.0004987316788174212\n",
      "epoch: 10 step: 1783, loss is 0.002322911284863949\n",
      "epoch: 10 step: 1784, loss is 0.00018623197684064507\n",
      "epoch: 10 step: 1785, loss is 0.001134050777181983\n",
      "epoch: 10 step: 1786, loss is 0.001955656800419092\n",
      "epoch: 10 step: 1787, loss is 0.0075027355924248695\n",
      "epoch: 10 step: 1788, loss is 0.000452600623248145\n",
      "epoch: 10 step: 1789, loss is 0.016454070806503296\n",
      "epoch: 10 step: 1790, loss is 0.0002678466262295842\n",
      "epoch: 10 step: 1791, loss is 0.05758398398756981\n",
      "epoch: 10 step: 1792, loss is 0.019106552004814148\n",
      "epoch: 10 step: 1793, loss is 0.0004900384228676558\n",
      "epoch: 10 step: 1794, loss is 0.0006472320528700948\n",
      "epoch: 10 step: 1795, loss is 0.0005444895359687507\n",
      "epoch: 10 step: 1796, loss is 0.0001990802848013118\n",
      "epoch: 10 step: 1797, loss is 8.98001526365988e-05\n",
      "epoch: 10 step: 1798, loss is 2.880985448427964e-05\n",
      "epoch: 10 step: 1799, loss is 0.0068733952939510345\n",
      "epoch: 10 step: 1800, loss is 0.18588851392269135\n",
      "epoch: 10 step: 1801, loss is 0.0024973852559924126\n",
      "epoch: 10 step: 1802, loss is 0.0006300503155216575\n",
      "epoch: 10 step: 1803, loss is 8.291310223285109e-06\n",
      "epoch: 10 step: 1804, loss is 0.0001633233914617449\n",
      "epoch: 10 step: 1805, loss is 1.3199540262576193e-05\n",
      "epoch: 10 step: 1806, loss is 0.12254674732685089\n",
      "epoch: 10 step: 1807, loss is 0.0010519891511648893\n",
      "epoch: 10 step: 1808, loss is 0.08311179280281067\n",
      "epoch: 10 step: 1809, loss is 0.002225233009085059\n",
      "epoch: 10 step: 1810, loss is 2.568235322542023e-05\n",
      "epoch: 10 step: 1811, loss is 0.10971798747777939\n",
      "epoch: 10 step: 1812, loss is 0.020130861550569534\n",
      "epoch: 10 step: 1813, loss is 0.003354328917339444\n",
      "epoch: 10 step: 1814, loss is 0.0002498065878171474\n",
      "epoch: 10 step: 1815, loss is 6.506699719466269e-06\n",
      "epoch: 10 step: 1816, loss is 0.006020093336701393\n",
      "epoch: 10 step: 1817, loss is 6.296458013821393e-05\n",
      "epoch: 10 step: 1818, loss is 9.068539657164365e-05\n",
      "epoch: 10 step: 1819, loss is 0.05818328261375427\n",
      "epoch: 10 step: 1820, loss is 0.0031153918243944645\n",
      "epoch: 10 step: 1821, loss is 1.7388922060490586e-05\n",
      "epoch: 10 step: 1822, loss is 0.07383361458778381\n",
      "epoch: 10 step: 1823, loss is 0.0003680386289488524\n",
      "epoch: 10 step: 1824, loss is 0.0027773845940828323\n",
      "epoch: 10 step: 1825, loss is 0.00023301118926610798\n",
      "epoch: 10 step: 1826, loss is 0.0010223457356914878\n",
      "epoch: 10 step: 1827, loss is 9.004274033941329e-06\n",
      "epoch: 10 step: 1828, loss is 0.0212889164686203\n",
      "epoch: 10 step: 1829, loss is 0.03089732863008976\n",
      "epoch: 10 step: 1830, loss is 0.0005408969009295106\n",
      "epoch: 10 step: 1831, loss is 0.000279245461570099\n",
      "epoch: 10 step: 1832, loss is 0.002515576547011733\n",
      "epoch: 10 step: 1833, loss is 0.00013714988017454743\n",
      "epoch: 10 step: 1834, loss is 0.12046415358781815\n",
      "epoch: 10 step: 1835, loss is 6.19118072791025e-05\n",
      "epoch: 10 step: 1836, loss is 0.015340087004005909\n",
      "epoch: 10 step: 1837, loss is 0.0009087859070859849\n",
      "epoch: 10 step: 1838, loss is 0.013947143219411373\n",
      "epoch: 10 step: 1839, loss is 0.0005103521980345249\n",
      "epoch: 10 step: 1840, loss is 6.0116912209196016e-05\n",
      "epoch: 10 step: 1841, loss is 0.015128130093216896\n",
      "epoch: 10 step: 1842, loss is 0.000100353492598515\n",
      "epoch: 10 step: 1843, loss is 0.016122322529554367\n",
      "epoch: 10 step: 1844, loss is 0.0016629495657980442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1845, loss is 0.0002996671828441322\n",
      "epoch: 10 step: 1846, loss is 0.001362378941848874\n",
      "epoch: 10 step: 1847, loss is 0.0001354935229755938\n",
      "epoch: 10 step: 1848, loss is 1.1171152436872944e-05\n",
      "epoch: 10 step: 1849, loss is 0.001734251040033996\n",
      "epoch: 10 step: 1850, loss is 0.04663177207112312\n",
      "epoch: 10 step: 1851, loss is 5.8216555771650746e-05\n",
      "epoch: 10 step: 1852, loss is 0.0006516302819363773\n",
      "epoch: 10 step: 1853, loss is 0.012148904614150524\n",
      "epoch: 10 step: 1854, loss is 0.00013349131040740758\n",
      "epoch: 10 step: 1855, loss is 5.040556516178185e-06\n",
      "epoch: 10 step: 1856, loss is 5.8021490985993296e-05\n",
      "epoch: 10 step: 1857, loss is 0.012768133543431759\n",
      "epoch: 10 step: 1858, loss is 0.005631063133478165\n",
      "epoch: 10 step: 1859, loss is 0.0028326266910880804\n",
      "epoch: 10 step: 1860, loss is 0.0004013504658360034\n",
      "epoch: 10 step: 1861, loss is 2.4815186407067813e-05\n",
      "epoch: 10 step: 1862, loss is 9.660967043600976e-05\n",
      "epoch: 10 step: 1863, loss is 0.002901215571910143\n",
      "epoch: 10 step: 1864, loss is 0.046314630657434464\n",
      "epoch: 10 step: 1865, loss is 0.14229385554790497\n",
      "epoch: 10 step: 1866, loss is 0.001392036909237504\n",
      "epoch: 10 step: 1867, loss is 0.01280962023884058\n",
      "epoch: 10 step: 1868, loss is 0.008373366668820381\n",
      "epoch: 10 step: 1869, loss is 0.00010718893463490531\n",
      "epoch: 10 step: 1870, loss is 0.0012863256270065904\n",
      "epoch: 10 step: 1871, loss is 6.411372851289343e-06\n",
      "epoch: 10 step: 1872, loss is 0.0005342239164747298\n",
      "epoch: 10 step: 1873, loss is 0.0013203779235482216\n",
      "epoch: 10 step: 1874, loss is 0.002128059044480324\n",
      "epoch: 10 step: 1875, loss is 0.0014955524820834398\n",
      "epoch: 10 step: 1876, loss is 0.07224030792713165\n",
      "epoch: 10 step: 1877, loss is 0.00038151844637468457\n",
      "epoch: 10 step: 1878, loss is 0.002033919095993042\n",
      "epoch: 10 step: 1879, loss is 0.014038542285561562\n",
      "epoch: 10 step: 1880, loss is 5.332672662916593e-05\n",
      "epoch: 10 step: 1881, loss is 0.4643544852733612\n",
      "epoch: 10 step: 1882, loss is 0.00010172452311962843\n",
      "epoch: 10 step: 1883, loss is 0.002585842739790678\n",
      "epoch: 10 step: 1884, loss is 0.20194591581821442\n",
      "epoch: 10 step: 1885, loss is 0.0003953524283133447\n",
      "epoch: 10 step: 1886, loss is 0.025826867669820786\n",
      "epoch: 10 step: 1887, loss is 8.386163972318172e-05\n",
      "epoch: 10 step: 1888, loss is 0.001873165019787848\n",
      "epoch: 10 step: 1889, loss is 0.00534145487472415\n",
      "epoch: 10 step: 1890, loss is 0.14889581501483917\n",
      "epoch: 10 step: 1891, loss is 0.016620833426713943\n",
      "epoch: 10 step: 1892, loss is 0.0027347069699317217\n",
      "epoch: 10 step: 1893, loss is 0.0020600035786628723\n",
      "epoch: 10 step: 1894, loss is 0.0005134335951879621\n",
      "epoch: 10 step: 1895, loss is 0.00023018455249257386\n",
      "epoch: 10 step: 1896, loss is 0.014154452830553055\n",
      "epoch: 10 step: 1897, loss is 0.02558033913373947\n",
      "epoch: 10 step: 1898, loss is 0.0022350787185132504\n",
      "epoch: 10 step: 1899, loss is 0.0007988247671164572\n",
      "epoch: 10 step: 1900, loss is 0.0017713301349431276\n",
      "epoch: 10 step: 1901, loss is 0.008586391806602478\n",
      "epoch: 10 step: 1902, loss is 0.007909668609499931\n",
      "epoch: 10 step: 1903, loss is 0.0038335598073899746\n",
      "epoch: 10 step: 1904, loss is 0.1570492833852768\n",
      "epoch: 10 step: 1905, loss is 0.012934889644384384\n",
      "epoch: 10 step: 1906, loss is 0.0014011411694809794\n",
      "epoch: 10 step: 1907, loss is 0.0002689399116206914\n",
      "epoch: 10 step: 1908, loss is 0.004746878985315561\n",
      "epoch: 10 step: 1909, loss is 0.0009816529927775264\n",
      "epoch: 10 step: 1910, loss is 0.008687576279044151\n",
      "epoch: 10 step: 1911, loss is 0.004118246957659721\n",
      "epoch: 10 step: 1912, loss is 0.00041186914313584566\n",
      "epoch: 10 step: 1913, loss is 0.0074370866641402245\n",
      "epoch: 10 step: 1914, loss is 1.2763289305439685e-05\n",
      "epoch: 10 step: 1915, loss is 0.07554028928279877\n",
      "epoch: 10 step: 1916, loss is 0.0007650325424037874\n",
      "epoch: 10 step: 1917, loss is 0.004516057204455137\n",
      "epoch: 10 step: 1918, loss is 4.520948641584255e-05\n",
      "epoch: 10 step: 1919, loss is 0.00033787242136895657\n",
      "epoch: 10 step: 1920, loss is 0.03820362314581871\n",
      "epoch: 10 step: 1921, loss is 0.0016557361232116818\n",
      "epoch: 10 step: 1922, loss is 0.0010924855014309287\n",
      "epoch: 10 step: 1923, loss is 0.00017196079716086388\n",
      "epoch: 10 step: 1924, loss is 0.0008498838287778199\n",
      "epoch: 10 step: 1925, loss is 0.08887534588575363\n",
      "epoch: 10 step: 1926, loss is 0.001253509079106152\n",
      "epoch: 10 step: 1927, loss is 1.4138780898065306e-05\n",
      "epoch: 10 step: 1928, loss is 0.07209816575050354\n",
      "epoch: 10 step: 1929, loss is 0.018461402505636215\n",
      "epoch: 10 step: 1930, loss is 8.24306407594122e-05\n",
      "epoch: 10 step: 1931, loss is 9.343713463749737e-05\n",
      "epoch: 10 step: 1932, loss is 0.0009386718738824129\n",
      "epoch: 10 step: 1933, loss is 0.0002647260553203523\n",
      "epoch: 10 step: 1934, loss is 6.797764945076779e-05\n",
      "epoch: 10 step: 1935, loss is 0.00010793039837153628\n",
      "epoch: 10 step: 1936, loss is 0.0003445875772740692\n",
      "epoch: 10 step: 1937, loss is 0.1027923971414566\n",
      "epoch: 10 step: 1938, loss is 0.027640631422400475\n",
      "epoch: 10 step: 1939, loss is 0.0005029125604778528\n",
      "epoch: 10 step: 1940, loss is 0.006460000295192003\n",
      "epoch: 10 step: 1941, loss is 0.006822190247476101\n",
      "epoch: 10 step: 1942, loss is 0.0033743258100003004\n",
      "epoch: 10 step: 1943, loss is 0.007310907356441021\n",
      "epoch: 10 step: 1944, loss is 0.003155055455863476\n",
      "epoch: 10 step: 1945, loss is 0.19024710357189178\n",
      "epoch: 10 step: 1946, loss is 0.0025150696747004986\n",
      "epoch: 10 step: 1947, loss is 0.01280420646071434\n",
      "epoch: 10 step: 1948, loss is 0.04952318221330643\n",
      "epoch: 10 step: 1949, loss is 0.008461041375994682\n",
      "epoch: 10 step: 1950, loss is 0.0002094857773045078\n",
      "epoch: 10 step: 1951, loss is 0.0004510478174779564\n",
      "epoch: 10 step: 1952, loss is 0.011320576071739197\n",
      "epoch: 10 step: 1953, loss is 7.321656448766589e-05\n",
      "epoch: 10 step: 1954, loss is 0.00025913139688782394\n",
      "epoch: 10 step: 1955, loss is 0.00022688877652399242\n",
      "epoch: 10 step: 1956, loss is 0.0011825098190456629\n",
      "epoch: 10 step: 1957, loss is 0.00010552075400482863\n",
      "epoch: 10 step: 1958, loss is 3.2207601179834455e-05\n",
      "epoch: 10 step: 1959, loss is 2.256307561765425e-05\n",
      "epoch: 10 step: 1960, loss is 0.00012451416114345193\n",
      "epoch: 10 step: 1961, loss is 0.005275178235024214\n",
      "epoch: 10 step: 1962, loss is 8.519049151800573e-05\n",
      "epoch: 10 step: 1963, loss is 0.000945163716096431\n",
      "epoch: 10 step: 1964, loss is 0.006772611290216446\n",
      "epoch: 10 step: 1965, loss is 0.011484886519610882\n",
      "epoch: 10 step: 1966, loss is 0.020615359768271446\n",
      "epoch: 10 step: 1967, loss is 0.0005282667698338628\n",
      "epoch: 10 step: 1968, loss is 2.7812013286165893e-05\n",
      "epoch: 10 step: 1969, loss is 8.135442476486787e-05\n",
      "epoch: 10 step: 1970, loss is 0.00038691976806148887\n",
      "epoch: 10 step: 1971, loss is 0.015321492217481136\n",
      "epoch: 10 step: 1972, loss is 0.0012997547164559364\n",
      "epoch: 10 step: 1973, loss is 0.0013251121854409575\n",
      "epoch: 10 step: 1974, loss is 0.009060136042535305\n",
      "epoch: 10 step: 1975, loss is 0.012655002065002918\n",
      "epoch: 10 step: 1976, loss is 0.00011006852582795545\n",
      "epoch: 10 step: 1977, loss is 0.009294332936406136\n",
      "epoch: 10 step: 1978, loss is 0.0212706308811903\n",
      "epoch: 10 step: 1979, loss is 0.040378253906965256\n",
      "epoch: 10 step: 1980, loss is 0.00031359324930235744\n",
      "epoch: 10 step: 1981, loss is 0.0018850123742595315\n",
      "epoch: 10 step: 1982, loss is 0.011138666421175003\n",
      "epoch: 10 step: 1983, loss is 0.09205891937017441\n",
      "epoch: 10 step: 1984, loss is 0.05369763448834419\n",
      "epoch: 10 step: 1985, loss is 0.0003369851619936526\n",
      "epoch: 10 step: 1986, loss is 0.008204575628042221\n",
      "epoch: 10 step: 1987, loss is 0.0005392216262407601\n",
      "epoch: 10 step: 1988, loss is 0.011902950704097748\n",
      "epoch: 10 step: 1989, loss is 5.984751260257326e-05\n",
      "epoch: 10 step: 1990, loss is 0.00034520335611887276\n",
      "epoch: 10 step: 1991, loss is 9.042616875376552e-05\n",
      "epoch: 10 step: 1992, loss is 0.021472930908203125\n",
      "epoch: 10 step: 1993, loss is 0.006470193155109882\n",
      "epoch: 10 step: 1994, loss is 7.82601855462417e-05\n",
      "epoch: 10 step: 1995, loss is 0.03657433018088341\n",
      "epoch: 10 step: 1996, loss is 0.06738216429948807\n",
      "epoch: 10 step: 1997, loss is 0.022312909364700317\n",
      "epoch: 10 step: 1998, loss is 0.026127373799681664\n",
      "epoch: 10 step: 1999, loss is 0.000835902348626405\n",
      "epoch: 10 step: 2000, loss is 0.00046737759839743376\n",
      "epoch: 10 step: 2001, loss is 4.6605105126218405e-06\n",
      "epoch: 10 step: 2002, loss is 6.0814978496637195e-05\n",
      "epoch: 10 step: 2003, loss is 2.7248048354522325e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 2004, loss is 0.0003181733482051641\n",
      "epoch: 10 step: 2005, loss is 0.00035207034670747817\n",
      "epoch: 10 step: 2006, loss is 0.08288626372814178\n",
      "epoch: 10 step: 2007, loss is 0.00021208511316217482\n",
      "epoch: 10 step: 2008, loss is 0.03773059323430061\n",
      "epoch: 10 step: 2009, loss is 0.03539890795946121\n",
      "epoch: 10 step: 2010, loss is 0.015195262618362904\n",
      "epoch: 10 step: 2011, loss is 0.025606906041502953\n",
      "epoch: 10 step: 2012, loss is 0.0003784235450439155\n",
      "epoch: 10 step: 2013, loss is 0.007725963369011879\n",
      "epoch: 10 step: 2014, loss is 0.002565056085586548\n",
      "epoch: 10 step: 2015, loss is 0.0006357438396662474\n",
      "epoch: 10 step: 2016, loss is 2.2073774744058028e-05\n",
      "epoch: 10 step: 2017, loss is 0.00022947763500269502\n",
      "epoch: 10 step: 2018, loss is 0.0002825249102897942\n",
      "epoch: 10 step: 2019, loss is 0.010376743040978909\n",
      "epoch: 10 step: 2020, loss is 0.015934713184833527\n",
      "epoch: 10 step: 2021, loss is 0.00010700973507482558\n",
      "epoch: 10 step: 2022, loss is 3.717890876941965e-06\n",
      "epoch: 10 step: 2023, loss is 0.0013375654816627502\n",
      "epoch: 10 step: 2024, loss is 0.0013779568253085017\n",
      "epoch: 10 step: 2025, loss is 0.0009836556855589151\n",
      "epoch: 10 step: 2026, loss is 0.00352643639780581\n",
      "epoch: 10 step: 2027, loss is 0.0009981399634853005\n",
      "epoch: 10 step: 2028, loss is 0.00013800674059893936\n",
      "epoch: 10 step: 2029, loss is 0.028201814740896225\n",
      "epoch: 10 step: 2030, loss is 0.0009976014262065291\n",
      "epoch: 10 step: 2031, loss is 0.001592022366821766\n",
      "epoch: 10 step: 2032, loss is 2.2537624317919835e-05\n",
      "epoch: 10 step: 2033, loss is 0.0008445192943327129\n",
      "epoch: 10 step: 2034, loss is 0.0008128234185278416\n",
      "epoch: 10 step: 2035, loss is 0.0001752391690388322\n",
      "epoch: 10 step: 2036, loss is 0.00040855485713109374\n",
      "epoch: 10 step: 2037, loss is 0.00025414457195438445\n",
      "epoch: 10 step: 2038, loss is 2.6531473849900067e-05\n",
      "epoch: 10 step: 2039, loss is 0.0003331365587655455\n",
      "epoch: 10 step: 2040, loss is 0.0004977192147634923\n",
      "epoch: 10 step: 2041, loss is 0.0005525777814909816\n",
      "epoch: 10 step: 2042, loss is 9.551720722811297e-05\n",
      "epoch: 10 step: 2043, loss is 0.18925711512565613\n",
      "epoch: 10 step: 2044, loss is 1.8764341803034768e-05\n",
      "epoch: 10 step: 2045, loss is 0.0005838787765242159\n",
      "epoch: 10 step: 2046, loss is 0.030874282121658325\n",
      "epoch: 10 step: 2047, loss is 0.0011382935335859656\n",
      "epoch: 10 step: 2048, loss is 9.743518603499979e-05\n",
      "epoch: 10 step: 2049, loss is 0.0007152364123612642\n",
      "epoch: 10 step: 2050, loss is 0.08061444014310837\n",
      "epoch: 10 step: 2051, loss is 1.3118490642227698e-05\n",
      "epoch: 10 step: 2052, loss is 0.00014426490815822035\n",
      "epoch: 10 step: 2053, loss is 0.05640898644924164\n",
      "epoch: 10 step: 2054, loss is 0.001845862832851708\n",
      "epoch: 10 step: 2055, loss is 0.0417824313044548\n",
      "epoch: 10 step: 2056, loss is 0.011584937572479248\n",
      "epoch: 10 step: 2057, loss is 0.0009332108893431723\n",
      "epoch: 10 step: 2058, loss is 0.1576053500175476\n",
      "epoch: 10 step: 2059, loss is 0.0008855417836457491\n",
      "epoch: 10 step: 2060, loss is 0.07629125565290451\n",
      "epoch: 10 step: 2061, loss is 2.6248326321365312e-05\n",
      "epoch: 10 step: 2062, loss is 0.0001018261827994138\n",
      "epoch: 10 step: 2063, loss is 0.010265706107020378\n",
      "epoch: 10 step: 2064, loss is 0.028410106897354126\n",
      "epoch: 10 step: 2065, loss is 0.0013590881135314703\n",
      "epoch: 10 step: 2066, loss is 0.0003957529552280903\n",
      "epoch: 10 step: 2067, loss is 0.001992997946217656\n",
      "epoch: 10 step: 2068, loss is 0.05639161169528961\n",
      "epoch: 10 step: 2069, loss is 0.0006126989610493183\n",
      "epoch: 10 step: 2070, loss is 5.1451097533572465e-05\n",
      "epoch: 10 step: 2071, loss is 0.002109876135364175\n",
      "epoch: 10 step: 2072, loss is 0.17663855850696564\n",
      "epoch: 10 step: 2073, loss is 0.02672194130718708\n",
      "epoch: 10 step: 2074, loss is 6.93801703164354e-05\n",
      "epoch: 10 step: 2075, loss is 0.0001028401602525264\n",
      "epoch: 10 step: 2076, loss is 0.02730502188205719\n",
      "epoch: 10 step: 2077, loss is 0.002635946264490485\n",
      "epoch: 10 step: 2078, loss is 0.003707082476466894\n",
      "epoch: 10 step: 2079, loss is 0.001924070413224399\n",
      "epoch: 10 step: 2080, loss is 0.0002518762485124171\n",
      "epoch: 10 step: 2081, loss is 0.02383764274418354\n",
      "epoch: 10 step: 2082, loss is 0.00026468641590327024\n",
      "epoch: 10 step: 2083, loss is 0.24099315702915192\n",
      "epoch: 10 step: 2084, loss is 0.0009554015123285353\n",
      "epoch: 10 step: 2085, loss is 0.12511859834194183\n",
      "epoch: 10 step: 2086, loss is 0.00029117241501808167\n",
      "epoch: 10 step: 2087, loss is 0.0008845697739161551\n",
      "epoch: 10 step: 2088, loss is 0.0004380595055408776\n",
      "epoch: 10 step: 2089, loss is 0.0679357722401619\n",
      "epoch: 10 step: 2090, loss is 0.07165314257144928\n",
      "epoch: 10 step: 2091, loss is 0.0026691884268075228\n",
      "epoch: 10 step: 2092, loss is 0.0015082376776263118\n",
      "epoch: 10 step: 2093, loss is 0.0013154023326933384\n",
      "epoch: 10 step: 2094, loss is 0.001999820815399289\n",
      "epoch: 10 step: 2095, loss is 0.01111510954797268\n",
      "epoch: 10 step: 2096, loss is 0.0013032048009335995\n",
      "epoch: 10 step: 2097, loss is 0.14166954159736633\n",
      "epoch: 10 step: 2098, loss is 0.0004443209618330002\n",
      "epoch: 10 step: 2099, loss is 0.009025024250149727\n",
      "epoch: 10 step: 2100, loss is 0.013064763508737087\n",
      "epoch: 10 step: 2101, loss is 0.0005425668205134571\n",
      "epoch: 10 step: 2102, loss is 0.0009000819991342723\n",
      "epoch: 10 step: 2103, loss is 0.00013158904039300978\n",
      "epoch: 10 step: 2104, loss is 0.002517204498872161\n",
      "epoch: 10 step: 2105, loss is 0.00032925570849329233\n",
      "epoch: 10 step: 2106, loss is 6.41395672573708e-05\n",
      "epoch: 10 step: 2107, loss is 0.06030923128128052\n",
      "epoch: 10 step: 2108, loss is 0.012280451133847237\n",
      "epoch: 10 step: 2109, loss is 0.013715803623199463\n",
      "epoch: 10 step: 2110, loss is 0.0008158193086273968\n",
      "epoch: 10 step: 2111, loss is 0.0002486657176632434\n",
      "epoch: 10 step: 2112, loss is 0.0009569711401127279\n",
      "epoch: 10 step: 2113, loss is 0.0019707572646439075\n",
      "epoch: 10 step: 2114, loss is 0.0003790851915255189\n",
      "epoch: 10 step: 2115, loss is 0.0013985438272356987\n",
      "epoch: 10 step: 2116, loss is 0.010075329802930355\n",
      "epoch: 10 step: 2117, loss is 0.02750970609486103\n",
      "epoch: 10 step: 2118, loss is 0.006801297422498465\n",
      "epoch: 10 step: 2119, loss is 0.012354022823274136\n",
      "epoch: 10 step: 2120, loss is 0.0071815005503594875\n",
      "epoch: 10 step: 2121, loss is 0.0015335300704464316\n",
      "epoch: 10 step: 2122, loss is 0.0002894634671974927\n",
      "epoch: 10 step: 2123, loss is 0.00833249744027853\n",
      "epoch: 10 step: 2124, loss is 5.220413004280999e-05\n",
      "epoch: 10 step: 2125, loss is 0.00022990943398326635\n",
      "epoch: 10 step: 2126, loss is 0.0028857006691396236\n",
      "epoch: 10 step: 2127, loss is 0.0029048388823866844\n",
      "epoch: 10 step: 2128, loss is 0.0013594278134405613\n",
      "epoch: 10 step: 2129, loss is 0.000347067165421322\n",
      "epoch: 10 step: 2130, loss is 0.0008425773703493178\n",
      "epoch: 10 step: 2131, loss is 0.010854269377887249\n",
      "epoch: 10 step: 2132, loss is 0.007120082620531321\n",
      "epoch: 10 step: 2133, loss is 4.429717591847293e-05\n",
      "epoch: 10 step: 2134, loss is 2.4853379727574065e-05\n",
      "epoch: 10 step: 2135, loss is 0.2601608633995056\n",
      "epoch: 10 step: 2136, loss is 0.0010388443479314446\n",
      "epoch: 10 step: 2137, loss is 0.011814423836767673\n",
      "epoch: 10 step: 2138, loss is 0.0001664827432250604\n",
      "epoch: 10 step: 2139, loss is 0.1245480328798294\n",
      "epoch: 10 step: 2140, loss is 0.0001533956383354962\n",
      "epoch: 10 step: 2141, loss is 0.001892377040348947\n",
      "epoch: 10 step: 2142, loss is 0.004735284484922886\n",
      "epoch: 10 step: 2143, loss is 0.0011995293898507953\n",
      "epoch: 10 step: 2144, loss is 0.00183863693382591\n",
      "epoch: 10 step: 2145, loss is 0.0007119731744751334\n",
      "epoch: 10 step: 2146, loss is 0.060941074043512344\n",
      "epoch: 10 step: 2147, loss is 0.008944624103605747\n",
      "epoch: 10 step: 2148, loss is 0.0017159524140879512\n",
      "epoch: 10 step: 2149, loss is 0.031408026814460754\n",
      "epoch: 10 step: 2150, loss is 0.002560763154178858\n",
      "epoch: 10 step: 2151, loss is 0.0008958517573773861\n",
      "epoch: 10 step: 2152, loss is 0.0005701259360648692\n",
      "epoch: 10 step: 2153, loss is 0.0005291707930155098\n",
      "epoch: 10 step: 2154, loss is 0.001457385253161192\n",
      "epoch: 10 step: 2155, loss is 2.1875277525396086e-05\n",
      "epoch: 10 step: 2156, loss is 0.00141355418600142\n",
      "epoch: 10 step: 2157, loss is 0.00041982397669926286\n",
      "epoch: 10 step: 2158, loss is 0.0009869285859167576\n",
      "epoch: 10 step: 2159, loss is 2.754655542958062e-05\n",
      "epoch: 10 step: 2160, loss is 6.26559994998388e-05\n",
      "epoch: 10 step: 2161, loss is 0.00011673333210637793\n",
      "epoch: 10 step: 2162, loss is 6.835716339992359e-05\n",
      "epoch: 10 step: 2163, loss is 0.001432515331543982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 2164, loss is 0.021363671869039536\n",
      "epoch: 10 step: 2165, loss is 0.01330494973808527\n",
      "epoch: 10 step: 2166, loss is 0.0015751547180116177\n",
      "epoch: 10 step: 2167, loss is 0.0019786525517702103\n",
      "epoch: 10 step: 2168, loss is 7.132025348255411e-05\n",
      "epoch: 10 step: 2169, loss is 0.00016240455443039536\n",
      "epoch: 10 step: 2170, loss is 3.628649938036688e-05\n",
      "epoch: 10 step: 2171, loss is 0.000890028546564281\n",
      "epoch: 10 step: 2172, loss is 0.006955612916499376\n",
      "epoch: 10 step: 2173, loss is 0.0758945420384407\n",
      "epoch: 10 step: 2174, loss is 0.06425654143095016\n",
      "epoch: 10 step: 2175, loss is 3.543455750332214e-05\n",
      "epoch: 10 step: 2176, loss is 0.0024920639116317034\n",
      "epoch: 10 step: 2177, loss is 0.004027483053505421\n",
      "epoch: 10 step: 2178, loss is 0.00011091174383182079\n",
      "epoch: 10 step: 2179, loss is 0.0005765431560575962\n",
      "epoch: 10 step: 2180, loss is 0.013204016722738743\n",
      "epoch: 10 step: 2181, loss is 0.000304813904222101\n",
      "epoch: 10 step: 2182, loss is 0.00025844646734185517\n",
      "epoch: 10 step: 2183, loss is 0.00010813850531121716\n",
      "epoch: 10 step: 2184, loss is 0.0004201069241389632\n",
      "epoch: 10 step: 2185, loss is 8.789659477770329e-05\n",
      "epoch: 10 step: 2186, loss is 0.002085041254758835\n",
      "epoch: 10 step: 2187, loss is 0.00046521032345481217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.529.225 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.530.223 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.531.220 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.531.220 [mindspore\\dataset\\core\\validator_helpers.py:744] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.532.217 [mindspore\\dataset\\core\\validator_helpers.py:744] 'TypeCast' from mindspore.dataset.transforms.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'TypeCast' from mindspore.dataset.transforms instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting Testing ==========\n",
      "Test Accuracy: 0.9975851623228167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:37.154.346 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:37.155.365 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:37.157.318 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:37.158.336 [mindspore\\dataset\\core\\validator_helpers.py:744] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting Predicting ==========\n",
      "Predicted: \"[1 4 3 7 6 3 7 2 4]\", Actual: \"[1 4 3 7 6 3 7 2 4]\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.ops import operations as ops\n",
    "from mindspore import dataset as ds\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "from mindspore.dataset.vision import Inter\n",
    "from mindspore import nn, context\n",
    "from mindspore.train import Model\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.common.initializer import initializer\n",
    "from mindspore.nn.loss import SoftmaxCrossEntropyWithLogits\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "import matplotlib.pyplot as plt\n",
    "from mindvision.dataset import Mnist\n",
    "\n",
    "# \n",
    "data_path = \"mnist\"\n",
    "train_path = os.path.join(data_path, \"train\")\n",
    "test_path = os.path.join(data_path, \"test\")\n",
    "\n",
    "# GPUCPU\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n",
    "\n",
    "# LeNet5\n",
    "class LeNet5(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        self.fc1 = nn.Dense(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Dense(120, 84)\n",
    "        self.fc3 = nn.Dense(84, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.max_pool2d(self.relu(self.conv1(x)))\n",
    "        x = self.max_pool2d(self.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# \n",
    "def create_dataset(data_path, batch_size=32, repeat_size=1,\n",
    "                   num_parallel_workers=1):\n",
    "    # \n",
    "    mnist_ds = ds.MnistDataset(data_path)\n",
    "\n",
    "    # \n",
    "    resize_height, resize_width = 32, 32\n",
    "    rescale = 1.0 / 255.0\n",
    "    shift = 0.0\n",
    "    rescale_nml = 1 / 0.3081\n",
    "    shift_nml = -1 * 0.1307 / 0.3081\n",
    "    resize_op = CV.Resize((resize_height, resize_width), interpolation=Inter.LINEAR)  \n",
    "    rescale_nml_op = CV.Rescale(rescale_nml, shift_nml)\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "    type_cast_op = C.TypeCast(mstype.int32)\n",
    "\n",
    "    # \n",
    "    mnist_ds = mnist_ds.map(operations=type_cast_op, input_columns=\"label\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=resize_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=rescale_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=rescale_nml_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=hwc2chw_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "\n",
    "    # shufflebatch\n",
    "    buffer_size = 10000\n",
    "    mnist_ds = mnist_ds.shuffle(buffer_size=buffer_size)\n",
    "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
    "    mnist_ds = mnist_ds.repeat(repeat_size)\n",
    "\n",
    "    return mnist_ds\n",
    "\n",
    "# \n",
    "def train_and_test(network, data_path, num_epochs=10, batch_size=32, lr=0.01,\n",
    "                   momentum=0.9, weight_decay=0.0):\n",
    "    # \n",
    "    dataset = create_dataset(data_path=data_path, batch_size=batch_size)\n",
    "\n",
    "    # \n",
    "    net_loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    net_opt = nn.Momentum(network.trainable_params(), lr, momentum)\n",
    "\n",
    "    # \n",
    "    model = Model(network, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()})\n",
    "\n",
    "    # \n",
    "    ckpt_save_dir = \"./ckpt_lenet/\"\n",
    "    ckpt_config = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)\n",
    "    ckpt_cb = ModelCheckpoint(prefix=\"checkpoint_lenet\", directory=ckpt_save_dir, config=ckpt_config)\n",
    "\n",
    "    # \n",
    "    print(\"========== Starting Training ==========\")\n",
    "    model.train(num_epochs, dataset, callbacks=[LossMonitor(), ckpt_cb], dataset_sink_mode=False)\n",
    "\n",
    "    # \n",
    "    print(\"========== Starting Testing ==========\")\n",
    "    res = model.eval(create_dataset(data_path=data_path, batch_size=batch_size, repeat_size=1))\n",
    "    print(\"Test Accuracy:\", res[\"Accuracy\"])\n",
    "\n",
    "# LeNet5\n",
    "if __name__ == \"__main__\":\n",
    "    net = LeNet5()\n",
    "    train_and_test(net, data_path, num_epochs=10, batch_size=32, lr=0.01, momentum=0.9, weight_decay=0.0)\n",
    "net = LeNet5()\n",
    "# \n",
    "param_dict = load_checkpoint(\"./ckpt_lenet/checkpoint_lenet-10_2187.ckpt\")\n",
    "# \n",
    "load_param_into_net(net, param_dict)\n",
    "            \n",
    "mnist = Mnist(\"./mnist\", split=\"train\", batch_size=9, resize=32)\n",
    "dataset_infer = mnist.run()\n",
    "ds_test = dataset_infer.create_dict_iterator()\n",
    "data = next(ds_test)\n",
    "images = data[\"image\"].asnumpy()\n",
    "labels = data[\"label\"].asnumpy()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(1, 10):\n",
    "    plt.subplot(3, 3, i)\n",
    "    plt.imshow(images[i-1][0], interpolation=\"None\", cmap=\"gray\")\n",
    "plt.show()\n",
    "lr=0.01\n",
    "momentum=0.9\n",
    "# model.predictimage\n",
    "net_loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "net_opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "# \n",
    "model = Model(net, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()})\n",
    "output = model.predict(Tensor(data['image']))\n",
    "predicted = np.argmax(output.asnumpy(), axis=1)\n",
    "# \n",
    "print(\"========== Starting Predicting ==========\")\n",
    "print(f'Predicted: \"{predicted}\", Actual: \"{labels}\"')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
