{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2554b851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.589.321 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.591.282 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.592.279 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.595.299 [mindspore\\dataset\\core\\validator_helpers.py:744] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:48:15.597.268 [mindspore\\dataset\\core\\validator_helpers.py:744] 'TypeCast' from mindspore.dataset.transforms.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'TypeCast' from mindspore.dataset.transforms instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting Training ==========\n",
      "epoch: 1 step: 1, loss is 2.3175418376922607\n",
      "epoch: 1 step: 2, loss is 2.2908544540405273\n",
      "epoch: 1 step: 3, loss is 2.2934257984161377\n",
      "epoch: 1 step: 4, loss is 2.294602155685425\n",
      "epoch: 1 step: 5, loss is 2.30145263671875\n",
      "epoch: 1 step: 6, loss is 2.302452802658081\n",
      "epoch: 1 step: 7, loss is 2.297163963317871\n",
      "epoch: 1 step: 8, loss is 2.302682876586914\n",
      "epoch: 1 step: 9, loss is 2.290586471557617\n",
      "epoch: 1 step: 10, loss is 2.294130802154541\n",
      "epoch: 1 step: 11, loss is 2.2916743755340576\n",
      "epoch: 1 step: 12, loss is 2.288522481918335\n",
      "epoch: 1 step: 13, loss is 2.2780914306640625\n",
      "epoch: 1 step: 14, loss is 2.2650272846221924\n",
      "epoch: 1 step: 15, loss is 2.2725777626037598\n",
      "epoch: 1 step: 16, loss is 2.28691029548645\n",
      "epoch: 1 step: 17, loss is 2.2750027179718018\n",
      "epoch: 1 step: 18, loss is 2.2607781887054443\n",
      "epoch: 1 step: 19, loss is 2.254864454269409\n",
      "epoch: 1 step: 20, loss is 2.241610527038574\n",
      "epoch: 1 step: 21, loss is 2.293060541152954\n",
      "epoch: 1 step: 22, loss is 2.3006386756896973\n",
      "epoch: 1 step: 23, loss is 2.2277445793151855\n",
      "epoch: 1 step: 24, loss is 2.2507224082946777\n",
      "epoch: 1 step: 25, loss is 2.26584529876709\n",
      "epoch: 1 step: 26, loss is 2.207688570022583\n",
      "epoch: 1 step: 27, loss is 2.246142864227295\n",
      "epoch: 1 step: 28, loss is 2.1804263591766357\n",
      "epoch: 1 step: 29, loss is 2.205709934234619\n",
      "epoch: 1 step: 30, loss is 2.182378053665161\n",
      "epoch: 1 step: 31, loss is 2.1874959468841553\n",
      "epoch: 1 step: 32, loss is 2.1799676418304443\n",
      "epoch: 1 step: 33, loss is 2.1516172885894775\n",
      "epoch: 1 step: 34, loss is 2.1759090423583984\n",
      "epoch: 1 step: 35, loss is 2.091303586959839\n",
      "epoch: 1 step: 36, loss is 2.0355770587921143\n",
      "epoch: 1 step: 37, loss is 2.031902551651001\n",
      "epoch: 1 step: 38, loss is 2.1715197563171387\n",
      "epoch: 1 step: 39, loss is 2.0977978706359863\n",
      "epoch: 1 step: 40, loss is 1.847468376159668\n",
      "epoch: 1 step: 41, loss is 1.9373332262039185\n",
      "epoch: 1 step: 42, loss is 1.7957099676132202\n",
      "epoch: 1 step: 43, loss is 1.6619372367858887\n",
      "epoch: 1 step: 44, loss is 1.7876548767089844\n",
      "epoch: 1 step: 45, loss is 1.4743096828460693\n",
      "epoch: 1 step: 46, loss is 1.3926582336425781\n",
      "epoch: 1 step: 47, loss is 1.644524335861206\n",
      "epoch: 1 step: 48, loss is 1.5712941884994507\n",
      "epoch: 1 step: 49, loss is 1.4531804323196411\n",
      "epoch: 1 step: 50, loss is 1.4712989330291748\n",
      "epoch: 1 step: 51, loss is 1.5175998210906982\n",
      "epoch: 1 step: 52, loss is 1.0682088136672974\n",
      "epoch: 1 step: 53, loss is 1.2217460870742798\n",
      "epoch: 1 step: 54, loss is 1.404093623161316\n",
      "epoch: 1 step: 55, loss is 1.1594278812408447\n",
      "epoch: 1 step: 56, loss is 2.0518457889556885\n",
      "epoch: 1 step: 57, loss is 1.2329230308532715\n",
      "epoch: 1 step: 58, loss is 1.3202353715896606\n",
      "epoch: 1 step: 59, loss is 1.4918452501296997\n",
      "epoch: 1 step: 60, loss is 1.5973533391952515\n",
      "epoch: 1 step: 61, loss is 1.2983890771865845\n",
      "epoch: 1 step: 62, loss is 1.6098568439483643\n",
      "epoch: 1 step: 63, loss is 1.0366758108139038\n",
      "epoch: 1 step: 64, loss is 1.334513545036316\n",
      "epoch: 1 step: 65, loss is 1.1339484453201294\n",
      "epoch: 1 step: 66, loss is 1.006945013999939\n",
      "epoch: 1 step: 67, loss is 1.2731263637542725\n",
      "epoch: 1 step: 68, loss is 0.8735068440437317\n",
      "epoch: 1 step: 69, loss is 0.9313348531723022\n",
      "epoch: 1 step: 70, loss is 0.9026170969009399\n",
      "epoch: 1 step: 71, loss is 0.9875935316085815\n",
      "epoch: 1 step: 72, loss is 0.6135706305503845\n",
      "epoch: 1 step: 73, loss is 0.8015072345733643\n",
      "epoch: 1 step: 74, loss is 0.9319887757301331\n",
      "epoch: 1 step: 75, loss is 0.7010061740875244\n",
      "epoch: 1 step: 76, loss is 0.6858168244361877\n",
      "epoch: 1 step: 77, loss is 0.7580164670944214\n",
      "epoch: 1 step: 78, loss is 0.8264782428741455\n",
      "epoch: 1 step: 79, loss is 0.7353325486183167\n",
      "epoch: 1 step: 80, loss is 0.974868893623352\n",
      "epoch: 1 step: 81, loss is 0.546840250492096\n",
      "epoch: 1 step: 82, loss is 0.6174237728118896\n",
      "epoch: 1 step: 83, loss is 0.5456783175468445\n",
      "epoch: 1 step: 84, loss is 1.0396517515182495\n",
      "epoch: 1 step: 85, loss is 0.8463142514228821\n",
      "epoch: 1 step: 86, loss is 0.8029271364212036\n",
      "epoch: 1 step: 87, loss is 0.3161952495574951\n",
      "epoch: 1 step: 88, loss is 0.920139729976654\n",
      "epoch: 1 step: 89, loss is 1.0269814729690552\n",
      "epoch: 1 step: 90, loss is 0.7351927757263184\n",
      "epoch: 1 step: 91, loss is 1.3856700658798218\n",
      "epoch: 1 step: 92, loss is 0.6388897895812988\n",
      "epoch: 1 step: 93, loss is 0.8796858787536621\n",
      "epoch: 1 step: 94, loss is 0.4826388359069824\n",
      "epoch: 1 step: 95, loss is 0.9781092405319214\n",
      "epoch: 1 step: 96, loss is 0.5574085712432861\n",
      "epoch: 1 step: 97, loss is 0.7047361731529236\n",
      "epoch: 1 step: 98, loss is 0.7510011792182922\n",
      "epoch: 1 step: 99, loss is 0.5397630929946899\n",
      "epoch: 1 step: 100, loss is 0.6118126511573792\n",
      "epoch: 1 step: 101, loss is 0.606071412563324\n",
      "epoch: 1 step: 102, loss is 0.4720498323440552\n",
      "epoch: 1 step: 103, loss is 0.7547380328178406\n",
      "epoch: 1 step: 104, loss is 0.5720964670181274\n",
      "epoch: 1 step: 105, loss is 0.3202435076236725\n",
      "epoch: 1 step: 106, loss is 0.2983555495738983\n",
      "epoch: 1 step: 107, loss is 0.7801538705825806\n",
      "epoch: 1 step: 108, loss is 0.4524952173233032\n",
      "epoch: 1 step: 109, loss is 0.7267738580703735\n",
      "epoch: 1 step: 110, loss is 0.7566455602645874\n",
      "epoch: 1 step: 111, loss is 0.716666579246521\n",
      "epoch: 1 step: 112, loss is 0.9082701206207275\n",
      "epoch: 1 step: 113, loss is 0.559441328048706\n",
      "epoch: 1 step: 114, loss is 0.5823757648468018\n",
      "epoch: 1 step: 115, loss is 0.4405117928981781\n",
      "epoch: 1 step: 116, loss is 0.5618816614151001\n",
      "epoch: 1 step: 117, loss is 0.5875471830368042\n",
      "epoch: 1 step: 118, loss is 0.622036337852478\n",
      "epoch: 1 step: 119, loss is 0.5784927010536194\n",
      "epoch: 1 step: 120, loss is 0.20969541370868683\n",
      "epoch: 1 step: 121, loss is 0.5863214731216431\n",
      "epoch: 1 step: 122, loss is 0.44111964106559753\n",
      "epoch: 1 step: 123, loss is 0.38225844502449036\n",
      "epoch: 1 step: 124, loss is 0.3960413634777069\n",
      "epoch: 1 step: 125, loss is 0.3975468873977661\n",
      "epoch: 1 step: 126, loss is 0.18171431124210358\n",
      "epoch: 1 step: 127, loss is 0.293552428483963\n",
      "epoch: 1 step: 128, loss is 0.7025222778320312\n",
      "epoch: 1 step: 129, loss is 0.370598167181015\n",
      "epoch: 1 step: 130, loss is 0.3170435428619385\n",
      "epoch: 1 step: 131, loss is 0.873563289642334\n",
      "epoch: 1 step: 132, loss is 0.37950456142425537\n",
      "epoch: 1 step: 133, loss is 0.3277991712093353\n",
      "epoch: 1 step: 134, loss is 0.28230705857276917\n",
      "epoch: 1 step: 135, loss is 0.29792216420173645\n",
      "epoch: 1 step: 136, loss is 0.18513689935207367\n",
      "epoch: 1 step: 137, loss is 0.11702938377857208\n",
      "epoch: 1 step: 138, loss is 0.11354537308216095\n",
      "epoch: 1 step: 139, loss is 0.2570441961288452\n",
      "epoch: 1 step: 140, loss is 0.4532487094402313\n",
      "epoch: 1 step: 141, loss is 0.5412837862968445\n",
      "epoch: 1 step: 142, loss is 0.5205171704292297\n",
      "epoch: 1 step: 143, loss is 0.1027718037366867\n",
      "epoch: 1 step: 144, loss is 0.34402406215667725\n",
      "epoch: 1 step: 145, loss is 0.7105377316474915\n",
      "epoch: 1 step: 146, loss is 0.24150781333446503\n",
      "epoch: 1 step: 147, loss is 0.3553943932056427\n",
      "epoch: 1 step: 148, loss is 0.46727991104125977\n",
      "epoch: 1 step: 149, loss is 0.2971290349960327\n",
      "epoch: 1 step: 150, loss is 0.30821970105171204\n",
      "epoch: 1 step: 151, loss is 0.4525424838066101\n",
      "epoch: 1 step: 152, loss is 0.3927713930606842\n",
      "epoch: 1 step: 153, loss is 0.3601992428302765\n",
      "epoch: 1 step: 154, loss is 0.22618833184242249\n",
      "epoch: 1 step: 155, loss is 0.47138354182243347\n",
      "epoch: 1 step: 156, loss is 0.20612512528896332\n",
      "epoch: 1 step: 157, loss is 0.442126989364624\n",
      "epoch: 1 step: 158, loss is 0.3348536193370819\n",
      "epoch: 1 step: 159, loss is 0.7171785235404968\n",
      "epoch: 1 step: 160, loss is 0.2680074870586395\n",
      "epoch: 1 step: 161, loss is 0.8051742911338806\n",
      "epoch: 1 step: 162, loss is 0.5005913376808167\n",
      "epoch: 1 step: 163, loss is 0.9733699560165405\n",
      "epoch: 1 step: 164, loss is 0.32516637444496155\n",
      "epoch: 1 step: 165, loss is 0.3360372483730316\n",
      "epoch: 1 step: 166, loss is 0.35474327206611633\n",
      "epoch: 1 step: 167, loss is 0.40739211440086365\n",
      "epoch: 1 step: 168, loss is 0.47661685943603516\n",
      "epoch: 1 step: 169, loss is 0.23857131600379944\n",
      "epoch: 1 step: 170, loss is 0.49369001388549805\n",
      "epoch: 1 step: 171, loss is 0.3707466423511505\n",
      "epoch: 1 step: 172, loss is 0.23667852580547333\n",
      "epoch: 1 step: 173, loss is 0.411373108625412\n",
      "epoch: 1 step: 174, loss is 0.31618836522102356\n",
      "epoch: 1 step: 175, loss is 0.4210568070411682\n",
      "epoch: 1 step: 176, loss is 0.4050482213497162\n",
      "epoch: 1 step: 177, loss is 0.29479700326919556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 178, loss is 0.3171994090080261\n",
      "epoch: 1 step: 179, loss is 0.19484888017177582\n",
      "epoch: 1 step: 180, loss is 0.12460707128047943\n",
      "epoch: 1 step: 181, loss is 0.3381057381629944\n",
      "epoch: 1 step: 182, loss is 0.44577330350875854\n",
      "epoch: 1 step: 183, loss is 0.3857579529285431\n",
      "epoch: 1 step: 184, loss is 0.4843492805957794\n",
      "epoch: 1 step: 185, loss is 0.21111765503883362\n",
      "epoch: 1 step: 186, loss is 0.13970337808132172\n",
      "epoch: 1 step: 187, loss is 0.271420955657959\n",
      "epoch: 1 step: 188, loss is 0.38114622235298157\n",
      "epoch: 1 step: 189, loss is 0.0730481743812561\n",
      "epoch: 1 step: 190, loss is 0.5099272727966309\n",
      "epoch: 1 step: 191, loss is 0.06591972708702087\n",
      "epoch: 1 step: 192, loss is 0.182000532746315\n",
      "epoch: 1 step: 193, loss is 0.19786794483661652\n",
      "epoch: 1 step: 194, loss is 0.16851435601711273\n",
      "epoch: 1 step: 195, loss is 0.3402138948440552\n",
      "epoch: 1 step: 196, loss is 0.38784852623939514\n",
      "epoch: 1 step: 197, loss is 0.5421263575553894\n",
      "epoch: 1 step: 198, loss is 0.22906368970870972\n",
      "epoch: 1 step: 199, loss is 0.22416695952415466\n",
      "epoch: 1 step: 200, loss is 0.18304072320461273\n",
      "epoch: 1 step: 201, loss is 0.4095975458621979\n",
      "epoch: 1 step: 202, loss is 0.3281824588775635\n",
      "epoch: 1 step: 203, loss is 0.1683480590581894\n",
      "epoch: 1 step: 204, loss is 0.35704511404037476\n",
      "epoch: 1 step: 205, loss is 0.5798599123954773\n",
      "epoch: 1 step: 206, loss is 0.07350669801235199\n",
      "epoch: 1 step: 207, loss is 0.24320757389068604\n",
      "epoch: 1 step: 208, loss is 0.5102852582931519\n",
      "epoch: 1 step: 209, loss is 0.35682353377342224\n",
      "epoch: 1 step: 210, loss is 0.30482518672943115\n",
      "epoch: 1 step: 211, loss is 0.08668193966150284\n",
      "epoch: 1 step: 212, loss is 0.1311597228050232\n",
      "epoch: 1 step: 213, loss is 0.08385451883077621\n",
      "epoch: 1 step: 214, loss is 0.4436822235584259\n",
      "epoch: 1 step: 215, loss is 0.26842281222343445\n",
      "epoch: 1 step: 216, loss is 0.1369004249572754\n",
      "epoch: 1 step: 217, loss is 0.41025981307029724\n",
      "epoch: 1 step: 218, loss is 0.11679280549287796\n",
      "epoch: 1 step: 219, loss is 0.31639963388442993\n",
      "epoch: 1 step: 220, loss is 0.16945526003837585\n",
      "epoch: 1 step: 221, loss is 0.1688651293516159\n",
      "epoch: 1 step: 222, loss is 0.20403173565864563\n",
      "epoch: 1 step: 223, loss is 0.19161948561668396\n",
      "epoch: 1 step: 224, loss is 0.16644072532653809\n",
      "epoch: 1 step: 225, loss is 0.4298224449157715\n",
      "epoch: 1 step: 226, loss is 0.16194471716880798\n",
      "epoch: 1 step: 227, loss is 0.23499788343906403\n",
      "epoch: 1 step: 228, loss is 0.08700654655694962\n",
      "epoch: 1 step: 229, loss is 0.2637394666671753\n",
      "epoch: 1 step: 230, loss is 0.433631956577301\n",
      "epoch: 1 step: 231, loss is 0.41027596592903137\n",
      "epoch: 1 step: 232, loss is 0.21629838645458221\n",
      "epoch: 1 step: 233, loss is 0.22090323269367218\n",
      "epoch: 1 step: 234, loss is 0.14308486878871918\n",
      "epoch: 1 step: 235, loss is 0.18427343666553497\n",
      "epoch: 1 step: 236, loss is 0.23738153278827667\n",
      "epoch: 1 step: 237, loss is 0.20132789015769958\n",
      "epoch: 1 step: 238, loss is 0.28211888670921326\n",
      "epoch: 1 step: 239, loss is 0.4446195363998413\n",
      "epoch: 1 step: 240, loss is 0.49313580989837646\n",
      "epoch: 1 step: 241, loss is 0.34892112016677856\n",
      "epoch: 1 step: 242, loss is 0.09343215823173523\n",
      "epoch: 1 step: 243, loss is 0.22496020793914795\n",
      "epoch: 1 step: 244, loss is 0.18704867362976074\n",
      "epoch: 1 step: 245, loss is 0.11238659173250198\n",
      "epoch: 1 step: 246, loss is 0.2459544837474823\n",
      "epoch: 1 step: 247, loss is 0.28769391775131226\n",
      "epoch: 1 step: 248, loss is 0.13381649553775787\n",
      "epoch: 1 step: 249, loss is 0.22008274495601654\n",
      "epoch: 1 step: 250, loss is 0.18215112388134003\n",
      "epoch: 1 step: 251, loss is 0.05730640888214111\n",
      "epoch: 1 step: 252, loss is 0.32168060541152954\n",
      "epoch: 1 step: 253, loss is 0.2483561784029007\n",
      "epoch: 1 step: 254, loss is 0.1349961906671524\n",
      "epoch: 1 step: 255, loss is 0.18781957030296326\n",
      "epoch: 1 step: 256, loss is 0.2963232398033142\n",
      "epoch: 1 step: 257, loss is 0.2625424861907959\n",
      "epoch: 1 step: 258, loss is 0.09552006423473358\n",
      "epoch: 1 step: 259, loss is 0.17659462988376617\n",
      "epoch: 1 step: 260, loss is 0.13359476625919342\n",
      "epoch: 1 step: 261, loss is 0.3197508454322815\n",
      "epoch: 1 step: 262, loss is 0.1752696931362152\n",
      "epoch: 1 step: 263, loss is 0.36164823174476624\n",
      "epoch: 1 step: 264, loss is 0.09864076226949692\n",
      "epoch: 1 step: 265, loss is 0.37782397866249084\n",
      "epoch: 1 step: 266, loss is 0.17577525973320007\n",
      "epoch: 1 step: 267, loss is 0.14000681042671204\n",
      "epoch: 1 step: 268, loss is 0.3371841311454773\n",
      "epoch: 1 step: 269, loss is 0.4703980088233948\n",
      "epoch: 1 step: 270, loss is 0.2736318111419678\n",
      "epoch: 1 step: 271, loss is 0.1019330844283104\n",
      "epoch: 1 step: 272, loss is 0.10382860153913498\n",
      "epoch: 1 step: 273, loss is 0.2370898723602295\n",
      "epoch: 1 step: 274, loss is 0.1162853091955185\n",
      "epoch: 1 step: 275, loss is 0.24805426597595215\n",
      "epoch: 1 step: 276, loss is 0.16943161189556122\n",
      "epoch: 1 step: 277, loss is 0.15452460944652557\n",
      "epoch: 1 step: 278, loss is 0.11183533817529678\n",
      "epoch: 1 step: 279, loss is 0.22407718002796173\n",
      "epoch: 1 step: 280, loss is 0.2301005721092224\n",
      "epoch: 1 step: 281, loss is 0.08086030185222626\n",
      "epoch: 1 step: 282, loss is 0.11917596310377121\n",
      "epoch: 1 step: 283, loss is 0.10907353460788727\n",
      "epoch: 1 step: 284, loss is 0.2578270137310028\n",
      "epoch: 1 step: 285, loss is 0.16806674003601074\n",
      "epoch: 1 step: 286, loss is 0.2669854760169983\n",
      "epoch: 1 step: 287, loss is 0.09988421201705933\n",
      "epoch: 1 step: 288, loss is 0.1596585065126419\n",
      "epoch: 1 step: 289, loss is 0.11607625335454941\n",
      "epoch: 1 step: 290, loss is 0.08603616803884506\n",
      "epoch: 1 step: 291, loss is 0.05189337208867073\n",
      "epoch: 1 step: 292, loss is 0.11783679574728012\n",
      "epoch: 1 step: 293, loss is 0.29529252648353577\n",
      "epoch: 1 step: 294, loss is 0.2752448618412018\n",
      "epoch: 1 step: 295, loss is 0.204662024974823\n",
      "epoch: 1 step: 296, loss is 0.23136183619499207\n",
      "epoch: 1 step: 297, loss is 0.6555410027503967\n",
      "epoch: 1 step: 298, loss is 0.06940391659736633\n",
      "epoch: 1 step: 299, loss is 0.0634239912033081\n",
      "epoch: 1 step: 300, loss is 0.48190587759017944\n",
      "epoch: 1 step: 301, loss is 0.5663076639175415\n",
      "epoch: 1 step: 302, loss is 0.3704090118408203\n",
      "epoch: 1 step: 303, loss is 0.07334533333778381\n",
      "epoch: 1 step: 304, loss is 0.09098739176988602\n",
      "epoch: 1 step: 305, loss is 0.15101400017738342\n",
      "epoch: 1 step: 306, loss is 0.32517650723457336\n",
      "epoch: 1 step: 307, loss is 0.05853941664099693\n",
      "epoch: 1 step: 308, loss is 0.24975882470607758\n",
      "epoch: 1 step: 309, loss is 0.09925667941570282\n",
      "epoch: 1 step: 310, loss is 0.865217387676239\n",
      "epoch: 1 step: 311, loss is 0.030967634171247482\n",
      "epoch: 1 step: 312, loss is 0.3886668384075165\n",
      "epoch: 1 step: 313, loss is 0.08837807178497314\n",
      "epoch: 1 step: 314, loss is 0.1968039572238922\n",
      "epoch: 1 step: 315, loss is 0.30188098549842834\n",
      "epoch: 1 step: 316, loss is 0.22518134117126465\n",
      "epoch: 1 step: 317, loss is 0.20836134254932404\n",
      "epoch: 1 step: 318, loss is 0.14337371289730072\n",
      "epoch: 1 step: 319, loss is 0.3125492036342621\n",
      "epoch: 1 step: 320, loss is 0.5289171934127808\n",
      "epoch: 1 step: 321, loss is 0.3228837251663208\n",
      "epoch: 1 step: 322, loss is 0.17632943391799927\n",
      "epoch: 1 step: 323, loss is 0.39853808283805847\n",
      "epoch: 1 step: 324, loss is 0.15022394061088562\n",
      "epoch: 1 step: 325, loss is 0.30129900574684143\n",
      "epoch: 1 step: 326, loss is 0.24605892598628998\n",
      "epoch: 1 step: 327, loss is 0.2399788200855255\n",
      "epoch: 1 step: 328, loss is 0.29397648572921753\n",
      "epoch: 1 step: 329, loss is 0.05073109269142151\n",
      "epoch: 1 step: 330, loss is 0.1943701058626175\n",
      "epoch: 1 step: 331, loss is 0.186749666929245\n",
      "epoch: 1 step: 332, loss is 0.07661106437444687\n",
      "epoch: 1 step: 333, loss is 0.10346318781375885\n",
      "epoch: 1 step: 334, loss is 0.4952208995819092\n",
      "epoch: 1 step: 335, loss is 0.23301248252391815\n",
      "epoch: 1 step: 336, loss is 0.27926161885261536\n",
      "epoch: 1 step: 337, loss is 0.17115075886249542\n",
      "epoch: 1 step: 338, loss is 0.11761052906513214\n",
      "epoch: 1 step: 339, loss is 0.24857407808303833\n",
      "epoch: 1 step: 340, loss is 0.22485415637493134\n",
      "epoch: 1 step: 341, loss is 0.1670868992805481\n",
      "epoch: 1 step: 342, loss is 0.14479312300682068\n",
      "epoch: 1 step: 343, loss is 0.3688966631889343\n",
      "epoch: 1 step: 344, loss is 0.057753365486860275\n",
      "epoch: 1 step: 345, loss is 0.04185975342988968\n",
      "epoch: 1 step: 346, loss is 0.11003182828426361\n",
      "epoch: 1 step: 347, loss is 0.030625637620687485\n",
      "epoch: 1 step: 348, loss is 0.5322091579437256\n",
      "epoch: 1 step: 349, loss is 0.18819159269332886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 350, loss is 0.15100015699863434\n",
      "epoch: 1 step: 351, loss is 0.178117036819458\n",
      "epoch: 1 step: 352, loss is 0.19426289200782776\n",
      "epoch: 1 step: 353, loss is 0.13013839721679688\n",
      "epoch: 1 step: 354, loss is 0.02224874123930931\n",
      "epoch: 1 step: 355, loss is 0.1651298999786377\n",
      "epoch: 1 step: 356, loss is 0.13923370838165283\n",
      "epoch: 1 step: 357, loss is 0.09570399671792984\n",
      "epoch: 1 step: 358, loss is 0.17957375943660736\n",
      "epoch: 1 step: 359, loss is 0.7028428316116333\n",
      "epoch: 1 step: 360, loss is 0.257169634103775\n",
      "epoch: 1 step: 361, loss is 0.05880412459373474\n",
      "epoch: 1 step: 362, loss is 0.11625021696090698\n",
      "epoch: 1 step: 363, loss is 0.40064123272895813\n",
      "epoch: 1 step: 364, loss is 0.4207502007484436\n",
      "epoch: 1 step: 365, loss is 0.3292776346206665\n",
      "epoch: 1 step: 366, loss is 0.03021877259016037\n",
      "epoch: 1 step: 367, loss is 0.20577846467494965\n",
      "epoch: 1 step: 368, loss is 0.07347355782985687\n",
      "epoch: 1 step: 369, loss is 0.21268638968467712\n",
      "epoch: 1 step: 370, loss is 0.25891658663749695\n",
      "epoch: 1 step: 371, loss is 0.07757827639579773\n",
      "epoch: 1 step: 372, loss is 0.03909033536911011\n",
      "epoch: 1 step: 373, loss is 0.20687083899974823\n",
      "epoch: 1 step: 374, loss is 0.145162895321846\n",
      "epoch: 1 step: 375, loss is 0.04964491352438927\n",
      "epoch: 1 step: 376, loss is 0.23767706751823425\n",
      "epoch: 1 step: 377, loss is 0.20324569940567017\n",
      "epoch: 1 step: 378, loss is 0.3009102940559387\n",
      "epoch: 1 step: 379, loss is 0.07085735350847244\n",
      "epoch: 1 step: 380, loss is 0.11008820682764053\n",
      "epoch: 1 step: 381, loss is 0.13192835450172424\n",
      "epoch: 1 step: 382, loss is 0.1185617446899414\n",
      "epoch: 1 step: 383, loss is 0.4087490439414978\n",
      "epoch: 1 step: 384, loss is 0.2649782598018646\n",
      "epoch: 1 step: 385, loss is 0.6200593113899231\n",
      "epoch: 1 step: 386, loss is 0.2587627172470093\n",
      "epoch: 1 step: 387, loss is 0.30526918172836304\n",
      "epoch: 1 step: 388, loss is 0.037917669862508774\n",
      "epoch: 1 step: 389, loss is 0.06533776223659515\n",
      "epoch: 1 step: 390, loss is 0.2122301459312439\n",
      "epoch: 1 step: 391, loss is 0.063897043466568\n",
      "epoch: 1 step: 392, loss is 0.32544875144958496\n",
      "epoch: 1 step: 393, loss is 0.23513956367969513\n",
      "epoch: 1 step: 394, loss is 0.13928864896297455\n",
      "epoch: 1 step: 395, loss is 0.18091222643852234\n",
      "epoch: 1 step: 396, loss is 0.17940111458301544\n",
      "epoch: 1 step: 397, loss is 0.13688190281391144\n",
      "epoch: 1 step: 398, loss is 0.4313735365867615\n",
      "epoch: 1 step: 399, loss is 0.05932013690471649\n",
      "epoch: 1 step: 400, loss is 0.37120357155799866\n",
      "epoch: 1 step: 401, loss is 0.3484007716178894\n",
      "epoch: 1 step: 402, loss is 0.063887819647789\n",
      "epoch: 1 step: 403, loss is 0.10918385535478592\n",
      "epoch: 1 step: 404, loss is 0.15831992030143738\n",
      "epoch: 1 step: 405, loss is 0.11790110170841217\n",
      "epoch: 1 step: 406, loss is 0.355755090713501\n",
      "epoch: 1 step: 407, loss is 0.12146714329719543\n",
      "epoch: 1 step: 408, loss is 0.10114014148712158\n",
      "epoch: 1 step: 409, loss is 0.32643812894821167\n",
      "epoch: 1 step: 410, loss is 0.033123429864645004\n",
      "epoch: 1 step: 411, loss is 0.13422326743602753\n",
      "epoch: 1 step: 412, loss is 0.1292591094970703\n",
      "epoch: 1 step: 413, loss is 0.3350502550601959\n",
      "epoch: 1 step: 414, loss is 0.13996858894824982\n",
      "epoch: 1 step: 415, loss is 0.09432101994752884\n",
      "epoch: 1 step: 416, loss is 0.07609251141548157\n",
      "epoch: 1 step: 417, loss is 0.19150708615779877\n",
      "epoch: 1 step: 418, loss is 0.012651784345507622\n",
      "epoch: 1 step: 419, loss is 0.04182575270533562\n",
      "epoch: 1 step: 420, loss is 0.14638188481330872\n",
      "epoch: 1 step: 421, loss is 0.0751120075583458\n",
      "epoch: 1 step: 422, loss is 0.16616810858249664\n",
      "epoch: 1 step: 423, loss is 0.033731505274772644\n",
      "epoch: 1 step: 424, loss is 0.08632350713014603\n",
      "epoch: 1 step: 425, loss is 0.22973687946796417\n",
      "epoch: 1 step: 426, loss is 0.576037585735321\n",
      "epoch: 1 step: 427, loss is 0.05792661011219025\n",
      "epoch: 1 step: 428, loss is 0.04394634813070297\n",
      "epoch: 1 step: 429, loss is 0.12968710064888\n",
      "epoch: 1 step: 430, loss is 0.1527213752269745\n",
      "epoch: 1 step: 431, loss is 0.1119287982583046\n",
      "epoch: 1 step: 432, loss is 0.2171502411365509\n",
      "epoch: 1 step: 433, loss is 0.05358494818210602\n",
      "epoch: 1 step: 434, loss is 0.17598815262317657\n",
      "epoch: 1 step: 435, loss is 0.08692483603954315\n",
      "epoch: 1 step: 436, loss is 0.11726848036050797\n",
      "epoch: 1 step: 437, loss is 0.30310654640197754\n",
      "epoch: 1 step: 438, loss is 0.047401752322912216\n",
      "epoch: 1 step: 439, loss is 0.16699232161045074\n",
      "epoch: 1 step: 440, loss is 0.08043239265680313\n",
      "epoch: 1 step: 441, loss is 0.0451098196208477\n",
      "epoch: 1 step: 442, loss is 0.05500231683254242\n",
      "epoch: 1 step: 443, loss is 0.0392165444791317\n",
      "epoch: 1 step: 444, loss is 0.5666540861129761\n",
      "epoch: 1 step: 445, loss is 0.027122976258397102\n",
      "epoch: 1 step: 446, loss is 0.38827285170555115\n",
      "epoch: 1 step: 447, loss is 0.029146023094654083\n",
      "epoch: 1 step: 448, loss is 0.041637420654296875\n",
      "epoch: 1 step: 449, loss is 0.3927779793739319\n",
      "epoch: 1 step: 450, loss is 0.31882965564727783\n",
      "epoch: 1 step: 451, loss is 0.09863525629043579\n",
      "epoch: 1 step: 452, loss is 0.2920491397380829\n",
      "epoch: 1 step: 453, loss is 0.05271214619278908\n",
      "epoch: 1 step: 454, loss is 0.021118560805916786\n",
      "epoch: 1 step: 455, loss is 0.15797275304794312\n",
      "epoch: 1 step: 456, loss is 0.22906117141246796\n",
      "epoch: 1 step: 457, loss is 0.29570242762565613\n",
      "epoch: 1 step: 458, loss is 0.223746195435524\n",
      "epoch: 1 step: 459, loss is 0.13028192520141602\n",
      "epoch: 1 step: 460, loss is 0.2573194205760956\n",
      "epoch: 1 step: 461, loss is 0.2662920355796814\n",
      "epoch: 1 step: 462, loss is 0.022065531462430954\n",
      "epoch: 1 step: 463, loss is 0.07814203202724457\n",
      "epoch: 1 step: 464, loss is 0.2670292258262634\n",
      "epoch: 1 step: 465, loss is 0.07685360312461853\n",
      "epoch: 1 step: 466, loss is 0.11393282562494278\n",
      "epoch: 1 step: 467, loss is 0.2259562611579895\n",
      "epoch: 1 step: 468, loss is 0.04226590692996979\n",
      "epoch: 1 step: 469, loss is 0.050052326172590256\n",
      "epoch: 1 step: 470, loss is 0.11466081440448761\n",
      "epoch: 1 step: 471, loss is 0.07378344982862473\n",
      "epoch: 1 step: 472, loss is 0.08200564235448837\n",
      "epoch: 1 step: 473, loss is 0.19986048340797424\n",
      "epoch: 1 step: 474, loss is 0.15793731808662415\n",
      "epoch: 1 step: 475, loss is 0.1004333421587944\n",
      "epoch: 1 step: 476, loss is 0.2006312906742096\n",
      "epoch: 1 step: 477, loss is 0.030221296474337578\n",
      "epoch: 1 step: 478, loss is 0.1064210757613182\n",
      "epoch: 1 step: 479, loss is 0.050465378910303116\n",
      "epoch: 1 step: 480, loss is 0.14268912374973297\n",
      "epoch: 1 step: 481, loss is 0.05031504109501839\n",
      "epoch: 1 step: 482, loss is 0.23204781115055084\n",
      "epoch: 1 step: 483, loss is 0.3759137988090515\n",
      "epoch: 1 step: 484, loss is 0.04043695330619812\n",
      "epoch: 1 step: 485, loss is 0.5286310911178589\n",
      "epoch: 1 step: 486, loss is 0.3172118365764618\n",
      "epoch: 1 step: 487, loss is 0.07916204631328583\n",
      "epoch: 1 step: 488, loss is 0.23013116419315338\n",
      "epoch: 1 step: 489, loss is 0.21549692749977112\n",
      "epoch: 1 step: 490, loss is 0.01749805174767971\n",
      "epoch: 1 step: 491, loss is 0.10456760227680206\n",
      "epoch: 1 step: 492, loss is 0.18691854178905487\n",
      "epoch: 1 step: 493, loss is 0.22638630867004395\n",
      "epoch: 1 step: 494, loss is 0.2657374143600464\n",
      "epoch: 1 step: 495, loss is 0.0820007398724556\n",
      "epoch: 1 step: 496, loss is 0.3269454836845398\n",
      "epoch: 1 step: 497, loss is 0.08251889795064926\n",
      "epoch: 1 step: 498, loss is 0.02450823225080967\n",
      "epoch: 1 step: 499, loss is 0.23111774027347565\n",
      "epoch: 1 step: 500, loss is 0.26234617829322815\n",
      "epoch: 1 step: 501, loss is 0.17657718062400818\n",
      "epoch: 1 step: 502, loss is 0.18105217814445496\n",
      "epoch: 1 step: 503, loss is 0.28920185565948486\n",
      "epoch: 1 step: 504, loss is 0.18450741469860077\n",
      "epoch: 1 step: 505, loss is 0.07026904076337814\n",
      "epoch: 1 step: 506, loss is 0.2209358960390091\n",
      "epoch: 1 step: 507, loss is 0.1468586027622223\n",
      "epoch: 1 step: 508, loss is 0.5282381176948547\n",
      "epoch: 1 step: 509, loss is 0.2863159775733948\n",
      "epoch: 1 step: 510, loss is 0.09168807417154312\n",
      "epoch: 1 step: 511, loss is 0.042605649679899216\n",
      "epoch: 1 step: 512, loss is 0.047232337296009064\n",
      "epoch: 1 step: 513, loss is 0.32931405305862427\n",
      "epoch: 1 step: 514, loss is 0.03920011594891548\n",
      "epoch: 1 step: 515, loss is 0.10831332206726074\n",
      "epoch: 1 step: 516, loss is 0.1366083025932312\n",
      "epoch: 1 step: 517, loss is 0.17408113181591034\n",
      "epoch: 1 step: 518, loss is 0.16720741987228394\n",
      "epoch: 1 step: 519, loss is 0.2062828093767166\n",
      "epoch: 1 step: 520, loss is 0.18398508429527283\n",
      "epoch: 1 step: 521, loss is 0.11492184549570084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 522, loss is 0.10779721289873123\n",
      "epoch: 1 step: 523, loss is 0.24831610918045044\n",
      "epoch: 1 step: 524, loss is 0.1394273042678833\n",
      "epoch: 1 step: 525, loss is 0.09465250372886658\n",
      "epoch: 1 step: 526, loss is 0.2404889166355133\n",
      "epoch: 1 step: 527, loss is 0.13177050650119781\n",
      "epoch: 1 step: 528, loss is 0.21349062025547028\n",
      "epoch: 1 step: 529, loss is 0.1194353699684143\n",
      "epoch: 1 step: 530, loss is 0.2565283179283142\n",
      "epoch: 1 step: 531, loss is 0.039831675589084625\n",
      "epoch: 1 step: 532, loss is 0.08793859928846359\n",
      "epoch: 1 step: 533, loss is 0.15323005616664886\n",
      "epoch: 1 step: 534, loss is 0.06748926639556885\n",
      "epoch: 1 step: 535, loss is 0.2148684561252594\n",
      "epoch: 1 step: 536, loss is 0.4421308934688568\n",
      "epoch: 1 step: 537, loss is 0.041479241102933884\n",
      "epoch: 1 step: 538, loss is 0.05381716415286064\n",
      "epoch: 1 step: 539, loss is 0.06971662491559982\n",
      "epoch: 1 step: 540, loss is 0.07796497642993927\n",
      "epoch: 1 step: 541, loss is 0.10505308955907822\n",
      "epoch: 1 step: 542, loss is 0.12726730108261108\n",
      "epoch: 1 step: 543, loss is 0.028174031525850296\n",
      "epoch: 1 step: 544, loss is 0.20734262466430664\n",
      "epoch: 1 step: 545, loss is 0.14722426235675812\n",
      "epoch: 1 step: 546, loss is 0.018981633707880974\n",
      "epoch: 1 step: 547, loss is 0.30173036456108093\n",
      "epoch: 1 step: 548, loss is 0.15655989944934845\n",
      "epoch: 1 step: 549, loss is 0.3115261495113373\n",
      "epoch: 1 step: 550, loss is 0.0927727222442627\n",
      "epoch: 1 step: 551, loss is 0.12826178967952728\n",
      "epoch: 1 step: 552, loss is 0.10420049726963043\n",
      "epoch: 1 step: 553, loss is 0.007452494464814663\n",
      "epoch: 1 step: 554, loss is 0.2769768238067627\n",
      "epoch: 1 step: 555, loss is 0.1963994950056076\n",
      "epoch: 1 step: 556, loss is 0.17365887761116028\n",
      "epoch: 1 step: 557, loss is 0.15491725504398346\n",
      "epoch: 1 step: 558, loss is 0.38548433780670166\n",
      "epoch: 1 step: 559, loss is 0.057717930525541306\n",
      "epoch: 1 step: 560, loss is 0.23498277366161346\n",
      "epoch: 1 step: 561, loss is 0.05213428661227226\n",
      "epoch: 1 step: 562, loss is 0.12682494521141052\n",
      "epoch: 1 step: 563, loss is 0.27430060505867004\n",
      "epoch: 1 step: 564, loss is 0.15294583141803741\n",
      "epoch: 1 step: 565, loss is 0.033170491456985474\n",
      "epoch: 1 step: 566, loss is 0.04369290918111801\n",
      "epoch: 1 step: 567, loss is 0.015258140861988068\n",
      "epoch: 1 step: 568, loss is 0.030972424894571304\n",
      "epoch: 1 step: 569, loss is 0.2993629276752472\n",
      "epoch: 1 step: 570, loss is 0.24966487288475037\n",
      "epoch: 1 step: 571, loss is 0.11977602541446686\n",
      "epoch: 1 step: 572, loss is 0.3914138078689575\n",
      "epoch: 1 step: 573, loss is 0.21344076097011566\n",
      "epoch: 1 step: 574, loss is 0.011948978528380394\n",
      "epoch: 1 step: 575, loss is 0.2479015290737152\n",
      "epoch: 1 step: 576, loss is 0.10164438188076019\n",
      "epoch: 1 step: 577, loss is 0.15389569103717804\n",
      "epoch: 1 step: 578, loss is 0.13880082964897156\n",
      "epoch: 1 step: 579, loss is 0.025454629212617874\n",
      "epoch: 1 step: 580, loss is 0.31586503982543945\n",
      "epoch: 1 step: 581, loss is 0.10131673514842987\n",
      "epoch: 1 step: 582, loss is 0.1802906095981598\n",
      "epoch: 1 step: 583, loss is 0.0422075130045414\n",
      "epoch: 1 step: 584, loss is 0.18895365297794342\n",
      "epoch: 1 step: 585, loss is 0.09911725670099258\n",
      "epoch: 1 step: 586, loss is 0.10550565272569656\n",
      "epoch: 1 step: 587, loss is 0.11934079974889755\n",
      "epoch: 1 step: 588, loss is 0.29439812898635864\n",
      "epoch: 1 step: 589, loss is 0.06520041078329086\n",
      "epoch: 1 step: 590, loss is 0.11345590651035309\n",
      "epoch: 1 step: 591, loss is 0.016556942835450172\n",
      "epoch: 1 step: 592, loss is 0.013387064449489117\n",
      "epoch: 1 step: 593, loss is 0.0571732223033905\n",
      "epoch: 1 step: 594, loss is 0.21655504405498505\n",
      "epoch: 1 step: 595, loss is 0.11215637624263763\n",
      "epoch: 1 step: 596, loss is 0.07004062831401825\n",
      "epoch: 1 step: 597, loss is 0.01701347343623638\n",
      "epoch: 1 step: 598, loss is 0.0818600133061409\n",
      "epoch: 1 step: 599, loss is 0.060329899191856384\n",
      "epoch: 1 step: 600, loss is 0.2134389579296112\n",
      "epoch: 1 step: 601, loss is 0.39739471673965454\n",
      "epoch: 1 step: 602, loss is 0.009422830305993557\n",
      "epoch: 1 step: 603, loss is 0.4829534590244293\n",
      "epoch: 1 step: 604, loss is 0.08382561802864075\n",
      "epoch: 1 step: 605, loss is 0.1253100335597992\n",
      "epoch: 1 step: 606, loss is 0.02304740995168686\n",
      "epoch: 1 step: 607, loss is 0.3576226830482483\n",
      "epoch: 1 step: 608, loss is 0.2772485017776489\n",
      "epoch: 1 step: 609, loss is 0.11447159945964813\n",
      "epoch: 1 step: 610, loss is 0.16015882790088654\n",
      "epoch: 1 step: 611, loss is 0.07300794124603271\n",
      "epoch: 1 step: 612, loss is 0.037712547928094864\n",
      "epoch: 1 step: 613, loss is 0.05333181843161583\n",
      "epoch: 1 step: 614, loss is 0.3218775987625122\n",
      "epoch: 1 step: 615, loss is 0.16894033551216125\n",
      "epoch: 1 step: 616, loss is 0.30378103256225586\n",
      "epoch: 1 step: 617, loss is 0.02134586311876774\n",
      "epoch: 1 step: 618, loss is 0.09462814033031464\n",
      "epoch: 1 step: 619, loss is 0.28487083315849304\n",
      "epoch: 1 step: 620, loss is 0.1822931170463562\n",
      "epoch: 1 step: 621, loss is 0.19231824576854706\n",
      "epoch: 1 step: 622, loss is 0.13968443870544434\n",
      "epoch: 1 step: 623, loss is 0.04975385218858719\n",
      "epoch: 1 step: 624, loss is 0.24438542127609253\n",
      "epoch: 1 step: 625, loss is 0.0215346347540617\n",
      "epoch: 1 step: 626, loss is 0.2448408454656601\n",
      "epoch: 1 step: 627, loss is 0.13090790808200836\n",
      "epoch: 1 step: 628, loss is 0.032735057175159454\n",
      "epoch: 1 step: 629, loss is 0.14440524578094482\n",
      "epoch: 1 step: 630, loss is 0.06369058787822723\n",
      "epoch: 1 step: 631, loss is 0.09045270085334778\n",
      "epoch: 1 step: 632, loss is 0.16277094185352325\n",
      "epoch: 1 step: 633, loss is 0.05235124006867409\n",
      "epoch: 1 step: 634, loss is 0.03238452225923538\n",
      "epoch: 1 step: 635, loss is 0.11765292286872864\n",
      "epoch: 1 step: 636, loss is 0.09777041524648666\n",
      "epoch: 1 step: 637, loss is 0.19763264060020447\n",
      "epoch: 1 step: 638, loss is 0.3351893424987793\n",
      "epoch: 1 step: 639, loss is 0.010080154985189438\n",
      "epoch: 1 step: 640, loss is 0.07811451703310013\n",
      "epoch: 1 step: 641, loss is 0.029020462185144424\n",
      "epoch: 1 step: 642, loss is 0.011357526294887066\n",
      "epoch: 1 step: 643, loss is 0.3004440665245056\n",
      "epoch: 1 step: 644, loss is 0.2705863118171692\n",
      "epoch: 1 step: 645, loss is 0.01761976070702076\n",
      "epoch: 1 step: 646, loss is 0.08916567265987396\n",
      "epoch: 1 step: 647, loss is 0.1082753837108612\n",
      "epoch: 1 step: 648, loss is 0.09589625149965286\n",
      "epoch: 1 step: 649, loss is 0.04469560459256172\n",
      "epoch: 1 step: 650, loss is 0.030918188393115997\n",
      "epoch: 1 step: 651, loss is 0.35540756583213806\n",
      "epoch: 1 step: 652, loss is 0.2523200213909149\n",
      "epoch: 1 step: 653, loss is 0.08670512586832047\n",
      "epoch: 1 step: 654, loss is 0.06372354179620743\n",
      "epoch: 1 step: 655, loss is 0.13513138890266418\n",
      "epoch: 1 step: 656, loss is 0.08502239733934402\n",
      "epoch: 1 step: 657, loss is 0.0698229968547821\n",
      "epoch: 1 step: 658, loss is 0.23280280828475952\n",
      "epoch: 1 step: 659, loss is 0.28012222051620483\n",
      "epoch: 1 step: 660, loss is 0.023122146725654602\n",
      "epoch: 1 step: 661, loss is 0.04987552762031555\n",
      "epoch: 1 step: 662, loss is 0.22297674417495728\n",
      "epoch: 1 step: 663, loss is 0.005879352800548077\n",
      "epoch: 1 step: 664, loss is 0.02703358232975006\n",
      "epoch: 1 step: 665, loss is 0.01794382743537426\n",
      "epoch: 1 step: 666, loss is 0.10379914194345474\n",
      "epoch: 1 step: 667, loss is 0.36937031149864197\n",
      "epoch: 1 step: 668, loss is 0.12868806719779968\n",
      "epoch: 1 step: 669, loss is 0.013169190846383572\n",
      "epoch: 1 step: 670, loss is 0.09044669568538666\n",
      "epoch: 1 step: 671, loss is 0.049702148884534836\n",
      "epoch: 1 step: 672, loss is 0.04347805306315422\n",
      "epoch: 1 step: 673, loss is 0.23373597860336304\n",
      "epoch: 1 step: 674, loss is 0.02537405863404274\n",
      "epoch: 1 step: 675, loss is 0.0908050537109375\n",
      "epoch: 1 step: 676, loss is 0.12168584018945694\n",
      "epoch: 1 step: 677, loss is 0.18826140463352203\n",
      "epoch: 1 step: 678, loss is 0.30954399704933167\n",
      "epoch: 1 step: 679, loss is 0.18930871784687042\n",
      "epoch: 1 step: 680, loss is 0.024736011400818825\n",
      "epoch: 1 step: 681, loss is 0.7234175801277161\n",
      "epoch: 1 step: 682, loss is 0.08899733424186707\n",
      "epoch: 1 step: 683, loss is 0.07579608261585236\n",
      "epoch: 1 step: 684, loss is 0.035699982196092606\n",
      "epoch: 1 step: 685, loss is 0.04597476124763489\n",
      "epoch: 1 step: 686, loss is 0.256898432970047\n",
      "epoch: 1 step: 687, loss is 0.12386341392993927\n",
      "epoch: 1 step: 688, loss is 0.014194128103554249\n",
      "epoch: 1 step: 689, loss is 0.1509624868631363\n",
      "epoch: 1 step: 690, loss is 0.0339658223092556\n",
      "epoch: 1 step: 691, loss is 0.11314219236373901\n",
      "epoch: 1 step: 692, loss is 0.027799859642982483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 693, loss is 0.027540216222405434\n",
      "epoch: 1 step: 694, loss is 0.008850938640534878\n",
      "epoch: 1 step: 695, loss is 0.02411147579550743\n",
      "epoch: 1 step: 696, loss is 0.15351097285747528\n",
      "epoch: 1 step: 697, loss is 0.004932492971420288\n",
      "epoch: 1 step: 698, loss is 0.37934738397598267\n",
      "epoch: 1 step: 699, loss is 0.12641601264476776\n",
      "epoch: 1 step: 700, loss is 0.08105283975601196\n",
      "epoch: 1 step: 701, loss is 0.2781510353088379\n",
      "epoch: 1 step: 702, loss is 0.45568183064460754\n",
      "epoch: 1 step: 703, loss is 0.12686043977737427\n",
      "epoch: 1 step: 704, loss is 0.19782616198062897\n",
      "epoch: 1 step: 705, loss is 0.0784536823630333\n",
      "epoch: 1 step: 706, loss is 0.10888228565454483\n",
      "epoch: 1 step: 707, loss is 0.2121647447347641\n",
      "epoch: 1 step: 708, loss is 0.09598977118730545\n",
      "epoch: 1 step: 709, loss is 0.37403392791748047\n",
      "epoch: 1 step: 710, loss is 0.1398908942937851\n",
      "epoch: 1 step: 711, loss is 0.13291901350021362\n",
      "epoch: 1 step: 712, loss is 0.07515129446983337\n",
      "epoch: 1 step: 713, loss is 0.06492391973733902\n",
      "epoch: 1 step: 714, loss is 0.10476380586624146\n",
      "epoch: 1 step: 715, loss is 0.06883236765861511\n",
      "epoch: 1 step: 716, loss is 0.1026858389377594\n",
      "epoch: 1 step: 717, loss is 0.19667185842990875\n",
      "epoch: 1 step: 718, loss is 0.1818787008523941\n",
      "epoch: 1 step: 719, loss is 0.0438433475792408\n",
      "epoch: 1 step: 720, loss is 0.10821262747049332\n",
      "epoch: 1 step: 721, loss is 0.02493252232670784\n",
      "epoch: 1 step: 722, loss is 0.16672702133655548\n",
      "epoch: 1 step: 723, loss is 0.14508269727230072\n",
      "epoch: 1 step: 724, loss is 0.053387485444545746\n",
      "epoch: 1 step: 725, loss is 0.07497942447662354\n",
      "epoch: 1 step: 726, loss is 0.11411295086145401\n",
      "epoch: 1 step: 727, loss is 0.05237066000699997\n",
      "epoch: 1 step: 728, loss is 0.24868549406528473\n",
      "epoch: 1 step: 729, loss is 0.1325424462556839\n",
      "epoch: 1 step: 730, loss is 0.035504329949617386\n",
      "epoch: 1 step: 731, loss is 0.06099360063672066\n",
      "epoch: 1 step: 732, loss is 0.0297611765563488\n",
      "epoch: 1 step: 733, loss is 0.1215352937579155\n",
      "epoch: 1 step: 734, loss is 0.04269316792488098\n",
      "epoch: 1 step: 735, loss is 0.0365765355527401\n",
      "epoch: 1 step: 736, loss is 0.10139281302690506\n",
      "epoch: 1 step: 737, loss is 0.06304997205734253\n",
      "epoch: 1 step: 738, loss is 0.07622359693050385\n",
      "epoch: 1 step: 739, loss is 0.019084755331277847\n",
      "epoch: 1 step: 740, loss is 0.032434556633234024\n",
      "epoch: 1 step: 741, loss is 0.019783956930041313\n",
      "epoch: 1 step: 742, loss is 0.133625328540802\n",
      "epoch: 1 step: 743, loss is 0.05389602109789848\n",
      "epoch: 1 step: 744, loss is 0.056198567152023315\n",
      "epoch: 1 step: 745, loss is 0.015306556597352028\n",
      "epoch: 1 step: 746, loss is 0.18934406340122223\n",
      "epoch: 1 step: 747, loss is 0.0032520724926143885\n",
      "epoch: 1 step: 748, loss is 0.15430912375450134\n",
      "epoch: 1 step: 749, loss is 0.0826607346534729\n",
      "epoch: 1 step: 750, loss is 0.05259275063872337\n",
      "epoch: 1 step: 751, loss is 0.009976452216506004\n",
      "epoch: 1 step: 752, loss is 0.05428885295987129\n",
      "epoch: 1 step: 753, loss is 0.006836432032287121\n",
      "epoch: 1 step: 754, loss is 0.07785087078809738\n",
      "epoch: 1 step: 755, loss is 0.12386883795261383\n",
      "epoch: 1 step: 756, loss is 0.2889326512813568\n",
      "epoch: 1 step: 757, loss is 0.3912053108215332\n",
      "epoch: 1 step: 758, loss is 0.09497664868831635\n",
      "epoch: 1 step: 759, loss is 0.14127515256404877\n",
      "epoch: 1 step: 760, loss is 0.16329430043697357\n",
      "epoch: 1 step: 761, loss is 0.24660830199718475\n",
      "epoch: 1 step: 762, loss is 0.1277495175600052\n",
      "epoch: 1 step: 763, loss is 0.008904686197638512\n",
      "epoch: 1 step: 764, loss is 0.10068824887275696\n",
      "epoch: 1 step: 765, loss is 0.1291297823190689\n",
      "epoch: 1 step: 766, loss is 0.14735768735408783\n",
      "epoch: 1 step: 767, loss is 0.2064807116985321\n",
      "epoch: 1 step: 768, loss is 0.08792831748723984\n",
      "epoch: 1 step: 769, loss is 0.017252933233976364\n",
      "epoch: 1 step: 770, loss is 0.01021804753690958\n",
      "epoch: 1 step: 771, loss is 0.05778966844081879\n",
      "epoch: 1 step: 772, loss is 0.048666130751371384\n",
      "epoch: 1 step: 773, loss is 0.12471716105937958\n",
      "epoch: 1 step: 774, loss is 0.08202393352985382\n",
      "epoch: 1 step: 775, loss is 0.09380435943603516\n",
      "epoch: 1 step: 776, loss is 0.10544179379940033\n",
      "epoch: 1 step: 777, loss is 0.09772957861423492\n",
      "epoch: 1 step: 778, loss is 0.021725794300436974\n",
      "epoch: 1 step: 779, loss is 0.014887621626257896\n",
      "epoch: 1 step: 780, loss is 0.05520128086209297\n",
      "epoch: 1 step: 781, loss is 0.004000004846602678\n",
      "epoch: 1 step: 782, loss is 0.06016860529780388\n",
      "epoch: 1 step: 783, loss is 0.11696114391088486\n",
      "epoch: 1 step: 784, loss is 0.0413687601685524\n",
      "epoch: 1 step: 785, loss is 0.06188370659947395\n",
      "epoch: 1 step: 786, loss is 0.188898503780365\n",
      "epoch: 1 step: 787, loss is 0.12559670209884644\n",
      "epoch: 1 step: 788, loss is 0.03295597806572914\n",
      "epoch: 1 step: 789, loss is 0.00881043542176485\n",
      "epoch: 1 step: 790, loss is 0.15806761384010315\n",
      "epoch: 1 step: 791, loss is 0.20298130810260773\n",
      "epoch: 1 step: 792, loss is 0.17911364138126373\n",
      "epoch: 1 step: 793, loss is 0.1764499396085739\n",
      "epoch: 1 step: 794, loss is 0.09302292764186859\n",
      "epoch: 1 step: 795, loss is 0.0675852820277214\n",
      "epoch: 1 step: 796, loss is 0.14234589040279388\n",
      "epoch: 1 step: 797, loss is 0.09066339582204819\n",
      "epoch: 1 step: 798, loss is 0.07163919508457184\n",
      "epoch: 1 step: 799, loss is 0.1213482990860939\n",
      "epoch: 1 step: 800, loss is 0.08615167438983917\n",
      "epoch: 1 step: 801, loss is 0.25441375374794006\n",
      "epoch: 1 step: 802, loss is 0.2659547030925751\n",
      "epoch: 1 step: 803, loss is 0.13862833380699158\n",
      "epoch: 1 step: 804, loss is 0.09740239381790161\n",
      "epoch: 1 step: 805, loss is 0.07396388798952103\n",
      "epoch: 1 step: 806, loss is 0.14892344176769257\n",
      "epoch: 1 step: 807, loss is 0.09763569384813309\n",
      "epoch: 1 step: 808, loss is 0.1310344934463501\n",
      "epoch: 1 step: 809, loss is 0.16855479776859283\n",
      "epoch: 1 step: 810, loss is 0.0411175936460495\n",
      "epoch: 1 step: 811, loss is 0.14537066221237183\n",
      "epoch: 1 step: 812, loss is 0.10276245325803757\n",
      "epoch: 1 step: 813, loss is 0.021468499675393105\n",
      "epoch: 1 step: 814, loss is 0.20439010858535767\n",
      "epoch: 1 step: 815, loss is 0.04995771497488022\n",
      "epoch: 1 step: 816, loss is 0.02629675529897213\n",
      "epoch: 1 step: 817, loss is 0.08504709601402283\n",
      "epoch: 1 step: 818, loss is 0.16590406000614166\n",
      "epoch: 1 step: 819, loss is 0.029127588495612144\n",
      "epoch: 1 step: 820, loss is 0.15587188303470612\n",
      "epoch: 1 step: 821, loss is 0.00522053986787796\n",
      "epoch: 1 step: 822, loss is 0.25533944368362427\n",
      "epoch: 1 step: 823, loss is 0.08555375784635544\n",
      "epoch: 1 step: 824, loss is 0.01766788214445114\n",
      "epoch: 1 step: 825, loss is 0.08758015930652618\n",
      "epoch: 1 step: 826, loss is 0.010021931491792202\n",
      "epoch: 1 step: 827, loss is 0.13099682331085205\n",
      "epoch: 1 step: 828, loss is 0.06392736732959747\n",
      "epoch: 1 step: 829, loss is 0.48705074191093445\n",
      "epoch: 1 step: 830, loss is 0.045380182564258575\n",
      "epoch: 1 step: 831, loss is 0.008032573387026787\n",
      "epoch: 1 step: 832, loss is 0.056272394955158234\n",
      "epoch: 1 step: 833, loss is 0.15155887603759766\n",
      "epoch: 1 step: 834, loss is 0.153687983751297\n",
      "epoch: 1 step: 835, loss is 0.04335618391633034\n",
      "epoch: 1 step: 836, loss is 0.0160842128098011\n",
      "epoch: 1 step: 837, loss is 0.015663577243685722\n",
      "epoch: 1 step: 838, loss is 0.07057351619005203\n",
      "epoch: 1 step: 839, loss is 0.15360379219055176\n",
      "epoch: 1 step: 840, loss is 0.08967117965221405\n",
      "epoch: 1 step: 841, loss is 0.202122762799263\n",
      "epoch: 1 step: 842, loss is 0.3106491267681122\n",
      "epoch: 1 step: 843, loss is 0.1045241579413414\n",
      "epoch: 1 step: 844, loss is 0.13041949272155762\n",
      "epoch: 1 step: 845, loss is 0.3521427810192108\n",
      "epoch: 1 step: 846, loss is 0.09067951142787933\n",
      "epoch: 1 step: 847, loss is 0.05767405778169632\n",
      "epoch: 1 step: 848, loss is 0.014692958444356918\n",
      "epoch: 1 step: 849, loss is 0.004246671684086323\n",
      "epoch: 1 step: 850, loss is 0.22921344637870789\n",
      "epoch: 1 step: 851, loss is 0.17346902191638947\n",
      "epoch: 1 step: 852, loss is 0.013515278697013855\n",
      "epoch: 1 step: 853, loss is 0.3778091371059418\n",
      "epoch: 1 step: 854, loss is 0.15052156150341034\n",
      "epoch: 1 step: 855, loss is 0.02386336959898472\n",
      "epoch: 1 step: 856, loss is 0.028277570381760597\n",
      "epoch: 1 step: 857, loss is 0.04116280376911163\n",
      "epoch: 1 step: 858, loss is 0.18111753463745117\n",
      "epoch: 1 step: 859, loss is 0.18299227952957153\n",
      "epoch: 1 step: 860, loss is 0.04722152277827263\n",
      "epoch: 1 step: 861, loss is 0.24214476346969604\n",
      "epoch: 1 step: 862, loss is 0.010552513413131237\n",
      "epoch: 1 step: 863, loss is 0.06466009467840195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 864, loss is 0.15190017223358154\n",
      "epoch: 1 step: 865, loss is 0.038339536637067795\n",
      "epoch: 1 step: 866, loss is 0.22408555448055267\n",
      "epoch: 1 step: 867, loss is 0.04005185887217522\n",
      "epoch: 1 step: 868, loss is 0.02768946811556816\n",
      "epoch: 1 step: 869, loss is 0.019322702661156654\n",
      "epoch: 1 step: 870, loss is 0.012362620793282986\n",
      "epoch: 1 step: 871, loss is 0.07627417892217636\n",
      "epoch: 1 step: 872, loss is 0.17202307283878326\n",
      "epoch: 1 step: 873, loss is 0.0032714547123759985\n",
      "epoch: 1 step: 874, loss is 0.011270343326032162\n",
      "epoch: 1 step: 875, loss is 0.013383056037127972\n",
      "epoch: 1 step: 876, loss is 0.10402186214923859\n",
      "epoch: 1 step: 877, loss is 0.23330187797546387\n",
      "epoch: 1 step: 878, loss is 0.5011972188949585\n",
      "epoch: 1 step: 879, loss is 0.12036632746458054\n",
      "epoch: 1 step: 880, loss is 0.01850488968193531\n",
      "epoch: 1 step: 881, loss is 0.0929601788520813\n",
      "epoch: 1 step: 882, loss is 0.1438855230808258\n",
      "epoch: 1 step: 883, loss is 0.1626630425453186\n",
      "epoch: 1 step: 884, loss is 0.008048216812312603\n",
      "epoch: 1 step: 885, loss is 0.05496814101934433\n",
      "epoch: 1 step: 886, loss is 0.08931025862693787\n",
      "epoch: 1 step: 887, loss is 0.14721760153770447\n",
      "epoch: 1 step: 888, loss is 0.06862065196037292\n",
      "epoch: 1 step: 889, loss is 0.05211738497018814\n",
      "epoch: 1 step: 890, loss is 0.13282468914985657\n",
      "epoch: 1 step: 891, loss is 0.03283372521400452\n",
      "epoch: 1 step: 892, loss is 0.024475734680891037\n",
      "epoch: 1 step: 893, loss is 0.01651025004684925\n",
      "epoch: 1 step: 894, loss is 0.022514762356877327\n",
      "epoch: 1 step: 895, loss is 0.015690907835960388\n",
      "epoch: 1 step: 896, loss is 0.44291672110557556\n",
      "epoch: 1 step: 897, loss is 0.011781937442719936\n",
      "epoch: 1 step: 898, loss is 0.016091186553239822\n",
      "epoch: 1 step: 899, loss is 0.1282980740070343\n",
      "epoch: 1 step: 900, loss is 0.04526776820421219\n",
      "epoch: 1 step: 901, loss is 0.08461099117994308\n",
      "epoch: 1 step: 902, loss is 0.022852230817079544\n",
      "epoch: 1 step: 903, loss is 0.008439396508038044\n",
      "epoch: 1 step: 904, loss is 0.020193319767713547\n",
      "epoch: 1 step: 905, loss is 0.06027999520301819\n",
      "epoch: 1 step: 906, loss is 0.12721891701221466\n",
      "epoch: 1 step: 907, loss is 0.05579811707139015\n",
      "epoch: 1 step: 908, loss is 0.22637200355529785\n",
      "epoch: 1 step: 909, loss is 0.007081789895892143\n",
      "epoch: 1 step: 910, loss is 0.04102274030447006\n",
      "epoch: 1 step: 911, loss is 0.13096651434898376\n",
      "epoch: 1 step: 912, loss is 0.008067675866186619\n",
      "epoch: 1 step: 913, loss is 0.28894442319869995\n",
      "epoch: 1 step: 914, loss is 0.053487226366996765\n",
      "epoch: 1 step: 915, loss is 0.019850486889481544\n",
      "epoch: 1 step: 916, loss is 0.17825157940387726\n",
      "epoch: 1 step: 917, loss is 0.0696244165301323\n",
      "epoch: 1 step: 918, loss is 0.13589848577976227\n",
      "epoch: 1 step: 919, loss is 0.030798478052020073\n",
      "epoch: 1 step: 920, loss is 0.09574972093105316\n",
      "epoch: 1 step: 921, loss is 0.02260199561715126\n",
      "epoch: 1 step: 922, loss is 0.07659485191106796\n",
      "epoch: 1 step: 923, loss is 0.010624500922858715\n",
      "epoch: 1 step: 924, loss is 0.10192539542913437\n",
      "epoch: 1 step: 925, loss is 0.14448387920856476\n",
      "epoch: 1 step: 926, loss is 0.4463270902633667\n",
      "epoch: 1 step: 927, loss is 0.059600360691547394\n",
      "epoch: 1 step: 928, loss is 0.02319359965622425\n",
      "epoch: 1 step: 929, loss is 0.011462931521236897\n",
      "epoch: 1 step: 930, loss is 0.0354076586663723\n",
      "epoch: 1 step: 931, loss is 0.10665279626846313\n",
      "epoch: 1 step: 932, loss is 0.12981556355953217\n",
      "epoch: 1 step: 933, loss is 0.1255323886871338\n",
      "epoch: 1 step: 934, loss is 0.06440657377243042\n",
      "epoch: 1 step: 935, loss is 0.13546901941299438\n",
      "epoch: 1 step: 936, loss is 0.06516651809215546\n",
      "epoch: 1 step: 937, loss is 0.060841772705316544\n",
      "epoch: 1 step: 938, loss is 0.0019801114685833454\n",
      "epoch: 1 step: 939, loss is 0.22069045901298523\n",
      "epoch: 1 step: 940, loss is 0.12303604930639267\n",
      "epoch: 1 step: 941, loss is 0.04673459753394127\n",
      "epoch: 1 step: 942, loss is 0.2767481505870819\n",
      "epoch: 1 step: 943, loss is 0.12652501463890076\n",
      "epoch: 1 step: 944, loss is 0.07365122437477112\n",
      "epoch: 1 step: 945, loss is 0.018284674733877182\n",
      "epoch: 1 step: 946, loss is 0.04274363070726395\n",
      "epoch: 1 step: 947, loss is 0.18611446022987366\n",
      "epoch: 1 step: 948, loss is 0.11196151375770569\n",
      "epoch: 1 step: 949, loss is 0.015469883568584919\n",
      "epoch: 1 step: 950, loss is 0.013646152801811695\n",
      "epoch: 1 step: 951, loss is 0.17845645546913147\n",
      "epoch: 1 step: 952, loss is 0.014544550329446793\n",
      "epoch: 1 step: 953, loss is 0.021894123405218124\n",
      "epoch: 1 step: 954, loss is 0.0685705617070198\n",
      "epoch: 1 step: 955, loss is 0.05037260055541992\n",
      "epoch: 1 step: 956, loss is 0.06933997571468353\n",
      "epoch: 1 step: 957, loss is 0.13640743494033813\n",
      "epoch: 1 step: 958, loss is 0.033621884882450104\n",
      "epoch: 1 step: 959, loss is 0.009806576184928417\n",
      "epoch: 1 step: 960, loss is 0.1359470784664154\n",
      "epoch: 1 step: 961, loss is 0.005244794767349958\n",
      "epoch: 1 step: 962, loss is 0.052402373403310776\n",
      "epoch: 1 step: 963, loss is 0.23402656614780426\n",
      "epoch: 1 step: 964, loss is 0.023946505039930344\n",
      "epoch: 1 step: 965, loss is 0.030290823429822922\n",
      "epoch: 1 step: 966, loss is 0.013486654497683048\n",
      "epoch: 1 step: 967, loss is 0.12573793530464172\n",
      "epoch: 1 step: 968, loss is 0.2742640972137451\n",
      "epoch: 1 step: 969, loss is 0.15474168956279755\n",
      "epoch: 1 step: 970, loss is 0.05838200822472572\n",
      "epoch: 1 step: 971, loss is 0.03618083894252777\n",
      "epoch: 1 step: 972, loss is 0.04201193526387215\n",
      "epoch: 1 step: 973, loss is 0.06939343363046646\n",
      "epoch: 1 step: 974, loss is 0.11556430160999298\n",
      "epoch: 1 step: 975, loss is 0.18702258169651031\n",
      "epoch: 1 step: 976, loss is 0.048080697655677795\n",
      "epoch: 1 step: 977, loss is 0.007765499409288168\n",
      "epoch: 1 step: 978, loss is 0.04268742352724075\n",
      "epoch: 1 step: 979, loss is 0.026387201622128487\n",
      "epoch: 1 step: 980, loss is 0.04905947297811508\n",
      "epoch: 1 step: 981, loss is 0.028615444898605347\n",
      "epoch: 1 step: 982, loss is 0.1844298243522644\n",
      "epoch: 1 step: 983, loss is 0.011321394704282284\n",
      "epoch: 1 step: 984, loss is 0.002276875078678131\n",
      "epoch: 1 step: 985, loss is 0.16108505427837372\n",
      "epoch: 1 step: 986, loss is 0.14546948671340942\n",
      "epoch: 1 step: 987, loss is 0.07742586731910706\n",
      "epoch: 1 step: 988, loss is 0.015060107223689556\n",
      "epoch: 1 step: 989, loss is 0.05289629474282265\n",
      "epoch: 1 step: 990, loss is 0.07591165602207184\n",
      "epoch: 1 step: 991, loss is 0.20685771107673645\n",
      "epoch: 1 step: 992, loss is 0.023569075390696526\n",
      "epoch: 1 step: 993, loss is 0.01460346020758152\n",
      "epoch: 1 step: 994, loss is 0.12860307097434998\n",
      "epoch: 1 step: 995, loss is 0.0838221088051796\n",
      "epoch: 1 step: 996, loss is 0.2659488022327423\n",
      "epoch: 1 step: 997, loss is 0.10463260114192963\n",
      "epoch: 1 step: 998, loss is 0.2922653555870056\n",
      "epoch: 1 step: 999, loss is 0.08151326328516006\n",
      "epoch: 1 step: 1000, loss is 0.09936258941888809\n",
      "epoch: 1 step: 1001, loss is 0.17242319881916046\n",
      "epoch: 1 step: 1002, loss is 0.0660630315542221\n",
      "epoch: 1 step: 1003, loss is 0.004246823024004698\n",
      "epoch: 1 step: 1004, loss is 0.004223733674734831\n",
      "epoch: 1 step: 1005, loss is 0.04149414226412773\n",
      "epoch: 1 step: 1006, loss is 0.14658379554748535\n",
      "epoch: 1 step: 1007, loss is 0.11888439208269119\n",
      "epoch: 1 step: 1008, loss is 0.15591572225093842\n",
      "epoch: 1 step: 1009, loss is 0.018220124766230583\n",
      "epoch: 1 step: 1010, loss is 0.09600386768579483\n",
      "epoch: 1 step: 1011, loss is 0.26132169365882874\n",
      "epoch: 1 step: 1012, loss is 0.04107871651649475\n",
      "epoch: 1 step: 1013, loss is 0.09273339807987213\n",
      "epoch: 1 step: 1014, loss is 0.08956494927406311\n",
      "epoch: 1 step: 1015, loss is 0.20875920355319977\n",
      "epoch: 1 step: 1016, loss is 0.2790728509426117\n",
      "epoch: 1 step: 1017, loss is 0.01549574639648199\n",
      "epoch: 1 step: 1018, loss is 0.09382294863462448\n",
      "epoch: 1 step: 1019, loss is 0.25846564769744873\n",
      "epoch: 1 step: 1020, loss is 0.41662612557411194\n",
      "epoch: 1 step: 1021, loss is 0.015836076810956\n",
      "epoch: 1 step: 1022, loss is 0.011845254339277744\n",
      "epoch: 1 step: 1023, loss is 0.01280118152499199\n",
      "epoch: 1 step: 1024, loss is 0.027859851717948914\n",
      "epoch: 1 step: 1025, loss is 0.08978145569562912\n",
      "epoch: 1 step: 1026, loss is 0.14793607592582703\n",
      "epoch: 1 step: 1027, loss is 0.164521262049675\n",
      "epoch: 1 step: 1028, loss is 0.10545771569013596\n",
      "epoch: 1 step: 1029, loss is 0.03034832328557968\n",
      "epoch: 1 step: 1030, loss is 0.2163100391626358\n",
      "epoch: 1 step: 1031, loss is 0.0977749451994896\n",
      "epoch: 1 step: 1032, loss is 0.024870997294783592\n",
      "epoch: 1 step: 1033, loss is 0.049661602824926376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1034, loss is 0.14198675751686096\n",
      "epoch: 1 step: 1035, loss is 0.06554936617612839\n",
      "epoch: 1 step: 1036, loss is 0.01079215295612812\n",
      "epoch: 1 step: 1037, loss is 0.09581349045038223\n",
      "epoch: 1 step: 1038, loss is 0.11530087888240814\n",
      "epoch: 1 step: 1039, loss is 0.03877302259206772\n",
      "epoch: 1 step: 1040, loss is 0.13716518878936768\n",
      "epoch: 1 step: 1041, loss is 0.04000960290431976\n",
      "epoch: 1 step: 1042, loss is 0.10766974836587906\n",
      "epoch: 1 step: 1043, loss is 0.02667236141860485\n",
      "epoch: 1 step: 1044, loss is 0.015621624886989594\n",
      "epoch: 1 step: 1045, loss is 0.11677470803260803\n",
      "epoch: 1 step: 1046, loss is 0.047826118767261505\n",
      "epoch: 1 step: 1047, loss is 0.11761388182640076\n",
      "epoch: 1 step: 1048, loss is 0.012074509635567665\n",
      "epoch: 1 step: 1049, loss is 0.1611384153366089\n",
      "epoch: 1 step: 1050, loss is 0.018501996994018555\n",
      "epoch: 1 step: 1051, loss is 0.07732710242271423\n",
      "epoch: 1 step: 1052, loss is 0.019553424790501595\n",
      "epoch: 1 step: 1053, loss is 0.058448225259780884\n",
      "epoch: 1 step: 1054, loss is 0.1896355003118515\n",
      "epoch: 1 step: 1055, loss is 0.05304862931370735\n",
      "epoch: 1 step: 1056, loss is 0.020096994936466217\n",
      "epoch: 1 step: 1057, loss is 0.32037055492401123\n",
      "epoch: 1 step: 1058, loss is 0.018808122724294662\n",
      "epoch: 1 step: 1059, loss is 0.013306017965078354\n",
      "epoch: 1 step: 1060, loss is 0.13653850555419922\n",
      "epoch: 1 step: 1061, loss is 0.04658694565296173\n",
      "epoch: 1 step: 1062, loss is 0.1261524111032486\n",
      "epoch: 1 step: 1063, loss is 0.01638743095099926\n",
      "epoch: 1 step: 1064, loss is 0.014801309444010258\n",
      "epoch: 1 step: 1065, loss is 0.18027009069919586\n",
      "epoch: 1 step: 1066, loss is 0.07263649255037308\n",
      "epoch: 1 step: 1067, loss is 0.06086751073598862\n",
      "epoch: 1 step: 1068, loss is 0.028631767258048058\n",
      "epoch: 1 step: 1069, loss is 0.10958908498287201\n",
      "epoch: 1 step: 1070, loss is 0.07702019810676575\n",
      "epoch: 1 step: 1071, loss is 0.022567320615053177\n",
      "epoch: 1 step: 1072, loss is 0.3592222034931183\n",
      "epoch: 1 step: 1073, loss is 0.15385852754116058\n",
      "epoch: 1 step: 1074, loss is 0.4004153609275818\n",
      "epoch: 1 step: 1075, loss is 0.2633056044578552\n",
      "epoch: 1 step: 1076, loss is 0.15595991909503937\n",
      "epoch: 1 step: 1077, loss is 0.010429460555315018\n",
      "epoch: 1 step: 1078, loss is 0.05358826369047165\n",
      "epoch: 1 step: 1079, loss is 0.16503682732582092\n",
      "epoch: 1 step: 1080, loss is 0.22826647758483887\n",
      "epoch: 1 step: 1081, loss is 0.22512131929397583\n",
      "epoch: 1 step: 1082, loss is 0.18696218729019165\n",
      "epoch: 1 step: 1083, loss is 0.04011329263448715\n",
      "epoch: 1 step: 1084, loss is 0.009135992266237736\n",
      "epoch: 1 step: 1085, loss is 0.08754564076662064\n",
      "epoch: 1 step: 1086, loss is 0.08275430649518967\n",
      "epoch: 1 step: 1087, loss is 0.07503397017717361\n",
      "epoch: 1 step: 1088, loss is 0.024164404720067978\n",
      "epoch: 1 step: 1089, loss is 0.08278531581163406\n",
      "epoch: 1 step: 1090, loss is 0.07254786044359207\n",
      "epoch: 1 step: 1091, loss is 0.355133593082428\n",
      "epoch: 1 step: 1092, loss is 0.17544330656528473\n",
      "epoch: 1 step: 1093, loss is 0.31307947635650635\n",
      "epoch: 1 step: 1094, loss is 0.08413390070199966\n",
      "epoch: 1 step: 1095, loss is 0.10230129957199097\n",
      "epoch: 1 step: 1096, loss is 0.05008627474308014\n",
      "epoch: 1 step: 1097, loss is 0.013211843557655811\n",
      "epoch: 1 step: 1098, loss is 0.1888749748468399\n",
      "epoch: 1 step: 1099, loss is 0.0387943759560585\n",
      "epoch: 1 step: 1100, loss is 0.02795221284031868\n",
      "epoch: 1 step: 1101, loss is 0.00508382311090827\n",
      "epoch: 1 step: 1102, loss is 0.06757671386003494\n",
      "epoch: 1 step: 1103, loss is 0.19338777661323547\n",
      "epoch: 1 step: 1104, loss is 0.17027752101421356\n",
      "epoch: 1 step: 1105, loss is 0.024614643305540085\n",
      "epoch: 1 step: 1106, loss is 0.2548072338104248\n",
      "epoch: 1 step: 1107, loss is 0.028974955901503563\n",
      "epoch: 1 step: 1108, loss is 0.06395988911390305\n",
      "epoch: 1 step: 1109, loss is 0.06671136617660522\n",
      "epoch: 1 step: 1110, loss is 0.049067750573158264\n",
      "epoch: 1 step: 1111, loss is 0.07045507431030273\n",
      "epoch: 1 step: 1112, loss is 0.028013499453663826\n",
      "epoch: 1 step: 1113, loss is 0.007314175833016634\n",
      "epoch: 1 step: 1114, loss is 0.07229693979024887\n",
      "epoch: 1 step: 1115, loss is 0.008455364033579826\n",
      "epoch: 1 step: 1116, loss is 0.011761710979044437\n",
      "epoch: 1 step: 1117, loss is 0.16488996148109436\n",
      "epoch: 1 step: 1118, loss is 0.04193739593029022\n",
      "epoch: 1 step: 1119, loss is 0.07602043449878693\n",
      "epoch: 1 step: 1120, loss is 0.15827986598014832\n",
      "epoch: 1 step: 1121, loss is 0.08467907458543777\n",
      "epoch: 1 step: 1122, loss is 0.019030999392271042\n",
      "epoch: 1 step: 1123, loss is 0.008649327792227268\n",
      "epoch: 1 step: 1124, loss is 0.002715153619647026\n",
      "epoch: 1 step: 1125, loss is 0.03555591404438019\n",
      "epoch: 1 step: 1126, loss is 0.03228454291820526\n",
      "epoch: 1 step: 1127, loss is 0.10766316950321198\n",
      "epoch: 1 step: 1128, loss is 0.08826923370361328\n",
      "epoch: 1 step: 1129, loss is 0.05781947821378708\n",
      "epoch: 1 step: 1130, loss is 0.009241179563105106\n",
      "epoch: 1 step: 1131, loss is 0.007479378022253513\n",
      "epoch: 1 step: 1132, loss is 0.027221590280532837\n",
      "epoch: 1 step: 1133, loss is 0.0011454347986727953\n",
      "epoch: 1 step: 1134, loss is 0.007662308868020773\n",
      "epoch: 1 step: 1135, loss is 0.09072273224592209\n",
      "epoch: 1 step: 1136, loss is 0.056138213723897934\n",
      "epoch: 1 step: 1137, loss is 0.10134797543287277\n",
      "epoch: 1 step: 1138, loss is 0.07779604196548462\n",
      "epoch: 1 step: 1139, loss is 0.045360904186964035\n",
      "epoch: 1 step: 1140, loss is 0.029689157381653786\n",
      "epoch: 1 step: 1141, loss is 0.006764138583093882\n",
      "epoch: 1 step: 1142, loss is 0.07641304284334183\n",
      "epoch: 1 step: 1143, loss is 0.08756142854690552\n",
      "epoch: 1 step: 1144, loss is 0.1734888255596161\n",
      "epoch: 1 step: 1145, loss is 0.12902894616127014\n",
      "epoch: 1 step: 1146, loss is 0.04571564868092537\n",
      "epoch: 1 step: 1147, loss is 0.1604585498571396\n",
      "epoch: 1 step: 1148, loss is 0.011356119066476822\n",
      "epoch: 1 step: 1149, loss is 0.1349131017923355\n",
      "epoch: 1 step: 1150, loss is 0.021388772875070572\n",
      "epoch: 1 step: 1151, loss is 0.14017540216445923\n",
      "epoch: 1 step: 1152, loss is 0.3589681386947632\n",
      "epoch: 1 step: 1153, loss is 0.002305185655131936\n",
      "epoch: 1 step: 1154, loss is 0.022820768877863884\n",
      "epoch: 1 step: 1155, loss is 0.008932385593652725\n",
      "epoch: 1 step: 1156, loss is 0.22245058417320251\n",
      "epoch: 1 step: 1157, loss is 0.029522281140089035\n",
      "epoch: 1 step: 1158, loss is 0.21462036669254303\n",
      "epoch: 1 step: 1159, loss is 0.02158079482614994\n",
      "epoch: 1 step: 1160, loss is 0.04265432432293892\n",
      "epoch: 1 step: 1161, loss is 0.10775269567966461\n",
      "epoch: 1 step: 1162, loss is 0.08100688457489014\n",
      "epoch: 1 step: 1163, loss is 0.1596584916114807\n",
      "epoch: 1 step: 1164, loss is 0.10581748187541962\n",
      "epoch: 1 step: 1165, loss is 0.04551466554403305\n",
      "epoch: 1 step: 1166, loss is 0.08260148763656616\n",
      "epoch: 1 step: 1167, loss is 0.02051372081041336\n",
      "epoch: 1 step: 1168, loss is 0.10890678316354752\n",
      "epoch: 1 step: 1169, loss is 0.18452200293540955\n",
      "epoch: 1 step: 1170, loss is 0.11425681412220001\n",
      "epoch: 1 step: 1171, loss is 0.18351735174655914\n",
      "epoch: 1 step: 1172, loss is 0.14284031093120575\n",
      "epoch: 1 step: 1173, loss is 0.3380402624607086\n",
      "epoch: 1 step: 1174, loss is 0.16561603546142578\n",
      "epoch: 1 step: 1175, loss is 0.060010265558958054\n",
      "epoch: 1 step: 1176, loss is 0.16974645853042603\n",
      "epoch: 1 step: 1177, loss is 0.031065596267580986\n",
      "epoch: 1 step: 1178, loss is 0.2575552463531494\n",
      "epoch: 1 step: 1179, loss is 0.07444020360708237\n",
      "epoch: 1 step: 1180, loss is 0.03578421473503113\n",
      "epoch: 1 step: 1181, loss is 0.2207961231470108\n",
      "epoch: 1 step: 1182, loss is 0.04364097863435745\n",
      "epoch: 1 step: 1183, loss is 0.18885259330272675\n",
      "epoch: 1 step: 1184, loss is 0.13523918390274048\n",
      "epoch: 1 step: 1185, loss is 0.0049292221665382385\n",
      "epoch: 1 step: 1186, loss is 0.26155251264572144\n",
      "epoch: 1 step: 1187, loss is 0.14677715301513672\n",
      "epoch: 1 step: 1188, loss is 0.018188226968050003\n",
      "epoch: 1 step: 1189, loss is 0.014891302213072777\n",
      "epoch: 1 step: 1190, loss is 0.18363891541957855\n",
      "epoch: 1 step: 1191, loss is 0.16338767111301422\n",
      "epoch: 1 step: 1192, loss is 0.010793861001729965\n",
      "epoch: 1 step: 1193, loss is 0.11290404945611954\n",
      "epoch: 1 step: 1194, loss is 0.05617918074131012\n",
      "epoch: 1 step: 1195, loss is 0.029551619663834572\n",
      "epoch: 1 step: 1196, loss is 0.1550482213497162\n",
      "epoch: 1 step: 1197, loss is 0.013662687502801418\n",
      "epoch: 1 step: 1198, loss is 0.0880647748708725\n",
      "epoch: 1 step: 1199, loss is 0.13565701246261597\n",
      "epoch: 1 step: 1200, loss is 0.11940647661685944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1201, loss is 0.029598090797662735\n",
      "epoch: 1 step: 1202, loss is 0.06141181290149689\n",
      "epoch: 1 step: 1203, loss is 0.09625694155693054\n",
      "epoch: 1 step: 1204, loss is 0.0515173114836216\n",
      "epoch: 1 step: 1205, loss is 0.007538415491580963\n",
      "epoch: 1 step: 1206, loss is 0.0432145781815052\n",
      "epoch: 1 step: 1207, loss is 0.050306640565395355\n",
      "epoch: 1 step: 1208, loss is 0.09341582655906677\n",
      "epoch: 1 step: 1209, loss is 0.05677484720945358\n",
      "epoch: 1 step: 1210, loss is 0.014183803461492062\n",
      "epoch: 1 step: 1211, loss is 0.01457598339766264\n",
      "epoch: 1 step: 1212, loss is 0.1587926596403122\n",
      "epoch: 1 step: 1213, loss is 0.1530013084411621\n",
      "epoch: 1 step: 1214, loss is 0.008268073201179504\n",
      "epoch: 1 step: 1215, loss is 0.04427216202020645\n",
      "epoch: 1 step: 1216, loss is 0.09464527666568756\n",
      "epoch: 1 step: 1217, loss is 0.029706323519349098\n",
      "epoch: 1 step: 1218, loss is 0.010507545433938503\n",
      "epoch: 1 step: 1219, loss is 0.01144428364932537\n",
      "epoch: 1 step: 1220, loss is 0.1324881911277771\n",
      "epoch: 1 step: 1221, loss is 0.11885588616132736\n",
      "epoch: 1 step: 1222, loss is 0.01846717670559883\n",
      "epoch: 1 step: 1223, loss is 0.0043191732838749886\n",
      "epoch: 1 step: 1224, loss is 0.3072415888309479\n",
      "epoch: 1 step: 1225, loss is 0.24490205943584442\n",
      "epoch: 1 step: 1226, loss is 0.1346093863248825\n",
      "epoch: 1 step: 1227, loss is 0.008118873462080956\n",
      "epoch: 1 step: 1228, loss is 0.20652954280376434\n",
      "epoch: 1 step: 1229, loss is 0.015405010432004929\n",
      "epoch: 1 step: 1230, loss is 0.24132287502288818\n",
      "epoch: 1 step: 1231, loss is 0.025775112211704254\n",
      "epoch: 1 step: 1232, loss is 0.04678761959075928\n",
      "epoch: 1 step: 1233, loss is 0.0284509789198637\n",
      "epoch: 1 step: 1234, loss is 0.04448879137635231\n",
      "epoch: 1 step: 1235, loss is 0.030081842094659805\n",
      "epoch: 1 step: 1236, loss is 0.12393689900636673\n",
      "epoch: 1 step: 1237, loss is 0.03837282955646515\n",
      "epoch: 1 step: 1238, loss is 0.006826229393482208\n",
      "epoch: 1 step: 1239, loss is 0.08063889294862747\n",
      "epoch: 1 step: 1240, loss is 0.055114272981882095\n",
      "epoch: 1 step: 1241, loss is 0.13943131268024445\n",
      "epoch: 1 step: 1242, loss is 0.04867471009492874\n",
      "epoch: 1 step: 1243, loss is 0.16544078290462494\n",
      "epoch: 1 step: 1244, loss is 0.0771791860461235\n",
      "epoch: 1 step: 1245, loss is 0.39788618683815\n",
      "epoch: 1 step: 1246, loss is 0.020263705402612686\n",
      "epoch: 1 step: 1247, loss is 0.10003628581762314\n",
      "epoch: 1 step: 1248, loss is 0.10504989326000214\n",
      "epoch: 1 step: 1249, loss is 0.14357158541679382\n",
      "epoch: 1 step: 1250, loss is 0.1286180466413498\n",
      "epoch: 1 step: 1251, loss is 0.1401032656431198\n",
      "epoch: 1 step: 1252, loss is 0.05324969068169594\n",
      "epoch: 1 step: 1253, loss is 0.10456067323684692\n",
      "epoch: 1 step: 1254, loss is 0.06096656620502472\n",
      "epoch: 1 step: 1255, loss is 0.08974277228116989\n",
      "epoch: 1 step: 1256, loss is 0.05125570669770241\n",
      "epoch: 1 step: 1257, loss is 0.018240422010421753\n",
      "epoch: 1 step: 1258, loss is 0.021836047992110252\n",
      "epoch: 1 step: 1259, loss is 0.127867192029953\n",
      "epoch: 1 step: 1260, loss is 0.36910146474838257\n",
      "epoch: 1 step: 1261, loss is 0.18736401200294495\n",
      "epoch: 1 step: 1262, loss is 0.12860584259033203\n",
      "epoch: 1 step: 1263, loss is 0.01921791397035122\n",
      "epoch: 1 step: 1264, loss is 0.07786236703395844\n",
      "epoch: 1 step: 1265, loss is 0.11517278105020523\n",
      "epoch: 1 step: 1266, loss is 0.010328237898647785\n",
      "epoch: 1 step: 1267, loss is 0.02198377437889576\n",
      "epoch: 1 step: 1268, loss is 0.1398051530122757\n",
      "epoch: 1 step: 1269, loss is 0.03565824776887894\n",
      "epoch: 1 step: 1270, loss is 0.0034325027372688055\n",
      "epoch: 1 step: 1271, loss is 0.16907261312007904\n",
      "epoch: 1 step: 1272, loss is 0.17990483343601227\n",
      "epoch: 1 step: 1273, loss is 0.044068384915590286\n",
      "epoch: 1 step: 1274, loss is 0.18938158452510834\n",
      "epoch: 1 step: 1275, loss is 0.04274473711848259\n",
      "epoch: 1 step: 1276, loss is 0.0202648788690567\n",
      "epoch: 1 step: 1277, loss is 0.009963244199752808\n",
      "epoch: 1 step: 1278, loss is 0.055798958986997604\n",
      "epoch: 1 step: 1279, loss is 0.01807437092065811\n",
      "epoch: 1 step: 1280, loss is 0.07419977337121964\n",
      "epoch: 1 step: 1281, loss is 0.02793779969215393\n",
      "epoch: 1 step: 1282, loss is 0.1534968912601471\n",
      "epoch: 1 step: 1283, loss is 0.0141495605930686\n",
      "epoch: 1 step: 1284, loss is 0.023752665147185326\n",
      "epoch: 1 step: 1285, loss is 0.013831323012709618\n",
      "epoch: 1 step: 1286, loss is 0.0270713958889246\n",
      "epoch: 1 step: 1287, loss is 0.0713859498500824\n",
      "epoch: 1 step: 1288, loss is 0.02841358818113804\n",
      "epoch: 1 step: 1289, loss is 0.05059962347149849\n",
      "epoch: 1 step: 1290, loss is 0.03493949770927429\n",
      "epoch: 1 step: 1291, loss is 0.2442854642868042\n",
      "epoch: 1 step: 1292, loss is 0.009153041057288647\n",
      "epoch: 1 step: 1293, loss is 0.022380400449037552\n",
      "epoch: 1 step: 1294, loss is 0.19911135733127594\n",
      "epoch: 1 step: 1295, loss is 0.12703564763069153\n",
      "epoch: 1 step: 1296, loss is 0.011191608384251595\n",
      "epoch: 1 step: 1297, loss is 0.02874753810465336\n",
      "epoch: 1 step: 1298, loss is 0.0015375716611742973\n",
      "epoch: 1 step: 1299, loss is 0.06572061032056808\n",
      "epoch: 1 step: 1300, loss is 0.08464545756578445\n",
      "epoch: 1 step: 1301, loss is 0.009455794468522072\n",
      "epoch: 1 step: 1302, loss is 0.00353533448651433\n",
      "epoch: 1 step: 1303, loss is 0.019437158480286598\n",
      "epoch: 1 step: 1304, loss is 0.0036327738780528307\n",
      "epoch: 1 step: 1305, loss is 0.013886859640479088\n",
      "epoch: 1 step: 1306, loss is 0.01124495081603527\n",
      "epoch: 1 step: 1307, loss is 0.00783092062920332\n",
      "epoch: 1 step: 1308, loss is 0.021679403260350227\n",
      "epoch: 1 step: 1309, loss is 0.15032421052455902\n",
      "epoch: 1 step: 1310, loss is 0.06279370933771133\n",
      "epoch: 1 step: 1311, loss is 0.1417485922574997\n",
      "epoch: 1 step: 1312, loss is 0.0036280504427850246\n",
      "epoch: 1 step: 1313, loss is 0.05135548859834671\n",
      "epoch: 1 step: 1314, loss is 0.010802698321640491\n",
      "epoch: 1 step: 1315, loss is 0.03176698088645935\n",
      "epoch: 1 step: 1316, loss is 0.18495580554008484\n",
      "epoch: 1 step: 1317, loss is 0.032475803047418594\n",
      "epoch: 1 step: 1318, loss is 0.002405639039352536\n",
      "epoch: 1 step: 1319, loss is 0.03701053932309151\n",
      "epoch: 1 step: 1320, loss is 0.11921054124832153\n",
      "epoch: 1 step: 1321, loss is 0.005852518603205681\n",
      "epoch: 1 step: 1322, loss is 0.013735492713749409\n",
      "epoch: 1 step: 1323, loss is 0.017754219472408295\n",
      "epoch: 1 step: 1324, loss is 0.007341188844293356\n",
      "epoch: 1 step: 1325, loss is 0.004405598156154156\n",
      "epoch: 1 step: 1326, loss is 0.006973285228013992\n",
      "epoch: 1 step: 1327, loss is 0.01361064612865448\n",
      "epoch: 1 step: 1328, loss is 0.14079032838344574\n",
      "epoch: 1 step: 1329, loss is 0.22444215416908264\n",
      "epoch: 1 step: 1330, loss is 0.05629242584109306\n",
      "epoch: 1 step: 1331, loss is 0.2175734043121338\n",
      "epoch: 1 step: 1332, loss is 0.09294579178094864\n",
      "epoch: 1 step: 1333, loss is 0.25859424471855164\n",
      "epoch: 1 step: 1334, loss is 0.016545213758945465\n",
      "epoch: 1 step: 1335, loss is 0.24582302570343018\n",
      "epoch: 1 step: 1336, loss is 0.1494358628988266\n",
      "epoch: 1 step: 1337, loss is 0.3011852502822876\n",
      "epoch: 1 step: 1338, loss is 0.005818033125251532\n",
      "epoch: 1 step: 1339, loss is 0.150627002120018\n",
      "epoch: 1 step: 1340, loss is 0.04032992571592331\n",
      "epoch: 1 step: 1341, loss is 0.048284851014614105\n",
      "epoch: 1 step: 1342, loss is 0.045161738991737366\n",
      "epoch: 1 step: 1343, loss is 0.048591699451208115\n",
      "epoch: 1 step: 1344, loss is 0.006629281211644411\n",
      "epoch: 1 step: 1345, loss is 0.042876213788986206\n",
      "epoch: 1 step: 1346, loss is 0.07151389122009277\n",
      "epoch: 1 step: 1347, loss is 0.05530840903520584\n",
      "epoch: 1 step: 1348, loss is 0.027171427384018898\n",
      "epoch: 1 step: 1349, loss is 0.2031766176223755\n",
      "epoch: 1 step: 1350, loss is 0.18821924924850464\n",
      "epoch: 1 step: 1351, loss is 0.007448806427419186\n",
      "epoch: 1 step: 1352, loss is 0.10261013358831406\n",
      "epoch: 1 step: 1353, loss is 0.18250642716884613\n",
      "epoch: 1 step: 1354, loss is 0.11091367900371552\n",
      "epoch: 1 step: 1355, loss is 0.020323336124420166\n",
      "epoch: 1 step: 1356, loss is 0.014285167679190636\n",
      "epoch: 1 step: 1357, loss is 0.0012793641071766615\n",
      "epoch: 1 step: 1358, loss is 0.18249906599521637\n",
      "epoch: 1 step: 1359, loss is 0.06674159318208694\n",
      "epoch: 1 step: 1360, loss is 0.04119718447327614\n",
      "epoch: 1 step: 1361, loss is 0.013793271966278553\n",
      "epoch: 1 step: 1362, loss is 0.01807277649641037\n",
      "epoch: 1 step: 1363, loss is 0.14837124943733215\n",
      "epoch: 1 step: 1364, loss is 0.2256208211183548\n",
      "epoch: 1 step: 1365, loss is 0.06476234644651413\n",
      "epoch: 1 step: 1366, loss is 0.1404813826084137\n",
      "epoch: 1 step: 1367, loss is 0.1746857762336731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1368, loss is 0.024640314280986786\n",
      "epoch: 1 step: 1369, loss is 0.010188971646130085\n",
      "epoch: 1 step: 1370, loss is 0.005057030823081732\n",
      "epoch: 1 step: 1371, loss is 0.16682879626750946\n",
      "epoch: 1 step: 1372, loss is 0.0715051218867302\n",
      "epoch: 1 step: 1373, loss is 0.008286496624350548\n",
      "epoch: 1 step: 1374, loss is 0.013482420705258846\n",
      "epoch: 1 step: 1375, loss is 0.06715387105941772\n",
      "epoch: 1 step: 1376, loss is 0.07105474919080734\n",
      "epoch: 1 step: 1377, loss is 0.08097165822982788\n",
      "epoch: 1 step: 1378, loss is 0.12408548593521118\n",
      "epoch: 1 step: 1379, loss is 0.024133961647748947\n",
      "epoch: 1 step: 1380, loss is 0.17873510718345642\n",
      "epoch: 1 step: 1381, loss is 0.06254412978887558\n",
      "epoch: 1 step: 1382, loss is 0.06938114762306213\n",
      "epoch: 1 step: 1383, loss is 0.10394518077373505\n",
      "epoch: 1 step: 1384, loss is 0.168577641248703\n",
      "epoch: 1 step: 1385, loss is 0.04276799038052559\n",
      "epoch: 1 step: 1386, loss is 0.038972724229097366\n",
      "epoch: 1 step: 1387, loss is 0.12333432585000992\n",
      "epoch: 1 step: 1388, loss is 0.01245926320552826\n",
      "epoch: 1 step: 1389, loss is 0.09982462972402573\n",
      "epoch: 1 step: 1390, loss is 0.03866945207118988\n",
      "epoch: 1 step: 1391, loss is 0.041336268186569214\n",
      "epoch: 1 step: 1392, loss is 0.13970157504081726\n",
      "epoch: 1 step: 1393, loss is 0.1143902987241745\n",
      "epoch: 1 step: 1394, loss is 0.06776551157236099\n",
      "epoch: 1 step: 1395, loss is 0.21166753768920898\n",
      "epoch: 1 step: 1396, loss is 0.07019451260566711\n",
      "epoch: 1 step: 1397, loss is 0.11401759088039398\n",
      "epoch: 1 step: 1398, loss is 0.021228954195976257\n",
      "epoch: 1 step: 1399, loss is 0.283858060836792\n",
      "epoch: 1 step: 1400, loss is 0.020320575684309006\n",
      "epoch: 1 step: 1401, loss is 0.044751010835170746\n",
      "epoch: 1 step: 1402, loss is 0.05732673034071922\n",
      "epoch: 1 step: 1403, loss is 0.05926917865872383\n",
      "epoch: 1 step: 1404, loss is 0.06431777030229568\n",
      "epoch: 1 step: 1405, loss is 0.07757364958524704\n",
      "epoch: 1 step: 1406, loss is 0.21951104700565338\n",
      "epoch: 1 step: 1407, loss is 0.00971884373575449\n",
      "epoch: 1 step: 1408, loss is 0.02194020338356495\n",
      "epoch: 1 step: 1409, loss is 0.16108311712741852\n",
      "epoch: 1 step: 1410, loss is 0.03257866948843002\n",
      "epoch: 1 step: 1411, loss is 0.18540561199188232\n",
      "epoch: 1 step: 1412, loss is 0.058708783239126205\n",
      "epoch: 1 step: 1413, loss is 0.14694397151470184\n",
      "epoch: 1 step: 1414, loss is 0.02087993361055851\n",
      "epoch: 1 step: 1415, loss is 0.06428837776184082\n",
      "epoch: 1 step: 1416, loss is 0.025159699842333794\n",
      "epoch: 1 step: 1417, loss is 0.03381915017962456\n",
      "epoch: 1 step: 1418, loss is 0.03860880434513092\n",
      "epoch: 1 step: 1419, loss is 0.016725294291973114\n",
      "epoch: 1 step: 1420, loss is 0.016229761764407158\n",
      "epoch: 1 step: 1421, loss is 0.04838315770030022\n",
      "epoch: 1 step: 1422, loss is 0.16996778547763824\n",
      "epoch: 1 step: 1423, loss is 0.01885480061173439\n",
      "epoch: 1 step: 1424, loss is 0.0171681959182024\n",
      "epoch: 1 step: 1425, loss is 0.13062551617622375\n",
      "epoch: 1 step: 1426, loss is 0.1013227328658104\n",
      "epoch: 1 step: 1427, loss is 0.15396365523338318\n",
      "epoch: 1 step: 1428, loss is 0.023274526000022888\n",
      "epoch: 1 step: 1429, loss is 0.2765049636363983\n",
      "epoch: 1 step: 1430, loss is 0.10687009990215302\n",
      "epoch: 1 step: 1431, loss is 0.09916798025369644\n",
      "epoch: 1 step: 1432, loss is 0.03465515002608299\n",
      "epoch: 1 step: 1433, loss is 0.03241218999028206\n",
      "epoch: 1 step: 1434, loss is 0.06989530473947525\n",
      "epoch: 1 step: 1435, loss is 0.08717788755893707\n",
      "epoch: 1 step: 1436, loss is 0.13311319053173065\n",
      "epoch: 1 step: 1437, loss is 0.12140180915594101\n",
      "epoch: 1 step: 1438, loss is 0.03449958190321922\n",
      "epoch: 1 step: 1439, loss is 0.013291933573782444\n",
      "epoch: 1 step: 1440, loss is 0.05812349170446396\n",
      "epoch: 1 step: 1441, loss is 0.01899002492427826\n",
      "epoch: 1 step: 1442, loss is 0.08517388999462128\n",
      "epoch: 1 step: 1443, loss is 0.023060211911797523\n",
      "epoch: 1 step: 1444, loss is 0.027899745851755142\n",
      "epoch: 1 step: 1445, loss is 0.03780555725097656\n",
      "epoch: 1 step: 1446, loss is 0.1706644594669342\n",
      "epoch: 1 step: 1447, loss is 0.007059544324874878\n",
      "epoch: 1 step: 1448, loss is 0.016745638102293015\n",
      "epoch: 1 step: 1449, loss is 0.012996058911085129\n",
      "epoch: 1 step: 1450, loss is 0.13886921107769012\n",
      "epoch: 1 step: 1451, loss is 0.3561309576034546\n",
      "epoch: 1 step: 1452, loss is 0.12653757631778717\n",
      "epoch: 1 step: 1453, loss is 0.040032342076301575\n",
      "epoch: 1 step: 1454, loss is 0.112830251455307\n",
      "epoch: 1 step: 1455, loss is 0.0015645986422896385\n",
      "epoch: 1 step: 1456, loss is 0.08603021502494812\n",
      "epoch: 1 step: 1457, loss is 0.11309195309877396\n",
      "epoch: 1 step: 1458, loss is 0.0019031813135370612\n",
      "epoch: 1 step: 1459, loss is 0.007900349795818329\n",
      "epoch: 1 step: 1460, loss is 0.1914854496717453\n",
      "epoch: 1 step: 1461, loss is 0.1518680602312088\n",
      "epoch: 1 step: 1462, loss is 0.04468350484967232\n",
      "epoch: 1 step: 1463, loss is 0.010157126933336258\n",
      "epoch: 1 step: 1464, loss is 0.18315516412258148\n",
      "epoch: 1 step: 1465, loss is 0.011702601797878742\n",
      "epoch: 1 step: 1466, loss is 0.07251834869384766\n",
      "epoch: 1 step: 1467, loss is 0.04724652320146561\n",
      "epoch: 1 step: 1468, loss is 0.05333557352423668\n",
      "epoch: 1 step: 1469, loss is 0.0020910673774778843\n",
      "epoch: 1 step: 1470, loss is 0.039501890540122986\n",
      "epoch: 1 step: 1471, loss is 0.04985989257693291\n",
      "epoch: 1 step: 1472, loss is 0.022221505641937256\n",
      "epoch: 1 step: 1473, loss is 0.1287335604429245\n",
      "epoch: 1 step: 1474, loss is 0.0028362926095724106\n",
      "epoch: 1 step: 1475, loss is 0.0637134239077568\n",
      "epoch: 1 step: 1476, loss is 0.08557555824518204\n",
      "epoch: 1 step: 1477, loss is 0.35486868023872375\n",
      "epoch: 1 step: 1478, loss is 0.0034224973060190678\n",
      "epoch: 1 step: 1479, loss is 0.12421511858701706\n",
      "epoch: 1 step: 1480, loss is 0.013387953862547874\n",
      "epoch: 1 step: 1481, loss is 0.011496299877762794\n",
      "epoch: 1 step: 1482, loss is 0.01459363754838705\n",
      "epoch: 1 step: 1483, loss is 0.04040529578924179\n",
      "epoch: 1 step: 1484, loss is 0.23887263238430023\n",
      "epoch: 1 step: 1485, loss is 0.02718191407620907\n",
      "epoch: 1 step: 1486, loss is 0.28064125776290894\n",
      "epoch: 1 step: 1487, loss is 0.09612783789634705\n",
      "epoch: 1 step: 1488, loss is 0.24404405057430267\n",
      "epoch: 1 step: 1489, loss is 0.01778062991797924\n",
      "epoch: 1 step: 1490, loss is 0.03354206308722496\n",
      "epoch: 1 step: 1491, loss is 0.22307977080345154\n",
      "epoch: 1 step: 1492, loss is 0.006752848159521818\n",
      "epoch: 1 step: 1493, loss is 0.007285975851118565\n",
      "epoch: 1 step: 1494, loss is 0.004088301211595535\n",
      "epoch: 1 step: 1495, loss is 0.02481989935040474\n",
      "epoch: 1 step: 1496, loss is 0.16974543035030365\n",
      "epoch: 1 step: 1497, loss is 0.014398227445781231\n",
      "epoch: 1 step: 1498, loss is 0.0411546491086483\n",
      "epoch: 1 step: 1499, loss is 0.01992597058415413\n",
      "epoch: 1 step: 1500, loss is 0.03831709548830986\n",
      "epoch: 1 step: 1501, loss is 0.05724753811955452\n",
      "epoch: 1 step: 1502, loss is 0.03396746888756752\n",
      "epoch: 1 step: 1503, loss is 0.014795935712754726\n",
      "epoch: 1 step: 1504, loss is 0.02970767952501774\n",
      "epoch: 1 step: 1505, loss is 0.0077779702842235565\n",
      "epoch: 1 step: 1506, loss is 0.07820738106966019\n",
      "epoch: 1 step: 1507, loss is 0.007909187115728855\n",
      "epoch: 1 step: 1508, loss is 0.17365482449531555\n",
      "epoch: 1 step: 1509, loss is 0.03509598225355148\n",
      "epoch: 1 step: 1510, loss is 0.06281250715255737\n",
      "epoch: 1 step: 1511, loss is 0.038169004023075104\n",
      "epoch: 1 step: 1512, loss is 0.032982368022203445\n",
      "epoch: 1 step: 1513, loss is 0.20694823563098907\n",
      "epoch: 1 step: 1514, loss is 0.02548215165734291\n",
      "epoch: 1 step: 1515, loss is 0.07704684138298035\n",
      "epoch: 1 step: 1516, loss is 0.12093070149421692\n",
      "epoch: 1 step: 1517, loss is 0.003443857654929161\n",
      "epoch: 1 step: 1518, loss is 0.1225970983505249\n",
      "epoch: 1 step: 1519, loss is 0.05097857117652893\n",
      "epoch: 1 step: 1520, loss is 0.008323589339852333\n",
      "epoch: 1 step: 1521, loss is 0.23977404832839966\n",
      "epoch: 1 step: 1522, loss is 0.04061293229460716\n",
      "epoch: 1 step: 1523, loss is 0.007659659255295992\n",
      "epoch: 1 step: 1524, loss is 0.05062362179160118\n",
      "epoch: 1 step: 1525, loss is 0.06512518227100372\n",
      "epoch: 1 step: 1526, loss is 0.0144800478592515\n",
      "epoch: 1 step: 1527, loss is 0.2058393657207489\n",
      "epoch: 1 step: 1528, loss is 0.07955154776573181\n",
      "epoch: 1 step: 1529, loss is 0.03699825704097748\n",
      "epoch: 1 step: 1530, loss is 0.042957909405231476\n",
      "epoch: 1 step: 1531, loss is 0.11409441381692886\n",
      "epoch: 1 step: 1532, loss is 0.2679472863674164\n",
      "epoch: 1 step: 1533, loss is 0.017508385702967644\n",
      "epoch: 1 step: 1534, loss is 0.030772695317864418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1535, loss is 0.04456080496311188\n",
      "epoch: 1 step: 1536, loss is 0.014552523382008076\n",
      "epoch: 1 step: 1537, loss is 0.08312486112117767\n",
      "epoch: 1 step: 1538, loss is 0.06701555103063583\n",
      "epoch: 1 step: 1539, loss is 0.017097335308790207\n",
      "epoch: 1 step: 1540, loss is 0.06606299430131912\n",
      "epoch: 1 step: 1541, loss is 0.03509145230054855\n",
      "epoch: 1 step: 1542, loss is 0.05889586731791496\n",
      "epoch: 1 step: 1543, loss is 0.09799590706825256\n",
      "epoch: 1 step: 1544, loss is 0.010943678207695484\n",
      "epoch: 1 step: 1545, loss is 0.02009459212422371\n",
      "epoch: 1 step: 1546, loss is 0.03946515917778015\n",
      "epoch: 1 step: 1547, loss is 0.039532385766506195\n",
      "epoch: 1 step: 1548, loss is 0.1621931940317154\n",
      "epoch: 1 step: 1549, loss is 0.18320554494857788\n",
      "epoch: 1 step: 1550, loss is 0.26190251111984253\n",
      "epoch: 1 step: 1551, loss is 0.16314201056957245\n",
      "epoch: 1 step: 1552, loss is 0.1744450032711029\n",
      "epoch: 1 step: 1553, loss is 0.07062267512083054\n",
      "epoch: 1 step: 1554, loss is 0.03350003808736801\n",
      "epoch: 1 step: 1555, loss is 0.08335518091917038\n",
      "epoch: 1 step: 1556, loss is 0.30236461758613586\n",
      "epoch: 1 step: 1557, loss is 0.023702897131443024\n",
      "epoch: 1 step: 1558, loss is 0.008712906390428543\n",
      "epoch: 1 step: 1559, loss is 0.07599806040525436\n",
      "epoch: 1 step: 1560, loss is 0.08985830843448639\n",
      "epoch: 1 step: 1561, loss is 0.023049455136060715\n",
      "epoch: 1 step: 1562, loss is 0.0051208361983299255\n",
      "epoch: 1 step: 1563, loss is 0.00461005512624979\n",
      "epoch: 1 step: 1564, loss is 0.0013300185091793537\n",
      "epoch: 1 step: 1565, loss is 0.006787200924009085\n",
      "epoch: 1 step: 1566, loss is 0.00854003056883812\n",
      "epoch: 1 step: 1567, loss is 0.10566296428442001\n",
      "epoch: 1 step: 1568, loss is 0.26217347383499146\n",
      "epoch: 1 step: 1569, loss is 0.017687810584902763\n",
      "epoch: 1 step: 1570, loss is 0.2081693857908249\n",
      "epoch: 1 step: 1571, loss is 0.18126344680786133\n",
      "epoch: 1 step: 1572, loss is 0.05242905393242836\n",
      "epoch: 1 step: 1573, loss is 0.09334848821163177\n",
      "epoch: 1 step: 1574, loss is 0.2970620095729828\n",
      "epoch: 1 step: 1575, loss is 0.07864713668823242\n",
      "epoch: 1 step: 1576, loss is 0.04133186116814613\n",
      "epoch: 1 step: 1577, loss is 0.11326371133327484\n",
      "epoch: 1 step: 1578, loss is 0.11382048577070236\n",
      "epoch: 1 step: 1579, loss is 0.06318795680999756\n",
      "epoch: 1 step: 1580, loss is 0.03256665915250778\n",
      "epoch: 1 step: 1581, loss is 0.08780363202095032\n",
      "epoch: 1 step: 1582, loss is 0.06266944855451584\n",
      "epoch: 1 step: 1583, loss is 0.009560499340295792\n",
      "epoch: 1 step: 1584, loss is 0.028619669377803802\n",
      "epoch: 1 step: 1585, loss is 0.03627544641494751\n",
      "epoch: 1 step: 1586, loss is 0.014348533935844898\n",
      "epoch: 1 step: 1587, loss is 0.02828761376440525\n",
      "epoch: 1 step: 1588, loss is 0.31391870975494385\n",
      "epoch: 1 step: 1589, loss is 0.023999175056815147\n",
      "epoch: 1 step: 1590, loss is 0.07535860687494278\n",
      "epoch: 1 step: 1591, loss is 0.022295478731393814\n",
      "epoch: 1 step: 1592, loss is 0.0703478455543518\n",
      "epoch: 1 step: 1593, loss is 0.08685673773288727\n",
      "epoch: 1 step: 1594, loss is 0.020788604393601418\n",
      "epoch: 1 step: 1595, loss is 0.035978544503450394\n",
      "epoch: 1 step: 1596, loss is 0.037205860018730164\n",
      "epoch: 1 step: 1597, loss is 0.042794156819581985\n",
      "epoch: 1 step: 1598, loss is 0.003950373735278845\n",
      "epoch: 1 step: 1599, loss is 0.06918613612651825\n",
      "epoch: 1 step: 1600, loss is 0.016468994319438934\n",
      "epoch: 1 step: 1601, loss is 0.13420231640338898\n",
      "epoch: 1 step: 1602, loss is 0.006803940050303936\n",
      "epoch: 1 step: 1603, loss is 0.0362047515809536\n",
      "epoch: 1 step: 1604, loss is 0.0015238214982673526\n",
      "epoch: 1 step: 1605, loss is 0.027225414291024208\n",
      "epoch: 1 step: 1606, loss is 0.002267487347126007\n",
      "epoch: 1 step: 1607, loss is 0.19459371268749237\n",
      "epoch: 1 step: 1608, loss is 0.1086067482829094\n",
      "epoch: 1 step: 1609, loss is 0.008284233510494232\n",
      "epoch: 1 step: 1610, loss is 0.2462136447429657\n",
      "epoch: 1 step: 1611, loss is 0.12025415897369385\n",
      "epoch: 1 step: 1612, loss is 0.019187655299901962\n",
      "epoch: 1 step: 1613, loss is 0.11089981347322464\n",
      "epoch: 1 step: 1614, loss is 0.04396473616361618\n",
      "epoch: 1 step: 1615, loss is 0.11984097212553024\n",
      "epoch: 1 step: 1616, loss is 0.0447147935628891\n",
      "epoch: 1 step: 1617, loss is 0.08127852529287338\n",
      "epoch: 1 step: 1618, loss is 0.06821870803833008\n",
      "epoch: 1 step: 1619, loss is 0.016174012795090675\n",
      "epoch: 1 step: 1620, loss is 0.06639517843723297\n",
      "epoch: 1 step: 1621, loss is 0.12978100776672363\n",
      "epoch: 1 step: 1622, loss is 0.03961833193898201\n",
      "epoch: 1 step: 1623, loss is 0.14222367107868195\n",
      "epoch: 1 step: 1624, loss is 0.15092667937278748\n",
      "epoch: 1 step: 1625, loss is 0.01186827477067709\n",
      "epoch: 1 step: 1626, loss is 0.04384154826402664\n",
      "epoch: 1 step: 1627, loss is 0.1947045773267746\n",
      "epoch: 1 step: 1628, loss is 0.0875653550028801\n",
      "epoch: 1 step: 1629, loss is 0.04730090871453285\n",
      "epoch: 1 step: 1630, loss is 0.02055186778306961\n",
      "epoch: 1 step: 1631, loss is 0.012988871894776821\n",
      "epoch: 1 step: 1632, loss is 0.015721812844276428\n",
      "epoch: 1 step: 1633, loss is 0.308079332113266\n",
      "epoch: 1 step: 1634, loss is 0.07502011954784393\n",
      "epoch: 1 step: 1635, loss is 0.022419093176722527\n",
      "epoch: 1 step: 1636, loss is 0.12163887172937393\n",
      "epoch: 1 step: 1637, loss is 0.07835493981838226\n",
      "epoch: 1 step: 1638, loss is 0.09720202535390854\n",
      "epoch: 1 step: 1639, loss is 0.06661812216043472\n",
      "epoch: 1 step: 1640, loss is 0.06294796615839005\n",
      "epoch: 1 step: 1641, loss is 0.10464107990264893\n",
      "epoch: 1 step: 1642, loss is 0.016424428671598434\n",
      "epoch: 1 step: 1643, loss is 0.013518871739506721\n",
      "epoch: 1 step: 1644, loss is 0.008644869551062584\n",
      "epoch: 1 step: 1645, loss is 0.016434451565146446\n",
      "epoch: 1 step: 1646, loss is 0.11354794353246689\n",
      "epoch: 1 step: 1647, loss is 0.019836749881505966\n",
      "epoch: 1 step: 1648, loss is 0.3419339954853058\n",
      "epoch: 1 step: 1649, loss is 0.23720286786556244\n",
      "epoch: 1 step: 1650, loss is 0.03279748931527138\n",
      "epoch: 1 step: 1651, loss is 0.009411673061549664\n",
      "epoch: 1 step: 1652, loss is 0.11696106195449829\n",
      "epoch: 1 step: 1653, loss is 0.020086724311113358\n",
      "epoch: 1 step: 1654, loss is 0.024569734930992126\n",
      "epoch: 1 step: 1655, loss is 0.1822100132703781\n",
      "epoch: 1 step: 1656, loss is 0.41995421051979065\n",
      "epoch: 1 step: 1657, loss is 0.03984120115637779\n",
      "epoch: 1 step: 1658, loss is 0.20349563658237457\n",
      "epoch: 1 step: 1659, loss is 0.00543876551091671\n",
      "epoch: 1 step: 1660, loss is 0.02856101095676422\n",
      "epoch: 1 step: 1661, loss is 0.012603014707565308\n",
      "epoch: 1 step: 1662, loss is 0.021591641008853912\n",
      "epoch: 1 step: 1663, loss is 0.10080817341804504\n",
      "epoch: 1 step: 1664, loss is 0.02738322503864765\n",
      "epoch: 1 step: 1665, loss is 0.08386491984128952\n",
      "epoch: 1 step: 1666, loss is 0.10999153554439545\n",
      "epoch: 1 step: 1667, loss is 0.06993530690670013\n",
      "epoch: 1 step: 1668, loss is 0.08545371890068054\n",
      "epoch: 1 step: 1669, loss is 0.04439206048846245\n",
      "epoch: 1 step: 1670, loss is 0.04232597351074219\n",
      "epoch: 1 step: 1671, loss is 0.05190673843026161\n",
      "epoch: 1 step: 1672, loss is 0.20310284197330475\n",
      "epoch: 1 step: 1673, loss is 0.026502372696995735\n",
      "epoch: 1 step: 1674, loss is 0.11226939409971237\n",
      "epoch: 1 step: 1675, loss is 0.196440652012825\n",
      "epoch: 1 step: 1676, loss is 0.008137829601764679\n",
      "epoch: 1 step: 1677, loss is 0.009482081048190594\n",
      "epoch: 1 step: 1678, loss is 0.06449457257986069\n",
      "epoch: 1 step: 1679, loss is 0.07619232684373856\n",
      "epoch: 1 step: 1680, loss is 0.049963001161813736\n",
      "epoch: 1 step: 1681, loss is 0.020170914009213448\n",
      "epoch: 1 step: 1682, loss is 0.01857510767877102\n",
      "epoch: 1 step: 1683, loss is 0.033193476498126984\n",
      "epoch: 1 step: 1684, loss is 0.0521899051964283\n",
      "epoch: 1 step: 1685, loss is 0.09951826184988022\n",
      "epoch: 1 step: 1686, loss is 0.08946879953145981\n",
      "epoch: 1 step: 1687, loss is 0.10956693440675735\n",
      "epoch: 1 step: 1688, loss is 0.0308671984821558\n",
      "epoch: 1 step: 1689, loss is 0.1281576156616211\n",
      "epoch: 1 step: 1690, loss is 0.06030776724219322\n",
      "epoch: 1 step: 1691, loss is 0.038199540227651596\n",
      "epoch: 1 step: 1692, loss is 0.014012511819601059\n",
      "epoch: 1 step: 1693, loss is 0.003595571732148528\n",
      "epoch: 1 step: 1694, loss is 0.024491528049111366\n",
      "epoch: 1 step: 1695, loss is 0.017478864639997482\n",
      "epoch: 1 step: 1696, loss is 0.07463090866804123\n",
      "epoch: 1 step: 1697, loss is 0.11633536964654922\n",
      "epoch: 1 step: 1698, loss is 0.11476851254701614\n",
      "epoch: 1 step: 1699, loss is 0.02518000267446041\n",
      "epoch: 1 step: 1700, loss is 0.17325399816036224\n",
      "epoch: 1 step: 1701, loss is 0.05615030974149704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1702, loss is 0.05058243125677109\n",
      "epoch: 1 step: 1703, loss is 0.0013739299029111862\n",
      "epoch: 1 step: 1704, loss is 0.0029298721347004175\n",
      "epoch: 1 step: 1705, loss is 0.2746153175830841\n",
      "epoch: 1 step: 1706, loss is 0.05073817819356918\n",
      "epoch: 1 step: 1707, loss is 0.19794830679893494\n",
      "epoch: 1 step: 1708, loss is 0.2006533145904541\n",
      "epoch: 1 step: 1709, loss is 0.1498280018568039\n",
      "epoch: 1 step: 1710, loss is 0.15861757099628448\n",
      "epoch: 1 step: 1711, loss is 0.05024115741252899\n",
      "epoch: 1 step: 1712, loss is 0.04811462387442589\n",
      "epoch: 1 step: 1713, loss is 0.09302955120801926\n",
      "epoch: 1 step: 1714, loss is 0.15037642419338226\n",
      "epoch: 1 step: 1715, loss is 0.0766156017780304\n",
      "epoch: 1 step: 1716, loss is 0.011061782017350197\n",
      "epoch: 1 step: 1717, loss is 0.03506561741232872\n",
      "epoch: 1 step: 1718, loss is 0.17323338985443115\n",
      "epoch: 1 step: 1719, loss is 0.05315908417105675\n",
      "epoch: 1 step: 1720, loss is 0.012474296614527702\n",
      "epoch: 1 step: 1721, loss is 0.17202849686145782\n",
      "epoch: 1 step: 1722, loss is 0.020538603886961937\n",
      "epoch: 1 step: 1723, loss is 0.09754633158445358\n",
      "epoch: 1 step: 1724, loss is 0.14016616344451904\n",
      "epoch: 1 step: 1725, loss is 0.2603289783000946\n",
      "epoch: 1 step: 1726, loss is 0.037127718329429626\n",
      "epoch: 1 step: 1727, loss is 0.010936957783997059\n",
      "epoch: 1 step: 1728, loss is 0.08865434676408768\n",
      "epoch: 1 step: 1729, loss is 0.11978134512901306\n",
      "epoch: 1 step: 1730, loss is 0.0736311823129654\n",
      "epoch: 1 step: 1731, loss is 0.006162676494568586\n",
      "epoch: 1 step: 1732, loss is 0.12512560188770294\n",
      "epoch: 1 step: 1733, loss is 0.05426821857690811\n",
      "epoch: 1 step: 1734, loss is 0.2526601552963257\n",
      "epoch: 1 step: 1735, loss is 0.006942452397197485\n",
      "epoch: 1 step: 1736, loss is 0.003005597973242402\n",
      "epoch: 1 step: 1737, loss is 0.1071726605296135\n",
      "epoch: 1 step: 1738, loss is 0.08855913579463959\n",
      "epoch: 1 step: 1739, loss is 0.010774407535791397\n",
      "epoch: 1 step: 1740, loss is 0.061303041875362396\n",
      "epoch: 1 step: 1741, loss is 0.14741750061511993\n",
      "epoch: 1 step: 1742, loss is 0.0065721916034817696\n",
      "epoch: 1 step: 1743, loss is 0.12241319566965103\n",
      "epoch: 1 step: 1744, loss is 0.01561226136982441\n",
      "epoch: 1 step: 1745, loss is 0.08225960284471512\n",
      "epoch: 1 step: 1746, loss is 0.05341136455535889\n",
      "epoch: 1 step: 1747, loss is 0.014972306787967682\n",
      "epoch: 1 step: 1748, loss is 0.06870543956756592\n",
      "epoch: 1 step: 1749, loss is 0.1046605110168457\n",
      "epoch: 1 step: 1750, loss is 0.13651154935359955\n",
      "epoch: 1 step: 1751, loss is 0.0033321836963295937\n",
      "epoch: 1 step: 1752, loss is 0.005963981617242098\n",
      "epoch: 1 step: 1753, loss is 0.23703809082508087\n",
      "epoch: 1 step: 1754, loss is 0.01650129444897175\n",
      "epoch: 1 step: 1755, loss is 0.17324954271316528\n",
      "epoch: 1 step: 1756, loss is 0.030381441116333008\n",
      "epoch: 1 step: 1757, loss is 0.05655396357178688\n",
      "epoch: 1 step: 1758, loss is 0.09227053821086884\n",
      "epoch: 1 step: 1759, loss is 0.1748029738664627\n",
      "epoch: 1 step: 1760, loss is 0.01176438108086586\n",
      "epoch: 1 step: 1761, loss is 0.04280772805213928\n",
      "epoch: 1 step: 1762, loss is 0.013729730620980263\n",
      "epoch: 1 step: 1763, loss is 0.2011881321668625\n",
      "epoch: 1 step: 1764, loss is 0.01880856789648533\n",
      "epoch: 1 step: 1765, loss is 0.03492576628923416\n",
      "epoch: 1 step: 1766, loss is 0.07733280956745148\n",
      "epoch: 1 step: 1767, loss is 0.003702679881826043\n",
      "epoch: 1 step: 1768, loss is 0.2790519595146179\n",
      "epoch: 1 step: 1769, loss is 0.02772325463593006\n",
      "epoch: 1 step: 1770, loss is 0.04298555850982666\n",
      "epoch: 1 step: 1771, loss is 0.15343640744686127\n",
      "epoch: 1 step: 1772, loss is 0.2137230634689331\n",
      "epoch: 1 step: 1773, loss is 0.0014702420448884368\n",
      "epoch: 1 step: 1774, loss is 0.03741072118282318\n",
      "epoch: 1 step: 1775, loss is 0.002750709652900696\n",
      "epoch: 1 step: 1776, loss is 0.019410334527492523\n",
      "epoch: 1 step: 1777, loss is 0.06929974257946014\n",
      "epoch: 1 step: 1778, loss is 0.08230311423540115\n",
      "epoch: 1 step: 1779, loss is 0.013779931701719761\n",
      "epoch: 1 step: 1780, loss is 0.25527819991111755\n",
      "epoch: 1 step: 1781, loss is 0.21850664913654327\n",
      "epoch: 1 step: 1782, loss is 0.10256920754909515\n",
      "epoch: 1 step: 1783, loss is 0.027677178382873535\n",
      "epoch: 1 step: 1784, loss is 0.014540642499923706\n",
      "epoch: 1 step: 1785, loss is 0.050250642001628876\n",
      "epoch: 1 step: 1786, loss is 0.03041117452085018\n",
      "epoch: 1 step: 1787, loss is 0.020344074815511703\n",
      "epoch: 1 step: 1788, loss is 0.07134777307510376\n",
      "epoch: 1 step: 1789, loss is 0.036621611565351486\n",
      "epoch: 1 step: 1790, loss is 0.017626654356718063\n",
      "epoch: 1 step: 1791, loss is 0.043015189468860626\n",
      "epoch: 1 step: 1792, loss is 0.012417029589414597\n",
      "epoch: 1 step: 1793, loss is 0.040633585304021835\n",
      "epoch: 1 step: 1794, loss is 0.09834294021129608\n",
      "epoch: 1 step: 1795, loss is 0.01835385523736477\n",
      "epoch: 1 step: 1796, loss is 0.003313504159450531\n",
      "epoch: 1 step: 1797, loss is 0.27648892998695374\n",
      "epoch: 1 step: 1798, loss is 0.012906135991215706\n",
      "epoch: 1 step: 1799, loss is 0.035453956574201584\n",
      "epoch: 1 step: 1800, loss is 0.008151066489517689\n",
      "epoch: 1 step: 1801, loss is 0.2530061900615692\n",
      "epoch: 1 step: 1802, loss is 0.03628022223711014\n",
      "epoch: 1 step: 1803, loss is 0.0014887660508975387\n",
      "epoch: 1 step: 1804, loss is 0.015609459020197392\n",
      "epoch: 1 step: 1805, loss is 0.005168247502297163\n",
      "epoch: 1 step: 1806, loss is 0.1208590716123581\n",
      "epoch: 1 step: 1807, loss is 0.1286584436893463\n",
      "epoch: 1 step: 1808, loss is 0.07132496684789658\n",
      "epoch: 1 step: 1809, loss is 0.026154065504670143\n",
      "epoch: 1 step: 1810, loss is 0.03707586228847504\n",
      "epoch: 1 step: 1811, loss is 0.18106712400913239\n",
      "epoch: 1 step: 1812, loss is 0.13820098340511322\n",
      "epoch: 1 step: 1813, loss is 0.08571866899728775\n",
      "epoch: 1 step: 1814, loss is 0.05378930643200874\n",
      "epoch: 1 step: 1815, loss is 0.03378090262413025\n",
      "epoch: 1 step: 1816, loss is 0.01811852492392063\n",
      "epoch: 1 step: 1817, loss is 0.04834367707371712\n",
      "epoch: 1 step: 1818, loss is 0.06575535237789154\n",
      "epoch: 1 step: 1819, loss is 0.025505727156996727\n",
      "epoch: 1 step: 1820, loss is 0.06823180615901947\n",
      "epoch: 1 step: 1821, loss is 0.025402678176760674\n",
      "epoch: 1 step: 1822, loss is 0.012264581397175789\n",
      "epoch: 1 step: 1823, loss is 0.03370997682213783\n",
      "epoch: 1 step: 1824, loss is 0.07115819305181503\n",
      "epoch: 1 step: 1825, loss is 0.05880441516637802\n",
      "epoch: 1 step: 1826, loss is 0.05672623589634895\n",
      "epoch: 1 step: 1827, loss is 0.06963463127613068\n",
      "epoch: 1 step: 1828, loss is 0.13474354147911072\n",
      "epoch: 1 step: 1829, loss is 0.04778417944908142\n",
      "epoch: 1 step: 1830, loss is 0.043480779975652695\n",
      "epoch: 1 step: 1831, loss is 0.01407886203378439\n",
      "epoch: 1 step: 1832, loss is 0.10341402888298035\n",
      "epoch: 1 step: 1833, loss is 0.0856751948595047\n",
      "epoch: 1 step: 1834, loss is 0.03561829403042793\n",
      "epoch: 1 step: 1835, loss is 0.120378278195858\n",
      "epoch: 1 step: 1836, loss is 0.0636262372136116\n",
      "epoch: 1 step: 1837, loss is 0.003063548356294632\n",
      "epoch: 1 step: 1838, loss is 0.03737389296293259\n",
      "epoch: 1 step: 1839, loss is 0.04522297903895378\n",
      "epoch: 1 step: 1840, loss is 0.018610475584864616\n",
      "epoch: 1 step: 1841, loss is 0.010386042296886444\n",
      "epoch: 1 step: 1842, loss is 0.16165675222873688\n",
      "epoch: 1 step: 1843, loss is 0.005997246131300926\n",
      "epoch: 1 step: 1844, loss is 0.20600435137748718\n",
      "epoch: 1 step: 1845, loss is 0.0007808880181983113\n",
      "epoch: 1 step: 1846, loss is 0.009307574480772018\n",
      "epoch: 1 step: 1847, loss is 0.0027542703319340944\n",
      "epoch: 1 step: 1848, loss is 0.14698749780654907\n",
      "epoch: 1 step: 1849, loss is 0.09614840149879456\n",
      "epoch: 1 step: 1850, loss is 0.0018747153226286173\n",
      "epoch: 1 step: 1851, loss is 0.08162429183721542\n",
      "epoch: 1 step: 1852, loss is 0.0931338295340538\n",
      "epoch: 1 step: 1853, loss is 0.017558971419930458\n",
      "epoch: 1 step: 1854, loss is 0.14126832783222198\n",
      "epoch: 1 step: 1855, loss is 0.04767431318759918\n",
      "epoch: 1 step: 1856, loss is 0.03863127902150154\n",
      "epoch: 1 step: 1857, loss is 0.2696792185306549\n",
      "epoch: 1 step: 1858, loss is 0.10544168949127197\n",
      "epoch: 1 step: 1859, loss is 0.24971254169940948\n",
      "epoch: 1 step: 1860, loss is 0.02583899162709713\n",
      "epoch: 1 step: 1861, loss is 0.2274932861328125\n",
      "epoch: 1 step: 1862, loss is 0.03672417625784874\n",
      "epoch: 1 step: 1863, loss is 0.01254548691213131\n",
      "epoch: 1 step: 1864, loss is 0.01327948085963726\n",
      "epoch: 1 step: 1865, loss is 0.06757545471191406\n",
      "epoch: 1 step: 1866, loss is 0.1537189930677414\n",
      "epoch: 1 step: 1867, loss is 0.4747878611087799\n",
      "epoch: 1 step: 1868, loss is 0.013183509930968285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1869, loss is 0.10151880979537964\n",
      "epoch: 1 step: 1870, loss is 0.007022312842309475\n",
      "epoch: 1 step: 1871, loss is 0.15927298367023468\n",
      "epoch: 1 step: 1872, loss is 0.011741270311176777\n",
      "epoch: 1 step: 1873, loss is 0.02782483957707882\n",
      "epoch: 1 step: 1874, loss is 0.05767851695418358\n",
      "epoch: 1 step: 1875, loss is 0.007893281988799572\n",
      "epoch: 1 step: 1876, loss is 0.1495991200208664\n",
      "epoch: 1 step: 1877, loss is 0.007201217580586672\n",
      "epoch: 1 step: 1878, loss is 0.044414177536964417\n",
      "epoch: 1 step: 1879, loss is 0.014730896800756454\n",
      "epoch: 1 step: 1880, loss is 0.023878516629338264\n",
      "epoch: 1 step: 1881, loss is 0.08600729703903198\n",
      "epoch: 1 step: 1882, loss is 0.05762689188122749\n",
      "epoch: 1 step: 1883, loss is 0.19915060698986053\n",
      "epoch: 1 step: 1884, loss is 0.03852972760796547\n",
      "epoch: 1 step: 1885, loss is 0.015817763283848763\n",
      "epoch: 1 step: 1886, loss is 0.006966069806367159\n",
      "epoch: 1 step: 1887, loss is 0.07390894740819931\n",
      "epoch: 1 step: 1888, loss is 0.046118054538965225\n",
      "epoch: 1 step: 1889, loss is 0.17113184928894043\n",
      "epoch: 1 step: 1890, loss is 0.011448378674685955\n",
      "epoch: 1 step: 1891, loss is 0.15546853840351105\n",
      "epoch: 1 step: 1892, loss is 0.0022091083228588104\n",
      "epoch: 1 step: 1893, loss is 0.29500553011894226\n",
      "epoch: 1 step: 1894, loss is 0.09493875503540039\n",
      "epoch: 1 step: 1895, loss is 0.0014228574000298977\n",
      "epoch: 1 step: 1896, loss is 0.057735417038202286\n",
      "epoch: 1 step: 1897, loss is 0.11290796101093292\n",
      "epoch: 1 step: 1898, loss is 0.04972653463482857\n",
      "epoch: 1 step: 1899, loss is 0.09243541210889816\n",
      "epoch: 1 step: 1900, loss is 0.010672514326870441\n",
      "epoch: 1 step: 1901, loss is 0.010042905807495117\n",
      "epoch: 1 step: 1902, loss is 0.0052054584957659245\n",
      "epoch: 1 step: 1903, loss is 0.2745569348335266\n",
      "epoch: 1 step: 1904, loss is 0.017245963215827942\n",
      "epoch: 1 step: 1905, loss is 0.007604547310620546\n",
      "epoch: 1 step: 1906, loss is 0.006415794137865305\n",
      "epoch: 1 step: 1907, loss is 0.12412513792514801\n",
      "epoch: 1 step: 1908, loss is 0.07928808778524399\n",
      "epoch: 1 step: 1909, loss is 0.05773499980568886\n",
      "epoch: 1 step: 1910, loss is 0.07119002938270569\n",
      "epoch: 1 step: 1911, loss is 0.25046825408935547\n",
      "epoch: 1 step: 1912, loss is 0.020588284358382225\n",
      "epoch: 1 step: 1913, loss is 0.005913600791245699\n",
      "epoch: 1 step: 1914, loss is 0.10337721556425095\n",
      "epoch: 1 step: 1915, loss is 0.19099773466587067\n",
      "epoch: 1 step: 1916, loss is 0.010386544279754162\n",
      "epoch: 1 step: 1917, loss is 0.035390421748161316\n",
      "epoch: 1 step: 1918, loss is 0.1353892982006073\n",
      "epoch: 1 step: 1919, loss is 0.0753878578543663\n",
      "epoch: 1 step: 1920, loss is 0.012186174280941486\n",
      "epoch: 1 step: 1921, loss is 0.01150352694094181\n",
      "epoch: 1 step: 1922, loss is 0.003684548195451498\n",
      "epoch: 1 step: 1923, loss is 0.011989683844149113\n",
      "epoch: 1 step: 1924, loss is 0.026365410536527634\n",
      "epoch: 1 step: 1925, loss is 0.018868060782551765\n",
      "epoch: 1 step: 1926, loss is 0.12252999097108841\n",
      "epoch: 1 step: 1927, loss is 0.014408493414521217\n",
      "epoch: 1 step: 1928, loss is 0.005967583041638136\n",
      "epoch: 1 step: 1929, loss is 0.026782408356666565\n",
      "epoch: 1 step: 1930, loss is 0.0030013318173587322\n",
      "epoch: 1 step: 1931, loss is 0.5066404342651367\n",
      "epoch: 1 step: 1932, loss is 0.003648080164566636\n",
      "epoch: 1 step: 1933, loss is 0.014559810981154442\n",
      "epoch: 1 step: 1934, loss is 0.1377047449350357\n",
      "epoch: 1 step: 1935, loss is 0.02114453911781311\n",
      "epoch: 1 step: 1936, loss is 0.3327431082725525\n",
      "epoch: 1 step: 1937, loss is 0.019417833536863327\n",
      "epoch: 1 step: 1938, loss is 0.016267981380224228\n",
      "epoch: 1 step: 1939, loss is 0.0795985609292984\n",
      "epoch: 1 step: 1940, loss is 0.007759361527860165\n",
      "epoch: 1 step: 1941, loss is 0.31656602025032043\n",
      "epoch: 1 step: 1942, loss is 0.002786265918985009\n",
      "epoch: 1 step: 1943, loss is 0.2816571593284607\n",
      "epoch: 1 step: 1944, loss is 0.0929548516869545\n",
      "epoch: 1 step: 1945, loss is 0.02803967334330082\n",
      "epoch: 1 step: 1946, loss is 0.03513175994157791\n",
      "epoch: 1 step: 1947, loss is 0.056996941566467285\n",
      "epoch: 1 step: 1948, loss is 0.10117378830909729\n",
      "epoch: 1 step: 1949, loss is 0.032496459782123566\n",
      "epoch: 1 step: 1950, loss is 0.014026941731572151\n",
      "epoch: 1 step: 1951, loss is 0.00300103472545743\n",
      "epoch: 1 step: 1952, loss is 0.02711266279220581\n",
      "epoch: 1 step: 1953, loss is 0.09739851206541061\n",
      "epoch: 1 step: 1954, loss is 0.018400881439447403\n",
      "epoch: 1 step: 1955, loss is 0.02681191824376583\n",
      "epoch: 1 step: 1956, loss is 0.06167278066277504\n",
      "epoch: 1 step: 1957, loss is 0.01327594369649887\n",
      "epoch: 1 step: 1958, loss is 0.025505272671580315\n",
      "epoch: 1 step: 1959, loss is 0.05325508117675781\n",
      "epoch: 1 step: 1960, loss is 0.0032835444435477257\n",
      "epoch: 1 step: 1961, loss is 0.0675460696220398\n",
      "epoch: 1 step: 1962, loss is 0.09030143916606903\n",
      "epoch: 1 step: 1963, loss is 0.07600629329681396\n",
      "epoch: 1 step: 1964, loss is 0.05289599299430847\n",
      "epoch: 1 step: 1965, loss is 0.0397731214761734\n",
      "epoch: 1 step: 1966, loss is 0.23137755692005157\n",
      "epoch: 1 step: 1967, loss is 0.04315457120537758\n",
      "epoch: 1 step: 1968, loss is 0.3118555247783661\n",
      "epoch: 1 step: 1969, loss is 0.05548003688454628\n",
      "epoch: 1 step: 1970, loss is 0.2589729428291321\n",
      "epoch: 1 step: 1971, loss is 0.01973389834165573\n",
      "epoch: 1 step: 1972, loss is 0.003922542091459036\n",
      "epoch: 1 step: 1973, loss is 0.14790219068527222\n",
      "epoch: 1 step: 1974, loss is 0.0009817148093134165\n",
      "epoch: 1 step: 1975, loss is 0.06018340215086937\n",
      "epoch: 1 step: 1976, loss is 0.11875591427087784\n",
      "epoch: 1 step: 1977, loss is 0.012617114931344986\n",
      "epoch: 1 step: 1978, loss is 0.03600231558084488\n",
      "epoch: 1 step: 1979, loss is 0.08424647897481918\n",
      "epoch: 1 step: 1980, loss is 0.11410935968160629\n",
      "epoch: 1 step: 1981, loss is 0.024097919464111328\n",
      "epoch: 1 step: 1982, loss is 0.015209933742880821\n",
      "epoch: 1 step: 1983, loss is 0.0895027443766594\n",
      "epoch: 1 step: 1984, loss is 0.20213976502418518\n",
      "epoch: 1 step: 1985, loss is 0.1157284677028656\n",
      "epoch: 1 step: 1986, loss is 0.07114008814096451\n",
      "epoch: 1 step: 1987, loss is 0.09233509749174118\n",
      "epoch: 1 step: 1988, loss is 0.053535282611846924\n",
      "epoch: 1 step: 1989, loss is 0.07168721407651901\n",
      "epoch: 1 step: 1990, loss is 0.07615429908037186\n",
      "epoch: 1 step: 1991, loss is 0.008103334344923496\n",
      "epoch: 1 step: 1992, loss is 0.04549538716673851\n",
      "epoch: 1 step: 1993, loss is 0.06973724812269211\n",
      "epoch: 1 step: 1994, loss is 0.037251923233270645\n",
      "epoch: 1 step: 1995, loss is 0.008661692030727863\n",
      "epoch: 1 step: 1996, loss is 0.11345437169075012\n",
      "epoch: 1 step: 1997, loss is 0.07012643665075302\n",
      "epoch: 1 step: 1998, loss is 0.0616777129471302\n",
      "epoch: 1 step: 1999, loss is 0.0025132005102932453\n",
      "epoch: 1 step: 2000, loss is 0.16693119704723358\n",
      "epoch: 1 step: 2001, loss is 0.12762078642845154\n",
      "epoch: 1 step: 2002, loss is 0.08715245872735977\n",
      "epoch: 1 step: 2003, loss is 0.03264173865318298\n",
      "epoch: 1 step: 2004, loss is 0.11963418871164322\n",
      "epoch: 1 step: 2005, loss is 0.03472810611128807\n",
      "epoch: 1 step: 2006, loss is 0.19272832572460175\n",
      "epoch: 1 step: 2007, loss is 0.02422744408249855\n",
      "epoch: 1 step: 2008, loss is 0.03657447546720505\n",
      "epoch: 1 step: 2009, loss is 0.05708499625325203\n",
      "epoch: 1 step: 2010, loss is 0.4815709888935089\n",
      "epoch: 1 step: 2011, loss is 0.034733619540929794\n",
      "epoch: 1 step: 2012, loss is 0.08922506868839264\n",
      "epoch: 1 step: 2013, loss is 0.03651442006230354\n",
      "epoch: 1 step: 2014, loss is 0.008311212994158268\n",
      "epoch: 1 step: 2015, loss is 0.0029368300456553698\n",
      "epoch: 1 step: 2016, loss is 0.1248309463262558\n",
      "epoch: 1 step: 2017, loss is 0.010409370996057987\n",
      "epoch: 1 step: 2018, loss is 0.08049046993255615\n",
      "epoch: 1 step: 2019, loss is 0.20952220261096954\n",
      "epoch: 1 step: 2020, loss is 0.07114864885807037\n",
      "epoch: 1 step: 2021, loss is 0.041187383234500885\n",
      "epoch: 1 step: 2022, loss is 0.026457879692316055\n",
      "epoch: 1 step: 2023, loss is 0.17995966970920563\n",
      "epoch: 1 step: 2024, loss is 0.0209723599255085\n",
      "epoch: 1 step: 2025, loss is 0.020305659621953964\n",
      "epoch: 1 step: 2026, loss is 0.2831094563007355\n",
      "epoch: 1 step: 2027, loss is 0.026420162990689278\n",
      "epoch: 1 step: 2028, loss is 0.05929627642035484\n",
      "epoch: 1 step: 2029, loss is 0.0022445525974035263\n",
      "epoch: 1 step: 2030, loss is 0.029627416282892227\n",
      "epoch: 1 step: 2031, loss is 0.012684384360909462\n",
      "epoch: 1 step: 2032, loss is 0.005234639625996351\n",
      "epoch: 1 step: 2033, loss is 0.0009211875731125474\n",
      "epoch: 1 step: 2034, loss is 0.20758506655693054\n",
      "epoch: 1 step: 2035, loss is 0.023408420383930206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 2036, loss is 0.012469121254980564\n",
      "epoch: 1 step: 2037, loss is 0.024066641926765442\n",
      "epoch: 1 step: 2038, loss is 0.04525028169155121\n",
      "epoch: 1 step: 2039, loss is 0.046636395156383514\n",
      "epoch: 1 step: 2040, loss is 0.018521582707762718\n",
      "epoch: 1 step: 2041, loss is 0.05916030704975128\n",
      "epoch: 1 step: 2042, loss is 0.21266034245491028\n",
      "epoch: 1 step: 2043, loss is 0.12001945078372955\n",
      "epoch: 1 step: 2044, loss is 0.03446924686431885\n",
      "epoch: 1 step: 2045, loss is 0.03990945592522621\n",
      "epoch: 1 step: 2046, loss is 0.0695941299200058\n",
      "epoch: 1 step: 2047, loss is 0.005954862106591463\n",
      "epoch: 1 step: 2048, loss is 0.09586509317159653\n",
      "epoch: 1 step: 2049, loss is 0.027880152687430382\n",
      "epoch: 1 step: 2050, loss is 0.27306705713272095\n",
      "epoch: 1 step: 2051, loss is 0.01887589879333973\n",
      "epoch: 1 step: 2052, loss is 0.13615064322948456\n",
      "epoch: 1 step: 2053, loss is 0.002181887160986662\n",
      "epoch: 1 step: 2054, loss is 0.07316244393587112\n",
      "epoch: 1 step: 2055, loss is 0.020839383825659752\n",
      "epoch: 1 step: 2056, loss is 0.10082961618900299\n",
      "epoch: 1 step: 2057, loss is 0.015829337760806084\n",
      "epoch: 1 step: 2058, loss is 0.0031631523743271828\n",
      "epoch: 1 step: 2059, loss is 0.04517493024468422\n",
      "epoch: 1 step: 2060, loss is 0.0820290595293045\n",
      "epoch: 1 step: 2061, loss is 0.029602687805891037\n",
      "epoch: 1 step: 2062, loss is 0.1716434806585312\n",
      "epoch: 1 step: 2063, loss is 0.1345500946044922\n",
      "epoch: 1 step: 2064, loss is 0.038604654371738434\n",
      "epoch: 1 step: 2065, loss is 0.01509118266403675\n",
      "epoch: 1 step: 2066, loss is 0.023190289735794067\n",
      "epoch: 1 step: 2067, loss is 0.10298864543437958\n",
      "epoch: 1 step: 2068, loss is 0.2760118544101715\n",
      "epoch: 1 step: 2069, loss is 0.1526605784893036\n",
      "epoch: 1 step: 2070, loss is 0.014741552993655205\n",
      "epoch: 1 step: 2071, loss is 0.02716073766350746\n",
      "epoch: 1 step: 2072, loss is 0.10846440494060516\n",
      "epoch: 1 step: 2073, loss is 0.09891689568758011\n",
      "epoch: 1 step: 2074, loss is 0.007569164503365755\n",
      "epoch: 1 step: 2075, loss is 0.04390653595328331\n",
      "epoch: 1 step: 2076, loss is 0.005645664408802986\n",
      "epoch: 1 step: 2077, loss is 0.024557914584875107\n",
      "epoch: 1 step: 2078, loss is 0.147142231464386\n",
      "epoch: 1 step: 2079, loss is 0.03767136484384537\n",
      "epoch: 1 step: 2080, loss is 0.07310785353183746\n",
      "epoch: 1 step: 2081, loss is 0.08479496091604233\n",
      "epoch: 1 step: 2082, loss is 0.008817913010716438\n",
      "epoch: 1 step: 2083, loss is 0.19135123491287231\n",
      "epoch: 1 step: 2084, loss is 0.003163837594911456\n",
      "epoch: 1 step: 2085, loss is 0.07442188262939453\n",
      "epoch: 1 step: 2086, loss is 0.07727599889039993\n",
      "epoch: 1 step: 2087, loss is 0.04055078327655792\n",
      "epoch: 1 step: 2088, loss is 0.012361702509224415\n",
      "epoch: 1 step: 2089, loss is 0.13217753171920776\n",
      "epoch: 1 step: 2090, loss is 0.012227448634803295\n",
      "epoch: 1 step: 2091, loss is 0.007231938187032938\n",
      "epoch: 1 step: 2092, loss is 0.006066701374948025\n",
      "epoch: 1 step: 2093, loss is 0.15689700841903687\n",
      "epoch: 1 step: 2094, loss is 0.010927959345281124\n",
      "epoch: 1 step: 2095, loss is 0.001544538652524352\n",
      "epoch: 1 step: 2096, loss is 0.10769359022378922\n",
      "epoch: 1 step: 2097, loss is 0.17752860486507416\n",
      "epoch: 1 step: 2098, loss is 0.15523654222488403\n",
      "epoch: 1 step: 2099, loss is 0.014548609964549541\n",
      "epoch: 1 step: 2100, loss is 0.06254614144563675\n",
      "epoch: 1 step: 2101, loss is 0.15033194422721863\n",
      "epoch: 1 step: 2102, loss is 0.23460368812084198\n",
      "epoch: 1 step: 2103, loss is 0.004430937580764294\n",
      "epoch: 1 step: 2104, loss is 0.0527837835252285\n",
      "epoch: 1 step: 2105, loss is 0.006170156877487898\n",
      "epoch: 1 step: 2106, loss is 0.011764719150960445\n",
      "epoch: 1 step: 2107, loss is 0.0396408848464489\n",
      "epoch: 1 step: 2108, loss is 0.011544416658580303\n",
      "epoch: 1 step: 2109, loss is 0.0067384676076471806\n",
      "epoch: 1 step: 2110, loss is 0.10610532015562057\n",
      "epoch: 1 step: 2111, loss is 0.0065688481554389\n",
      "epoch: 1 step: 2112, loss is 0.14262822270393372\n",
      "epoch: 1 step: 2113, loss is 0.0332639217376709\n",
      "epoch: 1 step: 2114, loss is 0.030709195882081985\n",
      "epoch: 1 step: 2115, loss is 0.008080540224909782\n",
      "epoch: 1 step: 2116, loss is 0.04659225046634674\n",
      "epoch: 1 step: 2117, loss is 0.1600124090909958\n",
      "epoch: 1 step: 2118, loss is 0.014737444929778576\n",
      "epoch: 1 step: 2119, loss is 0.23244509100914001\n",
      "epoch: 1 step: 2120, loss is 0.00556330056861043\n",
      "epoch: 1 step: 2121, loss is 0.22780631482601166\n",
      "epoch: 1 step: 2122, loss is 0.3219963610172272\n",
      "epoch: 1 step: 2123, loss is 0.017106592655181885\n",
      "epoch: 1 step: 2124, loss is 0.014052484184503555\n",
      "epoch: 1 step: 2125, loss is 0.2786233127117157\n",
      "epoch: 1 step: 2126, loss is 0.07630845159292221\n",
      "epoch: 1 step: 2127, loss is 0.1516977697610855\n",
      "epoch: 1 step: 2128, loss is 0.004918306600302458\n",
      "epoch: 1 step: 2129, loss is 0.03023768588900566\n",
      "epoch: 1 step: 2130, loss is 0.06387331336736679\n",
      "epoch: 1 step: 2131, loss is 0.03300490975379944\n",
      "epoch: 1 step: 2132, loss is 0.08501512557268143\n",
      "epoch: 1 step: 2133, loss is 0.0066025168634951115\n",
      "epoch: 1 step: 2134, loss is 0.10989344120025635\n",
      "epoch: 1 step: 2135, loss is 0.08883551508188248\n",
      "epoch: 1 step: 2136, loss is 0.09483163803815842\n",
      "epoch: 1 step: 2137, loss is 0.11036230623722076\n",
      "epoch: 1 step: 2138, loss is 0.15421156585216522\n",
      "epoch: 1 step: 2139, loss is 0.051251672208309174\n",
      "epoch: 1 step: 2140, loss is 0.33556926250457764\n",
      "epoch: 1 step: 2141, loss is 0.14570501446723938\n",
      "epoch: 1 step: 2142, loss is 0.30701518058776855\n",
      "epoch: 1 step: 2143, loss is 0.09094615280628204\n",
      "epoch: 1 step: 2144, loss is 0.04509352520108223\n",
      "epoch: 1 step: 2145, loss is 0.005200413055717945\n",
      "epoch: 1 step: 2146, loss is 0.24442371726036072\n",
      "epoch: 1 step: 2147, loss is 0.13658058643341064\n",
      "epoch: 1 step: 2148, loss is 0.027197059243917465\n",
      "epoch: 1 step: 2149, loss is 0.01689145900309086\n",
      "epoch: 1 step: 2150, loss is 0.017351994290947914\n",
      "epoch: 1 step: 2151, loss is 0.0421094186604023\n",
      "epoch: 1 step: 2152, loss is 0.004045325797051191\n",
      "epoch: 1 step: 2153, loss is 0.016602259129285812\n",
      "epoch: 1 step: 2154, loss is 0.06756217777729034\n",
      "epoch: 1 step: 2155, loss is 0.026010558009147644\n",
      "epoch: 1 step: 2156, loss is 0.002272021723911166\n",
      "epoch: 1 step: 2157, loss is 0.06995020061731339\n",
      "epoch: 1 step: 2158, loss is 0.00783613696694374\n",
      "epoch: 1 step: 2159, loss is 0.06384158134460449\n",
      "epoch: 1 step: 2160, loss is 0.10701743513345718\n",
      "epoch: 1 step: 2161, loss is 0.05532239004969597\n",
      "epoch: 1 step: 2162, loss is 0.053715553134679794\n",
      "epoch: 1 step: 2163, loss is 0.0036073157098144293\n",
      "epoch: 1 step: 2164, loss is 0.27775871753692627\n",
      "epoch: 1 step: 2165, loss is 0.02239351160824299\n",
      "epoch: 1 step: 2166, loss is 0.24016793072223663\n",
      "epoch: 1 step: 2167, loss is 0.004896041005849838\n",
      "epoch: 1 step: 2168, loss is 0.00833181943744421\n",
      "epoch: 1 step: 2169, loss is 0.07766184955835342\n",
      "epoch: 1 step: 2170, loss is 0.08258256316184998\n",
      "epoch: 1 step: 2171, loss is 0.018612027168273926\n",
      "epoch: 1 step: 2172, loss is 0.031837765127420425\n",
      "epoch: 1 step: 2173, loss is 0.004878262523561716\n",
      "epoch: 1 step: 2174, loss is 0.03184155002236366\n",
      "epoch: 1 step: 2175, loss is 0.003914467990398407\n",
      "epoch: 1 step: 2176, loss is 0.11798666417598724\n",
      "epoch: 1 step: 2177, loss is 0.017198259010910988\n",
      "epoch: 1 step: 2178, loss is 0.004229754209518433\n",
      "epoch: 1 step: 2179, loss is 0.24730892479419708\n",
      "epoch: 1 step: 2180, loss is 0.06831970065832138\n",
      "epoch: 1 step: 2181, loss is 0.0050074150785803795\n",
      "epoch: 1 step: 2182, loss is 0.08059462159872055\n",
      "epoch: 1 step: 2183, loss is 0.06536349654197693\n",
      "epoch: 1 step: 2184, loss is 0.02958434633910656\n",
      "epoch: 1 step: 2185, loss is 0.17808470129966736\n",
      "epoch: 1 step: 2186, loss is 0.004047563765197992\n",
      "epoch: 1 step: 2187, loss is 0.04498518258333206\n",
      "epoch: 2 step: 1, loss is 0.00304581830278039\n",
      "epoch: 2 step: 2, loss is 0.02189852111041546\n",
      "epoch: 2 step: 3, loss is 0.07343075424432755\n",
      "epoch: 2 step: 4, loss is 0.04741678386926651\n",
      "epoch: 2 step: 5, loss is 0.006960519589483738\n",
      "epoch: 2 step: 6, loss is 0.12948185205459595\n",
      "epoch: 2 step: 7, loss is 0.34242013096809387\n",
      "epoch: 2 step: 8, loss is 0.04500141367316246\n",
      "epoch: 2 step: 9, loss is 0.07678399980068207\n",
      "epoch: 2 step: 10, loss is 0.009330223314464092\n",
      "epoch: 2 step: 11, loss is 0.013136674650013447\n",
      "epoch: 2 step: 12, loss is 0.2590388059616089\n",
      "epoch: 2 step: 13, loss is 0.017291229218244553\n",
      "epoch: 2 step: 14, loss is 0.03477877005934715\n",
      "epoch: 2 step: 15, loss is 0.021057672798633575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 16, loss is 0.06100604683160782\n",
      "epoch: 2 step: 17, loss is 0.024007173255085945\n",
      "epoch: 2 step: 18, loss is 0.010738963261246681\n",
      "epoch: 2 step: 19, loss is 0.006826065946370363\n",
      "epoch: 2 step: 20, loss is 0.10025569796562195\n",
      "epoch: 2 step: 21, loss is 0.002188390353694558\n",
      "epoch: 2 step: 22, loss is 0.3281690776348114\n",
      "epoch: 2 step: 23, loss is 0.04626629501581192\n",
      "epoch: 2 step: 24, loss is 0.014061564579606056\n",
      "epoch: 2 step: 25, loss is 0.0271637961268425\n",
      "epoch: 2 step: 26, loss is 0.013628214597702026\n",
      "epoch: 2 step: 27, loss is 0.025987083092331886\n",
      "epoch: 2 step: 28, loss is 0.06193333491683006\n",
      "epoch: 2 step: 29, loss is 0.022467663511633873\n",
      "epoch: 2 step: 30, loss is 0.023733850568532944\n",
      "epoch: 2 step: 31, loss is 0.08477118611335754\n",
      "epoch: 2 step: 32, loss is 0.12424872070550919\n",
      "epoch: 2 step: 33, loss is 0.004547164775431156\n",
      "epoch: 2 step: 34, loss is 0.1099422350525856\n",
      "epoch: 2 step: 35, loss is 0.06600237637758255\n",
      "epoch: 2 step: 36, loss is 0.00460507906973362\n",
      "epoch: 2 step: 37, loss is 0.011612171307206154\n",
      "epoch: 2 step: 38, loss is 0.02180846780538559\n",
      "epoch: 2 step: 39, loss is 0.010708530433475971\n",
      "epoch: 2 step: 40, loss is 0.1225767657160759\n",
      "epoch: 2 step: 41, loss is 0.0863519236445427\n",
      "epoch: 2 step: 42, loss is 0.1716836839914322\n",
      "epoch: 2 step: 43, loss is 0.061931509524583817\n",
      "epoch: 2 step: 44, loss is 0.03567052632570267\n",
      "epoch: 2 step: 45, loss is 0.007481346372514963\n",
      "epoch: 2 step: 46, loss is 0.004563795868307352\n",
      "epoch: 2 step: 47, loss is 0.2833384871482849\n",
      "epoch: 2 step: 48, loss is 0.008757337927818298\n",
      "epoch: 2 step: 49, loss is 0.0023962731938809156\n",
      "epoch: 2 step: 50, loss is 0.17710727453231812\n",
      "epoch: 2 step: 51, loss is 0.06653743982315063\n",
      "epoch: 2 step: 52, loss is 0.03928383067250252\n",
      "epoch: 2 step: 53, loss is 0.010916205123066902\n",
      "epoch: 2 step: 54, loss is 0.016513649374246597\n",
      "epoch: 2 step: 55, loss is 0.0251440592110157\n",
      "epoch: 2 step: 56, loss is 0.01888563483953476\n",
      "epoch: 2 step: 57, loss is 0.02996101789176464\n",
      "epoch: 2 step: 58, loss is 0.011069885455071926\n",
      "epoch: 2 step: 59, loss is 0.16932086646556854\n",
      "epoch: 2 step: 60, loss is 0.059284135699272156\n",
      "epoch: 2 step: 61, loss is 0.01124492660164833\n",
      "epoch: 2 step: 62, loss is 0.02927875518798828\n",
      "epoch: 2 step: 63, loss is 0.006879047490656376\n",
      "epoch: 2 step: 64, loss is 0.003485671943053603\n",
      "epoch: 2 step: 65, loss is 0.03939078748226166\n",
      "epoch: 2 step: 66, loss is 0.013808582909405231\n",
      "epoch: 2 step: 67, loss is 0.004340837709605694\n",
      "epoch: 2 step: 68, loss is 0.1094692274928093\n",
      "epoch: 2 step: 69, loss is 0.02293669618666172\n",
      "epoch: 2 step: 70, loss is 0.013754751533269882\n",
      "epoch: 2 step: 71, loss is 0.09223559498786926\n",
      "epoch: 2 step: 72, loss is 0.09747432172298431\n",
      "epoch: 2 step: 73, loss is 0.009243100881576538\n",
      "epoch: 2 step: 74, loss is 0.012361221015453339\n",
      "epoch: 2 step: 75, loss is 0.07216791808605194\n",
      "epoch: 2 step: 76, loss is 0.004166102968156338\n",
      "epoch: 2 step: 77, loss is 0.009364200755953789\n",
      "epoch: 2 step: 78, loss is 0.015198138542473316\n",
      "epoch: 2 step: 79, loss is 0.039717670530080795\n",
      "epoch: 2 step: 80, loss is 0.008323940448462963\n",
      "epoch: 2 step: 81, loss is 0.023013250902295113\n",
      "epoch: 2 step: 82, loss is 0.16609179973602295\n",
      "epoch: 2 step: 83, loss is 0.025840282440185547\n",
      "epoch: 2 step: 84, loss is 0.001018036506138742\n",
      "epoch: 2 step: 85, loss is 0.0016528349369764328\n",
      "epoch: 2 step: 86, loss is 0.011713368818163872\n",
      "epoch: 2 step: 87, loss is 0.024179330095648766\n",
      "epoch: 2 step: 88, loss is 0.024681096896529198\n",
      "epoch: 2 step: 89, loss is 0.0012232885928824544\n",
      "epoch: 2 step: 90, loss is 0.027841104194521904\n",
      "epoch: 2 step: 91, loss is 0.002911270596086979\n",
      "epoch: 2 step: 92, loss is 0.007562215905636549\n",
      "epoch: 2 step: 93, loss is 0.008016768842935562\n",
      "epoch: 2 step: 94, loss is 0.299672394990921\n",
      "epoch: 2 step: 95, loss is 0.12349369376897812\n",
      "epoch: 2 step: 96, loss is 0.0005841896054334939\n",
      "epoch: 2 step: 97, loss is 0.024774936959147453\n",
      "epoch: 2 step: 98, loss is 0.06035665422677994\n",
      "epoch: 2 step: 99, loss is 0.10719887912273407\n",
      "epoch: 2 step: 100, loss is 0.17030535638332367\n",
      "epoch: 2 step: 101, loss is 0.04051816463470459\n",
      "epoch: 2 step: 102, loss is 0.024334678426384926\n",
      "epoch: 2 step: 103, loss is 0.013943301513791084\n",
      "epoch: 2 step: 104, loss is 0.012874739244580269\n",
      "epoch: 2 step: 105, loss is 0.006686522159725428\n",
      "epoch: 2 step: 106, loss is 0.03921361267566681\n",
      "epoch: 2 step: 107, loss is 0.06965862214565277\n",
      "epoch: 2 step: 108, loss is 0.09588123112916946\n",
      "epoch: 2 step: 109, loss is 0.00801444798707962\n",
      "epoch: 2 step: 110, loss is 0.004791774787008762\n",
      "epoch: 2 step: 111, loss is 0.19761329889297485\n",
      "epoch: 2 step: 112, loss is 0.02181950956583023\n",
      "epoch: 2 step: 113, loss is 0.020770838484168053\n",
      "epoch: 2 step: 114, loss is 0.24060486257076263\n",
      "epoch: 2 step: 115, loss is 0.07571257650852203\n",
      "epoch: 2 step: 116, loss is 0.18521061539649963\n",
      "epoch: 2 step: 117, loss is 0.0373610220849514\n",
      "epoch: 2 step: 118, loss is 0.007043357938528061\n",
      "epoch: 2 step: 119, loss is 0.11660999804735184\n",
      "epoch: 2 step: 120, loss is 0.014191579073667526\n",
      "epoch: 2 step: 121, loss is 0.03333643078804016\n",
      "epoch: 2 step: 122, loss is 0.11184849590063095\n",
      "epoch: 2 step: 123, loss is 0.03348936140537262\n",
      "epoch: 2 step: 124, loss is 0.00721081392839551\n",
      "epoch: 2 step: 125, loss is 0.046577055007219315\n",
      "epoch: 2 step: 126, loss is 0.19514985382556915\n",
      "epoch: 2 step: 127, loss is 0.11278273165225983\n",
      "epoch: 2 step: 128, loss is 0.11602848023176193\n",
      "epoch: 2 step: 129, loss is 0.018334174528717995\n",
      "epoch: 2 step: 130, loss is 0.013856825418770313\n",
      "epoch: 2 step: 131, loss is 0.048686519265174866\n",
      "epoch: 2 step: 132, loss is 0.03416275233030319\n",
      "epoch: 2 step: 133, loss is 0.03375691547989845\n",
      "epoch: 2 step: 134, loss is 0.07758660614490509\n",
      "epoch: 2 step: 135, loss is 0.04074155539274216\n",
      "epoch: 2 step: 136, loss is 0.05840452015399933\n",
      "epoch: 2 step: 137, loss is 0.0018270426662638783\n",
      "epoch: 2 step: 138, loss is 0.001968376338481903\n",
      "epoch: 2 step: 139, loss is 0.014712759293615818\n",
      "epoch: 2 step: 140, loss is 0.09146328270435333\n",
      "epoch: 2 step: 141, loss is 0.040490590035915375\n",
      "epoch: 2 step: 142, loss is 0.1600727140903473\n",
      "epoch: 2 step: 143, loss is 0.032442357391119\n",
      "epoch: 2 step: 144, loss is 0.08066597580909729\n",
      "epoch: 2 step: 145, loss is 0.042666882276535034\n",
      "epoch: 2 step: 146, loss is 0.010667241178452969\n",
      "epoch: 2 step: 147, loss is 0.07986350357532501\n",
      "epoch: 2 step: 148, loss is 0.017130039632320404\n",
      "epoch: 2 step: 149, loss is 0.07004199177026749\n",
      "epoch: 2 step: 150, loss is 0.008646148256957531\n",
      "epoch: 2 step: 151, loss is 0.0016019027680158615\n",
      "epoch: 2 step: 152, loss is 0.0013394784182310104\n",
      "epoch: 2 step: 153, loss is 0.10321250557899475\n",
      "epoch: 2 step: 154, loss is 0.007416602224111557\n",
      "epoch: 2 step: 155, loss is 0.1396331638097763\n",
      "epoch: 2 step: 156, loss is 0.007637457922101021\n",
      "epoch: 2 step: 157, loss is 0.1503121703863144\n",
      "epoch: 2 step: 158, loss is 0.0961107686161995\n",
      "epoch: 2 step: 159, loss is 0.035612184554338455\n",
      "epoch: 2 step: 160, loss is 0.017759036272764206\n",
      "epoch: 2 step: 161, loss is 0.07151880115270615\n",
      "epoch: 2 step: 162, loss is 0.22275279462337494\n",
      "epoch: 2 step: 163, loss is 0.06346721202135086\n",
      "epoch: 2 step: 164, loss is 0.17553594708442688\n",
      "epoch: 2 step: 165, loss is 0.013928646221756935\n",
      "epoch: 2 step: 166, loss is 0.010619757696986198\n",
      "epoch: 2 step: 167, loss is 0.09890101104974747\n",
      "epoch: 2 step: 168, loss is 0.015347153879702091\n",
      "epoch: 2 step: 169, loss is 0.03348749503493309\n",
      "epoch: 2 step: 170, loss is 0.08489686995744705\n",
      "epoch: 2 step: 171, loss is 0.08921492099761963\n",
      "epoch: 2 step: 172, loss is 0.010480191558599472\n",
      "epoch: 2 step: 173, loss is 0.020197808742523193\n",
      "epoch: 2 step: 174, loss is 0.024414731189608574\n",
      "epoch: 2 step: 175, loss is 0.020182106643915176\n",
      "epoch: 2 step: 176, loss is 0.014945837669074535\n",
      "epoch: 2 step: 177, loss is 0.044852301478385925\n",
      "epoch: 2 step: 178, loss is 0.09794948995113373\n",
      "epoch: 2 step: 179, loss is 0.002295747632160783\n",
      "epoch: 2 step: 180, loss is 0.04943171888589859\n",
      "epoch: 2 step: 181, loss is 0.04640118032693863\n",
      "epoch: 2 step: 182, loss is 0.04735090211033821\n",
      "epoch: 2 step: 183, loss is 0.0032160887494683266\n",
      "epoch: 2 step: 184, loss is 0.07641679793596268\n",
      "epoch: 2 step: 185, loss is 0.002225451171398163\n",
      "epoch: 2 step: 186, loss is 0.0954912006855011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 187, loss is 0.0029210741631686687\n",
      "epoch: 2 step: 188, loss is 0.09262656420469284\n",
      "epoch: 2 step: 189, loss is 0.051439233124256134\n",
      "epoch: 2 step: 190, loss is 0.006674550473690033\n",
      "epoch: 2 step: 191, loss is 0.0023484104312956333\n",
      "epoch: 2 step: 192, loss is 0.010242295451462269\n",
      "epoch: 2 step: 193, loss is 0.06549658626317978\n",
      "epoch: 2 step: 194, loss is 0.03228284791111946\n",
      "epoch: 2 step: 195, loss is 0.013376508839428425\n",
      "epoch: 2 step: 196, loss is 0.005419047549366951\n",
      "epoch: 2 step: 197, loss is 0.0007548260036855936\n",
      "epoch: 2 step: 198, loss is 0.1187121719121933\n",
      "epoch: 2 step: 199, loss is 0.032066475600004196\n",
      "epoch: 2 step: 200, loss is 0.014822406694293022\n",
      "epoch: 2 step: 201, loss is 0.024967726320028305\n",
      "epoch: 2 step: 202, loss is 0.06221739947795868\n",
      "epoch: 2 step: 203, loss is 0.4359198808670044\n",
      "epoch: 2 step: 204, loss is 0.120168037712574\n",
      "epoch: 2 step: 205, loss is 0.1380840390920639\n",
      "epoch: 2 step: 206, loss is 0.10555221885442734\n",
      "epoch: 2 step: 207, loss is 0.0077064186334609985\n",
      "epoch: 2 step: 208, loss is 0.24144691228866577\n",
      "epoch: 2 step: 209, loss is 0.008582230657339096\n",
      "epoch: 2 step: 210, loss is 0.15988312661647797\n",
      "epoch: 2 step: 211, loss is 0.11288712918758392\n",
      "epoch: 2 step: 212, loss is 0.05169036239385605\n",
      "epoch: 2 step: 213, loss is 0.0961008071899414\n",
      "epoch: 2 step: 214, loss is 0.055575110018253326\n",
      "epoch: 2 step: 215, loss is 0.05420200526714325\n",
      "epoch: 2 step: 216, loss is 0.037389371544122696\n",
      "epoch: 2 step: 217, loss is 0.0039518726989626884\n",
      "epoch: 2 step: 218, loss is 0.07336004823446274\n",
      "epoch: 2 step: 219, loss is 0.08604978770017624\n",
      "epoch: 2 step: 220, loss is 0.002884738380089402\n",
      "epoch: 2 step: 221, loss is 0.0027989433147013187\n",
      "epoch: 2 step: 222, loss is 0.14076939225196838\n",
      "epoch: 2 step: 223, loss is 0.030450766906142235\n",
      "epoch: 2 step: 224, loss is 0.014430561102926731\n",
      "epoch: 2 step: 225, loss is 0.007831016555428505\n",
      "epoch: 2 step: 226, loss is 0.01195884682238102\n",
      "epoch: 2 step: 227, loss is 0.010306132026016712\n",
      "epoch: 2 step: 228, loss is 0.07070091366767883\n",
      "epoch: 2 step: 229, loss is 0.09751579165458679\n",
      "epoch: 2 step: 230, loss is 0.01238155271857977\n",
      "epoch: 2 step: 231, loss is 0.017609892413020134\n",
      "epoch: 2 step: 232, loss is 0.2624126970767975\n",
      "epoch: 2 step: 233, loss is 0.05909343436360359\n",
      "epoch: 2 step: 234, loss is 0.03208708390593529\n",
      "epoch: 2 step: 235, loss is 0.0015674192691221833\n",
      "epoch: 2 step: 236, loss is 0.05613115802407265\n",
      "epoch: 2 step: 237, loss is 0.05793878808617592\n",
      "epoch: 2 step: 238, loss is 0.004511210136115551\n",
      "epoch: 2 step: 239, loss is 0.005391725804656744\n",
      "epoch: 2 step: 240, loss is 0.046096593141555786\n",
      "epoch: 2 step: 241, loss is 0.2573181390762329\n",
      "epoch: 2 step: 242, loss is 0.03653664514422417\n",
      "epoch: 2 step: 243, loss is 0.08823707699775696\n",
      "epoch: 2 step: 244, loss is 0.016427308320999146\n",
      "epoch: 2 step: 245, loss is 0.03049284964799881\n",
      "epoch: 2 step: 246, loss is 0.09174291044473648\n",
      "epoch: 2 step: 247, loss is 0.11117777228355408\n",
      "epoch: 2 step: 248, loss is 0.06596667319536209\n",
      "epoch: 2 step: 249, loss is 0.010138299316167831\n",
      "epoch: 2 step: 250, loss is 0.21069343388080597\n",
      "epoch: 2 step: 251, loss is 0.3400852084159851\n",
      "epoch: 2 step: 252, loss is 0.08293598145246506\n",
      "epoch: 2 step: 253, loss is 0.015709079802036285\n",
      "epoch: 2 step: 254, loss is 0.0840035080909729\n",
      "epoch: 2 step: 255, loss is 0.00793954636901617\n",
      "epoch: 2 step: 256, loss is 0.00988072995096445\n",
      "epoch: 2 step: 257, loss is 0.1759122759103775\n",
      "epoch: 2 step: 258, loss is 0.02192413993179798\n",
      "epoch: 2 step: 259, loss is 0.004883253946900368\n",
      "epoch: 2 step: 260, loss is 0.03077254816889763\n",
      "epoch: 2 step: 261, loss is 0.016437672078609467\n",
      "epoch: 2 step: 262, loss is 0.12259970605373383\n",
      "epoch: 2 step: 263, loss is 0.07073557376861572\n",
      "epoch: 2 step: 264, loss is 0.13001154363155365\n",
      "epoch: 2 step: 265, loss is 0.07633532583713531\n",
      "epoch: 2 step: 266, loss is 0.02060985006392002\n",
      "epoch: 2 step: 267, loss is 0.0024609353858977556\n",
      "epoch: 2 step: 268, loss is 0.009489904157817364\n",
      "epoch: 2 step: 269, loss is 0.005343659780919552\n",
      "epoch: 2 step: 270, loss is 0.007263231556862593\n",
      "epoch: 2 step: 271, loss is 0.029312118887901306\n",
      "epoch: 2 step: 272, loss is 0.144987553358078\n",
      "epoch: 2 step: 273, loss is 0.019004279747605324\n",
      "epoch: 2 step: 274, loss is 0.04972711205482483\n",
      "epoch: 2 step: 275, loss is 0.035512592643499374\n",
      "epoch: 2 step: 276, loss is 0.03149263933300972\n",
      "epoch: 2 step: 277, loss is 0.00913555733859539\n",
      "epoch: 2 step: 278, loss is 0.013829330913722515\n",
      "epoch: 2 step: 279, loss is 0.013549845665693283\n",
      "epoch: 2 step: 280, loss is 0.1334044188261032\n",
      "epoch: 2 step: 281, loss is 0.06615682691335678\n",
      "epoch: 2 step: 282, loss is 0.20426185429096222\n",
      "epoch: 2 step: 283, loss is 0.07667176425457001\n",
      "epoch: 2 step: 284, loss is 0.026980087161064148\n",
      "epoch: 2 step: 285, loss is 0.011548475362360477\n",
      "epoch: 2 step: 286, loss is 0.0017631200607866049\n",
      "epoch: 2 step: 287, loss is 0.01037649903446436\n",
      "epoch: 2 step: 288, loss is 0.003400756511837244\n",
      "epoch: 2 step: 289, loss is 0.07100449502468109\n",
      "epoch: 2 step: 290, loss is 0.003005208447575569\n",
      "epoch: 2 step: 291, loss is 0.007547616958618164\n",
      "epoch: 2 step: 292, loss is 0.02519252896308899\n",
      "epoch: 2 step: 293, loss is 0.019847901538014412\n",
      "epoch: 2 step: 294, loss is 0.008318588137626648\n",
      "epoch: 2 step: 295, loss is 0.006030272226780653\n",
      "epoch: 2 step: 296, loss is 0.05154682323336601\n",
      "epoch: 2 step: 297, loss is 0.015127786435186863\n",
      "epoch: 2 step: 298, loss is 0.0441206693649292\n",
      "epoch: 2 step: 299, loss is 0.03333233669400215\n",
      "epoch: 2 step: 300, loss is 0.0023454539477825165\n",
      "epoch: 2 step: 301, loss is 0.009115136228501797\n",
      "epoch: 2 step: 302, loss is 0.025998026132583618\n",
      "epoch: 2 step: 303, loss is 0.1250782161951065\n",
      "epoch: 2 step: 304, loss is 0.0755954459309578\n",
      "epoch: 2 step: 305, loss is 0.0017153079388663173\n",
      "epoch: 2 step: 306, loss is 0.004946214146912098\n",
      "epoch: 2 step: 307, loss is 0.021123524755239487\n",
      "epoch: 2 step: 308, loss is 0.011314363218843937\n",
      "epoch: 2 step: 309, loss is 0.07510420680046082\n",
      "epoch: 2 step: 310, loss is 0.007521557155996561\n",
      "epoch: 2 step: 311, loss is 0.011728559620678425\n",
      "epoch: 2 step: 312, loss is 0.17468152940273285\n",
      "epoch: 2 step: 313, loss is 0.14095918834209442\n",
      "epoch: 2 step: 314, loss is 0.00245244475081563\n",
      "epoch: 2 step: 315, loss is 0.07832007855176926\n",
      "epoch: 2 step: 316, loss is 0.13612565398216248\n",
      "epoch: 2 step: 317, loss is 0.06348738074302673\n",
      "epoch: 2 step: 318, loss is 0.008796620182693005\n",
      "epoch: 2 step: 319, loss is 0.03832225874066353\n",
      "epoch: 2 step: 320, loss is 0.0005014031194150448\n",
      "epoch: 2 step: 321, loss is 0.07415761053562164\n",
      "epoch: 2 step: 322, loss is 0.012107540853321552\n",
      "epoch: 2 step: 323, loss is 0.16975584626197815\n",
      "epoch: 2 step: 324, loss is 0.05203741788864136\n",
      "epoch: 2 step: 325, loss is 0.03631126508116722\n",
      "epoch: 2 step: 326, loss is 0.006954996380954981\n",
      "epoch: 2 step: 327, loss is 0.03377477452158928\n",
      "epoch: 2 step: 328, loss is 0.01604004204273224\n",
      "epoch: 2 step: 329, loss is 0.055273305624723434\n",
      "epoch: 2 step: 330, loss is 0.000723028089851141\n",
      "epoch: 2 step: 331, loss is 0.10975757986307144\n",
      "epoch: 2 step: 332, loss is 0.012179032899439335\n",
      "epoch: 2 step: 333, loss is 0.2374032437801361\n",
      "epoch: 2 step: 334, loss is 0.09550520777702332\n",
      "epoch: 2 step: 335, loss is 0.05804352089762688\n",
      "epoch: 2 step: 336, loss is 0.01904166117310524\n",
      "epoch: 2 step: 337, loss is 0.0009262027451768517\n",
      "epoch: 2 step: 338, loss is 0.13800375163555145\n",
      "epoch: 2 step: 339, loss is 0.0058481767773628235\n",
      "epoch: 2 step: 340, loss is 0.012647782452404499\n",
      "epoch: 2 step: 341, loss is 0.11912577599287033\n",
      "epoch: 2 step: 342, loss is 0.04038798436522484\n",
      "epoch: 2 step: 343, loss is 0.08287044614553452\n",
      "epoch: 2 step: 344, loss is 0.12046206742525101\n",
      "epoch: 2 step: 345, loss is 0.02237674407660961\n",
      "epoch: 2 step: 346, loss is 0.005435781553387642\n",
      "epoch: 2 step: 347, loss is 0.010386789217591286\n",
      "epoch: 2 step: 348, loss is 0.057556137442588806\n",
      "epoch: 2 step: 349, loss is 0.06811950355768204\n",
      "epoch: 2 step: 350, loss is 0.04107830673456192\n",
      "epoch: 2 step: 351, loss is 0.04183072969317436\n",
      "epoch: 2 step: 352, loss is 0.004045679699629545\n",
      "epoch: 2 step: 353, loss is 0.029297245666384697\n",
      "epoch: 2 step: 354, loss is 0.009212580509483814\n",
      "epoch: 2 step: 355, loss is 0.002087716944515705\n",
      "epoch: 2 step: 356, loss is 0.0025989008136093616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 357, loss is 0.008029894903302193\n",
      "epoch: 2 step: 358, loss is 0.02933543361723423\n",
      "epoch: 2 step: 359, loss is 0.04330308362841606\n",
      "epoch: 2 step: 360, loss is 0.008794102817773819\n",
      "epoch: 2 step: 361, loss is 0.19788162410259247\n",
      "epoch: 2 step: 362, loss is 0.000529047567397356\n",
      "epoch: 2 step: 363, loss is 0.0006838973495177925\n",
      "epoch: 2 step: 364, loss is 0.040788546204566956\n",
      "epoch: 2 step: 365, loss is 0.26290228962898254\n",
      "epoch: 2 step: 366, loss is 0.15275810658931732\n",
      "epoch: 2 step: 367, loss is 0.005953857209533453\n",
      "epoch: 2 step: 368, loss is 0.03379572555422783\n",
      "epoch: 2 step: 369, loss is 0.004575215280056\n",
      "epoch: 2 step: 370, loss is 0.029227696359157562\n",
      "epoch: 2 step: 371, loss is 0.06261080503463745\n",
      "epoch: 2 step: 372, loss is 0.11490123718976974\n",
      "epoch: 2 step: 373, loss is 0.02228430286049843\n",
      "epoch: 2 step: 374, loss is 0.14867350459098816\n",
      "epoch: 2 step: 375, loss is 0.0015383799327537417\n",
      "epoch: 2 step: 376, loss is 0.007468131370842457\n",
      "epoch: 2 step: 377, loss is 0.03774069994688034\n",
      "epoch: 2 step: 378, loss is 0.004235766362398863\n",
      "epoch: 2 step: 379, loss is 0.00512452470138669\n",
      "epoch: 2 step: 380, loss is 0.012691027484834194\n",
      "epoch: 2 step: 381, loss is 0.007864768616855145\n",
      "epoch: 2 step: 382, loss is 0.13894978165626526\n",
      "epoch: 2 step: 383, loss is 0.01757584884762764\n",
      "epoch: 2 step: 384, loss is 0.0890362486243248\n",
      "epoch: 2 step: 385, loss is 0.1766076385974884\n",
      "epoch: 2 step: 386, loss is 0.12180574238300323\n",
      "epoch: 2 step: 387, loss is 0.04554416611790657\n",
      "epoch: 2 step: 388, loss is 0.05931774526834488\n",
      "epoch: 2 step: 389, loss is 0.042861517518758774\n",
      "epoch: 2 step: 390, loss is 0.035091593861579895\n",
      "epoch: 2 step: 391, loss is 0.02399325743317604\n",
      "epoch: 2 step: 392, loss is 0.1058824434876442\n",
      "epoch: 2 step: 393, loss is 0.033528365194797516\n",
      "epoch: 2 step: 394, loss is 0.017215562984347343\n",
      "epoch: 2 step: 395, loss is 0.008023553527891636\n",
      "epoch: 2 step: 396, loss is 0.09418174624443054\n",
      "epoch: 2 step: 397, loss is 0.006167977582663298\n",
      "epoch: 2 step: 398, loss is 0.13467568159103394\n",
      "epoch: 2 step: 399, loss is 0.012488321401178837\n",
      "epoch: 2 step: 400, loss is 0.20877103507518768\n",
      "epoch: 2 step: 401, loss is 0.12012536823749542\n",
      "epoch: 2 step: 402, loss is 0.0033644847571849823\n",
      "epoch: 2 step: 403, loss is 0.02227320335805416\n",
      "epoch: 2 step: 404, loss is 0.07793479412794113\n",
      "epoch: 2 step: 405, loss is 0.0410693921148777\n",
      "epoch: 2 step: 406, loss is 0.03355930745601654\n",
      "epoch: 2 step: 407, loss is 0.01573788747191429\n",
      "epoch: 2 step: 408, loss is 0.013991273939609528\n",
      "epoch: 2 step: 409, loss is 0.07208386808633804\n",
      "epoch: 2 step: 410, loss is 0.22605319321155548\n",
      "epoch: 2 step: 411, loss is 0.017629258334636688\n",
      "epoch: 2 step: 412, loss is 0.011536825448274612\n",
      "epoch: 2 step: 413, loss is 0.0011098480317741632\n",
      "epoch: 2 step: 414, loss is 0.000953234382905066\n",
      "epoch: 2 step: 415, loss is 0.14961321651935577\n",
      "epoch: 2 step: 416, loss is 0.026952167972922325\n",
      "epoch: 2 step: 417, loss is 0.3810301423072815\n",
      "epoch: 2 step: 418, loss is 0.0014202177990227938\n",
      "epoch: 2 step: 419, loss is 0.03997652232646942\n",
      "epoch: 2 step: 420, loss is 0.02543710172176361\n",
      "epoch: 2 step: 421, loss is 0.005736098159104586\n",
      "epoch: 2 step: 422, loss is 0.05510035902261734\n",
      "epoch: 2 step: 423, loss is 0.0810994952917099\n",
      "epoch: 2 step: 424, loss is 0.013650770299136639\n",
      "epoch: 2 step: 425, loss is 0.01512669026851654\n",
      "epoch: 2 step: 426, loss is 0.0058246091939508915\n",
      "epoch: 2 step: 427, loss is 0.026235608384013176\n",
      "epoch: 2 step: 428, loss is 0.037209559231996536\n",
      "epoch: 2 step: 429, loss is 0.0462382547557354\n",
      "epoch: 2 step: 430, loss is 0.0036947811022400856\n",
      "epoch: 2 step: 431, loss is 0.005903960671275854\n",
      "epoch: 2 step: 432, loss is 0.13749812543392181\n",
      "epoch: 2 step: 433, loss is 0.03665836527943611\n",
      "epoch: 2 step: 434, loss is 0.12838780879974365\n",
      "epoch: 2 step: 435, loss is 0.0033703141380101442\n",
      "epoch: 2 step: 436, loss is 0.08594226837158203\n",
      "epoch: 2 step: 437, loss is 0.059412140399217606\n",
      "epoch: 2 step: 438, loss is 0.003834324888885021\n",
      "epoch: 2 step: 439, loss is 0.07001414149999619\n",
      "epoch: 2 step: 440, loss is 0.006274852901697159\n",
      "epoch: 2 step: 441, loss is 0.07349210232496262\n",
      "epoch: 2 step: 442, loss is 0.013104704208672047\n",
      "epoch: 2 step: 443, loss is 0.0016416833968833089\n",
      "epoch: 2 step: 444, loss is 0.023191697895526886\n",
      "epoch: 2 step: 445, loss is 0.006057169288396835\n",
      "epoch: 2 step: 446, loss is 0.005806722678244114\n",
      "epoch: 2 step: 447, loss is 0.04127681627869606\n",
      "epoch: 2 step: 448, loss is 0.20426511764526367\n",
      "epoch: 2 step: 449, loss is 0.002200509188696742\n",
      "epoch: 2 step: 450, loss is 0.006173508707433939\n",
      "epoch: 2 step: 451, loss is 0.0018129401141777635\n",
      "epoch: 2 step: 452, loss is 0.0515320785343647\n",
      "epoch: 2 step: 453, loss is 0.2979973554611206\n",
      "epoch: 2 step: 454, loss is 0.37877997756004333\n",
      "epoch: 2 step: 455, loss is 0.004770895000547171\n",
      "epoch: 2 step: 456, loss is 0.01145061757415533\n",
      "epoch: 2 step: 457, loss is 0.0730714350938797\n",
      "epoch: 2 step: 458, loss is 0.112428680062294\n",
      "epoch: 2 step: 459, loss is 0.005790054798126221\n",
      "epoch: 2 step: 460, loss is 0.006138240918517113\n",
      "epoch: 2 step: 461, loss is 0.10316798090934753\n",
      "epoch: 2 step: 462, loss is 0.01104335393756628\n",
      "epoch: 2 step: 463, loss is 0.2064216434955597\n",
      "epoch: 2 step: 464, loss is 0.0568072535097599\n",
      "epoch: 2 step: 465, loss is 0.003334446344524622\n",
      "epoch: 2 step: 466, loss is 0.03416166082024574\n",
      "epoch: 2 step: 467, loss is 0.09977778792381287\n",
      "epoch: 2 step: 468, loss is 0.04781371355056763\n",
      "epoch: 2 step: 469, loss is 0.010242925956845284\n",
      "epoch: 2 step: 470, loss is 0.007025431375950575\n",
      "epoch: 2 step: 471, loss is 0.01434393972158432\n",
      "epoch: 2 step: 472, loss is 0.059140894562006\n",
      "epoch: 2 step: 473, loss is 0.024977559223771095\n",
      "epoch: 2 step: 474, loss is 0.007030533626675606\n",
      "epoch: 2 step: 475, loss is 0.012455364689230919\n",
      "epoch: 2 step: 476, loss is 0.017799686640501022\n",
      "epoch: 2 step: 477, loss is 0.010925973765552044\n",
      "epoch: 2 step: 478, loss is 0.006402802187949419\n",
      "epoch: 2 step: 479, loss is 0.05602826178073883\n",
      "epoch: 2 step: 480, loss is 0.11728885769844055\n",
      "epoch: 2 step: 481, loss is 0.018172841519117355\n",
      "epoch: 2 step: 482, loss is 0.05552084371447563\n",
      "epoch: 2 step: 483, loss is 0.23329629004001617\n",
      "epoch: 2 step: 484, loss is 0.002542892936617136\n",
      "epoch: 2 step: 485, loss is 0.12111538648605347\n",
      "epoch: 2 step: 486, loss is 0.012939607724547386\n",
      "epoch: 2 step: 487, loss is 0.037443410605192184\n",
      "epoch: 2 step: 488, loss is 0.050367094576358795\n",
      "epoch: 2 step: 489, loss is 0.030834747478365898\n",
      "epoch: 2 step: 490, loss is 0.017604008316993713\n",
      "epoch: 2 step: 491, loss is 0.01717313937842846\n",
      "epoch: 2 step: 492, loss is 0.11437754333019257\n",
      "epoch: 2 step: 493, loss is 0.1321098655462265\n",
      "epoch: 2 step: 494, loss is 0.004343200474977493\n",
      "epoch: 2 step: 495, loss is 0.21691499650478363\n",
      "epoch: 2 step: 496, loss is 0.03694726899266243\n",
      "epoch: 2 step: 497, loss is 0.002835371531546116\n",
      "epoch: 2 step: 498, loss is 0.06041913852095604\n",
      "epoch: 2 step: 499, loss is 0.13388366997241974\n",
      "epoch: 2 step: 500, loss is 0.0672077164053917\n",
      "epoch: 2 step: 501, loss is 0.05031416192650795\n",
      "epoch: 2 step: 502, loss is 0.118792325258255\n",
      "epoch: 2 step: 503, loss is 0.03041612170636654\n",
      "epoch: 2 step: 504, loss is 0.10762515664100647\n",
      "epoch: 2 step: 505, loss is 0.018378444015979767\n",
      "epoch: 2 step: 506, loss is 0.06889955699443817\n",
      "epoch: 2 step: 507, loss is 0.11617184430360794\n",
      "epoch: 2 step: 508, loss is 0.005538469180464745\n",
      "epoch: 2 step: 509, loss is 0.007872155867516994\n",
      "epoch: 2 step: 510, loss is 0.003854809794574976\n",
      "epoch: 2 step: 511, loss is 0.10020041465759277\n",
      "epoch: 2 step: 512, loss is 0.001024528406560421\n",
      "epoch: 2 step: 513, loss is 0.038003090769052505\n",
      "epoch: 2 step: 514, loss is 0.0025286462623625994\n",
      "epoch: 2 step: 515, loss is 0.0013880003243684769\n",
      "epoch: 2 step: 516, loss is 0.0016380029264837503\n",
      "epoch: 2 step: 517, loss is 0.04088249430060387\n",
      "epoch: 2 step: 518, loss is 0.012837544083595276\n",
      "epoch: 2 step: 519, loss is 0.05854879319667816\n",
      "epoch: 2 step: 520, loss is 0.12427366524934769\n",
      "epoch: 2 step: 521, loss is 0.006700701080262661\n",
      "epoch: 2 step: 522, loss is 0.011513733305037022\n",
      "epoch: 2 step: 523, loss is 0.011014026589691639\n",
      "epoch: 2 step: 524, loss is 0.009845687076449394\n",
      "epoch: 2 step: 525, loss is 0.03395523503422737\n",
      "epoch: 2 step: 526, loss is 0.03265269845724106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 527, loss is 0.22074605524539948\n",
      "epoch: 2 step: 528, loss is 0.004915940575301647\n",
      "epoch: 2 step: 529, loss is 0.12459760159254074\n",
      "epoch: 2 step: 530, loss is 0.032078973948955536\n",
      "epoch: 2 step: 531, loss is 0.014229311607778072\n",
      "epoch: 2 step: 532, loss is 0.038505442440509796\n",
      "epoch: 2 step: 533, loss is 0.13664069771766663\n",
      "epoch: 2 step: 534, loss is 0.013823526911437511\n",
      "epoch: 2 step: 535, loss is 0.036672938615083694\n",
      "epoch: 2 step: 536, loss is 0.047335658222436905\n",
      "epoch: 2 step: 537, loss is 0.0016115133184939623\n",
      "epoch: 2 step: 538, loss is 0.047385748475790024\n",
      "epoch: 2 step: 539, loss is 0.0180682186037302\n",
      "epoch: 2 step: 540, loss is 0.20029520988464355\n",
      "epoch: 2 step: 541, loss is 0.208749458193779\n",
      "epoch: 2 step: 542, loss is 0.0015283036045730114\n",
      "epoch: 2 step: 543, loss is 0.18812023103237152\n",
      "epoch: 2 step: 544, loss is 0.12805256247520447\n",
      "epoch: 2 step: 545, loss is 0.036818474531173706\n",
      "epoch: 2 step: 546, loss is 0.030076056718826294\n",
      "epoch: 2 step: 547, loss is 0.004252552520483732\n",
      "epoch: 2 step: 548, loss is 0.16119259595870972\n",
      "epoch: 2 step: 549, loss is 0.02476559579372406\n",
      "epoch: 2 step: 550, loss is 0.11530129611492157\n",
      "epoch: 2 step: 551, loss is 0.011073444969952106\n",
      "epoch: 2 step: 552, loss is 0.032073553651571274\n",
      "epoch: 2 step: 553, loss is 0.01311718113720417\n",
      "epoch: 2 step: 554, loss is 0.11051048338413239\n",
      "epoch: 2 step: 555, loss is 0.08036164194345474\n",
      "epoch: 2 step: 556, loss is 0.002207122975960374\n",
      "epoch: 2 step: 557, loss is 0.011900979094207287\n",
      "epoch: 2 step: 558, loss is 0.0014871854800730944\n",
      "epoch: 2 step: 559, loss is 0.0005176757113076746\n",
      "epoch: 2 step: 560, loss is 0.028011932969093323\n",
      "epoch: 2 step: 561, loss is 0.059314701706171036\n",
      "epoch: 2 step: 562, loss is 0.12934930622577667\n",
      "epoch: 2 step: 563, loss is 0.15508580207824707\n",
      "epoch: 2 step: 564, loss is 0.22089731693267822\n",
      "epoch: 2 step: 565, loss is 0.0015795843210071325\n",
      "epoch: 2 step: 566, loss is 0.039051298052072525\n",
      "epoch: 2 step: 567, loss is 0.017433244735002518\n",
      "epoch: 2 step: 568, loss is 0.04445866495370865\n",
      "epoch: 2 step: 569, loss is 0.08577503263950348\n",
      "epoch: 2 step: 570, loss is 0.05056462809443474\n",
      "epoch: 2 step: 571, loss is 0.017166413366794586\n",
      "epoch: 2 step: 572, loss is 0.03292936459183693\n",
      "epoch: 2 step: 573, loss is 0.034330662339925766\n",
      "epoch: 2 step: 574, loss is 0.098444864153862\n",
      "epoch: 2 step: 575, loss is 0.19802802801132202\n",
      "epoch: 2 step: 576, loss is 0.1507261097431183\n",
      "epoch: 2 step: 577, loss is 0.024920718744397163\n",
      "epoch: 2 step: 578, loss is 0.16556814312934875\n",
      "epoch: 2 step: 579, loss is 0.007922887802124023\n",
      "epoch: 2 step: 580, loss is 0.01587698608636856\n",
      "epoch: 2 step: 581, loss is 0.07439059764146805\n",
      "epoch: 2 step: 582, loss is 0.016329364851117134\n",
      "epoch: 2 step: 583, loss is 0.02857356145977974\n",
      "epoch: 2 step: 584, loss is 0.012263013049960136\n",
      "epoch: 2 step: 585, loss is 0.049819767475128174\n",
      "epoch: 2 step: 586, loss is 0.10508595407009125\n",
      "epoch: 2 step: 587, loss is 0.03844289854168892\n",
      "epoch: 2 step: 588, loss is 0.005652622319757938\n",
      "epoch: 2 step: 589, loss is 0.01799565926194191\n",
      "epoch: 2 step: 590, loss is 0.008437255397439003\n",
      "epoch: 2 step: 591, loss is 0.014571158215403557\n",
      "epoch: 2 step: 592, loss is 0.011881002224981785\n",
      "epoch: 2 step: 593, loss is 0.016089484095573425\n",
      "epoch: 2 step: 594, loss is 0.23588760197162628\n",
      "epoch: 2 step: 595, loss is 0.0269003976136446\n",
      "epoch: 2 step: 596, loss is 0.02043624222278595\n",
      "epoch: 2 step: 597, loss is 0.0029658698476850986\n",
      "epoch: 2 step: 598, loss is 0.09462960809469223\n",
      "epoch: 2 step: 599, loss is 0.01420949399471283\n",
      "epoch: 2 step: 600, loss is 0.04353254660964012\n",
      "epoch: 2 step: 601, loss is 0.17488828301429749\n",
      "epoch: 2 step: 602, loss is 0.0495414100587368\n",
      "epoch: 2 step: 603, loss is 0.14038586616516113\n",
      "epoch: 2 step: 604, loss is 0.056943248957395554\n",
      "epoch: 2 step: 605, loss is 0.11456914246082306\n",
      "epoch: 2 step: 606, loss is 0.025142740458250046\n",
      "epoch: 2 step: 607, loss is 0.011306853964924812\n",
      "epoch: 2 step: 608, loss is 0.1780342310667038\n",
      "epoch: 2 step: 609, loss is 0.021454423666000366\n",
      "epoch: 2 step: 610, loss is 0.08033087104558945\n",
      "epoch: 2 step: 611, loss is 0.04056226462125778\n",
      "epoch: 2 step: 612, loss is 0.027400897815823555\n",
      "epoch: 2 step: 613, loss is 0.03965939208865166\n",
      "epoch: 2 step: 614, loss is 0.002613356104120612\n",
      "epoch: 2 step: 615, loss is 0.09447085857391357\n",
      "epoch: 2 step: 616, loss is 0.09608528017997742\n",
      "epoch: 2 step: 617, loss is 0.004097424913197756\n",
      "epoch: 2 step: 618, loss is 0.07930876314640045\n",
      "epoch: 2 step: 619, loss is 0.13124658167362213\n",
      "epoch: 2 step: 620, loss is 0.011065690778195858\n",
      "epoch: 2 step: 621, loss is 0.009423259645700455\n",
      "epoch: 2 step: 622, loss is 0.05396063253283501\n",
      "epoch: 2 step: 623, loss is 0.030269859358668327\n",
      "epoch: 2 step: 624, loss is 0.007852885872125626\n",
      "epoch: 2 step: 625, loss is 0.03872296214103699\n",
      "epoch: 2 step: 626, loss is 0.050991352647542953\n",
      "epoch: 2 step: 627, loss is 0.0019935767631977797\n",
      "epoch: 2 step: 628, loss is 0.004959768615663052\n",
      "epoch: 2 step: 629, loss is 0.04404948651790619\n",
      "epoch: 2 step: 630, loss is 0.02001427300274372\n",
      "epoch: 2 step: 631, loss is 0.06389559060335159\n",
      "epoch: 2 step: 632, loss is 0.08971899747848511\n",
      "epoch: 2 step: 633, loss is 0.054246630519628525\n",
      "epoch: 2 step: 634, loss is 0.05505630373954773\n",
      "epoch: 2 step: 635, loss is 0.06204918771982193\n",
      "epoch: 2 step: 636, loss is 0.10939808189868927\n",
      "epoch: 2 step: 637, loss is 0.009022156707942486\n",
      "epoch: 2 step: 638, loss is 0.0024669531267136335\n",
      "epoch: 2 step: 639, loss is 0.16523893177509308\n",
      "epoch: 2 step: 640, loss is 0.004095771349966526\n",
      "epoch: 2 step: 641, loss is 0.16673415899276733\n",
      "epoch: 2 step: 642, loss is 0.21326158940792084\n",
      "epoch: 2 step: 643, loss is 0.037834879010915756\n",
      "epoch: 2 step: 644, loss is 0.034497201442718506\n",
      "epoch: 2 step: 645, loss is 0.008251572027802467\n",
      "epoch: 2 step: 646, loss is 0.008876388892531395\n",
      "epoch: 2 step: 647, loss is 0.07833275198936462\n",
      "epoch: 2 step: 648, loss is 0.009873557835817337\n",
      "epoch: 2 step: 649, loss is 0.16955424845218658\n",
      "epoch: 2 step: 650, loss is 0.012745528481900692\n",
      "epoch: 2 step: 651, loss is 0.0071069421246647835\n",
      "epoch: 2 step: 652, loss is 0.0886412262916565\n",
      "epoch: 2 step: 653, loss is 0.005539061035960913\n",
      "epoch: 2 step: 654, loss is 0.03435409814119339\n",
      "epoch: 2 step: 655, loss is 0.16530467569828033\n",
      "epoch: 2 step: 656, loss is 0.43583256006240845\n",
      "epoch: 2 step: 657, loss is 0.026092709973454475\n",
      "epoch: 2 step: 658, loss is 0.07197429239749908\n",
      "epoch: 2 step: 659, loss is 0.005279450677335262\n",
      "epoch: 2 step: 660, loss is 0.005473244469612837\n",
      "epoch: 2 step: 661, loss is 0.0031450707465410233\n",
      "epoch: 2 step: 662, loss is 0.07631292939186096\n",
      "epoch: 2 step: 663, loss is 0.0019443248165771365\n",
      "epoch: 2 step: 664, loss is 0.3424796760082245\n",
      "epoch: 2 step: 665, loss is 0.03051815554499626\n",
      "epoch: 2 step: 666, loss is 0.028444845229387283\n",
      "epoch: 2 step: 667, loss is 0.03350235894322395\n",
      "epoch: 2 step: 668, loss is 0.02236061356961727\n",
      "epoch: 2 step: 669, loss is 0.15366250276565552\n",
      "epoch: 2 step: 670, loss is 0.2263258993625641\n",
      "epoch: 2 step: 671, loss is 0.08395121246576309\n",
      "epoch: 2 step: 672, loss is 0.010734515264630318\n",
      "epoch: 2 step: 673, loss is 0.03899442031979561\n",
      "epoch: 2 step: 674, loss is 0.07060850411653519\n",
      "epoch: 2 step: 675, loss is 0.08211877942085266\n",
      "epoch: 2 step: 676, loss is 0.011857225559651852\n",
      "epoch: 2 step: 677, loss is 0.21882514655590057\n",
      "epoch: 2 step: 678, loss is 0.16985462605953217\n",
      "epoch: 2 step: 679, loss is 0.07048329710960388\n",
      "epoch: 2 step: 680, loss is 0.011229025200009346\n",
      "epoch: 2 step: 681, loss is 0.005764969624578953\n",
      "epoch: 2 step: 682, loss is 0.3642990291118622\n",
      "epoch: 2 step: 683, loss is 0.09115287661552429\n",
      "epoch: 2 step: 684, loss is 0.2086893618106842\n",
      "epoch: 2 step: 685, loss is 0.04610710218548775\n",
      "epoch: 2 step: 686, loss is 0.008458150550723076\n",
      "epoch: 2 step: 687, loss is 0.11084325611591339\n",
      "epoch: 2 step: 688, loss is 0.07172311097383499\n",
      "epoch: 2 step: 689, loss is 0.006313798017799854\n",
      "epoch: 2 step: 690, loss is 0.0200551338493824\n",
      "epoch: 2 step: 691, loss is 0.07258061319589615\n",
      "epoch: 2 step: 692, loss is 0.01712931878864765\n",
      "epoch: 2 step: 693, loss is 0.010172671638429165\n",
      "epoch: 2 step: 694, loss is 0.0640009418129921\n",
      "epoch: 2 step: 695, loss is 0.2231772243976593\n",
      "epoch: 2 step: 696, loss is 0.01536521501839161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 697, loss is 0.02075064741075039\n",
      "epoch: 2 step: 698, loss is 0.06087150052189827\n",
      "epoch: 2 step: 699, loss is 0.035518042743206024\n",
      "epoch: 2 step: 700, loss is 0.14160118997097015\n",
      "epoch: 2 step: 701, loss is 0.14792129397392273\n",
      "epoch: 2 step: 702, loss is 0.007319771219044924\n",
      "epoch: 2 step: 703, loss is 0.027157582342624664\n",
      "epoch: 2 step: 704, loss is 0.0518629252910614\n",
      "epoch: 2 step: 705, loss is 0.006301390938460827\n",
      "epoch: 2 step: 706, loss is 0.36890074610710144\n",
      "epoch: 2 step: 707, loss is 0.039035864174366\n",
      "epoch: 2 step: 708, loss is 0.0037043821066617966\n",
      "epoch: 2 step: 709, loss is 0.00812527071684599\n",
      "epoch: 2 step: 710, loss is 0.06854887306690216\n",
      "epoch: 2 step: 711, loss is 0.004381773993372917\n",
      "epoch: 2 step: 712, loss is 0.024167008697986603\n",
      "epoch: 2 step: 713, loss is 0.05714568868279457\n",
      "epoch: 2 step: 714, loss is 0.014068888500332832\n",
      "epoch: 2 step: 715, loss is 0.022503497079014778\n",
      "epoch: 2 step: 716, loss is 0.037887971848249435\n",
      "epoch: 2 step: 717, loss is 0.11497105658054352\n",
      "epoch: 2 step: 718, loss is 0.006427513901144266\n",
      "epoch: 2 step: 719, loss is 0.043791092932224274\n",
      "epoch: 2 step: 720, loss is 0.04862977936863899\n",
      "epoch: 2 step: 721, loss is 0.03753191605210304\n",
      "epoch: 2 step: 722, loss is 0.01219880674034357\n",
      "epoch: 2 step: 723, loss is 0.03448152169585228\n",
      "epoch: 2 step: 724, loss is 0.01828080601990223\n",
      "epoch: 2 step: 725, loss is 0.14154323935508728\n",
      "epoch: 2 step: 726, loss is 0.00583435595035553\n",
      "epoch: 2 step: 727, loss is 0.017894092947244644\n",
      "epoch: 2 step: 728, loss is 0.0902239978313446\n",
      "epoch: 2 step: 729, loss is 0.008866513147950172\n",
      "epoch: 2 step: 730, loss is 0.05897613242268562\n",
      "epoch: 2 step: 731, loss is 0.010209307074546814\n",
      "epoch: 2 step: 732, loss is 0.006507947109639645\n",
      "epoch: 2 step: 733, loss is 0.06726504862308502\n",
      "epoch: 2 step: 734, loss is 0.1010158434510231\n",
      "epoch: 2 step: 735, loss is 0.11555003374814987\n",
      "epoch: 2 step: 736, loss is 0.04550674185156822\n",
      "epoch: 2 step: 737, loss is 0.1529725044965744\n",
      "epoch: 2 step: 738, loss is 0.103073351085186\n",
      "epoch: 2 step: 739, loss is 0.009757994674146175\n",
      "epoch: 2 step: 740, loss is 0.01814536564052105\n",
      "epoch: 2 step: 741, loss is 0.06556019186973572\n",
      "epoch: 2 step: 742, loss is 0.026097383350133896\n",
      "epoch: 2 step: 743, loss is 0.028302932158112526\n",
      "epoch: 2 step: 744, loss is 0.18647634983062744\n",
      "epoch: 2 step: 745, loss is 0.00570214306935668\n",
      "epoch: 2 step: 746, loss is 0.06148742139339447\n",
      "epoch: 2 step: 747, loss is 0.01423635147511959\n",
      "epoch: 2 step: 748, loss is 0.011366046033799648\n",
      "epoch: 2 step: 749, loss is 0.02711019478738308\n",
      "epoch: 2 step: 750, loss is 0.02424989454448223\n",
      "epoch: 2 step: 751, loss is 0.03531072661280632\n",
      "epoch: 2 step: 752, loss is 0.010409573093056679\n",
      "epoch: 2 step: 753, loss is 0.0340670645236969\n",
      "epoch: 2 step: 754, loss is 0.29559430480003357\n",
      "epoch: 2 step: 755, loss is 0.04622563347220421\n",
      "epoch: 2 step: 756, loss is 0.11715442687273026\n",
      "epoch: 2 step: 757, loss is 0.008435838855803013\n",
      "epoch: 2 step: 758, loss is 0.04292258620262146\n",
      "epoch: 2 step: 759, loss is 0.024157648906111717\n",
      "epoch: 2 step: 760, loss is 0.009807010181248188\n",
      "epoch: 2 step: 761, loss is 0.0013815801357850432\n",
      "epoch: 2 step: 762, loss is 0.03049873188138008\n",
      "epoch: 2 step: 763, loss is 0.07835526019334793\n",
      "epoch: 2 step: 764, loss is 0.004203335847705603\n",
      "epoch: 2 step: 765, loss is 0.0020210985094308853\n",
      "epoch: 2 step: 766, loss is 0.026963191106915474\n",
      "epoch: 2 step: 767, loss is 0.4242505431175232\n",
      "epoch: 2 step: 768, loss is 0.12383482605218887\n",
      "epoch: 2 step: 769, loss is 0.009632648900151253\n",
      "epoch: 2 step: 770, loss is 0.01662451960146427\n",
      "epoch: 2 step: 771, loss is 0.053887322545051575\n",
      "epoch: 2 step: 772, loss is 0.04895570129156113\n",
      "epoch: 2 step: 773, loss is 0.057712070643901825\n",
      "epoch: 2 step: 774, loss is 0.07257039844989777\n",
      "epoch: 2 step: 775, loss is 0.0653396025300026\n",
      "epoch: 2 step: 776, loss is 0.07605288177728653\n",
      "epoch: 2 step: 777, loss is 0.11820457875728607\n",
      "epoch: 2 step: 778, loss is 0.0016716731479391456\n",
      "epoch: 2 step: 779, loss is 0.023908322677016258\n",
      "epoch: 2 step: 780, loss is 0.0016903304494917393\n",
      "epoch: 2 step: 781, loss is 0.1146131157875061\n",
      "epoch: 2 step: 782, loss is 0.03385237231850624\n",
      "epoch: 2 step: 783, loss is 0.005824886728078127\n",
      "epoch: 2 step: 784, loss is 0.12217669934034348\n",
      "epoch: 2 step: 785, loss is 0.1611732393503189\n",
      "epoch: 2 step: 786, loss is 0.012782778590917587\n",
      "epoch: 2 step: 787, loss is 0.006771603599190712\n",
      "epoch: 2 step: 788, loss is 0.06096072122454643\n",
      "epoch: 2 step: 789, loss is 0.009710361249744892\n",
      "epoch: 2 step: 790, loss is 0.01866275444626808\n",
      "epoch: 2 step: 791, loss is 0.09341312944889069\n",
      "epoch: 2 step: 792, loss is 0.2748010456562042\n",
      "epoch: 2 step: 793, loss is 0.07809106260538101\n",
      "epoch: 2 step: 794, loss is 0.0496358759701252\n",
      "epoch: 2 step: 795, loss is 0.008752086199820042\n",
      "epoch: 2 step: 796, loss is 0.021743325516581535\n",
      "epoch: 2 step: 797, loss is 0.0494166761636734\n",
      "epoch: 2 step: 798, loss is 0.003593093017116189\n",
      "epoch: 2 step: 799, loss is 0.14838574826717377\n",
      "epoch: 2 step: 800, loss is 0.2053636610507965\n",
      "epoch: 2 step: 801, loss is 0.015372319146990776\n",
      "epoch: 2 step: 802, loss is 0.10215826332569122\n",
      "epoch: 2 step: 803, loss is 0.0028734353836625814\n",
      "epoch: 2 step: 804, loss is 0.023604337126016617\n",
      "epoch: 2 step: 805, loss is 0.032849349081516266\n",
      "epoch: 2 step: 806, loss is 0.001393437385559082\n",
      "epoch: 2 step: 807, loss is 0.002050096867606044\n",
      "epoch: 2 step: 808, loss is 0.2001517415046692\n",
      "epoch: 2 step: 809, loss is 0.05369638651609421\n",
      "epoch: 2 step: 810, loss is 0.030289623886346817\n",
      "epoch: 2 step: 811, loss is 0.0798974484205246\n",
      "epoch: 2 step: 812, loss is 0.041554998606443405\n",
      "epoch: 2 step: 813, loss is 0.05470013618469238\n",
      "epoch: 2 step: 814, loss is 0.06852927058935165\n",
      "epoch: 2 step: 815, loss is 0.002873346209526062\n",
      "epoch: 2 step: 816, loss is 0.008420203812420368\n",
      "epoch: 2 step: 817, loss is 0.012203081510961056\n",
      "epoch: 2 step: 818, loss is 0.004669610410928726\n",
      "epoch: 2 step: 819, loss is 0.0012992043048143387\n",
      "epoch: 2 step: 820, loss is 0.005381116643548012\n",
      "epoch: 2 step: 821, loss is 0.054341934621334076\n",
      "epoch: 2 step: 822, loss is 0.036961112171411514\n",
      "epoch: 2 step: 823, loss is 0.006699457764625549\n",
      "epoch: 2 step: 824, loss is 0.09224338829517365\n",
      "epoch: 2 step: 825, loss is 0.07606113702058792\n",
      "epoch: 2 step: 826, loss is 0.034626130014657974\n",
      "epoch: 2 step: 827, loss is 0.07997548580169678\n",
      "epoch: 2 step: 828, loss is 0.006083235144615173\n",
      "epoch: 2 step: 829, loss is 0.05675928667187691\n",
      "epoch: 2 step: 830, loss is 0.0019510274287313223\n",
      "epoch: 2 step: 831, loss is 0.0008771767024882138\n",
      "epoch: 2 step: 832, loss is 0.15701930224895477\n",
      "epoch: 2 step: 833, loss is 0.13428708910942078\n",
      "epoch: 2 step: 834, loss is 0.002171147149056196\n",
      "epoch: 2 step: 835, loss is 0.0006489112856797874\n",
      "epoch: 2 step: 836, loss is 0.0008558579720556736\n",
      "epoch: 2 step: 837, loss is 0.010468126274645329\n",
      "epoch: 2 step: 838, loss is 0.027823297306895256\n",
      "epoch: 2 step: 839, loss is 0.016994932666420937\n",
      "epoch: 2 step: 840, loss is 0.03042975626885891\n",
      "epoch: 2 step: 841, loss is 0.19061176478862762\n",
      "epoch: 2 step: 842, loss is 0.05593082308769226\n",
      "epoch: 2 step: 843, loss is 0.007566370069980621\n",
      "epoch: 2 step: 844, loss is 0.009132225066423416\n",
      "epoch: 2 step: 845, loss is 0.06863176077604294\n",
      "epoch: 2 step: 846, loss is 0.0012777986703440547\n",
      "epoch: 2 step: 847, loss is 0.086509570479393\n",
      "epoch: 2 step: 848, loss is 0.015503746457397938\n",
      "epoch: 2 step: 849, loss is 0.05107153207063675\n",
      "epoch: 2 step: 850, loss is 0.02552463859319687\n",
      "epoch: 2 step: 851, loss is 0.008480261079967022\n",
      "epoch: 2 step: 852, loss is 0.22070761024951935\n",
      "epoch: 2 step: 853, loss is 0.00930074043571949\n",
      "epoch: 2 step: 854, loss is 0.09839998185634613\n",
      "epoch: 2 step: 855, loss is 0.003356195753440261\n",
      "epoch: 2 step: 856, loss is 0.0040755560621619225\n",
      "epoch: 2 step: 857, loss is 0.07291766256093979\n",
      "epoch: 2 step: 858, loss is 0.03674570098519325\n",
      "epoch: 2 step: 859, loss is 0.003763571847230196\n",
      "epoch: 2 step: 860, loss is 0.031026596203446388\n",
      "epoch: 2 step: 861, loss is 0.06121012568473816\n",
      "epoch: 2 step: 862, loss is 0.16394343972206116\n",
      "epoch: 2 step: 863, loss is 0.008979786187410355\n",
      "epoch: 2 step: 864, loss is 0.0008825927507132292\n",
      "epoch: 2 step: 865, loss is 0.009021257981657982\n",
      "epoch: 2 step: 866, loss is 0.02079286240041256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 867, loss is 0.20719586312770844\n",
      "epoch: 2 step: 868, loss is 0.013262994587421417\n",
      "epoch: 2 step: 869, loss is 0.004139031749218702\n",
      "epoch: 2 step: 870, loss is 0.007661988027393818\n",
      "epoch: 2 step: 871, loss is 0.037747785449028015\n",
      "epoch: 2 step: 872, loss is 0.010963758453726768\n",
      "epoch: 2 step: 873, loss is 0.09741798788309097\n",
      "epoch: 2 step: 874, loss is 0.05293875187635422\n",
      "epoch: 2 step: 875, loss is 0.01962684839963913\n",
      "epoch: 2 step: 876, loss is 0.07991275936365128\n",
      "epoch: 2 step: 877, loss is 0.06471257656812668\n",
      "epoch: 2 step: 878, loss is 0.25294768810272217\n",
      "epoch: 2 step: 879, loss is 0.011725247837603092\n",
      "epoch: 2 step: 880, loss is 0.15866661071777344\n",
      "epoch: 2 step: 881, loss is 0.06547330319881439\n",
      "epoch: 2 step: 882, loss is 0.05225400626659393\n",
      "epoch: 2 step: 883, loss is 0.006193642038851976\n",
      "epoch: 2 step: 884, loss is 0.04640199616551399\n",
      "epoch: 2 step: 885, loss is 0.0019128036219626665\n",
      "epoch: 2 step: 886, loss is 0.02720351703464985\n",
      "epoch: 2 step: 887, loss is 0.05666561797261238\n",
      "epoch: 2 step: 888, loss is 0.016654033213853836\n",
      "epoch: 2 step: 889, loss is 0.23673658072948456\n",
      "epoch: 2 step: 890, loss is 0.05121937394142151\n",
      "epoch: 2 step: 891, loss is 0.17997689545154572\n",
      "epoch: 2 step: 892, loss is 0.12211360037326813\n",
      "epoch: 2 step: 893, loss is 0.025869078934192657\n",
      "epoch: 2 step: 894, loss is 0.0030310489237308502\n",
      "epoch: 2 step: 895, loss is 0.025796301662921906\n",
      "epoch: 2 step: 896, loss is 0.06973906606435776\n",
      "epoch: 2 step: 897, loss is 0.005357217974960804\n",
      "epoch: 2 step: 898, loss is 0.026544885709881783\n",
      "epoch: 2 step: 899, loss is 0.029363833367824554\n",
      "epoch: 2 step: 900, loss is 0.2635839879512787\n",
      "epoch: 2 step: 901, loss is 0.1898212432861328\n",
      "epoch: 2 step: 902, loss is 0.013885179534554482\n",
      "epoch: 2 step: 903, loss is 0.10355257242918015\n",
      "epoch: 2 step: 904, loss is 0.004205640871077776\n",
      "epoch: 2 step: 905, loss is 0.05982082709670067\n",
      "epoch: 2 step: 906, loss is 0.12463489919900894\n",
      "epoch: 2 step: 907, loss is 0.15296165645122528\n",
      "epoch: 2 step: 908, loss is 0.15988846123218536\n",
      "epoch: 2 step: 909, loss is 0.03714030981063843\n",
      "epoch: 2 step: 910, loss is 0.012889758683741093\n",
      "epoch: 2 step: 911, loss is 0.006478778552263975\n",
      "epoch: 2 step: 912, loss is 0.12653034925460815\n",
      "epoch: 2 step: 913, loss is 0.007775518111884594\n",
      "epoch: 2 step: 914, loss is 0.0007748150383122265\n",
      "epoch: 2 step: 915, loss is 0.11727846413850784\n",
      "epoch: 2 step: 916, loss is 0.042584314942359924\n",
      "epoch: 2 step: 917, loss is 0.024439679458737373\n",
      "epoch: 2 step: 918, loss is 0.09371835738420486\n",
      "epoch: 2 step: 919, loss is 0.11278810352087021\n",
      "epoch: 2 step: 920, loss is 0.03520611301064491\n",
      "epoch: 2 step: 921, loss is 0.004866642877459526\n",
      "epoch: 2 step: 922, loss is 0.01189515646547079\n",
      "epoch: 2 step: 923, loss is 0.054181475192308426\n",
      "epoch: 2 step: 924, loss is 0.07318846881389618\n",
      "epoch: 2 step: 925, loss is 0.01541853416711092\n",
      "epoch: 2 step: 926, loss is 0.018779369071125984\n",
      "epoch: 2 step: 927, loss is 0.07599582523107529\n",
      "epoch: 2 step: 928, loss is 0.014204651117324829\n",
      "epoch: 2 step: 929, loss is 0.24487543106079102\n",
      "epoch: 2 step: 930, loss is 0.008633206598460674\n",
      "epoch: 2 step: 931, loss is 0.012233379296958447\n",
      "epoch: 2 step: 932, loss is 0.03233746066689491\n",
      "epoch: 2 step: 933, loss is 0.013009302318096161\n",
      "epoch: 2 step: 934, loss is 0.003964931238442659\n",
      "epoch: 2 step: 935, loss is 0.06733840703964233\n",
      "epoch: 2 step: 936, loss is 0.02267042174935341\n",
      "epoch: 2 step: 937, loss is 0.024054402485489845\n",
      "epoch: 2 step: 938, loss is 0.012918946333229542\n",
      "epoch: 2 step: 939, loss is 0.01589624211192131\n",
      "epoch: 2 step: 940, loss is 0.0010046620154753327\n",
      "epoch: 2 step: 941, loss is 0.053701408207416534\n",
      "epoch: 2 step: 942, loss is 0.00271016638725996\n",
      "epoch: 2 step: 943, loss is 0.19531846046447754\n",
      "epoch: 2 step: 944, loss is 0.015273717232048512\n",
      "epoch: 2 step: 945, loss is 0.0016437434824183583\n",
      "epoch: 2 step: 946, loss is 0.003912733402103186\n",
      "epoch: 2 step: 947, loss is 0.03065785951912403\n",
      "epoch: 2 step: 948, loss is 0.0016758765559643507\n",
      "epoch: 2 step: 949, loss is 0.0006329369498416781\n",
      "epoch: 2 step: 950, loss is 0.0007063414668664336\n",
      "epoch: 2 step: 951, loss is 0.12680259346961975\n",
      "epoch: 2 step: 952, loss is 0.0015889505157247186\n",
      "epoch: 2 step: 953, loss is 0.0779920220375061\n",
      "epoch: 2 step: 954, loss is 0.004280224908143282\n",
      "epoch: 2 step: 955, loss is 0.006843956653028727\n",
      "epoch: 2 step: 956, loss is 0.0009451484074816108\n",
      "epoch: 2 step: 957, loss is 0.0045549459755420685\n",
      "epoch: 2 step: 958, loss is 0.08496437966823578\n",
      "epoch: 2 step: 959, loss is 0.002034877659752965\n",
      "epoch: 2 step: 960, loss is 0.0016251729102805257\n",
      "epoch: 2 step: 961, loss is 0.04412130266427994\n",
      "epoch: 2 step: 962, loss is 0.07756881415843964\n",
      "epoch: 2 step: 963, loss is 0.008048586547374725\n",
      "epoch: 2 step: 964, loss is 0.009949661791324615\n",
      "epoch: 2 step: 965, loss is 0.04428945481777191\n",
      "epoch: 2 step: 966, loss is 0.046127475798130035\n",
      "epoch: 2 step: 967, loss is 0.07934392988681793\n",
      "epoch: 2 step: 968, loss is 0.018617497757077217\n",
      "epoch: 2 step: 969, loss is 0.05098981782793999\n",
      "epoch: 2 step: 970, loss is 0.006977935787290335\n",
      "epoch: 2 step: 971, loss is 0.0011738750617951155\n",
      "epoch: 2 step: 972, loss is 0.015828588977456093\n",
      "epoch: 2 step: 973, loss is 0.1863834708929062\n",
      "epoch: 2 step: 974, loss is 0.015323801897466183\n",
      "epoch: 2 step: 975, loss is 0.0024353652261197567\n",
      "epoch: 2 step: 976, loss is 0.03168420121073723\n",
      "epoch: 2 step: 977, loss is 0.043041519820690155\n",
      "epoch: 2 step: 978, loss is 0.0009375314693897963\n",
      "epoch: 2 step: 979, loss is 0.043193940073251724\n",
      "epoch: 2 step: 980, loss is 0.4621160626411438\n",
      "epoch: 2 step: 981, loss is 0.004626984242349863\n",
      "epoch: 2 step: 982, loss is 0.024768495932221413\n",
      "epoch: 2 step: 983, loss is 0.17957958579063416\n",
      "epoch: 2 step: 984, loss is 0.00015360864927060902\n",
      "epoch: 2 step: 985, loss is 0.004266251809895039\n",
      "epoch: 2 step: 986, loss is 0.0012771512847393751\n",
      "epoch: 2 step: 987, loss is 0.012365416623651981\n",
      "epoch: 2 step: 988, loss is 0.029958339408040047\n",
      "epoch: 2 step: 989, loss is 0.003052900545299053\n",
      "epoch: 2 step: 990, loss is 0.020376263186335564\n",
      "epoch: 2 step: 991, loss is 0.12944836914539337\n",
      "epoch: 2 step: 992, loss is 0.0019317372934892774\n",
      "epoch: 2 step: 993, loss is 0.011090797372162342\n",
      "epoch: 2 step: 994, loss is 0.051537126302719116\n",
      "epoch: 2 step: 995, loss is 0.22085382044315338\n",
      "epoch: 2 step: 996, loss is 0.03143046051263809\n",
      "epoch: 2 step: 997, loss is 0.3431958854198456\n",
      "epoch: 2 step: 998, loss is 0.015412281267344952\n",
      "epoch: 2 step: 999, loss is 0.06595870107412338\n",
      "epoch: 2 step: 1000, loss is 0.027046754956245422\n",
      "epoch: 2 step: 1001, loss is 0.06921672821044922\n",
      "epoch: 2 step: 1002, loss is 0.1571243554353714\n",
      "epoch: 2 step: 1003, loss is 0.012421289458870888\n",
      "epoch: 2 step: 1004, loss is 0.0908401608467102\n",
      "epoch: 2 step: 1005, loss is 0.03956323117017746\n",
      "epoch: 2 step: 1006, loss is 0.004661906510591507\n",
      "epoch: 2 step: 1007, loss is 0.0848541185259819\n",
      "epoch: 2 step: 1008, loss is 0.012861939147114754\n",
      "epoch: 2 step: 1009, loss is 0.04713364690542221\n",
      "epoch: 2 step: 1010, loss is 0.011305156163871288\n",
      "epoch: 2 step: 1011, loss is 0.0012556408764794469\n",
      "epoch: 2 step: 1012, loss is 0.02837921865284443\n",
      "epoch: 2 step: 1013, loss is 0.11033899337053299\n",
      "epoch: 2 step: 1014, loss is 0.004626650828868151\n",
      "epoch: 2 step: 1015, loss is 0.019087521359324455\n",
      "epoch: 2 step: 1016, loss is 0.010936964303255081\n",
      "epoch: 2 step: 1017, loss is 0.01743672788143158\n",
      "epoch: 2 step: 1018, loss is 0.04990357160568237\n",
      "epoch: 2 step: 1019, loss is 0.012854281812906265\n",
      "epoch: 2 step: 1020, loss is 0.004161180928349495\n",
      "epoch: 2 step: 1021, loss is 0.03592947870492935\n",
      "epoch: 2 step: 1022, loss is 0.09883544594049454\n",
      "epoch: 2 step: 1023, loss is 0.2999703586101532\n",
      "epoch: 2 step: 1024, loss is 0.017476893961429596\n",
      "epoch: 2 step: 1025, loss is 0.024748090654611588\n",
      "epoch: 2 step: 1026, loss is 0.17680780589580536\n",
      "epoch: 2 step: 1027, loss is 0.16447778046131134\n",
      "epoch: 2 step: 1028, loss is 0.024431977421045303\n",
      "epoch: 2 step: 1029, loss is 0.002189985476434231\n",
      "epoch: 2 step: 1030, loss is 0.09737824648618698\n",
      "epoch: 2 step: 1031, loss is 0.003958566579967737\n",
      "epoch: 2 step: 1032, loss is 0.12435107678174973\n",
      "epoch: 2 step: 1033, loss is 0.28677132725715637\n",
      "epoch: 2 step: 1034, loss is 0.09864462167024612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1035, loss is 0.038349248468875885\n",
      "epoch: 2 step: 1036, loss is 0.02018527314066887\n",
      "epoch: 2 step: 1037, loss is 0.1268623024225235\n",
      "epoch: 2 step: 1038, loss is 0.011045741848647594\n",
      "epoch: 2 step: 1039, loss is 0.014553138986229897\n",
      "epoch: 2 step: 1040, loss is 0.043132130056619644\n",
      "epoch: 2 step: 1041, loss is 0.13481926918029785\n",
      "epoch: 2 step: 1042, loss is 0.02063574269413948\n",
      "epoch: 2 step: 1043, loss is 0.0397455170750618\n",
      "epoch: 2 step: 1044, loss is 0.0026295040734112263\n",
      "epoch: 2 step: 1045, loss is 0.030193360522389412\n",
      "epoch: 2 step: 1046, loss is 0.010226024314761162\n",
      "epoch: 2 step: 1047, loss is 0.07418888807296753\n",
      "epoch: 2 step: 1048, loss is 0.0238228477537632\n",
      "epoch: 2 step: 1049, loss is 0.23227980732917786\n",
      "epoch: 2 step: 1050, loss is 0.09600639343261719\n",
      "epoch: 2 step: 1051, loss is 0.011076525785028934\n",
      "epoch: 2 step: 1052, loss is 0.021400494500994682\n",
      "epoch: 2 step: 1053, loss is 0.053074877709150314\n",
      "epoch: 2 step: 1054, loss is 0.09581906348466873\n",
      "epoch: 2 step: 1055, loss is 0.0030885699670761824\n",
      "epoch: 2 step: 1056, loss is 0.019004665315151215\n",
      "epoch: 2 step: 1057, loss is 0.11755883693695068\n",
      "epoch: 2 step: 1058, loss is 0.011116879060864449\n",
      "epoch: 2 step: 1059, loss is 0.031175702810287476\n",
      "epoch: 2 step: 1060, loss is 0.16387535631656647\n",
      "epoch: 2 step: 1061, loss is 0.019910788163542747\n",
      "epoch: 2 step: 1062, loss is 0.010392960160970688\n",
      "epoch: 2 step: 1063, loss is 0.11248283088207245\n",
      "epoch: 2 step: 1064, loss is 0.13463138043880463\n",
      "epoch: 2 step: 1065, loss is 0.1096254512667656\n",
      "epoch: 2 step: 1066, loss is 0.0026764310896396637\n",
      "epoch: 2 step: 1067, loss is 0.014386780560016632\n",
      "epoch: 2 step: 1068, loss is 0.15485763549804688\n",
      "epoch: 2 step: 1069, loss is 0.000674887967761606\n",
      "epoch: 2 step: 1070, loss is 0.1517917960882187\n",
      "epoch: 2 step: 1071, loss is 0.053873226046562195\n",
      "epoch: 2 step: 1072, loss is 0.014172712340950966\n",
      "epoch: 2 step: 1073, loss is 0.08340335637331009\n",
      "epoch: 2 step: 1074, loss is 0.013217421248555183\n",
      "epoch: 2 step: 1075, loss is 0.001640901667997241\n",
      "epoch: 2 step: 1076, loss is 0.01252601109445095\n",
      "epoch: 2 step: 1077, loss is 0.0035430274438112974\n",
      "epoch: 2 step: 1078, loss is 0.019734663888812065\n",
      "epoch: 2 step: 1079, loss is 0.08364173769950867\n",
      "epoch: 2 step: 1080, loss is 0.017282096669077873\n",
      "epoch: 2 step: 1081, loss is 0.25659868121147156\n",
      "epoch: 2 step: 1082, loss is 0.004769692663103342\n",
      "epoch: 2 step: 1083, loss is 0.01306215487420559\n",
      "epoch: 2 step: 1084, loss is 0.10693751275539398\n",
      "epoch: 2 step: 1085, loss is 0.00493765389546752\n",
      "epoch: 2 step: 1086, loss is 0.023212255910038948\n",
      "epoch: 2 step: 1087, loss is 0.012950094416737556\n",
      "epoch: 2 step: 1088, loss is 0.022263318300247192\n",
      "epoch: 2 step: 1089, loss is 0.0023306687362492085\n",
      "epoch: 2 step: 1090, loss is 0.012159405276179314\n",
      "epoch: 2 step: 1091, loss is 0.027862800285220146\n",
      "epoch: 2 step: 1092, loss is 0.01105683483183384\n",
      "epoch: 2 step: 1093, loss is 0.01964876614511013\n",
      "epoch: 2 step: 1094, loss is 0.01446817722171545\n",
      "epoch: 2 step: 1095, loss is 0.1675442010164261\n",
      "epoch: 2 step: 1096, loss is 0.02229326218366623\n",
      "epoch: 2 step: 1097, loss is 0.04737675189971924\n",
      "epoch: 2 step: 1098, loss is 0.002182857831940055\n",
      "epoch: 2 step: 1099, loss is 0.006814018357545137\n",
      "epoch: 2 step: 1100, loss is 0.0032153697684407234\n",
      "epoch: 2 step: 1101, loss is 0.15592004358768463\n",
      "epoch: 2 step: 1102, loss is 0.17673955857753754\n",
      "epoch: 2 step: 1103, loss is 0.004949563182890415\n",
      "epoch: 2 step: 1104, loss is 0.005410258192569017\n",
      "epoch: 2 step: 1105, loss is 0.005454832222312689\n",
      "epoch: 2 step: 1106, loss is 0.027196135371923447\n",
      "epoch: 2 step: 1107, loss is 0.03545641154050827\n",
      "epoch: 2 step: 1108, loss is 0.0034061698243021965\n",
      "epoch: 2 step: 1109, loss is 0.016312314197421074\n",
      "epoch: 2 step: 1110, loss is 0.06759767234325409\n",
      "epoch: 2 step: 1111, loss is 0.25334808230400085\n",
      "epoch: 2 step: 1112, loss is 0.22813226282596588\n",
      "epoch: 2 step: 1113, loss is 0.13299761712551117\n",
      "epoch: 2 step: 1114, loss is 0.02620799094438553\n",
      "epoch: 2 step: 1115, loss is 0.0010711440118029714\n",
      "epoch: 2 step: 1116, loss is 0.004276456777006388\n",
      "epoch: 2 step: 1117, loss is 0.006307580508291721\n",
      "epoch: 2 step: 1118, loss is 0.030464770272374153\n",
      "epoch: 2 step: 1119, loss is 0.03159049525856972\n",
      "epoch: 2 step: 1120, loss is 0.0016022485215216875\n",
      "epoch: 2 step: 1121, loss is 0.015897070989012718\n",
      "epoch: 2 step: 1122, loss is 0.02003020979464054\n",
      "epoch: 2 step: 1123, loss is 0.005746735725551844\n",
      "epoch: 2 step: 1124, loss is 0.0354546494781971\n",
      "epoch: 2 step: 1125, loss is 0.04368113726377487\n",
      "epoch: 2 step: 1126, loss is 0.018301213160157204\n",
      "epoch: 2 step: 1127, loss is 0.26739487051963806\n",
      "epoch: 2 step: 1128, loss is 0.046658262610435486\n",
      "epoch: 2 step: 1129, loss is 0.019833020865917206\n",
      "epoch: 2 step: 1130, loss is 0.016845956444740295\n",
      "epoch: 2 step: 1131, loss is 0.003931351471692324\n",
      "epoch: 2 step: 1132, loss is 0.14943693578243256\n",
      "epoch: 2 step: 1133, loss is 0.03656885772943497\n",
      "epoch: 2 step: 1134, loss is 0.060309235006570816\n",
      "epoch: 2 step: 1135, loss is 0.038696736097335815\n",
      "epoch: 2 step: 1136, loss is 0.0274443868547678\n",
      "epoch: 2 step: 1137, loss is 0.005905940663069487\n",
      "epoch: 2 step: 1138, loss is 0.0013244554866105318\n",
      "epoch: 2 step: 1139, loss is 0.010317572392523289\n",
      "epoch: 2 step: 1140, loss is 0.017379427328705788\n",
      "epoch: 2 step: 1141, loss is 0.024002935737371445\n",
      "epoch: 2 step: 1142, loss is 0.03139011934399605\n",
      "epoch: 2 step: 1143, loss is 0.03742390125989914\n",
      "epoch: 2 step: 1144, loss is 0.0019101890502497554\n",
      "epoch: 2 step: 1145, loss is 0.14487972855567932\n",
      "epoch: 2 step: 1146, loss is 0.0065947058610618114\n",
      "epoch: 2 step: 1147, loss is 0.0010573160834610462\n",
      "epoch: 2 step: 1148, loss is 0.014624039642512798\n",
      "epoch: 2 step: 1149, loss is 0.006164755206555128\n",
      "epoch: 2 step: 1150, loss is 0.03323390707373619\n",
      "epoch: 2 step: 1151, loss is 0.11303649842739105\n",
      "epoch: 2 step: 1152, loss is 0.0041371607221663\n",
      "epoch: 2 step: 1153, loss is 0.003975430969148874\n",
      "epoch: 2 step: 1154, loss is 0.0010495901806280017\n",
      "epoch: 2 step: 1155, loss is 0.1645408421754837\n",
      "epoch: 2 step: 1156, loss is 0.05293573811650276\n",
      "epoch: 2 step: 1157, loss is 0.006664087064564228\n",
      "epoch: 2 step: 1158, loss is 0.016419027000665665\n",
      "epoch: 2 step: 1159, loss is 0.005638845264911652\n",
      "epoch: 2 step: 1160, loss is 0.01571149006485939\n",
      "epoch: 2 step: 1161, loss is 0.002855634316802025\n",
      "epoch: 2 step: 1162, loss is 0.26700907945632935\n",
      "epoch: 2 step: 1163, loss is 0.016209689900279045\n",
      "epoch: 2 step: 1164, loss is 0.047117095440626144\n",
      "epoch: 2 step: 1165, loss is 0.21650779247283936\n",
      "epoch: 2 step: 1166, loss is 0.08692663162946701\n",
      "epoch: 2 step: 1167, loss is 0.044190362095832825\n",
      "epoch: 2 step: 1168, loss is 0.024429554119706154\n",
      "epoch: 2 step: 1169, loss is 0.28891894221305847\n",
      "epoch: 2 step: 1170, loss is 0.199315145611763\n",
      "epoch: 2 step: 1171, loss is 0.023430274799466133\n",
      "epoch: 2 step: 1172, loss is 0.013624206185340881\n",
      "epoch: 2 step: 1173, loss is 0.0030407030135393143\n",
      "epoch: 2 step: 1174, loss is 0.02614574320614338\n",
      "epoch: 2 step: 1175, loss is 0.15596088767051697\n",
      "epoch: 2 step: 1176, loss is 0.0012360734399408102\n",
      "epoch: 2 step: 1177, loss is 0.006844715215265751\n",
      "epoch: 2 step: 1178, loss is 0.10011565685272217\n",
      "epoch: 2 step: 1179, loss is 0.0006556481239385903\n",
      "epoch: 2 step: 1180, loss is 0.14511308073997498\n",
      "epoch: 2 step: 1181, loss is 0.018581029027700424\n",
      "epoch: 2 step: 1182, loss is 0.023955944925546646\n",
      "epoch: 2 step: 1183, loss is 0.026194598525762558\n",
      "epoch: 2 step: 1184, loss is 0.016011405736207962\n",
      "epoch: 2 step: 1185, loss is 0.03680017217993736\n",
      "epoch: 2 step: 1186, loss is 0.006773021072149277\n",
      "epoch: 2 step: 1187, loss is 0.0016828072257339954\n",
      "epoch: 2 step: 1188, loss is 0.02628045715391636\n",
      "epoch: 2 step: 1189, loss is 0.010594656690955162\n",
      "epoch: 2 step: 1190, loss is 0.12257060408592224\n",
      "epoch: 2 step: 1191, loss is 0.0014653579564765096\n",
      "epoch: 2 step: 1192, loss is 0.06702470034360886\n",
      "epoch: 2 step: 1193, loss is 0.003127750474959612\n",
      "epoch: 2 step: 1194, loss is 0.11296956241130829\n",
      "epoch: 2 step: 1195, loss is 0.015539918094873428\n",
      "epoch: 2 step: 1196, loss is 0.09765873104333878\n",
      "epoch: 2 step: 1197, loss is 0.006076101213693619\n",
      "epoch: 2 step: 1198, loss is 0.017666932195425034\n",
      "epoch: 2 step: 1199, loss is 0.026252472773194313\n",
      "epoch: 2 step: 1200, loss is 0.06712903082370758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1201, loss is 0.07034455239772797\n",
      "epoch: 2 step: 1202, loss is 0.0682775005698204\n",
      "epoch: 2 step: 1203, loss is 0.05745251104235649\n",
      "epoch: 2 step: 1204, loss is 0.07328896969556808\n",
      "epoch: 2 step: 1205, loss is 0.3112734854221344\n",
      "epoch: 2 step: 1206, loss is 0.0028492591809481382\n",
      "epoch: 2 step: 1207, loss is 0.09710926562547684\n",
      "epoch: 2 step: 1208, loss is 0.04984254390001297\n",
      "epoch: 2 step: 1209, loss is 0.010738399811089039\n",
      "epoch: 2 step: 1210, loss is 0.08790338784456253\n",
      "epoch: 2 step: 1211, loss is 0.06760832667350769\n",
      "epoch: 2 step: 1212, loss is 0.05581609904766083\n",
      "epoch: 2 step: 1213, loss is 0.0024299731012433767\n",
      "epoch: 2 step: 1214, loss is 0.009562957100570202\n",
      "epoch: 2 step: 1215, loss is 0.005819584242999554\n",
      "epoch: 2 step: 1216, loss is 0.19597581028938293\n",
      "epoch: 2 step: 1217, loss is 0.13179002702236176\n",
      "epoch: 2 step: 1218, loss is 0.018066054210066795\n",
      "epoch: 2 step: 1219, loss is 0.006828371901065111\n",
      "epoch: 2 step: 1220, loss is 0.0008537669200450182\n",
      "epoch: 2 step: 1221, loss is 0.020645149052143097\n",
      "epoch: 2 step: 1222, loss is 0.037887539714574814\n",
      "epoch: 2 step: 1223, loss is 0.04398774728178978\n",
      "epoch: 2 step: 1224, loss is 0.0808558538556099\n",
      "epoch: 2 step: 1225, loss is 0.00184683280531317\n",
      "epoch: 2 step: 1226, loss is 0.022749457508325577\n",
      "epoch: 2 step: 1227, loss is 0.031387731432914734\n",
      "epoch: 2 step: 1228, loss is 0.018831903114914894\n",
      "epoch: 2 step: 1229, loss is 0.0037261592224240303\n",
      "epoch: 2 step: 1230, loss is 0.13136756420135498\n",
      "epoch: 2 step: 1231, loss is 0.006587448064237833\n",
      "epoch: 2 step: 1232, loss is 0.12644903361797333\n",
      "epoch: 2 step: 1233, loss is 0.0026393013540655375\n",
      "epoch: 2 step: 1234, loss is 0.03010554611682892\n",
      "epoch: 2 step: 1235, loss is 0.02781500667333603\n",
      "epoch: 2 step: 1236, loss is 0.000615621218457818\n",
      "epoch: 2 step: 1237, loss is 0.06036776676774025\n",
      "epoch: 2 step: 1238, loss is 0.03430238366127014\n",
      "epoch: 2 step: 1239, loss is 0.015005163848400116\n",
      "epoch: 2 step: 1240, loss is 0.0745360404253006\n",
      "epoch: 2 step: 1241, loss is 0.07736820727586746\n",
      "epoch: 2 step: 1242, loss is 0.00854929443448782\n",
      "epoch: 2 step: 1243, loss is 0.006731052417308092\n",
      "epoch: 2 step: 1244, loss is 0.06627002358436584\n",
      "epoch: 2 step: 1245, loss is 0.009236513637006283\n",
      "epoch: 2 step: 1246, loss is 0.014957414008677006\n",
      "epoch: 2 step: 1247, loss is 0.004420339595526457\n",
      "epoch: 2 step: 1248, loss is 0.0005826689302921295\n",
      "epoch: 2 step: 1249, loss is 0.010435076430439949\n",
      "epoch: 2 step: 1250, loss is 0.004294228740036488\n",
      "epoch: 2 step: 1251, loss is 0.0008230582461692393\n",
      "epoch: 2 step: 1252, loss is 0.03909546881914139\n",
      "epoch: 2 step: 1253, loss is 0.010734506882727146\n",
      "epoch: 2 step: 1254, loss is 0.0028652313631027937\n",
      "epoch: 2 step: 1255, loss is 0.0008079588878899813\n",
      "epoch: 2 step: 1256, loss is 0.020921289920806885\n",
      "epoch: 2 step: 1257, loss is 0.09226226806640625\n",
      "epoch: 2 step: 1258, loss is 0.0015296447090804577\n",
      "epoch: 2 step: 1259, loss is 0.020227573812007904\n",
      "epoch: 2 step: 1260, loss is 0.13732367753982544\n",
      "epoch: 2 step: 1261, loss is 0.021017009392380714\n",
      "epoch: 2 step: 1262, loss is 0.005125846713781357\n",
      "epoch: 2 step: 1263, loss is 0.0035366187803447247\n",
      "epoch: 2 step: 1264, loss is 0.16934573650360107\n",
      "epoch: 2 step: 1265, loss is 0.005226162262260914\n",
      "epoch: 2 step: 1266, loss is 0.015457144007086754\n",
      "epoch: 2 step: 1267, loss is 0.012296929955482483\n",
      "epoch: 2 step: 1268, loss is 0.22571291029453278\n",
      "epoch: 2 step: 1269, loss is 0.0024709925055503845\n",
      "epoch: 2 step: 1270, loss is 0.0005019885138608515\n",
      "epoch: 2 step: 1271, loss is 0.0013648481108248234\n",
      "epoch: 2 step: 1272, loss is 0.006763699930161238\n",
      "epoch: 2 step: 1273, loss is 0.0009470960358157754\n",
      "epoch: 2 step: 1274, loss is 0.01088319718837738\n",
      "epoch: 2 step: 1275, loss is 0.0045331791043281555\n",
      "epoch: 2 step: 1276, loss is 0.02407405525445938\n",
      "epoch: 2 step: 1277, loss is 0.03223330155014992\n",
      "epoch: 2 step: 1278, loss is 0.09772935509681702\n",
      "epoch: 2 step: 1279, loss is 0.15008528530597687\n",
      "epoch: 2 step: 1280, loss is 0.012375547550618649\n",
      "epoch: 2 step: 1281, loss is 0.06195003539323807\n",
      "epoch: 2 step: 1282, loss is 0.003222521860152483\n",
      "epoch: 2 step: 1283, loss is 0.05615843087434769\n",
      "epoch: 2 step: 1284, loss is 0.003060318995267153\n",
      "epoch: 2 step: 1285, loss is 0.010191203095018864\n",
      "epoch: 2 step: 1286, loss is 0.0009035594994202256\n",
      "epoch: 2 step: 1287, loss is 0.04808925464749336\n",
      "epoch: 2 step: 1288, loss is 0.006603000685572624\n",
      "epoch: 2 step: 1289, loss is 0.0610426664352417\n",
      "epoch: 2 step: 1290, loss is 0.023576881736516953\n",
      "epoch: 2 step: 1291, loss is 0.0029973224736750126\n",
      "epoch: 2 step: 1292, loss is 0.5282102227210999\n",
      "epoch: 2 step: 1293, loss is 0.4707878828048706\n",
      "epoch: 2 step: 1294, loss is 0.0052357017993927\n",
      "epoch: 2 step: 1295, loss is 0.016987474635243416\n",
      "epoch: 2 step: 1296, loss is 0.07716570049524307\n",
      "epoch: 2 step: 1297, loss is 0.041719306260347366\n",
      "epoch: 2 step: 1298, loss is 0.07804569602012634\n",
      "epoch: 2 step: 1299, loss is 0.0033027566969394684\n",
      "epoch: 2 step: 1300, loss is 0.07325263321399689\n",
      "epoch: 2 step: 1301, loss is 0.13509847223758698\n",
      "epoch: 2 step: 1302, loss is 0.07940444350242615\n",
      "epoch: 2 step: 1303, loss is 0.021825887262821198\n",
      "epoch: 2 step: 1304, loss is 0.038836050778627396\n",
      "epoch: 2 step: 1305, loss is 0.2559250295162201\n",
      "epoch: 2 step: 1306, loss is 0.027173982933163643\n",
      "epoch: 2 step: 1307, loss is 0.002727735787630081\n",
      "epoch: 2 step: 1308, loss is 0.010161994025111198\n",
      "epoch: 2 step: 1309, loss is 0.08239125460386276\n",
      "epoch: 2 step: 1310, loss is 0.03893595561385155\n",
      "epoch: 2 step: 1311, loss is 0.17202989757061005\n",
      "epoch: 2 step: 1312, loss is 0.005849646870046854\n",
      "epoch: 2 step: 1313, loss is 0.0620405413210392\n",
      "epoch: 2 step: 1314, loss is 0.010316461324691772\n",
      "epoch: 2 step: 1315, loss is 0.02326704002916813\n",
      "epoch: 2 step: 1316, loss is 0.0531887412071228\n",
      "epoch: 2 step: 1317, loss is 0.14941531419754028\n",
      "epoch: 2 step: 1318, loss is 0.01984921656548977\n",
      "epoch: 2 step: 1319, loss is 0.011018329299986362\n",
      "epoch: 2 step: 1320, loss is 0.03912872076034546\n",
      "epoch: 2 step: 1321, loss is 0.025883901864290237\n",
      "epoch: 2 step: 1322, loss is 0.002984470222145319\n",
      "epoch: 2 step: 1323, loss is 0.019185954704880714\n",
      "epoch: 2 step: 1324, loss is 0.022208329290151596\n",
      "epoch: 2 step: 1325, loss is 0.0010924771195277572\n",
      "epoch: 2 step: 1326, loss is 0.16694270074367523\n",
      "epoch: 2 step: 1327, loss is 0.026002192869782448\n",
      "epoch: 2 step: 1328, loss is 0.04577723518013954\n",
      "epoch: 2 step: 1329, loss is 0.018554609268903732\n",
      "epoch: 2 step: 1330, loss is 0.008770857937633991\n",
      "epoch: 2 step: 1331, loss is 0.002438628813251853\n",
      "epoch: 2 step: 1332, loss is 0.00416654022410512\n",
      "epoch: 2 step: 1333, loss is 0.022269994020462036\n",
      "epoch: 2 step: 1334, loss is 0.12471909821033478\n",
      "epoch: 2 step: 1335, loss is 0.000837985600810498\n",
      "epoch: 2 step: 1336, loss is 0.01363880280405283\n",
      "epoch: 2 step: 1337, loss is 0.021764960139989853\n",
      "epoch: 2 step: 1338, loss is 0.0035913262981921434\n",
      "epoch: 2 step: 1339, loss is 0.002949636662378907\n",
      "epoch: 2 step: 1340, loss is 0.0016465442022308707\n",
      "epoch: 2 step: 1341, loss is 0.0021306616254150867\n",
      "epoch: 2 step: 1342, loss is 0.011330872774124146\n",
      "epoch: 2 step: 1343, loss is 0.17157137393951416\n",
      "epoch: 2 step: 1344, loss is 0.10030801594257355\n",
      "epoch: 2 step: 1345, loss is 0.0009829314658418298\n",
      "epoch: 2 step: 1346, loss is 0.15146537125110626\n",
      "epoch: 2 step: 1347, loss is 0.052151940762996674\n",
      "epoch: 2 step: 1348, loss is 0.3189961016178131\n",
      "epoch: 2 step: 1349, loss is 0.25479403138160706\n",
      "epoch: 2 step: 1350, loss is 0.018230684101581573\n",
      "epoch: 2 step: 1351, loss is 0.011938883922994137\n",
      "epoch: 2 step: 1352, loss is 0.003642797702923417\n",
      "epoch: 2 step: 1353, loss is 0.04645390063524246\n",
      "epoch: 2 step: 1354, loss is 0.09469961374998093\n",
      "epoch: 2 step: 1355, loss is 0.0017163469456136227\n",
      "epoch: 2 step: 1356, loss is 0.0013884033542126417\n",
      "epoch: 2 step: 1357, loss is 0.048745136708021164\n",
      "epoch: 2 step: 1358, loss is 0.003761336440220475\n",
      "epoch: 2 step: 1359, loss is 0.00015248314593918622\n",
      "epoch: 2 step: 1360, loss is 0.026521671563386917\n",
      "epoch: 2 step: 1361, loss is 0.11359801143407822\n",
      "epoch: 2 step: 1362, loss is 0.0026270991656929255\n",
      "epoch: 2 step: 1363, loss is 0.1574520766735077\n",
      "epoch: 2 step: 1364, loss is 0.043632056564092636\n",
      "epoch: 2 step: 1365, loss is 0.0005251104012131691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1366, loss is 0.004216596484184265\n",
      "epoch: 2 step: 1367, loss is 0.006398165598511696\n",
      "epoch: 2 step: 1368, loss is 0.006400563754141331\n",
      "epoch: 2 step: 1369, loss is 0.0017891231691464782\n",
      "epoch: 2 step: 1370, loss is 0.014269931241869926\n",
      "epoch: 2 step: 1371, loss is 0.17806120216846466\n",
      "epoch: 2 step: 1372, loss is 0.004793296102434397\n",
      "epoch: 2 step: 1373, loss is 0.08879204094409943\n",
      "epoch: 2 step: 1374, loss is 0.006400813814252615\n",
      "epoch: 2 step: 1375, loss is 0.018158208578824997\n",
      "epoch: 2 step: 1376, loss is 0.0030748017597943544\n",
      "epoch: 2 step: 1377, loss is 0.22513137757778168\n",
      "epoch: 2 step: 1378, loss is 0.030637826770544052\n",
      "epoch: 2 step: 1379, loss is 0.08159633725881577\n",
      "epoch: 2 step: 1380, loss is 0.09511947631835938\n",
      "epoch: 2 step: 1381, loss is 0.002273769583553076\n",
      "epoch: 2 step: 1382, loss is 0.11148595064878464\n",
      "epoch: 2 step: 1383, loss is 0.013240517117083073\n",
      "epoch: 2 step: 1384, loss is 0.0674477219581604\n",
      "epoch: 2 step: 1385, loss is 0.006662101484835148\n",
      "epoch: 2 step: 1386, loss is 0.004859205335378647\n",
      "epoch: 2 step: 1387, loss is 0.014505363069474697\n",
      "epoch: 2 step: 1388, loss is 0.004056909121572971\n",
      "epoch: 2 step: 1389, loss is 0.04245642572641373\n",
      "epoch: 2 step: 1390, loss is 0.08506565541028976\n",
      "epoch: 2 step: 1391, loss is 0.010446948930621147\n",
      "epoch: 2 step: 1392, loss is 0.0006862478912808001\n",
      "epoch: 2 step: 1393, loss is 0.004913610871881247\n",
      "epoch: 2 step: 1394, loss is 0.024707136675715446\n",
      "epoch: 2 step: 1395, loss is 0.2619503140449524\n",
      "epoch: 2 step: 1396, loss is 0.007349399849772453\n",
      "epoch: 2 step: 1397, loss is 0.03435191139578819\n",
      "epoch: 2 step: 1398, loss is 0.006032649893313646\n",
      "epoch: 2 step: 1399, loss is 0.00074549246346578\n",
      "epoch: 2 step: 1400, loss is 0.011135930195450783\n",
      "epoch: 2 step: 1401, loss is 0.02809843048453331\n",
      "epoch: 2 step: 1402, loss is 0.026393910869956017\n",
      "epoch: 2 step: 1403, loss is 0.022959604859352112\n",
      "epoch: 2 step: 1404, loss is 0.0006535911816172302\n",
      "epoch: 2 step: 1405, loss is 0.017716895788908005\n",
      "epoch: 2 step: 1406, loss is 0.04124629497528076\n",
      "epoch: 2 step: 1407, loss is 0.09821051359176636\n",
      "epoch: 2 step: 1408, loss is 0.007338483817875385\n",
      "epoch: 2 step: 1409, loss is 0.03291243314743042\n",
      "epoch: 2 step: 1410, loss is 0.21432292461395264\n",
      "epoch: 2 step: 1411, loss is 0.02844659797847271\n",
      "epoch: 2 step: 1412, loss is 0.23272712528705597\n",
      "epoch: 2 step: 1413, loss is 0.0015012979274615645\n",
      "epoch: 2 step: 1414, loss is 0.14636872708797455\n",
      "epoch: 2 step: 1415, loss is 0.15905354917049408\n",
      "epoch: 2 step: 1416, loss is 0.06761086732149124\n",
      "epoch: 2 step: 1417, loss is 0.00036416988587006927\n",
      "epoch: 2 step: 1418, loss is 0.0407850556075573\n",
      "epoch: 2 step: 1419, loss is 0.09327825903892517\n",
      "epoch: 2 step: 1420, loss is 0.015893613919615746\n",
      "epoch: 2 step: 1421, loss is 0.015432899817824364\n",
      "epoch: 2 step: 1422, loss is 0.1449093222618103\n",
      "epoch: 2 step: 1423, loss is 0.0055516185238957405\n",
      "epoch: 2 step: 1424, loss is 0.18114151060581207\n",
      "epoch: 2 step: 1425, loss is 0.12936939299106598\n",
      "epoch: 2 step: 1426, loss is 0.07008674740791321\n",
      "epoch: 2 step: 1427, loss is 0.014030561782419682\n",
      "epoch: 2 step: 1428, loss is 0.2606693506240845\n",
      "epoch: 2 step: 1429, loss is 0.012292751111090183\n",
      "epoch: 2 step: 1430, loss is 0.0037815370596945286\n",
      "epoch: 2 step: 1431, loss is 0.0023541669361293316\n",
      "epoch: 2 step: 1432, loss is 0.062138479202985764\n",
      "epoch: 2 step: 1433, loss is 0.13202373683452606\n",
      "epoch: 2 step: 1434, loss is 0.0009244472021237016\n",
      "epoch: 2 step: 1435, loss is 0.014952304773032665\n",
      "epoch: 2 step: 1436, loss is 0.13761331140995026\n",
      "epoch: 2 step: 1437, loss is 0.002547512063756585\n",
      "epoch: 2 step: 1438, loss is 0.001954565290361643\n",
      "epoch: 2 step: 1439, loss is 0.018680084496736526\n",
      "epoch: 2 step: 1440, loss is 0.271061509847641\n",
      "epoch: 2 step: 1441, loss is 0.007125955540686846\n",
      "epoch: 2 step: 1442, loss is 0.0017181143630295992\n",
      "epoch: 2 step: 1443, loss is 0.002716420218348503\n",
      "epoch: 2 step: 1444, loss is 0.005040708929300308\n",
      "epoch: 2 step: 1445, loss is 0.044041045010089874\n",
      "epoch: 2 step: 1446, loss is 0.07882092148065567\n",
      "epoch: 2 step: 1447, loss is 0.014029547572135925\n",
      "epoch: 2 step: 1448, loss is 0.01140839233994484\n",
      "epoch: 2 step: 1449, loss is 0.025690896436572075\n",
      "epoch: 2 step: 1450, loss is 0.07853715866804123\n",
      "epoch: 2 step: 1451, loss is 0.038085490465164185\n",
      "epoch: 2 step: 1452, loss is 0.010813014581799507\n",
      "epoch: 2 step: 1453, loss is 0.07112451642751694\n",
      "epoch: 2 step: 1454, loss is 0.05915474891662598\n",
      "epoch: 2 step: 1455, loss is 0.003962744493037462\n",
      "epoch: 2 step: 1456, loss is 0.0014065911527723074\n",
      "epoch: 2 step: 1457, loss is 0.0109103349968791\n",
      "epoch: 2 step: 1458, loss is 0.009330935776233673\n",
      "epoch: 2 step: 1459, loss is 0.0021902520675212145\n",
      "epoch: 2 step: 1460, loss is 0.21456760168075562\n",
      "epoch: 2 step: 1461, loss is 0.08390900492668152\n",
      "epoch: 2 step: 1462, loss is 0.2390807718038559\n",
      "epoch: 2 step: 1463, loss is 0.01749385893344879\n",
      "epoch: 2 step: 1464, loss is 0.13056565821170807\n",
      "epoch: 2 step: 1465, loss is 0.08426131308078766\n",
      "epoch: 2 step: 1466, loss is 0.04063204675912857\n",
      "epoch: 2 step: 1467, loss is 0.031638745218515396\n",
      "epoch: 2 step: 1468, loss is 0.02638201043009758\n",
      "epoch: 2 step: 1469, loss is 0.015142127871513367\n",
      "epoch: 2 step: 1470, loss is 0.029216617345809937\n",
      "epoch: 2 step: 1471, loss is 0.0045782397501170635\n",
      "epoch: 2 step: 1472, loss is 0.017769627273082733\n",
      "epoch: 2 step: 1473, loss is 0.027483955025672913\n",
      "epoch: 2 step: 1474, loss is 0.00517602264881134\n",
      "epoch: 2 step: 1475, loss is 0.0013668953906744719\n",
      "epoch: 2 step: 1476, loss is 0.000946373213082552\n",
      "epoch: 2 step: 1477, loss is 0.033236972987651825\n",
      "epoch: 2 step: 1478, loss is 0.03741155564785004\n",
      "epoch: 2 step: 1479, loss is 0.06435682624578476\n",
      "epoch: 2 step: 1480, loss is 0.012592398561537266\n",
      "epoch: 2 step: 1481, loss is 0.0065190610475838184\n",
      "epoch: 2 step: 1482, loss is 0.1677352488040924\n",
      "epoch: 2 step: 1483, loss is 0.04048912599682808\n",
      "epoch: 2 step: 1484, loss is 0.34891584515571594\n",
      "epoch: 2 step: 1485, loss is 0.06240563467144966\n",
      "epoch: 2 step: 1486, loss is 0.17709140479564667\n",
      "epoch: 2 step: 1487, loss is 0.005735056009143591\n",
      "epoch: 2 step: 1488, loss is 0.026874249801039696\n",
      "epoch: 2 step: 1489, loss is 0.008384031243622303\n",
      "epoch: 2 step: 1490, loss is 0.013377358205616474\n",
      "epoch: 2 step: 1491, loss is 0.09066087752580643\n",
      "epoch: 2 step: 1492, loss is 0.04420631378889084\n",
      "epoch: 2 step: 1493, loss is 0.006752682849764824\n",
      "epoch: 2 step: 1494, loss is 0.030092090368270874\n",
      "epoch: 2 step: 1495, loss is 0.06816093623638153\n",
      "epoch: 2 step: 1496, loss is 0.266730934381485\n",
      "epoch: 2 step: 1497, loss is 0.11601826548576355\n",
      "epoch: 2 step: 1498, loss is 0.10974238812923431\n",
      "epoch: 2 step: 1499, loss is 0.08295602351427078\n",
      "epoch: 2 step: 1500, loss is 0.02955567091703415\n",
      "epoch: 2 step: 1501, loss is 0.03395609185099602\n",
      "epoch: 2 step: 1502, loss is 0.06114797666668892\n",
      "epoch: 2 step: 1503, loss is 0.002150530694052577\n",
      "epoch: 2 step: 1504, loss is 0.04192296043038368\n",
      "epoch: 2 step: 1505, loss is 0.01402465719729662\n",
      "epoch: 2 step: 1506, loss is 0.12731730937957764\n",
      "epoch: 2 step: 1507, loss is 0.003064524382352829\n",
      "epoch: 2 step: 1508, loss is 0.0281684510409832\n",
      "epoch: 2 step: 1509, loss is 0.16623082756996155\n",
      "epoch: 2 step: 1510, loss is 0.020021282136440277\n",
      "epoch: 2 step: 1511, loss is 0.04378403723239899\n",
      "epoch: 2 step: 1512, loss is 0.003607872175052762\n",
      "epoch: 2 step: 1513, loss is 0.0015730225713923573\n",
      "epoch: 2 step: 1514, loss is 0.1375959813594818\n",
      "epoch: 2 step: 1515, loss is 0.007211328949779272\n",
      "epoch: 2 step: 1516, loss is 0.044529106467962265\n",
      "epoch: 2 step: 1517, loss is 0.018869806081056595\n",
      "epoch: 2 step: 1518, loss is 0.014882729388773441\n",
      "epoch: 2 step: 1519, loss is 0.1247011348605156\n",
      "epoch: 2 step: 1520, loss is 0.1480197310447693\n",
      "epoch: 2 step: 1521, loss is 0.017024213448166847\n",
      "epoch: 2 step: 1522, loss is 0.0033661224879324436\n",
      "epoch: 2 step: 1523, loss is 0.014585339464247227\n",
      "epoch: 2 step: 1524, loss is 0.007256497163325548\n",
      "epoch: 2 step: 1525, loss is 0.004802008159458637\n",
      "epoch: 2 step: 1526, loss is 0.0036096060648560524\n",
      "epoch: 2 step: 1527, loss is 0.007130383979529142\n",
      "epoch: 2 step: 1528, loss is 0.00427506398409605\n",
      "epoch: 2 step: 1529, loss is 0.10240950435400009\n",
      "epoch: 2 step: 1530, loss is 0.06321236491203308\n",
      "epoch: 2 step: 1531, loss is 0.0016969051212072372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1532, loss is 0.000931176298763603\n",
      "epoch: 2 step: 1533, loss is 0.026924733072519302\n",
      "epoch: 2 step: 1534, loss is 0.05363716185092926\n",
      "epoch: 2 step: 1535, loss is 0.015465463511645794\n",
      "epoch: 2 step: 1536, loss is 0.010614852420985699\n",
      "epoch: 2 step: 1537, loss is 0.024683577939867973\n",
      "epoch: 2 step: 1538, loss is 0.04839349910616875\n",
      "epoch: 2 step: 1539, loss is 0.006127081345766783\n",
      "epoch: 2 step: 1540, loss is 0.02087424509227276\n",
      "epoch: 2 step: 1541, loss is 0.00288441963493824\n",
      "epoch: 2 step: 1542, loss is 0.0228379238396883\n",
      "epoch: 2 step: 1543, loss is 0.039570316672325134\n",
      "epoch: 2 step: 1544, loss is 0.015331939794123173\n",
      "epoch: 2 step: 1545, loss is 0.13037098944187164\n",
      "epoch: 2 step: 1546, loss is 0.012830585241317749\n",
      "epoch: 2 step: 1547, loss is 0.11136626452207565\n",
      "epoch: 2 step: 1548, loss is 0.001877583796158433\n",
      "epoch: 2 step: 1549, loss is 0.0014753631548956037\n",
      "epoch: 2 step: 1550, loss is 0.03868023678660393\n",
      "epoch: 2 step: 1551, loss is 0.20280346274375916\n",
      "epoch: 2 step: 1552, loss is 0.04193919897079468\n",
      "epoch: 2 step: 1553, loss is 0.001027856138534844\n",
      "epoch: 2 step: 1554, loss is 0.003082509385421872\n",
      "epoch: 2 step: 1555, loss is 0.0029571889899671078\n",
      "epoch: 2 step: 1556, loss is 0.0013308185152709484\n",
      "epoch: 2 step: 1557, loss is 0.004771943669766188\n",
      "epoch: 2 step: 1558, loss is 0.0005138592678122222\n",
      "epoch: 2 step: 1559, loss is 0.005097513552755117\n",
      "epoch: 2 step: 1560, loss is 0.050348374992609024\n",
      "epoch: 2 step: 1561, loss is 0.011390252970159054\n",
      "epoch: 2 step: 1562, loss is 0.0008292762795463204\n",
      "epoch: 2 step: 1563, loss is 0.1999499499797821\n",
      "epoch: 2 step: 1564, loss is 0.001676169573329389\n",
      "epoch: 2 step: 1565, loss is 0.0013470719568431377\n",
      "epoch: 2 step: 1566, loss is 0.003946084529161453\n",
      "epoch: 2 step: 1567, loss is 0.023647556081414223\n",
      "epoch: 2 step: 1568, loss is 0.00042598249274306\n",
      "epoch: 2 step: 1569, loss is 0.029343968257308006\n",
      "epoch: 2 step: 1570, loss is 0.05813898891210556\n",
      "epoch: 2 step: 1571, loss is 0.001491343486122787\n",
      "epoch: 2 step: 1572, loss is 0.0023930659517645836\n",
      "epoch: 2 step: 1573, loss is 0.040615372359752655\n",
      "epoch: 2 step: 1574, loss is 0.028128040954470634\n",
      "epoch: 2 step: 1575, loss is 0.0767955631017685\n",
      "epoch: 2 step: 1576, loss is 0.058216728270053864\n",
      "epoch: 2 step: 1577, loss is 0.005809885915368795\n",
      "epoch: 2 step: 1578, loss is 0.011074459180235863\n",
      "epoch: 2 step: 1579, loss is 0.06154151260852814\n",
      "epoch: 2 step: 1580, loss is 0.013770950958132744\n",
      "epoch: 2 step: 1581, loss is 0.0021019186824560165\n",
      "epoch: 2 step: 1582, loss is 0.010445737279951572\n",
      "epoch: 2 step: 1583, loss is 0.03192847594618797\n",
      "epoch: 2 step: 1584, loss is 0.14631535112857819\n",
      "epoch: 2 step: 1585, loss is 0.19246482849121094\n",
      "epoch: 2 step: 1586, loss is 0.02073097974061966\n",
      "epoch: 2 step: 1587, loss is 0.0021379536483436823\n",
      "epoch: 2 step: 1588, loss is 0.08669833838939667\n",
      "epoch: 2 step: 1589, loss is 0.06290137767791748\n",
      "epoch: 2 step: 1590, loss is 0.09552808105945587\n",
      "epoch: 2 step: 1591, loss is 0.08736921846866608\n",
      "epoch: 2 step: 1592, loss is 0.07203852385282516\n",
      "epoch: 2 step: 1593, loss is 0.10259260982275009\n",
      "epoch: 2 step: 1594, loss is 0.04868565872311592\n",
      "epoch: 2 step: 1595, loss is 0.04789664223790169\n",
      "epoch: 2 step: 1596, loss is 0.012380676344037056\n",
      "epoch: 2 step: 1597, loss is 0.04250902310013771\n",
      "epoch: 2 step: 1598, loss is 0.0881955549120903\n",
      "epoch: 2 step: 1599, loss is 0.017694322392344475\n",
      "epoch: 2 step: 1600, loss is 0.04415794461965561\n",
      "epoch: 2 step: 1601, loss is 0.03998741880059242\n",
      "epoch: 2 step: 1602, loss is 0.007081301417201757\n",
      "epoch: 2 step: 1603, loss is 0.15281125903129578\n",
      "epoch: 2 step: 1604, loss is 0.08048020303249359\n",
      "epoch: 2 step: 1605, loss is 0.02554909884929657\n",
      "epoch: 2 step: 1606, loss is 0.0113076725974679\n",
      "epoch: 2 step: 1607, loss is 0.012321285903453827\n",
      "epoch: 2 step: 1608, loss is 0.000752852822188288\n",
      "epoch: 2 step: 1609, loss is 0.0031261390540748835\n",
      "epoch: 2 step: 1610, loss is 0.024624371901154518\n",
      "epoch: 2 step: 1611, loss is 0.010114343836903572\n",
      "epoch: 2 step: 1612, loss is 0.0016200412064790726\n",
      "epoch: 2 step: 1613, loss is 0.033167965710163116\n",
      "epoch: 2 step: 1614, loss is 0.007474547252058983\n",
      "epoch: 2 step: 1615, loss is 0.0410483255982399\n",
      "epoch: 2 step: 1616, loss is 0.008977193385362625\n",
      "epoch: 2 step: 1617, loss is 0.0027607993688434362\n",
      "epoch: 2 step: 1618, loss is 0.008480903692543507\n",
      "epoch: 2 step: 1619, loss is 0.009292461909353733\n",
      "epoch: 2 step: 1620, loss is 0.007991106249392033\n",
      "epoch: 2 step: 1621, loss is 0.028886953368782997\n",
      "epoch: 2 step: 1622, loss is 0.05994526296854019\n",
      "epoch: 2 step: 1623, loss is 0.11640501022338867\n",
      "epoch: 2 step: 1624, loss is 0.006126874126493931\n",
      "epoch: 2 step: 1625, loss is 0.3141371011734009\n",
      "epoch: 2 step: 1626, loss is 0.03949696943163872\n",
      "epoch: 2 step: 1627, loss is 0.0078755347058177\n",
      "epoch: 2 step: 1628, loss is 0.017523180693387985\n",
      "epoch: 2 step: 1629, loss is 0.005656430497765541\n",
      "epoch: 2 step: 1630, loss is 0.002471993677318096\n",
      "epoch: 2 step: 1631, loss is 0.015425519086420536\n",
      "epoch: 2 step: 1632, loss is 0.005122635047882795\n",
      "epoch: 2 step: 1633, loss is 0.10555150359869003\n",
      "epoch: 2 step: 1634, loss is 0.12199363857507706\n",
      "epoch: 2 step: 1635, loss is 0.008606454357504845\n",
      "epoch: 2 step: 1636, loss is 0.10966756194829941\n",
      "epoch: 2 step: 1637, loss is 0.011914034374058247\n",
      "epoch: 2 step: 1638, loss is 0.15766486525535583\n",
      "epoch: 2 step: 1639, loss is 0.0018495293334126472\n",
      "epoch: 2 step: 1640, loss is 0.03281596675515175\n",
      "epoch: 2 step: 1641, loss is 0.0993664562702179\n",
      "epoch: 2 step: 1642, loss is 0.008614988997578621\n",
      "epoch: 2 step: 1643, loss is 0.13354027271270752\n",
      "epoch: 2 step: 1644, loss is 0.01537133939564228\n",
      "epoch: 2 step: 1645, loss is 0.00530085526406765\n",
      "epoch: 2 step: 1646, loss is 0.05412402004003525\n",
      "epoch: 2 step: 1647, loss is 0.0003745323629118502\n",
      "epoch: 2 step: 1648, loss is 0.0027552933897823095\n",
      "epoch: 2 step: 1649, loss is 0.02313351072371006\n",
      "epoch: 2 step: 1650, loss is 0.03936277702450752\n",
      "epoch: 2 step: 1651, loss is 0.21862594783306122\n",
      "epoch: 2 step: 1652, loss is 0.0011152041843160987\n",
      "epoch: 2 step: 1653, loss is 0.004682022146880627\n",
      "epoch: 2 step: 1654, loss is 0.03344820439815521\n",
      "epoch: 2 step: 1655, loss is 0.1900203377008438\n",
      "epoch: 2 step: 1656, loss is 0.022480597719550133\n",
      "epoch: 2 step: 1657, loss is 0.04460113123059273\n",
      "epoch: 2 step: 1658, loss is 0.0005575643153861165\n",
      "epoch: 2 step: 1659, loss is 0.004996826406568289\n",
      "epoch: 2 step: 1660, loss is 0.010859622620046139\n",
      "epoch: 2 step: 1661, loss is 0.009768147952854633\n",
      "epoch: 2 step: 1662, loss is 0.06675047427415848\n",
      "epoch: 2 step: 1663, loss is 0.07910376787185669\n",
      "epoch: 2 step: 1664, loss is 0.22501783072948456\n",
      "epoch: 2 step: 1665, loss is 0.1276809126138687\n",
      "epoch: 2 step: 1666, loss is 0.005559357348829508\n",
      "epoch: 2 step: 1667, loss is 0.01617337390780449\n",
      "epoch: 2 step: 1668, loss is 0.01034762617200613\n",
      "epoch: 2 step: 1669, loss is 0.06494040787220001\n",
      "epoch: 2 step: 1670, loss is 0.008907376788556576\n",
      "epoch: 2 step: 1671, loss is 0.4139006435871124\n",
      "epoch: 2 step: 1672, loss is 0.013288027606904507\n",
      "epoch: 2 step: 1673, loss is 0.04351162910461426\n",
      "epoch: 2 step: 1674, loss is 0.0479898601770401\n",
      "epoch: 2 step: 1675, loss is 0.4056626558303833\n",
      "epoch: 2 step: 1676, loss is 0.1817423701286316\n",
      "epoch: 2 step: 1677, loss is 0.06627549976110458\n",
      "epoch: 2 step: 1678, loss is 0.03794587403535843\n",
      "epoch: 2 step: 1679, loss is 0.017190292477607727\n",
      "epoch: 2 step: 1680, loss is 0.08298756927251816\n",
      "epoch: 2 step: 1681, loss is 0.0031052236445248127\n",
      "epoch: 2 step: 1682, loss is 0.03471377119421959\n",
      "epoch: 2 step: 1683, loss is 0.06473443657159805\n",
      "epoch: 2 step: 1684, loss is 0.20055650174617767\n",
      "epoch: 2 step: 1685, loss is 0.010548286139965057\n",
      "epoch: 2 step: 1686, loss is 0.2266721874475479\n",
      "epoch: 2 step: 1687, loss is 0.09186571836471558\n",
      "epoch: 2 step: 1688, loss is 0.04932801052927971\n",
      "epoch: 2 step: 1689, loss is 0.03864360600709915\n",
      "epoch: 2 step: 1690, loss is 0.01432129368185997\n",
      "epoch: 2 step: 1691, loss is 0.03533754125237465\n",
      "epoch: 2 step: 1692, loss is 0.04982876032590866\n",
      "epoch: 2 step: 1693, loss is 0.010581286624073982\n",
      "epoch: 2 step: 1694, loss is 0.0038618529215455055\n",
      "epoch: 2 step: 1695, loss is 0.0017894633347168565\n",
      "epoch: 2 step: 1696, loss is 0.011227036826312542\n",
      "epoch: 2 step: 1697, loss is 0.020767852663993835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1698, loss is 0.06031203642487526\n",
      "epoch: 2 step: 1699, loss is 0.040457241237163544\n",
      "epoch: 2 step: 1700, loss is 0.007135003339499235\n",
      "epoch: 2 step: 1701, loss is 0.0022368254140019417\n",
      "epoch: 2 step: 1702, loss is 0.07282327860593796\n",
      "epoch: 2 step: 1703, loss is 0.07091215997934341\n",
      "epoch: 2 step: 1704, loss is 0.015543445013463497\n",
      "epoch: 2 step: 1705, loss is 0.003135586390271783\n",
      "epoch: 2 step: 1706, loss is 0.01440662145614624\n",
      "epoch: 2 step: 1707, loss is 0.03180164471268654\n",
      "epoch: 2 step: 1708, loss is 0.04605864733457565\n",
      "epoch: 2 step: 1709, loss is 0.00912439078092575\n",
      "epoch: 2 step: 1710, loss is 0.030199512839317322\n",
      "epoch: 2 step: 1711, loss is 0.351796418428421\n",
      "epoch: 2 step: 1712, loss is 0.006692103575915098\n",
      "epoch: 2 step: 1713, loss is 0.008288884535431862\n",
      "epoch: 2 step: 1714, loss is 0.00606945063918829\n",
      "epoch: 2 step: 1715, loss is 0.07916666567325592\n",
      "epoch: 2 step: 1716, loss is 0.04235280677676201\n",
      "epoch: 2 step: 1717, loss is 0.05016372725367546\n",
      "epoch: 2 step: 1718, loss is 0.05631150305271149\n",
      "epoch: 2 step: 1719, loss is 0.044835664331912994\n",
      "epoch: 2 step: 1720, loss is 0.009634057059884071\n",
      "epoch: 2 step: 1721, loss is 0.010496558621525764\n",
      "epoch: 2 step: 1722, loss is 0.0060831052251160145\n",
      "epoch: 2 step: 1723, loss is 0.022876963019371033\n",
      "epoch: 2 step: 1724, loss is 0.006285601295530796\n",
      "epoch: 2 step: 1725, loss is 0.24340061843395233\n",
      "epoch: 2 step: 1726, loss is 0.025847848504781723\n",
      "epoch: 2 step: 1727, loss is 0.0034310731571167707\n",
      "epoch: 2 step: 1728, loss is 0.14105135202407837\n",
      "epoch: 2 step: 1729, loss is 0.0018704370595514774\n",
      "epoch: 2 step: 1730, loss is 0.0032616916578263044\n",
      "epoch: 2 step: 1731, loss is 0.0364973321557045\n",
      "epoch: 2 step: 1732, loss is 0.013380222022533417\n",
      "epoch: 2 step: 1733, loss is 0.25523653626441956\n",
      "epoch: 2 step: 1734, loss is 0.09620041400194168\n",
      "epoch: 2 step: 1735, loss is 0.21997308731079102\n",
      "epoch: 2 step: 1736, loss is 0.07888469099998474\n",
      "epoch: 2 step: 1737, loss is 0.011792981997132301\n",
      "epoch: 2 step: 1738, loss is 0.006742640398442745\n",
      "epoch: 2 step: 1739, loss is 0.08847376704216003\n",
      "epoch: 2 step: 1740, loss is 0.007894203066825867\n",
      "epoch: 2 step: 1741, loss is 0.0014850093284621835\n",
      "epoch: 2 step: 1742, loss is 0.004426445811986923\n",
      "epoch: 2 step: 1743, loss is 0.04727373644709587\n",
      "epoch: 2 step: 1744, loss is 0.005044691264629364\n",
      "epoch: 2 step: 1745, loss is 0.007559766992926598\n",
      "epoch: 2 step: 1746, loss is 0.03662589564919472\n",
      "epoch: 2 step: 1747, loss is 0.09601402282714844\n",
      "epoch: 2 step: 1748, loss is 0.018826600164175034\n",
      "epoch: 2 step: 1749, loss is 0.0481560193002224\n",
      "epoch: 2 step: 1750, loss is 0.053957249969244\n",
      "epoch: 2 step: 1751, loss is 0.009305095300078392\n",
      "epoch: 2 step: 1752, loss is 0.04344141483306885\n",
      "epoch: 2 step: 1753, loss is 0.0433785542845726\n",
      "epoch: 2 step: 1754, loss is 0.009934390895068645\n",
      "epoch: 2 step: 1755, loss is 0.08884752541780472\n",
      "epoch: 2 step: 1756, loss is 0.13037492334842682\n",
      "epoch: 2 step: 1757, loss is 0.10973861813545227\n",
      "epoch: 2 step: 1758, loss is 0.4684542119503021\n",
      "epoch: 2 step: 1759, loss is 0.013115975074470043\n",
      "epoch: 2 step: 1760, loss is 0.0023911285679787397\n",
      "epoch: 2 step: 1761, loss is 0.14615429937839508\n",
      "epoch: 2 step: 1762, loss is 0.003979117143899202\n",
      "epoch: 2 step: 1763, loss is 0.0014573292573913932\n",
      "epoch: 2 step: 1764, loss is 0.002068860922008753\n",
      "epoch: 2 step: 1765, loss is 0.009021708741784096\n",
      "epoch: 2 step: 1766, loss is 0.013836458325386047\n",
      "epoch: 2 step: 1767, loss is 0.0047342595644295216\n",
      "epoch: 2 step: 1768, loss is 0.033682189881801605\n",
      "epoch: 2 step: 1769, loss is 0.1784975528717041\n",
      "epoch: 2 step: 1770, loss is 0.002356552518904209\n",
      "epoch: 2 step: 1771, loss is 0.009507432579994202\n",
      "epoch: 2 step: 1772, loss is 0.011163647286593914\n",
      "epoch: 2 step: 1773, loss is 0.11138664186000824\n",
      "epoch: 2 step: 1774, loss is 0.035939790308475494\n",
      "epoch: 2 step: 1775, loss is 0.010718307457864285\n",
      "epoch: 2 step: 1776, loss is 0.1115589290857315\n",
      "epoch: 2 step: 1777, loss is 0.019271260127425194\n",
      "epoch: 2 step: 1778, loss is 0.02081511728465557\n",
      "epoch: 2 step: 1779, loss is 0.02214646339416504\n",
      "epoch: 2 step: 1780, loss is 0.002671747002750635\n",
      "epoch: 2 step: 1781, loss is 0.06219854950904846\n",
      "epoch: 2 step: 1782, loss is 0.09661731123924255\n",
      "epoch: 2 step: 1783, loss is 0.1577356904745102\n",
      "epoch: 2 step: 1784, loss is 0.0085802236571908\n",
      "epoch: 2 step: 1785, loss is 0.042927030473947525\n",
      "epoch: 2 step: 1786, loss is 0.006528587080538273\n",
      "epoch: 2 step: 1787, loss is 0.03161821514368057\n",
      "epoch: 2 step: 1788, loss is 0.06588295102119446\n",
      "epoch: 2 step: 1789, loss is 0.010725370608270168\n",
      "epoch: 2 step: 1790, loss is 0.003695014165714383\n",
      "epoch: 2 step: 1791, loss is 0.0030301047954708338\n",
      "epoch: 2 step: 1792, loss is 0.2295115739107132\n",
      "epoch: 2 step: 1793, loss is 0.11455544084310532\n",
      "epoch: 2 step: 1794, loss is 0.007117665372788906\n",
      "epoch: 2 step: 1795, loss is 0.09940323233604431\n",
      "epoch: 2 step: 1796, loss is 0.0013379722367972136\n",
      "epoch: 2 step: 1797, loss is 0.03943110257387161\n",
      "epoch: 2 step: 1798, loss is 0.0008326969109475613\n",
      "epoch: 2 step: 1799, loss is 0.01398976519703865\n",
      "epoch: 2 step: 1800, loss is 0.002596375998109579\n",
      "epoch: 2 step: 1801, loss is 0.028445815667510033\n",
      "epoch: 2 step: 1802, loss is 0.13493399322032928\n",
      "epoch: 2 step: 1803, loss is 0.03900725021958351\n",
      "epoch: 2 step: 1804, loss is 0.04690515249967575\n",
      "epoch: 2 step: 1805, loss is 0.012852057814598083\n",
      "epoch: 2 step: 1806, loss is 0.09166139364242554\n",
      "epoch: 2 step: 1807, loss is 0.01610252633690834\n",
      "epoch: 2 step: 1808, loss is 0.043665312230587006\n",
      "epoch: 2 step: 1809, loss is 0.1027330532670021\n",
      "epoch: 2 step: 1810, loss is 0.001960328547284007\n",
      "epoch: 2 step: 1811, loss is 0.17570896446704865\n",
      "epoch: 2 step: 1812, loss is 0.019359230995178223\n",
      "epoch: 2 step: 1813, loss is 0.019010836258530617\n",
      "epoch: 2 step: 1814, loss is 0.00457614753395319\n",
      "epoch: 2 step: 1815, loss is 0.004614835139364004\n",
      "epoch: 2 step: 1816, loss is 0.029959358274936676\n",
      "epoch: 2 step: 1817, loss is 0.22742901742458344\n",
      "epoch: 2 step: 1818, loss is 0.012041863054037094\n",
      "epoch: 2 step: 1819, loss is 0.0007747578783892095\n",
      "epoch: 2 step: 1820, loss is 0.03950042650103569\n",
      "epoch: 2 step: 1821, loss is 0.001151415635831654\n",
      "epoch: 2 step: 1822, loss is 0.280575156211853\n",
      "epoch: 2 step: 1823, loss is 0.0032995035871863365\n",
      "epoch: 2 step: 1824, loss is 0.007258489262312651\n",
      "epoch: 2 step: 1825, loss is 0.24774979054927826\n",
      "epoch: 2 step: 1826, loss is 0.09590622782707214\n",
      "epoch: 2 step: 1827, loss is 0.0049011316150426865\n",
      "epoch: 2 step: 1828, loss is 0.03719177097082138\n",
      "epoch: 2 step: 1829, loss is 0.006947288755327463\n",
      "epoch: 2 step: 1830, loss is 0.06464137881994247\n",
      "epoch: 2 step: 1831, loss is 0.010527468286454678\n",
      "epoch: 2 step: 1832, loss is 0.010068496689200401\n",
      "epoch: 2 step: 1833, loss is 0.1616741120815277\n",
      "epoch: 2 step: 1834, loss is 0.041794948279857635\n",
      "epoch: 2 step: 1835, loss is 0.010321564972400665\n",
      "epoch: 2 step: 1836, loss is 0.18252409994602203\n",
      "epoch: 2 step: 1837, loss is 0.02559923194348812\n",
      "epoch: 2 step: 1838, loss is 0.1546032428741455\n",
      "epoch: 2 step: 1839, loss is 0.07388578355312347\n",
      "epoch: 2 step: 1840, loss is 0.013137995265424252\n",
      "epoch: 2 step: 1841, loss is 0.005817231256514788\n",
      "epoch: 2 step: 1842, loss is 0.08775848895311356\n",
      "epoch: 2 step: 1843, loss is 0.02577829733490944\n",
      "epoch: 2 step: 1844, loss is 0.00231226091273129\n",
      "epoch: 2 step: 1845, loss is 0.0568733885884285\n",
      "epoch: 2 step: 1846, loss is 0.0072397505864501\n",
      "epoch: 2 step: 1847, loss is 0.0019591536838561296\n",
      "epoch: 2 step: 1848, loss is 0.033985063433647156\n",
      "epoch: 2 step: 1849, loss is 0.010761636309325695\n",
      "epoch: 2 step: 1850, loss is 0.034415267407894135\n",
      "epoch: 2 step: 1851, loss is 0.010096589103341103\n",
      "epoch: 2 step: 1852, loss is 0.16673117876052856\n",
      "epoch: 2 step: 1853, loss is 0.004689943045377731\n",
      "epoch: 2 step: 1854, loss is 0.04264536499977112\n",
      "epoch: 2 step: 1855, loss is 0.004364980850368738\n",
      "epoch: 2 step: 1856, loss is 0.013147513382136822\n",
      "epoch: 2 step: 1857, loss is 0.14017364382743835\n",
      "epoch: 2 step: 1858, loss is 0.0403066910803318\n",
      "epoch: 2 step: 1859, loss is 0.002529782010242343\n",
      "epoch: 2 step: 1860, loss is 0.04297354072332382\n",
      "epoch: 2 step: 1861, loss is 0.045144688338041306\n",
      "epoch: 2 step: 1862, loss is 0.008232091553509235\n",
      "epoch: 2 step: 1863, loss is 0.022229153662919998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1864, loss is 0.22841283679008484\n",
      "epoch: 2 step: 1865, loss is 0.023997193202376366\n",
      "epoch: 2 step: 1866, loss is 0.020300090312957764\n",
      "epoch: 2 step: 1867, loss is 0.06114561855792999\n",
      "epoch: 2 step: 1868, loss is 0.14434638619422913\n",
      "epoch: 2 step: 1869, loss is 0.024418331682682037\n",
      "epoch: 2 step: 1870, loss is 0.007561173755675554\n",
      "epoch: 2 step: 1871, loss is 0.16388975083827972\n",
      "epoch: 2 step: 1872, loss is 0.008337916806340218\n",
      "epoch: 2 step: 1873, loss is 0.002086945343762636\n",
      "epoch: 2 step: 1874, loss is 0.0707833543419838\n",
      "epoch: 2 step: 1875, loss is 0.0031394914258271456\n",
      "epoch: 2 step: 1876, loss is 0.005163346882909536\n",
      "epoch: 2 step: 1877, loss is 0.33359476923942566\n",
      "epoch: 2 step: 1878, loss is 0.02350710891187191\n",
      "epoch: 2 step: 1879, loss is 0.0022171323653310537\n",
      "epoch: 2 step: 1880, loss is 0.006392354611307383\n",
      "epoch: 2 step: 1881, loss is 0.10784091055393219\n",
      "epoch: 2 step: 1882, loss is 0.06510050594806671\n",
      "epoch: 2 step: 1883, loss is 0.043552789837121964\n",
      "epoch: 2 step: 1884, loss is 0.10938746482133865\n",
      "epoch: 2 step: 1885, loss is 0.0331714041531086\n",
      "epoch: 2 step: 1886, loss is 0.009448802098631859\n",
      "epoch: 2 step: 1887, loss is 0.000911542447283864\n",
      "epoch: 2 step: 1888, loss is 0.0038407945539802313\n",
      "epoch: 2 step: 1889, loss is 0.12347779422998428\n",
      "epoch: 2 step: 1890, loss is 0.0070044007152318954\n",
      "epoch: 2 step: 1891, loss is 0.06838288903236389\n",
      "epoch: 2 step: 1892, loss is 0.1033153161406517\n",
      "epoch: 2 step: 1893, loss is 0.10995135456323624\n",
      "epoch: 2 step: 1894, loss is 0.14014820754528046\n",
      "epoch: 2 step: 1895, loss is 0.05933510884642601\n",
      "epoch: 2 step: 1896, loss is 0.013245798647403717\n",
      "epoch: 2 step: 1897, loss is 0.009037433192133904\n",
      "epoch: 2 step: 1898, loss is 0.03925323113799095\n",
      "epoch: 2 step: 1899, loss is 0.009276296943426132\n",
      "epoch: 2 step: 1900, loss is 0.0313228964805603\n",
      "epoch: 2 step: 1901, loss is 0.0018168920651078224\n",
      "epoch: 2 step: 1902, loss is 0.04056559130549431\n",
      "epoch: 2 step: 1903, loss is 0.1596721112728119\n",
      "epoch: 2 step: 1904, loss is 0.018731096759438515\n",
      "epoch: 2 step: 1905, loss is 0.06204082444310188\n",
      "epoch: 2 step: 1906, loss is 0.162770077586174\n",
      "epoch: 2 step: 1907, loss is 0.0017683554906398058\n",
      "epoch: 2 step: 1908, loss is 0.05600317195057869\n",
      "epoch: 2 step: 1909, loss is 0.14437761902809143\n",
      "epoch: 2 step: 1910, loss is 0.0018459653947502375\n",
      "epoch: 2 step: 1911, loss is 0.0105811832472682\n",
      "epoch: 2 step: 1912, loss is 0.002403841819614172\n",
      "epoch: 2 step: 1913, loss is 0.08388075232505798\n",
      "epoch: 2 step: 1914, loss is 0.006986376363784075\n",
      "epoch: 2 step: 1915, loss is 0.35336509346961975\n",
      "epoch: 2 step: 1916, loss is 0.11967604607343674\n",
      "epoch: 2 step: 1917, loss is 0.026026150211691856\n",
      "epoch: 2 step: 1918, loss is 0.005358393769711256\n",
      "epoch: 2 step: 1919, loss is 0.001554533839225769\n",
      "epoch: 2 step: 1920, loss is 0.026654334738850594\n",
      "epoch: 2 step: 1921, loss is 0.029635794460773468\n",
      "epoch: 2 step: 1922, loss is 0.002475943649187684\n",
      "epoch: 2 step: 1923, loss is 0.051792360842227936\n",
      "epoch: 2 step: 1924, loss is 0.14985916018486023\n",
      "epoch: 2 step: 1925, loss is 0.015854356810450554\n",
      "epoch: 2 step: 1926, loss is 0.000921623024623841\n",
      "epoch: 2 step: 1927, loss is 0.019273219630122185\n",
      "epoch: 2 step: 1928, loss is 0.04801049828529358\n",
      "epoch: 2 step: 1929, loss is 0.08727402985095978\n",
      "epoch: 2 step: 1930, loss is 0.03160355985164642\n",
      "epoch: 2 step: 1931, loss is 0.0985296443104744\n",
      "epoch: 2 step: 1932, loss is 0.016416266560554504\n",
      "epoch: 2 step: 1933, loss is 0.002017961349338293\n",
      "epoch: 2 step: 1934, loss is 0.01115759089589119\n",
      "epoch: 2 step: 1935, loss is 0.012064449489116669\n",
      "epoch: 2 step: 1936, loss is 0.014555683359503746\n",
      "epoch: 2 step: 1937, loss is 0.004006111063063145\n",
      "epoch: 2 step: 1938, loss is 0.11115463078022003\n",
      "epoch: 2 step: 1939, loss is 0.05794801563024521\n",
      "epoch: 2 step: 1940, loss is 0.032984960824251175\n",
      "epoch: 2 step: 1941, loss is 0.034943174570798874\n",
      "epoch: 2 step: 1942, loss is 0.004006546922028065\n",
      "epoch: 2 step: 1943, loss is 0.004902939312160015\n",
      "epoch: 2 step: 1944, loss is 0.01023639552295208\n",
      "epoch: 2 step: 1945, loss is 0.010948298498988152\n",
      "epoch: 2 step: 1946, loss is 0.022458158433437347\n",
      "epoch: 2 step: 1947, loss is 0.0035351549740880728\n",
      "epoch: 2 step: 1948, loss is 0.06354986876249313\n",
      "epoch: 2 step: 1949, loss is 0.034343548119068146\n",
      "epoch: 2 step: 1950, loss is 0.04888821020722389\n",
      "epoch: 2 step: 1951, loss is 0.006478695664554834\n",
      "epoch: 2 step: 1952, loss is 0.10328175872564316\n",
      "epoch: 2 step: 1953, loss is 0.12946482002735138\n",
      "epoch: 2 step: 1954, loss is 0.010068563744425774\n",
      "epoch: 2 step: 1955, loss is 0.000911685056053102\n",
      "epoch: 2 step: 1956, loss is 0.17489884793758392\n",
      "epoch: 2 step: 1957, loss is 0.05098253861069679\n",
      "epoch: 2 step: 1958, loss is 0.009690314531326294\n",
      "epoch: 2 step: 1959, loss is 0.02513803355395794\n",
      "epoch: 2 step: 1960, loss is 0.06001497805118561\n",
      "epoch: 2 step: 1961, loss is 0.0011172402882948518\n",
      "epoch: 2 step: 1962, loss is 0.039343398064374924\n",
      "epoch: 2 step: 1963, loss is 0.01335146464407444\n",
      "epoch: 2 step: 1964, loss is 0.008754129521548748\n",
      "epoch: 2 step: 1965, loss is 0.01626596227288246\n",
      "epoch: 2 step: 1966, loss is 0.11686748266220093\n",
      "epoch: 2 step: 1967, loss is 0.06272019445896149\n",
      "epoch: 2 step: 1968, loss is 0.018645407631993294\n",
      "epoch: 2 step: 1969, loss is 0.3396502435207367\n",
      "epoch: 2 step: 1970, loss is 0.00698118144646287\n",
      "epoch: 2 step: 1971, loss is 0.13417573273181915\n",
      "epoch: 2 step: 1972, loss is 0.005817857105284929\n",
      "epoch: 2 step: 1973, loss is 0.017723089084029198\n",
      "epoch: 2 step: 1974, loss is 0.0029297361616045237\n",
      "epoch: 2 step: 1975, loss is 0.266622930765152\n",
      "epoch: 2 step: 1976, loss is 0.027487486600875854\n",
      "epoch: 2 step: 1977, loss is 0.056482113897800446\n",
      "epoch: 2 step: 1978, loss is 0.08446531742811203\n",
      "epoch: 2 step: 1979, loss is 0.0009762699482962489\n",
      "epoch: 2 step: 1980, loss is 0.003408314660191536\n",
      "epoch: 2 step: 1981, loss is 0.08854450285434723\n",
      "epoch: 2 step: 1982, loss is 0.021036989986896515\n",
      "epoch: 2 step: 1983, loss is 0.04091327637434006\n",
      "epoch: 2 step: 1984, loss is 0.025974737480282784\n",
      "epoch: 2 step: 1985, loss is 0.02747192792594433\n",
      "epoch: 2 step: 1986, loss is 0.0022984081879258156\n",
      "epoch: 2 step: 1987, loss is 0.24742519855499268\n",
      "epoch: 2 step: 1988, loss is 0.012394225224852562\n",
      "epoch: 2 step: 1989, loss is 0.004259072709828615\n",
      "epoch: 2 step: 1990, loss is 0.0069657075218856335\n",
      "epoch: 2 step: 1991, loss is 0.002662419341504574\n",
      "epoch: 2 step: 1992, loss is 0.02797248773276806\n",
      "epoch: 2 step: 1993, loss is 0.028631605207920074\n",
      "epoch: 2 step: 1994, loss is 0.0018064695177599788\n",
      "epoch: 2 step: 1995, loss is 0.0014930996112525463\n",
      "epoch: 2 step: 1996, loss is 0.13032123446464539\n",
      "epoch: 2 step: 1997, loss is 0.01908198744058609\n",
      "epoch: 2 step: 1998, loss is 0.10643768310546875\n",
      "epoch: 2 step: 1999, loss is 0.06033167243003845\n",
      "epoch: 2 step: 2000, loss is 0.047149233520030975\n",
      "epoch: 2 step: 2001, loss is 0.03420966863632202\n",
      "epoch: 2 step: 2002, loss is 0.031236916780471802\n",
      "epoch: 2 step: 2003, loss is 0.09397970885038376\n",
      "epoch: 2 step: 2004, loss is 0.0012007964542135596\n",
      "epoch: 2 step: 2005, loss is 0.03211919218301773\n",
      "epoch: 2 step: 2006, loss is 0.0006303182453848422\n",
      "epoch: 2 step: 2007, loss is 0.0018028449267148972\n",
      "epoch: 2 step: 2008, loss is 0.005030232015997171\n",
      "epoch: 2 step: 2009, loss is 0.035935867577791214\n",
      "epoch: 2 step: 2010, loss is 0.015028008259832859\n",
      "epoch: 2 step: 2011, loss is 0.0007544800755567849\n",
      "epoch: 2 step: 2012, loss is 0.003563881618902087\n",
      "epoch: 2 step: 2013, loss is 0.007199139799922705\n",
      "epoch: 2 step: 2014, loss is 0.10940391570329666\n",
      "epoch: 2 step: 2015, loss is 0.0013865395449101925\n",
      "epoch: 2 step: 2016, loss is 0.037264786660671234\n",
      "epoch: 2 step: 2017, loss is 0.00802494678646326\n",
      "epoch: 2 step: 2018, loss is 0.019525863230228424\n",
      "epoch: 2 step: 2019, loss is 0.054762743413448334\n",
      "epoch: 2 step: 2020, loss is 0.04030954837799072\n",
      "epoch: 2 step: 2021, loss is 0.01345459371805191\n",
      "epoch: 2 step: 2022, loss is 0.04143619164824486\n",
      "epoch: 2 step: 2023, loss is 0.13562512397766113\n",
      "epoch: 2 step: 2024, loss is 0.04179975017905235\n",
      "epoch: 2 step: 2025, loss is 0.1531745195388794\n",
      "epoch: 2 step: 2026, loss is 0.024403385818004608\n",
      "epoch: 2 step: 2027, loss is 0.0015550850657746196\n",
      "epoch: 2 step: 2028, loss is 0.04093115031719208\n",
      "epoch: 2 step: 2029, loss is 0.0014482747064903378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 2030, loss is 0.16717170178890228\n",
      "epoch: 2 step: 2031, loss is 0.009658467024564743\n",
      "epoch: 2 step: 2032, loss is 0.16811732947826385\n",
      "epoch: 2 step: 2033, loss is 0.13811838626861572\n",
      "epoch: 2 step: 2034, loss is 0.046284954994916916\n",
      "epoch: 2 step: 2035, loss is 0.035705000162124634\n",
      "epoch: 2 step: 2036, loss is 0.002605505520477891\n",
      "epoch: 2 step: 2037, loss is 0.11455710977315903\n",
      "epoch: 2 step: 2038, loss is 0.035951100289821625\n",
      "epoch: 2 step: 2039, loss is 0.03580784425139427\n",
      "epoch: 2 step: 2040, loss is 0.00155375967733562\n",
      "epoch: 2 step: 2041, loss is 0.03172410652041435\n",
      "epoch: 2 step: 2042, loss is 0.004558110143989325\n",
      "epoch: 2 step: 2043, loss is 0.003071374027058482\n",
      "epoch: 2 step: 2044, loss is 0.018928201869130135\n",
      "epoch: 2 step: 2045, loss is 0.07073605060577393\n",
      "epoch: 2 step: 2046, loss is 0.0018407140159979463\n",
      "epoch: 2 step: 2047, loss is 0.011584983207285404\n",
      "epoch: 2 step: 2048, loss is 0.057462405413389206\n",
      "epoch: 2 step: 2049, loss is 0.06080617383122444\n",
      "epoch: 2 step: 2050, loss is 0.24131742119789124\n",
      "epoch: 2 step: 2051, loss is 0.005634813569486141\n",
      "epoch: 2 step: 2052, loss is 0.0007871085545048118\n",
      "epoch: 2 step: 2053, loss is 0.005395360756665468\n",
      "epoch: 2 step: 2054, loss is 0.0015119275776669383\n",
      "epoch: 2 step: 2055, loss is 0.01945735141634941\n",
      "epoch: 2 step: 2056, loss is 0.018928438425064087\n",
      "epoch: 2 step: 2057, loss is 0.00687910383567214\n",
      "epoch: 2 step: 2058, loss is 0.26276540756225586\n",
      "epoch: 2 step: 2059, loss is 0.03528723493218422\n",
      "epoch: 2 step: 2060, loss is 0.09133776277303696\n",
      "epoch: 2 step: 2061, loss is 0.0008820916409604251\n",
      "epoch: 2 step: 2062, loss is 0.015749948099255562\n",
      "epoch: 2 step: 2063, loss is 0.07879869639873505\n",
      "epoch: 2 step: 2064, loss is 0.31408268213272095\n",
      "epoch: 2 step: 2065, loss is 0.12325811386108398\n",
      "epoch: 2 step: 2066, loss is 0.21401454508304596\n",
      "epoch: 2 step: 2067, loss is 0.08213207870721817\n",
      "epoch: 2 step: 2068, loss is 0.09937979280948639\n",
      "epoch: 2 step: 2069, loss is 0.021059444174170494\n",
      "epoch: 2 step: 2070, loss is 0.02024776302278042\n",
      "epoch: 2 step: 2071, loss is 0.09160813689231873\n",
      "epoch: 2 step: 2072, loss is 0.053687918931245804\n",
      "epoch: 2 step: 2073, loss is 0.06337007880210876\n",
      "epoch: 2 step: 2074, loss is 0.008367880247533321\n",
      "epoch: 2 step: 2075, loss is 0.01890261471271515\n",
      "epoch: 2 step: 2076, loss is 0.11977603286504745\n",
      "epoch: 2 step: 2077, loss is 0.010205467231571674\n",
      "epoch: 2 step: 2078, loss is 0.38523590564727783\n",
      "epoch: 2 step: 2079, loss is 0.009323390200734138\n",
      "epoch: 2 step: 2080, loss is 0.14666473865509033\n",
      "epoch: 2 step: 2081, loss is 0.02903592772781849\n",
      "epoch: 2 step: 2082, loss is 0.000527195748873055\n",
      "epoch: 2 step: 2083, loss is 0.054572731256484985\n",
      "epoch: 2 step: 2084, loss is 0.005403195042163134\n",
      "epoch: 2 step: 2085, loss is 0.039977457374334335\n",
      "epoch: 2 step: 2086, loss is 0.0023454176262021065\n",
      "epoch: 2 step: 2087, loss is 0.01345243863761425\n",
      "epoch: 2 step: 2088, loss is 0.028624361380934715\n",
      "epoch: 2 step: 2089, loss is 0.02448013424873352\n",
      "epoch: 2 step: 2090, loss is 0.007385689299553633\n",
      "epoch: 2 step: 2091, loss is 0.02976805344223976\n",
      "epoch: 2 step: 2092, loss is 0.06870143115520477\n",
      "epoch: 2 step: 2093, loss is 0.0025175667833536863\n",
      "epoch: 2 step: 2094, loss is 0.020406045019626617\n",
      "epoch: 2 step: 2095, loss is 0.1565554440021515\n",
      "epoch: 2 step: 2096, loss is 0.05048908293247223\n",
      "epoch: 2 step: 2097, loss is 0.04078182205557823\n",
      "epoch: 2 step: 2098, loss is 0.019663967192173004\n",
      "epoch: 2 step: 2099, loss is 0.13211604952812195\n",
      "epoch: 2 step: 2100, loss is 0.0026224451139569283\n",
      "epoch: 2 step: 2101, loss is 0.008793221786618233\n",
      "epoch: 2 step: 2102, loss is 0.007890045642852783\n",
      "epoch: 2 step: 2103, loss is 0.010059296153485775\n",
      "epoch: 2 step: 2104, loss is 0.026070507243275642\n",
      "epoch: 2 step: 2105, loss is 0.08385702967643738\n",
      "epoch: 2 step: 2106, loss is 0.0011759749613702297\n",
      "epoch: 2 step: 2107, loss is 0.000680375553201884\n",
      "epoch: 2 step: 2108, loss is 0.060528017580509186\n",
      "epoch: 2 step: 2109, loss is 0.006804370786994696\n",
      "epoch: 2 step: 2110, loss is 0.0030758902430534363\n",
      "epoch: 2 step: 2111, loss is 0.05988799408078194\n",
      "epoch: 2 step: 2112, loss is 0.005992659833282232\n",
      "epoch: 2 step: 2113, loss is 0.09614934772253036\n",
      "epoch: 2 step: 2114, loss is 0.00027515162946656346\n",
      "epoch: 2 step: 2115, loss is 0.04454446956515312\n",
      "epoch: 2 step: 2116, loss is 0.003276383737102151\n",
      "epoch: 2 step: 2117, loss is 0.05394323915243149\n",
      "epoch: 2 step: 2118, loss is 0.30316129326820374\n",
      "epoch: 2 step: 2119, loss is 0.0003308697778265923\n",
      "epoch: 2 step: 2120, loss is 0.005153050180524588\n",
      "epoch: 2 step: 2121, loss is 0.00087910977890715\n",
      "epoch: 2 step: 2122, loss is 0.05668242648243904\n",
      "epoch: 2 step: 2123, loss is 0.1517690122127533\n",
      "epoch: 2 step: 2124, loss is 0.013845622539520264\n",
      "epoch: 2 step: 2125, loss is 0.008192644454538822\n",
      "epoch: 2 step: 2126, loss is 0.0722920373082161\n",
      "epoch: 2 step: 2127, loss is 0.01984012871980667\n",
      "epoch: 2 step: 2128, loss is 0.025152523070573807\n",
      "epoch: 2 step: 2129, loss is 0.01194598525762558\n",
      "epoch: 2 step: 2130, loss is 0.07316967844963074\n",
      "epoch: 2 step: 2131, loss is 0.003974702209234238\n",
      "epoch: 2 step: 2132, loss is 0.03743863105773926\n",
      "epoch: 2 step: 2133, loss is 0.009096398018300533\n",
      "epoch: 2 step: 2134, loss is 0.09842204302549362\n",
      "epoch: 2 step: 2135, loss is 0.07747168093919754\n",
      "epoch: 2 step: 2136, loss is 0.05755540728569031\n",
      "epoch: 2 step: 2137, loss is 0.007693507242947817\n",
      "epoch: 2 step: 2138, loss is 0.007858257740736008\n",
      "epoch: 2 step: 2139, loss is 0.037084631621837616\n",
      "epoch: 2 step: 2140, loss is 0.21912676095962524\n",
      "epoch: 2 step: 2141, loss is 0.013041038066148758\n",
      "epoch: 2 step: 2142, loss is 0.003087658202275634\n",
      "epoch: 2 step: 2143, loss is 0.02229253761470318\n",
      "epoch: 2 step: 2144, loss is 0.018417445942759514\n",
      "epoch: 2 step: 2145, loss is 0.0021751204039901495\n",
      "epoch: 2 step: 2146, loss is 0.0014544727746397257\n",
      "epoch: 2 step: 2147, loss is 0.07955283671617508\n",
      "epoch: 2 step: 2148, loss is 0.031609807163476944\n",
      "epoch: 2 step: 2149, loss is 0.022194229066371918\n",
      "epoch: 2 step: 2150, loss is 0.013983783312141895\n",
      "epoch: 2 step: 2151, loss is 0.08165507763624191\n",
      "epoch: 2 step: 2152, loss is 0.015363236889243126\n",
      "epoch: 2 step: 2153, loss is 0.008232143707573414\n",
      "epoch: 2 step: 2154, loss is 0.08772692084312439\n",
      "epoch: 2 step: 2155, loss is 0.060745514929294586\n",
      "epoch: 2 step: 2156, loss is 0.4372217357158661\n",
      "epoch: 2 step: 2157, loss is 0.0030907082837074995\n",
      "epoch: 2 step: 2158, loss is 0.01110470574349165\n",
      "epoch: 2 step: 2159, loss is 0.010035962797701359\n",
      "epoch: 2 step: 2160, loss is 0.00164378946647048\n",
      "epoch: 2 step: 2161, loss is 0.013316560536623001\n",
      "epoch: 2 step: 2162, loss is 0.001232351758517325\n",
      "epoch: 2 step: 2163, loss is 0.004897169768810272\n",
      "epoch: 2 step: 2164, loss is 0.10439864546060562\n",
      "epoch: 2 step: 2165, loss is 0.10303258150815964\n",
      "epoch: 2 step: 2166, loss is 0.04813895374536514\n",
      "epoch: 2 step: 2167, loss is 0.01149715855717659\n",
      "epoch: 2 step: 2168, loss is 0.03035261668264866\n",
      "epoch: 2 step: 2169, loss is 0.052643682807683945\n",
      "epoch: 2 step: 2170, loss is 0.03066396899521351\n",
      "epoch: 2 step: 2171, loss is 0.04486280679702759\n",
      "epoch: 2 step: 2172, loss is 0.1257534772157669\n",
      "epoch: 2 step: 2173, loss is 0.021271497011184692\n",
      "epoch: 2 step: 2174, loss is 0.04996807873249054\n",
      "epoch: 2 step: 2175, loss is 0.06655565649271011\n",
      "epoch: 2 step: 2176, loss is 0.013675584457814693\n",
      "epoch: 2 step: 2177, loss is 0.010564790107309818\n",
      "epoch: 2 step: 2178, loss is 0.0006347226444631815\n",
      "epoch: 2 step: 2179, loss is 0.11859431862831116\n",
      "epoch: 2 step: 2180, loss is 0.00047752217506058514\n",
      "epoch: 2 step: 2181, loss is 0.175446555018425\n",
      "epoch: 2 step: 2182, loss is 0.011422064155340195\n",
      "epoch: 2 step: 2183, loss is 0.031045276671648026\n",
      "epoch: 2 step: 2184, loss is 0.024867190048098564\n",
      "epoch: 2 step: 2185, loss is 0.002287356648594141\n",
      "epoch: 2 step: 2186, loss is 0.005435108672827482\n",
      "epoch: 2 step: 2187, loss is 0.0011117998510599136\n",
      "epoch: 3 step: 1, loss is 0.01718207821249962\n",
      "epoch: 3 step: 2, loss is 0.005290588364005089\n",
      "epoch: 3 step: 3, loss is 0.001205579494126141\n",
      "epoch: 3 step: 4, loss is 0.02252517268061638\n",
      "epoch: 3 step: 5, loss is 0.0058265794068574905\n",
      "epoch: 3 step: 6, loss is 0.006292229518294334\n",
      "epoch: 3 step: 7, loss is 0.2172345668077469\n",
      "epoch: 3 step: 8, loss is 0.001265553291887045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 9, loss is 0.004165573976933956\n",
      "epoch: 3 step: 10, loss is 0.03421208634972572\n",
      "epoch: 3 step: 11, loss is 0.010686258785426617\n",
      "epoch: 3 step: 12, loss is 0.021172169595956802\n",
      "epoch: 3 step: 13, loss is 0.0016572444001212716\n",
      "epoch: 3 step: 14, loss is 0.013642393983900547\n",
      "epoch: 3 step: 15, loss is 0.19992807507514954\n",
      "epoch: 3 step: 16, loss is 0.0017331538256257772\n",
      "epoch: 3 step: 17, loss is 0.14200282096862793\n",
      "epoch: 3 step: 18, loss is 0.006344019901007414\n",
      "epoch: 3 step: 19, loss is 0.035597484558820724\n",
      "epoch: 3 step: 20, loss is 0.0456603579223156\n",
      "epoch: 3 step: 21, loss is 0.004020743537694216\n",
      "epoch: 3 step: 22, loss is 0.0006489938823506236\n",
      "epoch: 3 step: 23, loss is 0.001129279495216906\n",
      "epoch: 3 step: 24, loss is 0.002068739850074053\n",
      "epoch: 3 step: 25, loss is 0.0037686419673264027\n",
      "epoch: 3 step: 26, loss is 0.10870642215013504\n",
      "epoch: 3 step: 27, loss is 0.0013865054352208972\n",
      "epoch: 3 step: 28, loss is 0.0005968367913737893\n",
      "epoch: 3 step: 29, loss is 0.009957186877727509\n",
      "epoch: 3 step: 30, loss is 0.052282460033893585\n",
      "epoch: 3 step: 31, loss is 0.021266143769025803\n",
      "epoch: 3 step: 32, loss is 0.002208308782428503\n",
      "epoch: 3 step: 33, loss is 0.002305026166141033\n",
      "epoch: 3 step: 34, loss is 0.004470487125217915\n",
      "epoch: 3 step: 35, loss is 0.04098457098007202\n",
      "epoch: 3 step: 36, loss is 0.00025994019233621657\n",
      "epoch: 3 step: 37, loss is 0.031920500099658966\n",
      "epoch: 3 step: 38, loss is 0.10731387138366699\n",
      "epoch: 3 step: 39, loss is 0.0026419763453304768\n",
      "epoch: 3 step: 40, loss is 0.009243697859346867\n",
      "epoch: 3 step: 41, loss is 0.3534936308860779\n",
      "epoch: 3 step: 42, loss is 0.0014385662507265806\n",
      "epoch: 3 step: 43, loss is 0.08062689006328583\n",
      "epoch: 3 step: 44, loss is 0.0011431098682805896\n",
      "epoch: 3 step: 45, loss is 0.11211147159337997\n",
      "epoch: 3 step: 46, loss is 0.03480887413024902\n",
      "epoch: 3 step: 47, loss is 0.0027367526199668646\n",
      "epoch: 3 step: 48, loss is 0.001347248675301671\n",
      "epoch: 3 step: 49, loss is 0.1807233989238739\n",
      "epoch: 3 step: 50, loss is 0.004981338512152433\n",
      "epoch: 3 step: 51, loss is 0.05386746674776077\n",
      "epoch: 3 step: 52, loss is 0.005760290659964085\n",
      "epoch: 3 step: 53, loss is 0.006487214472144842\n",
      "epoch: 3 step: 54, loss is 0.006484511308372021\n",
      "epoch: 3 step: 55, loss is 0.001069233170710504\n",
      "epoch: 3 step: 56, loss is 0.006463783327490091\n",
      "epoch: 3 step: 57, loss is 0.04284384846687317\n",
      "epoch: 3 step: 58, loss is 0.05832444131374359\n",
      "epoch: 3 step: 59, loss is 0.00963891763240099\n",
      "epoch: 3 step: 60, loss is 0.011202828958630562\n",
      "epoch: 3 step: 61, loss is 0.0639566034078598\n",
      "epoch: 3 step: 62, loss is 0.004502539522945881\n",
      "epoch: 3 step: 63, loss is 0.0259422454982996\n",
      "epoch: 3 step: 64, loss is 0.02151815965771675\n",
      "epoch: 3 step: 65, loss is 0.02927139773964882\n",
      "epoch: 3 step: 66, loss is 0.005925219040364027\n",
      "epoch: 3 step: 67, loss is 0.0026980547700077295\n",
      "epoch: 3 step: 68, loss is 0.005961436778306961\n",
      "epoch: 3 step: 69, loss is 0.04811200127005577\n",
      "epoch: 3 step: 70, loss is 0.0017333707073703408\n",
      "epoch: 3 step: 71, loss is 0.010032882913947105\n",
      "epoch: 3 step: 72, loss is 0.1575026959180832\n",
      "epoch: 3 step: 73, loss is 0.010524557903409004\n",
      "epoch: 3 step: 74, loss is 0.01299272570759058\n",
      "epoch: 3 step: 75, loss is 0.0005495105870068073\n",
      "epoch: 3 step: 76, loss is 0.020460525527596474\n",
      "epoch: 3 step: 77, loss is 0.0011631724191829562\n",
      "epoch: 3 step: 78, loss is 0.004077392164617777\n",
      "epoch: 3 step: 79, loss is 0.0050017498433589935\n",
      "epoch: 3 step: 80, loss is 0.015031512826681137\n",
      "epoch: 3 step: 81, loss is 0.23259924352169037\n",
      "epoch: 3 step: 82, loss is 0.002364611253142357\n",
      "epoch: 3 step: 83, loss is 0.011319042183458805\n",
      "epoch: 3 step: 84, loss is 0.052029676735401154\n",
      "epoch: 3 step: 85, loss is 0.030062295496463776\n",
      "epoch: 3 step: 86, loss is 0.14321984350681305\n",
      "epoch: 3 step: 87, loss is 0.0006765627767890692\n",
      "epoch: 3 step: 88, loss is 0.0018275484908372164\n",
      "epoch: 3 step: 89, loss is 0.0034879108425229788\n",
      "epoch: 3 step: 90, loss is 0.1831013262271881\n",
      "epoch: 3 step: 91, loss is 0.045554645359516144\n",
      "epoch: 3 step: 92, loss is 0.05010949820280075\n",
      "epoch: 3 step: 93, loss is 0.033390868455171585\n",
      "epoch: 3 step: 94, loss is 0.03282903879880905\n",
      "epoch: 3 step: 95, loss is 0.20117872953414917\n",
      "epoch: 3 step: 96, loss is 0.05975326895713806\n",
      "epoch: 3 step: 97, loss is 0.004534447565674782\n",
      "epoch: 3 step: 98, loss is 0.015382399782538414\n",
      "epoch: 3 step: 99, loss is 0.27648288011550903\n",
      "epoch: 3 step: 100, loss is 0.012693889439105988\n",
      "epoch: 3 step: 101, loss is 0.006831693928688765\n",
      "epoch: 3 step: 102, loss is 0.0024688136763870716\n",
      "epoch: 3 step: 103, loss is 0.01569429598748684\n",
      "epoch: 3 step: 104, loss is 0.017080072313547134\n",
      "epoch: 3 step: 105, loss is 0.0038325919304043055\n",
      "epoch: 3 step: 106, loss is 0.04817779362201691\n",
      "epoch: 3 step: 107, loss is 0.07154327630996704\n",
      "epoch: 3 step: 108, loss is 0.0046103885397315025\n",
      "epoch: 3 step: 109, loss is 0.05449498072266579\n",
      "epoch: 3 step: 110, loss is 0.004648945294320583\n",
      "epoch: 3 step: 111, loss is 0.02199520729482174\n",
      "epoch: 3 step: 112, loss is 0.003768304595723748\n",
      "epoch: 3 step: 113, loss is 0.008246835321187973\n",
      "epoch: 3 step: 114, loss is 0.012578609399497509\n",
      "epoch: 3 step: 115, loss is 0.12771941721439362\n",
      "epoch: 3 step: 116, loss is 0.11764582991600037\n",
      "epoch: 3 step: 117, loss is 0.0072013624012470245\n",
      "epoch: 3 step: 118, loss is 0.016148682683706284\n",
      "epoch: 3 step: 119, loss is 0.0014541377313435078\n",
      "epoch: 3 step: 120, loss is 0.028943132609128952\n",
      "epoch: 3 step: 121, loss is 0.021871909499168396\n",
      "epoch: 3 step: 122, loss is 0.03391209989786148\n",
      "epoch: 3 step: 123, loss is 0.002499924972653389\n",
      "epoch: 3 step: 124, loss is 0.09382954239845276\n",
      "epoch: 3 step: 125, loss is 0.011818935163319111\n",
      "epoch: 3 step: 126, loss is 0.0020425277762115\n",
      "epoch: 3 step: 127, loss is 0.002518111141398549\n",
      "epoch: 3 step: 128, loss is 0.005706020165234804\n",
      "epoch: 3 step: 129, loss is 0.04537873715162277\n",
      "epoch: 3 step: 130, loss is 0.24327228963375092\n",
      "epoch: 3 step: 131, loss is 0.0001566508290125057\n",
      "epoch: 3 step: 132, loss is 0.009249485097825527\n",
      "epoch: 3 step: 133, loss is 0.001526495791040361\n",
      "epoch: 3 step: 134, loss is 0.06019343435764313\n",
      "epoch: 3 step: 135, loss is 0.04853074997663498\n",
      "epoch: 3 step: 136, loss is 0.0620068684220314\n",
      "epoch: 3 step: 137, loss is 0.008184405043721199\n",
      "epoch: 3 step: 138, loss is 0.015385987237095833\n",
      "epoch: 3 step: 139, loss is 0.21706528961658478\n",
      "epoch: 3 step: 140, loss is 0.022561602294445038\n",
      "epoch: 3 step: 141, loss is 0.0008215862326323986\n",
      "epoch: 3 step: 142, loss is 0.12390556931495667\n",
      "epoch: 3 step: 143, loss is 0.0929705798625946\n",
      "epoch: 3 step: 144, loss is 0.09448419511318207\n",
      "epoch: 3 step: 145, loss is 0.012029186822474003\n",
      "epoch: 3 step: 146, loss is 0.07072854787111282\n",
      "epoch: 3 step: 147, loss is 0.00827740877866745\n",
      "epoch: 3 step: 148, loss is 0.18378566205501556\n",
      "epoch: 3 step: 149, loss is 0.12691138684749603\n",
      "epoch: 3 step: 150, loss is 0.11617235094308853\n",
      "epoch: 3 step: 151, loss is 0.047654636204242706\n",
      "epoch: 3 step: 152, loss is 0.02430214174091816\n",
      "epoch: 3 step: 153, loss is 0.005769381299614906\n",
      "epoch: 3 step: 154, loss is 0.06802048534154892\n",
      "epoch: 3 step: 155, loss is 0.005643364507704973\n",
      "epoch: 3 step: 156, loss is 0.005176559556275606\n",
      "epoch: 3 step: 157, loss is 0.0006601522327400744\n",
      "epoch: 3 step: 158, loss is 0.0013981396332383156\n",
      "epoch: 3 step: 159, loss is 0.02751908265054226\n",
      "epoch: 3 step: 160, loss is 0.001183554413728416\n",
      "epoch: 3 step: 161, loss is 0.19805921614170074\n",
      "epoch: 3 step: 162, loss is 0.0015375984366983175\n",
      "epoch: 3 step: 163, loss is 0.021719973534345627\n",
      "epoch: 3 step: 164, loss is 0.006059359293431044\n",
      "epoch: 3 step: 165, loss is 0.02885378897190094\n",
      "epoch: 3 step: 166, loss is 0.013777876272797585\n",
      "epoch: 3 step: 167, loss is 0.005126639734953642\n",
      "epoch: 3 step: 168, loss is 0.011469871737062931\n",
      "epoch: 3 step: 169, loss is 0.03236676752567291\n",
      "epoch: 3 step: 170, loss is 0.002690557623282075\n",
      "epoch: 3 step: 171, loss is 0.016322201117873192\n",
      "epoch: 3 step: 172, loss is 0.0019012141274288297\n",
      "epoch: 3 step: 173, loss is 0.09921815991401672\n",
      "epoch: 3 step: 174, loss is 0.038038622587919235\n",
      "epoch: 3 step: 175, loss is 0.030822759494185448\n",
      "epoch: 3 step: 176, loss is 0.04086669161915779\n",
      "epoch: 3 step: 177, loss is 0.04042225331068039\n",
      "epoch: 3 step: 178, loss is 0.002818702021613717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 179, loss is 0.0007493687444366515\n",
      "epoch: 3 step: 180, loss is 0.007239590864628553\n",
      "epoch: 3 step: 181, loss is 0.11243490129709244\n",
      "epoch: 3 step: 182, loss is 0.013155796565115452\n",
      "epoch: 3 step: 183, loss is 0.01777390018105507\n",
      "epoch: 3 step: 184, loss is 0.005165429785847664\n",
      "epoch: 3 step: 185, loss is 0.01456738356500864\n",
      "epoch: 3 step: 186, loss is 0.056200191378593445\n",
      "epoch: 3 step: 187, loss is 0.058593593537807465\n",
      "epoch: 3 step: 188, loss is 0.005421123467385769\n",
      "epoch: 3 step: 189, loss is 0.0030218379106372595\n",
      "epoch: 3 step: 190, loss is 0.16608016192913055\n",
      "epoch: 3 step: 191, loss is 0.002205595374107361\n",
      "epoch: 3 step: 192, loss is 0.0007100944640114903\n",
      "epoch: 3 step: 193, loss is 0.0010843250202015042\n",
      "epoch: 3 step: 194, loss is 0.006596853956580162\n",
      "epoch: 3 step: 195, loss is 0.010814384557306767\n",
      "epoch: 3 step: 196, loss is 0.050567202270030975\n",
      "epoch: 3 step: 197, loss is 0.0018663129303604364\n",
      "epoch: 3 step: 198, loss is 0.004449768923223019\n",
      "epoch: 3 step: 199, loss is 0.010892905294895172\n",
      "epoch: 3 step: 200, loss is 0.011951669119298458\n",
      "epoch: 3 step: 201, loss is 0.03193961828947067\n",
      "epoch: 3 step: 202, loss is 0.0007255625096149743\n",
      "epoch: 3 step: 203, loss is 0.038563571870326996\n",
      "epoch: 3 step: 204, loss is 0.0011103719007223845\n",
      "epoch: 3 step: 205, loss is 0.000597802922129631\n",
      "epoch: 3 step: 206, loss is 0.00694530364125967\n",
      "epoch: 3 step: 207, loss is 0.0011441081296652555\n",
      "epoch: 3 step: 208, loss is 0.005381823983043432\n",
      "epoch: 3 step: 209, loss is 0.1236826553940773\n",
      "epoch: 3 step: 210, loss is 0.0035138013772666454\n",
      "epoch: 3 step: 211, loss is 0.08314003795385361\n",
      "epoch: 3 step: 212, loss is 0.12268366664648056\n",
      "epoch: 3 step: 213, loss is 0.030607517808675766\n",
      "epoch: 3 step: 214, loss is 0.004844989627599716\n",
      "epoch: 3 step: 215, loss is 0.0006874175160191953\n",
      "epoch: 3 step: 216, loss is 0.0031144586391747\n",
      "epoch: 3 step: 217, loss is 0.018239036202430725\n",
      "epoch: 3 step: 218, loss is 0.01676579937338829\n",
      "epoch: 3 step: 219, loss is 0.005921803414821625\n",
      "epoch: 3 step: 220, loss is 0.0352899543941021\n",
      "epoch: 3 step: 221, loss is 0.0010275724343955517\n",
      "epoch: 3 step: 222, loss is 0.0007323150057345629\n",
      "epoch: 3 step: 223, loss is 0.1396327167749405\n",
      "epoch: 3 step: 224, loss is 0.0809108316898346\n",
      "epoch: 3 step: 225, loss is 0.30732062458992004\n",
      "epoch: 3 step: 226, loss is 0.2317943125963211\n",
      "epoch: 3 step: 227, loss is 0.02905770018696785\n",
      "epoch: 3 step: 228, loss is 0.0042907483875751495\n",
      "epoch: 3 step: 229, loss is 0.004101653583347797\n",
      "epoch: 3 step: 230, loss is 0.00507784727960825\n",
      "epoch: 3 step: 231, loss is 0.002701141405850649\n",
      "epoch: 3 step: 232, loss is 0.04552798718214035\n",
      "epoch: 3 step: 233, loss is 0.004339448641985655\n",
      "epoch: 3 step: 234, loss is 0.22321084141731262\n",
      "epoch: 3 step: 235, loss is 0.003122396534308791\n",
      "epoch: 3 step: 236, loss is 0.00986188743263483\n",
      "epoch: 3 step: 237, loss is 0.009207183495163918\n",
      "epoch: 3 step: 238, loss is 0.014654794707894325\n",
      "epoch: 3 step: 239, loss is 0.0073866997845470905\n",
      "epoch: 3 step: 240, loss is 0.17332717776298523\n",
      "epoch: 3 step: 241, loss is 0.010328474454581738\n",
      "epoch: 3 step: 242, loss is 0.018456432968378067\n",
      "epoch: 3 step: 243, loss is 0.004653371870517731\n",
      "epoch: 3 step: 244, loss is 0.0016463748179376125\n",
      "epoch: 3 step: 245, loss is 0.003366928780451417\n",
      "epoch: 3 step: 246, loss is 0.022001348435878754\n",
      "epoch: 3 step: 247, loss is 0.14182080328464508\n",
      "epoch: 3 step: 248, loss is 0.011237791739404202\n",
      "epoch: 3 step: 249, loss is 0.025506531819701195\n",
      "epoch: 3 step: 250, loss is 0.025097794830799103\n",
      "epoch: 3 step: 251, loss is 0.005391437094658613\n",
      "epoch: 3 step: 252, loss is 0.0034624477848410606\n",
      "epoch: 3 step: 253, loss is 0.06972169131040573\n",
      "epoch: 3 step: 254, loss is 0.004185489844530821\n",
      "epoch: 3 step: 255, loss is 0.002047633519396186\n",
      "epoch: 3 step: 256, loss is 0.1638602912425995\n",
      "epoch: 3 step: 257, loss is 0.011329540982842445\n",
      "epoch: 3 step: 258, loss is 0.004739643540233374\n",
      "epoch: 3 step: 259, loss is 0.005900949239730835\n",
      "epoch: 3 step: 260, loss is 0.011389944702386856\n",
      "epoch: 3 step: 261, loss is 0.05846448987722397\n",
      "epoch: 3 step: 262, loss is 0.007882846519351006\n",
      "epoch: 3 step: 263, loss is 0.10724534839391708\n",
      "epoch: 3 step: 264, loss is 0.042021624743938446\n",
      "epoch: 3 step: 265, loss is 0.005869148764759302\n",
      "epoch: 3 step: 266, loss is 0.05091998726129532\n",
      "epoch: 3 step: 267, loss is 0.0008507544989697635\n",
      "epoch: 3 step: 268, loss is 0.019212938845157623\n",
      "epoch: 3 step: 269, loss is 0.013524814508855343\n",
      "epoch: 3 step: 270, loss is 0.0867534652352333\n",
      "epoch: 3 step: 271, loss is 0.007895574904978275\n",
      "epoch: 3 step: 272, loss is 0.017406899482011795\n",
      "epoch: 3 step: 273, loss is 0.009487660601735115\n",
      "epoch: 3 step: 274, loss is 0.015378965064883232\n",
      "epoch: 3 step: 275, loss is 0.020115718245506287\n",
      "epoch: 3 step: 276, loss is 0.04084620624780655\n",
      "epoch: 3 step: 277, loss is 0.03880994766950607\n",
      "epoch: 3 step: 278, loss is 0.06188327074050903\n",
      "epoch: 3 step: 279, loss is 0.001346903620287776\n",
      "epoch: 3 step: 280, loss is 0.013542301021516323\n",
      "epoch: 3 step: 281, loss is 0.003020042786374688\n",
      "epoch: 3 step: 282, loss is 0.0025435916613787413\n",
      "epoch: 3 step: 283, loss is 5.8009372878586873e-05\n",
      "epoch: 3 step: 284, loss is 0.0014328688848763704\n",
      "epoch: 3 step: 285, loss is 0.06377231329679489\n",
      "epoch: 3 step: 286, loss is 0.0005367111880332232\n",
      "epoch: 3 step: 287, loss is 0.011029430665075779\n",
      "epoch: 3 step: 288, loss is 0.07737582921981812\n",
      "epoch: 3 step: 289, loss is 0.01651354320347309\n",
      "epoch: 3 step: 290, loss is 0.013598007149994373\n",
      "epoch: 3 step: 291, loss is 0.025954479351639748\n",
      "epoch: 3 step: 292, loss is 0.08409792184829712\n",
      "epoch: 3 step: 293, loss is 0.12204135954380035\n",
      "epoch: 3 step: 294, loss is 0.0026456674095243216\n",
      "epoch: 3 step: 295, loss is 0.022422559559345245\n",
      "epoch: 3 step: 296, loss is 0.005970141384750605\n",
      "epoch: 3 step: 297, loss is 0.03473682701587677\n",
      "epoch: 3 step: 298, loss is 0.02276095375418663\n",
      "epoch: 3 step: 299, loss is 0.00017135875532403588\n",
      "epoch: 3 step: 300, loss is 0.0486464761197567\n",
      "epoch: 3 step: 301, loss is 0.0016877185553312302\n",
      "epoch: 3 step: 302, loss is 0.0016104280948638916\n",
      "epoch: 3 step: 303, loss is 0.054861146956682205\n",
      "epoch: 3 step: 304, loss is 0.0012773785274475813\n",
      "epoch: 3 step: 305, loss is 0.08259216696023941\n",
      "epoch: 3 step: 306, loss is 0.006503572687506676\n",
      "epoch: 3 step: 307, loss is 0.0071496726013720036\n",
      "epoch: 3 step: 308, loss is 0.017671382054686546\n",
      "epoch: 3 step: 309, loss is 0.0012506679631769657\n",
      "epoch: 3 step: 310, loss is 0.002161164302378893\n",
      "epoch: 3 step: 311, loss is 0.00022581632947549224\n",
      "epoch: 3 step: 312, loss is 0.07878509163856506\n",
      "epoch: 3 step: 313, loss is 0.05070693790912628\n",
      "epoch: 3 step: 314, loss is 0.036763887852430344\n",
      "epoch: 3 step: 315, loss is 0.015307732857763767\n",
      "epoch: 3 step: 316, loss is 0.08881823718547821\n",
      "epoch: 3 step: 317, loss is 0.2599847614765167\n",
      "epoch: 3 step: 318, loss is 0.005092345643788576\n",
      "epoch: 3 step: 319, loss is 0.0794651135802269\n",
      "epoch: 3 step: 320, loss is 0.0012127029476687312\n",
      "epoch: 3 step: 321, loss is 0.022558091208338737\n",
      "epoch: 3 step: 322, loss is 0.06157263368368149\n",
      "epoch: 3 step: 323, loss is 0.17529533803462982\n",
      "epoch: 3 step: 324, loss is 0.09808209538459778\n",
      "epoch: 3 step: 325, loss is 0.006855363957583904\n",
      "epoch: 3 step: 326, loss is 0.03378208354115486\n",
      "epoch: 3 step: 327, loss is 0.0034780860878527164\n",
      "epoch: 3 step: 328, loss is 0.12256626784801483\n",
      "epoch: 3 step: 329, loss is 0.01992170885205269\n",
      "epoch: 3 step: 330, loss is 0.0008602759917266667\n",
      "epoch: 3 step: 331, loss is 0.0069526308216154575\n",
      "epoch: 3 step: 332, loss is 0.09193453192710876\n",
      "epoch: 3 step: 333, loss is 0.17603591084480286\n",
      "epoch: 3 step: 334, loss is 0.020809195935726166\n",
      "epoch: 3 step: 335, loss is 0.009658599272370338\n",
      "epoch: 3 step: 336, loss is 0.07310451567173004\n",
      "epoch: 3 step: 337, loss is 0.01589296944439411\n",
      "epoch: 3 step: 338, loss is 0.002949574263766408\n",
      "epoch: 3 step: 339, loss is 0.01903298683464527\n",
      "epoch: 3 step: 340, loss is 0.0007027176325209439\n",
      "epoch: 3 step: 341, loss is 0.0020832710433751345\n",
      "epoch: 3 step: 342, loss is 0.02060210518538952\n",
      "epoch: 3 step: 343, loss is 0.009276664815843105\n",
      "epoch: 3 step: 344, loss is 0.06074949726462364\n",
      "epoch: 3 step: 345, loss is 0.03676498681306839\n",
      "epoch: 3 step: 346, loss is 0.16095620393753052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 347, loss is 0.0057752844877541065\n",
      "epoch: 3 step: 348, loss is 0.035894185304641724\n",
      "epoch: 3 step: 349, loss is 0.013771583326160908\n",
      "epoch: 3 step: 350, loss is 0.06985469162464142\n",
      "epoch: 3 step: 351, loss is 0.11418576538562775\n",
      "epoch: 3 step: 352, loss is 0.006907305680215359\n",
      "epoch: 3 step: 353, loss is 0.017882267013192177\n",
      "epoch: 3 step: 354, loss is 0.008852493017911911\n",
      "epoch: 3 step: 355, loss is 0.0011265004286542535\n",
      "epoch: 3 step: 356, loss is 0.001044012140482664\n",
      "epoch: 3 step: 357, loss is 0.07657324522733688\n",
      "epoch: 3 step: 358, loss is 0.0015328521840274334\n",
      "epoch: 3 step: 359, loss is 0.005110735073685646\n",
      "epoch: 3 step: 360, loss is 0.027270697057247162\n",
      "epoch: 3 step: 361, loss is 0.0006172883440740407\n",
      "epoch: 3 step: 362, loss is 0.044845692813396454\n",
      "epoch: 3 step: 363, loss is 0.013877215795218945\n",
      "epoch: 3 step: 364, loss is 0.01857725903391838\n",
      "epoch: 3 step: 365, loss is 0.0016431799158453941\n",
      "epoch: 3 step: 366, loss is 0.0360087975859642\n",
      "epoch: 3 step: 367, loss is 0.03510895371437073\n",
      "epoch: 3 step: 368, loss is 0.0035230289213359356\n",
      "epoch: 3 step: 369, loss is 0.0025765537284314632\n",
      "epoch: 3 step: 370, loss is 0.05338554084300995\n",
      "epoch: 3 step: 371, loss is 0.005772840231657028\n",
      "epoch: 3 step: 372, loss is 0.339449405670166\n",
      "epoch: 3 step: 373, loss is 0.058878324925899506\n",
      "epoch: 3 step: 374, loss is 0.11810669302940369\n",
      "epoch: 3 step: 375, loss is 0.005344930570572615\n",
      "epoch: 3 step: 376, loss is 0.11123571544885635\n",
      "epoch: 3 step: 377, loss is 0.011344624683260918\n",
      "epoch: 3 step: 378, loss is 0.03440282493829727\n",
      "epoch: 3 step: 379, loss is 0.004999586846679449\n",
      "epoch: 3 step: 380, loss is 0.09216810762882233\n",
      "epoch: 3 step: 381, loss is 0.03637326881289482\n",
      "epoch: 3 step: 382, loss is 0.05639553442597389\n",
      "epoch: 3 step: 383, loss is 0.006454749498516321\n",
      "epoch: 3 step: 384, loss is 0.015170502476394176\n",
      "epoch: 3 step: 385, loss is 0.01137781236320734\n",
      "epoch: 3 step: 386, loss is 0.021936379373073578\n",
      "epoch: 3 step: 387, loss is 0.10286947339773178\n",
      "epoch: 3 step: 388, loss is 0.008924596942961216\n",
      "epoch: 3 step: 389, loss is 0.004592812154442072\n",
      "epoch: 3 step: 390, loss is 0.07081004977226257\n",
      "epoch: 3 step: 391, loss is 0.02609032392501831\n",
      "epoch: 3 step: 392, loss is 0.08385477215051651\n",
      "epoch: 3 step: 393, loss is 0.008989492431282997\n",
      "epoch: 3 step: 394, loss is 0.26889410614967346\n",
      "epoch: 3 step: 395, loss is 0.13951517641544342\n",
      "epoch: 3 step: 396, loss is 0.007940161041915417\n",
      "epoch: 3 step: 397, loss is 0.020991716533899307\n",
      "epoch: 3 step: 398, loss is 0.03519846871495247\n",
      "epoch: 3 step: 399, loss is 0.00607305159792304\n",
      "epoch: 3 step: 400, loss is 0.1885872185230255\n",
      "epoch: 3 step: 401, loss is 0.09010300040245056\n",
      "epoch: 3 step: 402, loss is 0.018733419477939606\n",
      "epoch: 3 step: 403, loss is 0.16555334627628326\n",
      "epoch: 3 step: 404, loss is 0.03120361641049385\n",
      "epoch: 3 step: 405, loss is 0.06550092250108719\n",
      "epoch: 3 step: 406, loss is 0.010285960510373116\n",
      "epoch: 3 step: 407, loss is 0.17330488562583923\n",
      "epoch: 3 step: 408, loss is 0.006972331088036299\n",
      "epoch: 3 step: 409, loss is 0.0797775611281395\n",
      "epoch: 3 step: 410, loss is 0.2762557864189148\n",
      "epoch: 3 step: 411, loss is 0.2634974420070648\n",
      "epoch: 3 step: 412, loss is 0.0105510912835598\n",
      "epoch: 3 step: 413, loss is 0.004698319360613823\n",
      "epoch: 3 step: 414, loss is 0.12872233986854553\n",
      "epoch: 3 step: 415, loss is 0.01784548908472061\n",
      "epoch: 3 step: 416, loss is 0.003776064608246088\n",
      "epoch: 3 step: 417, loss is 0.1429150104522705\n",
      "epoch: 3 step: 418, loss is 0.17956455051898956\n",
      "epoch: 3 step: 419, loss is 0.008320825174450874\n",
      "epoch: 3 step: 420, loss is 0.005185164976865053\n",
      "epoch: 3 step: 421, loss is 0.0030517992563545704\n",
      "epoch: 3 step: 422, loss is 0.015175829641520977\n",
      "epoch: 3 step: 423, loss is 0.0355040542781353\n",
      "epoch: 3 step: 424, loss is 0.009356626309454441\n",
      "epoch: 3 step: 425, loss is 0.09864267706871033\n",
      "epoch: 3 step: 426, loss is 0.017924897372722626\n",
      "epoch: 3 step: 427, loss is 0.02048768475651741\n",
      "epoch: 3 step: 428, loss is 0.03498442843556404\n",
      "epoch: 3 step: 429, loss is 0.0039463527500629425\n",
      "epoch: 3 step: 430, loss is 0.0007359680603258312\n",
      "epoch: 3 step: 431, loss is 0.015375254675745964\n",
      "epoch: 3 step: 432, loss is 0.1846955567598343\n",
      "epoch: 3 step: 433, loss is 0.06824059784412384\n",
      "epoch: 3 step: 434, loss is 0.003487722249701619\n",
      "epoch: 3 step: 435, loss is 0.00402299128472805\n",
      "epoch: 3 step: 436, loss is 0.10052803158760071\n",
      "epoch: 3 step: 437, loss is 0.004617948085069656\n",
      "epoch: 3 step: 438, loss is 0.11731631308794022\n",
      "epoch: 3 step: 439, loss is 0.0857163518667221\n",
      "epoch: 3 step: 440, loss is 0.1896137148141861\n",
      "epoch: 3 step: 441, loss is 0.0027380564715713263\n",
      "epoch: 3 step: 442, loss is 0.024031976237893105\n",
      "epoch: 3 step: 443, loss is 0.02823183871805668\n",
      "epoch: 3 step: 444, loss is 0.005564401391893625\n",
      "epoch: 3 step: 445, loss is 0.025016941130161285\n",
      "epoch: 3 step: 446, loss is 0.006754857953637838\n",
      "epoch: 3 step: 447, loss is 0.0875050276517868\n",
      "epoch: 3 step: 448, loss is 0.1208256334066391\n",
      "epoch: 3 step: 449, loss is 0.010934379883110523\n",
      "epoch: 3 step: 450, loss is 0.015541224740445614\n",
      "epoch: 3 step: 451, loss is 0.014633161947131157\n",
      "epoch: 3 step: 452, loss is 0.17910757660865784\n",
      "epoch: 3 step: 453, loss is 0.21255405247211456\n",
      "epoch: 3 step: 454, loss is 0.09425494819879532\n",
      "epoch: 3 step: 455, loss is 0.01001583319157362\n",
      "epoch: 3 step: 456, loss is 0.0029453241731971502\n",
      "epoch: 3 step: 457, loss is 0.003734382102265954\n",
      "epoch: 3 step: 458, loss is 0.059570200741291046\n",
      "epoch: 3 step: 459, loss is 0.19759272038936615\n",
      "epoch: 3 step: 460, loss is 0.0040314700454473495\n",
      "epoch: 3 step: 461, loss is 0.09228407591581345\n",
      "epoch: 3 step: 462, loss is 0.23298139870166779\n",
      "epoch: 3 step: 463, loss is 0.025668267160654068\n",
      "epoch: 3 step: 464, loss is 0.1100332960486412\n",
      "epoch: 3 step: 465, loss is 0.05031347647309303\n",
      "epoch: 3 step: 466, loss is 0.0033057034015655518\n",
      "epoch: 3 step: 467, loss is 0.2208661139011383\n",
      "epoch: 3 step: 468, loss is 0.0015514061087742448\n",
      "epoch: 3 step: 469, loss is 0.0032312043476849794\n",
      "epoch: 3 step: 470, loss is 0.11113634705543518\n",
      "epoch: 3 step: 471, loss is 0.0010905165690928698\n",
      "epoch: 3 step: 472, loss is 0.028951767832040787\n",
      "epoch: 3 step: 473, loss is 0.005602575372904539\n",
      "epoch: 3 step: 474, loss is 0.004636611323803663\n",
      "epoch: 3 step: 475, loss is 0.16594122350215912\n",
      "epoch: 3 step: 476, loss is 0.0039208815433084965\n",
      "epoch: 3 step: 477, loss is 0.008085655979812145\n",
      "epoch: 3 step: 478, loss is 0.00027843896532431245\n",
      "epoch: 3 step: 479, loss is 0.023608196526765823\n",
      "epoch: 3 step: 480, loss is 0.020649120211601257\n",
      "epoch: 3 step: 481, loss is 0.059524934738874435\n",
      "epoch: 3 step: 482, loss is 0.04845329001545906\n",
      "epoch: 3 step: 483, loss is 0.02992783486843109\n",
      "epoch: 3 step: 484, loss is 0.2042475938796997\n",
      "epoch: 3 step: 485, loss is 0.0023558742832392454\n",
      "epoch: 3 step: 486, loss is 0.003189696464687586\n",
      "epoch: 3 step: 487, loss is 0.009331694804131985\n",
      "epoch: 3 step: 488, loss is 0.22862882912158966\n",
      "epoch: 3 step: 489, loss is 0.11641155928373337\n",
      "epoch: 3 step: 490, loss is 0.0721566304564476\n",
      "epoch: 3 step: 491, loss is 0.04845324158668518\n",
      "epoch: 3 step: 492, loss is 0.0034788688644766808\n",
      "epoch: 3 step: 493, loss is 0.001493107876740396\n",
      "epoch: 3 step: 494, loss is 0.0010517204646021128\n",
      "epoch: 3 step: 495, loss is 0.008350326679646969\n",
      "epoch: 3 step: 496, loss is 0.057914599776268005\n",
      "epoch: 3 step: 497, loss is 0.08434080332517624\n",
      "epoch: 3 step: 498, loss is 0.008692717179656029\n",
      "epoch: 3 step: 499, loss is 0.049961939454078674\n",
      "epoch: 3 step: 500, loss is 0.024375692009925842\n",
      "epoch: 3 step: 501, loss is 0.08446887880563736\n",
      "epoch: 3 step: 502, loss is 0.002328313887119293\n",
      "epoch: 3 step: 503, loss is 0.036315061151981354\n",
      "epoch: 3 step: 504, loss is 0.054787978529930115\n",
      "epoch: 3 step: 505, loss is 0.001945465337485075\n",
      "epoch: 3 step: 506, loss is 0.05876992642879486\n",
      "epoch: 3 step: 507, loss is 0.0730198323726654\n",
      "epoch: 3 step: 508, loss is 0.17096476256847382\n",
      "epoch: 3 step: 509, loss is 0.08002050966024399\n",
      "epoch: 3 step: 510, loss is 0.011344064958393574\n",
      "epoch: 3 step: 511, loss is 0.0010211467742919922\n",
      "epoch: 3 step: 512, loss is 0.029322583228349686\n",
      "epoch: 3 step: 513, loss is 0.13327957689762115\n",
      "epoch: 3 step: 514, loss is 0.011010855436325073\n",
      "epoch: 3 step: 515, loss is 0.03462453559041023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 516, loss is 0.009012204594910145\n",
      "epoch: 3 step: 517, loss is 0.01038969773799181\n",
      "epoch: 3 step: 518, loss is 0.011715967208147049\n",
      "epoch: 3 step: 519, loss is 0.01920628733932972\n",
      "epoch: 3 step: 520, loss is 0.025856876745820045\n",
      "epoch: 3 step: 521, loss is 0.0017057721270248294\n",
      "epoch: 3 step: 522, loss is 0.008466578088700771\n",
      "epoch: 3 step: 523, loss is 0.009536819532513618\n",
      "epoch: 3 step: 524, loss is 0.04925651103258133\n",
      "epoch: 3 step: 525, loss is 0.02965848706662655\n",
      "epoch: 3 step: 526, loss is 0.0019211549079045653\n",
      "epoch: 3 step: 527, loss is 0.0023947127629071474\n",
      "epoch: 3 step: 528, loss is 0.0013370707165449858\n",
      "epoch: 3 step: 529, loss is 0.09850800037384033\n",
      "epoch: 3 step: 530, loss is 0.11758535355329514\n",
      "epoch: 3 step: 531, loss is 0.000957953161559999\n",
      "epoch: 3 step: 532, loss is 0.0014157327823340893\n",
      "epoch: 3 step: 533, loss is 0.12568867206573486\n",
      "epoch: 3 step: 534, loss is 0.025652583688497543\n",
      "epoch: 3 step: 535, loss is 0.00427266675978899\n",
      "epoch: 3 step: 536, loss is 0.016015315428376198\n",
      "epoch: 3 step: 537, loss is 0.003997085150331259\n",
      "epoch: 3 step: 538, loss is 0.0059126317501068115\n",
      "epoch: 3 step: 539, loss is 0.032657332718372345\n",
      "epoch: 3 step: 540, loss is 0.0066215950064361095\n",
      "epoch: 3 step: 541, loss is 0.07431655377149582\n",
      "epoch: 3 step: 542, loss is 0.004368727561086416\n",
      "epoch: 3 step: 543, loss is 0.016849003732204437\n",
      "epoch: 3 step: 544, loss is 0.01638215035200119\n",
      "epoch: 3 step: 545, loss is 0.0084893349558115\n",
      "epoch: 3 step: 546, loss is 0.08175594359636307\n",
      "epoch: 3 step: 547, loss is 0.11083576828241348\n",
      "epoch: 3 step: 548, loss is 0.001795312506146729\n",
      "epoch: 3 step: 549, loss is 0.005213673692196608\n",
      "epoch: 3 step: 550, loss is 0.020086120814085007\n",
      "epoch: 3 step: 551, loss is 0.014525435864925385\n",
      "epoch: 3 step: 552, loss is 0.002609814051538706\n",
      "epoch: 3 step: 553, loss is 0.00048375516780652106\n",
      "epoch: 3 step: 554, loss is 0.18059705197811127\n",
      "epoch: 3 step: 555, loss is 0.014889405108988285\n",
      "epoch: 3 step: 556, loss is 0.0015580295585095882\n",
      "epoch: 3 step: 557, loss is 0.012337294407188892\n",
      "epoch: 3 step: 558, loss is 0.021772854030132294\n",
      "epoch: 3 step: 559, loss is 0.014110271818935871\n",
      "epoch: 3 step: 560, loss is 0.007364547811448574\n",
      "epoch: 3 step: 561, loss is 0.0014567816397175193\n",
      "epoch: 3 step: 562, loss is 0.07443025708198547\n",
      "epoch: 3 step: 563, loss is 0.0032406190875917673\n",
      "epoch: 3 step: 564, loss is 0.00758369080722332\n",
      "epoch: 3 step: 565, loss is 0.0038841250352561474\n",
      "epoch: 3 step: 566, loss is 0.006072225049138069\n",
      "epoch: 3 step: 567, loss is 0.054169122129678726\n",
      "epoch: 3 step: 568, loss is 0.0025757504627108574\n",
      "epoch: 3 step: 569, loss is 0.02127472124993801\n",
      "epoch: 3 step: 570, loss is 0.00030265937675721943\n",
      "epoch: 3 step: 571, loss is 0.012804058380424976\n",
      "epoch: 3 step: 572, loss is 0.0238790400326252\n",
      "epoch: 3 step: 573, loss is 0.015286436304450035\n",
      "epoch: 3 step: 574, loss is 0.08146996051073074\n",
      "epoch: 3 step: 575, loss is 0.0009069218649528921\n",
      "epoch: 3 step: 576, loss is 0.1855681985616684\n",
      "epoch: 3 step: 577, loss is 0.010682799853384495\n",
      "epoch: 3 step: 578, loss is 0.03281218558549881\n",
      "epoch: 3 step: 579, loss is 0.008876372128725052\n",
      "epoch: 3 step: 580, loss is 0.006482646334916353\n",
      "epoch: 3 step: 581, loss is 0.014468705281615257\n",
      "epoch: 3 step: 582, loss is 0.0034873117692768574\n",
      "epoch: 3 step: 583, loss is 0.00020579325791914016\n",
      "epoch: 3 step: 584, loss is 0.06860984861850739\n",
      "epoch: 3 step: 585, loss is 0.003775649704039097\n",
      "epoch: 3 step: 586, loss is 0.00045279794721864164\n",
      "epoch: 3 step: 587, loss is 0.07032491266727448\n",
      "epoch: 3 step: 588, loss is 0.002406110754236579\n",
      "epoch: 3 step: 589, loss is 0.039518143981695175\n",
      "epoch: 3 step: 590, loss is 0.005806677974760532\n",
      "epoch: 3 step: 591, loss is 0.04764242097735405\n",
      "epoch: 3 step: 592, loss is 0.0002556979306973517\n",
      "epoch: 3 step: 593, loss is 0.01260603778064251\n",
      "epoch: 3 step: 594, loss is 0.0004604448040481657\n",
      "epoch: 3 step: 595, loss is 0.0010058589978143573\n",
      "epoch: 3 step: 596, loss is 0.0017230994999408722\n",
      "epoch: 3 step: 597, loss is 0.0019410080276429653\n",
      "epoch: 3 step: 598, loss is 0.008845305070281029\n",
      "epoch: 3 step: 599, loss is 0.004496104083955288\n",
      "epoch: 3 step: 600, loss is 0.0004840581677854061\n",
      "epoch: 3 step: 601, loss is 0.0006791552295908332\n",
      "epoch: 3 step: 602, loss is 0.01951921172440052\n",
      "epoch: 3 step: 603, loss is 0.00531687680631876\n",
      "epoch: 3 step: 604, loss is 0.004475710913538933\n",
      "epoch: 3 step: 605, loss is 0.0027949060313403606\n",
      "epoch: 3 step: 606, loss is 0.005415226332843304\n",
      "epoch: 3 step: 607, loss is 0.003917992580682039\n",
      "epoch: 3 step: 608, loss is 0.02140996977686882\n",
      "epoch: 3 step: 609, loss is 0.002970632864162326\n",
      "epoch: 3 step: 610, loss is 0.12903746962547302\n",
      "epoch: 3 step: 611, loss is 0.12174224853515625\n",
      "epoch: 3 step: 612, loss is 0.0025308593176305294\n",
      "epoch: 3 step: 613, loss is 0.0009214105666615069\n",
      "epoch: 3 step: 614, loss is 0.014801849611103535\n",
      "epoch: 3 step: 615, loss is 0.1396641880273819\n",
      "epoch: 3 step: 616, loss is 0.0005970384227111936\n",
      "epoch: 3 step: 617, loss is 0.0014012341853231192\n",
      "epoch: 3 step: 618, loss is 0.03276993706822395\n",
      "epoch: 3 step: 619, loss is 0.0012060943990945816\n",
      "epoch: 3 step: 620, loss is 0.00700173806399107\n",
      "epoch: 3 step: 621, loss is 0.1447683721780777\n",
      "epoch: 3 step: 622, loss is 0.2827162742614746\n",
      "epoch: 3 step: 623, loss is 0.0026821100618690252\n",
      "epoch: 3 step: 624, loss is 0.017547395080327988\n",
      "epoch: 3 step: 625, loss is 0.0005149135831743479\n",
      "epoch: 3 step: 626, loss is 0.06236480548977852\n",
      "epoch: 3 step: 627, loss is 0.001792637980543077\n",
      "epoch: 3 step: 628, loss is 0.08301575481891632\n",
      "epoch: 3 step: 629, loss is 0.11421218514442444\n",
      "epoch: 3 step: 630, loss is 0.0034036028664559126\n",
      "epoch: 3 step: 631, loss is 0.016932092607021332\n",
      "epoch: 3 step: 632, loss is 0.004068679641932249\n",
      "epoch: 3 step: 633, loss is 0.018890876322984695\n",
      "epoch: 3 step: 634, loss is 0.0015328662702813745\n",
      "epoch: 3 step: 635, loss is 0.0019568942952901125\n",
      "epoch: 3 step: 636, loss is 0.035707440227270126\n",
      "epoch: 3 step: 637, loss is 0.026211589574813843\n",
      "epoch: 3 step: 638, loss is 0.2694537341594696\n",
      "epoch: 3 step: 639, loss is 0.003344410564750433\n",
      "epoch: 3 step: 640, loss is 0.00137798092328012\n",
      "epoch: 3 step: 641, loss is 0.0004951405571773648\n",
      "epoch: 3 step: 642, loss is 0.011709718964993954\n",
      "epoch: 3 step: 643, loss is 0.032754506915807724\n",
      "epoch: 3 step: 644, loss is 0.061397697776556015\n",
      "epoch: 3 step: 645, loss is 0.008816306479275227\n",
      "epoch: 3 step: 646, loss is 0.012944197282195091\n",
      "epoch: 3 step: 647, loss is 0.054719969630241394\n",
      "epoch: 3 step: 648, loss is 0.10171304643154144\n",
      "epoch: 3 step: 649, loss is 0.012835972011089325\n",
      "epoch: 3 step: 650, loss is 0.009121530689299107\n",
      "epoch: 3 step: 651, loss is 0.04975023493170738\n",
      "epoch: 3 step: 652, loss is 0.1358339488506317\n",
      "epoch: 3 step: 653, loss is 0.002546388888731599\n",
      "epoch: 3 step: 654, loss is 0.009583177044987679\n",
      "epoch: 3 step: 655, loss is 0.13574610650539398\n",
      "epoch: 3 step: 656, loss is 0.1345272809267044\n",
      "epoch: 3 step: 657, loss is 0.00037675275234505534\n",
      "epoch: 3 step: 658, loss is 0.07976085692644119\n",
      "epoch: 3 step: 659, loss is 0.0029148731846362352\n",
      "epoch: 3 step: 660, loss is 0.0002679760509636253\n",
      "epoch: 3 step: 661, loss is 0.016024412587285042\n",
      "epoch: 3 step: 662, loss is 0.0018811860354617238\n",
      "epoch: 3 step: 663, loss is 0.015851741656661034\n",
      "epoch: 3 step: 664, loss is 0.02297220192849636\n",
      "epoch: 3 step: 665, loss is 0.00042921287240460515\n",
      "epoch: 3 step: 666, loss is 0.0011925660073757172\n",
      "epoch: 3 step: 667, loss is 0.0014374149031937122\n",
      "epoch: 3 step: 668, loss is 0.03660115227103233\n",
      "epoch: 3 step: 669, loss is 0.004342543892562389\n",
      "epoch: 3 step: 670, loss is 0.09897569566965103\n",
      "epoch: 3 step: 671, loss is 0.002236712258309126\n",
      "epoch: 3 step: 672, loss is 0.012461707927286625\n",
      "epoch: 3 step: 673, loss is 0.02725691720843315\n",
      "epoch: 3 step: 674, loss is 0.08778475224971771\n",
      "epoch: 3 step: 675, loss is 0.014099320396780968\n",
      "epoch: 3 step: 676, loss is 0.020668717101216316\n",
      "epoch: 3 step: 677, loss is 0.032795604318380356\n",
      "epoch: 3 step: 678, loss is 9.633001172915101e-05\n",
      "epoch: 3 step: 679, loss is 0.0011694446438923478\n",
      "epoch: 3 step: 680, loss is 0.11417803913354874\n",
      "epoch: 3 step: 681, loss is 0.07009277492761612\n",
      "epoch: 3 step: 682, loss is 0.00391834182664752\n",
      "epoch: 3 step: 683, loss is 0.07931995391845703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 684, loss is 0.0062553780153393745\n",
      "epoch: 3 step: 685, loss is 0.0008296677260659635\n",
      "epoch: 3 step: 686, loss is 0.024545729160308838\n",
      "epoch: 3 step: 687, loss is 0.0025316497776657343\n",
      "epoch: 3 step: 688, loss is 0.0033433788921684027\n",
      "epoch: 3 step: 689, loss is 0.004019691608846188\n",
      "epoch: 3 step: 690, loss is 0.005183997564017773\n",
      "epoch: 3 step: 691, loss is 0.007882744073867798\n",
      "epoch: 3 step: 692, loss is 0.006187887396663427\n",
      "epoch: 3 step: 693, loss is 0.03280484676361084\n",
      "epoch: 3 step: 694, loss is 0.01440050732344389\n",
      "epoch: 3 step: 695, loss is 0.010464716702699661\n",
      "epoch: 3 step: 696, loss is 0.002682673977687955\n",
      "epoch: 3 step: 697, loss is 0.00034852998214773834\n",
      "epoch: 3 step: 698, loss is 0.10411237925291061\n",
      "epoch: 3 step: 699, loss is 0.021469855681061745\n",
      "epoch: 3 step: 700, loss is 0.18404562771320343\n",
      "epoch: 3 step: 701, loss is 0.32064247131347656\n",
      "epoch: 3 step: 702, loss is 0.09009431302547455\n",
      "epoch: 3 step: 703, loss is 0.049839701503515244\n",
      "epoch: 3 step: 704, loss is 0.12617714703083038\n",
      "epoch: 3 step: 705, loss is 0.004958577919751406\n",
      "epoch: 3 step: 706, loss is 0.00026789912953972816\n",
      "epoch: 3 step: 707, loss is 0.00035173536161892116\n",
      "epoch: 3 step: 708, loss is 0.0064764972776174545\n",
      "epoch: 3 step: 709, loss is 0.000875753175932914\n",
      "epoch: 3 step: 710, loss is 0.007602545898407698\n",
      "epoch: 3 step: 711, loss is 0.030658932402729988\n",
      "epoch: 3 step: 712, loss is 0.015152514912188053\n",
      "epoch: 3 step: 713, loss is 0.004193642642349005\n",
      "epoch: 3 step: 714, loss is 0.13421426713466644\n",
      "epoch: 3 step: 715, loss is 0.011543232016265392\n",
      "epoch: 3 step: 716, loss is 0.016679832711815834\n",
      "epoch: 3 step: 717, loss is 0.1605563759803772\n",
      "epoch: 3 step: 718, loss is 0.01628420129418373\n",
      "epoch: 3 step: 719, loss is 0.0438389889895916\n",
      "epoch: 3 step: 720, loss is 0.08792910724878311\n",
      "epoch: 3 step: 721, loss is 0.008463725447654724\n",
      "epoch: 3 step: 722, loss is 0.0017853061435744166\n",
      "epoch: 3 step: 723, loss is 0.09956839680671692\n",
      "epoch: 3 step: 724, loss is 0.10872237384319305\n",
      "epoch: 3 step: 725, loss is 0.001314629684202373\n",
      "epoch: 3 step: 726, loss is 0.021090272814035416\n",
      "epoch: 3 step: 727, loss is 0.025362102314829826\n",
      "epoch: 3 step: 728, loss is 0.057586099952459335\n",
      "epoch: 3 step: 729, loss is 0.049921829253435135\n",
      "epoch: 3 step: 730, loss is 0.022581974044442177\n",
      "epoch: 3 step: 731, loss is 0.11230628192424774\n",
      "epoch: 3 step: 732, loss is 0.2349063605070114\n",
      "epoch: 3 step: 733, loss is 0.023469284176826477\n",
      "epoch: 3 step: 734, loss is 0.0211404450237751\n",
      "epoch: 3 step: 735, loss is 0.011454911902546883\n",
      "epoch: 3 step: 736, loss is 0.06803186237812042\n",
      "epoch: 3 step: 737, loss is 0.04913425073027611\n",
      "epoch: 3 step: 738, loss is 0.23091885447502136\n",
      "epoch: 3 step: 739, loss is 0.0017017618520185351\n",
      "epoch: 3 step: 740, loss is 0.04763108491897583\n",
      "epoch: 3 step: 741, loss is 0.03162724897265434\n",
      "epoch: 3 step: 742, loss is 0.024758819490671158\n",
      "epoch: 3 step: 743, loss is 0.1825455278158188\n",
      "epoch: 3 step: 744, loss is 0.04231630265712738\n",
      "epoch: 3 step: 745, loss is 0.020076630637049675\n",
      "epoch: 3 step: 746, loss is 0.000139079726068303\n",
      "epoch: 3 step: 747, loss is 0.004438851960003376\n",
      "epoch: 3 step: 748, loss is 0.06346782296895981\n",
      "epoch: 3 step: 749, loss is 0.005962439812719822\n",
      "epoch: 3 step: 750, loss is 0.06319437175989151\n",
      "epoch: 3 step: 751, loss is 0.02801654301583767\n",
      "epoch: 3 step: 752, loss is 0.11018253117799759\n",
      "epoch: 3 step: 753, loss is 0.11317358911037445\n",
      "epoch: 3 step: 754, loss is 0.1365688145160675\n",
      "epoch: 3 step: 755, loss is 0.17578597366809845\n",
      "epoch: 3 step: 756, loss is 0.054806552827358246\n",
      "epoch: 3 step: 757, loss is 0.045140210539102554\n",
      "epoch: 3 step: 758, loss is 0.09551138430833817\n",
      "epoch: 3 step: 759, loss is 0.04564131423830986\n",
      "epoch: 3 step: 760, loss is 0.0038776923902332783\n",
      "epoch: 3 step: 761, loss is 0.07376151531934738\n",
      "epoch: 3 step: 762, loss is 0.003865043865516782\n",
      "epoch: 3 step: 763, loss is 0.06148931384086609\n",
      "epoch: 3 step: 764, loss is 0.10602512210607529\n",
      "epoch: 3 step: 765, loss is 0.06469230353832245\n",
      "epoch: 3 step: 766, loss is 0.0035057724453508854\n",
      "epoch: 3 step: 767, loss is 0.010167059488594532\n",
      "epoch: 3 step: 768, loss is 0.0549018494784832\n",
      "epoch: 3 step: 769, loss is 0.15657617151737213\n",
      "epoch: 3 step: 770, loss is 0.006021581590175629\n",
      "epoch: 3 step: 771, loss is 0.01620054803788662\n",
      "epoch: 3 step: 772, loss is 0.053812142461538315\n",
      "epoch: 3 step: 773, loss is 0.007925589568912983\n",
      "epoch: 3 step: 774, loss is 0.002778675640001893\n",
      "epoch: 3 step: 775, loss is 0.1440197229385376\n",
      "epoch: 3 step: 776, loss is 0.005925740581005812\n",
      "epoch: 3 step: 777, loss is 0.0010881656780838966\n",
      "epoch: 3 step: 778, loss is 0.07747413963079453\n",
      "epoch: 3 step: 779, loss is 0.05789104104042053\n",
      "epoch: 3 step: 780, loss is 0.00834419671446085\n",
      "epoch: 3 step: 781, loss is 0.0010240781120955944\n",
      "epoch: 3 step: 782, loss is 0.016764961183071136\n",
      "epoch: 3 step: 783, loss is 0.12387533485889435\n",
      "epoch: 3 step: 784, loss is 0.0036256888415664434\n",
      "epoch: 3 step: 785, loss is 0.03521187976002693\n",
      "epoch: 3 step: 786, loss is 0.09998679906129837\n",
      "epoch: 3 step: 787, loss is 0.02338925376534462\n",
      "epoch: 3 step: 788, loss is 0.010364037938416004\n",
      "epoch: 3 step: 789, loss is 0.12334581464529037\n",
      "epoch: 3 step: 790, loss is 0.024030623957514763\n",
      "epoch: 3 step: 791, loss is 0.05624045059084892\n",
      "epoch: 3 step: 792, loss is 0.07903515547513962\n",
      "epoch: 3 step: 793, loss is 0.016461392864584923\n",
      "epoch: 3 step: 794, loss is 0.008093515411019325\n",
      "epoch: 3 step: 795, loss is 0.04251720383763313\n",
      "epoch: 3 step: 796, loss is 0.004150316584855318\n",
      "epoch: 3 step: 797, loss is 0.033227261155843735\n",
      "epoch: 3 step: 798, loss is 0.052796620875597\n",
      "epoch: 3 step: 799, loss is 0.006482732482254505\n",
      "epoch: 3 step: 800, loss is 0.0012021261500194669\n",
      "epoch: 3 step: 801, loss is 0.004157065413892269\n",
      "epoch: 3 step: 802, loss is 0.26733076572418213\n",
      "epoch: 3 step: 803, loss is 0.07667092978954315\n",
      "epoch: 3 step: 804, loss is 0.061805013567209244\n",
      "epoch: 3 step: 805, loss is 0.01836276426911354\n",
      "epoch: 3 step: 806, loss is 0.018380723893642426\n",
      "epoch: 3 step: 807, loss is 0.001095016486942768\n",
      "epoch: 3 step: 808, loss is 0.012839563190937042\n",
      "epoch: 3 step: 809, loss is 0.03097766451537609\n",
      "epoch: 3 step: 810, loss is 0.01205037347972393\n",
      "epoch: 3 step: 811, loss is 0.0014373705489560962\n",
      "epoch: 3 step: 812, loss is 0.06830526888370514\n",
      "epoch: 3 step: 813, loss is 0.005231463350355625\n",
      "epoch: 3 step: 814, loss is 0.15106528997421265\n",
      "epoch: 3 step: 815, loss is 0.0021739588119089603\n",
      "epoch: 3 step: 816, loss is 0.006830557249486446\n",
      "epoch: 3 step: 817, loss is 0.28455716371536255\n",
      "epoch: 3 step: 818, loss is 0.013059940189123154\n",
      "epoch: 3 step: 819, loss is 0.0799427181482315\n",
      "epoch: 3 step: 820, loss is 0.010740314610302448\n",
      "epoch: 3 step: 821, loss is 0.054759640246629715\n",
      "epoch: 3 step: 822, loss is 0.010401872918009758\n",
      "epoch: 3 step: 823, loss is 0.016896327957510948\n",
      "epoch: 3 step: 824, loss is 0.0036731993313878775\n",
      "epoch: 3 step: 825, loss is 0.007789183408021927\n",
      "epoch: 3 step: 826, loss is 0.0027255117893218994\n",
      "epoch: 3 step: 827, loss is 0.0003068885998800397\n",
      "epoch: 3 step: 828, loss is 0.0038342252373695374\n",
      "epoch: 3 step: 829, loss is 0.09848909825086594\n",
      "epoch: 3 step: 830, loss is 0.15217477083206177\n",
      "epoch: 3 step: 831, loss is 0.006202214863151312\n",
      "epoch: 3 step: 832, loss is 0.014171932823956013\n",
      "epoch: 3 step: 833, loss is 0.013621816411614418\n",
      "epoch: 3 step: 834, loss is 0.05929131805896759\n",
      "epoch: 3 step: 835, loss is 0.04071883484721184\n",
      "epoch: 3 step: 836, loss is 0.10165653377771378\n",
      "epoch: 3 step: 837, loss is 0.11416700482368469\n",
      "epoch: 3 step: 838, loss is 0.08031307905912399\n",
      "epoch: 3 step: 839, loss is 0.009936087764799595\n",
      "epoch: 3 step: 840, loss is 0.010008145123720169\n",
      "epoch: 3 step: 841, loss is 0.13941438496112823\n",
      "epoch: 3 step: 842, loss is 0.011302564293146133\n",
      "epoch: 3 step: 843, loss is 0.010092658922076225\n",
      "epoch: 3 step: 844, loss is 0.0004772419633809477\n",
      "epoch: 3 step: 845, loss is 0.000949005305301398\n",
      "epoch: 3 step: 846, loss is 0.0050895302556455135\n",
      "epoch: 3 step: 847, loss is 0.03723062202334404\n",
      "epoch: 3 step: 848, loss is 0.02321224845945835\n",
      "epoch: 3 step: 849, loss is 0.0024031605571508408\n",
      "epoch: 3 step: 850, loss is 0.002597016980871558\n",
      "epoch: 3 step: 851, loss is 0.09555625915527344\n",
      "epoch: 3 step: 852, loss is 0.00832296721637249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 853, loss is 0.037725236266851425\n",
      "epoch: 3 step: 854, loss is 0.0083583053201437\n",
      "epoch: 3 step: 855, loss is 0.00995537731796503\n",
      "epoch: 3 step: 856, loss is 0.15349918603897095\n",
      "epoch: 3 step: 857, loss is 0.03812322020530701\n",
      "epoch: 3 step: 858, loss is 0.06575299799442291\n",
      "epoch: 3 step: 859, loss is 0.010337981395423412\n",
      "epoch: 3 step: 860, loss is 0.18081840872764587\n",
      "epoch: 3 step: 861, loss is 0.027174079790711403\n",
      "epoch: 3 step: 862, loss is 0.006381211802363396\n",
      "epoch: 3 step: 863, loss is 0.04423931986093521\n",
      "epoch: 3 step: 864, loss is 0.03765300661325455\n",
      "epoch: 3 step: 865, loss is 0.001320294919423759\n",
      "epoch: 3 step: 866, loss is 0.07551030069589615\n",
      "epoch: 3 step: 867, loss is 0.029772166162729263\n",
      "epoch: 3 step: 868, loss is 0.058538634330034256\n",
      "epoch: 3 step: 869, loss is 0.012069160118699074\n",
      "epoch: 3 step: 870, loss is 0.17873333394527435\n",
      "epoch: 3 step: 871, loss is 0.04197843372821808\n",
      "epoch: 3 step: 872, loss is 0.10413806140422821\n",
      "epoch: 3 step: 873, loss is 0.003309021471068263\n",
      "epoch: 3 step: 874, loss is 0.17282642424106598\n",
      "epoch: 3 step: 875, loss is 0.011738101951777935\n",
      "epoch: 3 step: 876, loss is 0.009613066911697388\n",
      "epoch: 3 step: 877, loss is 0.006202045828104019\n",
      "epoch: 3 step: 878, loss is 0.005784796550869942\n",
      "epoch: 3 step: 879, loss is 0.0008319119224324822\n",
      "epoch: 3 step: 880, loss is 0.06902530044317245\n",
      "epoch: 3 step: 881, loss is 0.002209792146459222\n",
      "epoch: 3 step: 882, loss is 0.009295900352299213\n",
      "epoch: 3 step: 883, loss is 0.009921329095959663\n",
      "epoch: 3 step: 884, loss is 0.07699357718229294\n",
      "epoch: 3 step: 885, loss is 0.09089038521051407\n",
      "epoch: 3 step: 886, loss is 0.06583812832832336\n",
      "epoch: 3 step: 887, loss is 0.10074778646230698\n",
      "epoch: 3 step: 888, loss is 0.03150331601500511\n",
      "epoch: 3 step: 889, loss is 0.04923591762781143\n",
      "epoch: 3 step: 890, loss is 0.0015961090102791786\n",
      "epoch: 3 step: 891, loss is 0.11939624696969986\n",
      "epoch: 3 step: 892, loss is 0.00038839629269205034\n",
      "epoch: 3 step: 893, loss is 0.018677065148949623\n",
      "epoch: 3 step: 894, loss is 0.041230835020542145\n",
      "epoch: 3 step: 895, loss is 0.06304414570331573\n",
      "epoch: 3 step: 896, loss is 0.0019092331640422344\n",
      "epoch: 3 step: 897, loss is 0.08584293723106384\n",
      "epoch: 3 step: 898, loss is 0.00551501102745533\n",
      "epoch: 3 step: 899, loss is 0.0009496085112914443\n",
      "epoch: 3 step: 900, loss is 0.16048043966293335\n",
      "epoch: 3 step: 901, loss is 0.14557881653308868\n",
      "epoch: 3 step: 902, loss is 0.0006561446934938431\n",
      "epoch: 3 step: 903, loss is 0.1605716347694397\n",
      "epoch: 3 step: 904, loss is 0.174264594912529\n",
      "epoch: 3 step: 905, loss is 0.02025965228676796\n",
      "epoch: 3 step: 906, loss is 0.021457510069012642\n",
      "epoch: 3 step: 907, loss is 0.03454659506678581\n",
      "epoch: 3 step: 908, loss is 0.003497292986139655\n",
      "epoch: 3 step: 909, loss is 0.1977529525756836\n",
      "epoch: 3 step: 910, loss is 0.004851494450122118\n",
      "epoch: 3 step: 911, loss is 0.04475382715463638\n",
      "epoch: 3 step: 912, loss is 0.0968896746635437\n",
      "epoch: 3 step: 913, loss is 0.1737501472234726\n",
      "epoch: 3 step: 914, loss is 0.12786749005317688\n",
      "epoch: 3 step: 915, loss is 0.07160069048404694\n",
      "epoch: 3 step: 916, loss is 0.0014550620689988136\n",
      "epoch: 3 step: 917, loss is 0.05573273450136185\n",
      "epoch: 3 step: 918, loss is 0.0033551764208823442\n",
      "epoch: 3 step: 919, loss is 0.017581287771463394\n",
      "epoch: 3 step: 920, loss is 0.004972997587174177\n",
      "epoch: 3 step: 921, loss is 0.005901598371565342\n",
      "epoch: 3 step: 922, loss is 0.012794449925422668\n",
      "epoch: 3 step: 923, loss is 0.008887803182005882\n",
      "epoch: 3 step: 924, loss is 0.038102682679891586\n",
      "epoch: 3 step: 925, loss is 0.2900601625442505\n",
      "epoch: 3 step: 926, loss is 0.0018983694026246667\n",
      "epoch: 3 step: 927, loss is 0.10037362575531006\n",
      "epoch: 3 step: 928, loss is 0.00357440416701138\n",
      "epoch: 3 step: 929, loss is 0.022159438580274582\n",
      "epoch: 3 step: 930, loss is 0.08559821546077728\n",
      "epoch: 3 step: 931, loss is 0.035426873713731766\n",
      "epoch: 3 step: 932, loss is 0.030032653361558914\n",
      "epoch: 3 step: 933, loss is 0.004087618552148342\n",
      "epoch: 3 step: 934, loss is 0.001214833464473486\n",
      "epoch: 3 step: 935, loss is 0.01569417491555214\n",
      "epoch: 3 step: 936, loss is 0.2279815524816513\n",
      "epoch: 3 step: 937, loss is 0.00416033947840333\n",
      "epoch: 3 step: 938, loss is 0.023578621447086334\n",
      "epoch: 3 step: 939, loss is 0.015645956620573997\n",
      "epoch: 3 step: 940, loss is 0.02433294989168644\n",
      "epoch: 3 step: 941, loss is 0.0021488263737410307\n",
      "epoch: 3 step: 942, loss is 0.0039047389291226864\n",
      "epoch: 3 step: 943, loss is 0.020171305164694786\n",
      "epoch: 3 step: 944, loss is 0.009286205284297466\n",
      "epoch: 3 step: 945, loss is 0.008084379136562347\n",
      "epoch: 3 step: 946, loss is 0.17962022125720978\n",
      "epoch: 3 step: 947, loss is 0.003985942341387272\n",
      "epoch: 3 step: 948, loss is 0.0035020383074879646\n",
      "epoch: 3 step: 949, loss is 0.051386911422014236\n",
      "epoch: 3 step: 950, loss is 0.013554323464632034\n",
      "epoch: 3 step: 951, loss is 0.011101731099188328\n",
      "epoch: 3 step: 952, loss is 0.006497987546026707\n",
      "epoch: 3 step: 953, loss is 0.003805864602327347\n",
      "epoch: 3 step: 954, loss is 0.004425970371812582\n",
      "epoch: 3 step: 955, loss is 0.026051681488752365\n",
      "epoch: 3 step: 956, loss is 0.05032036826014519\n",
      "epoch: 3 step: 957, loss is 0.012004554271697998\n",
      "epoch: 3 step: 958, loss is 0.01093983743339777\n",
      "epoch: 3 step: 959, loss is 0.0705045759677887\n",
      "epoch: 3 step: 960, loss is 0.10757660865783691\n",
      "epoch: 3 step: 961, loss is 0.06432903558015823\n",
      "epoch: 3 step: 962, loss is 0.0013374679256230593\n",
      "epoch: 3 step: 963, loss is 0.0030810267198830843\n",
      "epoch: 3 step: 964, loss is 0.02470364235341549\n",
      "epoch: 3 step: 965, loss is 0.04992881044745445\n",
      "epoch: 3 step: 966, loss is 0.10970872640609741\n",
      "epoch: 3 step: 967, loss is 0.07340388745069504\n",
      "epoch: 3 step: 968, loss is 0.05606634169816971\n",
      "epoch: 3 step: 969, loss is 0.005951036233454943\n",
      "epoch: 3 step: 970, loss is 0.07473296672105789\n",
      "epoch: 3 step: 971, loss is 0.0014524292200803757\n",
      "epoch: 3 step: 972, loss is 0.005066392477601767\n",
      "epoch: 3 step: 973, loss is 0.01550841424614191\n",
      "epoch: 3 step: 974, loss is 0.013799288310110569\n",
      "epoch: 3 step: 975, loss is 0.002130956621840596\n",
      "epoch: 3 step: 976, loss is 0.0013246072921901941\n",
      "epoch: 3 step: 977, loss is 0.02716323360800743\n",
      "epoch: 3 step: 978, loss is 0.00018436207028571516\n",
      "epoch: 3 step: 979, loss is 0.03740676864981651\n",
      "epoch: 3 step: 980, loss is 0.04360686242580414\n",
      "epoch: 3 step: 981, loss is 0.002487449673935771\n",
      "epoch: 3 step: 982, loss is 0.005059913266450167\n",
      "epoch: 3 step: 983, loss is 0.023701781406998634\n",
      "epoch: 3 step: 984, loss is 0.08498424291610718\n",
      "epoch: 3 step: 985, loss is 0.0009092259570024908\n",
      "epoch: 3 step: 986, loss is 0.022601941600441933\n",
      "epoch: 3 step: 987, loss is 0.03493055701255798\n",
      "epoch: 3 step: 988, loss is 0.0019977728370577097\n",
      "epoch: 3 step: 989, loss is 0.0021016693208366632\n",
      "epoch: 3 step: 990, loss is 0.005603634752333164\n",
      "epoch: 3 step: 991, loss is 0.0022288078907877207\n",
      "epoch: 3 step: 992, loss is 0.004211218561977148\n",
      "epoch: 3 step: 993, loss is 0.006368786562234163\n",
      "epoch: 3 step: 994, loss is 0.07865588366985321\n",
      "epoch: 3 step: 995, loss is 0.05279541015625\n",
      "epoch: 3 step: 996, loss is 0.008656480349600315\n",
      "epoch: 3 step: 997, loss is 0.036723196506500244\n",
      "epoch: 3 step: 998, loss is 0.002702312543988228\n",
      "epoch: 3 step: 999, loss is 0.0632866621017456\n",
      "epoch: 3 step: 1000, loss is 0.15762868523597717\n",
      "epoch: 3 step: 1001, loss is 0.029652385041117668\n",
      "epoch: 3 step: 1002, loss is 0.04698282852768898\n",
      "epoch: 3 step: 1003, loss is 0.0008635006379336119\n",
      "epoch: 3 step: 1004, loss is 0.0003224709362257272\n",
      "epoch: 3 step: 1005, loss is 0.0190324354916811\n",
      "epoch: 3 step: 1006, loss is 0.0023468334693461657\n",
      "epoch: 3 step: 1007, loss is 0.11399489641189575\n",
      "epoch: 3 step: 1008, loss is 0.03849337249994278\n",
      "epoch: 3 step: 1009, loss is 0.05904100462794304\n",
      "epoch: 3 step: 1010, loss is 0.034600671380758286\n",
      "epoch: 3 step: 1011, loss is 0.19941766560077667\n",
      "epoch: 3 step: 1012, loss is 0.003991270903497934\n",
      "epoch: 3 step: 1013, loss is 0.0333307683467865\n",
      "epoch: 3 step: 1014, loss is 0.0014849876752123237\n",
      "epoch: 3 step: 1015, loss is 0.0005772418226115406\n",
      "epoch: 3 step: 1016, loss is 0.00045027208398096263\n",
      "epoch: 3 step: 1017, loss is 0.06972488015890121\n",
      "epoch: 3 step: 1018, loss is 0.01065721083432436\n",
      "epoch: 3 step: 1019, loss is 0.032383281737565994\n",
      "epoch: 3 step: 1020, loss is 0.11954302340745926\n",
      "epoch: 3 step: 1021, loss is 0.0044525014236569405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1022, loss is 0.021007653325796127\n",
      "epoch: 3 step: 1023, loss is 0.0908132940530777\n",
      "epoch: 3 step: 1024, loss is 0.0061357757076621056\n",
      "epoch: 3 step: 1025, loss is 0.14178109169006348\n",
      "epoch: 3 step: 1026, loss is 0.07802054286003113\n",
      "epoch: 3 step: 1027, loss is 0.02298269420862198\n",
      "epoch: 3 step: 1028, loss is 0.0913018211722374\n",
      "epoch: 3 step: 1029, loss is 0.0054339515045285225\n",
      "epoch: 3 step: 1030, loss is 0.0006179005140438676\n",
      "epoch: 3 step: 1031, loss is 0.021559130400419235\n",
      "epoch: 3 step: 1032, loss is 0.00031708282767795026\n",
      "epoch: 3 step: 1033, loss is 0.020025478675961494\n",
      "epoch: 3 step: 1034, loss is 0.041118960827589035\n",
      "epoch: 3 step: 1035, loss is 0.000986415077932179\n",
      "epoch: 3 step: 1036, loss is 0.1777959167957306\n",
      "epoch: 3 step: 1037, loss is 0.0004770101513713598\n",
      "epoch: 3 step: 1038, loss is 0.022588100284337997\n",
      "epoch: 3 step: 1039, loss is 0.00019769376376643777\n",
      "epoch: 3 step: 1040, loss is 0.001766496803611517\n",
      "epoch: 3 step: 1041, loss is 0.02099352329969406\n",
      "epoch: 3 step: 1042, loss is 0.004418179392814636\n",
      "epoch: 3 step: 1043, loss is 0.002369802910834551\n",
      "epoch: 3 step: 1044, loss is 0.002520656678825617\n",
      "epoch: 3 step: 1045, loss is 0.0005123352748341858\n",
      "epoch: 3 step: 1046, loss is 0.0177850890904665\n",
      "epoch: 3 step: 1047, loss is 0.018346747383475304\n",
      "epoch: 3 step: 1048, loss is 0.00043651042506098747\n",
      "epoch: 3 step: 1049, loss is 0.04551861435174942\n",
      "epoch: 3 step: 1050, loss is 0.010160742327570915\n",
      "epoch: 3 step: 1051, loss is 0.0008108032052405179\n",
      "epoch: 3 step: 1052, loss is 0.017334138974547386\n",
      "epoch: 3 step: 1053, loss is 0.008563423529267311\n",
      "epoch: 3 step: 1054, loss is 0.18167047202587128\n",
      "epoch: 3 step: 1055, loss is 0.002507499884814024\n",
      "epoch: 3 step: 1056, loss is 0.0023648180067539215\n",
      "epoch: 3 step: 1057, loss is 0.004626750014722347\n",
      "epoch: 3 step: 1058, loss is 0.0028893619310110807\n",
      "epoch: 3 step: 1059, loss is 0.0021376393269747496\n",
      "epoch: 3 step: 1060, loss is 0.031604569405317307\n",
      "epoch: 3 step: 1061, loss is 0.03876470774412155\n",
      "epoch: 3 step: 1062, loss is 0.17761489748954773\n",
      "epoch: 3 step: 1063, loss is 0.02020588144659996\n",
      "epoch: 3 step: 1064, loss is 0.016209814697504044\n",
      "epoch: 3 step: 1065, loss is 0.00015668068954255432\n",
      "epoch: 3 step: 1066, loss is 0.12348471581935883\n",
      "epoch: 3 step: 1067, loss is 0.06600339710712433\n",
      "epoch: 3 step: 1068, loss is 0.054206911474466324\n",
      "epoch: 3 step: 1069, loss is 0.000981460209004581\n",
      "epoch: 3 step: 1070, loss is 0.019114000722765923\n",
      "epoch: 3 step: 1071, loss is 0.06501438468694687\n",
      "epoch: 3 step: 1072, loss is 0.15295183658599854\n",
      "epoch: 3 step: 1073, loss is 0.04269896820187569\n",
      "epoch: 3 step: 1074, loss is 0.061264265328645706\n",
      "epoch: 3 step: 1075, loss is 0.000370197172742337\n",
      "epoch: 3 step: 1076, loss is 0.010916467756032944\n",
      "epoch: 3 step: 1077, loss is 0.034320492297410965\n",
      "epoch: 3 step: 1078, loss is 0.11474683880805969\n",
      "epoch: 3 step: 1079, loss is 0.003596697933971882\n",
      "epoch: 3 step: 1080, loss is 0.0019568109419196844\n",
      "epoch: 3 step: 1081, loss is 0.031220072880387306\n",
      "epoch: 3 step: 1082, loss is 0.12302063405513763\n",
      "epoch: 3 step: 1083, loss is 0.08222122490406036\n",
      "epoch: 3 step: 1084, loss is 0.0007357000722549856\n",
      "epoch: 3 step: 1085, loss is 0.0031027894001454115\n",
      "epoch: 3 step: 1086, loss is 0.016527779400348663\n",
      "epoch: 3 step: 1087, loss is 0.016581568866968155\n",
      "epoch: 3 step: 1088, loss is 0.12602588534355164\n",
      "epoch: 3 step: 1089, loss is 0.0037757272366434336\n",
      "epoch: 3 step: 1090, loss is 0.013928242027759552\n",
      "epoch: 3 step: 1091, loss is 0.04810493439435959\n",
      "epoch: 3 step: 1092, loss is 0.0010638561798259616\n",
      "epoch: 3 step: 1093, loss is 0.00044314496335573494\n",
      "epoch: 3 step: 1094, loss is 0.0019493467407301068\n",
      "epoch: 3 step: 1095, loss is 0.0020427850540727377\n",
      "epoch: 3 step: 1096, loss is 0.000776156724896282\n",
      "epoch: 3 step: 1097, loss is 0.002229266334325075\n",
      "epoch: 3 step: 1098, loss is 0.07311145216226578\n",
      "epoch: 3 step: 1099, loss is 0.10648141801357269\n",
      "epoch: 3 step: 1100, loss is 0.0025405671913176775\n",
      "epoch: 3 step: 1101, loss is 0.0013341150479391217\n",
      "epoch: 3 step: 1102, loss is 0.00794654805213213\n",
      "epoch: 3 step: 1103, loss is 0.019034279510378838\n",
      "epoch: 3 step: 1104, loss is 0.0011993983061984181\n",
      "epoch: 3 step: 1105, loss is 0.012760505080223083\n",
      "epoch: 3 step: 1106, loss is 0.007061452139168978\n",
      "epoch: 3 step: 1107, loss is 0.006791921332478523\n",
      "epoch: 3 step: 1108, loss is 0.1830720156431198\n",
      "epoch: 3 step: 1109, loss is 0.0013716520043089986\n",
      "epoch: 3 step: 1110, loss is 0.09814778715372086\n",
      "epoch: 3 step: 1111, loss is 0.07438929378986359\n",
      "epoch: 3 step: 1112, loss is 0.003959896508604288\n",
      "epoch: 3 step: 1113, loss is 0.02644617110490799\n",
      "epoch: 3 step: 1114, loss is 0.03061569668352604\n",
      "epoch: 3 step: 1115, loss is 0.27462705969810486\n",
      "epoch: 3 step: 1116, loss is 0.016806481406092644\n",
      "epoch: 3 step: 1117, loss is 0.011793247424066067\n",
      "epoch: 3 step: 1118, loss is 0.009080516174435616\n",
      "epoch: 3 step: 1119, loss is 0.0009806986199691892\n",
      "epoch: 3 step: 1120, loss is 0.0018626756500452757\n",
      "epoch: 3 step: 1121, loss is 0.025736432522535324\n",
      "epoch: 3 step: 1122, loss is 0.08128340542316437\n",
      "epoch: 3 step: 1123, loss is 0.007771298289299011\n",
      "epoch: 3 step: 1124, loss is 0.007304659113287926\n",
      "epoch: 3 step: 1125, loss is 0.01850784569978714\n",
      "epoch: 3 step: 1126, loss is 0.0214002076536417\n",
      "epoch: 3 step: 1127, loss is 0.004960107617080212\n",
      "epoch: 3 step: 1128, loss is 0.0027020012494176626\n",
      "epoch: 3 step: 1129, loss is 0.009352616965770721\n",
      "epoch: 3 step: 1130, loss is 0.0033472105860710144\n",
      "epoch: 3 step: 1131, loss is 0.055500589311122894\n",
      "epoch: 3 step: 1132, loss is 0.022997183725237846\n",
      "epoch: 3 step: 1133, loss is 0.004553587641566992\n",
      "epoch: 3 step: 1134, loss is 0.09964058548212051\n",
      "epoch: 3 step: 1135, loss is 0.2447056770324707\n",
      "epoch: 3 step: 1136, loss is 0.016648270189762115\n",
      "epoch: 3 step: 1137, loss is 0.0023768788669258356\n",
      "epoch: 3 step: 1138, loss is 0.0036380805540829897\n",
      "epoch: 3 step: 1139, loss is 0.009458096697926521\n",
      "epoch: 3 step: 1140, loss is 0.0074883936904370785\n",
      "epoch: 3 step: 1141, loss is 0.043781690299510956\n",
      "epoch: 3 step: 1142, loss is 0.03683757036924362\n",
      "epoch: 3 step: 1143, loss is 0.005097218789160252\n",
      "epoch: 3 step: 1144, loss is 0.006765054538846016\n",
      "epoch: 3 step: 1145, loss is 0.05276472121477127\n",
      "epoch: 3 step: 1146, loss is 0.17020615935325623\n",
      "epoch: 3 step: 1147, loss is 0.0026072231121361256\n",
      "epoch: 3 step: 1148, loss is 0.0013271807692945004\n",
      "epoch: 3 step: 1149, loss is 0.07922132313251495\n",
      "epoch: 3 step: 1150, loss is 0.1881117969751358\n",
      "epoch: 3 step: 1151, loss is 0.17388659715652466\n",
      "epoch: 3 step: 1152, loss is 0.01984037645161152\n",
      "epoch: 3 step: 1153, loss is 0.005423954222351313\n",
      "epoch: 3 step: 1154, loss is 0.012746206484735012\n",
      "epoch: 3 step: 1155, loss is 0.015118297189474106\n",
      "epoch: 3 step: 1156, loss is 0.08166272193193436\n",
      "epoch: 3 step: 1157, loss is 0.03366689383983612\n",
      "epoch: 3 step: 1158, loss is 0.0011582679580897093\n",
      "epoch: 3 step: 1159, loss is 0.08456294983625412\n",
      "epoch: 3 step: 1160, loss is 0.04727397486567497\n",
      "epoch: 3 step: 1161, loss is 0.09578222036361694\n",
      "epoch: 3 step: 1162, loss is 0.13486507534980774\n",
      "epoch: 3 step: 1163, loss is 0.002091066911816597\n",
      "epoch: 3 step: 1164, loss is 0.1197463646531105\n",
      "epoch: 3 step: 1165, loss is 0.002468396443873644\n",
      "epoch: 3 step: 1166, loss is 0.06156863644719124\n",
      "epoch: 3 step: 1167, loss is 0.0369054451584816\n",
      "epoch: 3 step: 1168, loss is 0.019211651757359505\n",
      "epoch: 3 step: 1169, loss is 0.10095151513814926\n",
      "epoch: 3 step: 1170, loss is 0.04771992564201355\n",
      "epoch: 3 step: 1171, loss is 0.04401742294430733\n",
      "epoch: 3 step: 1172, loss is 0.011329900473356247\n",
      "epoch: 3 step: 1173, loss is 0.05159131437540054\n",
      "epoch: 3 step: 1174, loss is 0.019992578774690628\n",
      "epoch: 3 step: 1175, loss is 0.0044461688958108425\n",
      "epoch: 3 step: 1176, loss is 0.07855966687202454\n",
      "epoch: 3 step: 1177, loss is 0.0037338973488658667\n",
      "epoch: 3 step: 1178, loss is 0.016678161919116974\n",
      "epoch: 3 step: 1179, loss is 0.18182916939258575\n",
      "epoch: 3 step: 1180, loss is 0.006856262683868408\n",
      "epoch: 3 step: 1181, loss is 0.008293692022562027\n",
      "epoch: 3 step: 1182, loss is 0.06418625265359879\n",
      "epoch: 3 step: 1183, loss is 0.031206782907247543\n",
      "epoch: 3 step: 1184, loss is 0.010891511105000973\n",
      "epoch: 3 step: 1185, loss is 0.010166012682020664\n",
      "epoch: 3 step: 1186, loss is 0.028172409161925316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1187, loss is 0.0208006352186203\n",
      "epoch: 3 step: 1188, loss is 0.04671109467744827\n",
      "epoch: 3 step: 1189, loss is 0.003358513815328479\n",
      "epoch: 3 step: 1190, loss is 0.0029057443607598543\n",
      "epoch: 3 step: 1191, loss is 0.21044650673866272\n",
      "epoch: 3 step: 1192, loss is 0.022435711696743965\n",
      "epoch: 3 step: 1193, loss is 0.0014065655414015055\n",
      "epoch: 3 step: 1194, loss is 0.0239575058221817\n",
      "epoch: 3 step: 1195, loss is 0.034481264650821686\n",
      "epoch: 3 step: 1196, loss is 0.012953367084264755\n",
      "epoch: 3 step: 1197, loss is 0.004761064425110817\n",
      "epoch: 3 step: 1198, loss is 0.0032361745834350586\n",
      "epoch: 3 step: 1199, loss is 0.004015506710857153\n",
      "epoch: 3 step: 1200, loss is 0.058823831379413605\n",
      "epoch: 3 step: 1201, loss is 0.002661427715793252\n",
      "epoch: 3 step: 1202, loss is 0.0007970382575877011\n",
      "epoch: 3 step: 1203, loss is 0.0007395230932161212\n",
      "epoch: 3 step: 1204, loss is 0.008518454618752003\n",
      "epoch: 3 step: 1205, loss is 0.008047659881412983\n",
      "epoch: 3 step: 1206, loss is 0.10002944618463516\n",
      "epoch: 3 step: 1207, loss is 0.003809866728261113\n",
      "epoch: 3 step: 1208, loss is 0.06196220591664314\n",
      "epoch: 3 step: 1209, loss is 0.23131485283374786\n",
      "epoch: 3 step: 1210, loss is 0.0031347349286079407\n",
      "epoch: 3 step: 1211, loss is 0.0030166024807840586\n",
      "epoch: 3 step: 1212, loss is 0.04107073321938515\n",
      "epoch: 3 step: 1213, loss is 0.11168842017650604\n",
      "epoch: 3 step: 1214, loss is 0.003975339699536562\n",
      "epoch: 3 step: 1215, loss is 0.008652038872241974\n",
      "epoch: 3 step: 1216, loss is 0.01976950839161873\n",
      "epoch: 3 step: 1217, loss is 0.058142390102148056\n",
      "epoch: 3 step: 1218, loss is 0.015040326863527298\n",
      "epoch: 3 step: 1219, loss is 0.08385936915874481\n",
      "epoch: 3 step: 1220, loss is 0.0323331356048584\n",
      "epoch: 3 step: 1221, loss is 0.0008619838044978678\n",
      "epoch: 3 step: 1222, loss is 0.022858550772070885\n",
      "epoch: 3 step: 1223, loss is 0.0007345900521613657\n",
      "epoch: 3 step: 1224, loss is 0.011124992743134499\n",
      "epoch: 3 step: 1225, loss is 0.0008331193821504712\n",
      "epoch: 3 step: 1226, loss is 0.00791169237345457\n",
      "epoch: 3 step: 1227, loss is 0.014403588138520718\n",
      "epoch: 3 step: 1228, loss is 0.0017879193183034658\n",
      "epoch: 3 step: 1229, loss is 0.039454713463783264\n",
      "epoch: 3 step: 1230, loss is 0.0054636672139167786\n",
      "epoch: 3 step: 1231, loss is 0.10529554635286331\n",
      "epoch: 3 step: 1232, loss is 0.03870363160967827\n",
      "epoch: 3 step: 1233, loss is 0.0008140124846249819\n",
      "epoch: 3 step: 1234, loss is 0.03315568342804909\n",
      "epoch: 3 step: 1235, loss is 0.08065228164196014\n",
      "epoch: 3 step: 1236, loss is 0.18053537607192993\n",
      "epoch: 3 step: 1237, loss is 0.002293236553668976\n",
      "epoch: 3 step: 1238, loss is 0.0002905102155636996\n",
      "epoch: 3 step: 1239, loss is 0.01782131753861904\n",
      "epoch: 3 step: 1240, loss is 0.06811588257551193\n",
      "epoch: 3 step: 1241, loss is 0.0010188486194238067\n",
      "epoch: 3 step: 1242, loss is 0.01983402669429779\n",
      "epoch: 3 step: 1243, loss is 0.17017224431037903\n",
      "epoch: 3 step: 1244, loss is 0.052842289209365845\n",
      "epoch: 3 step: 1245, loss is 0.016634244471788406\n",
      "epoch: 3 step: 1246, loss is 0.03346925973892212\n",
      "epoch: 3 step: 1247, loss is 0.15274712443351746\n",
      "epoch: 3 step: 1248, loss is 0.07462096214294434\n",
      "epoch: 3 step: 1249, loss is 0.024305198341608047\n",
      "epoch: 3 step: 1250, loss is 0.03948584571480751\n",
      "epoch: 3 step: 1251, loss is 0.08387695997953415\n",
      "epoch: 3 step: 1252, loss is 0.014382155612111092\n",
      "epoch: 3 step: 1253, loss is 0.01281209196895361\n",
      "epoch: 3 step: 1254, loss is 0.01919942907989025\n",
      "epoch: 3 step: 1255, loss is 0.00025004122289828956\n",
      "epoch: 3 step: 1256, loss is 0.012705978937447071\n",
      "epoch: 3 step: 1257, loss is 0.01841399446129799\n",
      "epoch: 3 step: 1258, loss is 0.029481250792741776\n",
      "epoch: 3 step: 1259, loss is 0.10330606997013092\n",
      "epoch: 3 step: 1260, loss is 0.01286326814442873\n",
      "epoch: 3 step: 1261, loss is 0.015522425994277\n",
      "epoch: 3 step: 1262, loss is 0.08607606589794159\n",
      "epoch: 3 step: 1263, loss is 0.16904738545417786\n",
      "epoch: 3 step: 1264, loss is 0.04620002955198288\n",
      "epoch: 3 step: 1265, loss is 0.009443609043955803\n",
      "epoch: 3 step: 1266, loss is 0.0021660267375409603\n",
      "epoch: 3 step: 1267, loss is 0.0005643775803036988\n",
      "epoch: 3 step: 1268, loss is 0.06249874085187912\n",
      "epoch: 3 step: 1269, loss is 0.0031262387055903673\n",
      "epoch: 3 step: 1270, loss is 0.10514049232006073\n",
      "epoch: 3 step: 1271, loss is 0.006652400828897953\n",
      "epoch: 3 step: 1272, loss is 0.002265019342303276\n",
      "epoch: 3 step: 1273, loss is 0.12272380292415619\n",
      "epoch: 3 step: 1274, loss is 0.0036672342102974653\n",
      "epoch: 3 step: 1275, loss is 0.1707996428012848\n",
      "epoch: 3 step: 1276, loss is 0.0038027106784284115\n",
      "epoch: 3 step: 1277, loss is 0.07761656492948532\n",
      "epoch: 3 step: 1278, loss is 0.008007090538740158\n",
      "epoch: 3 step: 1279, loss is 0.076043039560318\n",
      "epoch: 3 step: 1280, loss is 0.042810820043087006\n",
      "epoch: 3 step: 1281, loss is 0.028626184910535812\n",
      "epoch: 3 step: 1282, loss is 0.019541466608643532\n",
      "epoch: 3 step: 1283, loss is 0.002996345516294241\n",
      "epoch: 3 step: 1284, loss is 0.07324947416782379\n",
      "epoch: 3 step: 1285, loss is 0.021488556638360023\n",
      "epoch: 3 step: 1286, loss is 0.0016196968499571085\n",
      "epoch: 3 step: 1287, loss is 0.001919272355735302\n",
      "epoch: 3 step: 1288, loss is 0.018617145717144012\n",
      "epoch: 3 step: 1289, loss is 0.01099914126098156\n",
      "epoch: 3 step: 1290, loss is 0.001600470975972712\n",
      "epoch: 3 step: 1291, loss is 0.049357734620571136\n",
      "epoch: 3 step: 1292, loss is 0.10357719659805298\n",
      "epoch: 3 step: 1293, loss is 0.0406072698533535\n",
      "epoch: 3 step: 1294, loss is 0.00508430041372776\n",
      "epoch: 3 step: 1295, loss is 0.11809854954481125\n",
      "epoch: 3 step: 1296, loss is 0.05933534726500511\n",
      "epoch: 3 step: 1297, loss is 0.05276757851243019\n",
      "epoch: 3 step: 1298, loss is 0.004304173868149519\n",
      "epoch: 3 step: 1299, loss is 0.048767633736133575\n",
      "epoch: 3 step: 1300, loss is 0.0036090004723519087\n",
      "epoch: 3 step: 1301, loss is 0.00048674739082343876\n",
      "epoch: 3 step: 1302, loss is 0.0018745741108432412\n",
      "epoch: 3 step: 1303, loss is 0.012123554944992065\n",
      "epoch: 3 step: 1304, loss is 0.0025796203408390284\n",
      "epoch: 3 step: 1305, loss is 0.011819230392575264\n",
      "epoch: 3 step: 1306, loss is 0.11790067702531815\n",
      "epoch: 3 step: 1307, loss is 0.06436687707901001\n",
      "epoch: 3 step: 1308, loss is 0.05441303178668022\n",
      "epoch: 3 step: 1309, loss is 0.0036654751747846603\n",
      "epoch: 3 step: 1310, loss is 0.00021736470807809383\n",
      "epoch: 3 step: 1311, loss is 0.02321380376815796\n",
      "epoch: 3 step: 1312, loss is 0.007011973299086094\n",
      "epoch: 3 step: 1313, loss is 0.03484524041414261\n",
      "epoch: 3 step: 1314, loss is 0.07830006629228592\n",
      "epoch: 3 step: 1315, loss is 0.011074673384428024\n",
      "epoch: 3 step: 1316, loss is 0.018369605764746666\n",
      "epoch: 3 step: 1317, loss is 0.3328806459903717\n",
      "epoch: 3 step: 1318, loss is 0.10165046900510788\n",
      "epoch: 3 step: 1319, loss is 0.03048456460237503\n",
      "epoch: 3 step: 1320, loss is 0.24112489819526672\n",
      "epoch: 3 step: 1321, loss is 0.00032868707785382867\n",
      "epoch: 3 step: 1322, loss is 0.2387085258960724\n",
      "epoch: 3 step: 1323, loss is 0.008603472262620926\n",
      "epoch: 3 step: 1324, loss is 0.35952866077423096\n",
      "epoch: 3 step: 1325, loss is 0.0278632752597332\n",
      "epoch: 3 step: 1326, loss is 0.0076384288258850574\n",
      "epoch: 3 step: 1327, loss is 0.0029342682100832462\n",
      "epoch: 3 step: 1328, loss is 0.1402566134929657\n",
      "epoch: 3 step: 1329, loss is 0.0006702999235130847\n",
      "epoch: 3 step: 1330, loss is 0.14952224493026733\n",
      "epoch: 3 step: 1331, loss is 0.05160629749298096\n",
      "epoch: 3 step: 1332, loss is 0.059879761189222336\n",
      "epoch: 3 step: 1333, loss is 0.0030120632145553827\n",
      "epoch: 3 step: 1334, loss is 0.0051800888031721115\n",
      "epoch: 3 step: 1335, loss is 0.0041016824543476105\n",
      "epoch: 3 step: 1336, loss is 0.00937140267342329\n",
      "epoch: 3 step: 1337, loss is 0.001864720368757844\n",
      "epoch: 3 step: 1338, loss is 0.0009593346621841192\n",
      "epoch: 3 step: 1339, loss is 0.18280385434627533\n",
      "epoch: 3 step: 1340, loss is 0.004207560792565346\n",
      "epoch: 3 step: 1341, loss is 0.04263360798358917\n",
      "epoch: 3 step: 1342, loss is 0.018079956993460655\n",
      "epoch: 3 step: 1343, loss is 0.049688730388879776\n",
      "epoch: 3 step: 1344, loss is 0.10635294765233994\n",
      "epoch: 3 step: 1345, loss is 0.0034788204357028008\n",
      "epoch: 3 step: 1346, loss is 0.012893696315586567\n",
      "epoch: 3 step: 1347, loss is 0.0034420073498040438\n",
      "epoch: 3 step: 1348, loss is 0.03716282546520233\n",
      "epoch: 3 step: 1349, loss is 0.0048212152905762196\n",
      "epoch: 3 step: 1350, loss is 0.00279247690923512\n",
      "epoch: 3 step: 1351, loss is 0.0557674877345562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1352, loss is 0.006703004706650972\n",
      "epoch: 3 step: 1353, loss is 0.04506947472691536\n",
      "epoch: 3 step: 1354, loss is 0.12666265666484833\n",
      "epoch: 3 step: 1355, loss is 0.0013754728715866804\n",
      "epoch: 3 step: 1356, loss is 0.02355150505900383\n",
      "epoch: 3 step: 1357, loss is 0.06736711412668228\n",
      "epoch: 3 step: 1358, loss is 0.011998919770121574\n",
      "epoch: 3 step: 1359, loss is 0.019648773595690727\n",
      "epoch: 3 step: 1360, loss is 0.09915770590305328\n",
      "epoch: 3 step: 1361, loss is 0.061261583119630814\n",
      "epoch: 3 step: 1362, loss is 0.005027439445257187\n",
      "epoch: 3 step: 1363, loss is 0.02357127144932747\n",
      "epoch: 3 step: 1364, loss is 0.005945321638137102\n",
      "epoch: 3 step: 1365, loss is 0.2703690826892853\n",
      "epoch: 3 step: 1366, loss is 0.0018517294665798545\n",
      "epoch: 3 step: 1367, loss is 0.1329013556241989\n",
      "epoch: 3 step: 1368, loss is 0.049320466816425323\n",
      "epoch: 3 step: 1369, loss is 0.005045711062848568\n",
      "epoch: 3 step: 1370, loss is 0.0011845326516777277\n",
      "epoch: 3 step: 1371, loss is 0.2038552463054657\n",
      "epoch: 3 step: 1372, loss is 0.012024655938148499\n",
      "epoch: 3 step: 1373, loss is 0.005269787274301052\n",
      "epoch: 3 step: 1374, loss is 0.01545611210167408\n",
      "epoch: 3 step: 1375, loss is 0.004523599054664373\n",
      "epoch: 3 step: 1376, loss is 0.008132530376315117\n",
      "epoch: 3 step: 1377, loss is 0.009631689637899399\n",
      "epoch: 3 step: 1378, loss is 0.003359593218192458\n",
      "epoch: 3 step: 1379, loss is 0.0003476549172773957\n",
      "epoch: 3 step: 1380, loss is 0.167741596698761\n",
      "epoch: 3 step: 1381, loss is 0.005719244945794344\n",
      "epoch: 3 step: 1382, loss is 0.01122990157455206\n",
      "epoch: 3 step: 1383, loss is 0.04924112185835838\n",
      "epoch: 3 step: 1384, loss is 0.01355031318962574\n",
      "epoch: 3 step: 1385, loss is 0.1944073587656021\n",
      "epoch: 3 step: 1386, loss is 0.004109903238713741\n",
      "epoch: 3 step: 1387, loss is 0.009585786610841751\n",
      "epoch: 3 step: 1388, loss is 0.008650582283735275\n",
      "epoch: 3 step: 1389, loss is 0.0014611892402172089\n",
      "epoch: 3 step: 1390, loss is 0.3078843653202057\n",
      "epoch: 3 step: 1391, loss is 0.002516299718990922\n",
      "epoch: 3 step: 1392, loss is 0.23124931752681732\n",
      "epoch: 3 step: 1393, loss is 0.030743559822440147\n",
      "epoch: 3 step: 1394, loss is 0.10158982872962952\n",
      "epoch: 3 step: 1395, loss is 0.0018150649266317487\n",
      "epoch: 3 step: 1396, loss is 0.006892327219247818\n",
      "epoch: 3 step: 1397, loss is 0.01060539297759533\n",
      "epoch: 3 step: 1398, loss is 0.006670956499874592\n",
      "epoch: 3 step: 1399, loss is 0.06331179291009903\n",
      "epoch: 3 step: 1400, loss is 0.02290981076657772\n",
      "epoch: 3 step: 1401, loss is 0.1987268477678299\n",
      "epoch: 3 step: 1402, loss is 0.010739630088210106\n",
      "epoch: 3 step: 1403, loss is 0.0037895108107477427\n",
      "epoch: 3 step: 1404, loss is 0.014576200395822525\n",
      "epoch: 3 step: 1405, loss is 0.0050201620906591415\n",
      "epoch: 3 step: 1406, loss is 0.026566628366708755\n",
      "epoch: 3 step: 1407, loss is 0.00996391475200653\n",
      "epoch: 3 step: 1408, loss is 0.04087633639574051\n",
      "epoch: 3 step: 1409, loss is 0.008107287809252739\n",
      "epoch: 3 step: 1410, loss is 0.007760119158774614\n",
      "epoch: 3 step: 1411, loss is 0.06811334192752838\n",
      "epoch: 3 step: 1412, loss is 0.03636230155825615\n",
      "epoch: 3 step: 1413, loss is 0.0465366430580616\n",
      "epoch: 3 step: 1414, loss is 0.007645286154001951\n",
      "epoch: 3 step: 1415, loss is 0.003198495600372553\n",
      "epoch: 3 step: 1416, loss is 0.0748019590973854\n",
      "epoch: 3 step: 1417, loss is 0.024990985170006752\n",
      "epoch: 3 step: 1418, loss is 0.025065798312425613\n",
      "epoch: 3 step: 1419, loss is 0.20882689952850342\n",
      "epoch: 3 step: 1420, loss is 0.01994749903678894\n",
      "epoch: 3 step: 1421, loss is 0.054608482867479324\n",
      "epoch: 3 step: 1422, loss is 0.0010605951538309455\n",
      "epoch: 3 step: 1423, loss is 0.0232270248234272\n",
      "epoch: 3 step: 1424, loss is 0.003433916252106428\n",
      "epoch: 3 step: 1425, loss is 0.047352250665426254\n",
      "epoch: 3 step: 1426, loss is 0.22593146562576294\n",
      "epoch: 3 step: 1427, loss is 0.001572927227243781\n",
      "epoch: 3 step: 1428, loss is 0.016828451305627823\n",
      "epoch: 3 step: 1429, loss is 0.0531843900680542\n",
      "epoch: 3 step: 1430, loss is 0.09687141329050064\n",
      "epoch: 3 step: 1431, loss is 0.03361060842871666\n",
      "epoch: 3 step: 1432, loss is 0.027416901662945747\n",
      "epoch: 3 step: 1433, loss is 0.17422641813755035\n",
      "epoch: 3 step: 1434, loss is 0.0021705422550439835\n",
      "epoch: 3 step: 1435, loss is 0.007038138806819916\n",
      "epoch: 3 step: 1436, loss is 0.03273675963282585\n",
      "epoch: 3 step: 1437, loss is 0.0802575945854187\n",
      "epoch: 3 step: 1438, loss is 0.004206355661153793\n",
      "epoch: 3 step: 1439, loss is 0.007149400655180216\n",
      "epoch: 3 step: 1440, loss is 0.1752602607011795\n",
      "epoch: 3 step: 1441, loss is 0.015302861109375954\n",
      "epoch: 3 step: 1442, loss is 0.023146869614720345\n",
      "epoch: 3 step: 1443, loss is 0.04029282182455063\n",
      "epoch: 3 step: 1444, loss is 0.008235613815486431\n",
      "epoch: 3 step: 1445, loss is 0.01574074849486351\n",
      "epoch: 3 step: 1446, loss is 0.0007209916948340833\n",
      "epoch: 3 step: 1447, loss is 0.06966926902532578\n",
      "epoch: 3 step: 1448, loss is 0.14970886707305908\n",
      "epoch: 3 step: 1449, loss is 0.002266576047986746\n",
      "epoch: 3 step: 1450, loss is 0.05026021599769592\n",
      "epoch: 3 step: 1451, loss is 0.010021794587373734\n",
      "epoch: 3 step: 1452, loss is 0.12178900092840195\n",
      "epoch: 3 step: 1453, loss is 0.0029387492686510086\n",
      "epoch: 3 step: 1454, loss is 0.01696021854877472\n",
      "epoch: 3 step: 1455, loss is 0.010610799305140972\n",
      "epoch: 3 step: 1456, loss is 0.0008983120205812156\n",
      "epoch: 3 step: 1457, loss is 0.024262316524982452\n",
      "epoch: 3 step: 1458, loss is 0.012750992551445961\n",
      "epoch: 3 step: 1459, loss is 0.18317504227161407\n",
      "epoch: 3 step: 1460, loss is 0.007266799919307232\n",
      "epoch: 3 step: 1461, loss is 0.010701227001845837\n",
      "epoch: 3 step: 1462, loss is 0.005276590585708618\n",
      "epoch: 3 step: 1463, loss is 0.009889652952551842\n",
      "epoch: 3 step: 1464, loss is 0.01380927674472332\n",
      "epoch: 3 step: 1465, loss is 0.010602951981127262\n",
      "epoch: 3 step: 1466, loss is 0.22525177896022797\n",
      "epoch: 3 step: 1467, loss is 0.004142977297306061\n",
      "epoch: 3 step: 1468, loss is 0.0005306922248564661\n",
      "epoch: 3 step: 1469, loss is 0.0005104235606268048\n",
      "epoch: 3 step: 1470, loss is 0.0006157879251986742\n",
      "epoch: 3 step: 1471, loss is 0.11688338220119476\n",
      "epoch: 3 step: 1472, loss is 0.07548484951257706\n",
      "epoch: 3 step: 1473, loss is 0.007030715234577656\n",
      "epoch: 3 step: 1474, loss is 0.005695518106222153\n",
      "epoch: 3 step: 1475, loss is 0.019832728430628777\n",
      "epoch: 3 step: 1476, loss is 0.0021497777197510004\n",
      "epoch: 3 step: 1477, loss is 0.007691793609410524\n",
      "epoch: 3 step: 1478, loss is 0.00416609738022089\n",
      "epoch: 3 step: 1479, loss is 0.000531864701770246\n",
      "epoch: 3 step: 1480, loss is 0.053295526653528214\n",
      "epoch: 3 step: 1481, loss is 0.020173514261841774\n",
      "epoch: 3 step: 1482, loss is 0.002871414413675666\n",
      "epoch: 3 step: 1483, loss is 0.0112540815025568\n",
      "epoch: 3 step: 1484, loss is 0.002016301266849041\n",
      "epoch: 3 step: 1485, loss is 0.05142911523580551\n",
      "epoch: 3 step: 1486, loss is 0.013018887490034103\n",
      "epoch: 3 step: 1487, loss is 0.003937033005058765\n",
      "epoch: 3 step: 1488, loss is 0.0006093007978051901\n",
      "epoch: 3 step: 1489, loss is 0.003293468616902828\n",
      "epoch: 3 step: 1490, loss is 0.002563453046604991\n",
      "epoch: 3 step: 1491, loss is 0.003315169597044587\n",
      "epoch: 3 step: 1492, loss is 0.0034142937511205673\n",
      "epoch: 3 step: 1493, loss is 0.0044051832519471645\n",
      "epoch: 3 step: 1494, loss is 0.06107663735747337\n",
      "epoch: 3 step: 1495, loss is 0.04062864929437637\n",
      "epoch: 3 step: 1496, loss is 0.0028391920495778322\n",
      "epoch: 3 step: 1497, loss is 0.007958018220961094\n",
      "epoch: 3 step: 1498, loss is 0.06832848489284515\n",
      "epoch: 3 step: 1499, loss is 0.010779310949146748\n",
      "epoch: 3 step: 1500, loss is 0.04590814560651779\n",
      "epoch: 3 step: 1501, loss is 0.06377793848514557\n",
      "epoch: 3 step: 1502, loss is 0.06102538853883743\n",
      "epoch: 3 step: 1503, loss is 0.0006020812434144318\n",
      "epoch: 3 step: 1504, loss is 0.007694507483392954\n",
      "epoch: 3 step: 1505, loss is 0.0010413402924314141\n",
      "epoch: 3 step: 1506, loss is 0.029433567076921463\n",
      "epoch: 3 step: 1507, loss is 0.0015575478319078684\n",
      "epoch: 3 step: 1508, loss is 0.005832508206367493\n",
      "epoch: 3 step: 1509, loss is 0.18433667719364166\n",
      "epoch: 3 step: 1510, loss is 0.002918631536886096\n",
      "epoch: 3 step: 1511, loss is 0.10914978384971619\n",
      "epoch: 3 step: 1512, loss is 0.046090610325336456\n",
      "epoch: 3 step: 1513, loss is 0.004058000631630421\n",
      "epoch: 3 step: 1514, loss is 0.013917232863605022\n",
      "epoch: 3 step: 1515, loss is 0.00033001223346218467\n",
      "epoch: 3 step: 1516, loss is 0.0018654076848179102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1517, loss is 0.17353875935077667\n",
      "epoch: 3 step: 1518, loss is 0.009634150192141533\n",
      "epoch: 3 step: 1519, loss is 0.0037985811941325665\n",
      "epoch: 3 step: 1520, loss is 0.035896528512239456\n",
      "epoch: 3 step: 1521, loss is 0.006542056333273649\n",
      "epoch: 3 step: 1522, loss is 0.012180204503238201\n",
      "epoch: 3 step: 1523, loss is 0.044467464089393616\n",
      "epoch: 3 step: 1524, loss is 0.0002678932505659759\n",
      "epoch: 3 step: 1525, loss is 0.0017431476153433323\n",
      "epoch: 3 step: 1526, loss is 0.03651293367147446\n",
      "epoch: 3 step: 1527, loss is 0.000801716698333621\n",
      "epoch: 3 step: 1528, loss is 0.006646221969276667\n",
      "epoch: 3 step: 1529, loss is 0.008104737848043442\n",
      "epoch: 3 step: 1530, loss is 0.003910926170647144\n",
      "epoch: 3 step: 1531, loss is 0.005003633443266153\n",
      "epoch: 3 step: 1532, loss is 0.0009850928327068686\n",
      "epoch: 3 step: 1533, loss is 0.2886998951435089\n",
      "epoch: 3 step: 1534, loss is 0.008578185923397541\n",
      "epoch: 3 step: 1535, loss is 0.004757432267069817\n",
      "epoch: 3 step: 1536, loss is 0.035322416573762894\n",
      "epoch: 3 step: 1537, loss is 0.0017610857030376792\n",
      "epoch: 3 step: 1538, loss is 0.0024916501715779305\n",
      "epoch: 3 step: 1539, loss is 0.021349841728806496\n",
      "epoch: 3 step: 1540, loss is 0.0040817102417349815\n",
      "epoch: 3 step: 1541, loss is 0.07051515579223633\n",
      "epoch: 3 step: 1542, loss is 0.004807841032743454\n",
      "epoch: 3 step: 1543, loss is 0.003146049566566944\n",
      "epoch: 3 step: 1544, loss is 0.10405120253562927\n",
      "epoch: 3 step: 1545, loss is 0.05769260972738266\n",
      "epoch: 3 step: 1546, loss is 0.1987147033214569\n",
      "epoch: 3 step: 1547, loss is 0.008539438247680664\n",
      "epoch: 3 step: 1548, loss is 0.005794648081064224\n",
      "epoch: 3 step: 1549, loss is 0.007426767610013485\n",
      "epoch: 3 step: 1550, loss is 0.13902299106121063\n",
      "epoch: 3 step: 1551, loss is 0.07707688957452774\n",
      "epoch: 3 step: 1552, loss is 0.004265212919563055\n",
      "epoch: 3 step: 1553, loss is 0.017553668469190598\n",
      "epoch: 3 step: 1554, loss is 0.0008930742042139173\n",
      "epoch: 3 step: 1555, loss is 0.024922115728259087\n",
      "epoch: 3 step: 1556, loss is 0.0011224511545151472\n",
      "epoch: 3 step: 1557, loss is 0.06158512085676193\n",
      "epoch: 3 step: 1558, loss is 0.000977525021880865\n",
      "epoch: 3 step: 1559, loss is 0.00869192648679018\n",
      "epoch: 3 step: 1560, loss is 0.008800565265119076\n",
      "epoch: 3 step: 1561, loss is 0.0680549144744873\n",
      "epoch: 3 step: 1562, loss is 0.0007919772760942578\n",
      "epoch: 3 step: 1563, loss is 0.043137773871421814\n",
      "epoch: 3 step: 1564, loss is 0.0060025230050086975\n",
      "epoch: 3 step: 1565, loss is 0.009383373893797398\n",
      "epoch: 3 step: 1566, loss is 0.0010482497746124864\n",
      "epoch: 3 step: 1567, loss is 0.0389493964612484\n",
      "epoch: 3 step: 1568, loss is 0.09968290477991104\n",
      "epoch: 3 step: 1569, loss is 0.0023143526632338762\n",
      "epoch: 3 step: 1570, loss is 0.023758135735988617\n",
      "epoch: 3 step: 1571, loss is 0.0025184217374771833\n",
      "epoch: 3 step: 1572, loss is 0.0016456682933494449\n",
      "epoch: 3 step: 1573, loss is 0.1584857702255249\n",
      "epoch: 3 step: 1574, loss is 0.018485594540834427\n",
      "epoch: 3 step: 1575, loss is 0.004851676989346743\n",
      "epoch: 3 step: 1576, loss is 0.005614739377051592\n",
      "epoch: 3 step: 1577, loss is 0.1517157107591629\n",
      "epoch: 3 step: 1578, loss is 0.007561099249869585\n",
      "epoch: 3 step: 1579, loss is 0.17853505909442902\n",
      "epoch: 3 step: 1580, loss is 0.005640605464577675\n",
      "epoch: 3 step: 1581, loss is 0.003970191348344088\n",
      "epoch: 3 step: 1582, loss is 0.01638919487595558\n",
      "epoch: 3 step: 1583, loss is 0.00830096285790205\n",
      "epoch: 3 step: 1584, loss is 0.1838189661502838\n",
      "epoch: 3 step: 1585, loss is 0.11274760961532593\n",
      "epoch: 3 step: 1586, loss is 0.044585008174180984\n",
      "epoch: 3 step: 1587, loss is 0.023531431332230568\n",
      "epoch: 3 step: 1588, loss is 0.0308550912886858\n",
      "epoch: 3 step: 1589, loss is 0.013036424294114113\n",
      "epoch: 3 step: 1590, loss is 0.00110721739474684\n",
      "epoch: 3 step: 1591, loss is 0.01649428904056549\n",
      "epoch: 3 step: 1592, loss is 0.08452362567186356\n",
      "epoch: 3 step: 1593, loss is 0.012781678698956966\n",
      "epoch: 3 step: 1594, loss is 0.0030239801853895187\n",
      "epoch: 3 step: 1595, loss is 0.0038052694872021675\n",
      "epoch: 3 step: 1596, loss is 0.03439541533589363\n",
      "epoch: 3 step: 1597, loss is 0.05363751947879791\n",
      "epoch: 3 step: 1598, loss is 0.04185086488723755\n",
      "epoch: 3 step: 1599, loss is 0.16339896619319916\n",
      "epoch: 3 step: 1600, loss is 0.001493769814260304\n",
      "epoch: 3 step: 1601, loss is 0.007143101654946804\n",
      "epoch: 3 step: 1602, loss is 0.02132987789809704\n",
      "epoch: 3 step: 1603, loss is 0.0542522594332695\n",
      "epoch: 3 step: 1604, loss is 0.00897937174886465\n",
      "epoch: 3 step: 1605, loss is 0.004771241918206215\n",
      "epoch: 3 step: 1606, loss is 0.031820256263017654\n",
      "epoch: 3 step: 1607, loss is 0.0005202751490287483\n",
      "epoch: 3 step: 1608, loss is 0.008309196680784225\n",
      "epoch: 3 step: 1609, loss is 0.008626364171504974\n",
      "epoch: 3 step: 1610, loss is 0.036869730800390244\n",
      "epoch: 3 step: 1611, loss is 0.06802114099264145\n",
      "epoch: 3 step: 1612, loss is 0.003504763590171933\n",
      "epoch: 3 step: 1613, loss is 0.10605652630329132\n",
      "epoch: 3 step: 1614, loss is 0.0058516389690339565\n",
      "epoch: 3 step: 1615, loss is 0.012219509109854698\n",
      "epoch: 3 step: 1616, loss is 0.009682678617537022\n",
      "epoch: 3 step: 1617, loss is 0.027308516204357147\n",
      "epoch: 3 step: 1618, loss is 0.27937114238739014\n",
      "epoch: 3 step: 1619, loss is 0.004133796319365501\n",
      "epoch: 3 step: 1620, loss is 0.009423058480024338\n",
      "epoch: 3 step: 1621, loss is 0.04018470644950867\n",
      "epoch: 3 step: 1622, loss is 0.0005409437580965459\n",
      "epoch: 3 step: 1623, loss is 0.055327001959085464\n",
      "epoch: 3 step: 1624, loss is 0.00332055427134037\n",
      "epoch: 3 step: 1625, loss is 0.05856000632047653\n",
      "epoch: 3 step: 1626, loss is 0.05836835876107216\n",
      "epoch: 3 step: 1627, loss is 0.17347319424152374\n",
      "epoch: 3 step: 1628, loss is 0.0018362647388130426\n",
      "epoch: 3 step: 1629, loss is 0.014209378510713577\n",
      "epoch: 3 step: 1630, loss is 0.00029349623946473\n",
      "epoch: 3 step: 1631, loss is 0.0019975772593170404\n",
      "epoch: 3 step: 1632, loss is 0.0008854172774590552\n",
      "epoch: 3 step: 1633, loss is 0.03546111658215523\n",
      "epoch: 3 step: 1634, loss is 0.04733744636178017\n",
      "epoch: 3 step: 1635, loss is 0.0021633198484778404\n",
      "epoch: 3 step: 1636, loss is 0.0033730182331055403\n",
      "epoch: 3 step: 1637, loss is 0.009715944528579712\n",
      "epoch: 3 step: 1638, loss is 0.03935779258608818\n",
      "epoch: 3 step: 1639, loss is 0.005771788768470287\n",
      "epoch: 3 step: 1640, loss is 0.004662004299461842\n",
      "epoch: 3 step: 1641, loss is 0.0010509564308449626\n",
      "epoch: 3 step: 1642, loss is 0.0028692299965769053\n",
      "epoch: 3 step: 1643, loss is 0.0010057584149762988\n",
      "epoch: 3 step: 1644, loss is 0.012995624914765358\n",
      "epoch: 3 step: 1645, loss is 0.0030739265494048595\n",
      "epoch: 3 step: 1646, loss is 0.004951404873281717\n",
      "epoch: 3 step: 1647, loss is 0.14435924589633942\n",
      "epoch: 3 step: 1648, loss is 0.03667611628770828\n",
      "epoch: 3 step: 1649, loss is 0.02689291350543499\n",
      "epoch: 3 step: 1650, loss is 0.0865798369050026\n",
      "epoch: 3 step: 1651, loss is 0.0035385419614613056\n",
      "epoch: 3 step: 1652, loss is 0.0012073309626430273\n",
      "epoch: 3 step: 1653, loss is 0.0009394485969096422\n",
      "epoch: 3 step: 1654, loss is 0.003098237095400691\n",
      "epoch: 3 step: 1655, loss is 0.20932438969612122\n",
      "epoch: 3 step: 1656, loss is 0.2355470508337021\n",
      "epoch: 3 step: 1657, loss is 0.03390256315469742\n",
      "epoch: 3 step: 1658, loss is 0.06431903690099716\n",
      "epoch: 3 step: 1659, loss is 0.06435082107782364\n",
      "epoch: 3 step: 1660, loss is 0.04061508923768997\n",
      "epoch: 3 step: 1661, loss is 0.011606129817664623\n",
      "epoch: 3 step: 1662, loss is 0.0506133958697319\n",
      "epoch: 3 step: 1663, loss is 0.0020948192104697227\n",
      "epoch: 3 step: 1664, loss is 0.014373255893588066\n",
      "epoch: 3 step: 1665, loss is 0.005987043026834726\n",
      "epoch: 3 step: 1666, loss is 0.02752654068171978\n",
      "epoch: 3 step: 1667, loss is 0.12951162457466125\n",
      "epoch: 3 step: 1668, loss is 0.004008408170193434\n",
      "epoch: 3 step: 1669, loss is 0.004584792535752058\n",
      "epoch: 3 step: 1670, loss is 0.2467811554670334\n",
      "epoch: 3 step: 1671, loss is 0.10808558017015457\n",
      "epoch: 3 step: 1672, loss is 0.19148467481136322\n",
      "epoch: 3 step: 1673, loss is 0.0032378605101257563\n",
      "epoch: 3 step: 1674, loss is 0.11352506279945374\n",
      "epoch: 3 step: 1675, loss is 0.014084613882005215\n",
      "epoch: 3 step: 1676, loss is 0.004394464194774628\n",
      "epoch: 3 step: 1677, loss is 0.009985383599996567\n",
      "epoch: 3 step: 1678, loss is 0.026545513421297073\n",
      "epoch: 3 step: 1679, loss is 0.0244606863707304\n",
      "epoch: 3 step: 1680, loss is 0.08439455926418304\n",
      "epoch: 3 step: 1681, loss is 0.0045791929587721825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1682, loss is 0.0480613112449646\n",
      "epoch: 3 step: 1683, loss is 0.001254756236448884\n",
      "epoch: 3 step: 1684, loss is 0.009898647665977478\n",
      "epoch: 3 step: 1685, loss is 0.05175756290555\n",
      "epoch: 3 step: 1686, loss is 0.07678627222776413\n",
      "epoch: 3 step: 1687, loss is 0.042703092098236084\n",
      "epoch: 3 step: 1688, loss is 0.037873879075050354\n",
      "epoch: 3 step: 1689, loss is 0.00032355228904634714\n",
      "epoch: 3 step: 1690, loss is 0.044818077236413956\n",
      "epoch: 3 step: 1691, loss is 0.06775782257318497\n",
      "epoch: 3 step: 1692, loss is 0.06860066950321198\n",
      "epoch: 3 step: 1693, loss is 0.02365698479115963\n",
      "epoch: 3 step: 1694, loss is 0.012485007755458355\n",
      "epoch: 3 step: 1695, loss is 0.0074316151440143585\n",
      "epoch: 3 step: 1696, loss is 0.003295683767646551\n",
      "epoch: 3 step: 1697, loss is 0.0655258446931839\n",
      "epoch: 3 step: 1698, loss is 0.003428989788517356\n",
      "epoch: 3 step: 1699, loss is 0.0008834616164676845\n",
      "epoch: 3 step: 1700, loss is 0.017868440598249435\n",
      "epoch: 3 step: 1701, loss is 0.016203049570322037\n",
      "epoch: 3 step: 1702, loss is 0.1463593989610672\n",
      "epoch: 3 step: 1703, loss is 0.11870388686656952\n",
      "epoch: 3 step: 1704, loss is 0.015073169022798538\n",
      "epoch: 3 step: 1705, loss is 0.03657447546720505\n",
      "epoch: 3 step: 1706, loss is 0.03387373313307762\n",
      "epoch: 3 step: 1707, loss is 0.02424568124115467\n",
      "epoch: 3 step: 1708, loss is 0.0027655870653688908\n",
      "epoch: 3 step: 1709, loss is 0.007808975409716368\n",
      "epoch: 3 step: 1710, loss is 0.03977669030427933\n",
      "epoch: 3 step: 1711, loss is 0.05564669519662857\n",
      "epoch: 3 step: 1712, loss is 0.0013953145826235414\n",
      "epoch: 3 step: 1713, loss is 0.0019065396627411246\n",
      "epoch: 3 step: 1714, loss is 0.09268410503864288\n",
      "epoch: 3 step: 1715, loss is 0.11952154338359833\n",
      "epoch: 3 step: 1716, loss is 0.022503456100821495\n",
      "epoch: 3 step: 1717, loss is 0.009877510368824005\n",
      "epoch: 3 step: 1718, loss is 0.06859495490789413\n",
      "epoch: 3 step: 1719, loss is 0.004433713387697935\n",
      "epoch: 3 step: 1720, loss is 0.0046870592050254345\n",
      "epoch: 3 step: 1721, loss is 0.002503471216186881\n",
      "epoch: 3 step: 1722, loss is 0.07814590632915497\n",
      "epoch: 3 step: 1723, loss is 0.0006778386887162924\n",
      "epoch: 3 step: 1724, loss is 0.0752703994512558\n",
      "epoch: 3 step: 1725, loss is 0.025289500132203102\n",
      "epoch: 3 step: 1726, loss is 0.001369787729345262\n",
      "epoch: 3 step: 1727, loss is 0.031129498034715652\n",
      "epoch: 3 step: 1728, loss is 0.01906311884522438\n",
      "epoch: 3 step: 1729, loss is 0.14450860023498535\n",
      "epoch: 3 step: 1730, loss is 0.01103886216878891\n",
      "epoch: 3 step: 1731, loss is 0.02180665172636509\n",
      "epoch: 3 step: 1732, loss is 0.05319646745920181\n",
      "epoch: 3 step: 1733, loss is 0.02707694098353386\n",
      "epoch: 3 step: 1734, loss is 0.0017939687240868807\n",
      "epoch: 3 step: 1735, loss is 0.07940901815891266\n",
      "epoch: 3 step: 1736, loss is 0.010081563144922256\n",
      "epoch: 3 step: 1737, loss is 0.0002546967880334705\n",
      "epoch: 3 step: 1738, loss is 0.01920832321047783\n",
      "epoch: 3 step: 1739, loss is 0.04182830825448036\n",
      "epoch: 3 step: 1740, loss is 0.01712910830974579\n",
      "epoch: 3 step: 1741, loss is 0.017449311912059784\n",
      "epoch: 3 step: 1742, loss is 0.006748741492629051\n",
      "epoch: 3 step: 1743, loss is 0.00445935782045126\n",
      "epoch: 3 step: 1744, loss is 0.035317182540893555\n",
      "epoch: 3 step: 1745, loss is 0.02744964137673378\n",
      "epoch: 3 step: 1746, loss is 0.01352609321475029\n",
      "epoch: 3 step: 1747, loss is 0.020971795544028282\n",
      "epoch: 3 step: 1748, loss is 0.05043138563632965\n",
      "epoch: 3 step: 1749, loss is 0.04201332852244377\n",
      "epoch: 3 step: 1750, loss is 0.007446683011949062\n",
      "epoch: 3 step: 1751, loss is 0.00047816475853323936\n",
      "epoch: 3 step: 1752, loss is 0.0012600366026163101\n",
      "epoch: 3 step: 1753, loss is 0.21211548149585724\n",
      "epoch: 3 step: 1754, loss is 0.013803924433887005\n",
      "epoch: 3 step: 1755, loss is 0.10055431723594666\n",
      "epoch: 3 step: 1756, loss is 0.0011496866354718804\n",
      "epoch: 3 step: 1757, loss is 0.0015998154412955046\n",
      "epoch: 3 step: 1758, loss is 0.009455610997974873\n",
      "epoch: 3 step: 1759, loss is 0.008523423224687576\n",
      "epoch: 3 step: 1760, loss is 0.010557201690971851\n",
      "epoch: 3 step: 1761, loss is 0.031859710812568665\n",
      "epoch: 3 step: 1762, loss is 0.07669348269701004\n",
      "epoch: 3 step: 1763, loss is 0.009853534400463104\n",
      "epoch: 3 step: 1764, loss is 0.04383157938718796\n",
      "epoch: 3 step: 1765, loss is 0.12401466816663742\n",
      "epoch: 3 step: 1766, loss is 0.06825071573257446\n",
      "epoch: 3 step: 1767, loss is 0.004937826190143824\n",
      "epoch: 3 step: 1768, loss is 0.00066518469247967\n",
      "epoch: 3 step: 1769, loss is 0.08309745788574219\n",
      "epoch: 3 step: 1770, loss is 0.024846434593200684\n",
      "epoch: 3 step: 1771, loss is 0.0010598973603919148\n",
      "epoch: 3 step: 1772, loss is 0.010126703418791294\n",
      "epoch: 3 step: 1773, loss is 0.02401527389883995\n",
      "epoch: 3 step: 1774, loss is 0.01586880348622799\n",
      "epoch: 3 step: 1775, loss is 0.08579226583242416\n",
      "epoch: 3 step: 1776, loss is 0.07777368277311325\n",
      "epoch: 3 step: 1777, loss is 0.0005792732117697597\n",
      "epoch: 3 step: 1778, loss is 0.0018126670038327575\n",
      "epoch: 3 step: 1779, loss is 0.0005859351367689669\n",
      "epoch: 3 step: 1780, loss is 0.00014840329822618514\n",
      "epoch: 3 step: 1781, loss is 0.013625159859657288\n",
      "epoch: 3 step: 1782, loss is 0.00483024911954999\n",
      "epoch: 3 step: 1783, loss is 8.322719077114016e-05\n",
      "epoch: 3 step: 1784, loss is 0.04158853739500046\n",
      "epoch: 3 step: 1785, loss is 0.00042913161450996995\n",
      "epoch: 3 step: 1786, loss is 0.0010823012562468648\n",
      "epoch: 3 step: 1787, loss is 0.027653072029352188\n",
      "epoch: 3 step: 1788, loss is 0.07522054761648178\n",
      "epoch: 3 step: 1789, loss is 0.05863408371806145\n",
      "epoch: 3 step: 1790, loss is 0.014435368590056896\n",
      "epoch: 3 step: 1791, loss is 0.0014891054015606642\n",
      "epoch: 3 step: 1792, loss is 0.004881983622908592\n",
      "epoch: 3 step: 1793, loss is 0.0020387812983244658\n",
      "epoch: 3 step: 1794, loss is 0.061184655874967575\n",
      "epoch: 3 step: 1795, loss is 0.0069584776647388935\n",
      "epoch: 3 step: 1796, loss is 0.03057263232767582\n",
      "epoch: 3 step: 1797, loss is 0.016286570578813553\n",
      "epoch: 3 step: 1798, loss is 0.000806304335128516\n",
      "epoch: 3 step: 1799, loss is 0.04157475382089615\n",
      "epoch: 3 step: 1800, loss is 0.005383842159062624\n",
      "epoch: 3 step: 1801, loss is 0.258218914270401\n",
      "epoch: 3 step: 1802, loss is 0.07358046621084213\n",
      "epoch: 3 step: 1803, loss is 8.332815923495218e-05\n",
      "epoch: 3 step: 1804, loss is 0.019706401973962784\n",
      "epoch: 3 step: 1805, loss is 0.00017418181232642382\n",
      "epoch: 3 step: 1806, loss is 0.02855960838496685\n",
      "epoch: 3 step: 1807, loss is 0.03601246327161789\n",
      "epoch: 3 step: 1808, loss is 0.0013832534896209836\n",
      "epoch: 3 step: 1809, loss is 0.0032071101013571024\n",
      "epoch: 3 step: 1810, loss is 0.003075614105910063\n",
      "epoch: 3 step: 1811, loss is 0.3309834897518158\n",
      "epoch: 3 step: 1812, loss is 0.017091352492570877\n",
      "epoch: 3 step: 1813, loss is 0.09655120223760605\n",
      "epoch: 3 step: 1814, loss is 0.006001351401209831\n",
      "epoch: 3 step: 1815, loss is 0.045590244233608246\n",
      "epoch: 3 step: 1816, loss is 0.007957675494253635\n",
      "epoch: 3 step: 1817, loss is 0.0005314219160936773\n",
      "epoch: 3 step: 1818, loss is 0.014586576260626316\n",
      "epoch: 3 step: 1819, loss is 0.304822713136673\n",
      "epoch: 3 step: 1820, loss is 0.03748682141304016\n",
      "epoch: 3 step: 1821, loss is 0.056172072887420654\n",
      "epoch: 3 step: 1822, loss is 0.0012614271836355329\n",
      "epoch: 3 step: 1823, loss is 0.010788756422698498\n",
      "epoch: 3 step: 1824, loss is 0.0006064241752028465\n",
      "epoch: 3 step: 1825, loss is 0.002844814909622073\n",
      "epoch: 3 step: 1826, loss is 0.0035792957060039043\n",
      "epoch: 3 step: 1827, loss is 0.09569717198610306\n",
      "epoch: 3 step: 1828, loss is 0.2532680034637451\n",
      "epoch: 3 step: 1829, loss is 0.001407017232850194\n",
      "epoch: 3 step: 1830, loss is 0.05108357593417168\n",
      "epoch: 3 step: 1831, loss is 0.014607121236622334\n",
      "epoch: 3 step: 1832, loss is 0.0050898646004498005\n",
      "epoch: 3 step: 1833, loss is 0.037445276975631714\n",
      "epoch: 3 step: 1834, loss is 0.0010699097765609622\n",
      "epoch: 3 step: 1835, loss is 0.0016233606729656458\n",
      "epoch: 3 step: 1836, loss is 0.017367737367749214\n",
      "epoch: 3 step: 1837, loss is 0.003497212426736951\n",
      "epoch: 3 step: 1838, loss is 0.26016339659690857\n",
      "epoch: 3 step: 1839, loss is 0.003576131071895361\n",
      "epoch: 3 step: 1840, loss is 0.19218659400939941\n",
      "epoch: 3 step: 1841, loss is 0.006304656621068716\n",
      "epoch: 3 step: 1842, loss is 0.16997043788433075\n",
      "epoch: 3 step: 1843, loss is 0.020078303292393684\n",
      "epoch: 3 step: 1844, loss is 0.002866315422579646\n",
      "epoch: 3 step: 1845, loss is 0.012598679400980473\n",
      "epoch: 3 step: 1846, loss is 0.09222310036420822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1847, loss is 0.08291136473417282\n",
      "epoch: 3 step: 1848, loss is 0.01403328962624073\n",
      "epoch: 3 step: 1849, loss is 0.009968478232622147\n",
      "epoch: 3 step: 1850, loss is 0.008026201277971268\n",
      "epoch: 3 step: 1851, loss is 0.18904748558998108\n",
      "epoch: 3 step: 1852, loss is 0.0004984118859283626\n",
      "epoch: 3 step: 1853, loss is 0.08047512173652649\n",
      "epoch: 3 step: 1854, loss is 0.023307127878069878\n",
      "epoch: 3 step: 1855, loss is 0.005838294513523579\n",
      "epoch: 3 step: 1856, loss is 0.03817030042409897\n",
      "epoch: 3 step: 1857, loss is 0.02007225900888443\n",
      "epoch: 3 step: 1858, loss is 0.06324116140604019\n",
      "epoch: 3 step: 1859, loss is 0.0016787262866273522\n",
      "epoch: 3 step: 1860, loss is 0.18749991059303284\n",
      "epoch: 3 step: 1861, loss is 0.0008463881677016616\n",
      "epoch: 3 step: 1862, loss is 0.00300598400644958\n",
      "epoch: 3 step: 1863, loss is 0.0007396169239655137\n",
      "epoch: 3 step: 1864, loss is 0.008930029347538948\n",
      "epoch: 3 step: 1865, loss is 0.010039902292191982\n",
      "epoch: 3 step: 1866, loss is 0.005760610569268465\n",
      "epoch: 3 step: 1867, loss is 0.031996872276067734\n",
      "epoch: 3 step: 1868, loss is 0.009837892837822437\n",
      "epoch: 3 step: 1869, loss is 0.0013239295221865177\n",
      "epoch: 3 step: 1870, loss is 0.002501966431736946\n",
      "epoch: 3 step: 1871, loss is 0.015234188176691532\n",
      "epoch: 3 step: 1872, loss is 0.010233934037387371\n",
      "epoch: 3 step: 1873, loss is 0.004180434159934521\n",
      "epoch: 3 step: 1874, loss is 8.382599480682984e-05\n",
      "epoch: 3 step: 1875, loss is 0.004520362243056297\n",
      "epoch: 3 step: 1876, loss is 0.016339492052793503\n",
      "epoch: 3 step: 1877, loss is 0.11232446879148483\n",
      "epoch: 3 step: 1878, loss is 0.09387446939945221\n",
      "epoch: 3 step: 1879, loss is 0.0017779981717467308\n",
      "epoch: 3 step: 1880, loss is 0.042914699763059616\n",
      "epoch: 3 step: 1881, loss is 0.00990948174148798\n",
      "epoch: 3 step: 1882, loss is 0.0258636511862278\n",
      "epoch: 3 step: 1883, loss is 0.007223036605864763\n",
      "epoch: 3 step: 1884, loss is 0.0346854105591774\n",
      "epoch: 3 step: 1885, loss is 0.002052080584689975\n",
      "epoch: 3 step: 1886, loss is 0.0013906325912103057\n",
      "epoch: 3 step: 1887, loss is 0.0017667588545009494\n",
      "epoch: 3 step: 1888, loss is 0.003910254221409559\n",
      "epoch: 3 step: 1889, loss is 0.006028865464031696\n",
      "epoch: 3 step: 1890, loss is 0.009426235221326351\n",
      "epoch: 3 step: 1891, loss is 0.016980871558189392\n",
      "epoch: 3 step: 1892, loss is 0.06331586092710495\n",
      "epoch: 3 step: 1893, loss is 0.08860106021165848\n",
      "epoch: 3 step: 1894, loss is 0.21714317798614502\n",
      "epoch: 3 step: 1895, loss is 0.00031340724672190845\n",
      "epoch: 3 step: 1896, loss is 0.0017251336248591542\n",
      "epoch: 3 step: 1897, loss is 0.04734349995851517\n",
      "epoch: 3 step: 1898, loss is 0.0328468456864357\n",
      "epoch: 3 step: 1899, loss is 0.0006329795578494668\n",
      "epoch: 3 step: 1900, loss is 0.0007360412273555994\n",
      "epoch: 3 step: 1901, loss is 0.010521462187170982\n",
      "epoch: 3 step: 1902, loss is 0.11041309684515\n",
      "epoch: 3 step: 1903, loss is 0.0012415542732924223\n",
      "epoch: 3 step: 1904, loss is 0.02381654642522335\n",
      "epoch: 3 step: 1905, loss is 0.26645463705062866\n",
      "epoch: 3 step: 1906, loss is 0.12134820967912674\n",
      "epoch: 3 step: 1907, loss is 0.07696232199668884\n",
      "epoch: 3 step: 1908, loss is 0.024540020152926445\n",
      "epoch: 3 step: 1909, loss is 0.00306413765065372\n",
      "epoch: 3 step: 1910, loss is 0.04925282672047615\n",
      "epoch: 3 step: 1911, loss is 0.006335814483463764\n",
      "epoch: 3 step: 1912, loss is 0.0005019293166697025\n",
      "epoch: 3 step: 1913, loss is 0.001626617624424398\n",
      "epoch: 3 step: 1914, loss is 0.0003975338477175683\n",
      "epoch: 3 step: 1915, loss is 0.04308832436800003\n",
      "epoch: 3 step: 1916, loss is 0.10246089845895767\n",
      "epoch: 3 step: 1917, loss is 0.01122778095304966\n",
      "epoch: 3 step: 1918, loss is 0.11680234223604202\n",
      "epoch: 3 step: 1919, loss is 0.20774787664413452\n",
      "epoch: 3 step: 1920, loss is 0.0007491220021620393\n",
      "epoch: 3 step: 1921, loss is 0.004041979089379311\n",
      "epoch: 3 step: 1922, loss is 0.008599658496677876\n",
      "epoch: 3 step: 1923, loss is 0.002780304988846183\n",
      "epoch: 3 step: 1924, loss is 0.0008197068818844855\n",
      "epoch: 3 step: 1925, loss is 0.15770955383777618\n",
      "epoch: 3 step: 1926, loss is 0.007935496978461742\n",
      "epoch: 3 step: 1927, loss is 0.03634374961256981\n",
      "epoch: 3 step: 1928, loss is 0.0013912050053477287\n",
      "epoch: 3 step: 1929, loss is 0.12779046595096588\n",
      "epoch: 3 step: 1930, loss is 0.07860900461673737\n",
      "epoch: 3 step: 1931, loss is 0.1269564926624298\n",
      "epoch: 3 step: 1932, loss is 0.045775335282087326\n",
      "epoch: 3 step: 1933, loss is 0.05859866365790367\n",
      "epoch: 3 step: 1934, loss is 0.0034072152338922024\n",
      "epoch: 3 step: 1935, loss is 0.0048407018184661865\n",
      "epoch: 3 step: 1936, loss is 0.04539845511317253\n",
      "epoch: 3 step: 1937, loss is 0.016131538897752762\n",
      "epoch: 3 step: 1938, loss is 0.0009348151506856084\n",
      "epoch: 3 step: 1939, loss is 0.0015009413473308086\n",
      "epoch: 3 step: 1940, loss is 0.013915794901549816\n",
      "epoch: 3 step: 1941, loss is 0.011186161078512669\n",
      "epoch: 3 step: 1942, loss is 0.003751640673726797\n",
      "epoch: 3 step: 1943, loss is 0.008732571266591549\n",
      "epoch: 3 step: 1944, loss is 0.02033323422074318\n",
      "epoch: 3 step: 1945, loss is 0.0018594157882034779\n",
      "epoch: 3 step: 1946, loss is 0.048723530024290085\n",
      "epoch: 3 step: 1947, loss is 0.0017480773385614157\n",
      "epoch: 3 step: 1948, loss is 0.07537560909986496\n",
      "epoch: 3 step: 1949, loss is 0.28291046619415283\n",
      "epoch: 3 step: 1950, loss is 0.03510193154215813\n",
      "epoch: 3 step: 1951, loss is 0.023969212546944618\n",
      "epoch: 3 step: 1952, loss is 0.0021244522649794817\n",
      "epoch: 3 step: 1953, loss is 0.03875654190778732\n",
      "epoch: 3 step: 1954, loss is 0.16319039463996887\n",
      "epoch: 3 step: 1955, loss is 0.004201292060315609\n",
      "epoch: 3 step: 1956, loss is 0.08263910561800003\n",
      "epoch: 3 step: 1957, loss is 0.0371304489672184\n",
      "epoch: 3 step: 1958, loss is 0.004139565862715244\n",
      "epoch: 3 step: 1959, loss is 0.18493157625198364\n",
      "epoch: 3 step: 1960, loss is 0.015571728348731995\n",
      "epoch: 3 step: 1961, loss is 0.04479781165719032\n",
      "epoch: 3 step: 1962, loss is 0.01103739719837904\n",
      "epoch: 3 step: 1963, loss is 0.019930332899093628\n",
      "epoch: 3 step: 1964, loss is 0.003919289447367191\n",
      "epoch: 3 step: 1965, loss is 0.7087989449501038\n",
      "epoch: 3 step: 1966, loss is 0.0029804203659296036\n",
      "epoch: 3 step: 1967, loss is 0.02097497507929802\n",
      "epoch: 3 step: 1968, loss is 0.06491903215646744\n",
      "epoch: 3 step: 1969, loss is 0.18821236491203308\n",
      "epoch: 3 step: 1970, loss is 0.023004023358225822\n",
      "epoch: 3 step: 1971, loss is 0.005547122098505497\n",
      "epoch: 3 step: 1972, loss is 0.009722896851599216\n",
      "epoch: 3 step: 1973, loss is 0.011561752296984196\n",
      "epoch: 3 step: 1974, loss is 0.03999626636505127\n",
      "epoch: 3 step: 1975, loss is 0.06856665015220642\n",
      "epoch: 3 step: 1976, loss is 0.004149645566940308\n",
      "epoch: 3 step: 1977, loss is 0.013378025963902473\n",
      "epoch: 3 step: 1978, loss is 0.023238593712449074\n",
      "epoch: 3 step: 1979, loss is 0.00794108584523201\n",
      "epoch: 3 step: 1980, loss is 0.006794809363782406\n",
      "epoch: 3 step: 1981, loss is 0.012711066752672195\n",
      "epoch: 3 step: 1982, loss is 0.048898473381996155\n",
      "epoch: 3 step: 1983, loss is 0.03680037334561348\n",
      "epoch: 3 step: 1984, loss is 0.011675954796373844\n",
      "epoch: 3 step: 1985, loss is 0.0008564837044104934\n",
      "epoch: 3 step: 1986, loss is 0.0035525166895240545\n",
      "epoch: 3 step: 1987, loss is 0.0008896305807866156\n",
      "epoch: 3 step: 1988, loss is 0.059894632548093796\n",
      "epoch: 3 step: 1989, loss is 0.004114300943911076\n",
      "epoch: 3 step: 1990, loss is 0.037570081651210785\n",
      "epoch: 3 step: 1991, loss is 0.0024493313394486904\n",
      "epoch: 3 step: 1992, loss is 0.003501076018437743\n",
      "epoch: 3 step: 1993, loss is 0.18443213403224945\n",
      "epoch: 3 step: 1994, loss is 0.05894779786467552\n",
      "epoch: 3 step: 1995, loss is 0.02759154513478279\n",
      "epoch: 3 step: 1996, loss is 0.26857897639274597\n",
      "epoch: 3 step: 1997, loss is 0.0695912316441536\n",
      "epoch: 3 step: 1998, loss is 0.004011481534689665\n",
      "epoch: 3 step: 1999, loss is 0.02976701408624649\n",
      "epoch: 3 step: 2000, loss is 0.009467815980315208\n",
      "epoch: 3 step: 2001, loss is 0.06120067462325096\n",
      "epoch: 3 step: 2002, loss is 0.015688925981521606\n",
      "epoch: 3 step: 2003, loss is 0.024518294259905815\n",
      "epoch: 3 step: 2004, loss is 0.001102027716115117\n",
      "epoch: 3 step: 2005, loss is 0.00150869763456285\n",
      "epoch: 3 step: 2006, loss is 0.08231458812952042\n",
      "epoch: 3 step: 2007, loss is 0.0005529389018192887\n",
      "epoch: 3 step: 2008, loss is 0.0010689293267205358\n",
      "epoch: 3 step: 2009, loss is 0.008384332992136478\n",
      "epoch: 3 step: 2010, loss is 0.002492271363735199\n",
      "epoch: 3 step: 2011, loss is 0.0023576586972922087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 2012, loss is 0.0659768283367157\n",
      "epoch: 3 step: 2013, loss is 0.0014390498399734497\n",
      "epoch: 3 step: 2014, loss is 0.027470823377370834\n",
      "epoch: 3 step: 2015, loss is 0.0005876323557458818\n",
      "epoch: 3 step: 2016, loss is 0.004149707965552807\n",
      "epoch: 3 step: 2017, loss is 0.000871131953317672\n",
      "epoch: 3 step: 2018, loss is 0.00701764365658164\n",
      "epoch: 3 step: 2019, loss is 0.029281282797455788\n",
      "epoch: 3 step: 2020, loss is 0.0020544235594570637\n",
      "epoch: 3 step: 2021, loss is 0.012280737981200218\n",
      "epoch: 3 step: 2022, loss is 0.18241386115550995\n",
      "epoch: 3 step: 2023, loss is 0.10919485241174698\n",
      "epoch: 3 step: 2024, loss is 0.010018293745815754\n",
      "epoch: 3 step: 2025, loss is 0.002504447242245078\n",
      "epoch: 3 step: 2026, loss is 0.07289514690637589\n",
      "epoch: 3 step: 2027, loss is 0.005940879695117474\n",
      "epoch: 3 step: 2028, loss is 0.004666863474994898\n",
      "epoch: 3 step: 2029, loss is 0.018241170793771744\n",
      "epoch: 3 step: 2030, loss is 0.12274883687496185\n",
      "epoch: 3 step: 2031, loss is 0.0008620674489066005\n",
      "epoch: 3 step: 2032, loss is 0.08569991588592529\n",
      "epoch: 3 step: 2033, loss is 0.06256945431232452\n",
      "epoch: 3 step: 2034, loss is 0.000716589333023876\n",
      "epoch: 3 step: 2035, loss is 0.0032155662775039673\n",
      "epoch: 3 step: 2036, loss is 0.019654927775263786\n",
      "epoch: 3 step: 2037, loss is 0.029776528477668762\n",
      "epoch: 3 step: 2038, loss is 0.03418663516640663\n",
      "epoch: 3 step: 2039, loss is 0.01815750263631344\n",
      "epoch: 3 step: 2040, loss is 0.0017107134917750955\n",
      "epoch: 3 step: 2041, loss is 0.0005880107637494802\n",
      "epoch: 3 step: 2042, loss is 0.0213245190680027\n",
      "epoch: 3 step: 2043, loss is 0.26746612787246704\n",
      "epoch: 3 step: 2044, loss is 0.003595503978431225\n",
      "epoch: 3 step: 2045, loss is 0.0020995107479393482\n",
      "epoch: 3 step: 2046, loss is 0.009011423215270042\n",
      "epoch: 3 step: 2047, loss is 0.12932783365249634\n",
      "epoch: 3 step: 2048, loss is 0.004287661053240299\n",
      "epoch: 3 step: 2049, loss is 0.045169733464717865\n",
      "epoch: 3 step: 2050, loss is 0.00292911846190691\n",
      "epoch: 3 step: 2051, loss is 0.0018530705710873008\n",
      "epoch: 3 step: 2052, loss is 0.002163183642551303\n",
      "epoch: 3 step: 2053, loss is 0.021293459460139275\n",
      "epoch: 3 step: 2054, loss is 0.003841054392978549\n",
      "epoch: 3 step: 2055, loss is 0.06604982912540436\n",
      "epoch: 3 step: 2056, loss is 0.00720168137922883\n",
      "epoch: 3 step: 2057, loss is 0.05209248140454292\n",
      "epoch: 3 step: 2058, loss is 0.05286542326211929\n",
      "epoch: 3 step: 2059, loss is 0.062438685446977615\n",
      "epoch: 3 step: 2060, loss is 0.11788859218358994\n",
      "epoch: 3 step: 2061, loss is 0.07726559787988663\n",
      "epoch: 3 step: 2062, loss is 0.22867612540721893\n",
      "epoch: 3 step: 2063, loss is 0.008055044338107109\n",
      "epoch: 3 step: 2064, loss is 0.012890036217868328\n",
      "epoch: 3 step: 2065, loss is 0.06826947629451752\n",
      "epoch: 3 step: 2066, loss is 0.002255053259432316\n",
      "epoch: 3 step: 2067, loss is 0.0006509413360618055\n",
      "epoch: 3 step: 2068, loss is 0.06147308275103569\n",
      "epoch: 3 step: 2069, loss is 0.03344034031033516\n",
      "epoch: 3 step: 2070, loss is 0.06308265030384064\n",
      "epoch: 3 step: 2071, loss is 0.1842130422592163\n",
      "epoch: 3 step: 2072, loss is 0.009712846018373966\n",
      "epoch: 3 step: 2073, loss is 0.022510671988129616\n",
      "epoch: 3 step: 2074, loss is 0.054403048008680344\n",
      "epoch: 3 step: 2075, loss is 0.0006000815774314106\n",
      "epoch: 3 step: 2076, loss is 0.020449260249733925\n",
      "epoch: 3 step: 2077, loss is 0.030880942940711975\n",
      "epoch: 3 step: 2078, loss is 0.15198522806167603\n",
      "epoch: 3 step: 2079, loss is 0.028541872277855873\n",
      "epoch: 3 step: 2080, loss is 0.08774519711732864\n",
      "epoch: 3 step: 2081, loss is 0.04470648989081383\n",
      "epoch: 3 step: 2082, loss is 0.059233859181404114\n",
      "epoch: 3 step: 2083, loss is 0.0008978849509730935\n",
      "epoch: 3 step: 2084, loss is 0.07241655886173248\n",
      "epoch: 3 step: 2085, loss is 0.014682117849588394\n",
      "epoch: 3 step: 2086, loss is 0.03834177926182747\n",
      "epoch: 3 step: 2087, loss is 0.020570235326886177\n",
      "epoch: 3 step: 2088, loss is 0.008916563354432583\n",
      "epoch: 3 step: 2089, loss is 0.012399043887853622\n",
      "epoch: 3 step: 2090, loss is 0.04074884206056595\n",
      "epoch: 3 step: 2091, loss is 0.03167745843529701\n",
      "epoch: 3 step: 2092, loss is 0.04961692914366722\n",
      "epoch: 3 step: 2093, loss is 0.011042247526347637\n",
      "epoch: 3 step: 2094, loss is 0.00927920825779438\n",
      "epoch: 3 step: 2095, loss is 0.002349543385207653\n",
      "epoch: 3 step: 2096, loss is 0.06697511672973633\n",
      "epoch: 3 step: 2097, loss is 0.04018080234527588\n",
      "epoch: 3 step: 2098, loss is 0.04250304028391838\n",
      "epoch: 3 step: 2099, loss is 0.018283983692526817\n",
      "epoch: 3 step: 2100, loss is 0.0005301308701746166\n",
      "epoch: 3 step: 2101, loss is 0.02314627915620804\n",
      "epoch: 3 step: 2102, loss is 0.0006728302105329931\n",
      "epoch: 3 step: 2103, loss is 0.0011868065921589732\n",
      "epoch: 3 step: 2104, loss is 0.09548084437847137\n",
      "epoch: 3 step: 2105, loss is 0.06154215335845947\n",
      "epoch: 3 step: 2106, loss is 0.039963334798812866\n",
      "epoch: 3 step: 2107, loss is 0.011168273165822029\n",
      "epoch: 3 step: 2108, loss is 0.07483957707881927\n",
      "epoch: 3 step: 2109, loss is 0.013957653194665909\n",
      "epoch: 3 step: 2110, loss is 0.002694632625207305\n",
      "epoch: 3 step: 2111, loss is 0.00903287436813116\n",
      "epoch: 3 step: 2112, loss is 0.02316260151565075\n",
      "epoch: 3 step: 2113, loss is 0.019539181143045425\n",
      "epoch: 3 step: 2114, loss is 0.007859757170081139\n",
      "epoch: 3 step: 2115, loss is 0.023191655054688454\n",
      "epoch: 3 step: 2116, loss is 0.0069901542738080025\n",
      "epoch: 3 step: 2117, loss is 0.03667275235056877\n",
      "epoch: 3 step: 2118, loss is 0.005417580716311932\n",
      "epoch: 3 step: 2119, loss is 0.00038477295311167836\n",
      "epoch: 3 step: 2120, loss is 0.012310950085520744\n",
      "epoch: 3 step: 2121, loss is 0.0266574639827013\n",
      "epoch: 3 step: 2122, loss is 0.0025473767891526222\n",
      "epoch: 3 step: 2123, loss is 0.09068368375301361\n",
      "epoch: 3 step: 2124, loss is 0.057520586997270584\n",
      "epoch: 3 step: 2125, loss is 0.12049247324466705\n",
      "epoch: 3 step: 2126, loss is 0.0008440886740572751\n",
      "epoch: 3 step: 2127, loss is 0.007533265743404627\n",
      "epoch: 3 step: 2128, loss is 0.0011431585298851132\n",
      "epoch: 3 step: 2129, loss is 0.004137744661420584\n",
      "epoch: 3 step: 2130, loss is 0.10337401926517487\n",
      "epoch: 3 step: 2131, loss is 0.07521813362836838\n",
      "epoch: 3 step: 2132, loss is 0.16800861060619354\n",
      "epoch: 3 step: 2133, loss is 0.22047799825668335\n",
      "epoch: 3 step: 2134, loss is 0.0024160905741155148\n",
      "epoch: 3 step: 2135, loss is 0.00025719916447997093\n",
      "epoch: 3 step: 2136, loss is 0.011550418101251125\n",
      "epoch: 3 step: 2137, loss is 0.009254537522792816\n",
      "epoch: 3 step: 2138, loss is 0.0014746354427188635\n",
      "epoch: 3 step: 2139, loss is 0.03644748777151108\n",
      "epoch: 3 step: 2140, loss is 0.008449138142168522\n",
      "epoch: 3 step: 2141, loss is 0.0037421018350869417\n",
      "epoch: 3 step: 2142, loss is 0.000767027959227562\n",
      "epoch: 3 step: 2143, loss is 0.03951052203774452\n",
      "epoch: 3 step: 2144, loss is 0.024179751053452492\n",
      "epoch: 3 step: 2145, loss is 0.0022204651031643152\n",
      "epoch: 3 step: 2146, loss is 0.044871736317873\n",
      "epoch: 3 step: 2147, loss is 0.0015755579806864262\n",
      "epoch: 3 step: 2148, loss is 0.0017046872526407242\n",
      "epoch: 3 step: 2149, loss is 0.17017406225204468\n",
      "epoch: 3 step: 2150, loss is 0.028788980096578598\n",
      "epoch: 3 step: 2151, loss is 0.1187358871102333\n",
      "epoch: 3 step: 2152, loss is 0.0002861515968106687\n",
      "epoch: 3 step: 2153, loss is 0.02651623636484146\n",
      "epoch: 3 step: 2154, loss is 0.0023576158564537764\n",
      "epoch: 3 step: 2155, loss is 0.1268978714942932\n",
      "epoch: 3 step: 2156, loss is 0.0002396516065346077\n",
      "epoch: 3 step: 2157, loss is 0.0793391689658165\n",
      "epoch: 3 step: 2158, loss is 0.0006594556616619229\n",
      "epoch: 3 step: 2159, loss is 0.002142596058547497\n",
      "epoch: 3 step: 2160, loss is 0.02136385068297386\n",
      "epoch: 3 step: 2161, loss is 0.004927928559482098\n",
      "epoch: 3 step: 2162, loss is 0.026785437017679214\n",
      "epoch: 3 step: 2163, loss is 0.07078030705451965\n",
      "epoch: 3 step: 2164, loss is 0.002666299697011709\n",
      "epoch: 3 step: 2165, loss is 0.0016609716694802046\n",
      "epoch: 3 step: 2166, loss is 0.0013986974954605103\n",
      "epoch: 3 step: 2167, loss is 0.07512984424829483\n",
      "epoch: 3 step: 2168, loss is 0.01827304996550083\n",
      "epoch: 3 step: 2169, loss is 0.022195130586624146\n",
      "epoch: 3 step: 2170, loss is 0.01662272773683071\n",
      "epoch: 3 step: 2171, loss is 0.0021799502428621054\n",
      "epoch: 3 step: 2172, loss is 0.0003889824147336185\n",
      "epoch: 3 step: 2173, loss is 0.06726453453302383\n",
      "epoch: 3 step: 2174, loss is 0.014906206168234348\n",
      "epoch: 3 step: 2175, loss is 0.0005207357462495565\n",
      "epoch: 3 step: 2176, loss is 0.010959779843688011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 2177, loss is 0.01368491631001234\n",
      "epoch: 3 step: 2178, loss is 0.13971421122550964\n",
      "epoch: 3 step: 2179, loss is 0.0030262579675763845\n",
      "epoch: 3 step: 2180, loss is 0.04240600764751434\n",
      "epoch: 3 step: 2181, loss is 0.08737480640411377\n",
      "epoch: 3 step: 2182, loss is 0.0031176041811704636\n",
      "epoch: 3 step: 2183, loss is 0.006440145894885063\n",
      "epoch: 3 step: 2184, loss is 0.09578009694814682\n",
      "epoch: 3 step: 2185, loss is 0.07547813653945923\n",
      "epoch: 3 step: 2186, loss is 0.0004797744331881404\n",
      "epoch: 3 step: 2187, loss is 0.020599599927663803\n",
      "epoch: 4 step: 1, loss is 0.0038974552880972624\n",
      "epoch: 4 step: 2, loss is 0.003847783897072077\n",
      "epoch: 4 step: 3, loss is 0.00022964119852986187\n",
      "epoch: 4 step: 4, loss is 0.22100453078746796\n",
      "epoch: 4 step: 5, loss is 0.007212646305561066\n",
      "epoch: 4 step: 6, loss is 0.02271612547338009\n",
      "epoch: 4 step: 7, loss is 0.01761390082538128\n",
      "epoch: 4 step: 8, loss is 0.03540951386094093\n",
      "epoch: 4 step: 9, loss is 0.05590544268488884\n",
      "epoch: 4 step: 10, loss is 0.19151225686073303\n",
      "epoch: 4 step: 11, loss is 0.1515330821275711\n",
      "epoch: 4 step: 12, loss is 0.22287310659885406\n",
      "epoch: 4 step: 13, loss is 0.0012221263023093343\n",
      "epoch: 4 step: 14, loss is 0.04422512650489807\n",
      "epoch: 4 step: 15, loss is 0.0006265768315643072\n",
      "epoch: 4 step: 16, loss is 0.005591084249317646\n",
      "epoch: 4 step: 17, loss is 0.0038926813285797834\n",
      "epoch: 4 step: 18, loss is 0.012826303951442242\n",
      "epoch: 4 step: 19, loss is 0.03912945091724396\n",
      "epoch: 4 step: 20, loss is 0.02602180652320385\n",
      "epoch: 4 step: 21, loss is 0.01224685087800026\n",
      "epoch: 4 step: 22, loss is 0.32291802763938904\n",
      "epoch: 4 step: 23, loss is 0.030201448127627373\n",
      "epoch: 4 step: 24, loss is 0.017525924369692802\n",
      "epoch: 4 step: 25, loss is 0.03614698722958565\n",
      "epoch: 4 step: 26, loss is 0.045137565582990646\n",
      "epoch: 4 step: 27, loss is 0.08964276313781738\n",
      "epoch: 4 step: 28, loss is 0.01013079471886158\n",
      "epoch: 4 step: 29, loss is 0.0033399288076907396\n",
      "epoch: 4 step: 30, loss is 0.017817314714193344\n",
      "epoch: 4 step: 31, loss is 0.09664508700370789\n",
      "epoch: 4 step: 32, loss is 0.004993881098926067\n",
      "epoch: 4 step: 33, loss is 0.0008098910329863429\n",
      "epoch: 4 step: 34, loss is 0.1594453752040863\n",
      "epoch: 4 step: 35, loss is 0.013513597659766674\n",
      "epoch: 4 step: 36, loss is 0.1956138163805008\n",
      "epoch: 4 step: 37, loss is 0.006990653462707996\n",
      "epoch: 4 step: 38, loss is 0.013693948276340961\n",
      "epoch: 4 step: 39, loss is 0.02167903631925583\n",
      "epoch: 4 step: 40, loss is 0.15842771530151367\n",
      "epoch: 4 step: 41, loss is 0.0571785531938076\n",
      "epoch: 4 step: 42, loss is 0.005926691927015781\n",
      "epoch: 4 step: 43, loss is 0.003751841839402914\n",
      "epoch: 4 step: 44, loss is 0.009571690112352371\n",
      "epoch: 4 step: 45, loss is 0.0019994163885712624\n",
      "epoch: 4 step: 46, loss is 0.00043048348743468523\n",
      "epoch: 4 step: 47, loss is 0.006416442804038525\n",
      "epoch: 4 step: 48, loss is 0.012174881063401699\n",
      "epoch: 4 step: 49, loss is 0.021481765434145927\n",
      "epoch: 4 step: 50, loss is 0.12704989314079285\n",
      "epoch: 4 step: 51, loss is 0.002101955935359001\n",
      "epoch: 4 step: 52, loss is 0.14362919330596924\n",
      "epoch: 4 step: 53, loss is 0.002016200451180339\n",
      "epoch: 4 step: 54, loss is 0.007125865202397108\n",
      "epoch: 4 step: 55, loss is 0.0063185556791722775\n",
      "epoch: 4 step: 56, loss is 0.0709366723895073\n",
      "epoch: 4 step: 57, loss is 0.047902997583150864\n",
      "epoch: 4 step: 58, loss is 0.00067008106270805\n",
      "epoch: 4 step: 59, loss is 0.003430993529036641\n",
      "epoch: 4 step: 60, loss is 0.012728984467685223\n",
      "epoch: 4 step: 61, loss is 0.00109603232704103\n",
      "epoch: 4 step: 62, loss is 0.03087165206670761\n",
      "epoch: 4 step: 63, loss is 0.014293283224105835\n",
      "epoch: 4 step: 64, loss is 0.023177659139037132\n",
      "epoch: 4 step: 65, loss is 0.002126299776136875\n",
      "epoch: 4 step: 66, loss is 0.06628648191690445\n",
      "epoch: 4 step: 67, loss is 0.07703391462564468\n",
      "epoch: 4 step: 68, loss is 0.0006097553414292634\n",
      "epoch: 4 step: 69, loss is 0.06509952247142792\n",
      "epoch: 4 step: 70, loss is 0.04611120745539665\n",
      "epoch: 4 step: 71, loss is 0.020535921677947044\n",
      "epoch: 4 step: 72, loss is 0.0009873636299744248\n",
      "epoch: 4 step: 73, loss is 0.01085335947573185\n",
      "epoch: 4 step: 74, loss is 0.07776261121034622\n",
      "epoch: 4 step: 75, loss is 0.0024664446245878935\n",
      "epoch: 4 step: 76, loss is 0.03202538564801216\n",
      "epoch: 4 step: 77, loss is 0.006260976195335388\n",
      "epoch: 4 step: 78, loss is 0.004178231116384268\n",
      "epoch: 4 step: 79, loss is 0.0018168921815231442\n",
      "epoch: 4 step: 80, loss is 0.0019606018904596567\n",
      "epoch: 4 step: 81, loss is 0.003165080677717924\n",
      "epoch: 4 step: 82, loss is 0.038788802921772\n",
      "epoch: 4 step: 83, loss is 0.02558870241045952\n",
      "epoch: 4 step: 84, loss is 0.009919170290231705\n",
      "epoch: 4 step: 85, loss is 0.06749846786260605\n",
      "epoch: 4 step: 86, loss is 0.057483043521642685\n",
      "epoch: 4 step: 87, loss is 0.002146349521353841\n",
      "epoch: 4 step: 88, loss is 0.0015785673167556524\n",
      "epoch: 4 step: 89, loss is 0.011756866239011288\n",
      "epoch: 4 step: 90, loss is 0.05764101445674896\n",
      "epoch: 4 step: 91, loss is 0.36471888422966003\n",
      "epoch: 4 step: 92, loss is 0.07984478771686554\n",
      "epoch: 4 step: 93, loss is 0.005731169134378433\n",
      "epoch: 4 step: 94, loss is 0.2624305784702301\n",
      "epoch: 4 step: 95, loss is 0.002697806106880307\n",
      "epoch: 4 step: 96, loss is 0.030094174668192863\n",
      "epoch: 4 step: 97, loss is 0.06409727782011032\n",
      "epoch: 4 step: 98, loss is 0.0025441604666411877\n",
      "epoch: 4 step: 99, loss is 0.024590451270341873\n",
      "epoch: 4 step: 100, loss is 0.0017359458142891526\n",
      "epoch: 4 step: 101, loss is 0.002828284865245223\n",
      "epoch: 4 step: 102, loss is 0.043774865567684174\n",
      "epoch: 4 step: 103, loss is 0.004786563105881214\n",
      "epoch: 4 step: 104, loss is 0.011846505105495453\n",
      "epoch: 4 step: 105, loss is 0.002910183509811759\n",
      "epoch: 4 step: 106, loss is 0.10113506019115448\n",
      "epoch: 4 step: 107, loss is 0.005168895702809095\n",
      "epoch: 4 step: 108, loss is 0.06445363163948059\n",
      "epoch: 4 step: 109, loss is 0.001325842342339456\n",
      "epoch: 4 step: 110, loss is 0.03594139218330383\n",
      "epoch: 4 step: 111, loss is 0.0036539873108267784\n",
      "epoch: 4 step: 112, loss is 0.0961356833577156\n",
      "epoch: 4 step: 113, loss is 0.001267186482436955\n",
      "epoch: 4 step: 114, loss is 0.2887933850288391\n",
      "epoch: 4 step: 115, loss is 0.11622599512338638\n",
      "epoch: 4 step: 116, loss is 0.011595772579312325\n",
      "epoch: 4 step: 117, loss is 0.002246301621198654\n",
      "epoch: 4 step: 118, loss is 0.0021937210112810135\n",
      "epoch: 4 step: 119, loss is 0.04505923017859459\n",
      "epoch: 4 step: 120, loss is 0.0031346972100436687\n",
      "epoch: 4 step: 121, loss is 0.026233231648802757\n",
      "epoch: 4 step: 122, loss is 0.0012589485850185156\n",
      "epoch: 4 step: 123, loss is 0.03768547996878624\n",
      "epoch: 4 step: 124, loss is 0.0011129938066005707\n",
      "epoch: 4 step: 125, loss is 0.10406830906867981\n",
      "epoch: 4 step: 126, loss is 0.06901690363883972\n",
      "epoch: 4 step: 127, loss is 0.0024617048911750317\n",
      "epoch: 4 step: 128, loss is 0.006219761911779642\n",
      "epoch: 4 step: 129, loss is 0.001463877153582871\n",
      "epoch: 4 step: 130, loss is 0.00616308581084013\n",
      "epoch: 4 step: 131, loss is 0.001975607592612505\n",
      "epoch: 4 step: 132, loss is 0.008851615712046623\n",
      "epoch: 4 step: 133, loss is 0.003335534129291773\n",
      "epoch: 4 step: 134, loss is 0.018746482208371162\n",
      "epoch: 4 step: 135, loss is 0.002391334855929017\n",
      "epoch: 4 step: 136, loss is 0.05834994092583656\n",
      "epoch: 4 step: 137, loss is 0.007321896031498909\n",
      "epoch: 4 step: 138, loss is 0.0764274001121521\n",
      "epoch: 4 step: 139, loss is 0.11107317358255386\n",
      "epoch: 4 step: 140, loss is 0.011081483215093613\n",
      "epoch: 4 step: 141, loss is 0.005293125752359629\n",
      "epoch: 4 step: 142, loss is 0.003581474767997861\n",
      "epoch: 4 step: 143, loss is 0.0325833261013031\n",
      "epoch: 4 step: 144, loss is 0.007471836172044277\n",
      "epoch: 4 step: 145, loss is 0.0009133077692240477\n",
      "epoch: 4 step: 146, loss is 0.14681093394756317\n",
      "epoch: 4 step: 147, loss is 0.17000238597393036\n",
      "epoch: 4 step: 148, loss is 0.06219926103949547\n",
      "epoch: 4 step: 149, loss is 0.011899604462087154\n",
      "epoch: 4 step: 150, loss is 0.008052160032093525\n",
      "epoch: 4 step: 151, loss is 0.027033235877752304\n",
      "epoch: 4 step: 152, loss is 0.012019223533570766\n",
      "epoch: 4 step: 153, loss is 0.017896540462970734\n",
      "epoch: 4 step: 154, loss is 0.0011210483498871326\n",
      "epoch: 4 step: 155, loss is 0.02827644720673561\n",
      "epoch: 4 step: 156, loss is 0.0536063089966774\n",
      "epoch: 4 step: 157, loss is 0.003638916416093707\n",
      "epoch: 4 step: 158, loss is 0.0013483682414516807\n",
      "epoch: 4 step: 159, loss is 0.007139775902032852\n",
      "epoch: 4 step: 160, loss is 0.002829419681802392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 161, loss is 0.006886345334351063\n",
      "epoch: 4 step: 162, loss is 0.021806376054883003\n",
      "epoch: 4 step: 163, loss is 0.009680360555648804\n",
      "epoch: 4 step: 164, loss is 0.0015730231534689665\n",
      "epoch: 4 step: 165, loss is 0.02027696929872036\n",
      "epoch: 4 step: 166, loss is 0.013717396184802055\n",
      "epoch: 4 step: 167, loss is 0.0027103067841380835\n",
      "epoch: 4 step: 168, loss is 0.012032424099743366\n",
      "epoch: 4 step: 169, loss is 0.043441291898489\n",
      "epoch: 4 step: 170, loss is 0.0336020365357399\n",
      "epoch: 4 step: 171, loss is 0.04411832243204117\n",
      "epoch: 4 step: 172, loss is 0.140692800283432\n",
      "epoch: 4 step: 173, loss is 0.16978120803833008\n",
      "epoch: 4 step: 174, loss is 0.0020752246491611004\n",
      "epoch: 4 step: 175, loss is 0.03546890243887901\n",
      "epoch: 4 step: 176, loss is 0.010607401840388775\n",
      "epoch: 4 step: 177, loss is 0.1299770325422287\n",
      "epoch: 4 step: 178, loss is 0.004610906820744276\n",
      "epoch: 4 step: 179, loss is 0.00034977341420017183\n",
      "epoch: 4 step: 180, loss is 0.0010196485091000795\n",
      "epoch: 4 step: 181, loss is 0.03527397662401199\n",
      "epoch: 4 step: 182, loss is 0.003016849746927619\n",
      "epoch: 4 step: 183, loss is 0.10017095506191254\n",
      "epoch: 4 step: 184, loss is 0.004972217604517937\n",
      "epoch: 4 step: 185, loss is 0.009517667815089226\n",
      "epoch: 4 step: 186, loss is 0.0023357351310551167\n",
      "epoch: 4 step: 187, loss is 0.1258975714445114\n",
      "epoch: 4 step: 188, loss is 0.030241068452596664\n",
      "epoch: 4 step: 189, loss is 0.08304057270288467\n",
      "epoch: 4 step: 190, loss is 0.06558171659708023\n",
      "epoch: 4 step: 191, loss is 0.003575701965019107\n",
      "epoch: 4 step: 192, loss is 0.02414005436003208\n",
      "epoch: 4 step: 193, loss is 0.037597112357616425\n",
      "epoch: 4 step: 194, loss is 0.003719778498634696\n",
      "epoch: 4 step: 195, loss is 0.0030197687447071075\n",
      "epoch: 4 step: 196, loss is 0.009183964692056179\n",
      "epoch: 4 step: 197, loss is 0.0008743248763494194\n",
      "epoch: 4 step: 198, loss is 0.006428879220038652\n",
      "epoch: 4 step: 199, loss is 0.007672404404729605\n",
      "epoch: 4 step: 200, loss is 0.05846580117940903\n",
      "epoch: 4 step: 201, loss is 0.000608396134339273\n",
      "epoch: 4 step: 202, loss is 0.004104927182197571\n",
      "epoch: 4 step: 203, loss is 0.0022380549926310778\n",
      "epoch: 4 step: 204, loss is 0.12293403595685959\n",
      "epoch: 4 step: 205, loss is 0.0004800673632416874\n",
      "epoch: 4 step: 206, loss is 0.00046251193271018565\n",
      "epoch: 4 step: 207, loss is 0.04014277458190918\n",
      "epoch: 4 step: 208, loss is 0.0048614321276545525\n",
      "epoch: 4 step: 209, loss is 0.033611781895160675\n",
      "epoch: 4 step: 210, loss is 0.09679273515939713\n",
      "epoch: 4 step: 211, loss is 0.05096345394849777\n",
      "epoch: 4 step: 212, loss is 0.0032620925921946764\n",
      "epoch: 4 step: 213, loss is 0.0017242624890059233\n",
      "epoch: 4 step: 214, loss is 0.0175493024289608\n",
      "epoch: 4 step: 215, loss is 0.008468949235975742\n",
      "epoch: 4 step: 216, loss is 0.03138011693954468\n",
      "epoch: 4 step: 217, loss is 0.0005714504513889551\n",
      "epoch: 4 step: 218, loss is 0.03170176222920418\n",
      "epoch: 4 step: 219, loss is 0.0027017095126211643\n",
      "epoch: 4 step: 220, loss is 0.0016709621995687485\n",
      "epoch: 4 step: 221, loss is 0.06551169604063034\n",
      "epoch: 4 step: 222, loss is 0.0005849828012287617\n",
      "epoch: 4 step: 223, loss is 0.02658785693347454\n",
      "epoch: 4 step: 224, loss is 0.001859067240729928\n",
      "epoch: 4 step: 225, loss is 0.08057969063520432\n",
      "epoch: 4 step: 226, loss is 0.027033329010009766\n",
      "epoch: 4 step: 227, loss is 0.002738794544711709\n",
      "epoch: 4 step: 228, loss is 0.008005372248589993\n",
      "epoch: 4 step: 229, loss is 0.002204063581302762\n",
      "epoch: 4 step: 230, loss is 0.028225693851709366\n",
      "epoch: 4 step: 231, loss is 0.0007597743533551693\n",
      "epoch: 4 step: 232, loss is 0.016378842294216156\n",
      "epoch: 4 step: 233, loss is 0.004968269728124142\n",
      "epoch: 4 step: 234, loss is 0.0010734888492152095\n",
      "epoch: 4 step: 235, loss is 0.05164942890405655\n",
      "epoch: 4 step: 236, loss is 0.00021464833116624504\n",
      "epoch: 4 step: 237, loss is 0.007330610416829586\n",
      "epoch: 4 step: 238, loss is 0.02620091661810875\n",
      "epoch: 4 step: 239, loss is 0.0004051710129715502\n",
      "epoch: 4 step: 240, loss is 0.1201748475432396\n",
      "epoch: 4 step: 241, loss is 0.005933241453021765\n",
      "epoch: 4 step: 242, loss is 0.01311210636049509\n",
      "epoch: 4 step: 243, loss is 0.05103042721748352\n",
      "epoch: 4 step: 244, loss is 0.022565312683582306\n",
      "epoch: 4 step: 245, loss is 0.0030657644383609295\n",
      "epoch: 4 step: 246, loss is 0.001355624757707119\n",
      "epoch: 4 step: 247, loss is 0.0009169313707388937\n",
      "epoch: 4 step: 248, loss is 0.003499478567391634\n",
      "epoch: 4 step: 249, loss is 0.0011900389799848199\n",
      "epoch: 4 step: 250, loss is 0.0054329088889062405\n",
      "epoch: 4 step: 251, loss is 0.0031886606011539698\n",
      "epoch: 4 step: 252, loss is 0.002306247130036354\n",
      "epoch: 4 step: 253, loss is 0.0008912975899875164\n",
      "epoch: 4 step: 254, loss is 0.0004115006304346025\n",
      "epoch: 4 step: 255, loss is 0.006251321639865637\n",
      "epoch: 4 step: 256, loss is 0.000933359726332128\n",
      "epoch: 4 step: 257, loss is 0.007527758367359638\n",
      "epoch: 4 step: 258, loss is 0.0022620444651693106\n",
      "epoch: 4 step: 259, loss is 0.0014534932561218739\n",
      "epoch: 4 step: 260, loss is 0.002441179007291794\n",
      "epoch: 4 step: 261, loss is 0.00015217778855003417\n",
      "epoch: 4 step: 262, loss is 0.16569878160953522\n",
      "epoch: 4 step: 263, loss is 0.0002374391769990325\n",
      "epoch: 4 step: 264, loss is 0.02892148308455944\n",
      "epoch: 4 step: 265, loss is 0.01024477556347847\n",
      "epoch: 4 step: 266, loss is 0.01591774821281433\n",
      "epoch: 4 step: 267, loss is 0.04200594872236252\n",
      "epoch: 4 step: 268, loss is 0.036061421036720276\n",
      "epoch: 4 step: 269, loss is 0.010342068038880825\n",
      "epoch: 4 step: 270, loss is 0.0005578473210334778\n",
      "epoch: 4 step: 271, loss is 0.005594324320554733\n",
      "epoch: 4 step: 272, loss is 0.016476867720484734\n",
      "epoch: 4 step: 273, loss is 0.017660513520240784\n",
      "epoch: 4 step: 274, loss is 0.004371402785181999\n",
      "epoch: 4 step: 275, loss is 0.0003808467590715736\n",
      "epoch: 4 step: 276, loss is 0.0006425123428925872\n",
      "epoch: 4 step: 277, loss is 0.001746071269735694\n",
      "epoch: 4 step: 278, loss is 0.002384395804256201\n",
      "epoch: 4 step: 279, loss is 0.0423792339861393\n",
      "epoch: 4 step: 280, loss is 0.053120579570531845\n",
      "epoch: 4 step: 281, loss is 0.0010497033363208175\n",
      "epoch: 4 step: 282, loss is 0.1276269108057022\n",
      "epoch: 4 step: 283, loss is 0.004115642048418522\n",
      "epoch: 4 step: 284, loss is 0.00065189617453143\n",
      "epoch: 4 step: 285, loss is 0.009191198274493217\n",
      "epoch: 4 step: 286, loss is 0.09075946360826492\n",
      "epoch: 4 step: 287, loss is 0.005439296830445528\n",
      "epoch: 4 step: 288, loss is 0.0013704744633287191\n",
      "epoch: 4 step: 289, loss is 0.002927500521764159\n",
      "epoch: 4 step: 290, loss is 0.011949076317250729\n",
      "epoch: 4 step: 291, loss is 0.00045460424735210836\n",
      "epoch: 4 step: 292, loss is 0.0013972267042845488\n",
      "epoch: 4 step: 293, loss is 0.043321214616298676\n",
      "epoch: 4 step: 294, loss is 0.0014216562267392874\n",
      "epoch: 4 step: 295, loss is 0.002827770309522748\n",
      "epoch: 4 step: 296, loss is 0.0017525748116895556\n",
      "epoch: 4 step: 297, loss is 0.0033031259663403034\n",
      "epoch: 4 step: 298, loss is 0.03284035623073578\n",
      "epoch: 4 step: 299, loss is 0.0003729771706275642\n",
      "epoch: 4 step: 300, loss is 0.00390181178227067\n",
      "epoch: 4 step: 301, loss is 0.016015667468309402\n",
      "epoch: 4 step: 302, loss is 0.060179609805345535\n",
      "epoch: 4 step: 303, loss is 0.015134253539144993\n",
      "epoch: 4 step: 304, loss is 0.005399794317781925\n",
      "epoch: 4 step: 305, loss is 0.0002497390378266573\n",
      "epoch: 4 step: 306, loss is 0.15290406346321106\n",
      "epoch: 4 step: 307, loss is 0.002578504616394639\n",
      "epoch: 4 step: 308, loss is 0.05665881559252739\n",
      "epoch: 4 step: 309, loss is 0.01831630803644657\n",
      "epoch: 4 step: 310, loss is 0.10386175662279129\n",
      "epoch: 4 step: 311, loss is 0.006172898691147566\n",
      "epoch: 4 step: 312, loss is 0.03671297803521156\n",
      "epoch: 4 step: 313, loss is 0.014867990277707577\n",
      "epoch: 4 step: 314, loss is 0.005429969169199467\n",
      "epoch: 4 step: 315, loss is 0.0021925491746515036\n",
      "epoch: 4 step: 316, loss is 0.00033114705001935363\n",
      "epoch: 4 step: 317, loss is 0.0035674232058227062\n",
      "epoch: 4 step: 318, loss is 0.014860083349049091\n",
      "epoch: 4 step: 319, loss is 0.001499429577961564\n",
      "epoch: 4 step: 320, loss is 0.002504150616005063\n",
      "epoch: 4 step: 321, loss is 0.10030687600374222\n",
      "epoch: 4 step: 322, loss is 0.000926612876355648\n",
      "epoch: 4 step: 323, loss is 0.021895531564950943\n",
      "epoch: 4 step: 324, loss is 0.0004176999500487\n",
      "epoch: 4 step: 325, loss is 0.0027073859237134457\n",
      "epoch: 4 step: 326, loss is 0.0009941961616277695\n",
      "epoch: 4 step: 327, loss is 0.09346435219049454\n",
      "epoch: 4 step: 328, loss is 0.009094664826989174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 329, loss is 0.039711032062768936\n",
      "epoch: 4 step: 330, loss is 0.0008988498011603951\n",
      "epoch: 4 step: 331, loss is 0.05653129890561104\n",
      "epoch: 4 step: 332, loss is 0.000562588160391897\n",
      "epoch: 4 step: 333, loss is 0.012566390447318554\n",
      "epoch: 4 step: 334, loss is 0.0030477603431791067\n",
      "epoch: 4 step: 335, loss is 0.0016418419545516372\n",
      "epoch: 4 step: 336, loss is 0.030538471415638924\n",
      "epoch: 4 step: 337, loss is 0.04350288584828377\n",
      "epoch: 4 step: 338, loss is 0.010405655018985271\n",
      "epoch: 4 step: 339, loss is 0.017742564901709557\n",
      "epoch: 4 step: 340, loss is 0.0004745018668472767\n",
      "epoch: 4 step: 341, loss is 0.021702401340007782\n",
      "epoch: 4 step: 342, loss is 0.12598751485347748\n",
      "epoch: 4 step: 343, loss is 0.0004234365769661963\n",
      "epoch: 4 step: 344, loss is 0.03665934503078461\n",
      "epoch: 4 step: 345, loss is 0.02400961145758629\n",
      "epoch: 4 step: 346, loss is 0.0018152233678847551\n",
      "epoch: 4 step: 347, loss is 0.0035173906944692135\n",
      "epoch: 4 step: 348, loss is 0.034510284662246704\n",
      "epoch: 4 step: 349, loss is 0.001011042157188058\n",
      "epoch: 4 step: 350, loss is 0.010017154738307\n",
      "epoch: 4 step: 351, loss is 0.063558429479599\n",
      "epoch: 4 step: 352, loss is 0.00879942998290062\n",
      "epoch: 4 step: 353, loss is 0.0014365339884534478\n",
      "epoch: 4 step: 354, loss is 0.02163415215909481\n",
      "epoch: 4 step: 355, loss is 0.02938305400311947\n",
      "epoch: 4 step: 356, loss is 0.007757549174129963\n",
      "epoch: 4 step: 357, loss is 0.16487568616867065\n",
      "epoch: 4 step: 358, loss is 0.0015022414736449718\n",
      "epoch: 4 step: 359, loss is 0.030387476086616516\n",
      "epoch: 4 step: 360, loss is 0.0046696895733475685\n",
      "epoch: 4 step: 361, loss is 0.012115901336073875\n",
      "epoch: 4 step: 362, loss is 0.02356904000043869\n",
      "epoch: 4 step: 363, loss is 0.012795566581189632\n",
      "epoch: 4 step: 364, loss is 0.15006345510482788\n",
      "epoch: 4 step: 365, loss is 0.10337985306978226\n",
      "epoch: 4 step: 366, loss is 0.0734640508890152\n",
      "epoch: 4 step: 367, loss is 0.0008619994623586535\n",
      "epoch: 4 step: 368, loss is 0.011783908121287823\n",
      "epoch: 4 step: 369, loss is 0.00038871608558110893\n",
      "epoch: 4 step: 370, loss is 0.0071777948178350925\n",
      "epoch: 4 step: 371, loss is 0.004378228913992643\n",
      "epoch: 4 step: 372, loss is 0.004676288925111294\n",
      "epoch: 4 step: 373, loss is 0.045904818922281265\n",
      "epoch: 4 step: 374, loss is 0.03627218306064606\n",
      "epoch: 4 step: 375, loss is 0.003173969453200698\n",
      "epoch: 4 step: 376, loss is 0.1216287910938263\n",
      "epoch: 4 step: 377, loss is 0.0019709125626832247\n",
      "epoch: 4 step: 378, loss is 0.011051534675061703\n",
      "epoch: 4 step: 379, loss is 0.0018317201174795628\n",
      "epoch: 4 step: 380, loss is 0.0009838482365012169\n",
      "epoch: 4 step: 381, loss is 0.00459434324875474\n",
      "epoch: 4 step: 382, loss is 0.05565735697746277\n",
      "epoch: 4 step: 383, loss is 0.0488855242729187\n",
      "epoch: 4 step: 384, loss is 0.06986327469348907\n",
      "epoch: 4 step: 385, loss is 0.011790243908762932\n",
      "epoch: 4 step: 386, loss is 0.0038137517403811216\n",
      "epoch: 4 step: 387, loss is 0.19804124534130096\n",
      "epoch: 4 step: 388, loss is 0.01297887321561575\n",
      "epoch: 4 step: 389, loss is 0.008880622684955597\n",
      "epoch: 4 step: 390, loss is 0.012738739140331745\n",
      "epoch: 4 step: 391, loss is 0.000732681539375335\n",
      "epoch: 4 step: 392, loss is 0.002484443597495556\n",
      "epoch: 4 step: 393, loss is 0.23581409454345703\n",
      "epoch: 4 step: 394, loss is 0.01890612207353115\n",
      "epoch: 4 step: 395, loss is 0.1295030415058136\n",
      "epoch: 4 step: 396, loss is 0.005402047652751207\n",
      "epoch: 4 step: 397, loss is 0.005403342191129923\n",
      "epoch: 4 step: 398, loss is 0.17898550629615784\n",
      "epoch: 4 step: 399, loss is 0.007129686884582043\n",
      "epoch: 4 step: 400, loss is 0.1176161840558052\n",
      "epoch: 4 step: 401, loss is 0.0041731358505785465\n",
      "epoch: 4 step: 402, loss is 0.0305826086550951\n",
      "epoch: 4 step: 403, loss is 0.004768745508044958\n",
      "epoch: 4 step: 404, loss is 0.005387499462813139\n",
      "epoch: 4 step: 405, loss is 0.0016709822230041027\n",
      "epoch: 4 step: 406, loss is 0.025819897651672363\n",
      "epoch: 4 step: 407, loss is 0.0020058017689734697\n",
      "epoch: 4 step: 408, loss is 0.0011928122257813811\n",
      "epoch: 4 step: 409, loss is 0.14801083505153656\n",
      "epoch: 4 step: 410, loss is 0.001012327498756349\n",
      "epoch: 4 step: 411, loss is 0.009940255433321\n",
      "epoch: 4 step: 412, loss is 0.005216819699853659\n",
      "epoch: 4 step: 413, loss is 0.015688620507717133\n",
      "epoch: 4 step: 414, loss is 0.0022058046888560057\n",
      "epoch: 4 step: 415, loss is 0.004774597939103842\n",
      "epoch: 4 step: 416, loss is 0.01954067125916481\n",
      "epoch: 4 step: 417, loss is 0.0061942352913320065\n",
      "epoch: 4 step: 418, loss is 0.011674730107188225\n",
      "epoch: 4 step: 419, loss is 0.0030841445550322533\n",
      "epoch: 4 step: 420, loss is 0.11629227548837662\n",
      "epoch: 4 step: 421, loss is 0.09458929300308228\n",
      "epoch: 4 step: 422, loss is 0.005134955048561096\n",
      "epoch: 4 step: 423, loss is 0.007544563151896\n",
      "epoch: 4 step: 424, loss is 0.011862218379974365\n",
      "epoch: 4 step: 425, loss is 0.12450502067804337\n",
      "epoch: 4 step: 426, loss is 0.008064530789852142\n",
      "epoch: 4 step: 427, loss is 0.08037124574184418\n",
      "epoch: 4 step: 428, loss is 0.09329669922590256\n",
      "epoch: 4 step: 429, loss is 0.011225446127355099\n",
      "epoch: 4 step: 430, loss is 0.008968978188931942\n",
      "epoch: 4 step: 431, loss is 0.000185755270649679\n",
      "epoch: 4 step: 432, loss is 0.13804860413074493\n",
      "epoch: 4 step: 433, loss is 0.004805481527000666\n",
      "epoch: 4 step: 434, loss is 0.022732120007276535\n",
      "epoch: 4 step: 435, loss is 0.020937031134963036\n",
      "epoch: 4 step: 436, loss is 0.03532423451542854\n",
      "epoch: 4 step: 437, loss is 0.007373419590294361\n",
      "epoch: 4 step: 438, loss is 0.0016748030902817845\n",
      "epoch: 4 step: 439, loss is 0.010842187330126762\n",
      "epoch: 4 step: 440, loss is 0.008523262105882168\n",
      "epoch: 4 step: 441, loss is 0.003293856279924512\n",
      "epoch: 4 step: 442, loss is 0.11711866408586502\n",
      "epoch: 4 step: 443, loss is 0.05611744895577431\n",
      "epoch: 4 step: 444, loss is 0.010558385401964188\n",
      "epoch: 4 step: 445, loss is 0.10108716785907745\n",
      "epoch: 4 step: 446, loss is 0.00028495967853814363\n",
      "epoch: 4 step: 447, loss is 0.027900921180844307\n",
      "epoch: 4 step: 448, loss is 0.01168279442936182\n",
      "epoch: 4 step: 449, loss is 0.0025679157115519047\n",
      "epoch: 4 step: 450, loss is 0.019917497411370277\n",
      "epoch: 4 step: 451, loss is 0.00022435153368860483\n",
      "epoch: 4 step: 452, loss is 0.04994088411331177\n",
      "epoch: 4 step: 453, loss is 0.000978604075498879\n",
      "epoch: 4 step: 454, loss is 0.0012027507182210684\n",
      "epoch: 4 step: 455, loss is 0.07681780308485031\n",
      "epoch: 4 step: 456, loss is 0.00042409347952343524\n",
      "epoch: 4 step: 457, loss is 0.2010679692029953\n",
      "epoch: 4 step: 458, loss is 0.03216976672410965\n",
      "epoch: 4 step: 459, loss is 0.06610696762800217\n",
      "epoch: 4 step: 460, loss is 0.07100006192922592\n",
      "epoch: 4 step: 461, loss is 0.007810445036739111\n",
      "epoch: 4 step: 462, loss is 0.010215753689408302\n",
      "epoch: 4 step: 463, loss is 0.0006668489659205079\n",
      "epoch: 4 step: 464, loss is 0.028549406677484512\n",
      "epoch: 4 step: 465, loss is 0.12585651874542236\n",
      "epoch: 4 step: 466, loss is 0.0010903970105573535\n",
      "epoch: 4 step: 467, loss is 0.0002884186105802655\n",
      "epoch: 4 step: 468, loss is 0.03273472189903259\n",
      "epoch: 4 step: 469, loss is 0.02637278288602829\n",
      "epoch: 4 step: 470, loss is 0.0011692626867443323\n",
      "epoch: 4 step: 471, loss is 0.0038701461162418127\n",
      "epoch: 4 step: 472, loss is 0.00022222095867618918\n",
      "epoch: 4 step: 473, loss is 0.033626385033130646\n",
      "epoch: 4 step: 474, loss is 0.0006081436877138913\n",
      "epoch: 4 step: 475, loss is 0.056281015276908875\n",
      "epoch: 4 step: 476, loss is 0.0018186684465035796\n",
      "epoch: 4 step: 477, loss is 0.06080473214387894\n",
      "epoch: 4 step: 478, loss is 0.009312872774899006\n",
      "epoch: 4 step: 479, loss is 0.049832213670015335\n",
      "epoch: 4 step: 480, loss is 0.13815398514270782\n",
      "epoch: 4 step: 481, loss is 0.0031108581461012363\n",
      "epoch: 4 step: 482, loss is 0.0031992094591259956\n",
      "epoch: 4 step: 483, loss is 0.09363663196563721\n",
      "epoch: 4 step: 484, loss is 0.0021539144217967987\n",
      "epoch: 4 step: 485, loss is 0.0006361803389154375\n",
      "epoch: 4 step: 486, loss is 0.0014030317543074489\n",
      "epoch: 4 step: 487, loss is 0.009043075144290924\n",
      "epoch: 4 step: 488, loss is 0.005215099081397057\n",
      "epoch: 4 step: 489, loss is 0.001402466674335301\n",
      "epoch: 4 step: 490, loss is 0.00021222782379481941\n",
      "epoch: 4 step: 491, loss is 0.005295292474329472\n",
      "epoch: 4 step: 492, loss is 0.001514103845693171\n",
      "epoch: 4 step: 493, loss is 0.0020759347826242447\n",
      "epoch: 4 step: 494, loss is 0.01783372461795807\n",
      "epoch: 4 step: 495, loss is 0.031187666580080986\n",
      "epoch: 4 step: 496, loss is 0.0002218680747319013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 497, loss is 0.010567431338131428\n",
      "epoch: 4 step: 498, loss is 0.06553169339895248\n",
      "epoch: 4 step: 499, loss is 0.003373353974893689\n",
      "epoch: 4 step: 500, loss is 0.009302559308707714\n",
      "epoch: 4 step: 501, loss is 0.002022312255576253\n",
      "epoch: 4 step: 502, loss is 0.001772883115336299\n",
      "epoch: 4 step: 503, loss is 0.10781095176935196\n",
      "epoch: 4 step: 504, loss is 0.08879736065864563\n",
      "epoch: 4 step: 505, loss is 0.002000079257413745\n",
      "epoch: 4 step: 506, loss is 0.07772549241781235\n",
      "epoch: 4 step: 507, loss is 0.09380165487527847\n",
      "epoch: 4 step: 508, loss is 0.02032097615301609\n",
      "epoch: 4 step: 509, loss is 0.007966858334839344\n",
      "epoch: 4 step: 510, loss is 0.014184537343680859\n",
      "epoch: 4 step: 511, loss is 0.0035600527189671993\n",
      "epoch: 4 step: 512, loss is 0.0003425090399105102\n",
      "epoch: 4 step: 513, loss is 0.032611455768346786\n",
      "epoch: 4 step: 514, loss is 0.004380608443170786\n",
      "epoch: 4 step: 515, loss is 0.00036004872526973486\n",
      "epoch: 4 step: 516, loss is 0.0014041389804333448\n",
      "epoch: 4 step: 517, loss is 0.0015767172444611788\n",
      "epoch: 4 step: 518, loss is 0.001330728642642498\n",
      "epoch: 4 step: 519, loss is 0.038197945803403854\n",
      "epoch: 4 step: 520, loss is 0.03063676692545414\n",
      "epoch: 4 step: 521, loss is 0.005525894928723574\n",
      "epoch: 4 step: 522, loss is 0.0050331405363976955\n",
      "epoch: 4 step: 523, loss is 0.09396801143884659\n",
      "epoch: 4 step: 524, loss is 0.0012755314819514751\n",
      "epoch: 4 step: 525, loss is 0.08914582431316376\n",
      "epoch: 4 step: 526, loss is 0.007887824438512325\n",
      "epoch: 4 step: 527, loss is 0.05827182158827782\n",
      "epoch: 4 step: 528, loss is 0.00025847775395959616\n",
      "epoch: 4 step: 529, loss is 0.004526949487626553\n",
      "epoch: 4 step: 530, loss is 0.003587360493838787\n",
      "epoch: 4 step: 531, loss is 0.016521921381354332\n",
      "epoch: 4 step: 532, loss is 0.0005037396331317723\n",
      "epoch: 4 step: 533, loss is 0.009281585924327374\n",
      "epoch: 4 step: 534, loss is 0.000424245314206928\n",
      "epoch: 4 step: 535, loss is 0.017465174198150635\n",
      "epoch: 4 step: 536, loss is 0.004970354028046131\n",
      "epoch: 4 step: 537, loss is 0.0007075904868543148\n",
      "epoch: 4 step: 538, loss is 0.0029132585041224957\n",
      "epoch: 4 step: 539, loss is 0.4018958806991577\n",
      "epoch: 4 step: 540, loss is 0.058593254536390305\n",
      "epoch: 4 step: 541, loss is 0.1363413780927658\n",
      "epoch: 4 step: 542, loss is 0.0031326781027019024\n",
      "epoch: 4 step: 543, loss is 0.00918172113597393\n",
      "epoch: 4 step: 544, loss is 0.1293429136276245\n",
      "epoch: 4 step: 545, loss is 0.008194154128432274\n",
      "epoch: 4 step: 546, loss is 0.024553705006837845\n",
      "epoch: 4 step: 547, loss is 0.007662464864552021\n",
      "epoch: 4 step: 548, loss is 0.1437709927558899\n",
      "epoch: 4 step: 549, loss is 0.05709376931190491\n",
      "epoch: 4 step: 550, loss is 0.004050164017826319\n",
      "epoch: 4 step: 551, loss is 0.008301143534481525\n",
      "epoch: 4 step: 552, loss is 0.011169864796102047\n",
      "epoch: 4 step: 553, loss is 0.0031658874358981848\n",
      "epoch: 4 step: 554, loss is 0.0013295314274728298\n",
      "epoch: 4 step: 555, loss is 0.0006430839421227574\n",
      "epoch: 4 step: 556, loss is 0.0017232222016900778\n",
      "epoch: 4 step: 557, loss is 0.0012066976632922888\n",
      "epoch: 4 step: 558, loss is 0.016721220687031746\n",
      "epoch: 4 step: 559, loss is 0.019034873694181442\n",
      "epoch: 4 step: 560, loss is 0.00782185047864914\n",
      "epoch: 4 step: 561, loss is 0.052178170531988144\n",
      "epoch: 4 step: 562, loss is 0.0007497264887206256\n",
      "epoch: 4 step: 563, loss is 0.0009007541229948401\n",
      "epoch: 4 step: 564, loss is 0.025824323296546936\n",
      "epoch: 4 step: 565, loss is 0.0027578193694353104\n",
      "epoch: 4 step: 566, loss is 0.25954219698905945\n",
      "epoch: 4 step: 567, loss is 0.0008663648623041809\n",
      "epoch: 4 step: 568, loss is 0.0009855135576799512\n",
      "epoch: 4 step: 569, loss is 0.0013598420191556215\n",
      "epoch: 4 step: 570, loss is 0.038226429373025894\n",
      "epoch: 4 step: 571, loss is 0.0065440833568573\n",
      "epoch: 4 step: 572, loss is 0.005954126827418804\n",
      "epoch: 4 step: 573, loss is 0.007090361788868904\n",
      "epoch: 4 step: 574, loss is 0.18767420947551727\n",
      "epoch: 4 step: 575, loss is 0.00665680505335331\n",
      "epoch: 4 step: 576, loss is 0.0015037829289212823\n",
      "epoch: 4 step: 577, loss is 0.016597388312220573\n",
      "epoch: 4 step: 578, loss is 0.00827811099588871\n",
      "epoch: 4 step: 579, loss is 0.0034193226601928473\n",
      "epoch: 4 step: 580, loss is 0.19909417629241943\n",
      "epoch: 4 step: 581, loss is 0.0383811891078949\n",
      "epoch: 4 step: 582, loss is 0.0046026986092329025\n",
      "epoch: 4 step: 583, loss is 0.021361958235502243\n",
      "epoch: 4 step: 584, loss is 0.0013150771846994758\n",
      "epoch: 4 step: 585, loss is 0.016476722434163094\n",
      "epoch: 4 step: 586, loss is 0.00043755953083746135\n",
      "epoch: 4 step: 587, loss is 0.0009643463417887688\n",
      "epoch: 4 step: 588, loss is 0.040105853229761124\n",
      "epoch: 4 step: 589, loss is 0.14873577654361725\n",
      "epoch: 4 step: 590, loss is 0.06637545675039291\n",
      "epoch: 4 step: 591, loss is 0.0002727622340898961\n",
      "epoch: 4 step: 592, loss is 0.010007393546402454\n",
      "epoch: 4 step: 593, loss is 0.012949911877512932\n",
      "epoch: 4 step: 594, loss is 0.011419233866035938\n",
      "epoch: 4 step: 595, loss is 0.08286400884389877\n",
      "epoch: 4 step: 596, loss is 0.0016889855032786727\n",
      "epoch: 4 step: 597, loss is 0.008881947956979275\n",
      "epoch: 4 step: 598, loss is 0.0015975122805684805\n",
      "epoch: 4 step: 599, loss is 0.014828811399638653\n",
      "epoch: 4 step: 600, loss is 0.00018929506768472493\n",
      "epoch: 4 step: 601, loss is 0.0038670478388667107\n",
      "epoch: 4 step: 602, loss is 0.0018907308112829924\n",
      "epoch: 4 step: 603, loss is 0.02236844412982464\n",
      "epoch: 4 step: 604, loss is 0.06433029472827911\n",
      "epoch: 4 step: 605, loss is 0.0038357581943273544\n",
      "epoch: 4 step: 606, loss is 0.0003151213168166578\n",
      "epoch: 4 step: 607, loss is 0.11235953867435455\n",
      "epoch: 4 step: 608, loss is 0.035281095653772354\n",
      "epoch: 4 step: 609, loss is 0.016992054879665375\n",
      "epoch: 4 step: 610, loss is 0.06181038171052933\n",
      "epoch: 4 step: 611, loss is 0.0028087859973311424\n",
      "epoch: 4 step: 612, loss is 0.0010846747318282723\n",
      "epoch: 4 step: 613, loss is 0.0022871389519423246\n",
      "epoch: 4 step: 614, loss is 0.000741761876270175\n",
      "epoch: 4 step: 615, loss is 0.0009971203980967402\n",
      "epoch: 4 step: 616, loss is 0.0005574983661063015\n",
      "epoch: 4 step: 617, loss is 0.0006992314592935145\n",
      "epoch: 4 step: 618, loss is 0.08318372815847397\n",
      "epoch: 4 step: 619, loss is 0.0005185790942050517\n",
      "epoch: 4 step: 620, loss is 0.0004273340164218098\n",
      "epoch: 4 step: 621, loss is 0.1279522180557251\n",
      "epoch: 4 step: 622, loss is 0.04795609787106514\n",
      "epoch: 4 step: 623, loss is 0.010717450641095638\n",
      "epoch: 4 step: 624, loss is 0.007186029572039843\n",
      "epoch: 4 step: 625, loss is 0.0045449864119291306\n",
      "epoch: 4 step: 626, loss is 0.06316637992858887\n",
      "epoch: 4 step: 627, loss is 0.009458701126277447\n",
      "epoch: 4 step: 628, loss is 0.002514804247766733\n",
      "epoch: 4 step: 629, loss is 0.02217402309179306\n",
      "epoch: 4 step: 630, loss is 0.0011043110862374306\n",
      "epoch: 4 step: 631, loss is 0.0010820823954418302\n",
      "epoch: 4 step: 632, loss is 0.0009233423043042421\n",
      "epoch: 4 step: 633, loss is 0.0033851221669465303\n",
      "epoch: 4 step: 634, loss is 0.014819133095443249\n",
      "epoch: 4 step: 635, loss is 0.005922799929976463\n",
      "epoch: 4 step: 636, loss is 0.01525246724486351\n",
      "epoch: 4 step: 637, loss is 0.0037838348653167486\n",
      "epoch: 4 step: 638, loss is 0.0049059283919632435\n",
      "epoch: 4 step: 639, loss is 0.015743711963295937\n",
      "epoch: 4 step: 640, loss is 0.07155458629131317\n",
      "epoch: 4 step: 641, loss is 0.0033964423928409815\n",
      "epoch: 4 step: 642, loss is 0.06316018849611282\n",
      "epoch: 4 step: 643, loss is 0.0012362736742943525\n",
      "epoch: 4 step: 644, loss is 0.009643896482884884\n",
      "epoch: 4 step: 645, loss is 0.00395149877294898\n",
      "epoch: 4 step: 646, loss is 0.008187484927475452\n",
      "epoch: 4 step: 647, loss is 0.05545187368988991\n",
      "epoch: 4 step: 648, loss is 0.007823683321475983\n",
      "epoch: 4 step: 649, loss is 0.0016835322603583336\n",
      "epoch: 4 step: 650, loss is 0.026076436042785645\n",
      "epoch: 4 step: 651, loss is 0.0007595255738124251\n",
      "epoch: 4 step: 652, loss is 0.0002407919819233939\n",
      "epoch: 4 step: 653, loss is 0.015340006910264492\n",
      "epoch: 4 step: 654, loss is 0.012491201981902122\n",
      "epoch: 4 step: 655, loss is 0.08176043629646301\n",
      "epoch: 4 step: 656, loss is 0.0016141966916620731\n",
      "epoch: 4 step: 657, loss is 0.015201198868453503\n",
      "epoch: 4 step: 658, loss is 0.01687990128993988\n",
      "epoch: 4 step: 659, loss is 0.021236101165413857\n",
      "epoch: 4 step: 660, loss is 0.005269508808851242\n",
      "epoch: 4 step: 661, loss is 0.04300103709101677\n",
      "epoch: 4 step: 662, loss is 0.09627524018287659\n",
      "epoch: 4 step: 663, loss is 0.043436892330646515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 664, loss is 2.095283525704872e-05\n",
      "epoch: 4 step: 665, loss is 0.0026456054765731096\n",
      "epoch: 4 step: 666, loss is 0.001352900406345725\n",
      "epoch: 4 step: 667, loss is 0.12610623240470886\n",
      "epoch: 4 step: 668, loss is 0.02744555100798607\n",
      "epoch: 4 step: 669, loss is 0.0005743827787227929\n",
      "epoch: 4 step: 670, loss is 0.0017277207225561142\n",
      "epoch: 4 step: 671, loss is 0.0024633987341076136\n",
      "epoch: 4 step: 672, loss is 0.0006183122168295085\n",
      "epoch: 4 step: 673, loss is 0.05173126980662346\n",
      "epoch: 4 step: 674, loss is 0.013020186685025692\n",
      "epoch: 4 step: 675, loss is 0.012081661261618137\n",
      "epoch: 4 step: 676, loss is 0.007731152232736349\n",
      "epoch: 4 step: 677, loss is 0.0011531689669936895\n",
      "epoch: 4 step: 678, loss is 0.003554996568709612\n",
      "epoch: 4 step: 679, loss is 0.1305093765258789\n",
      "epoch: 4 step: 680, loss is 0.05749622359871864\n",
      "epoch: 4 step: 681, loss is 0.0001479114143876359\n",
      "epoch: 4 step: 682, loss is 0.0015454539097845554\n",
      "epoch: 4 step: 683, loss is 0.1251686066389084\n",
      "epoch: 4 step: 684, loss is 0.15184123814105988\n",
      "epoch: 4 step: 685, loss is 0.00041971655446104705\n",
      "epoch: 4 step: 686, loss is 0.0005923414137214422\n",
      "epoch: 4 step: 687, loss is 0.007000688463449478\n",
      "epoch: 4 step: 688, loss is 0.10073213279247284\n",
      "epoch: 4 step: 689, loss is 0.011566169559955597\n",
      "epoch: 4 step: 690, loss is 0.0020175985991954803\n",
      "epoch: 4 step: 691, loss is 0.008996877819299698\n",
      "epoch: 4 step: 692, loss is 0.04960649833083153\n",
      "epoch: 4 step: 693, loss is 0.0009779322426766157\n",
      "epoch: 4 step: 694, loss is 0.010501531884074211\n",
      "epoch: 4 step: 695, loss is 0.004602028522640467\n",
      "epoch: 4 step: 696, loss is 0.04885086789727211\n",
      "epoch: 4 step: 697, loss is 0.30066338181495667\n",
      "epoch: 4 step: 698, loss is 0.014501751400530338\n",
      "epoch: 4 step: 699, loss is 0.002271183067932725\n",
      "epoch: 4 step: 700, loss is 0.013008845038712025\n",
      "epoch: 4 step: 701, loss is 0.00590820237994194\n",
      "epoch: 4 step: 702, loss is 0.01218319870531559\n",
      "epoch: 4 step: 703, loss is 0.00026715549756772816\n",
      "epoch: 4 step: 704, loss is 0.020098267123103142\n",
      "epoch: 4 step: 705, loss is 0.008810504339635372\n",
      "epoch: 4 step: 706, loss is 0.0007183009875006974\n",
      "epoch: 4 step: 707, loss is 0.014789098873734474\n",
      "epoch: 4 step: 708, loss is 0.00741614680737257\n",
      "epoch: 4 step: 709, loss is 0.00026481066015549004\n",
      "epoch: 4 step: 710, loss is 0.05886883661150932\n",
      "epoch: 4 step: 711, loss is 0.0050336383283138275\n",
      "epoch: 4 step: 712, loss is 0.020803488790988922\n",
      "epoch: 4 step: 713, loss is 0.0052179982885718346\n",
      "epoch: 4 step: 714, loss is 0.00013623815902974457\n",
      "epoch: 4 step: 715, loss is 0.0048166727647185326\n",
      "epoch: 4 step: 716, loss is 0.0014409013092517853\n",
      "epoch: 4 step: 717, loss is 0.03323207050561905\n",
      "epoch: 4 step: 718, loss is 0.017465252429246902\n",
      "epoch: 4 step: 719, loss is 0.00013889427646063268\n",
      "epoch: 4 step: 720, loss is 0.0017678417498245835\n",
      "epoch: 4 step: 721, loss is 0.08999120444059372\n",
      "epoch: 4 step: 722, loss is 0.0009518037550151348\n",
      "epoch: 4 step: 723, loss is 0.005961093120276928\n",
      "epoch: 4 step: 724, loss is 0.18582797050476074\n",
      "epoch: 4 step: 725, loss is 0.0029028886929154396\n",
      "epoch: 4 step: 726, loss is 0.011563761159777641\n",
      "epoch: 4 step: 727, loss is 0.06703951209783554\n",
      "epoch: 4 step: 728, loss is 0.00761270010843873\n",
      "epoch: 4 step: 729, loss is 0.0008835573098622262\n",
      "epoch: 4 step: 730, loss is 0.0018113780533894897\n",
      "epoch: 4 step: 731, loss is 0.011437793262302876\n",
      "epoch: 4 step: 732, loss is 0.026239363476634026\n",
      "epoch: 4 step: 733, loss is 0.003988487645983696\n",
      "epoch: 4 step: 734, loss is 0.024850448593497276\n",
      "epoch: 4 step: 735, loss is 0.00011166055628564209\n",
      "epoch: 4 step: 736, loss is 0.005053219851106405\n",
      "epoch: 4 step: 737, loss is 0.010140120051801205\n",
      "epoch: 4 step: 738, loss is 0.007184197660535574\n",
      "epoch: 4 step: 739, loss is 0.003649820340797305\n",
      "epoch: 4 step: 740, loss is 0.04268743097782135\n",
      "epoch: 4 step: 741, loss is 0.005483795888721943\n",
      "epoch: 4 step: 742, loss is 0.007142776157706976\n",
      "epoch: 4 step: 743, loss is 0.12307887524366379\n",
      "epoch: 4 step: 744, loss is 0.00015462434384971857\n",
      "epoch: 4 step: 745, loss is 0.0012891198275610805\n",
      "epoch: 4 step: 746, loss is 0.1893276870250702\n",
      "epoch: 4 step: 747, loss is 0.017174258828163147\n",
      "epoch: 4 step: 748, loss is 9.012090595206246e-05\n",
      "epoch: 4 step: 749, loss is 0.005828844383358955\n",
      "epoch: 4 step: 750, loss is 0.00143731280695647\n",
      "epoch: 4 step: 751, loss is 0.0013320577563717961\n",
      "epoch: 4 step: 752, loss is 0.005524144973605871\n",
      "epoch: 4 step: 753, loss is 0.023629173636436462\n",
      "epoch: 4 step: 754, loss is 0.0009012908558361232\n",
      "epoch: 4 step: 755, loss is 0.10965612530708313\n",
      "epoch: 4 step: 756, loss is 0.012492102570831776\n",
      "epoch: 4 step: 757, loss is 0.0069485013373196125\n",
      "epoch: 4 step: 758, loss is 0.0024034837260842323\n",
      "epoch: 4 step: 759, loss is 0.010158343240618706\n",
      "epoch: 4 step: 760, loss is 0.021407539024949074\n",
      "epoch: 4 step: 761, loss is 0.00039321157964877784\n",
      "epoch: 4 step: 762, loss is 0.2669536769390106\n",
      "epoch: 4 step: 763, loss is 0.05624524876475334\n",
      "epoch: 4 step: 764, loss is 0.010782063938677311\n",
      "epoch: 4 step: 765, loss is 0.0002779707428999245\n",
      "epoch: 4 step: 766, loss is 0.001184159074909985\n",
      "epoch: 4 step: 767, loss is 0.0010438116732984781\n",
      "epoch: 4 step: 768, loss is 0.002900158753618598\n",
      "epoch: 4 step: 769, loss is 0.001274854177609086\n",
      "epoch: 4 step: 770, loss is 0.0016616499051451683\n",
      "epoch: 4 step: 771, loss is 0.004915033467113972\n",
      "epoch: 4 step: 772, loss is 0.12847483158111572\n",
      "epoch: 4 step: 773, loss is 0.011703405529260635\n",
      "epoch: 4 step: 774, loss is 0.12211669236421585\n",
      "epoch: 4 step: 775, loss is 0.0027674913872033358\n",
      "epoch: 4 step: 776, loss is 0.02675160951912403\n",
      "epoch: 4 step: 777, loss is 0.0002576490514911711\n",
      "epoch: 4 step: 778, loss is 0.0008630353840999305\n",
      "epoch: 4 step: 779, loss is 0.004918553400784731\n",
      "epoch: 4 step: 780, loss is 0.0007693227380514145\n",
      "epoch: 4 step: 781, loss is 0.007963797077536583\n",
      "epoch: 4 step: 782, loss is 0.022615084424614906\n",
      "epoch: 4 step: 783, loss is 0.010324962437152863\n",
      "epoch: 4 step: 784, loss is 0.0029278970323503017\n",
      "epoch: 4 step: 785, loss is 0.000748443475458771\n",
      "epoch: 4 step: 786, loss is 0.023440593853592873\n",
      "epoch: 4 step: 787, loss is 0.0001951409358298406\n",
      "epoch: 4 step: 788, loss is 0.17714008688926697\n",
      "epoch: 4 step: 789, loss is 0.000861744221765548\n",
      "epoch: 4 step: 790, loss is 0.0019644489511847496\n",
      "epoch: 4 step: 791, loss is 0.2125963419675827\n",
      "epoch: 4 step: 792, loss is 0.0036940211430191994\n",
      "epoch: 4 step: 793, loss is 0.10375811904668808\n",
      "epoch: 4 step: 794, loss is 0.012024890631437302\n",
      "epoch: 4 step: 795, loss is 0.00521750608459115\n",
      "epoch: 4 step: 796, loss is 0.010743716731667519\n",
      "epoch: 4 step: 797, loss is 0.07401148974895477\n",
      "epoch: 4 step: 798, loss is 0.00037742964923381805\n",
      "epoch: 4 step: 799, loss is 0.1032034307718277\n",
      "epoch: 4 step: 800, loss is 0.00013725209282711148\n",
      "epoch: 4 step: 801, loss is 0.00018636758613865823\n",
      "epoch: 4 step: 802, loss is 0.018098512664437294\n",
      "epoch: 4 step: 803, loss is 0.0029683688189834356\n",
      "epoch: 4 step: 804, loss is 0.0024847108870744705\n",
      "epoch: 4 step: 805, loss is 8.186129707610235e-05\n",
      "epoch: 4 step: 806, loss is 0.0049232374876737595\n",
      "epoch: 4 step: 807, loss is 0.07798274606466293\n",
      "epoch: 4 step: 808, loss is 0.09744717180728912\n",
      "epoch: 4 step: 809, loss is 0.023312130942940712\n",
      "epoch: 4 step: 810, loss is 0.06086115911602974\n",
      "epoch: 4 step: 811, loss is 0.01651618629693985\n",
      "epoch: 4 step: 812, loss is 0.018539205193519592\n",
      "epoch: 4 step: 813, loss is 0.002009634394198656\n",
      "epoch: 4 step: 814, loss is 0.029498709365725517\n",
      "epoch: 4 step: 815, loss is 0.002281351713463664\n",
      "epoch: 4 step: 816, loss is 0.10734649002552032\n",
      "epoch: 4 step: 817, loss is 0.004844438284635544\n",
      "epoch: 4 step: 818, loss is 0.029733940958976746\n",
      "epoch: 4 step: 819, loss is 0.0021757713984698057\n",
      "epoch: 4 step: 820, loss is 0.0011618444696068764\n",
      "epoch: 4 step: 821, loss is 0.10558094084262848\n",
      "epoch: 4 step: 822, loss is 0.002863061847165227\n",
      "epoch: 4 step: 823, loss is 0.034657739102840424\n",
      "epoch: 4 step: 824, loss is 0.043128568679094315\n",
      "epoch: 4 step: 825, loss is 0.0005809544236399233\n",
      "epoch: 4 step: 826, loss is 0.05698752775788307\n",
      "epoch: 4 step: 827, loss is 0.0018421390559524298\n",
      "epoch: 4 step: 828, loss is 0.0014720095787197351\n",
      "epoch: 4 step: 829, loss is 0.0005720328190363944\n",
      "epoch: 4 step: 830, loss is 0.14889277517795563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 831, loss is 0.00022521107166539878\n",
      "epoch: 4 step: 832, loss is 0.00015248566342052072\n",
      "epoch: 4 step: 833, loss is 0.004625464323908091\n",
      "epoch: 4 step: 834, loss is 0.04739559441804886\n",
      "epoch: 4 step: 835, loss is 0.005207603331655264\n",
      "epoch: 4 step: 836, loss is 0.00407068058848381\n",
      "epoch: 4 step: 837, loss is 0.0075719100423157215\n",
      "epoch: 4 step: 838, loss is 0.004156399983912706\n",
      "epoch: 4 step: 839, loss is 0.003916809801012278\n",
      "epoch: 4 step: 840, loss is 0.03603276610374451\n",
      "epoch: 4 step: 841, loss is 0.009152648039162159\n",
      "epoch: 4 step: 842, loss is 0.10296883434057236\n",
      "epoch: 4 step: 843, loss is 0.010573988780379295\n",
      "epoch: 4 step: 844, loss is 0.0024292445741593838\n",
      "epoch: 4 step: 845, loss is 0.004707674495875835\n",
      "epoch: 4 step: 846, loss is 0.011866211891174316\n",
      "epoch: 4 step: 847, loss is 0.008020115084946156\n",
      "epoch: 4 step: 848, loss is 0.00849644560366869\n",
      "epoch: 4 step: 849, loss is 0.001441307133063674\n",
      "epoch: 4 step: 850, loss is 0.007335800677537918\n",
      "epoch: 4 step: 851, loss is 0.006410923786461353\n",
      "epoch: 4 step: 852, loss is 0.0019350637448951602\n",
      "epoch: 4 step: 853, loss is 0.0232840683311224\n",
      "epoch: 4 step: 854, loss is 0.0003166197275277227\n",
      "epoch: 4 step: 855, loss is 0.0020092290360480547\n",
      "epoch: 4 step: 856, loss is 0.0055352007038891315\n",
      "epoch: 4 step: 857, loss is 0.004703449085354805\n",
      "epoch: 4 step: 858, loss is 0.08054061233997345\n",
      "epoch: 4 step: 859, loss is 0.0006901431479491293\n",
      "epoch: 4 step: 860, loss is 0.0033613117411732674\n",
      "epoch: 4 step: 861, loss is 0.002472609980031848\n",
      "epoch: 4 step: 862, loss is 0.0002316890168003738\n",
      "epoch: 4 step: 863, loss is 0.03484455868601799\n",
      "epoch: 4 step: 864, loss is 0.001948541379533708\n",
      "epoch: 4 step: 865, loss is 0.0007394419517368078\n",
      "epoch: 4 step: 866, loss is 0.0005428447620943189\n",
      "epoch: 4 step: 867, loss is 0.013738407753407955\n",
      "epoch: 4 step: 868, loss is 0.003656151005998254\n",
      "epoch: 4 step: 869, loss is 0.0028507292736321688\n",
      "epoch: 4 step: 870, loss is 0.008300695568323135\n",
      "epoch: 4 step: 871, loss is 0.00809994712471962\n",
      "epoch: 4 step: 872, loss is 0.2939590811729431\n",
      "epoch: 4 step: 873, loss is 0.0004676728567574173\n",
      "epoch: 4 step: 874, loss is 0.002343014581128955\n",
      "epoch: 4 step: 875, loss is 0.003572969464585185\n",
      "epoch: 4 step: 876, loss is 0.0038623777218163013\n",
      "epoch: 4 step: 877, loss is 0.0003719916276168078\n",
      "epoch: 4 step: 878, loss is 0.001015817397274077\n",
      "epoch: 4 step: 879, loss is 0.0026422846131026745\n",
      "epoch: 4 step: 880, loss is 0.03131880611181259\n",
      "epoch: 4 step: 881, loss is 0.03698337823152542\n",
      "epoch: 4 step: 882, loss is 0.01744285225868225\n",
      "epoch: 4 step: 883, loss is 0.007952979765832424\n",
      "epoch: 4 step: 884, loss is 0.006755110342055559\n",
      "epoch: 4 step: 885, loss is 0.003315055277198553\n",
      "epoch: 4 step: 886, loss is 0.01379118487238884\n",
      "epoch: 4 step: 887, loss is 0.004670030903071165\n",
      "epoch: 4 step: 888, loss is 0.18857872486114502\n",
      "epoch: 4 step: 889, loss is 0.01207009982317686\n",
      "epoch: 4 step: 890, loss is 0.0004674454394262284\n",
      "epoch: 4 step: 891, loss is 0.001193571137264371\n",
      "epoch: 4 step: 892, loss is 0.019525159150362015\n",
      "epoch: 4 step: 893, loss is 0.0027710155118256807\n",
      "epoch: 4 step: 894, loss is 0.019854698330163956\n",
      "epoch: 4 step: 895, loss is 0.010567625053226948\n",
      "epoch: 4 step: 896, loss is 0.0002377614437136799\n",
      "epoch: 4 step: 897, loss is 0.009794019162654877\n",
      "epoch: 4 step: 898, loss is 0.0036875559017062187\n",
      "epoch: 4 step: 899, loss is 0.0690205991268158\n",
      "epoch: 4 step: 900, loss is 0.051628511399030685\n",
      "epoch: 4 step: 901, loss is 0.037918929010629654\n",
      "epoch: 4 step: 902, loss is 0.0024576508440077305\n",
      "epoch: 4 step: 903, loss is 0.0011637975694611669\n",
      "epoch: 4 step: 904, loss is 0.08909737318754196\n",
      "epoch: 4 step: 905, loss is 0.13919201493263245\n",
      "epoch: 4 step: 906, loss is 0.0018184598302468657\n",
      "epoch: 4 step: 907, loss is 0.013428954407572746\n",
      "epoch: 4 step: 908, loss is 0.09366621822118759\n",
      "epoch: 4 step: 909, loss is 0.008574247360229492\n",
      "epoch: 4 step: 910, loss is 0.0003292273613624275\n",
      "epoch: 4 step: 911, loss is 0.002549302764236927\n",
      "epoch: 4 step: 912, loss is 0.00019603660621214658\n",
      "epoch: 4 step: 913, loss is 0.053942665457725525\n",
      "epoch: 4 step: 914, loss is 0.005895232316106558\n",
      "epoch: 4 step: 915, loss is 0.051718469709157944\n",
      "epoch: 4 step: 916, loss is 0.0346321277320385\n",
      "epoch: 4 step: 917, loss is 0.00017270947864744812\n",
      "epoch: 4 step: 918, loss is 0.3499932289123535\n",
      "epoch: 4 step: 919, loss is 0.03533684462308884\n",
      "epoch: 4 step: 920, loss is 0.02311037667095661\n",
      "epoch: 4 step: 921, loss is 0.062126126140356064\n",
      "epoch: 4 step: 922, loss is 0.04507077485322952\n",
      "epoch: 4 step: 923, loss is 0.05366192013025284\n",
      "epoch: 4 step: 924, loss is 0.037197090685367584\n",
      "epoch: 4 step: 925, loss is 0.007984697818756104\n",
      "epoch: 4 step: 926, loss is 0.0035285349003970623\n",
      "epoch: 4 step: 927, loss is 0.08128567039966583\n",
      "epoch: 4 step: 928, loss is 0.0048835380002856255\n",
      "epoch: 4 step: 929, loss is 0.00986183900386095\n",
      "epoch: 4 step: 930, loss is 0.002640576334670186\n",
      "epoch: 4 step: 931, loss is 0.11166713386774063\n",
      "epoch: 4 step: 932, loss is 0.0028248741291463375\n",
      "epoch: 4 step: 933, loss is 0.002909081056714058\n",
      "epoch: 4 step: 934, loss is 0.14020748436450958\n",
      "epoch: 4 step: 935, loss is 0.06847137957811356\n",
      "epoch: 4 step: 936, loss is 0.018356595188379288\n",
      "epoch: 4 step: 937, loss is 0.008871518075466156\n",
      "epoch: 4 step: 938, loss is 0.04309921711683273\n",
      "epoch: 4 step: 939, loss is 0.00508382823318243\n",
      "epoch: 4 step: 940, loss is 0.07921125739812851\n",
      "epoch: 4 step: 941, loss is 0.01293307077139616\n",
      "epoch: 4 step: 942, loss is 0.022263331338763237\n",
      "epoch: 4 step: 943, loss is 0.13869129121303558\n",
      "epoch: 4 step: 944, loss is 0.02375403419137001\n",
      "epoch: 4 step: 945, loss is 0.008218139410018921\n",
      "epoch: 4 step: 946, loss is 0.0046416986733675\n",
      "epoch: 4 step: 947, loss is 0.13728660345077515\n",
      "epoch: 4 step: 948, loss is 0.005143072456121445\n",
      "epoch: 4 step: 949, loss is 0.00824540015310049\n",
      "epoch: 4 step: 950, loss is 0.006412227172404528\n",
      "epoch: 4 step: 951, loss is 0.010019740089774132\n",
      "epoch: 4 step: 952, loss is 0.0036225616931915283\n",
      "epoch: 4 step: 953, loss is 0.00010939624189632013\n",
      "epoch: 4 step: 954, loss is 0.06774076074361801\n",
      "epoch: 4 step: 955, loss is 0.0009057421120814979\n",
      "epoch: 4 step: 956, loss is 0.006044961977750063\n",
      "epoch: 4 step: 957, loss is 0.0023314000573009253\n",
      "epoch: 4 step: 958, loss is 0.1060391515493393\n",
      "epoch: 4 step: 959, loss is 0.0038901364896446466\n",
      "epoch: 4 step: 960, loss is 0.0034082976635545492\n",
      "epoch: 4 step: 961, loss is 0.02777046710252762\n",
      "epoch: 4 step: 962, loss is 0.0012855533277615905\n",
      "epoch: 4 step: 963, loss is 0.018540034070611\n",
      "epoch: 4 step: 964, loss is 0.016094468533992767\n",
      "epoch: 4 step: 965, loss is 0.17157749831676483\n",
      "epoch: 4 step: 966, loss is 0.0007637818926014006\n",
      "epoch: 4 step: 967, loss is 0.02850804291665554\n",
      "epoch: 4 step: 968, loss is 0.1788237988948822\n",
      "epoch: 4 step: 969, loss is 0.11704748123884201\n",
      "epoch: 4 step: 970, loss is 0.014517949894070625\n",
      "epoch: 4 step: 971, loss is 0.11327662318944931\n",
      "epoch: 4 step: 972, loss is 0.0494307279586792\n",
      "epoch: 4 step: 973, loss is 0.29435858130455017\n",
      "epoch: 4 step: 974, loss is 0.0005388977006077766\n",
      "epoch: 4 step: 975, loss is 0.00029887750861234963\n",
      "epoch: 4 step: 976, loss is 0.02467171661555767\n",
      "epoch: 4 step: 977, loss is 0.06336715817451477\n",
      "epoch: 4 step: 978, loss is 0.00760246766731143\n",
      "epoch: 4 step: 979, loss is 0.041491854935884476\n",
      "epoch: 4 step: 980, loss is 0.04471468925476074\n",
      "epoch: 4 step: 981, loss is 0.0009841433493420482\n",
      "epoch: 4 step: 982, loss is 0.0008789307903498411\n",
      "epoch: 4 step: 983, loss is 0.004064890090376139\n",
      "epoch: 4 step: 984, loss is 0.0006222777883522213\n",
      "epoch: 4 step: 985, loss is 0.1244688630104065\n",
      "epoch: 4 step: 986, loss is 0.00023242853058036417\n",
      "epoch: 4 step: 987, loss is 0.003219925332814455\n",
      "epoch: 4 step: 988, loss is 0.04609494283795357\n",
      "epoch: 4 step: 989, loss is 0.0038818586617708206\n",
      "epoch: 4 step: 990, loss is 0.006084055174142122\n",
      "epoch: 4 step: 991, loss is 0.002128508174791932\n",
      "epoch: 4 step: 992, loss is 0.0022401809692382812\n",
      "epoch: 4 step: 993, loss is 0.0022910533007234335\n",
      "epoch: 4 step: 994, loss is 0.0007339896401390433\n",
      "epoch: 4 step: 995, loss is 0.07637662440538406\n",
      "epoch: 4 step: 996, loss is 6.35238247923553e-05\n",
      "epoch: 4 step: 997, loss is 0.03771200776100159\n",
      "epoch: 4 step: 998, loss is 0.002380379708483815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 999, loss is 0.049364831298589706\n",
      "epoch: 4 step: 1000, loss is 0.20773744583129883\n",
      "epoch: 4 step: 1001, loss is 0.012022255919873714\n",
      "epoch: 4 step: 1002, loss is 0.0021905195899307728\n",
      "epoch: 4 step: 1003, loss is 0.11462510377168655\n",
      "epoch: 4 step: 1004, loss is 0.07981811463832855\n",
      "epoch: 4 step: 1005, loss is 0.09882157295942307\n",
      "epoch: 4 step: 1006, loss is 0.0007232293137349188\n",
      "epoch: 4 step: 1007, loss is 0.0034133456647396088\n",
      "epoch: 4 step: 1008, loss is 0.0012269893195480108\n",
      "epoch: 4 step: 1009, loss is 0.09141126275062561\n",
      "epoch: 4 step: 1010, loss is 0.0007086239638738334\n",
      "epoch: 4 step: 1011, loss is 0.053030725568532944\n",
      "epoch: 4 step: 1012, loss is 0.03659046068787575\n",
      "epoch: 4 step: 1013, loss is 0.0007585263228975236\n",
      "epoch: 4 step: 1014, loss is 0.006313443183898926\n",
      "epoch: 4 step: 1015, loss is 0.003411070443689823\n",
      "epoch: 4 step: 1016, loss is 0.007864397950470448\n",
      "epoch: 4 step: 1017, loss is 0.17128346860408783\n",
      "epoch: 4 step: 1018, loss is 0.11815360188484192\n",
      "epoch: 4 step: 1019, loss is 0.04506315663456917\n",
      "epoch: 4 step: 1020, loss is 0.02123211696743965\n",
      "epoch: 4 step: 1021, loss is 0.06815942376852036\n",
      "epoch: 4 step: 1022, loss is 0.0010294616222381592\n",
      "epoch: 4 step: 1023, loss is 0.01151067204773426\n",
      "epoch: 4 step: 1024, loss is 0.025956282392144203\n",
      "epoch: 4 step: 1025, loss is 0.01610505022108555\n",
      "epoch: 4 step: 1026, loss is 0.032085321843624115\n",
      "epoch: 4 step: 1027, loss is 0.0005315031739883125\n",
      "epoch: 4 step: 1028, loss is 0.000734463392291218\n",
      "epoch: 4 step: 1029, loss is 0.0803789421916008\n",
      "epoch: 4 step: 1030, loss is 0.003499433631077409\n",
      "epoch: 4 step: 1031, loss is 0.03657812625169754\n",
      "epoch: 4 step: 1032, loss is 0.0031832752283662558\n",
      "epoch: 4 step: 1033, loss is 0.0005872889305464923\n",
      "epoch: 4 step: 1034, loss is 0.038057591766119\n",
      "epoch: 4 step: 1035, loss is 0.0013597208308055997\n",
      "epoch: 4 step: 1036, loss is 0.004609940107911825\n",
      "epoch: 4 step: 1037, loss is 0.0026477156206965446\n",
      "epoch: 4 step: 1038, loss is 0.0015881996368989348\n",
      "epoch: 4 step: 1039, loss is 0.013446398079395294\n",
      "epoch: 4 step: 1040, loss is 0.0031060376204550266\n",
      "epoch: 4 step: 1041, loss is 0.0024494051467627287\n",
      "epoch: 4 step: 1042, loss is 0.007364517543464899\n",
      "epoch: 4 step: 1043, loss is 0.14320111274719238\n",
      "epoch: 4 step: 1044, loss is 0.0935288742184639\n",
      "epoch: 4 step: 1045, loss is 0.0003193441079929471\n",
      "epoch: 4 step: 1046, loss is 0.026109954342246056\n",
      "epoch: 4 step: 1047, loss is 0.005644512362778187\n",
      "epoch: 4 step: 1048, loss is 0.13534122705459595\n",
      "epoch: 4 step: 1049, loss is 0.08106224983930588\n",
      "epoch: 4 step: 1050, loss is 0.014630335383117199\n",
      "epoch: 4 step: 1051, loss is 0.0035121997352689505\n",
      "epoch: 4 step: 1052, loss is 0.03662686422467232\n",
      "epoch: 4 step: 1053, loss is 0.009417804889380932\n",
      "epoch: 4 step: 1054, loss is 0.04025759920477867\n",
      "epoch: 4 step: 1055, loss is 0.0014224133919924498\n",
      "epoch: 4 step: 1056, loss is 0.13063885271549225\n",
      "epoch: 4 step: 1057, loss is 0.043434128165245056\n",
      "epoch: 4 step: 1058, loss is 0.10622784495353699\n",
      "epoch: 4 step: 1059, loss is 0.003486047498881817\n",
      "epoch: 4 step: 1060, loss is 0.0005233300616964698\n",
      "epoch: 4 step: 1061, loss is 0.005095768719911575\n",
      "epoch: 4 step: 1062, loss is 0.21859529614448547\n",
      "epoch: 4 step: 1063, loss is 0.0001893217850010842\n",
      "epoch: 4 step: 1064, loss is 0.0710269883275032\n",
      "epoch: 4 step: 1065, loss is 0.17771607637405396\n",
      "epoch: 4 step: 1066, loss is 0.003363373689353466\n",
      "epoch: 4 step: 1067, loss is 0.003890044055879116\n",
      "epoch: 4 step: 1068, loss is 0.0012216074392199516\n",
      "epoch: 4 step: 1069, loss is 0.0016086641699075699\n",
      "epoch: 4 step: 1070, loss is 0.06178521364927292\n",
      "epoch: 4 step: 1071, loss is 0.057630281895399094\n",
      "epoch: 4 step: 1072, loss is 0.14747603237628937\n",
      "epoch: 4 step: 1073, loss is 0.0007228525937534869\n",
      "epoch: 4 step: 1074, loss is 0.002283148467540741\n",
      "epoch: 4 step: 1075, loss is 0.018651776015758514\n",
      "epoch: 4 step: 1076, loss is 0.004201845731586218\n",
      "epoch: 4 step: 1077, loss is 0.037224140018224716\n",
      "epoch: 4 step: 1078, loss is 0.0012472361559048295\n",
      "epoch: 4 step: 1079, loss is 0.0017179464921355247\n",
      "epoch: 4 step: 1080, loss is 0.021140405908226967\n",
      "epoch: 4 step: 1081, loss is 0.0023660422302782536\n",
      "epoch: 4 step: 1082, loss is 0.055495914071798325\n",
      "epoch: 4 step: 1083, loss is 0.002906478475779295\n",
      "epoch: 4 step: 1084, loss is 0.0001614411303307861\n",
      "epoch: 4 step: 1085, loss is 0.03504115343093872\n",
      "epoch: 4 step: 1086, loss is 0.0007304997998289764\n",
      "epoch: 4 step: 1087, loss is 0.0032856108155101538\n",
      "epoch: 4 step: 1088, loss is 0.06457770615816116\n",
      "epoch: 4 step: 1089, loss is 0.014876195229589939\n",
      "epoch: 4 step: 1090, loss is 0.002602769760414958\n",
      "epoch: 4 step: 1091, loss is 0.0008079832186922431\n",
      "epoch: 4 step: 1092, loss is 0.0035742006730288267\n",
      "epoch: 4 step: 1093, loss is 0.02131551131606102\n",
      "epoch: 4 step: 1094, loss is 0.0008542067371308804\n",
      "epoch: 4 step: 1095, loss is 0.009773478843271732\n",
      "epoch: 4 step: 1096, loss is 0.003457105252891779\n",
      "epoch: 4 step: 1097, loss is 0.00044802759657613933\n",
      "epoch: 4 step: 1098, loss is 0.0007562466198578477\n",
      "epoch: 4 step: 1099, loss is 0.004122256767004728\n",
      "epoch: 4 step: 1100, loss is 0.01943877898156643\n",
      "epoch: 4 step: 1101, loss is 0.0036657091695815325\n",
      "epoch: 4 step: 1102, loss is 0.0008437953074462712\n",
      "epoch: 4 step: 1103, loss is 0.0023952177725732327\n",
      "epoch: 4 step: 1104, loss is 0.09793323278427124\n",
      "epoch: 4 step: 1105, loss is 0.017382031306624413\n",
      "epoch: 4 step: 1106, loss is 0.04112257435917854\n",
      "epoch: 4 step: 1107, loss is 0.00018614568398334086\n",
      "epoch: 4 step: 1108, loss is 0.037953898310661316\n",
      "epoch: 4 step: 1109, loss is 0.0012685814872384071\n",
      "epoch: 4 step: 1110, loss is 0.012341988272964954\n",
      "epoch: 4 step: 1111, loss is 0.0007635977235622704\n",
      "epoch: 4 step: 1112, loss is 0.01563710719347\n",
      "epoch: 4 step: 1113, loss is 0.04093311354517937\n",
      "epoch: 4 step: 1114, loss is 0.040376123040914536\n",
      "epoch: 4 step: 1115, loss is 0.3147059977054596\n",
      "epoch: 4 step: 1116, loss is 0.0011683633783832192\n",
      "epoch: 4 step: 1117, loss is 0.00025747044128365815\n",
      "epoch: 4 step: 1118, loss is 0.029393170028924942\n",
      "epoch: 4 step: 1119, loss is 0.09031089395284653\n",
      "epoch: 4 step: 1120, loss is 0.041354916989803314\n",
      "epoch: 4 step: 1121, loss is 0.010124260559678078\n",
      "epoch: 4 step: 1122, loss is 0.0048012323677539825\n",
      "epoch: 4 step: 1123, loss is 0.04632068797945976\n",
      "epoch: 4 step: 1124, loss is 0.005365618504583836\n",
      "epoch: 4 step: 1125, loss is 0.008204437792301178\n",
      "epoch: 4 step: 1126, loss is 0.0009332475601695478\n",
      "epoch: 4 step: 1127, loss is 0.08263334631919861\n",
      "epoch: 4 step: 1128, loss is 0.27693605422973633\n",
      "epoch: 4 step: 1129, loss is 0.00014771470159757882\n",
      "epoch: 4 step: 1130, loss is 0.0012387940660119057\n",
      "epoch: 4 step: 1131, loss is 0.0052382852882146835\n",
      "epoch: 4 step: 1132, loss is 0.056514445692300797\n",
      "epoch: 4 step: 1133, loss is 0.00013614709314424545\n",
      "epoch: 4 step: 1134, loss is 0.029093917459249496\n",
      "epoch: 4 step: 1135, loss is 0.0008558670524507761\n",
      "epoch: 4 step: 1136, loss is 0.00955014768987894\n",
      "epoch: 4 step: 1137, loss is 0.06428662687540054\n",
      "epoch: 4 step: 1138, loss is 0.032980870455503464\n",
      "epoch: 4 step: 1139, loss is 0.0017684274353086948\n",
      "epoch: 4 step: 1140, loss is 0.07308898121118546\n",
      "epoch: 4 step: 1141, loss is 0.00044705657637678087\n",
      "epoch: 4 step: 1142, loss is 0.012431414797902107\n",
      "epoch: 4 step: 1143, loss is 0.193727508187294\n",
      "epoch: 4 step: 1144, loss is 0.008138738572597504\n",
      "epoch: 4 step: 1145, loss is 0.003941837698221207\n",
      "epoch: 4 step: 1146, loss is 0.001521429279819131\n",
      "epoch: 4 step: 1147, loss is 0.008069229312241077\n",
      "epoch: 4 step: 1148, loss is 0.0006977329612709582\n",
      "epoch: 4 step: 1149, loss is 0.15010860562324524\n",
      "epoch: 4 step: 1150, loss is 0.0013777537969872355\n",
      "epoch: 4 step: 1151, loss is 0.006759283132851124\n",
      "epoch: 4 step: 1152, loss is 0.0012834426015615463\n",
      "epoch: 4 step: 1153, loss is 0.006308449432253838\n",
      "epoch: 4 step: 1154, loss is 0.06512992084026337\n",
      "epoch: 4 step: 1155, loss is 0.0021539214067161083\n",
      "epoch: 4 step: 1156, loss is 0.05920146405696869\n",
      "epoch: 4 step: 1157, loss is 0.003661805298179388\n",
      "epoch: 4 step: 1158, loss is 0.002162069547921419\n",
      "epoch: 4 step: 1159, loss is 0.01574021205306053\n",
      "epoch: 4 step: 1160, loss is 0.0012430313508957624\n",
      "epoch: 4 step: 1161, loss is 0.0009207357652485371\n",
      "epoch: 4 step: 1162, loss is 0.025316547602415085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1163, loss is 0.13327668607234955\n",
      "epoch: 4 step: 1164, loss is 0.017580365762114525\n",
      "epoch: 4 step: 1165, loss is 0.0004910234129056334\n",
      "epoch: 4 step: 1166, loss is 0.0047319913282990456\n",
      "epoch: 4 step: 1167, loss is 0.0017475011991336942\n",
      "epoch: 4 step: 1168, loss is 0.002599089639261365\n",
      "epoch: 4 step: 1169, loss is 0.009779680520296097\n",
      "epoch: 4 step: 1170, loss is 0.24328143894672394\n",
      "epoch: 4 step: 1171, loss is 0.0007851325208321214\n",
      "epoch: 4 step: 1172, loss is 0.0004364686901681125\n",
      "epoch: 4 step: 1173, loss is 0.02714049071073532\n",
      "epoch: 4 step: 1174, loss is 0.001550914254039526\n",
      "epoch: 4 step: 1175, loss is 0.000793343991972506\n",
      "epoch: 4 step: 1176, loss is 0.01707279309630394\n",
      "epoch: 4 step: 1177, loss is 0.0016188689041882753\n",
      "epoch: 4 step: 1178, loss is 0.018018562346696854\n",
      "epoch: 4 step: 1179, loss is 0.02794157713651657\n",
      "epoch: 4 step: 1180, loss is 0.019281141459941864\n",
      "epoch: 4 step: 1181, loss is 0.0007306389161385596\n",
      "epoch: 4 step: 1182, loss is 0.0008392318850383162\n",
      "epoch: 4 step: 1183, loss is 0.029368005692958832\n",
      "epoch: 4 step: 1184, loss is 0.006197250913828611\n",
      "epoch: 4 step: 1185, loss is 0.018567124381661415\n",
      "epoch: 4 step: 1186, loss is 0.009319278411567211\n",
      "epoch: 4 step: 1187, loss is 0.003044262295588851\n",
      "epoch: 4 step: 1188, loss is 0.007087748032063246\n",
      "epoch: 4 step: 1189, loss is 0.001115200575441122\n",
      "epoch: 4 step: 1190, loss is 0.0013225397560745478\n",
      "epoch: 4 step: 1191, loss is 0.0026210639625787735\n",
      "epoch: 4 step: 1192, loss is 0.0007465459639206529\n",
      "epoch: 4 step: 1193, loss is 0.07012484967708588\n",
      "epoch: 4 step: 1194, loss is 0.006906910799443722\n",
      "epoch: 4 step: 1195, loss is 0.15934959053993225\n",
      "epoch: 4 step: 1196, loss is 0.004584388807415962\n",
      "epoch: 4 step: 1197, loss is 0.0020674108527600765\n",
      "epoch: 4 step: 1198, loss is 0.0009440779103897512\n",
      "epoch: 4 step: 1199, loss is 0.00209630629979074\n",
      "epoch: 4 step: 1200, loss is 0.004489985294640064\n",
      "epoch: 4 step: 1201, loss is 0.0006012633675709367\n",
      "epoch: 4 step: 1202, loss is 0.002444124547764659\n",
      "epoch: 4 step: 1203, loss is 0.0023160481359809637\n",
      "epoch: 4 step: 1204, loss is 0.0057642776519060135\n",
      "epoch: 4 step: 1205, loss is 0.01584816910326481\n",
      "epoch: 4 step: 1206, loss is 0.12046030163764954\n",
      "epoch: 4 step: 1207, loss is 0.005756748840212822\n",
      "epoch: 4 step: 1208, loss is 0.0009908528300002217\n",
      "epoch: 4 step: 1209, loss is 0.0015743483090773225\n",
      "epoch: 4 step: 1210, loss is 0.0004129036096855998\n",
      "epoch: 4 step: 1211, loss is 0.0694044753909111\n",
      "epoch: 4 step: 1212, loss is 0.058373644948005676\n",
      "epoch: 4 step: 1213, loss is 0.014856557361781597\n",
      "epoch: 4 step: 1214, loss is 0.0010356447892263532\n",
      "epoch: 4 step: 1215, loss is 0.16848614811897278\n",
      "epoch: 4 step: 1216, loss is 0.0014359792694449425\n",
      "epoch: 4 step: 1217, loss is 0.000658068573102355\n",
      "epoch: 4 step: 1218, loss is 4.146482751821168e-05\n",
      "epoch: 4 step: 1219, loss is 0.0026177566032856703\n",
      "epoch: 4 step: 1220, loss is 0.12491389364004135\n",
      "epoch: 4 step: 1221, loss is 0.11352290958166122\n",
      "epoch: 4 step: 1222, loss is 0.001707270392216742\n",
      "epoch: 4 step: 1223, loss is 0.04082585126161575\n",
      "epoch: 4 step: 1224, loss is 0.0004944795509800315\n",
      "epoch: 4 step: 1225, loss is 0.001193343778140843\n",
      "epoch: 4 step: 1226, loss is 0.002194702159613371\n",
      "epoch: 4 step: 1227, loss is 0.11920655518770218\n",
      "epoch: 4 step: 1228, loss is 0.0012449361383914948\n",
      "epoch: 4 step: 1229, loss is 0.020197387784719467\n",
      "epoch: 4 step: 1230, loss is 0.010940957814455032\n",
      "epoch: 4 step: 1231, loss is 0.0046540722250938416\n",
      "epoch: 4 step: 1232, loss is 0.0018515196861699224\n",
      "epoch: 4 step: 1233, loss is 0.0009386723977513611\n",
      "epoch: 4 step: 1234, loss is 0.020490318536758423\n",
      "epoch: 4 step: 1235, loss is 0.01347578875720501\n",
      "epoch: 4 step: 1236, loss is 0.003778713522478938\n",
      "epoch: 4 step: 1237, loss is 0.00030962435994297266\n",
      "epoch: 4 step: 1238, loss is 0.00022529484704136848\n",
      "epoch: 4 step: 1239, loss is 0.004411238711327314\n",
      "epoch: 4 step: 1240, loss is 0.0006980903563089669\n",
      "epoch: 4 step: 1241, loss is 0.03008859045803547\n",
      "epoch: 4 step: 1242, loss is 0.0008313339785672724\n",
      "epoch: 4 step: 1243, loss is 0.0005852060276083648\n",
      "epoch: 4 step: 1244, loss is 0.0023928829468786716\n",
      "epoch: 4 step: 1245, loss is 0.0004895685124211013\n",
      "epoch: 4 step: 1246, loss is 0.002184094162657857\n",
      "epoch: 4 step: 1247, loss is 0.003773908130824566\n",
      "epoch: 4 step: 1248, loss is 0.062389373779296875\n",
      "epoch: 4 step: 1249, loss is 0.0007036588503979146\n",
      "epoch: 4 step: 1250, loss is 7.694793021073565e-05\n",
      "epoch: 4 step: 1251, loss is 0.030179796740412712\n",
      "epoch: 4 step: 1252, loss is 0.010806596837937832\n",
      "epoch: 4 step: 1253, loss is 0.08490956574678421\n",
      "epoch: 4 step: 1254, loss is 0.022761398926377296\n",
      "epoch: 4 step: 1255, loss is 0.000850542273838073\n",
      "epoch: 4 step: 1256, loss is 0.008460832759737968\n",
      "epoch: 4 step: 1257, loss is 0.04845355451107025\n",
      "epoch: 4 step: 1258, loss is 0.0009094031411223114\n",
      "epoch: 4 step: 1259, loss is 0.0010913254227489233\n",
      "epoch: 4 step: 1260, loss is 0.012440075166523457\n",
      "epoch: 4 step: 1261, loss is 0.0013963168021291494\n",
      "epoch: 4 step: 1262, loss is 0.007965871132910252\n",
      "epoch: 4 step: 1263, loss is 0.07713010162115097\n",
      "epoch: 4 step: 1264, loss is 0.026145555078983307\n",
      "epoch: 4 step: 1265, loss is 0.005880782380700111\n",
      "epoch: 4 step: 1266, loss is 0.0006662948289886117\n",
      "epoch: 4 step: 1267, loss is 0.0017264342168346047\n",
      "epoch: 4 step: 1268, loss is 0.008490007370710373\n",
      "epoch: 4 step: 1269, loss is 0.007153769489377737\n",
      "epoch: 4 step: 1270, loss is 0.012201217003166676\n",
      "epoch: 4 step: 1271, loss is 0.009894834831357002\n",
      "epoch: 4 step: 1272, loss is 0.0589449480175972\n",
      "epoch: 4 step: 1273, loss is 0.005260704550892115\n",
      "epoch: 4 step: 1274, loss is 0.0009646923863328993\n",
      "epoch: 4 step: 1275, loss is 0.0009538537706248462\n",
      "epoch: 4 step: 1276, loss is 0.0026016016490757465\n",
      "epoch: 4 step: 1277, loss is 0.005037873983383179\n",
      "epoch: 4 step: 1278, loss is 0.0007812048424966633\n",
      "epoch: 4 step: 1279, loss is 0.0006591551355086267\n",
      "epoch: 4 step: 1280, loss is 0.024874843657016754\n",
      "epoch: 4 step: 1281, loss is 0.0237362552434206\n",
      "epoch: 4 step: 1282, loss is 0.012647265568375587\n",
      "epoch: 4 step: 1283, loss is 0.0009867422049865127\n",
      "epoch: 4 step: 1284, loss is 0.07627962529659271\n",
      "epoch: 4 step: 1285, loss is 0.0009927202481776476\n",
      "epoch: 4 step: 1286, loss is 0.004172757733613253\n",
      "epoch: 4 step: 1287, loss is 0.001527131418697536\n",
      "epoch: 4 step: 1288, loss is 0.0009511427488178015\n",
      "epoch: 4 step: 1289, loss is 0.0007258516852743924\n",
      "epoch: 4 step: 1290, loss is 0.0007780019077472389\n",
      "epoch: 4 step: 1291, loss is 0.014605105854570866\n",
      "epoch: 4 step: 1292, loss is 0.008949961513280869\n",
      "epoch: 4 step: 1293, loss is 0.005941534414887428\n",
      "epoch: 4 step: 1294, loss is 0.016290578991174698\n",
      "epoch: 4 step: 1295, loss is 0.0007532950839959085\n",
      "epoch: 4 step: 1296, loss is 0.06462918221950531\n",
      "epoch: 4 step: 1297, loss is 0.0008566421456634998\n",
      "epoch: 4 step: 1298, loss is 0.036503616720438004\n",
      "epoch: 4 step: 1299, loss is 0.0005988908815197647\n",
      "epoch: 4 step: 1300, loss is 0.048085931688547134\n",
      "epoch: 4 step: 1301, loss is 0.03674275800585747\n",
      "epoch: 4 step: 1302, loss is 5.0423219363437966e-05\n",
      "epoch: 4 step: 1303, loss is 0.0017575303791090846\n",
      "epoch: 4 step: 1304, loss is 0.00017386206309311092\n",
      "epoch: 4 step: 1305, loss is 0.006326295435428619\n",
      "epoch: 4 step: 1306, loss is 0.0031473797280341387\n",
      "epoch: 4 step: 1307, loss is 0.017003579065203667\n",
      "epoch: 4 step: 1308, loss is 0.009074358269572258\n",
      "epoch: 4 step: 1309, loss is 0.23719219863414764\n",
      "epoch: 4 step: 1310, loss is 0.009944385848939419\n",
      "epoch: 4 step: 1311, loss is 0.00013390523963607848\n",
      "epoch: 4 step: 1312, loss is 0.0024672667495906353\n",
      "epoch: 4 step: 1313, loss is 0.0032089240849018097\n",
      "epoch: 4 step: 1314, loss is 0.00035616508102975786\n",
      "epoch: 4 step: 1315, loss is 0.007341104559600353\n",
      "epoch: 4 step: 1316, loss is 0.0021072227973490953\n",
      "epoch: 4 step: 1317, loss is 0.009161443449556828\n",
      "epoch: 4 step: 1318, loss is 0.0020459918305277824\n",
      "epoch: 4 step: 1319, loss is 0.05730897933244705\n",
      "epoch: 4 step: 1320, loss is 0.0033559820149093866\n",
      "epoch: 4 step: 1321, loss is 0.0025112575385719538\n",
      "epoch: 4 step: 1322, loss is 0.004957898519933224\n",
      "epoch: 4 step: 1323, loss is 0.007072661072015762\n",
      "epoch: 4 step: 1324, loss is 0.011167758144438267\n",
      "epoch: 4 step: 1325, loss is 0.00013216622755862772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1326, loss is 0.00540496688336134\n",
      "epoch: 4 step: 1327, loss is 0.022037958726286888\n",
      "epoch: 4 step: 1328, loss is 2.7542782845557667e-05\n",
      "epoch: 4 step: 1329, loss is 0.04851479083299637\n",
      "epoch: 4 step: 1330, loss is 0.0004553919134195894\n",
      "epoch: 4 step: 1331, loss is 3.379713598405942e-05\n",
      "epoch: 4 step: 1332, loss is 6.583658250747249e-05\n",
      "epoch: 4 step: 1333, loss is 0.0006837433320470154\n",
      "epoch: 4 step: 1334, loss is 0.0007027848623692989\n",
      "epoch: 4 step: 1335, loss is 9.864909225143492e-05\n",
      "epoch: 4 step: 1336, loss is 0.09147511422634125\n",
      "epoch: 4 step: 1337, loss is 0.1657121479511261\n",
      "epoch: 4 step: 1338, loss is 0.158108189702034\n",
      "epoch: 4 step: 1339, loss is 0.009282732382416725\n",
      "epoch: 4 step: 1340, loss is 0.0005698908935301006\n",
      "epoch: 4 step: 1341, loss is 0.007993726059794426\n",
      "epoch: 4 step: 1342, loss is 0.23039890825748444\n",
      "epoch: 4 step: 1343, loss is 0.001807568478398025\n",
      "epoch: 4 step: 1344, loss is 0.001102923764847219\n",
      "epoch: 4 step: 1345, loss is 0.005490363575518131\n",
      "epoch: 4 step: 1346, loss is 0.007001417223364115\n",
      "epoch: 4 step: 1347, loss is 0.0019967174157500267\n",
      "epoch: 4 step: 1348, loss is 0.21516165137290955\n",
      "epoch: 4 step: 1349, loss is 0.0012327382573857903\n",
      "epoch: 4 step: 1350, loss is 0.0005369811551645398\n",
      "epoch: 4 step: 1351, loss is 0.0428355373442173\n",
      "epoch: 4 step: 1352, loss is 0.029717762023210526\n",
      "epoch: 4 step: 1353, loss is 0.001379135763272643\n",
      "epoch: 4 step: 1354, loss is 0.11048515141010284\n",
      "epoch: 4 step: 1355, loss is 0.18806882202625275\n",
      "epoch: 4 step: 1356, loss is 0.09437184780836105\n",
      "epoch: 4 step: 1357, loss is 0.0004094045434612781\n",
      "epoch: 4 step: 1358, loss is 0.0030990089289844036\n",
      "epoch: 4 step: 1359, loss is 0.0007334472029469907\n",
      "epoch: 4 step: 1360, loss is 0.004444412421435118\n",
      "epoch: 4 step: 1361, loss is 0.0009032629895955324\n",
      "epoch: 4 step: 1362, loss is 0.0037890381645411253\n",
      "epoch: 4 step: 1363, loss is 0.044334735721349716\n",
      "epoch: 4 step: 1364, loss is 0.0060239797458052635\n",
      "epoch: 4 step: 1365, loss is 0.02057379111647606\n",
      "epoch: 4 step: 1366, loss is 0.01766086183488369\n",
      "epoch: 4 step: 1367, loss is 0.10809886455535889\n",
      "epoch: 4 step: 1368, loss is 0.0008969391346909106\n",
      "epoch: 4 step: 1369, loss is 0.0006935519049875438\n",
      "epoch: 4 step: 1370, loss is 0.07004407048225403\n",
      "epoch: 4 step: 1371, loss is 0.029395325109362602\n",
      "epoch: 4 step: 1372, loss is 0.06739573180675507\n",
      "epoch: 4 step: 1373, loss is 0.01627347804605961\n",
      "epoch: 4 step: 1374, loss is 0.0005787882837466896\n",
      "epoch: 4 step: 1375, loss is 0.10925493389368057\n",
      "epoch: 4 step: 1376, loss is 0.14773353934288025\n",
      "epoch: 4 step: 1377, loss is 0.004005065653473139\n",
      "epoch: 4 step: 1378, loss is 0.04500173032283783\n",
      "epoch: 4 step: 1379, loss is 0.02623657137155533\n",
      "epoch: 4 step: 1380, loss is 0.005656033288687468\n",
      "epoch: 4 step: 1381, loss is 0.0017681431490927935\n",
      "epoch: 4 step: 1382, loss is 0.052188847213983536\n",
      "epoch: 4 step: 1383, loss is 0.05413892865180969\n",
      "epoch: 4 step: 1384, loss is 0.0013174808118492365\n",
      "epoch: 4 step: 1385, loss is 0.001693528494797647\n",
      "epoch: 4 step: 1386, loss is 0.011494571343064308\n",
      "epoch: 4 step: 1387, loss is 0.011406096629798412\n",
      "epoch: 4 step: 1388, loss is 0.014214239083230495\n",
      "epoch: 4 step: 1389, loss is 0.0006140176556073129\n",
      "epoch: 4 step: 1390, loss is 0.00017767175449989736\n",
      "epoch: 4 step: 1391, loss is 0.0015054731629788876\n",
      "epoch: 4 step: 1392, loss is 0.0024287800770252943\n",
      "epoch: 4 step: 1393, loss is 0.0007827137596905231\n",
      "epoch: 4 step: 1394, loss is 0.08931168168783188\n",
      "epoch: 4 step: 1395, loss is 0.1175229549407959\n",
      "epoch: 4 step: 1396, loss is 0.0065108793787658215\n",
      "epoch: 4 step: 1397, loss is 0.0074461097829043865\n",
      "epoch: 4 step: 1398, loss is 4.8663750931154937e-05\n",
      "epoch: 4 step: 1399, loss is 0.009361623786389828\n",
      "epoch: 4 step: 1400, loss is 0.09115961194038391\n",
      "epoch: 4 step: 1401, loss is 0.020326750352978706\n",
      "epoch: 4 step: 1402, loss is 0.02187173441052437\n",
      "epoch: 4 step: 1403, loss is 0.0011735878651961684\n",
      "epoch: 4 step: 1404, loss is 0.007243433967232704\n",
      "epoch: 4 step: 1405, loss is 0.07406476885080338\n",
      "epoch: 4 step: 1406, loss is 0.015207950957119465\n",
      "epoch: 4 step: 1407, loss is 0.027115099132061005\n",
      "epoch: 4 step: 1408, loss is 0.020100541412830353\n",
      "epoch: 4 step: 1409, loss is 0.07511354237794876\n",
      "epoch: 4 step: 1410, loss is 0.007589495275169611\n",
      "epoch: 4 step: 1411, loss is 0.0005454440251924098\n",
      "epoch: 4 step: 1412, loss is 0.0008791718864813447\n",
      "epoch: 4 step: 1413, loss is 0.009642724879086018\n",
      "epoch: 4 step: 1414, loss is 0.03582746535539627\n",
      "epoch: 4 step: 1415, loss is 0.0006312711630016565\n",
      "epoch: 4 step: 1416, loss is 0.004573986865580082\n",
      "epoch: 4 step: 1417, loss is 0.016953058540821075\n",
      "epoch: 4 step: 1418, loss is 0.0031120306812226772\n",
      "epoch: 4 step: 1419, loss is 0.03769107535481453\n",
      "epoch: 4 step: 1420, loss is 0.0007018496398814023\n",
      "epoch: 4 step: 1421, loss is 0.0017086210427805781\n",
      "epoch: 4 step: 1422, loss is 0.002571525052189827\n",
      "epoch: 4 step: 1423, loss is 0.001314632361754775\n",
      "epoch: 4 step: 1424, loss is 0.0002480919356457889\n",
      "epoch: 4 step: 1425, loss is 0.0003251848975196481\n",
      "epoch: 4 step: 1426, loss is 0.08000548928976059\n",
      "epoch: 4 step: 1427, loss is 0.014242990873754025\n",
      "epoch: 4 step: 1428, loss is 0.046188388019800186\n",
      "epoch: 4 step: 1429, loss is 0.016156278550624847\n",
      "epoch: 4 step: 1430, loss is 0.0007657365640625358\n",
      "epoch: 4 step: 1431, loss is 0.0008457654621452093\n",
      "epoch: 4 step: 1432, loss is 0.0012776822550222278\n",
      "epoch: 4 step: 1433, loss is 0.02006739191710949\n",
      "epoch: 4 step: 1434, loss is 0.003263093065470457\n",
      "epoch: 4 step: 1435, loss is 0.02528972737491131\n",
      "epoch: 4 step: 1436, loss is 0.2866989076137543\n",
      "epoch: 4 step: 1437, loss is 0.041528116911649704\n",
      "epoch: 4 step: 1438, loss is 0.04711240902543068\n",
      "epoch: 4 step: 1439, loss is 0.0014059243258088827\n",
      "epoch: 4 step: 1440, loss is 0.011327816173434258\n",
      "epoch: 4 step: 1441, loss is 0.17389421164989471\n",
      "epoch: 4 step: 1442, loss is 0.054240576922893524\n",
      "epoch: 4 step: 1443, loss is 0.0007624312420375645\n",
      "epoch: 4 step: 1444, loss is 0.0007905706879682839\n",
      "epoch: 4 step: 1445, loss is 0.014868360944092274\n",
      "epoch: 4 step: 1446, loss is 0.0036882120184600353\n",
      "epoch: 4 step: 1447, loss is 0.03874366357922554\n",
      "epoch: 4 step: 1448, loss is 0.2060449868440628\n",
      "epoch: 4 step: 1449, loss is 0.0017823155503720045\n",
      "epoch: 4 step: 1450, loss is 0.056463439017534256\n",
      "epoch: 4 step: 1451, loss is 0.008661921136081219\n",
      "epoch: 4 step: 1452, loss is 0.02552640810608864\n",
      "epoch: 4 step: 1453, loss is 0.017555316910147667\n",
      "epoch: 4 step: 1454, loss is 0.00026818260084837675\n",
      "epoch: 4 step: 1455, loss is 0.026965253055095673\n",
      "epoch: 4 step: 1456, loss is 0.007001922931522131\n",
      "epoch: 4 step: 1457, loss is 0.025193555280566216\n",
      "epoch: 4 step: 1458, loss is 0.014589108526706696\n",
      "epoch: 4 step: 1459, loss is 0.02099839597940445\n",
      "epoch: 4 step: 1460, loss is 0.10416615754365921\n",
      "epoch: 4 step: 1461, loss is 0.00046462813043035567\n",
      "epoch: 4 step: 1462, loss is 0.018222011625766754\n",
      "epoch: 4 step: 1463, loss is 0.007248085457831621\n",
      "epoch: 4 step: 1464, loss is 0.0006936839781701565\n",
      "epoch: 4 step: 1465, loss is 0.03215199336409569\n",
      "epoch: 4 step: 1466, loss is 0.16952519118785858\n",
      "epoch: 4 step: 1467, loss is 0.0020836107432842255\n",
      "epoch: 4 step: 1468, loss is 0.05536332726478577\n",
      "epoch: 4 step: 1469, loss is 0.12512442469596863\n",
      "epoch: 4 step: 1470, loss is 0.007341165095567703\n",
      "epoch: 4 step: 1471, loss is 0.0010067119728773832\n",
      "epoch: 4 step: 1472, loss is 0.002097626682370901\n",
      "epoch: 4 step: 1473, loss is 0.020597781985998154\n",
      "epoch: 4 step: 1474, loss is 0.009631745517253876\n",
      "epoch: 4 step: 1475, loss is 0.006728527136147022\n",
      "epoch: 4 step: 1476, loss is 0.024404510855674744\n",
      "epoch: 4 step: 1477, loss is 0.051946885883808136\n",
      "epoch: 4 step: 1478, loss is 0.0007581310346722603\n",
      "epoch: 4 step: 1479, loss is 0.00966417882591486\n",
      "epoch: 4 step: 1480, loss is 0.003905117278918624\n",
      "epoch: 4 step: 1481, loss is 0.18639294803142548\n",
      "epoch: 4 step: 1482, loss is 0.02791280299425125\n",
      "epoch: 4 step: 1483, loss is 0.0038345595821738243\n",
      "epoch: 4 step: 1484, loss is 0.001105444971472025\n",
      "epoch: 4 step: 1485, loss is 0.0029976842924952507\n",
      "epoch: 4 step: 1486, loss is 0.006309225223958492\n",
      "epoch: 4 step: 1487, loss is 0.06257473677396774\n",
      "epoch: 4 step: 1488, loss is 0.0007061850628815591\n",
      "epoch: 4 step: 1489, loss is 0.09140376001596451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1490, loss is 0.006798615213483572\n",
      "epoch: 4 step: 1491, loss is 0.012471815571188927\n",
      "epoch: 4 step: 1492, loss is 0.11644445359706879\n",
      "epoch: 4 step: 1493, loss is 0.02295074053108692\n",
      "epoch: 4 step: 1494, loss is 0.0008126187021844089\n",
      "epoch: 4 step: 1495, loss is 0.016049649566411972\n",
      "epoch: 4 step: 1496, loss is 0.001547710387967527\n",
      "epoch: 4 step: 1497, loss is 0.024499155580997467\n",
      "epoch: 4 step: 1498, loss is 0.0861414447426796\n",
      "epoch: 4 step: 1499, loss is 0.024868054315447807\n",
      "epoch: 4 step: 1500, loss is 0.0005923531716689467\n",
      "epoch: 4 step: 1501, loss is 0.0005091030616313219\n",
      "epoch: 4 step: 1502, loss is 0.0010760019067674875\n",
      "epoch: 4 step: 1503, loss is 0.16737380623817444\n",
      "epoch: 4 step: 1504, loss is 0.0017033580224961042\n",
      "epoch: 4 step: 1505, loss is 0.054617855697870255\n",
      "epoch: 4 step: 1506, loss is 0.0022722824942320585\n",
      "epoch: 4 step: 1507, loss is 0.0030315082985907793\n",
      "epoch: 4 step: 1508, loss is 0.10833270102739334\n",
      "epoch: 4 step: 1509, loss is 0.0017677375581115484\n",
      "epoch: 4 step: 1510, loss is 0.003088835161179304\n",
      "epoch: 4 step: 1511, loss is 0.0020310557447373867\n",
      "epoch: 4 step: 1512, loss is 0.05501219630241394\n",
      "epoch: 4 step: 1513, loss is 0.0164694394916296\n",
      "epoch: 4 step: 1514, loss is 0.0073488615453243256\n",
      "epoch: 4 step: 1515, loss is 0.0061129010282456875\n",
      "epoch: 4 step: 1516, loss is 0.011709870770573616\n",
      "epoch: 4 step: 1517, loss is 0.0005990288336761296\n",
      "epoch: 4 step: 1518, loss is 0.021489568054676056\n",
      "epoch: 4 step: 1519, loss is 0.08623529970645905\n",
      "epoch: 4 step: 1520, loss is 0.11573626101016998\n",
      "epoch: 4 step: 1521, loss is 0.02014084905385971\n",
      "epoch: 4 step: 1522, loss is 0.0045990063808858395\n",
      "epoch: 4 step: 1523, loss is 0.021781491115689278\n",
      "epoch: 4 step: 1524, loss is 0.0724586695432663\n",
      "epoch: 4 step: 1525, loss is 0.009508072398602962\n",
      "epoch: 4 step: 1526, loss is 0.007518061436712742\n",
      "epoch: 4 step: 1527, loss is 0.00264817476272583\n",
      "epoch: 4 step: 1528, loss is 0.00013595918426290154\n",
      "epoch: 4 step: 1529, loss is 0.23114728927612305\n",
      "epoch: 4 step: 1530, loss is 0.03486456722021103\n",
      "epoch: 4 step: 1531, loss is 0.0020692634861916304\n",
      "epoch: 4 step: 1532, loss is 0.004152590408921242\n",
      "epoch: 4 step: 1533, loss is 0.04938045144081116\n",
      "epoch: 4 step: 1534, loss is 0.0012153441784903407\n",
      "epoch: 4 step: 1535, loss is 0.013404404744505882\n",
      "epoch: 4 step: 1536, loss is 0.004736006259918213\n",
      "epoch: 4 step: 1537, loss is 0.033782538026571274\n",
      "epoch: 4 step: 1538, loss is 0.0006142011261545122\n",
      "epoch: 4 step: 1539, loss is 0.024563999846577644\n",
      "epoch: 4 step: 1540, loss is 0.03439133241772652\n",
      "epoch: 4 step: 1541, loss is 0.0020681344904005527\n",
      "epoch: 4 step: 1542, loss is 0.0011237713042646646\n",
      "epoch: 4 step: 1543, loss is 0.01969210058450699\n",
      "epoch: 4 step: 1544, loss is 0.0068905651569366455\n",
      "epoch: 4 step: 1545, loss is 0.007836959324777126\n",
      "epoch: 4 step: 1546, loss is 0.1759272813796997\n",
      "epoch: 4 step: 1547, loss is 0.00011415448534535244\n",
      "epoch: 4 step: 1548, loss is 0.013580880127847195\n",
      "epoch: 4 step: 1549, loss is 0.0186089426279068\n",
      "epoch: 4 step: 1550, loss is 0.05381618067622185\n",
      "epoch: 4 step: 1551, loss is 0.11253487318754196\n",
      "epoch: 4 step: 1552, loss is 0.04967606067657471\n",
      "epoch: 4 step: 1553, loss is 0.00020297980518080294\n",
      "epoch: 4 step: 1554, loss is 0.009554000571370125\n",
      "epoch: 4 step: 1555, loss is 0.0007867210078984499\n",
      "epoch: 4 step: 1556, loss is 0.09623406082391739\n",
      "epoch: 4 step: 1557, loss is 0.01795533113181591\n",
      "epoch: 4 step: 1558, loss is 0.18638025224208832\n",
      "epoch: 4 step: 1559, loss is 0.02699810080230236\n",
      "epoch: 4 step: 1560, loss is 0.0013762910384684801\n",
      "epoch: 4 step: 1561, loss is 0.1925404816865921\n",
      "epoch: 4 step: 1562, loss is 0.0001796772558009252\n",
      "epoch: 4 step: 1563, loss is 0.000685398408677429\n",
      "epoch: 4 step: 1564, loss is 0.09764830768108368\n",
      "epoch: 4 step: 1565, loss is 0.020413702353835106\n",
      "epoch: 4 step: 1566, loss is 0.00845528393983841\n",
      "epoch: 4 step: 1567, loss is 0.05894717574119568\n",
      "epoch: 4 step: 1568, loss is 0.0044393702410161495\n",
      "epoch: 4 step: 1569, loss is 0.0003765514411497861\n",
      "epoch: 4 step: 1570, loss is 0.05404316633939743\n",
      "epoch: 4 step: 1571, loss is 0.049324747174978256\n",
      "epoch: 4 step: 1572, loss is 0.02026250958442688\n",
      "epoch: 4 step: 1573, loss is 0.054406289011240005\n",
      "epoch: 4 step: 1574, loss is 0.0007126324926503003\n",
      "epoch: 4 step: 1575, loss is 0.04048948734998703\n",
      "epoch: 4 step: 1576, loss is 0.023063763976097107\n",
      "epoch: 4 step: 1577, loss is 0.000708283856511116\n",
      "epoch: 4 step: 1578, loss is 0.0015590718248859048\n",
      "epoch: 4 step: 1579, loss is 0.0022209808230400085\n",
      "epoch: 4 step: 1580, loss is 0.08693201839923859\n",
      "epoch: 4 step: 1581, loss is 0.09330901503562927\n",
      "epoch: 4 step: 1582, loss is 0.02318963035941124\n",
      "epoch: 4 step: 1583, loss is 0.004529127851128578\n",
      "epoch: 4 step: 1584, loss is 0.002447176491841674\n",
      "epoch: 4 step: 1585, loss is 0.024547040462493896\n",
      "epoch: 4 step: 1586, loss is 0.009783286601305008\n",
      "epoch: 4 step: 1587, loss is 0.09285223484039307\n",
      "epoch: 4 step: 1588, loss is 0.11372590810060501\n",
      "epoch: 4 step: 1589, loss is 0.00891190953552723\n",
      "epoch: 4 step: 1590, loss is 0.0026198644191026688\n",
      "epoch: 4 step: 1591, loss is 0.06589484214782715\n",
      "epoch: 4 step: 1592, loss is 0.0035223893355578184\n",
      "epoch: 4 step: 1593, loss is 0.01917102560400963\n",
      "epoch: 4 step: 1594, loss is 0.0011973120272159576\n",
      "epoch: 4 step: 1595, loss is 0.0017561421263962984\n",
      "epoch: 4 step: 1596, loss is 0.2515397369861603\n",
      "epoch: 4 step: 1597, loss is 0.009452697820961475\n",
      "epoch: 4 step: 1598, loss is 0.06202581897377968\n",
      "epoch: 4 step: 1599, loss is 0.009011783637106419\n",
      "epoch: 4 step: 1600, loss is 0.0008661674219183624\n",
      "epoch: 4 step: 1601, loss is 0.0034059020690619946\n",
      "epoch: 4 step: 1602, loss is 0.25465127825737\n",
      "epoch: 4 step: 1603, loss is 0.009151628240942955\n",
      "epoch: 4 step: 1604, loss is 0.003998539876192808\n",
      "epoch: 4 step: 1605, loss is 0.0015980302123352885\n",
      "epoch: 4 step: 1606, loss is 0.0008262788760475814\n",
      "epoch: 4 step: 1607, loss is 0.0033501763828098774\n",
      "epoch: 4 step: 1608, loss is 0.07808445394039154\n",
      "epoch: 4 step: 1609, loss is 0.014924896880984306\n",
      "epoch: 4 step: 1610, loss is 0.007539762184023857\n",
      "epoch: 4 step: 1611, loss is 0.0025560164358466864\n",
      "epoch: 4 step: 1612, loss is 0.0879800096154213\n",
      "epoch: 4 step: 1613, loss is 0.06335660815238953\n",
      "epoch: 4 step: 1614, loss is 0.05478644743561745\n",
      "epoch: 4 step: 1615, loss is 0.0064940983429551125\n",
      "epoch: 4 step: 1616, loss is 0.002050803042948246\n",
      "epoch: 4 step: 1617, loss is 0.0028129960410296917\n",
      "epoch: 4 step: 1618, loss is 0.0006185013335198164\n",
      "epoch: 4 step: 1619, loss is 0.012417209334671497\n",
      "epoch: 4 step: 1620, loss is 0.24783413112163544\n",
      "epoch: 4 step: 1621, loss is 0.0008833676110953093\n",
      "epoch: 4 step: 1622, loss is 0.06482294946908951\n",
      "epoch: 4 step: 1623, loss is 0.007957227528095245\n",
      "epoch: 4 step: 1624, loss is 0.0036469693295657635\n",
      "epoch: 4 step: 1625, loss is 0.004009241703897715\n",
      "epoch: 4 step: 1626, loss is 0.0002946348977275193\n",
      "epoch: 4 step: 1627, loss is 0.049451325088739395\n",
      "epoch: 4 step: 1628, loss is 0.07384506613016129\n",
      "epoch: 4 step: 1629, loss is 0.0003229006251785904\n",
      "epoch: 4 step: 1630, loss is 0.025172168388962746\n",
      "epoch: 4 step: 1631, loss is 0.32286345958709717\n",
      "epoch: 4 step: 1632, loss is 0.00018360215472057462\n",
      "epoch: 4 step: 1633, loss is 0.03917651250958443\n",
      "epoch: 4 step: 1634, loss is 0.0789022371172905\n",
      "epoch: 4 step: 1635, loss is 0.03183433413505554\n",
      "epoch: 4 step: 1636, loss is 0.013225367292761803\n",
      "epoch: 4 step: 1637, loss is 0.05886489897966385\n",
      "epoch: 4 step: 1638, loss is 0.000398123636841774\n",
      "epoch: 4 step: 1639, loss is 0.11767987161874771\n",
      "epoch: 4 step: 1640, loss is 0.001070265076123178\n",
      "epoch: 4 step: 1641, loss is 0.07365211844444275\n",
      "epoch: 4 step: 1642, loss is 0.03954007104039192\n",
      "epoch: 4 step: 1643, loss is 0.07281544804573059\n",
      "epoch: 4 step: 1644, loss is 0.022155409678816795\n",
      "epoch: 4 step: 1645, loss is 0.006442962680011988\n",
      "epoch: 4 step: 1646, loss is 0.003594613866880536\n",
      "epoch: 4 step: 1647, loss is 0.0005825417465530336\n",
      "epoch: 4 step: 1648, loss is 0.028922878205776215\n",
      "epoch: 4 step: 1649, loss is 0.00027952835080213845\n",
      "epoch: 4 step: 1650, loss is 0.16572526097297668\n",
      "epoch: 4 step: 1651, loss is 0.11490130424499512\n",
      "epoch: 4 step: 1652, loss is 0.12206196039915085\n",
      "epoch: 4 step: 1653, loss is 0.029539626091718674\n",
      "epoch: 4 step: 1654, loss is 0.08042023330926895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1655, loss is 0.019297746941447258\n",
      "epoch: 4 step: 1656, loss is 0.0014408560236915946\n",
      "epoch: 4 step: 1657, loss is 0.0013934141024947166\n",
      "epoch: 4 step: 1658, loss is 0.09074416011571884\n",
      "epoch: 4 step: 1659, loss is 0.25131648778915405\n",
      "epoch: 4 step: 1660, loss is 0.08350413292646408\n",
      "epoch: 4 step: 1661, loss is 0.0006256008055061102\n",
      "epoch: 4 step: 1662, loss is 0.013790881261229515\n",
      "epoch: 4 step: 1663, loss is 0.014183282852172852\n",
      "epoch: 4 step: 1664, loss is 0.004509226884692907\n",
      "epoch: 4 step: 1665, loss is 0.011407813057303429\n",
      "epoch: 4 step: 1666, loss is 0.002147125545889139\n",
      "epoch: 4 step: 1667, loss is 0.0027932715602219105\n",
      "epoch: 4 step: 1668, loss is 0.06200003996491432\n",
      "epoch: 4 step: 1669, loss is 0.007775409612804651\n",
      "epoch: 4 step: 1670, loss is 0.007403937168419361\n",
      "epoch: 4 step: 1671, loss is 0.010766152292490005\n",
      "epoch: 4 step: 1672, loss is 0.000759364920668304\n",
      "epoch: 4 step: 1673, loss is 0.00740487314760685\n",
      "epoch: 4 step: 1674, loss is 0.001327462843619287\n",
      "epoch: 4 step: 1675, loss is 0.009506996721029282\n",
      "epoch: 4 step: 1676, loss is 0.0011574290692806244\n",
      "epoch: 4 step: 1677, loss is 0.014742791652679443\n",
      "epoch: 4 step: 1678, loss is 0.028175735846161842\n",
      "epoch: 4 step: 1679, loss is 0.09106362611055374\n",
      "epoch: 4 step: 1680, loss is 0.006841215305030346\n",
      "epoch: 4 step: 1681, loss is 0.0011492744088172913\n",
      "epoch: 4 step: 1682, loss is 0.0035764009226113558\n",
      "epoch: 4 step: 1683, loss is 0.007115841377526522\n",
      "epoch: 4 step: 1684, loss is 0.006097139324992895\n",
      "epoch: 4 step: 1685, loss is 0.023342549800872803\n",
      "epoch: 4 step: 1686, loss is 0.00036026083398610353\n",
      "epoch: 4 step: 1687, loss is 0.00042140690493397415\n",
      "epoch: 4 step: 1688, loss is 0.014962871558964252\n",
      "epoch: 4 step: 1689, loss is 0.06256560981273651\n",
      "epoch: 4 step: 1690, loss is 0.07893569767475128\n",
      "epoch: 4 step: 1691, loss is 0.05149354040622711\n",
      "epoch: 4 step: 1692, loss is 0.0064716036431491375\n",
      "epoch: 4 step: 1693, loss is 0.016392383724451065\n",
      "epoch: 4 step: 1694, loss is 0.0034673085901886225\n",
      "epoch: 4 step: 1695, loss is 0.003221016377210617\n",
      "epoch: 4 step: 1696, loss is 0.06291316449642181\n",
      "epoch: 4 step: 1697, loss is 0.01389837171882391\n",
      "epoch: 4 step: 1698, loss is 0.003954870626330376\n",
      "epoch: 4 step: 1699, loss is 0.004583375528454781\n",
      "epoch: 4 step: 1700, loss is 0.0001957678032340482\n",
      "epoch: 4 step: 1701, loss is 0.0017189534846693277\n",
      "epoch: 4 step: 1702, loss is 0.020011302083730698\n",
      "epoch: 4 step: 1703, loss is 0.019231228157877922\n",
      "epoch: 4 step: 1704, loss is 0.0025391741655766964\n",
      "epoch: 4 step: 1705, loss is 0.010446096770465374\n",
      "epoch: 4 step: 1706, loss is 0.012813636101782322\n",
      "epoch: 4 step: 1707, loss is 0.053513262420892715\n",
      "epoch: 4 step: 1708, loss is 0.1016831174492836\n",
      "epoch: 4 step: 1709, loss is 0.001347354962490499\n",
      "epoch: 4 step: 1710, loss is 0.010531862266361713\n",
      "epoch: 4 step: 1711, loss is 0.002566668437793851\n",
      "epoch: 4 step: 1712, loss is 0.06027138978242874\n",
      "epoch: 4 step: 1713, loss is 8.623865141998976e-05\n",
      "epoch: 4 step: 1714, loss is 0.02952432818710804\n",
      "epoch: 4 step: 1715, loss is 0.014013798907399178\n",
      "epoch: 4 step: 1716, loss is 0.0023594843223690987\n",
      "epoch: 4 step: 1717, loss is 0.0006496363785117865\n",
      "epoch: 4 step: 1718, loss is 0.008095462806522846\n",
      "epoch: 4 step: 1719, loss is 0.015158871188759804\n",
      "epoch: 4 step: 1720, loss is 0.0032258867286145687\n",
      "epoch: 4 step: 1721, loss is 0.0009774784557521343\n",
      "epoch: 4 step: 1722, loss is 0.11212088912725449\n",
      "epoch: 4 step: 1723, loss is 0.0023110604379326105\n",
      "epoch: 4 step: 1724, loss is 0.008985948748886585\n",
      "epoch: 4 step: 1725, loss is 0.010644347406923771\n",
      "epoch: 4 step: 1726, loss is 0.0004551956371869892\n",
      "epoch: 4 step: 1727, loss is 0.019238902255892754\n",
      "epoch: 4 step: 1728, loss is 0.0028317715041339397\n",
      "epoch: 4 step: 1729, loss is 0.03231876343488693\n",
      "epoch: 4 step: 1730, loss is 0.0009068590006791055\n",
      "epoch: 4 step: 1731, loss is 0.0011706473305821419\n",
      "epoch: 4 step: 1732, loss is 0.017925351858139038\n",
      "epoch: 4 step: 1733, loss is 0.03649948537349701\n",
      "epoch: 4 step: 1734, loss is 0.00904223695397377\n",
      "epoch: 4 step: 1735, loss is 0.22560134530067444\n",
      "epoch: 4 step: 1736, loss is 0.021867787465453148\n",
      "epoch: 4 step: 1737, loss is 0.0004577796207740903\n",
      "epoch: 4 step: 1738, loss is 0.0016196025535464287\n",
      "epoch: 4 step: 1739, loss is 0.0020581367425620556\n",
      "epoch: 4 step: 1740, loss is 0.003900469047948718\n",
      "epoch: 4 step: 1741, loss is 0.0002613775432109833\n",
      "epoch: 4 step: 1742, loss is 0.055741239339113235\n",
      "epoch: 4 step: 1743, loss is 0.0025058910250663757\n",
      "epoch: 4 step: 1744, loss is 0.02082335203886032\n",
      "epoch: 4 step: 1745, loss is 0.028260692954063416\n",
      "epoch: 4 step: 1746, loss is 0.0010656388476490974\n",
      "epoch: 4 step: 1747, loss is 0.0007144162082113326\n",
      "epoch: 4 step: 1748, loss is 0.015837883576750755\n",
      "epoch: 4 step: 1749, loss is 0.06863991916179657\n",
      "epoch: 4 step: 1750, loss is 0.0003634269523900002\n",
      "epoch: 4 step: 1751, loss is 0.037232570350170135\n",
      "epoch: 4 step: 1752, loss is 0.002943057334050536\n",
      "epoch: 4 step: 1753, loss is 0.000662769190967083\n",
      "epoch: 4 step: 1754, loss is 0.0011768226977437735\n",
      "epoch: 4 step: 1755, loss is 0.006429687142372131\n",
      "epoch: 4 step: 1756, loss is 0.0005310190026648343\n",
      "epoch: 4 step: 1757, loss is 0.0009782807901501656\n",
      "epoch: 4 step: 1758, loss is 0.11518401652574539\n",
      "epoch: 4 step: 1759, loss is 0.001676969463005662\n",
      "epoch: 4 step: 1760, loss is 0.006041411310434341\n",
      "epoch: 4 step: 1761, loss is 0.009436430409550667\n",
      "epoch: 4 step: 1762, loss is 0.000608462723903358\n",
      "epoch: 4 step: 1763, loss is 0.007274907547980547\n",
      "epoch: 4 step: 1764, loss is 0.0021490948274731636\n",
      "epoch: 4 step: 1765, loss is 0.05846676230430603\n",
      "epoch: 4 step: 1766, loss is 0.0027622017078101635\n",
      "epoch: 4 step: 1767, loss is 0.06007702648639679\n",
      "epoch: 4 step: 1768, loss is 0.025807466357946396\n",
      "epoch: 4 step: 1769, loss is 0.0013174331979826093\n",
      "epoch: 4 step: 1770, loss is 0.007841861806809902\n",
      "epoch: 4 step: 1771, loss is 0.007554046809673309\n",
      "epoch: 4 step: 1772, loss is 0.0005252478295005858\n",
      "epoch: 4 step: 1773, loss is 0.0015007001347839832\n",
      "epoch: 4 step: 1774, loss is 0.05614424869418144\n",
      "epoch: 4 step: 1775, loss is 0.13644719123840332\n",
      "epoch: 4 step: 1776, loss is 0.03226488456130028\n",
      "epoch: 4 step: 1777, loss is 0.007358226925134659\n",
      "epoch: 4 step: 1778, loss is 0.003435329766944051\n",
      "epoch: 4 step: 1779, loss is 0.0017276378348469734\n",
      "epoch: 4 step: 1780, loss is 0.007377518340945244\n",
      "epoch: 4 step: 1781, loss is 0.004363547544926405\n",
      "epoch: 4 step: 1782, loss is 0.0012193017173558474\n",
      "epoch: 4 step: 1783, loss is 0.06695518642663956\n",
      "epoch: 4 step: 1784, loss is 0.033213961869478226\n",
      "epoch: 4 step: 1785, loss is 0.04102712869644165\n",
      "epoch: 4 step: 1786, loss is 0.04714394360780716\n",
      "epoch: 4 step: 1787, loss is 0.004918461199849844\n",
      "epoch: 4 step: 1788, loss is 0.002720852615311742\n",
      "epoch: 4 step: 1789, loss is 0.0034241536632180214\n",
      "epoch: 4 step: 1790, loss is 0.15296991169452667\n",
      "epoch: 4 step: 1791, loss is 0.002215229207649827\n",
      "epoch: 4 step: 1792, loss is 0.011844562366604805\n",
      "epoch: 4 step: 1793, loss is 0.0018564923666417599\n",
      "epoch: 4 step: 1794, loss is 0.0011578751727938652\n",
      "epoch: 4 step: 1795, loss is 0.04098144546151161\n",
      "epoch: 4 step: 1796, loss is 0.0006609958945773542\n",
      "epoch: 4 step: 1797, loss is 0.04898073524236679\n",
      "epoch: 4 step: 1798, loss is 0.00047534049372188747\n",
      "epoch: 4 step: 1799, loss is 0.08039359748363495\n",
      "epoch: 4 step: 1800, loss is 0.003117671702057123\n",
      "epoch: 4 step: 1801, loss is 0.08321303874254227\n",
      "epoch: 4 step: 1802, loss is 0.0011667910730466247\n",
      "epoch: 4 step: 1803, loss is 0.0127046387642622\n",
      "epoch: 4 step: 1804, loss is 0.025499265640974045\n",
      "epoch: 4 step: 1805, loss is 0.004128996282815933\n",
      "epoch: 4 step: 1806, loss is 0.2226448804140091\n",
      "epoch: 4 step: 1807, loss is 0.0034563664812594652\n",
      "epoch: 4 step: 1808, loss is 0.016967017203569412\n",
      "epoch: 4 step: 1809, loss is 0.002689227694645524\n",
      "epoch: 4 step: 1810, loss is 0.09907598793506622\n",
      "epoch: 4 step: 1811, loss is 0.03490061312913895\n",
      "epoch: 4 step: 1812, loss is 0.01039051078259945\n",
      "epoch: 4 step: 1813, loss is 0.0014823728706687689\n",
      "epoch: 4 step: 1814, loss is 0.00037298037204891443\n",
      "epoch: 4 step: 1815, loss is 0.012104827910661697\n",
      "epoch: 4 step: 1816, loss is 0.0003910541126970202\n",
      "epoch: 4 step: 1817, loss is 0.06593883037567139\n",
      "epoch: 4 step: 1818, loss is 0.05488009378314018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1819, loss is 0.12356477975845337\n",
      "epoch: 4 step: 1820, loss is 0.10434111207723618\n",
      "epoch: 4 step: 1821, loss is 0.10084160417318344\n",
      "epoch: 4 step: 1822, loss is 0.002841543173417449\n",
      "epoch: 4 step: 1823, loss is 0.14593809843063354\n",
      "epoch: 4 step: 1824, loss is 0.004180845804512501\n",
      "epoch: 4 step: 1825, loss is 0.031103234738111496\n",
      "epoch: 4 step: 1826, loss is 0.0009606870007701218\n",
      "epoch: 4 step: 1827, loss is 0.0029593007639050484\n",
      "epoch: 4 step: 1828, loss is 0.0032212042715400457\n",
      "epoch: 4 step: 1829, loss is 0.03628700226545334\n",
      "epoch: 4 step: 1830, loss is 0.00014589058991987258\n",
      "epoch: 4 step: 1831, loss is 0.22495731711387634\n",
      "epoch: 4 step: 1832, loss is 0.04002511501312256\n",
      "epoch: 4 step: 1833, loss is 0.012980004772543907\n",
      "epoch: 4 step: 1834, loss is 0.009220205247402191\n",
      "epoch: 4 step: 1835, loss is 0.04160649701952934\n",
      "epoch: 4 step: 1836, loss is 0.1235380694270134\n",
      "epoch: 4 step: 1837, loss is 0.10132212936878204\n",
      "epoch: 4 step: 1838, loss is 0.001278000301681459\n",
      "epoch: 4 step: 1839, loss is 0.002571528311818838\n",
      "epoch: 4 step: 1840, loss is 0.0018822926795110106\n",
      "epoch: 4 step: 1841, loss is 0.0030776183120906353\n",
      "epoch: 4 step: 1842, loss is 0.021421432495117188\n",
      "epoch: 4 step: 1843, loss is 0.04068312793970108\n",
      "epoch: 4 step: 1844, loss is 0.12134241312742233\n",
      "epoch: 4 step: 1845, loss is 0.027174722403287888\n",
      "epoch: 4 step: 1846, loss is 0.007494398392736912\n",
      "epoch: 4 step: 1847, loss is 0.06148744374513626\n",
      "epoch: 4 step: 1848, loss is 0.026695718988776207\n",
      "epoch: 4 step: 1849, loss is 0.002669748617336154\n",
      "epoch: 4 step: 1850, loss is 0.0025758862029761076\n",
      "epoch: 4 step: 1851, loss is 0.02421974018216133\n",
      "epoch: 4 step: 1852, loss is 0.3004671633243561\n",
      "epoch: 4 step: 1853, loss is 0.005101494025439024\n",
      "epoch: 4 step: 1854, loss is 0.041634220629930496\n",
      "epoch: 4 step: 1855, loss is 0.04163992777466774\n",
      "epoch: 4 step: 1856, loss is 0.17984777688980103\n",
      "epoch: 4 step: 1857, loss is 0.02031455934047699\n",
      "epoch: 4 step: 1858, loss is 0.009310762397944927\n",
      "epoch: 4 step: 1859, loss is 0.009419488720595837\n",
      "epoch: 4 step: 1860, loss is 0.006062857806682587\n",
      "epoch: 4 step: 1861, loss is 0.07287030667066574\n",
      "epoch: 4 step: 1862, loss is 0.01650490239262581\n",
      "epoch: 4 step: 1863, loss is 0.0026096368674188852\n",
      "epoch: 4 step: 1864, loss is 0.0035757303703576326\n",
      "epoch: 4 step: 1865, loss is 0.03653782978653908\n",
      "epoch: 4 step: 1866, loss is 0.008760933764278889\n",
      "epoch: 4 step: 1867, loss is 0.023179668933153152\n",
      "epoch: 4 step: 1868, loss is 0.012217920273542404\n",
      "epoch: 4 step: 1869, loss is 0.11388874053955078\n",
      "epoch: 4 step: 1870, loss is 0.011914110742509365\n",
      "epoch: 4 step: 1871, loss is 0.010098489001393318\n",
      "epoch: 4 step: 1872, loss is 0.06503866612911224\n",
      "epoch: 4 step: 1873, loss is 0.2504158914089203\n",
      "epoch: 4 step: 1874, loss is 0.0029306458309292793\n",
      "epoch: 4 step: 1875, loss is 0.018239546567201614\n",
      "epoch: 4 step: 1876, loss is 0.1789703518152237\n",
      "epoch: 4 step: 1877, loss is 0.003544483333826065\n",
      "epoch: 4 step: 1878, loss is 0.0015163847710937262\n",
      "epoch: 4 step: 1879, loss is 0.03880207613110542\n",
      "epoch: 4 step: 1880, loss is 0.019051430746912956\n",
      "epoch: 4 step: 1881, loss is 0.008067899383604527\n",
      "epoch: 4 step: 1882, loss is 0.0016866009682416916\n",
      "epoch: 4 step: 1883, loss is 0.03184327483177185\n",
      "epoch: 4 step: 1884, loss is 0.00044289621291682124\n",
      "epoch: 4 step: 1885, loss is 0.01341178547590971\n",
      "epoch: 4 step: 1886, loss is 0.004521660506725311\n",
      "epoch: 4 step: 1887, loss is 0.002450494095683098\n",
      "epoch: 4 step: 1888, loss is 0.012266553938388824\n",
      "epoch: 4 step: 1889, loss is 0.1457478404045105\n",
      "epoch: 4 step: 1890, loss is 0.007885411381721497\n",
      "epoch: 4 step: 1891, loss is 0.033853355795145035\n",
      "epoch: 4 step: 1892, loss is 0.006369114853441715\n",
      "epoch: 4 step: 1893, loss is 0.056094296276569366\n",
      "epoch: 4 step: 1894, loss is 0.016872907057404518\n",
      "epoch: 4 step: 1895, loss is 0.1899193823337555\n",
      "epoch: 4 step: 1896, loss is 0.09998409450054169\n",
      "epoch: 4 step: 1897, loss is 0.05361301824450493\n",
      "epoch: 4 step: 1898, loss is 0.02223162166774273\n",
      "epoch: 4 step: 1899, loss is 0.008624187670648098\n",
      "epoch: 4 step: 1900, loss is 0.09761492162942886\n",
      "epoch: 4 step: 1901, loss is 0.00027489211061038077\n",
      "epoch: 4 step: 1902, loss is 0.0035768430680036545\n",
      "epoch: 4 step: 1903, loss is 0.03365448862314224\n",
      "epoch: 4 step: 1904, loss is 0.0016012563137337565\n",
      "epoch: 4 step: 1905, loss is 0.0023028228897601366\n",
      "epoch: 4 step: 1906, loss is 0.0009679103386588395\n",
      "epoch: 4 step: 1907, loss is 0.0031547616235911846\n",
      "epoch: 4 step: 1908, loss is 0.0037140129134058952\n",
      "epoch: 4 step: 1909, loss is 0.005682266317307949\n",
      "epoch: 4 step: 1910, loss is 0.0007024842198006809\n",
      "epoch: 4 step: 1911, loss is 0.002735601272433996\n",
      "epoch: 4 step: 1912, loss is 0.010227295570075512\n",
      "epoch: 4 step: 1913, loss is 0.0003160341002512723\n",
      "epoch: 4 step: 1914, loss is 0.01053642388433218\n",
      "epoch: 4 step: 1915, loss is 0.18916276097297668\n",
      "epoch: 4 step: 1916, loss is 0.0014968932373449206\n",
      "epoch: 4 step: 1917, loss is 0.05667610466480255\n",
      "epoch: 4 step: 1918, loss is 0.0017110547050833702\n",
      "epoch: 4 step: 1919, loss is 0.011093630455434322\n",
      "epoch: 4 step: 1920, loss is 0.001786480424925685\n",
      "epoch: 4 step: 1921, loss is 0.028906168416142464\n",
      "epoch: 4 step: 1922, loss is 0.1427476555109024\n",
      "epoch: 4 step: 1923, loss is 0.011660818941891193\n",
      "epoch: 4 step: 1924, loss is 0.04500589892268181\n",
      "epoch: 4 step: 1925, loss is 0.007739503867924213\n",
      "epoch: 4 step: 1926, loss is 0.0874355211853981\n",
      "epoch: 4 step: 1927, loss is 0.06185237690806389\n",
      "epoch: 4 step: 1928, loss is 0.008105271495878696\n",
      "epoch: 4 step: 1929, loss is 0.0029793046414852142\n",
      "epoch: 4 step: 1930, loss is 0.0018569700187072158\n",
      "epoch: 4 step: 1931, loss is 0.07179760187864304\n",
      "epoch: 4 step: 1932, loss is 0.07837624102830887\n",
      "epoch: 4 step: 1933, loss is 0.0028077769093215466\n",
      "epoch: 4 step: 1934, loss is 0.06571800261735916\n",
      "epoch: 4 step: 1935, loss is 0.08188001066446304\n",
      "epoch: 4 step: 1936, loss is 0.00700828293338418\n",
      "epoch: 4 step: 1937, loss is 0.08608018606901169\n",
      "epoch: 4 step: 1938, loss is 0.005778283812105656\n",
      "epoch: 4 step: 1939, loss is 0.02436007931828499\n",
      "epoch: 4 step: 1940, loss is 0.013553173281252384\n",
      "epoch: 4 step: 1941, loss is 0.04316997528076172\n",
      "epoch: 4 step: 1942, loss is 0.013977022841572762\n",
      "epoch: 4 step: 1943, loss is 0.013264495879411697\n",
      "epoch: 4 step: 1944, loss is 0.04574726149439812\n",
      "epoch: 4 step: 1945, loss is 0.0034442779142409563\n",
      "epoch: 4 step: 1946, loss is 0.08541464060544968\n",
      "epoch: 4 step: 1947, loss is 0.017441358417272568\n",
      "epoch: 4 step: 1948, loss is 0.0007415219442918897\n",
      "epoch: 4 step: 1949, loss is 0.029905712231993675\n",
      "epoch: 4 step: 1950, loss is 0.17650820314884186\n",
      "epoch: 4 step: 1951, loss is 0.0021611163392663\n",
      "epoch: 4 step: 1952, loss is 0.0014946478186175227\n",
      "epoch: 4 step: 1953, loss is 0.003311309264972806\n",
      "epoch: 4 step: 1954, loss is 0.0066022686660289764\n",
      "epoch: 4 step: 1955, loss is 0.003537768265232444\n",
      "epoch: 4 step: 1956, loss is 0.04954252764582634\n",
      "epoch: 4 step: 1957, loss is 0.003070272272452712\n",
      "epoch: 4 step: 1958, loss is 0.048901788890361786\n",
      "epoch: 4 step: 1959, loss is 0.07439149171113968\n",
      "epoch: 4 step: 1960, loss is 0.00020306957594584674\n",
      "epoch: 4 step: 1961, loss is 0.01090636383742094\n",
      "epoch: 4 step: 1962, loss is 0.0035678085405379534\n",
      "epoch: 4 step: 1963, loss is 0.007267145439982414\n",
      "epoch: 4 step: 1964, loss is 0.004832804203033447\n",
      "epoch: 4 step: 1965, loss is 0.06029476970434189\n",
      "epoch: 4 step: 1966, loss is 0.0036789062432944775\n",
      "epoch: 4 step: 1967, loss is 0.09499986469745636\n",
      "epoch: 4 step: 1968, loss is 0.06579352170228958\n",
      "epoch: 4 step: 1969, loss is 0.005631252191960812\n",
      "epoch: 4 step: 1970, loss is 0.03005521558225155\n",
      "epoch: 4 step: 1971, loss is 0.0012079982552677393\n",
      "epoch: 4 step: 1972, loss is 0.00042072185897268355\n",
      "epoch: 4 step: 1973, loss is 0.015257222577929497\n",
      "epoch: 4 step: 1974, loss is 0.0033183761406689882\n",
      "epoch: 4 step: 1975, loss is 0.0007135854102671146\n",
      "epoch: 4 step: 1976, loss is 0.0006607028772123158\n",
      "epoch: 4 step: 1977, loss is 0.05105825886130333\n",
      "epoch: 4 step: 1978, loss is 0.15528297424316406\n",
      "epoch: 4 step: 1979, loss is 0.02011922560632229\n",
      "epoch: 4 step: 1980, loss is 0.06932646781206131\n",
      "epoch: 4 step: 1981, loss is 0.023190978914499283\n",
      "epoch: 4 step: 1982, loss is 0.01123893354088068\n",
      "epoch: 4 step: 1983, loss is 0.006352190859615803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1984, loss is 0.19668056070804596\n",
      "epoch: 4 step: 1985, loss is 0.05215747281908989\n",
      "epoch: 4 step: 1986, loss is 0.0026577292010188103\n",
      "epoch: 4 step: 1987, loss is 0.0007513713790103793\n",
      "epoch: 4 step: 1988, loss is 0.002864011563360691\n",
      "epoch: 4 step: 1989, loss is 0.01664794608950615\n",
      "epoch: 4 step: 1990, loss is 0.023897258564829826\n",
      "epoch: 4 step: 1991, loss is 0.014296836219727993\n",
      "epoch: 4 step: 1992, loss is 0.04248451068997383\n",
      "epoch: 4 step: 1993, loss is 0.04371458292007446\n",
      "epoch: 4 step: 1994, loss is 0.10999109596014023\n",
      "epoch: 4 step: 1995, loss is 0.012285199947655201\n",
      "epoch: 4 step: 1996, loss is 0.05087092146277428\n",
      "epoch: 4 step: 1997, loss is 0.48876217007637024\n",
      "epoch: 4 step: 1998, loss is 0.007626631762832403\n",
      "epoch: 4 step: 1999, loss is 0.016535144299268723\n",
      "epoch: 4 step: 2000, loss is 0.0007099639042280614\n",
      "epoch: 4 step: 2001, loss is 0.0023288591764867306\n",
      "epoch: 4 step: 2002, loss is 0.004729801323264837\n",
      "epoch: 4 step: 2003, loss is 0.12374058365821838\n",
      "epoch: 4 step: 2004, loss is 0.0015862461877986789\n",
      "epoch: 4 step: 2005, loss is 0.08851879835128784\n",
      "epoch: 4 step: 2006, loss is 0.0005161185399629176\n",
      "epoch: 4 step: 2007, loss is 0.047344405204057693\n",
      "epoch: 4 step: 2008, loss is 0.0009677043999545276\n",
      "epoch: 4 step: 2009, loss is 0.1319606602191925\n",
      "epoch: 4 step: 2010, loss is 0.00152306049130857\n",
      "epoch: 4 step: 2011, loss is 0.16590413451194763\n",
      "epoch: 4 step: 2012, loss is 0.000970344350207597\n",
      "epoch: 4 step: 2013, loss is 0.002943493193015456\n",
      "epoch: 4 step: 2014, loss is 0.04175422713160515\n",
      "epoch: 4 step: 2015, loss is 0.00834419671446085\n",
      "epoch: 4 step: 2016, loss is 0.03995347395539284\n",
      "epoch: 4 step: 2017, loss is 0.012581290677189827\n",
      "epoch: 4 step: 2018, loss is 0.01342647522687912\n",
      "epoch: 4 step: 2019, loss is 0.059632014483213425\n",
      "epoch: 4 step: 2020, loss is 0.04082639142870903\n",
      "epoch: 4 step: 2021, loss is 0.0016992491437122226\n",
      "epoch: 4 step: 2022, loss is 0.008696075528860092\n",
      "epoch: 4 step: 2023, loss is 0.1561889350414276\n",
      "epoch: 4 step: 2024, loss is 0.2892006039619446\n",
      "epoch: 4 step: 2025, loss is 0.09590426087379456\n",
      "epoch: 4 step: 2026, loss is 0.10336485505104065\n",
      "epoch: 4 step: 2027, loss is 0.18859867751598358\n",
      "epoch: 4 step: 2028, loss is 0.034421298652887344\n",
      "epoch: 4 step: 2029, loss is 0.014491334557533264\n",
      "epoch: 4 step: 2030, loss is 0.04376733675599098\n",
      "epoch: 4 step: 2031, loss is 0.02306479401886463\n",
      "epoch: 4 step: 2032, loss is 0.014962553977966309\n",
      "epoch: 4 step: 2033, loss is 0.10972734540700912\n",
      "epoch: 4 step: 2034, loss is 0.007711801212280989\n",
      "epoch: 4 step: 2035, loss is 0.008168079890310764\n",
      "epoch: 4 step: 2036, loss is 0.06836948543787003\n",
      "epoch: 4 step: 2037, loss is 0.0853932574391365\n",
      "epoch: 4 step: 2038, loss is 0.0013448211830109358\n",
      "epoch: 4 step: 2039, loss is 0.07838472723960876\n",
      "epoch: 4 step: 2040, loss is 0.03152196854352951\n",
      "epoch: 4 step: 2041, loss is 0.054129764437675476\n",
      "epoch: 4 step: 2042, loss is 0.07859653979539871\n",
      "epoch: 4 step: 2043, loss is 0.0282941572368145\n",
      "epoch: 4 step: 2044, loss is 0.0166902057826519\n",
      "epoch: 4 step: 2045, loss is 0.020276833325624466\n",
      "epoch: 4 step: 2046, loss is 0.00347703043371439\n",
      "epoch: 4 step: 2047, loss is 0.002239249413833022\n",
      "epoch: 4 step: 2048, loss is 0.0018949698423966765\n",
      "epoch: 4 step: 2049, loss is 0.12250810861587524\n",
      "epoch: 4 step: 2050, loss is 0.0030892230570316315\n",
      "epoch: 4 step: 2051, loss is 0.02228371426463127\n",
      "epoch: 4 step: 2052, loss is 0.10751297324895859\n",
      "epoch: 4 step: 2053, loss is 0.11056812107563019\n",
      "epoch: 4 step: 2054, loss is 0.012189666740596294\n",
      "epoch: 4 step: 2055, loss is 0.2126898169517517\n",
      "epoch: 4 step: 2056, loss is 0.0405578576028347\n",
      "epoch: 4 step: 2057, loss is 0.0005842134123668075\n",
      "epoch: 4 step: 2058, loss is 0.003045083489269018\n",
      "epoch: 4 step: 2059, loss is 0.003532974747940898\n",
      "epoch: 4 step: 2060, loss is 0.00033102065208368003\n",
      "epoch: 4 step: 2061, loss is 0.003816477954387665\n",
      "epoch: 4 step: 2062, loss is 0.0014808464329689741\n",
      "epoch: 4 step: 2063, loss is 0.002617214573547244\n",
      "epoch: 4 step: 2064, loss is 0.010839438065886497\n",
      "epoch: 4 step: 2065, loss is 0.08216173946857452\n",
      "epoch: 4 step: 2066, loss is 0.02675013057887554\n",
      "epoch: 4 step: 2067, loss is 0.33284398913383484\n",
      "epoch: 4 step: 2068, loss is 0.00025548681151121855\n",
      "epoch: 4 step: 2069, loss is 0.009019896388053894\n",
      "epoch: 4 step: 2070, loss is 0.016703875735402107\n",
      "epoch: 4 step: 2071, loss is 0.10796287655830383\n",
      "epoch: 4 step: 2072, loss is 0.003440084168687463\n",
      "epoch: 4 step: 2073, loss is 0.003192330477759242\n",
      "epoch: 4 step: 2074, loss is 0.00933049526065588\n",
      "epoch: 4 step: 2075, loss is 0.001806753920391202\n",
      "epoch: 4 step: 2076, loss is 0.09442418813705444\n",
      "epoch: 4 step: 2077, loss is 0.0007290726061910391\n",
      "epoch: 4 step: 2078, loss is 0.01809178851544857\n",
      "epoch: 4 step: 2079, loss is 0.0034832353703677654\n",
      "epoch: 4 step: 2080, loss is 0.1678786724805832\n",
      "epoch: 4 step: 2081, loss is 0.05427902936935425\n",
      "epoch: 4 step: 2082, loss is 0.048013631254434586\n",
      "epoch: 4 step: 2083, loss is 0.13051338493824005\n",
      "epoch: 4 step: 2084, loss is 0.002897026715800166\n",
      "epoch: 4 step: 2085, loss is 0.002291639568284154\n",
      "epoch: 4 step: 2086, loss is 0.00728245684877038\n",
      "epoch: 4 step: 2087, loss is 0.28618568181991577\n",
      "epoch: 4 step: 2088, loss is 0.040957819670438766\n",
      "epoch: 4 step: 2089, loss is 0.09962979704141617\n",
      "epoch: 4 step: 2090, loss is 0.010069398209452629\n",
      "epoch: 4 step: 2091, loss is 0.0030568463262170553\n",
      "epoch: 4 step: 2092, loss is 0.03557398542761803\n",
      "epoch: 4 step: 2093, loss is 0.16640633344650269\n",
      "epoch: 4 step: 2094, loss is 0.001980028348043561\n",
      "epoch: 4 step: 2095, loss is 0.10692740231752396\n",
      "epoch: 4 step: 2096, loss is 0.0010109044378623366\n",
      "epoch: 4 step: 2097, loss is 0.12989498674869537\n",
      "epoch: 4 step: 2098, loss is 0.0059842681512236595\n",
      "epoch: 4 step: 2099, loss is 0.0009139057947322726\n",
      "epoch: 4 step: 2100, loss is 0.0020845301914960146\n",
      "epoch: 4 step: 2101, loss is 0.04620447754859924\n",
      "epoch: 4 step: 2102, loss is 0.17586293816566467\n",
      "epoch: 4 step: 2103, loss is 0.009767955169081688\n",
      "epoch: 4 step: 2104, loss is 0.15104849636554718\n",
      "epoch: 4 step: 2105, loss is 0.009302797727286816\n",
      "epoch: 4 step: 2106, loss is 0.026258988305926323\n",
      "epoch: 4 step: 2107, loss is 0.10589500516653061\n",
      "epoch: 4 step: 2108, loss is 0.004236815497279167\n",
      "epoch: 4 step: 2109, loss is 0.002675181021913886\n",
      "epoch: 4 step: 2110, loss is 0.008927677758038044\n",
      "epoch: 4 step: 2111, loss is 0.015378635376691818\n",
      "epoch: 4 step: 2112, loss is 0.012680458836257458\n",
      "epoch: 4 step: 2113, loss is 0.1653061956167221\n",
      "epoch: 4 step: 2114, loss is 0.006036677397787571\n",
      "epoch: 4 step: 2115, loss is 0.06688904762268066\n",
      "epoch: 4 step: 2116, loss is 0.008194901049137115\n",
      "epoch: 4 step: 2117, loss is 0.015807459130883217\n",
      "epoch: 4 step: 2118, loss is 0.0005509215989150107\n",
      "epoch: 4 step: 2119, loss is 0.007301563862711191\n",
      "epoch: 4 step: 2120, loss is 0.019675301387906075\n",
      "epoch: 4 step: 2121, loss is 0.0027503815945237875\n",
      "epoch: 4 step: 2122, loss is 0.012008436024188995\n",
      "epoch: 4 step: 2123, loss is 0.12269408255815506\n",
      "epoch: 4 step: 2124, loss is 0.02215075120329857\n",
      "epoch: 4 step: 2125, loss is 0.006353443954139948\n",
      "epoch: 4 step: 2126, loss is 0.11356399953365326\n",
      "epoch: 4 step: 2127, loss is 0.03627169504761696\n",
      "epoch: 4 step: 2128, loss is 0.001327070058323443\n",
      "epoch: 4 step: 2129, loss is 0.00040972797432914376\n",
      "epoch: 4 step: 2130, loss is 0.0061050718650221825\n",
      "epoch: 4 step: 2131, loss is 0.00584392249584198\n",
      "epoch: 4 step: 2132, loss is 0.007150067016482353\n",
      "epoch: 4 step: 2133, loss is 0.02158528007566929\n",
      "epoch: 4 step: 2134, loss is 0.12697993218898773\n",
      "epoch: 4 step: 2135, loss is 0.0066003454849123955\n",
      "epoch: 4 step: 2136, loss is 0.020643630996346474\n",
      "epoch: 4 step: 2137, loss is 0.010168997570872307\n",
      "epoch: 4 step: 2138, loss is 0.0073440298438072205\n",
      "epoch: 4 step: 2139, loss is 0.00860468577593565\n",
      "epoch: 4 step: 2140, loss is 0.0014953856589272618\n",
      "epoch: 4 step: 2141, loss is 0.0440097413957119\n",
      "epoch: 4 step: 2142, loss is 0.003061163006350398\n",
      "epoch: 4 step: 2143, loss is 0.017772436141967773\n",
      "epoch: 4 step: 2144, loss is 0.006427432410418987\n",
      "epoch: 4 step: 2145, loss is 0.002230470534414053\n",
      "epoch: 4 step: 2146, loss is 0.0032838264014571905\n",
      "epoch: 4 step: 2147, loss is 0.006991430651396513\n",
      "epoch: 4 step: 2148, loss is 0.0010322539601475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 2149, loss is 0.00237242947332561\n",
      "epoch: 4 step: 2150, loss is 0.031731605529785156\n",
      "epoch: 4 step: 2151, loss is 0.10467536747455597\n",
      "epoch: 4 step: 2152, loss is 0.00585150858387351\n",
      "epoch: 4 step: 2153, loss is 0.002880622399970889\n",
      "epoch: 4 step: 2154, loss is 0.014264985918998718\n",
      "epoch: 4 step: 2155, loss is 0.02339458093047142\n",
      "epoch: 4 step: 2156, loss is 0.22243918478488922\n",
      "epoch: 4 step: 2157, loss is 0.16511227190494537\n",
      "epoch: 4 step: 2158, loss is 0.00027526033227331936\n",
      "epoch: 4 step: 2159, loss is 0.031799621880054474\n",
      "epoch: 4 step: 2160, loss is 0.00031934387516230345\n",
      "epoch: 4 step: 2161, loss is 0.005198851227760315\n",
      "epoch: 4 step: 2162, loss is 0.04451170563697815\n",
      "epoch: 4 step: 2163, loss is 0.02953079715371132\n",
      "epoch: 4 step: 2164, loss is 0.1458262801170349\n",
      "epoch: 4 step: 2165, loss is 0.0890447199344635\n",
      "epoch: 4 step: 2166, loss is 0.001234158524312079\n",
      "epoch: 4 step: 2167, loss is 0.07093625515699387\n",
      "epoch: 4 step: 2168, loss is 0.19613949954509735\n",
      "epoch: 4 step: 2169, loss is 0.1713777482509613\n",
      "epoch: 4 step: 2170, loss is 0.023185160011053085\n",
      "epoch: 4 step: 2171, loss is 0.007909744046628475\n",
      "epoch: 4 step: 2172, loss is 0.2913011610507965\n",
      "epoch: 4 step: 2173, loss is 0.0184872318059206\n",
      "epoch: 4 step: 2174, loss is 0.04101413115859032\n",
      "epoch: 4 step: 2175, loss is 0.04477585479617119\n",
      "epoch: 4 step: 2176, loss is 0.024829525500535965\n",
      "epoch: 4 step: 2177, loss is 0.0030321741942316294\n",
      "epoch: 4 step: 2178, loss is 0.022334856912493706\n",
      "epoch: 4 step: 2179, loss is 0.015603232197463512\n",
      "epoch: 4 step: 2180, loss is 0.012824342586100101\n",
      "epoch: 4 step: 2181, loss is 0.0836680680513382\n",
      "epoch: 4 step: 2182, loss is 0.0022963888477534056\n",
      "epoch: 4 step: 2183, loss is 0.00011257256119279191\n",
      "epoch: 4 step: 2184, loss is 0.013719256967306137\n",
      "epoch: 4 step: 2185, loss is 0.012660566717386246\n",
      "epoch: 4 step: 2186, loss is 0.051916081458330154\n",
      "epoch: 4 step: 2187, loss is 0.12209225445985794\n",
      "epoch: 5 step: 1, loss is 0.011562281288206577\n",
      "epoch: 5 step: 2, loss is 0.002733658067882061\n",
      "epoch: 5 step: 3, loss is 0.008513481356203556\n",
      "epoch: 5 step: 4, loss is 0.0012384910369291902\n",
      "epoch: 5 step: 5, loss is 0.0005850952584296465\n",
      "epoch: 5 step: 6, loss is 0.016205372288823128\n",
      "epoch: 5 step: 7, loss is 0.007672988343983889\n",
      "epoch: 5 step: 8, loss is 0.0008203185861930251\n",
      "epoch: 5 step: 9, loss is 0.01789778470993042\n",
      "epoch: 5 step: 10, loss is 0.005584643688052893\n",
      "epoch: 5 step: 11, loss is 0.039253585040569305\n",
      "epoch: 5 step: 12, loss is 0.033358845859766006\n",
      "epoch: 5 step: 13, loss is 0.003129107877612114\n",
      "epoch: 5 step: 14, loss is 0.001435929094441235\n",
      "epoch: 5 step: 15, loss is 0.0033812597393989563\n",
      "epoch: 5 step: 16, loss is 0.001501111895777285\n",
      "epoch: 5 step: 17, loss is 0.00014477195509243757\n",
      "epoch: 5 step: 18, loss is 0.00412049051374197\n",
      "epoch: 5 step: 19, loss is 0.038322895765304565\n",
      "epoch: 5 step: 20, loss is 0.007489153649657965\n",
      "epoch: 5 step: 21, loss is 0.038766320794820786\n",
      "epoch: 5 step: 22, loss is 0.0030994070693850517\n",
      "epoch: 5 step: 23, loss is 0.012592179700732231\n",
      "epoch: 5 step: 24, loss is 0.0007951241568662226\n",
      "epoch: 5 step: 25, loss is 0.05367721617221832\n",
      "epoch: 5 step: 26, loss is 0.01617155782878399\n",
      "epoch: 5 step: 27, loss is 0.04720483347773552\n",
      "epoch: 5 step: 28, loss is 0.001491341507062316\n",
      "epoch: 5 step: 29, loss is 0.0005170645308680832\n",
      "epoch: 5 step: 30, loss is 0.045499350875616074\n",
      "epoch: 5 step: 31, loss is 0.015234929509460926\n",
      "epoch: 5 step: 32, loss is 0.005383789539337158\n",
      "epoch: 5 step: 33, loss is 0.026210468262434006\n",
      "epoch: 5 step: 34, loss is 0.04061752185225487\n",
      "epoch: 5 step: 35, loss is 0.003968060947954655\n",
      "epoch: 5 step: 36, loss is 0.08561962842941284\n",
      "epoch: 5 step: 37, loss is 0.03523985296487808\n",
      "epoch: 5 step: 38, loss is 0.11457768827676773\n",
      "epoch: 5 step: 39, loss is 0.016527049243450165\n",
      "epoch: 5 step: 40, loss is 0.0010110489092767239\n",
      "epoch: 5 step: 41, loss is 0.126242995262146\n",
      "epoch: 5 step: 42, loss is 0.0013901848578825593\n",
      "epoch: 5 step: 43, loss is 0.0006397408433258533\n",
      "epoch: 5 step: 44, loss is 0.06754341721534729\n",
      "epoch: 5 step: 45, loss is 0.0010437163291499019\n",
      "epoch: 5 step: 46, loss is 0.0003645203833002597\n",
      "epoch: 5 step: 47, loss is 0.001820215955376625\n",
      "epoch: 5 step: 48, loss is 0.008749839849770069\n",
      "epoch: 5 step: 49, loss is 0.0037371234502643347\n",
      "epoch: 5 step: 50, loss is 0.017144812270998955\n",
      "epoch: 5 step: 51, loss is 0.0002438614028505981\n",
      "epoch: 5 step: 52, loss is 0.028038883581757545\n",
      "epoch: 5 step: 53, loss is 0.052336275577545166\n",
      "epoch: 5 step: 54, loss is 0.07634513080120087\n",
      "epoch: 5 step: 55, loss is 0.015359803102910519\n",
      "epoch: 5 step: 56, loss is 0.013165440410375595\n",
      "epoch: 5 step: 57, loss is 0.002078154357150197\n",
      "epoch: 5 step: 58, loss is 0.007621597032994032\n",
      "epoch: 5 step: 59, loss is 0.0029247491620481014\n",
      "epoch: 5 step: 60, loss is 0.008925890550017357\n",
      "epoch: 5 step: 61, loss is 0.009614638052880764\n",
      "epoch: 5 step: 62, loss is 0.0011251308023929596\n",
      "epoch: 5 step: 63, loss is 0.01428127195686102\n",
      "epoch: 5 step: 64, loss is 0.1432163268327713\n",
      "epoch: 5 step: 65, loss is 0.0014880584785714746\n",
      "epoch: 5 step: 66, loss is 0.0016132290475070477\n",
      "epoch: 5 step: 67, loss is 0.019089307636022568\n",
      "epoch: 5 step: 68, loss is 0.0011499164393171668\n",
      "epoch: 5 step: 69, loss is 0.06998363137245178\n",
      "epoch: 5 step: 70, loss is 0.0003392219659872353\n",
      "epoch: 5 step: 71, loss is 0.00018240537610836327\n",
      "epoch: 5 step: 72, loss is 0.0017221333691850305\n",
      "epoch: 5 step: 73, loss is 0.0019384309416636825\n",
      "epoch: 5 step: 74, loss is 0.005490914918482304\n",
      "epoch: 5 step: 75, loss is 0.05704442411661148\n",
      "epoch: 5 step: 76, loss is 0.00266647944226861\n",
      "epoch: 5 step: 77, loss is 0.0028235469944775105\n",
      "epoch: 5 step: 78, loss is 0.029970891773700714\n",
      "epoch: 5 step: 79, loss is 0.003099018707871437\n",
      "epoch: 5 step: 80, loss is 0.005060885567218065\n",
      "epoch: 5 step: 81, loss is 0.13267453014850616\n",
      "epoch: 5 step: 82, loss is 0.0009177963947877288\n",
      "epoch: 5 step: 83, loss is 0.03249652683734894\n",
      "epoch: 5 step: 84, loss is 0.0013018302852287889\n",
      "epoch: 5 step: 85, loss is 0.0015353676863014698\n",
      "epoch: 5 step: 86, loss is 0.000488962628878653\n",
      "epoch: 5 step: 87, loss is 0.009638328105211258\n",
      "epoch: 5 step: 88, loss is 0.00021413674403447658\n",
      "epoch: 5 step: 89, loss is 0.0025783414021134377\n",
      "epoch: 5 step: 90, loss is 0.0007507937261834741\n",
      "epoch: 5 step: 91, loss is 0.03861497715115547\n",
      "epoch: 5 step: 92, loss is 0.0032959708478301764\n",
      "epoch: 5 step: 93, loss is 0.012599502690136433\n",
      "epoch: 5 step: 94, loss is 0.10211252421140671\n",
      "epoch: 5 step: 95, loss is 0.0007500534411519766\n",
      "epoch: 5 step: 96, loss is 0.018114615231752396\n",
      "epoch: 5 step: 97, loss is 0.002200980903580785\n",
      "epoch: 5 step: 98, loss is 0.028371458873152733\n",
      "epoch: 5 step: 99, loss is 0.00029222649754956365\n",
      "epoch: 5 step: 100, loss is 0.00040799795533530414\n",
      "epoch: 5 step: 101, loss is 0.0024819602258503437\n",
      "epoch: 5 step: 102, loss is 0.0007001797202974558\n",
      "epoch: 5 step: 103, loss is 0.0014858399517834187\n",
      "epoch: 5 step: 104, loss is 0.019053451716899872\n",
      "epoch: 5 step: 105, loss is 0.0005239570164121687\n",
      "epoch: 5 step: 106, loss is 0.0003628352133091539\n",
      "epoch: 5 step: 107, loss is 0.003337400034070015\n",
      "epoch: 5 step: 108, loss is 0.0005892786430194974\n",
      "epoch: 5 step: 109, loss is 9.357530507259071e-05\n",
      "epoch: 5 step: 110, loss is 0.00031674507772549987\n",
      "epoch: 5 step: 111, loss is 0.0060141305439174175\n",
      "epoch: 5 step: 112, loss is 0.005532623268663883\n",
      "epoch: 5 step: 113, loss is 0.0071695223450660706\n",
      "epoch: 5 step: 114, loss is 0.0003929039230570197\n",
      "epoch: 5 step: 115, loss is 0.00361302075907588\n",
      "epoch: 5 step: 116, loss is 0.0020663770847022533\n",
      "epoch: 5 step: 117, loss is 0.0002579473948571831\n",
      "epoch: 5 step: 118, loss is 0.0001466600806452334\n",
      "epoch: 5 step: 119, loss is 0.00018447954789735377\n",
      "epoch: 5 step: 120, loss is 0.031314559280872345\n",
      "epoch: 5 step: 121, loss is 0.001376509782858193\n",
      "epoch: 5 step: 122, loss is 0.002371616428717971\n",
      "epoch: 5 step: 123, loss is 0.0005438397056423128\n",
      "epoch: 5 step: 124, loss is 0.0018502074526622891\n",
      "epoch: 5 step: 125, loss is 0.009065338410437107\n",
      "epoch: 5 step: 126, loss is 0.009518668055534363\n",
      "epoch: 5 step: 127, loss is 0.0005431455210782588\n",
      "epoch: 5 step: 128, loss is 0.009561690501868725\n",
      "epoch: 5 step: 129, loss is 0.0019731621723622084\n",
      "epoch: 5 step: 130, loss is 0.002350523602217436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 131, loss is 0.014924435876309872\n",
      "epoch: 5 step: 132, loss is 0.005052805878221989\n",
      "epoch: 5 step: 133, loss is 0.001072862185537815\n",
      "epoch: 5 step: 134, loss is 0.0197925828397274\n",
      "epoch: 5 step: 135, loss is 0.0016250014305114746\n",
      "epoch: 5 step: 136, loss is 0.10565206408500671\n",
      "epoch: 5 step: 137, loss is 0.0002467857557348907\n",
      "epoch: 5 step: 138, loss is 0.009731704369187355\n",
      "epoch: 5 step: 139, loss is 0.00019845917995553464\n",
      "epoch: 5 step: 140, loss is 0.0015134408604353666\n",
      "epoch: 5 step: 141, loss is 0.0005859180819243193\n",
      "epoch: 5 step: 142, loss is 0.0001816627336665988\n",
      "epoch: 5 step: 143, loss is 0.00016763345047365874\n",
      "epoch: 5 step: 144, loss is 0.04615124315023422\n",
      "epoch: 5 step: 145, loss is 0.03766708821058273\n",
      "epoch: 5 step: 146, loss is 0.00043746273149736226\n",
      "epoch: 5 step: 147, loss is 0.008648709394037724\n",
      "epoch: 5 step: 148, loss is 0.0016948676202446222\n",
      "epoch: 5 step: 149, loss is 0.0010593633633106947\n",
      "epoch: 5 step: 150, loss is 0.00869736261665821\n",
      "epoch: 5 step: 151, loss is 0.00041898799827322364\n",
      "epoch: 5 step: 152, loss is 0.01947401650249958\n",
      "epoch: 5 step: 153, loss is 0.02444489672780037\n",
      "epoch: 5 step: 154, loss is 0.004425082355737686\n",
      "epoch: 5 step: 155, loss is 0.00027397394296713173\n",
      "epoch: 5 step: 156, loss is 0.0001931442820932716\n",
      "epoch: 5 step: 157, loss is 0.17962750792503357\n",
      "epoch: 5 step: 158, loss is 4.970008012605831e-05\n",
      "epoch: 5 step: 159, loss is 0.0001978411164600402\n",
      "epoch: 5 step: 160, loss is 0.001983666094020009\n",
      "epoch: 5 step: 161, loss is 0.00035127013688907027\n",
      "epoch: 5 step: 162, loss is 0.012187442742288113\n",
      "epoch: 5 step: 163, loss is 0.0001427946554031223\n",
      "epoch: 5 step: 164, loss is 0.16582517325878143\n",
      "epoch: 5 step: 165, loss is 0.002219828777015209\n",
      "epoch: 5 step: 166, loss is 0.031001074239611626\n",
      "epoch: 5 step: 167, loss is 0.004221627023071051\n",
      "epoch: 5 step: 168, loss is 0.0001574565249029547\n",
      "epoch: 5 step: 169, loss is 0.0015619999030604959\n",
      "epoch: 5 step: 170, loss is 0.14657561480998993\n",
      "epoch: 5 step: 171, loss is 0.03339165076613426\n",
      "epoch: 5 step: 172, loss is 0.00029677493148483336\n",
      "epoch: 5 step: 173, loss is 0.0027307216078042984\n",
      "epoch: 5 step: 174, loss is 0.0004598720697686076\n",
      "epoch: 5 step: 175, loss is 0.001339176669716835\n",
      "epoch: 5 step: 176, loss is 0.0045187463983893394\n",
      "epoch: 5 step: 177, loss is 0.038200028240680695\n",
      "epoch: 5 step: 178, loss is 0.11787611246109009\n",
      "epoch: 5 step: 179, loss is 0.024186229333281517\n",
      "epoch: 5 step: 180, loss is 0.046628668904304504\n",
      "epoch: 5 step: 181, loss is 0.0007341613527387381\n",
      "epoch: 5 step: 182, loss is 0.07838088274002075\n",
      "epoch: 5 step: 183, loss is 0.004845611751079559\n",
      "epoch: 5 step: 184, loss is 0.18919789791107178\n",
      "epoch: 5 step: 185, loss is 0.0002874817291740328\n",
      "epoch: 5 step: 186, loss is 0.00199444149620831\n",
      "epoch: 5 step: 187, loss is 0.16534745693206787\n",
      "epoch: 5 step: 188, loss is 0.07609652727842331\n",
      "epoch: 5 step: 189, loss is 0.0021628476679325104\n",
      "epoch: 5 step: 190, loss is 0.004195008892565966\n",
      "epoch: 5 step: 191, loss is 0.006399627774953842\n",
      "epoch: 5 step: 192, loss is 0.014312040992081165\n",
      "epoch: 5 step: 193, loss is 0.0007910158601589501\n",
      "epoch: 5 step: 194, loss is 0.042931631207466125\n",
      "epoch: 5 step: 195, loss is 0.0025002751499414444\n",
      "epoch: 5 step: 196, loss is 0.0032431844156235456\n",
      "epoch: 5 step: 197, loss is 0.19002071022987366\n",
      "epoch: 5 step: 198, loss is 0.0020387431140989065\n",
      "epoch: 5 step: 199, loss is 0.04137954115867615\n",
      "epoch: 5 step: 200, loss is 0.11965988576412201\n",
      "epoch: 5 step: 201, loss is 0.036665599793195724\n",
      "epoch: 5 step: 202, loss is 0.0006028988864272833\n",
      "epoch: 5 step: 203, loss is 0.10892261564731598\n",
      "epoch: 5 step: 204, loss is 0.004442931152880192\n",
      "epoch: 5 step: 205, loss is 0.000506018113810569\n",
      "epoch: 5 step: 206, loss is 0.24827530980110168\n",
      "epoch: 5 step: 207, loss is 0.004399674013257027\n",
      "epoch: 5 step: 208, loss is 0.0005466693546622992\n",
      "epoch: 5 step: 209, loss is 0.13279442489147186\n",
      "epoch: 5 step: 210, loss is 0.00861386489123106\n",
      "epoch: 5 step: 211, loss is 0.010370304808020592\n",
      "epoch: 5 step: 212, loss is 0.0034053358249366283\n",
      "epoch: 5 step: 213, loss is 0.02804115042090416\n",
      "epoch: 5 step: 214, loss is 0.004560372326523066\n",
      "epoch: 5 step: 215, loss is 0.001641897833906114\n",
      "epoch: 5 step: 216, loss is 0.001739101018756628\n",
      "epoch: 5 step: 217, loss is 0.0009753871709108353\n",
      "epoch: 5 step: 218, loss is 0.003157045692205429\n",
      "epoch: 5 step: 219, loss is 0.00286699621938169\n",
      "epoch: 5 step: 220, loss is 0.01739058643579483\n",
      "epoch: 5 step: 221, loss is 0.021610092371702194\n",
      "epoch: 5 step: 222, loss is 0.005330438259989023\n",
      "epoch: 5 step: 223, loss is 0.0013033756986260414\n",
      "epoch: 5 step: 224, loss is 0.002093520713970065\n",
      "epoch: 5 step: 225, loss is 0.0018408482428640127\n",
      "epoch: 5 step: 226, loss is 0.00036634120624512434\n",
      "epoch: 5 step: 227, loss is 0.002318470273166895\n",
      "epoch: 5 step: 228, loss is 0.02822064608335495\n",
      "epoch: 5 step: 229, loss is 0.060666926205158234\n",
      "epoch: 5 step: 230, loss is 0.0015861396677792072\n",
      "epoch: 5 step: 231, loss is 0.0012816579546779394\n",
      "epoch: 5 step: 232, loss is 0.10186778008937836\n",
      "epoch: 5 step: 233, loss is 0.06903602182865143\n",
      "epoch: 5 step: 234, loss is 0.006581693887710571\n",
      "epoch: 5 step: 235, loss is 0.03877022862434387\n",
      "epoch: 5 step: 236, loss is 0.011917727999389172\n",
      "epoch: 5 step: 237, loss is 0.07077004760503769\n",
      "epoch: 5 step: 238, loss is 0.04848704859614372\n",
      "epoch: 5 step: 239, loss is 0.01432747207581997\n",
      "epoch: 5 step: 240, loss is 0.22351615130901337\n",
      "epoch: 5 step: 241, loss is 0.002482883632183075\n",
      "epoch: 5 step: 242, loss is 0.009292847476899624\n",
      "epoch: 5 step: 243, loss is 0.00435083219781518\n",
      "epoch: 5 step: 244, loss is 0.03681313991546631\n",
      "epoch: 5 step: 245, loss is 0.009466228075325489\n",
      "epoch: 5 step: 246, loss is 0.06597317010164261\n",
      "epoch: 5 step: 247, loss is 0.059712085872888565\n",
      "epoch: 5 step: 248, loss is 0.000631590373814106\n",
      "epoch: 5 step: 249, loss is 0.026388458907604218\n",
      "epoch: 5 step: 250, loss is 0.009590648114681244\n",
      "epoch: 5 step: 251, loss is 0.004174548201262951\n",
      "epoch: 5 step: 252, loss is 0.00040359669947065413\n",
      "epoch: 5 step: 253, loss is 0.03823119029402733\n",
      "epoch: 5 step: 254, loss is 0.002890228759497404\n",
      "epoch: 5 step: 255, loss is 0.038711246103048325\n",
      "epoch: 5 step: 256, loss is 0.0031772153452038765\n",
      "epoch: 5 step: 257, loss is 0.010535361245274544\n",
      "epoch: 5 step: 258, loss is 0.0014483571285381913\n",
      "epoch: 5 step: 259, loss is 0.017539430409669876\n",
      "epoch: 5 step: 260, loss is 0.06956157088279724\n",
      "epoch: 5 step: 261, loss is 0.002242631744593382\n",
      "epoch: 5 step: 262, loss is 0.0013395085697993636\n",
      "epoch: 5 step: 263, loss is 0.010145733132958412\n",
      "epoch: 5 step: 264, loss is 0.0013481245841830969\n",
      "epoch: 5 step: 265, loss is 0.0020468803122639656\n",
      "epoch: 5 step: 266, loss is 0.0020188731141388416\n",
      "epoch: 5 step: 267, loss is 0.02641580067574978\n",
      "epoch: 5 step: 268, loss is 0.001131717930547893\n",
      "epoch: 5 step: 269, loss is 0.00030564991175197065\n",
      "epoch: 5 step: 270, loss is 0.011863688006997108\n",
      "epoch: 5 step: 271, loss is 0.001550244283862412\n",
      "epoch: 5 step: 272, loss is 0.0004470098065212369\n",
      "epoch: 5 step: 273, loss is 0.040956050157547\n",
      "epoch: 5 step: 274, loss is 0.017213895916938782\n",
      "epoch: 5 step: 275, loss is 0.22574760019779205\n",
      "epoch: 5 step: 276, loss is 0.0025898858439177275\n",
      "epoch: 5 step: 277, loss is 0.0043541500344872475\n",
      "epoch: 5 step: 278, loss is 0.0004484190430957824\n",
      "epoch: 5 step: 279, loss is 0.001837736344896257\n",
      "epoch: 5 step: 280, loss is 0.00495856162160635\n",
      "epoch: 5 step: 281, loss is 0.00245619541965425\n",
      "epoch: 5 step: 282, loss is 0.0017086256993934512\n",
      "epoch: 5 step: 283, loss is 0.003915606066584587\n",
      "epoch: 5 step: 284, loss is 0.0014253441477194428\n",
      "epoch: 5 step: 285, loss is 0.0209942739456892\n",
      "epoch: 5 step: 286, loss is 0.10318684577941895\n",
      "epoch: 5 step: 287, loss is 0.0896369218826294\n",
      "epoch: 5 step: 288, loss is 0.11519543081521988\n",
      "epoch: 5 step: 289, loss is 0.000634505064226687\n",
      "epoch: 5 step: 290, loss is 0.001098305219784379\n",
      "epoch: 5 step: 291, loss is 0.0005087360041216016\n",
      "epoch: 5 step: 292, loss is 0.07706736773252487\n",
      "epoch: 5 step: 293, loss is 0.02986868843436241\n",
      "epoch: 5 step: 294, loss is 0.13525892794132233\n",
      "epoch: 5 step: 295, loss is 0.0009057323914021254\n",
      "epoch: 5 step: 296, loss is 0.00018268378335051239\n",
      "epoch: 5 step: 297, loss is 0.016550330445170403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 298, loss is 0.04251819849014282\n",
      "epoch: 5 step: 299, loss is 0.0026612328365445137\n",
      "epoch: 5 step: 300, loss is 0.012265698984265327\n",
      "epoch: 5 step: 301, loss is 0.19187776744365692\n",
      "epoch: 5 step: 302, loss is 0.009602969512343407\n",
      "epoch: 5 step: 303, loss is 0.04937021806836128\n",
      "epoch: 5 step: 304, loss is 0.0009666685946285725\n",
      "epoch: 5 step: 305, loss is 0.027683332562446594\n",
      "epoch: 5 step: 306, loss is 0.018730012699961662\n",
      "epoch: 5 step: 307, loss is 0.0008591291843913496\n",
      "epoch: 5 step: 308, loss is 0.013006559573113918\n",
      "epoch: 5 step: 309, loss is 0.004595268052071333\n",
      "epoch: 5 step: 310, loss is 0.020232291892170906\n",
      "epoch: 5 step: 311, loss is 0.004512623883783817\n",
      "epoch: 5 step: 312, loss is 0.07377468049526215\n",
      "epoch: 5 step: 313, loss is 0.04570620879530907\n",
      "epoch: 5 step: 314, loss is 0.002026114845648408\n",
      "epoch: 5 step: 315, loss is 0.0063356938771903515\n",
      "epoch: 5 step: 316, loss is 0.00974242202937603\n",
      "epoch: 5 step: 317, loss is 0.014134975150227547\n",
      "epoch: 5 step: 318, loss is 0.0039212205447256565\n",
      "epoch: 5 step: 319, loss is 0.0005064461729489267\n",
      "epoch: 5 step: 320, loss is 0.01700848899781704\n",
      "epoch: 5 step: 321, loss is 0.0028186773415654898\n",
      "epoch: 5 step: 322, loss is 0.008802839554846287\n",
      "epoch: 5 step: 323, loss is 0.16548152267932892\n",
      "epoch: 5 step: 324, loss is 0.1319957673549652\n",
      "epoch: 5 step: 325, loss is 0.00044201541459187865\n",
      "epoch: 5 step: 326, loss is 0.04940317943692207\n",
      "epoch: 5 step: 327, loss is 0.023908570408821106\n",
      "epoch: 5 step: 328, loss is 0.0028200310189276934\n",
      "epoch: 5 step: 329, loss is 0.020052621141076088\n",
      "epoch: 5 step: 330, loss is 0.0005552688962779939\n",
      "epoch: 5 step: 331, loss is 0.004672440700232983\n",
      "epoch: 5 step: 332, loss is 0.0004333869437687099\n",
      "epoch: 5 step: 333, loss is 0.001153044868260622\n",
      "epoch: 5 step: 334, loss is 0.0019277316750958562\n",
      "epoch: 5 step: 335, loss is 0.039252106100320816\n",
      "epoch: 5 step: 336, loss is 0.022858455777168274\n",
      "epoch: 5 step: 337, loss is 0.05288442224264145\n",
      "epoch: 5 step: 338, loss is 0.0018132281256839633\n",
      "epoch: 5 step: 339, loss is 0.00044979501399211586\n",
      "epoch: 5 step: 340, loss is 0.05906136333942413\n",
      "epoch: 5 step: 341, loss is 0.04678468778729439\n",
      "epoch: 5 step: 342, loss is 0.00776821980252862\n",
      "epoch: 5 step: 343, loss is 0.005980271380394697\n",
      "epoch: 5 step: 344, loss is 0.0017989426851272583\n",
      "epoch: 5 step: 345, loss is 0.00980140920728445\n",
      "epoch: 5 step: 346, loss is 0.008586479350924492\n",
      "epoch: 5 step: 347, loss is 0.0136072663590312\n",
      "epoch: 5 step: 348, loss is 0.01897408254444599\n",
      "epoch: 5 step: 349, loss is 0.0005453318008221686\n",
      "epoch: 5 step: 350, loss is 0.001241570571437478\n",
      "epoch: 5 step: 351, loss is 0.036176975816488266\n",
      "epoch: 5 step: 352, loss is 0.10742511600255966\n",
      "epoch: 5 step: 353, loss is 0.0875953733921051\n",
      "epoch: 5 step: 354, loss is 0.011678509414196014\n",
      "epoch: 5 step: 355, loss is 0.0046708304435014725\n",
      "epoch: 5 step: 356, loss is 0.01838487572968006\n",
      "epoch: 5 step: 357, loss is 0.005990878213196993\n",
      "epoch: 5 step: 358, loss is 0.04998330399394035\n",
      "epoch: 5 step: 359, loss is 0.039914049208164215\n",
      "epoch: 5 step: 360, loss is 0.02560994029045105\n",
      "epoch: 5 step: 361, loss is 0.0009109602542594075\n",
      "epoch: 5 step: 362, loss is 0.007181375753134489\n",
      "epoch: 5 step: 363, loss is 0.004062889609485865\n",
      "epoch: 5 step: 364, loss is 0.011181003414094448\n",
      "epoch: 5 step: 365, loss is 0.00017002127424348146\n",
      "epoch: 5 step: 366, loss is 0.0005038643721491098\n",
      "epoch: 5 step: 367, loss is 0.022148463875055313\n",
      "epoch: 5 step: 368, loss is 0.013917379081249237\n",
      "epoch: 5 step: 369, loss is 0.01153256744146347\n",
      "epoch: 5 step: 370, loss is 0.10376817733049393\n",
      "epoch: 5 step: 371, loss is 0.000499809393659234\n",
      "epoch: 5 step: 372, loss is 0.0010469740955159068\n",
      "epoch: 5 step: 373, loss is 0.028105806559324265\n",
      "epoch: 5 step: 374, loss is 0.03254682943224907\n",
      "epoch: 5 step: 375, loss is 0.0004895058227702975\n",
      "epoch: 5 step: 376, loss is 0.005521678365767002\n",
      "epoch: 5 step: 377, loss is 0.036852456629276276\n",
      "epoch: 5 step: 378, loss is 0.007551663555204868\n",
      "epoch: 5 step: 379, loss is 0.012311268597841263\n",
      "epoch: 5 step: 380, loss is 0.0016403759364038706\n",
      "epoch: 5 step: 381, loss is 0.006449409760534763\n",
      "epoch: 5 step: 382, loss is 0.0020868186838924885\n",
      "epoch: 5 step: 383, loss is 0.0003237744967918843\n",
      "epoch: 5 step: 384, loss is 0.000513330742251128\n",
      "epoch: 5 step: 385, loss is 0.018202589824795723\n",
      "epoch: 5 step: 386, loss is 0.0005194996483623981\n",
      "epoch: 5 step: 387, loss is 0.016576116904616356\n",
      "epoch: 5 step: 388, loss is 0.0017085701692849398\n",
      "epoch: 5 step: 389, loss is 0.03230906277894974\n",
      "epoch: 5 step: 390, loss is 0.03799763694405556\n",
      "epoch: 5 step: 391, loss is 0.0010283805895596743\n",
      "epoch: 5 step: 392, loss is 0.0002317912585567683\n",
      "epoch: 5 step: 393, loss is 0.0003848728956654668\n",
      "epoch: 5 step: 394, loss is 0.0015384913422167301\n",
      "epoch: 5 step: 395, loss is 0.022161230444908142\n",
      "epoch: 5 step: 396, loss is 0.04702369496226311\n",
      "epoch: 5 step: 397, loss is 8.879845699993894e-05\n",
      "epoch: 5 step: 398, loss is 0.00888808909803629\n",
      "epoch: 5 step: 399, loss is 0.013212878257036209\n",
      "epoch: 5 step: 400, loss is 0.011476839892566204\n",
      "epoch: 5 step: 401, loss is 0.013443429954349995\n",
      "epoch: 5 step: 402, loss is 0.004355783574283123\n",
      "epoch: 5 step: 403, loss is 0.003908975515514612\n",
      "epoch: 5 step: 404, loss is 0.006795056629925966\n",
      "epoch: 5 step: 405, loss is 0.00012530383537523448\n",
      "epoch: 5 step: 406, loss is 0.0011407649144530296\n",
      "epoch: 5 step: 407, loss is 0.08506728708744049\n",
      "epoch: 5 step: 408, loss is 0.03796941041946411\n",
      "epoch: 5 step: 409, loss is 0.0021989825181663036\n",
      "epoch: 5 step: 410, loss is 0.0014365044189617038\n",
      "epoch: 5 step: 411, loss is 0.042491693049669266\n",
      "epoch: 5 step: 412, loss is 0.0014960322296246886\n",
      "epoch: 5 step: 413, loss is 0.00013351134839467704\n",
      "epoch: 5 step: 414, loss is 0.0014352098805829883\n",
      "epoch: 5 step: 415, loss is 0.0002309448318555951\n",
      "epoch: 5 step: 416, loss is 0.0025246108416467905\n",
      "epoch: 5 step: 417, loss is 0.0005770241259597242\n",
      "epoch: 5 step: 418, loss is 0.0010883377399295568\n",
      "epoch: 5 step: 419, loss is 0.009869585745036602\n",
      "epoch: 5 step: 420, loss is 0.003969072364270687\n",
      "epoch: 5 step: 421, loss is 0.0004270138742867857\n",
      "epoch: 5 step: 422, loss is 5.4665124480379745e-05\n",
      "epoch: 5 step: 423, loss is 0.0035458493512123823\n",
      "epoch: 5 step: 424, loss is 0.01255863904953003\n",
      "epoch: 5 step: 425, loss is 0.00019520538626238704\n",
      "epoch: 5 step: 426, loss is 0.0031560950446873903\n",
      "epoch: 5 step: 427, loss is 0.004395035095512867\n",
      "epoch: 5 step: 428, loss is 0.015456552617251873\n",
      "epoch: 5 step: 429, loss is 0.0005268724635243416\n",
      "epoch: 5 step: 430, loss is 0.013167009688913822\n",
      "epoch: 5 step: 431, loss is 0.0033780401572585106\n",
      "epoch: 5 step: 432, loss is 4.9712722102412954e-05\n",
      "epoch: 5 step: 433, loss is 0.06697159260511398\n",
      "epoch: 5 step: 434, loss is 0.0003984853392466903\n",
      "epoch: 5 step: 435, loss is 0.01773773692548275\n",
      "epoch: 5 step: 436, loss is 0.0019468852551653981\n",
      "epoch: 5 step: 437, loss is 0.0036628430243581533\n",
      "epoch: 5 step: 438, loss is 0.013533166609704494\n",
      "epoch: 5 step: 439, loss is 0.0020492919720709324\n",
      "epoch: 5 step: 440, loss is 0.0005479722167365253\n",
      "epoch: 5 step: 441, loss is 0.09791246056556702\n",
      "epoch: 5 step: 442, loss is 0.001295951078645885\n",
      "epoch: 5 step: 443, loss is 0.03761817514896393\n",
      "epoch: 5 step: 444, loss is 0.1319684237241745\n",
      "epoch: 5 step: 445, loss is 0.0013103719102218747\n",
      "epoch: 5 step: 446, loss is 0.01227403711527586\n",
      "epoch: 5 step: 447, loss is 0.00043447065399959683\n",
      "epoch: 5 step: 448, loss is 0.00015364799764938653\n",
      "epoch: 5 step: 449, loss is 0.005383562762290239\n",
      "epoch: 5 step: 450, loss is 0.0034156953915953636\n",
      "epoch: 5 step: 451, loss is 0.040552131831645966\n",
      "epoch: 5 step: 452, loss is 0.02770232781767845\n",
      "epoch: 5 step: 453, loss is 0.0006578047177754343\n",
      "epoch: 5 step: 454, loss is 0.0519297793507576\n",
      "epoch: 5 step: 455, loss is 0.0007241094135679305\n",
      "epoch: 5 step: 456, loss is 0.0010248057078570127\n",
      "epoch: 5 step: 457, loss is 0.04930194467306137\n",
      "epoch: 5 step: 458, loss is 0.0006032787496224046\n",
      "epoch: 5 step: 459, loss is 0.12975336611270905\n",
      "epoch: 5 step: 460, loss is 0.001036169589497149\n",
      "epoch: 5 step: 461, loss is 0.0006782012642361224\n",
      "epoch: 5 step: 462, loss is 0.00018840315169654787\n",
      "epoch: 5 step: 463, loss is 8.127657929435372e-05\n",
      "epoch: 5 step: 464, loss is 0.027840889990329742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 465, loss is 0.02926645241677761\n",
      "epoch: 5 step: 466, loss is 0.11034545302391052\n",
      "epoch: 5 step: 467, loss is 0.0019859287422150373\n",
      "epoch: 5 step: 468, loss is 0.014023039489984512\n",
      "epoch: 5 step: 469, loss is 0.015116466209292412\n",
      "epoch: 5 step: 470, loss is 0.00010099754581460729\n",
      "epoch: 5 step: 471, loss is 0.01411727536469698\n",
      "epoch: 5 step: 472, loss is 0.00046358018880710006\n",
      "epoch: 5 step: 473, loss is 0.012295536696910858\n",
      "epoch: 5 step: 474, loss is 0.0010621203109622002\n",
      "epoch: 5 step: 475, loss is 0.04078329727053642\n",
      "epoch: 5 step: 476, loss is 0.17377373576164246\n",
      "epoch: 5 step: 477, loss is 0.0020658071152865887\n",
      "epoch: 5 step: 478, loss is 0.0007024700753390789\n",
      "epoch: 5 step: 479, loss is 0.2668524980545044\n",
      "epoch: 5 step: 480, loss is 0.07412514835596085\n",
      "epoch: 5 step: 481, loss is 0.00035767946974374354\n",
      "epoch: 5 step: 482, loss is 0.01867329329252243\n",
      "epoch: 5 step: 483, loss is 0.010984014719724655\n",
      "epoch: 5 step: 484, loss is 0.0008613175014033914\n",
      "epoch: 5 step: 485, loss is 0.0005087275640107691\n",
      "epoch: 5 step: 486, loss is 0.05199083685874939\n",
      "epoch: 5 step: 487, loss is 0.0025333345402032137\n",
      "epoch: 5 step: 488, loss is 0.00019190202874597162\n",
      "epoch: 5 step: 489, loss is 0.0028094325680285692\n",
      "epoch: 5 step: 490, loss is 0.034867364913225174\n",
      "epoch: 5 step: 491, loss is 0.028750158846378326\n",
      "epoch: 5 step: 492, loss is 0.15160717070102692\n",
      "epoch: 5 step: 493, loss is 0.002084938110783696\n",
      "epoch: 5 step: 494, loss is 0.007853502407670021\n",
      "epoch: 5 step: 495, loss is 0.004302157089114189\n",
      "epoch: 5 step: 496, loss is 0.08279202878475189\n",
      "epoch: 5 step: 497, loss is 0.04937778040766716\n",
      "epoch: 5 step: 498, loss is 0.0004860280314460397\n",
      "epoch: 5 step: 499, loss is 0.04159563034772873\n",
      "epoch: 5 step: 500, loss is 0.00030509373755194247\n",
      "epoch: 5 step: 501, loss is 0.003581724362447858\n",
      "epoch: 5 step: 502, loss is 0.020147651433944702\n",
      "epoch: 5 step: 503, loss is 0.0008753202273510396\n",
      "epoch: 5 step: 504, loss is 0.009792718105018139\n",
      "epoch: 5 step: 505, loss is 0.06733772903680801\n",
      "epoch: 5 step: 506, loss is 0.0024120088201016188\n",
      "epoch: 5 step: 507, loss is 0.012757058255374432\n",
      "epoch: 5 step: 508, loss is 0.004121416248381138\n",
      "epoch: 5 step: 509, loss is 0.0037137852050364017\n",
      "epoch: 5 step: 510, loss is 0.09048464149236679\n",
      "epoch: 5 step: 511, loss is 0.03979238495230675\n",
      "epoch: 5 step: 512, loss is 0.0013938623014837503\n",
      "epoch: 5 step: 513, loss is 0.00011410002480261028\n",
      "epoch: 5 step: 514, loss is 0.03205103054642677\n",
      "epoch: 5 step: 515, loss is 0.00020456755009945482\n",
      "epoch: 5 step: 516, loss is 0.004594952799379826\n",
      "epoch: 5 step: 517, loss is 0.03824741020798683\n",
      "epoch: 5 step: 518, loss is 0.002967648906633258\n",
      "epoch: 5 step: 519, loss is 0.009980458766222\n",
      "epoch: 5 step: 520, loss is 0.00039711978752166033\n",
      "epoch: 5 step: 521, loss is 0.0007871785783208907\n",
      "epoch: 5 step: 522, loss is 0.09475713223218918\n",
      "epoch: 5 step: 523, loss is 0.007446503732353449\n",
      "epoch: 5 step: 524, loss is 0.008820673450827599\n",
      "epoch: 5 step: 525, loss is 0.00016939284978434443\n",
      "epoch: 5 step: 526, loss is 0.002650993876159191\n",
      "epoch: 5 step: 527, loss is 0.001088002580218017\n",
      "epoch: 5 step: 528, loss is 0.0048909373581409454\n",
      "epoch: 5 step: 529, loss is 0.006832528859376907\n",
      "epoch: 5 step: 530, loss is 0.011086306534707546\n",
      "epoch: 5 step: 531, loss is 0.00821783859282732\n",
      "epoch: 5 step: 532, loss is 0.0037644330877810717\n",
      "epoch: 5 step: 533, loss is 0.07734919339418411\n",
      "epoch: 5 step: 534, loss is 0.0008569651981815696\n",
      "epoch: 5 step: 535, loss is 0.00040508416714146733\n",
      "epoch: 5 step: 536, loss is 0.00024197122547775507\n",
      "epoch: 5 step: 537, loss is 0.01371185015887022\n",
      "epoch: 5 step: 538, loss is 0.0004621153639163822\n",
      "epoch: 5 step: 539, loss is 0.017145290970802307\n",
      "epoch: 5 step: 540, loss is 0.0019527934491634369\n",
      "epoch: 5 step: 541, loss is 0.010570592246949673\n",
      "epoch: 5 step: 542, loss is 0.010347812436521053\n",
      "epoch: 5 step: 543, loss is 0.15213575959205627\n",
      "epoch: 5 step: 544, loss is 0.002907347632572055\n",
      "epoch: 5 step: 545, loss is 0.004894738085567951\n",
      "epoch: 5 step: 546, loss is 0.0005374961183406413\n",
      "epoch: 5 step: 547, loss is 0.039675191044807434\n",
      "epoch: 5 step: 548, loss is 0.002805112162604928\n",
      "epoch: 5 step: 549, loss is 0.009382444433867931\n",
      "epoch: 5 step: 550, loss is 0.023834094405174255\n",
      "epoch: 5 step: 551, loss is 0.014827079139649868\n",
      "epoch: 5 step: 552, loss is 0.0002505118609406054\n",
      "epoch: 5 step: 553, loss is 0.025490814819931984\n",
      "epoch: 5 step: 554, loss is 0.0029026588890701532\n",
      "epoch: 5 step: 555, loss is 0.00018488720525056124\n",
      "epoch: 5 step: 556, loss is 0.026436880230903625\n",
      "epoch: 5 step: 557, loss is 0.0024870531633496284\n",
      "epoch: 5 step: 558, loss is 0.06121188402175903\n",
      "epoch: 5 step: 559, loss is 0.12960010766983032\n",
      "epoch: 5 step: 560, loss is 0.002741666976362467\n",
      "epoch: 5 step: 561, loss is 0.003162045730277896\n",
      "epoch: 5 step: 562, loss is 0.0022338679991662502\n",
      "epoch: 5 step: 563, loss is 0.00016183714615181088\n",
      "epoch: 5 step: 564, loss is 8.926985901780427e-05\n",
      "epoch: 5 step: 565, loss is 0.0005633910186588764\n",
      "epoch: 5 step: 566, loss is 0.0005045644356869161\n",
      "epoch: 5 step: 567, loss is 0.01724419556558132\n",
      "epoch: 5 step: 568, loss is 0.2460310310125351\n",
      "epoch: 5 step: 569, loss is 0.0018693277379497886\n",
      "epoch: 5 step: 570, loss is 0.011604060418903828\n",
      "epoch: 5 step: 571, loss is 0.020668255165219307\n",
      "epoch: 5 step: 572, loss is 0.0005287040257826447\n",
      "epoch: 5 step: 573, loss is 0.00230233883485198\n",
      "epoch: 5 step: 574, loss is 0.0005427697906270623\n",
      "epoch: 5 step: 575, loss is 0.0003423262678552419\n",
      "epoch: 5 step: 576, loss is 0.0067083039321005344\n",
      "epoch: 5 step: 577, loss is 0.03281868249177933\n",
      "epoch: 5 step: 578, loss is 0.0011425281409174204\n",
      "epoch: 5 step: 579, loss is 0.011053765192627907\n",
      "epoch: 5 step: 580, loss is 0.002273018006235361\n",
      "epoch: 5 step: 581, loss is 0.003174759913235903\n",
      "epoch: 5 step: 582, loss is 0.002042808337137103\n",
      "epoch: 5 step: 583, loss is 0.020801402628421783\n",
      "epoch: 5 step: 584, loss is 0.08762192726135254\n",
      "epoch: 5 step: 585, loss is 0.07353418320417404\n",
      "epoch: 5 step: 586, loss is 0.010579911060631275\n",
      "epoch: 5 step: 587, loss is 0.0023013101890683174\n",
      "epoch: 5 step: 588, loss is 0.000483121897559613\n",
      "epoch: 5 step: 589, loss is 0.055751170963048935\n",
      "epoch: 5 step: 590, loss is 0.0010489377891644835\n",
      "epoch: 5 step: 591, loss is 6.29774367553182e-05\n",
      "epoch: 5 step: 592, loss is 0.00034381094155833125\n",
      "epoch: 5 step: 593, loss is 0.009755047038197517\n",
      "epoch: 5 step: 594, loss is 0.000767555262427777\n",
      "epoch: 5 step: 595, loss is 0.030691232532262802\n",
      "epoch: 5 step: 596, loss is 0.19708497822284698\n",
      "epoch: 5 step: 597, loss is 0.0024214338045567274\n",
      "epoch: 5 step: 598, loss is 0.0008467398001812398\n",
      "epoch: 5 step: 599, loss is 0.0029208636842668056\n",
      "epoch: 5 step: 600, loss is 0.013851162046194077\n",
      "epoch: 5 step: 601, loss is 0.0009094314882531762\n",
      "epoch: 5 step: 602, loss is 0.0018629060359671712\n",
      "epoch: 5 step: 603, loss is 0.038321103900671005\n",
      "epoch: 5 step: 604, loss is 0.003945667762309313\n",
      "epoch: 5 step: 605, loss is 0.09026546031236649\n",
      "epoch: 5 step: 606, loss is 0.00023084337590262294\n",
      "epoch: 5 step: 607, loss is 0.001394295715726912\n",
      "epoch: 5 step: 608, loss is 3.8629426853731275e-05\n",
      "epoch: 5 step: 609, loss is 0.0036994724068790674\n",
      "epoch: 5 step: 610, loss is 0.0015358587261289358\n",
      "epoch: 5 step: 611, loss is 0.014884473755955696\n",
      "epoch: 5 step: 612, loss is 0.08366402238607407\n",
      "epoch: 5 step: 613, loss is 0.0026086890138685703\n",
      "epoch: 5 step: 614, loss is 0.07446729391813278\n",
      "epoch: 5 step: 615, loss is 0.0015659235650673509\n",
      "epoch: 5 step: 616, loss is 0.04060477390885353\n",
      "epoch: 5 step: 617, loss is 0.002728389110416174\n",
      "epoch: 5 step: 618, loss is 0.008712160401046276\n",
      "epoch: 5 step: 619, loss is 0.0023345602676272392\n",
      "epoch: 5 step: 620, loss is 0.0005945368902757764\n",
      "epoch: 5 step: 621, loss is 0.01905004493892193\n",
      "epoch: 5 step: 622, loss is 0.0019227482844144106\n",
      "epoch: 5 step: 623, loss is 0.015418630093336105\n",
      "epoch: 5 step: 624, loss is 0.2175282984972\n",
      "epoch: 5 step: 625, loss is 0.0033111756201833487\n",
      "epoch: 5 step: 626, loss is 0.00043519807513803244\n",
      "epoch: 5 step: 627, loss is 0.0876183956861496\n",
      "epoch: 5 step: 628, loss is 0.041522588580846786\n",
      "epoch: 5 step: 629, loss is 0.0027217562310397625\n",
      "epoch: 5 step: 630, loss is 0.0007660234696231782\n",
      "epoch: 5 step: 631, loss is 0.005236469674855471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 632, loss is 0.16039280593395233\n",
      "epoch: 5 step: 633, loss is 0.03595590218901634\n",
      "epoch: 5 step: 634, loss is 0.01165690366178751\n",
      "epoch: 5 step: 635, loss is 0.0036629445385187864\n",
      "epoch: 5 step: 636, loss is 0.001332308747805655\n",
      "epoch: 5 step: 637, loss is 0.0047582779079675674\n",
      "epoch: 5 step: 638, loss is 0.03834868595004082\n",
      "epoch: 5 step: 639, loss is 0.03589474782347679\n",
      "epoch: 5 step: 640, loss is 0.0005702367634512484\n",
      "epoch: 5 step: 641, loss is 0.004063349682837725\n",
      "epoch: 5 step: 642, loss is 0.0005679975729435682\n",
      "epoch: 5 step: 643, loss is 0.024184536188840866\n",
      "epoch: 5 step: 644, loss is 0.0325198732316494\n",
      "epoch: 5 step: 645, loss is 0.003982539754360914\n",
      "epoch: 5 step: 646, loss is 0.0010895951418206096\n",
      "epoch: 5 step: 647, loss is 0.00017672906687948853\n",
      "epoch: 5 step: 648, loss is 0.001398110412992537\n",
      "epoch: 5 step: 649, loss is 0.035858992487192154\n",
      "epoch: 5 step: 650, loss is 0.010470351204276085\n",
      "epoch: 5 step: 651, loss is 0.003596968948841095\n",
      "epoch: 5 step: 652, loss is 0.004038604907691479\n",
      "epoch: 5 step: 653, loss is 0.0150695675984025\n",
      "epoch: 5 step: 654, loss is 0.12828198075294495\n",
      "epoch: 5 step: 655, loss is 0.039414044469594955\n",
      "epoch: 5 step: 656, loss is 0.0012134845601394773\n",
      "epoch: 5 step: 657, loss is 0.004395483527332544\n",
      "epoch: 5 step: 658, loss is 0.0411321185529232\n",
      "epoch: 5 step: 659, loss is 0.05945949628949165\n",
      "epoch: 5 step: 660, loss is 0.0002280297048855573\n",
      "epoch: 5 step: 661, loss is 0.0003385195741429925\n",
      "epoch: 5 step: 662, loss is 0.0026545964647084475\n",
      "epoch: 5 step: 663, loss is 0.012366192415356636\n",
      "epoch: 5 step: 664, loss is 0.004582792986184359\n",
      "epoch: 5 step: 665, loss is 0.05000711977481842\n",
      "epoch: 5 step: 666, loss is 0.0020402362570166588\n",
      "epoch: 5 step: 667, loss is 0.0015555726131424308\n",
      "epoch: 5 step: 668, loss is 0.0005638800794258714\n",
      "epoch: 5 step: 669, loss is 0.09483572840690613\n",
      "epoch: 5 step: 670, loss is 0.0013206569710746408\n",
      "epoch: 5 step: 671, loss is 0.02688935399055481\n",
      "epoch: 5 step: 672, loss is 0.0006118505843915045\n",
      "epoch: 5 step: 673, loss is 0.04293709993362427\n",
      "epoch: 5 step: 674, loss is 0.011019262485206127\n",
      "epoch: 5 step: 675, loss is 0.0004305041511543095\n",
      "epoch: 5 step: 676, loss is 0.0007848237291909754\n",
      "epoch: 5 step: 677, loss is 0.06760703772306442\n",
      "epoch: 5 step: 678, loss is 0.009539369493722916\n",
      "epoch: 5 step: 679, loss is 0.004329390823841095\n",
      "epoch: 5 step: 680, loss is 0.004382767248898745\n",
      "epoch: 5 step: 681, loss is 0.001314547029323876\n",
      "epoch: 5 step: 682, loss is 0.00022527763212565333\n",
      "epoch: 5 step: 683, loss is 0.12488054484128952\n",
      "epoch: 5 step: 684, loss is 0.029039185494184494\n",
      "epoch: 5 step: 685, loss is 0.0009539471357129514\n",
      "epoch: 5 step: 686, loss is 0.0024907749611884356\n",
      "epoch: 5 step: 687, loss is 0.24869263172149658\n",
      "epoch: 5 step: 688, loss is 0.0006132762646302581\n",
      "epoch: 5 step: 689, loss is 0.001610859646461904\n",
      "epoch: 5 step: 690, loss is 0.011546997353434563\n",
      "epoch: 5 step: 691, loss is 0.0023640471044927835\n",
      "epoch: 5 step: 692, loss is 0.012954634614288807\n",
      "epoch: 5 step: 693, loss is 0.024890460073947906\n",
      "epoch: 5 step: 694, loss is 0.0030094021931290627\n",
      "epoch: 5 step: 695, loss is 0.005140002816915512\n",
      "epoch: 5 step: 696, loss is 0.02614923007786274\n",
      "epoch: 5 step: 697, loss is 0.008385462686419487\n",
      "epoch: 5 step: 698, loss is 0.005300296004861593\n",
      "epoch: 5 step: 699, loss is 0.0025700752157717943\n",
      "epoch: 5 step: 700, loss is 0.14191840589046478\n",
      "epoch: 5 step: 701, loss is 0.04289921373128891\n",
      "epoch: 5 step: 702, loss is 0.16874068975448608\n",
      "epoch: 5 step: 703, loss is 0.0004665171727538109\n",
      "epoch: 5 step: 704, loss is 0.020457932725548744\n",
      "epoch: 5 step: 705, loss is 0.0011612930102273822\n",
      "epoch: 5 step: 706, loss is 4.556425119517371e-05\n",
      "epoch: 5 step: 707, loss is 0.06277729570865631\n",
      "epoch: 5 step: 708, loss is 0.0036340050864964724\n",
      "epoch: 5 step: 709, loss is 0.024509845301508904\n",
      "epoch: 5 step: 710, loss is 0.010777580551803112\n",
      "epoch: 5 step: 711, loss is 0.02691386267542839\n",
      "epoch: 5 step: 712, loss is 0.06353636831045151\n",
      "epoch: 5 step: 713, loss is 0.006358157377690077\n",
      "epoch: 5 step: 714, loss is 0.007742712739855051\n",
      "epoch: 5 step: 715, loss is 0.0004579130618367344\n",
      "epoch: 5 step: 716, loss is 0.002520353998988867\n",
      "epoch: 5 step: 717, loss is 0.001034788554534316\n",
      "epoch: 5 step: 718, loss is 0.07117460668087006\n",
      "epoch: 5 step: 719, loss is 0.0036427797749638557\n",
      "epoch: 5 step: 720, loss is 0.013508482836186886\n",
      "epoch: 5 step: 721, loss is 0.0013872422277927399\n",
      "epoch: 5 step: 722, loss is 0.004929935093969107\n",
      "epoch: 5 step: 723, loss is 0.036997999995946884\n",
      "epoch: 5 step: 724, loss is 0.0011400830699130893\n",
      "epoch: 5 step: 725, loss is 0.004644724540412426\n",
      "epoch: 5 step: 726, loss is 0.021494794636964798\n",
      "epoch: 5 step: 727, loss is 0.0001191765841213055\n",
      "epoch: 5 step: 728, loss is 0.007165169809013605\n",
      "epoch: 5 step: 729, loss is 0.03043913096189499\n",
      "epoch: 5 step: 730, loss is 0.00021938406280241907\n",
      "epoch: 5 step: 731, loss is 0.0007171856705099344\n",
      "epoch: 5 step: 732, loss is 0.004746577236801386\n",
      "epoch: 5 step: 733, loss is 0.007600093726068735\n",
      "epoch: 5 step: 734, loss is 0.07316858321428299\n",
      "epoch: 5 step: 735, loss is 0.00023027323186397552\n",
      "epoch: 5 step: 736, loss is 0.003108025062829256\n",
      "epoch: 5 step: 737, loss is 0.004154135473072529\n",
      "epoch: 5 step: 738, loss is 0.0034727747552096844\n",
      "epoch: 5 step: 739, loss is 0.0007989982259459794\n",
      "epoch: 5 step: 740, loss is 0.0009133071871474385\n",
      "epoch: 5 step: 741, loss is 0.034473247826099396\n",
      "epoch: 5 step: 742, loss is 0.0005350322462618351\n",
      "epoch: 5 step: 743, loss is 0.1144319549202919\n",
      "epoch: 5 step: 744, loss is 0.12274320423603058\n",
      "epoch: 5 step: 745, loss is 0.08402515947818756\n",
      "epoch: 5 step: 746, loss is 0.0015502426540479064\n",
      "epoch: 5 step: 747, loss is 0.06094597652554512\n",
      "epoch: 5 step: 748, loss is 0.03158990666270256\n",
      "epoch: 5 step: 749, loss is 0.0014584033051505685\n",
      "epoch: 5 step: 750, loss is 0.004696078598499298\n",
      "epoch: 5 step: 751, loss is 0.09538436681032181\n",
      "epoch: 5 step: 752, loss is 0.012426486238837242\n",
      "epoch: 5 step: 753, loss is 0.00234854849986732\n",
      "epoch: 5 step: 754, loss is 0.0006823354051448405\n",
      "epoch: 5 step: 755, loss is 0.01046869345009327\n",
      "epoch: 5 step: 756, loss is 0.001171290990896523\n",
      "epoch: 5 step: 757, loss is 0.01064530573785305\n",
      "epoch: 5 step: 758, loss is 0.005444996990263462\n",
      "epoch: 5 step: 759, loss is 0.0020814663730561733\n",
      "epoch: 5 step: 760, loss is 0.005323719698935747\n",
      "epoch: 5 step: 761, loss is 0.003948525059968233\n",
      "epoch: 5 step: 762, loss is 0.00013709095946978778\n",
      "epoch: 5 step: 763, loss is 0.016260093078017235\n",
      "epoch: 5 step: 764, loss is 0.04136817157268524\n",
      "epoch: 5 step: 765, loss is 0.00523048872128129\n",
      "epoch: 5 step: 766, loss is 0.009442313574254513\n",
      "epoch: 5 step: 767, loss is 0.008142299018800259\n",
      "epoch: 5 step: 768, loss is 0.02893216721713543\n",
      "epoch: 5 step: 769, loss is 0.04991798847913742\n",
      "epoch: 5 step: 770, loss is 0.09754862636327744\n",
      "epoch: 5 step: 771, loss is 0.005534408148378134\n",
      "epoch: 5 step: 772, loss is 0.12620839476585388\n",
      "epoch: 5 step: 773, loss is 0.0009284591069445014\n",
      "epoch: 5 step: 774, loss is 0.0003427281917538494\n",
      "epoch: 5 step: 775, loss is 0.0003330397594254464\n",
      "epoch: 5 step: 776, loss is 0.022873802110552788\n",
      "epoch: 5 step: 777, loss is 0.00047671206993982196\n",
      "epoch: 5 step: 778, loss is 0.0030858158133924007\n",
      "epoch: 5 step: 779, loss is 0.022726530209183693\n",
      "epoch: 5 step: 780, loss is 0.012836746871471405\n",
      "epoch: 5 step: 781, loss is 0.014057788997888565\n",
      "epoch: 5 step: 782, loss is 0.007589329965412617\n",
      "epoch: 5 step: 783, loss is 0.0013598890509456396\n",
      "epoch: 5 step: 784, loss is 0.0033900064881891012\n",
      "epoch: 5 step: 785, loss is 0.015344272367656231\n",
      "epoch: 5 step: 786, loss is 0.008860744535923004\n",
      "epoch: 5 step: 787, loss is 0.002176710171625018\n",
      "epoch: 5 step: 788, loss is 0.010664521716535091\n",
      "epoch: 5 step: 789, loss is 0.03735581040382385\n",
      "epoch: 5 step: 790, loss is 0.0009076137794181705\n",
      "epoch: 5 step: 791, loss is 0.02143942564725876\n",
      "epoch: 5 step: 792, loss is 0.0009367975872009993\n",
      "epoch: 5 step: 793, loss is 0.011467747390270233\n",
      "epoch: 5 step: 794, loss is 0.09655111283063889\n",
      "epoch: 5 step: 795, loss is 0.007877840660512447\n",
      "epoch: 5 step: 796, loss is 0.031344812363386154\n",
      "epoch: 5 step: 797, loss is 0.015357650816440582\n",
      "epoch: 5 step: 798, loss is 0.11290684342384338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 799, loss is 0.022149140015244484\n",
      "epoch: 5 step: 800, loss is 0.03237271308898926\n",
      "epoch: 5 step: 801, loss is 0.03485342860221863\n",
      "epoch: 5 step: 802, loss is 0.0030659916810691357\n",
      "epoch: 5 step: 803, loss is 0.008773764595389366\n",
      "epoch: 5 step: 804, loss is 0.009315287694334984\n",
      "epoch: 5 step: 805, loss is 0.010834229178726673\n",
      "epoch: 5 step: 806, loss is 0.0021073424722999334\n",
      "epoch: 5 step: 807, loss is 0.011282804422080517\n",
      "epoch: 5 step: 808, loss is 0.08533588796854019\n",
      "epoch: 5 step: 809, loss is 0.09151814877986908\n",
      "epoch: 5 step: 810, loss is 0.009837665595114231\n",
      "epoch: 5 step: 811, loss is 0.003385453252121806\n",
      "epoch: 5 step: 812, loss is 0.03498955816030502\n",
      "epoch: 5 step: 813, loss is 0.042895037680864334\n",
      "epoch: 5 step: 814, loss is 0.0018997001461684704\n",
      "epoch: 5 step: 815, loss is 0.00035973472404293716\n",
      "epoch: 5 step: 816, loss is 0.0037405749317258596\n",
      "epoch: 5 step: 817, loss is 0.1158047541975975\n",
      "epoch: 5 step: 818, loss is 0.07899267971515656\n",
      "epoch: 5 step: 819, loss is 0.004761829972267151\n",
      "epoch: 5 step: 820, loss is 0.0002839870285242796\n",
      "epoch: 5 step: 821, loss is 0.016533495858311653\n",
      "epoch: 5 step: 822, loss is 0.003817512420937419\n",
      "epoch: 5 step: 823, loss is 0.07787026464939117\n",
      "epoch: 5 step: 824, loss is 0.046426933258771896\n",
      "epoch: 5 step: 825, loss is 0.009371823631227016\n",
      "epoch: 5 step: 826, loss is 0.02054106444120407\n",
      "epoch: 5 step: 827, loss is 0.002345654182136059\n",
      "epoch: 5 step: 828, loss is 0.006429035682231188\n",
      "epoch: 5 step: 829, loss is 0.009840304031968117\n",
      "epoch: 5 step: 830, loss is 0.0027096315752714872\n",
      "epoch: 5 step: 831, loss is 0.00026185507886111736\n",
      "epoch: 5 step: 832, loss is 0.00042325371759943664\n",
      "epoch: 5 step: 833, loss is 0.00454584788531065\n",
      "epoch: 5 step: 834, loss is 0.00014630079385824502\n",
      "epoch: 5 step: 835, loss is 0.001880610128864646\n",
      "epoch: 5 step: 836, loss is 0.0030740348156541586\n",
      "epoch: 5 step: 837, loss is 0.0023220223374664783\n",
      "epoch: 5 step: 838, loss is 0.004741146694868803\n",
      "epoch: 5 step: 839, loss is 0.15666241943836212\n",
      "epoch: 5 step: 840, loss is 0.009104485623538494\n",
      "epoch: 5 step: 841, loss is 0.007327040657401085\n",
      "epoch: 5 step: 842, loss is 0.010353063233196735\n",
      "epoch: 5 step: 843, loss is 0.026976916939020157\n",
      "epoch: 5 step: 844, loss is 0.0016986370319500566\n",
      "epoch: 5 step: 845, loss is 0.016829119995236397\n",
      "epoch: 5 step: 846, loss is 0.0014118388062343001\n",
      "epoch: 5 step: 847, loss is 0.007607081905007362\n",
      "epoch: 5 step: 848, loss is 0.022360166534781456\n",
      "epoch: 5 step: 849, loss is 0.0009884428000077605\n",
      "epoch: 5 step: 850, loss is 0.00010032601130660623\n",
      "epoch: 5 step: 851, loss is 0.0014779678313061595\n",
      "epoch: 5 step: 852, loss is 0.006377805955708027\n",
      "epoch: 5 step: 853, loss is 0.0018123409245163202\n",
      "epoch: 5 step: 854, loss is 0.000609325070399791\n",
      "epoch: 5 step: 855, loss is 0.000644593732431531\n",
      "epoch: 5 step: 856, loss is 0.0007482473156414926\n",
      "epoch: 5 step: 857, loss is 0.0040320600382983685\n",
      "epoch: 5 step: 858, loss is 0.005360870156437159\n",
      "epoch: 5 step: 859, loss is 0.05313849076628685\n",
      "epoch: 5 step: 860, loss is 0.003180930158123374\n",
      "epoch: 5 step: 861, loss is 0.0012023258022964\n",
      "epoch: 5 step: 862, loss is 0.08293163776397705\n",
      "epoch: 5 step: 863, loss is 0.0008323352667503059\n",
      "epoch: 5 step: 864, loss is 0.006177694071084261\n",
      "epoch: 5 step: 865, loss is 0.003513815812766552\n",
      "epoch: 5 step: 866, loss is 0.0009255710174329579\n",
      "epoch: 5 step: 867, loss is 0.06321245431900024\n",
      "epoch: 5 step: 868, loss is 0.06866692751646042\n",
      "epoch: 5 step: 869, loss is 0.002785565797239542\n",
      "epoch: 5 step: 870, loss is 0.26451197266578674\n",
      "epoch: 5 step: 871, loss is 0.06025117635726929\n",
      "epoch: 5 step: 872, loss is 0.0027359789237380028\n",
      "epoch: 5 step: 873, loss is 0.0681576356291771\n",
      "epoch: 5 step: 874, loss is 0.015522727742791176\n",
      "epoch: 5 step: 875, loss is 0.01519219484180212\n",
      "epoch: 5 step: 876, loss is 0.07692179083824158\n",
      "epoch: 5 step: 877, loss is 0.0005538816913031042\n",
      "epoch: 5 step: 878, loss is 0.0019417465664446354\n",
      "epoch: 5 step: 879, loss is 0.10426079481840134\n",
      "epoch: 5 step: 880, loss is 0.00018642932991497219\n",
      "epoch: 5 step: 881, loss is 0.006398641038686037\n",
      "epoch: 5 step: 882, loss is 0.0004338746366556734\n",
      "epoch: 5 step: 883, loss is 0.029678652063012123\n",
      "epoch: 5 step: 884, loss is 0.01283088605850935\n",
      "epoch: 5 step: 885, loss is 0.005410935264080763\n",
      "epoch: 5 step: 886, loss is 0.002107827691361308\n",
      "epoch: 5 step: 887, loss is 0.0006968408124521375\n",
      "epoch: 5 step: 888, loss is 0.0010619303211569786\n",
      "epoch: 5 step: 889, loss is 0.015307387337088585\n",
      "epoch: 5 step: 890, loss is 0.0014481564285233617\n",
      "epoch: 5 step: 891, loss is 0.001011412125080824\n",
      "epoch: 5 step: 892, loss is 0.030287714675068855\n",
      "epoch: 5 step: 893, loss is 0.020660290494561195\n",
      "epoch: 5 step: 894, loss is 0.17448361217975616\n",
      "epoch: 5 step: 895, loss is 0.0006623066146858037\n",
      "epoch: 5 step: 896, loss is 0.0009326816652901471\n",
      "epoch: 5 step: 897, loss is 0.0013358950382098556\n",
      "epoch: 5 step: 898, loss is 0.05291513353586197\n",
      "epoch: 5 step: 899, loss is 0.07515294849872589\n",
      "epoch: 5 step: 900, loss is 0.11411882191896439\n",
      "epoch: 5 step: 901, loss is 0.026818430051207542\n",
      "epoch: 5 step: 902, loss is 0.0006140939076431096\n",
      "epoch: 5 step: 903, loss is 0.00028840595041401684\n",
      "epoch: 5 step: 904, loss is 0.00028955176821909845\n",
      "epoch: 5 step: 905, loss is 0.002478956012055278\n",
      "epoch: 5 step: 906, loss is 0.0001281105214729905\n",
      "epoch: 5 step: 907, loss is 0.07242900878190994\n",
      "epoch: 5 step: 908, loss is 0.0022057141177356243\n",
      "epoch: 5 step: 909, loss is 0.08873551338911057\n",
      "epoch: 5 step: 910, loss is 0.10007630288600922\n",
      "epoch: 5 step: 911, loss is 0.0018718024948611856\n",
      "epoch: 5 step: 912, loss is 0.00021781167015433311\n",
      "epoch: 5 step: 913, loss is 0.0029318910092115402\n",
      "epoch: 5 step: 914, loss is 0.002065505599603057\n",
      "epoch: 5 step: 915, loss is 0.0014233357505872846\n",
      "epoch: 5 step: 916, loss is 0.0008082322310656309\n",
      "epoch: 5 step: 917, loss is 0.013326290994882584\n",
      "epoch: 5 step: 918, loss is 0.019561536610126495\n",
      "epoch: 5 step: 919, loss is 0.019200388342142105\n",
      "epoch: 5 step: 920, loss is 0.001264289254322648\n",
      "epoch: 5 step: 921, loss is 0.002390173962339759\n",
      "epoch: 5 step: 922, loss is 0.3228757381439209\n",
      "epoch: 5 step: 923, loss is 0.00040718179661780596\n",
      "epoch: 5 step: 924, loss is 0.0011649341322481632\n",
      "epoch: 5 step: 925, loss is 0.005276121664792299\n",
      "epoch: 5 step: 926, loss is 0.125453382730484\n",
      "epoch: 5 step: 927, loss is 0.1928997039794922\n",
      "epoch: 5 step: 928, loss is 0.0027351216413080692\n",
      "epoch: 5 step: 929, loss is 9.089885134017095e-05\n",
      "epoch: 5 step: 930, loss is 0.0029044225811958313\n",
      "epoch: 5 step: 931, loss is 0.03034186363220215\n",
      "epoch: 5 step: 932, loss is 0.003575975075364113\n",
      "epoch: 5 step: 933, loss is 0.0037135332822799683\n",
      "epoch: 5 step: 934, loss is 0.004442507866770029\n",
      "epoch: 5 step: 935, loss is 0.0003864398750010878\n",
      "epoch: 5 step: 936, loss is 0.0002174276887672022\n",
      "epoch: 5 step: 937, loss is 0.0034198430366814137\n",
      "epoch: 5 step: 938, loss is 0.006016585510224104\n",
      "epoch: 5 step: 939, loss is 0.005582455080002546\n",
      "epoch: 5 step: 940, loss is 0.01871129497885704\n",
      "epoch: 5 step: 941, loss is 0.0005819222424179316\n",
      "epoch: 5 step: 942, loss is 0.04707987606525421\n",
      "epoch: 5 step: 943, loss is 0.0027304908726364374\n",
      "epoch: 5 step: 944, loss is 0.08041437715291977\n",
      "epoch: 5 step: 945, loss is 0.0796617642045021\n",
      "epoch: 5 step: 946, loss is 0.0820179358124733\n",
      "epoch: 5 step: 947, loss is 0.09356283396482468\n",
      "epoch: 5 step: 948, loss is 1.752837488311343e-05\n",
      "epoch: 5 step: 949, loss is 0.04536397382616997\n",
      "epoch: 5 step: 950, loss is 0.015083846636116505\n",
      "epoch: 5 step: 951, loss is 0.04592224955558777\n",
      "epoch: 5 step: 952, loss is 0.0015356475487351418\n",
      "epoch: 5 step: 953, loss is 0.0016859145835042\n",
      "epoch: 5 step: 954, loss is 0.004810241516679525\n",
      "epoch: 5 step: 955, loss is 0.002842814428731799\n",
      "epoch: 5 step: 956, loss is 0.0021880129352211952\n",
      "epoch: 5 step: 957, loss is 0.0010256117675453424\n",
      "epoch: 5 step: 958, loss is 0.003869562176987529\n",
      "epoch: 5 step: 959, loss is 0.0027641323395073414\n",
      "epoch: 5 step: 960, loss is 0.09547371417284012\n",
      "epoch: 5 step: 961, loss is 0.01958465203642845\n",
      "epoch: 5 step: 962, loss is 0.014349156990647316\n",
      "epoch: 5 step: 963, loss is 0.011193796060979366\n",
      "epoch: 5 step: 964, loss is 0.012314897030591965\n",
      "epoch: 5 step: 965, loss is 0.025937579572200775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 966, loss is 0.00028011854737997055\n",
      "epoch: 5 step: 967, loss is 0.010540145449340343\n",
      "epoch: 5 step: 968, loss is 0.010111525654792786\n",
      "epoch: 5 step: 969, loss is 0.001295869005843997\n",
      "epoch: 5 step: 970, loss is 0.001076631946489215\n",
      "epoch: 5 step: 971, loss is 0.0011609579669311643\n",
      "epoch: 5 step: 972, loss is 0.0002590948424767703\n",
      "epoch: 5 step: 973, loss is 0.008990844711661339\n",
      "epoch: 5 step: 974, loss is 0.00011077531962655485\n",
      "epoch: 5 step: 975, loss is 0.004545044619590044\n",
      "epoch: 5 step: 976, loss is 0.001301947282627225\n",
      "epoch: 5 step: 977, loss is 0.0006332652410492301\n",
      "epoch: 5 step: 978, loss is 8.939476538216695e-05\n",
      "epoch: 5 step: 979, loss is 0.007297531235963106\n",
      "epoch: 5 step: 980, loss is 0.006834104657173157\n",
      "epoch: 5 step: 981, loss is 0.0004770733357872814\n",
      "epoch: 5 step: 982, loss is 0.00015631596033927053\n",
      "epoch: 5 step: 983, loss is 0.0493740513920784\n",
      "epoch: 5 step: 984, loss is 0.047854553908109665\n",
      "epoch: 5 step: 985, loss is 0.07850825041532516\n",
      "epoch: 5 step: 986, loss is 0.0009038408170454204\n",
      "epoch: 5 step: 987, loss is 0.034346241503953934\n",
      "epoch: 5 step: 988, loss is 0.007037865463644266\n",
      "epoch: 5 step: 989, loss is 0.0013595203636214137\n",
      "epoch: 5 step: 990, loss is 0.002433180343359709\n",
      "epoch: 5 step: 991, loss is 0.41289764642715454\n",
      "epoch: 5 step: 992, loss is 0.0011021480895578861\n",
      "epoch: 5 step: 993, loss is 0.06007201969623566\n",
      "epoch: 5 step: 994, loss is 0.009181085973978043\n",
      "epoch: 5 step: 995, loss is 0.006258048117160797\n",
      "epoch: 5 step: 996, loss is 0.028991438448429108\n",
      "epoch: 5 step: 997, loss is 0.00021825787553098053\n",
      "epoch: 5 step: 998, loss is 0.0010107429698109627\n",
      "epoch: 5 step: 999, loss is 0.04277550429105759\n",
      "epoch: 5 step: 1000, loss is 0.0013046760577708483\n",
      "epoch: 5 step: 1001, loss is 0.008321077562868595\n",
      "epoch: 5 step: 1002, loss is 0.21737508475780487\n",
      "epoch: 5 step: 1003, loss is 0.1529863327741623\n",
      "epoch: 5 step: 1004, loss is 0.0003031743399333209\n",
      "epoch: 5 step: 1005, loss is 0.044768281280994415\n",
      "epoch: 5 step: 1006, loss is 0.02088887244462967\n",
      "epoch: 5 step: 1007, loss is 0.0004237556713633239\n",
      "epoch: 5 step: 1008, loss is 0.01584700308740139\n",
      "epoch: 5 step: 1009, loss is 0.018847549334168434\n",
      "epoch: 5 step: 1010, loss is 0.00506682088598609\n",
      "epoch: 5 step: 1011, loss is 0.0011216660495847464\n",
      "epoch: 5 step: 1012, loss is 0.047457076609134674\n",
      "epoch: 5 step: 1013, loss is 0.015845518559217453\n",
      "epoch: 5 step: 1014, loss is 0.0194354560226202\n",
      "epoch: 5 step: 1015, loss is 0.0006122555932961404\n",
      "epoch: 5 step: 1016, loss is 0.003618404967710376\n",
      "epoch: 5 step: 1017, loss is 0.0009445146424695849\n",
      "epoch: 5 step: 1018, loss is 0.03628953918814659\n",
      "epoch: 5 step: 1019, loss is 0.11829488724470139\n",
      "epoch: 5 step: 1020, loss is 0.0032819435000419617\n",
      "epoch: 5 step: 1021, loss is 0.10802865028381348\n",
      "epoch: 5 step: 1022, loss is 0.012298567220568657\n",
      "epoch: 5 step: 1023, loss is 0.00019436972797848284\n",
      "epoch: 5 step: 1024, loss is 0.0029790899716317654\n",
      "epoch: 5 step: 1025, loss is 0.0010627935407683253\n",
      "epoch: 5 step: 1026, loss is 0.0007000069017522037\n",
      "epoch: 5 step: 1027, loss is 0.02914034202694893\n",
      "epoch: 5 step: 1028, loss is 0.025514570996165276\n",
      "epoch: 5 step: 1029, loss is 0.002067059511318803\n",
      "epoch: 5 step: 1030, loss is 0.0016657834639772773\n",
      "epoch: 5 step: 1031, loss is 0.0013517301995307207\n",
      "epoch: 5 step: 1032, loss is 0.0026189961936324835\n",
      "epoch: 5 step: 1033, loss is 0.0016125808469951153\n",
      "epoch: 5 step: 1034, loss is 0.003174193436279893\n",
      "epoch: 5 step: 1035, loss is 0.003943116404116154\n",
      "epoch: 5 step: 1036, loss is 0.0011280665639787912\n",
      "epoch: 5 step: 1037, loss is 0.013830705545842648\n",
      "epoch: 5 step: 1038, loss is 0.010556470602750778\n",
      "epoch: 5 step: 1039, loss is 0.029823632910847664\n",
      "epoch: 5 step: 1040, loss is 0.0029291610699146986\n",
      "epoch: 5 step: 1041, loss is 0.0032823632936924696\n",
      "epoch: 5 step: 1042, loss is 0.01358131691813469\n",
      "epoch: 5 step: 1043, loss is 0.30706527829170227\n",
      "epoch: 5 step: 1044, loss is 0.05000732094049454\n",
      "epoch: 5 step: 1045, loss is 0.00229294179007411\n",
      "epoch: 5 step: 1046, loss is 0.06745874136686325\n",
      "epoch: 5 step: 1047, loss is 0.29087206721305847\n",
      "epoch: 5 step: 1048, loss is 0.0229496993124485\n",
      "epoch: 5 step: 1049, loss is 0.0017588352784514427\n",
      "epoch: 5 step: 1050, loss is 0.01827061176300049\n",
      "epoch: 5 step: 1051, loss is 0.04216693714261055\n",
      "epoch: 5 step: 1052, loss is 0.008620204403996468\n",
      "epoch: 5 step: 1053, loss is 0.0004941002698615193\n",
      "epoch: 5 step: 1054, loss is 0.0004968098946847022\n",
      "epoch: 5 step: 1055, loss is 0.005650768987834454\n",
      "epoch: 5 step: 1056, loss is 0.06259483098983765\n",
      "epoch: 5 step: 1057, loss is 0.0005772419390268624\n",
      "epoch: 5 step: 1058, loss is 0.05254460498690605\n",
      "epoch: 5 step: 1059, loss is 0.13568685948848724\n",
      "epoch: 5 step: 1060, loss is 0.002535805804654956\n",
      "epoch: 5 step: 1061, loss is 0.05369250848889351\n",
      "epoch: 5 step: 1062, loss is 0.0542229562997818\n",
      "epoch: 5 step: 1063, loss is 0.0008134833769872785\n",
      "epoch: 5 step: 1064, loss is 0.0003241707163397223\n",
      "epoch: 5 step: 1065, loss is 0.0022776674013584852\n",
      "epoch: 5 step: 1066, loss is 0.0013434573775157332\n",
      "epoch: 5 step: 1067, loss is 0.0036941110156476498\n",
      "epoch: 5 step: 1068, loss is 0.09240496158599854\n",
      "epoch: 5 step: 1069, loss is 0.026679042726755142\n",
      "epoch: 5 step: 1070, loss is 0.0034547518007457256\n",
      "epoch: 5 step: 1071, loss is 0.22653724253177643\n",
      "epoch: 5 step: 1072, loss is 0.004691231530159712\n",
      "epoch: 5 step: 1073, loss is 0.005440430715680122\n",
      "epoch: 5 step: 1074, loss is 0.003291275817900896\n",
      "epoch: 5 step: 1075, loss is 0.007609196938574314\n",
      "epoch: 5 step: 1076, loss is 0.033849190920591354\n",
      "epoch: 5 step: 1077, loss is 0.009553924202919006\n",
      "epoch: 5 step: 1078, loss is 0.016636379063129425\n",
      "epoch: 5 step: 1079, loss is 0.2182079553604126\n",
      "epoch: 5 step: 1080, loss is 0.0018688898999243975\n",
      "epoch: 5 step: 1081, loss is 0.0032769343815743923\n",
      "epoch: 5 step: 1082, loss is 0.0008280479232780635\n",
      "epoch: 5 step: 1083, loss is 0.047489725053310394\n",
      "epoch: 5 step: 1084, loss is 0.00027395106735639274\n",
      "epoch: 5 step: 1085, loss is 0.004850136116147041\n",
      "epoch: 5 step: 1086, loss is 0.0034910498652607203\n",
      "epoch: 5 step: 1087, loss is 0.0575043261051178\n",
      "epoch: 5 step: 1088, loss is 0.10707930475473404\n",
      "epoch: 5 step: 1089, loss is 0.003320185234770179\n",
      "epoch: 5 step: 1090, loss is 0.08551880717277527\n",
      "epoch: 5 step: 1091, loss is 0.10632164031267166\n",
      "epoch: 5 step: 1092, loss is 0.0003757286467589438\n",
      "epoch: 5 step: 1093, loss is 0.00018766371067613363\n",
      "epoch: 5 step: 1094, loss is 0.0010741770965978503\n",
      "epoch: 5 step: 1095, loss is 0.1298307627439499\n",
      "epoch: 5 step: 1096, loss is 0.07712604105472565\n",
      "epoch: 5 step: 1097, loss is 0.004877085331827402\n",
      "epoch: 5 step: 1098, loss is 0.0009678033529780805\n",
      "epoch: 5 step: 1099, loss is 0.04474247992038727\n",
      "epoch: 5 step: 1100, loss is 0.0036790864542126656\n",
      "epoch: 5 step: 1101, loss is 0.03275623917579651\n",
      "epoch: 5 step: 1102, loss is 0.01348155178129673\n",
      "epoch: 5 step: 1103, loss is 0.07496508210897446\n",
      "epoch: 5 step: 1104, loss is 0.014121150597929955\n",
      "epoch: 5 step: 1105, loss is 0.013566502369940281\n",
      "epoch: 5 step: 1106, loss is 0.008128179237246513\n",
      "epoch: 5 step: 1107, loss is 0.0020600103307515383\n",
      "epoch: 5 step: 1108, loss is 0.09728672355413437\n",
      "epoch: 5 step: 1109, loss is 0.0013380196178331971\n",
      "epoch: 5 step: 1110, loss is 0.009467482566833496\n",
      "epoch: 5 step: 1111, loss is 0.007909235544502735\n",
      "epoch: 5 step: 1112, loss is 0.007321321405470371\n",
      "epoch: 5 step: 1113, loss is 0.006224744487553835\n",
      "epoch: 5 step: 1114, loss is 0.10343749076128006\n",
      "epoch: 5 step: 1115, loss is 0.00022658737725578249\n",
      "epoch: 5 step: 1116, loss is 0.02722989022731781\n",
      "epoch: 5 step: 1117, loss is 0.008906465955078602\n",
      "epoch: 5 step: 1118, loss is 0.011412887834012508\n",
      "epoch: 5 step: 1119, loss is 0.0012814771616831422\n",
      "epoch: 5 step: 1120, loss is 0.06259351968765259\n",
      "epoch: 5 step: 1121, loss is 0.02356691099703312\n",
      "epoch: 5 step: 1122, loss is 0.00018719145737122744\n",
      "epoch: 5 step: 1123, loss is 0.021283399313688278\n",
      "epoch: 5 step: 1124, loss is 0.10088938474655151\n",
      "epoch: 5 step: 1125, loss is 0.004408964887261391\n",
      "epoch: 5 step: 1126, loss is 0.02802686020731926\n",
      "epoch: 5 step: 1127, loss is 0.003485593944787979\n",
      "epoch: 5 step: 1128, loss is 0.023405177518725395\n",
      "epoch: 5 step: 1129, loss is 0.03482867777347565\n",
      "epoch: 5 step: 1130, loss is 0.0044121816754341125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1131, loss is 0.3043038249015808\n",
      "epoch: 5 step: 1132, loss is 0.010461428202688694\n",
      "epoch: 5 step: 1133, loss is 0.0008671876275911927\n",
      "epoch: 5 step: 1134, loss is 0.009814509190618992\n",
      "epoch: 5 step: 1135, loss is 0.060856714844703674\n",
      "epoch: 5 step: 1136, loss is 0.003375266445800662\n",
      "epoch: 5 step: 1137, loss is 0.00045799562940374017\n",
      "epoch: 5 step: 1138, loss is 0.01907407119870186\n",
      "epoch: 5 step: 1139, loss is 0.1669834703207016\n",
      "epoch: 5 step: 1140, loss is 0.022304346784949303\n",
      "epoch: 5 step: 1141, loss is 0.0003465167828835547\n",
      "epoch: 5 step: 1142, loss is 0.0006524877971969545\n",
      "epoch: 5 step: 1143, loss is 0.0006694881594739854\n",
      "epoch: 5 step: 1144, loss is 0.000782885414082557\n",
      "epoch: 5 step: 1145, loss is 0.002090388908982277\n",
      "epoch: 5 step: 1146, loss is 0.0049490295350551605\n",
      "epoch: 5 step: 1147, loss is 0.018528994172811508\n",
      "epoch: 5 step: 1148, loss is 0.12622177600860596\n",
      "epoch: 5 step: 1149, loss is 0.0011879325611516833\n",
      "epoch: 5 step: 1150, loss is 0.18042272329330444\n",
      "epoch: 5 step: 1151, loss is 0.0022292144130915403\n",
      "epoch: 5 step: 1152, loss is 0.0037910216487944126\n",
      "epoch: 5 step: 1153, loss is 0.0007029037806205451\n",
      "epoch: 5 step: 1154, loss is 0.07373347878456116\n",
      "epoch: 5 step: 1155, loss is 0.001069470657967031\n",
      "epoch: 5 step: 1156, loss is 0.00024381096591241658\n",
      "epoch: 5 step: 1157, loss is 0.0028337612748146057\n",
      "epoch: 5 step: 1158, loss is 0.05506424233317375\n",
      "epoch: 5 step: 1159, loss is 0.006039760075509548\n",
      "epoch: 5 step: 1160, loss is 0.0002999246644321829\n",
      "epoch: 5 step: 1161, loss is 0.0006024310132488608\n",
      "epoch: 5 step: 1162, loss is 0.003191402880474925\n",
      "epoch: 5 step: 1163, loss is 0.12031003087759018\n",
      "epoch: 5 step: 1164, loss is 0.01259631384164095\n",
      "epoch: 5 step: 1165, loss is 0.0002470083418302238\n",
      "epoch: 5 step: 1166, loss is 0.007699974346905947\n",
      "epoch: 5 step: 1167, loss is 0.03857429325580597\n",
      "epoch: 5 step: 1168, loss is 0.026326006278395653\n",
      "epoch: 5 step: 1169, loss is 0.0397043451666832\n",
      "epoch: 5 step: 1170, loss is 0.025442717596888542\n",
      "epoch: 5 step: 1171, loss is 0.023064889013767242\n",
      "epoch: 5 step: 1172, loss is 0.0013141337549313903\n",
      "epoch: 5 step: 1173, loss is 0.0003018667339347303\n",
      "epoch: 5 step: 1174, loss is 0.06086529791355133\n",
      "epoch: 5 step: 1175, loss is 0.02271723747253418\n",
      "epoch: 5 step: 1176, loss is 0.0032509262673556805\n",
      "epoch: 5 step: 1177, loss is 0.0012428589398041368\n",
      "epoch: 5 step: 1178, loss is 0.07740512490272522\n",
      "epoch: 5 step: 1179, loss is 0.0025926160160452127\n",
      "epoch: 5 step: 1180, loss is 0.00159864139277488\n",
      "epoch: 5 step: 1181, loss is 0.018526384606957436\n",
      "epoch: 5 step: 1182, loss is 0.011855151504278183\n",
      "epoch: 5 step: 1183, loss is 0.0279035996645689\n",
      "epoch: 5 step: 1184, loss is 0.05247114598751068\n",
      "epoch: 5 step: 1185, loss is 0.026219459250569344\n",
      "epoch: 5 step: 1186, loss is 0.00018449145136401057\n",
      "epoch: 5 step: 1187, loss is 0.006791106890887022\n",
      "epoch: 5 step: 1188, loss is 0.0314728282392025\n",
      "epoch: 5 step: 1189, loss is 0.0024568899534642696\n",
      "epoch: 5 step: 1190, loss is 0.02196338213980198\n",
      "epoch: 5 step: 1191, loss is 0.09422888606786728\n",
      "epoch: 5 step: 1192, loss is 0.011565239168703556\n",
      "epoch: 5 step: 1193, loss is 0.0025606683921068907\n",
      "epoch: 5 step: 1194, loss is 0.0020299479365348816\n",
      "epoch: 5 step: 1195, loss is 0.001727598486468196\n",
      "epoch: 5 step: 1196, loss is 0.010324249044060707\n",
      "epoch: 5 step: 1197, loss is 0.08614218235015869\n",
      "epoch: 5 step: 1198, loss is 8.309016266139224e-05\n",
      "epoch: 5 step: 1199, loss is 0.09733849763870239\n",
      "epoch: 5 step: 1200, loss is 0.011558916419744492\n",
      "epoch: 5 step: 1201, loss is 0.004357509780675173\n",
      "epoch: 5 step: 1202, loss is 0.002104841871187091\n",
      "epoch: 5 step: 1203, loss is 0.007984176278114319\n",
      "epoch: 5 step: 1204, loss is 0.002091033849865198\n",
      "epoch: 5 step: 1205, loss is 0.003789867740124464\n",
      "epoch: 5 step: 1206, loss is 0.0755869448184967\n",
      "epoch: 5 step: 1207, loss is 0.003765188157558441\n",
      "epoch: 5 step: 1208, loss is 0.004119951277971268\n",
      "epoch: 5 step: 1209, loss is 0.018532635644078255\n",
      "epoch: 5 step: 1210, loss is 0.027111459523439407\n",
      "epoch: 5 step: 1211, loss is 0.17121581733226776\n",
      "epoch: 5 step: 1212, loss is 0.014511112123727798\n",
      "epoch: 5 step: 1213, loss is 0.005042949225753546\n",
      "epoch: 5 step: 1214, loss is 0.16002967953681946\n",
      "epoch: 5 step: 1215, loss is 0.032936275005340576\n",
      "epoch: 5 step: 1216, loss is 0.0005035571521148086\n",
      "epoch: 5 step: 1217, loss is 0.10480927675962448\n",
      "epoch: 5 step: 1218, loss is 0.014385205693542957\n",
      "epoch: 5 step: 1219, loss is 0.0756923109292984\n",
      "epoch: 5 step: 1220, loss is 0.0014498160453513265\n",
      "epoch: 5 step: 1221, loss is 0.00162281293887645\n",
      "epoch: 5 step: 1222, loss is 0.04152464121580124\n",
      "epoch: 5 step: 1223, loss is 0.0907619372010231\n",
      "epoch: 5 step: 1224, loss is 0.000837679544929415\n",
      "epoch: 5 step: 1225, loss is 0.0016896314918994904\n",
      "epoch: 5 step: 1226, loss is 0.2894331216812134\n",
      "epoch: 5 step: 1227, loss is 0.028544142842292786\n",
      "epoch: 5 step: 1228, loss is 0.0008874624036252499\n",
      "epoch: 5 step: 1229, loss is 0.01814303733408451\n",
      "epoch: 5 step: 1230, loss is 0.0016738499980419874\n",
      "epoch: 5 step: 1231, loss is 0.09445659816265106\n",
      "epoch: 5 step: 1232, loss is 0.03281322866678238\n",
      "epoch: 5 step: 1233, loss is 0.006222937256097794\n",
      "epoch: 5 step: 1234, loss is 0.009925737977027893\n",
      "epoch: 5 step: 1235, loss is 0.01960965432226658\n",
      "epoch: 5 step: 1236, loss is 0.002044891705736518\n",
      "epoch: 5 step: 1237, loss is 0.0009607503889128566\n",
      "epoch: 5 step: 1238, loss is 0.01487426646053791\n",
      "epoch: 5 step: 1239, loss is 0.0018402044661343098\n",
      "epoch: 5 step: 1240, loss is 0.01303137931972742\n",
      "epoch: 5 step: 1241, loss is 0.0020708772353827953\n",
      "epoch: 5 step: 1242, loss is 0.001447901246137917\n",
      "epoch: 5 step: 1243, loss is 0.002783456351608038\n",
      "epoch: 5 step: 1244, loss is 0.032090552151203156\n",
      "epoch: 5 step: 1245, loss is 0.0009868255583569407\n",
      "epoch: 5 step: 1246, loss is 0.0035367109812796116\n",
      "epoch: 5 step: 1247, loss is 0.0013403326738625765\n",
      "epoch: 5 step: 1248, loss is 0.012599623762071133\n",
      "epoch: 5 step: 1249, loss is 0.007845343090593815\n",
      "epoch: 5 step: 1250, loss is 0.013156087137758732\n",
      "epoch: 5 step: 1251, loss is 0.0016495188465341926\n",
      "epoch: 5 step: 1252, loss is 0.08215676248073578\n",
      "epoch: 5 step: 1253, loss is 0.048331256955862045\n",
      "epoch: 5 step: 1254, loss is 0.0012027790071442723\n",
      "epoch: 5 step: 1255, loss is 0.0029695050325244665\n",
      "epoch: 5 step: 1256, loss is 0.010789837688207626\n",
      "epoch: 5 step: 1257, loss is 0.006914942059665918\n",
      "epoch: 5 step: 1258, loss is 0.04220312833786011\n",
      "epoch: 5 step: 1259, loss is 0.07588086277246475\n",
      "epoch: 5 step: 1260, loss is 0.03603473678231239\n",
      "epoch: 5 step: 1261, loss is 0.008682950399816036\n",
      "epoch: 5 step: 1262, loss is 0.0018793739145621657\n",
      "epoch: 5 step: 1263, loss is 0.0002341466606594622\n",
      "epoch: 5 step: 1264, loss is 0.018273381516337395\n",
      "epoch: 5 step: 1265, loss is 0.009539433754980564\n",
      "epoch: 5 step: 1266, loss is 0.0009554247371852398\n",
      "epoch: 5 step: 1267, loss is 0.005768742877990007\n",
      "epoch: 5 step: 1268, loss is 0.0018744842382147908\n",
      "epoch: 5 step: 1269, loss is 0.030980834737420082\n",
      "epoch: 5 step: 1270, loss is 0.00026806246023625135\n",
      "epoch: 5 step: 1271, loss is 0.001065054559148848\n",
      "epoch: 5 step: 1272, loss is 0.00023480490199290216\n",
      "epoch: 5 step: 1273, loss is 0.025930384173989296\n",
      "epoch: 5 step: 1274, loss is 0.011718213558197021\n",
      "epoch: 5 step: 1275, loss is 0.022438261657953262\n",
      "epoch: 5 step: 1276, loss is 0.016811255365610123\n",
      "epoch: 5 step: 1277, loss is 0.0003086309880018234\n",
      "epoch: 5 step: 1278, loss is 0.0028320339042693377\n",
      "epoch: 5 step: 1279, loss is 0.0038350278045982122\n",
      "epoch: 5 step: 1280, loss is 0.0024772114120423794\n",
      "epoch: 5 step: 1281, loss is 0.0018176266457885504\n",
      "epoch: 5 step: 1282, loss is 0.005104422569274902\n",
      "epoch: 5 step: 1283, loss is 0.0007827068911865354\n",
      "epoch: 5 step: 1284, loss is 0.0062818266451358795\n",
      "epoch: 5 step: 1285, loss is 0.0035089494194835424\n",
      "epoch: 5 step: 1286, loss is 0.09413569420576096\n",
      "epoch: 5 step: 1287, loss is 0.024639811366796494\n",
      "epoch: 5 step: 1288, loss is 0.001882862881757319\n",
      "epoch: 5 step: 1289, loss is 0.004374833777546883\n",
      "epoch: 5 step: 1290, loss is 0.02100425958633423\n",
      "epoch: 5 step: 1291, loss is 0.007821918465197086\n",
      "epoch: 5 step: 1292, loss is 0.006238178815692663\n",
      "epoch: 5 step: 1293, loss is 0.0008868231670930982\n",
      "epoch: 5 step: 1294, loss is 0.0003716377541422844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1295, loss is 0.17782185971736908\n",
      "epoch: 5 step: 1296, loss is 0.0009101345203816891\n",
      "epoch: 5 step: 1297, loss is 0.014567707665264606\n",
      "epoch: 5 step: 1298, loss is 0.1423357129096985\n",
      "epoch: 5 step: 1299, loss is 0.004428433254361153\n",
      "epoch: 5 step: 1300, loss is 0.007268777582794428\n",
      "epoch: 5 step: 1301, loss is 0.0015844627050682902\n",
      "epoch: 5 step: 1302, loss is 0.007519405335187912\n",
      "epoch: 5 step: 1303, loss is 0.0912262573838234\n",
      "epoch: 5 step: 1304, loss is 0.001809559646062553\n",
      "epoch: 5 step: 1305, loss is 0.1455124467611313\n",
      "epoch: 5 step: 1306, loss is 0.014993703924119473\n",
      "epoch: 5 step: 1307, loss is 0.0014087293529883027\n",
      "epoch: 5 step: 1308, loss is 0.01257992535829544\n",
      "epoch: 5 step: 1309, loss is 0.002121817087754607\n",
      "epoch: 5 step: 1310, loss is 0.14271022379398346\n",
      "epoch: 5 step: 1311, loss is 0.0002825928386300802\n",
      "epoch: 5 step: 1312, loss is 0.001583049655891955\n",
      "epoch: 5 step: 1313, loss is 0.0015480020083487034\n",
      "epoch: 5 step: 1314, loss is 0.0013151810271665454\n",
      "epoch: 5 step: 1315, loss is 0.12223875522613525\n",
      "epoch: 5 step: 1316, loss is 0.01984187215566635\n",
      "epoch: 5 step: 1317, loss is 0.005515698809176683\n",
      "epoch: 5 step: 1318, loss is 0.03407806158065796\n",
      "epoch: 5 step: 1319, loss is 0.003223241539672017\n",
      "epoch: 5 step: 1320, loss is 0.030303509905934334\n",
      "epoch: 5 step: 1321, loss is 0.0028765443712472916\n",
      "epoch: 5 step: 1322, loss is 0.025628890842199326\n",
      "epoch: 5 step: 1323, loss is 0.0014691534452140331\n",
      "epoch: 5 step: 1324, loss is 0.0027889704797416925\n",
      "epoch: 5 step: 1325, loss is 0.05203897878527641\n",
      "epoch: 5 step: 1326, loss is 0.01726640574634075\n",
      "epoch: 5 step: 1327, loss is 0.0055924272164702415\n",
      "epoch: 5 step: 1328, loss is 0.0928163230419159\n",
      "epoch: 5 step: 1329, loss is 0.16139058768749237\n",
      "epoch: 5 step: 1330, loss is 0.11772078275680542\n",
      "epoch: 5 step: 1331, loss is 0.001642538351006806\n",
      "epoch: 5 step: 1332, loss is 0.06089121848344803\n",
      "epoch: 5 step: 1333, loss is 0.03818097710609436\n",
      "epoch: 5 step: 1334, loss is 0.004883323330432177\n",
      "epoch: 5 step: 1335, loss is 0.058121830224990845\n",
      "epoch: 5 step: 1336, loss is 0.04297224059700966\n",
      "epoch: 5 step: 1337, loss is 0.0629444569349289\n",
      "epoch: 5 step: 1338, loss is 0.024792632088065147\n",
      "epoch: 5 step: 1339, loss is 0.06945541501045227\n",
      "epoch: 5 step: 1340, loss is 0.02502218820154667\n",
      "epoch: 5 step: 1341, loss is 0.00038260099245235324\n",
      "epoch: 5 step: 1342, loss is 0.003992707002907991\n",
      "epoch: 5 step: 1343, loss is 0.0015707440907135606\n",
      "epoch: 5 step: 1344, loss is 0.002180740237236023\n",
      "epoch: 5 step: 1345, loss is 0.006030157208442688\n",
      "epoch: 5 step: 1346, loss is 0.0006687360582873225\n",
      "epoch: 5 step: 1347, loss is 0.025250358507037163\n",
      "epoch: 5 step: 1348, loss is 0.009344669990241528\n",
      "epoch: 5 step: 1349, loss is 0.001402936759404838\n",
      "epoch: 5 step: 1350, loss is 0.03297783061861992\n",
      "epoch: 5 step: 1351, loss is 0.007047874387353659\n",
      "epoch: 5 step: 1352, loss is 0.04864543676376343\n",
      "epoch: 5 step: 1353, loss is 0.06039756163954735\n",
      "epoch: 5 step: 1354, loss is 0.0017818417400121689\n",
      "epoch: 5 step: 1355, loss is 0.0006651379517279565\n",
      "epoch: 5 step: 1356, loss is 0.006734036840498447\n",
      "epoch: 5 step: 1357, loss is 0.0007222346030175686\n",
      "epoch: 5 step: 1358, loss is 0.12100669741630554\n",
      "epoch: 5 step: 1359, loss is 0.0055226897820830345\n",
      "epoch: 5 step: 1360, loss is 0.009366360493004322\n",
      "epoch: 5 step: 1361, loss is 0.0066556441597640514\n",
      "epoch: 5 step: 1362, loss is 0.0010966164991259575\n",
      "epoch: 5 step: 1363, loss is 0.004365449771285057\n",
      "epoch: 5 step: 1364, loss is 0.001946170930750668\n",
      "epoch: 5 step: 1365, loss is 0.048047538846731186\n",
      "epoch: 5 step: 1366, loss is 0.08474467694759369\n",
      "epoch: 5 step: 1367, loss is 0.001448643859475851\n",
      "epoch: 5 step: 1368, loss is 0.03357832878828049\n",
      "epoch: 5 step: 1369, loss is 0.07264640182256699\n",
      "epoch: 5 step: 1370, loss is 0.21081982553005219\n",
      "epoch: 5 step: 1371, loss is 0.01577386073768139\n",
      "epoch: 5 step: 1372, loss is 0.009033598937094212\n",
      "epoch: 5 step: 1373, loss is 0.004044446628540754\n",
      "epoch: 5 step: 1374, loss is 0.0015392806380987167\n",
      "epoch: 5 step: 1375, loss is 0.05160561949014664\n",
      "epoch: 5 step: 1376, loss is 0.0003721021639648825\n",
      "epoch: 5 step: 1377, loss is 0.0012692800955846906\n",
      "epoch: 5 step: 1378, loss is 0.0013075456954538822\n",
      "epoch: 5 step: 1379, loss is 0.048038385808467865\n",
      "epoch: 5 step: 1380, loss is 0.0013701838906854391\n",
      "epoch: 5 step: 1381, loss is 0.0003316504298709333\n",
      "epoch: 5 step: 1382, loss is 0.0005126509931869805\n",
      "epoch: 5 step: 1383, loss is 0.0009677800117060542\n",
      "epoch: 5 step: 1384, loss is 0.052002716809511185\n",
      "epoch: 5 step: 1385, loss is 0.0005640363087877631\n",
      "epoch: 5 step: 1386, loss is 0.007275843992829323\n",
      "epoch: 5 step: 1387, loss is 0.002887156791985035\n",
      "epoch: 5 step: 1388, loss is 0.028047943487763405\n",
      "epoch: 5 step: 1389, loss is 0.17364071309566498\n",
      "epoch: 5 step: 1390, loss is 0.0013038930483162403\n",
      "epoch: 5 step: 1391, loss is 0.003609608393162489\n",
      "epoch: 5 step: 1392, loss is 0.02385842055082321\n",
      "epoch: 5 step: 1393, loss is 0.01778324320912361\n",
      "epoch: 5 step: 1394, loss is 0.06913264095783234\n",
      "epoch: 5 step: 1395, loss is 0.0004170627216808498\n",
      "epoch: 5 step: 1396, loss is 0.02523588202893734\n",
      "epoch: 5 step: 1397, loss is 0.04670078679919243\n",
      "epoch: 5 step: 1398, loss is 0.001156515907496214\n",
      "epoch: 5 step: 1399, loss is 0.01722932606935501\n",
      "epoch: 5 step: 1400, loss is 0.0024467657785862684\n",
      "epoch: 5 step: 1401, loss is 0.0001380784233333543\n",
      "epoch: 5 step: 1402, loss is 0.0011730013648048043\n",
      "epoch: 5 step: 1403, loss is 0.0007981384987942874\n",
      "epoch: 5 step: 1404, loss is 0.07804694026708603\n",
      "epoch: 5 step: 1405, loss is 0.008582115173339844\n",
      "epoch: 5 step: 1406, loss is 0.008954038843512535\n",
      "epoch: 5 step: 1407, loss is 0.0015117402654141188\n",
      "epoch: 5 step: 1408, loss is 0.02061058208346367\n",
      "epoch: 5 step: 1409, loss is 0.003746981965377927\n",
      "epoch: 5 step: 1410, loss is 0.006670978851616383\n",
      "epoch: 5 step: 1411, loss is 7.027115498203784e-05\n",
      "epoch: 5 step: 1412, loss is 0.049571529030799866\n",
      "epoch: 5 step: 1413, loss is 0.004487581551074982\n",
      "epoch: 5 step: 1414, loss is 0.008554881438612938\n",
      "epoch: 5 step: 1415, loss is 0.00029222184093669057\n",
      "epoch: 5 step: 1416, loss is 0.0033830490428954363\n",
      "epoch: 5 step: 1417, loss is 0.00042613493860699236\n",
      "epoch: 5 step: 1418, loss is 0.0013450351543724537\n",
      "epoch: 5 step: 1419, loss is 0.050135958939790726\n",
      "epoch: 5 step: 1420, loss is 0.12390676885843277\n",
      "epoch: 5 step: 1421, loss is 0.020798156037926674\n",
      "epoch: 5 step: 1422, loss is 0.00047325919149443507\n",
      "epoch: 5 step: 1423, loss is 0.010337524116039276\n",
      "epoch: 5 step: 1424, loss is 0.0005126711330376565\n",
      "epoch: 5 step: 1425, loss is 0.05359319597482681\n",
      "epoch: 5 step: 1426, loss is 0.029368333518505096\n",
      "epoch: 5 step: 1427, loss is 5.5869142670417204e-05\n",
      "epoch: 5 step: 1428, loss is 0.01986098103225231\n",
      "epoch: 5 step: 1429, loss is 0.00687452545389533\n",
      "epoch: 5 step: 1430, loss is 0.020798370242118835\n",
      "epoch: 5 step: 1431, loss is 0.005476388148963451\n",
      "epoch: 5 step: 1432, loss is 0.0016635190695524216\n",
      "epoch: 5 step: 1433, loss is 0.002817583968862891\n",
      "epoch: 5 step: 1434, loss is 0.00025856721913442016\n",
      "epoch: 5 step: 1435, loss is 0.017198771238327026\n",
      "epoch: 5 step: 1436, loss is 0.03167487308382988\n",
      "epoch: 5 step: 1437, loss is 0.0011022711405530572\n",
      "epoch: 5 step: 1438, loss is 0.054831042885780334\n",
      "epoch: 5 step: 1439, loss is 0.47169622778892517\n",
      "epoch: 5 step: 1440, loss is 0.10077057778835297\n",
      "epoch: 5 step: 1441, loss is 0.011796791106462479\n",
      "epoch: 5 step: 1442, loss is 0.0016866637161001563\n",
      "epoch: 5 step: 1443, loss is 0.0037605115212500095\n",
      "epoch: 5 step: 1444, loss is 0.0010098916245624423\n",
      "epoch: 5 step: 1445, loss is 0.00011296921729808673\n",
      "epoch: 5 step: 1446, loss is 0.006421281490474939\n",
      "epoch: 5 step: 1447, loss is 0.002132222056388855\n",
      "epoch: 5 step: 1448, loss is 0.0035724537447094917\n",
      "epoch: 5 step: 1449, loss is 0.002369100693613291\n",
      "epoch: 5 step: 1450, loss is 0.000900299521163106\n",
      "epoch: 5 step: 1451, loss is 0.009326854720711708\n",
      "epoch: 5 step: 1452, loss is 0.001759182894602418\n",
      "epoch: 5 step: 1453, loss is 0.0012938524596393108\n",
      "epoch: 5 step: 1454, loss is 0.0003009568608831614\n",
      "epoch: 5 step: 1455, loss is 0.014299381524324417\n",
      "epoch: 5 step: 1456, loss is 0.0025084984954446554\n",
      "epoch: 5 step: 1457, loss is 0.1629561483860016\n",
      "epoch: 5 step: 1458, loss is 0.00018272495071869344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1459, loss is 0.0003597321338020265\n",
      "epoch: 5 step: 1460, loss is 0.000503318733535707\n",
      "epoch: 5 step: 1461, loss is 0.018527748063206673\n",
      "epoch: 5 step: 1462, loss is 0.0017686511855572462\n",
      "epoch: 5 step: 1463, loss is 0.0015715686604380608\n",
      "epoch: 5 step: 1464, loss is 0.007002883590757847\n",
      "epoch: 5 step: 1465, loss is 0.002491627587005496\n",
      "epoch: 5 step: 1466, loss is 0.004138563293963671\n",
      "epoch: 5 step: 1467, loss is 0.0010866201482713223\n",
      "epoch: 5 step: 1468, loss is 0.010404440574347973\n",
      "epoch: 5 step: 1469, loss is 0.002260687993839383\n",
      "epoch: 5 step: 1470, loss is 0.009097271598875523\n",
      "epoch: 5 step: 1471, loss is 0.00764757115393877\n",
      "epoch: 5 step: 1472, loss is 0.050598375499248505\n",
      "epoch: 5 step: 1473, loss is 0.005589278880506754\n",
      "epoch: 5 step: 1474, loss is 0.005642914213240147\n",
      "epoch: 5 step: 1475, loss is 0.0004141156969126314\n",
      "epoch: 5 step: 1476, loss is 0.0069177476689219475\n",
      "epoch: 5 step: 1477, loss is 0.01301478873938322\n",
      "epoch: 5 step: 1478, loss is 0.00048447406152263284\n",
      "epoch: 5 step: 1479, loss is 0.009169490076601505\n",
      "epoch: 5 step: 1480, loss is 0.00198442698456347\n",
      "epoch: 5 step: 1481, loss is 0.013165311887860298\n",
      "epoch: 5 step: 1482, loss is 0.0170099139213562\n",
      "epoch: 5 step: 1483, loss is 0.0001719461433822289\n",
      "epoch: 5 step: 1484, loss is 0.01056425366550684\n",
      "epoch: 5 step: 1485, loss is 0.15461024641990662\n",
      "epoch: 5 step: 1486, loss is 0.0019775365944951773\n",
      "epoch: 5 step: 1487, loss is 0.03540399298071861\n",
      "epoch: 5 step: 1488, loss is 0.007772708777338266\n",
      "epoch: 5 step: 1489, loss is 0.0012147375382483006\n",
      "epoch: 5 step: 1490, loss is 0.009233160875737667\n",
      "epoch: 5 step: 1491, loss is 0.10536102950572968\n",
      "epoch: 5 step: 1492, loss is 0.002163248835131526\n",
      "epoch: 5 step: 1493, loss is 0.00961272232234478\n",
      "epoch: 5 step: 1494, loss is 0.010849284008145332\n",
      "epoch: 5 step: 1495, loss is 0.055326469242572784\n",
      "epoch: 5 step: 1496, loss is 0.008768952451646328\n",
      "epoch: 5 step: 1497, loss is 0.008015120401978493\n",
      "epoch: 5 step: 1498, loss is 0.05635330453515053\n",
      "epoch: 5 step: 1499, loss is 0.022368475794792175\n",
      "epoch: 5 step: 1500, loss is 0.00020823071827180684\n",
      "epoch: 5 step: 1501, loss is 0.3793887794017792\n",
      "epoch: 5 step: 1502, loss is 0.1147596538066864\n",
      "epoch: 5 step: 1503, loss is 0.048422183841466904\n",
      "epoch: 5 step: 1504, loss is 0.004725578241050243\n",
      "epoch: 5 step: 1505, loss is 0.005126583855599165\n",
      "epoch: 5 step: 1506, loss is 0.004744574427604675\n",
      "epoch: 5 step: 1507, loss is 0.0007525002583861351\n",
      "epoch: 5 step: 1508, loss is 0.04733350872993469\n",
      "epoch: 5 step: 1509, loss is 0.0807880312204361\n",
      "epoch: 5 step: 1510, loss is 0.3482436239719391\n",
      "epoch: 5 step: 1511, loss is 0.01760365627706051\n",
      "epoch: 5 step: 1512, loss is 0.012736759148538113\n",
      "epoch: 5 step: 1513, loss is 0.01625262014567852\n",
      "epoch: 5 step: 1514, loss is 0.007339897565543652\n",
      "epoch: 5 step: 1515, loss is 0.01813163235783577\n",
      "epoch: 5 step: 1516, loss is 0.022375168278813362\n",
      "epoch: 5 step: 1517, loss is 0.002201144816353917\n",
      "epoch: 5 step: 1518, loss is 0.09807776659727097\n",
      "epoch: 5 step: 1519, loss is 0.03862190619111061\n",
      "epoch: 5 step: 1520, loss is 0.007410313934087753\n",
      "epoch: 5 step: 1521, loss is 0.010678812861442566\n",
      "epoch: 5 step: 1522, loss is 0.001973300939425826\n",
      "epoch: 5 step: 1523, loss is 0.0015191049315035343\n",
      "epoch: 5 step: 1524, loss is 0.005785438232123852\n",
      "epoch: 5 step: 1525, loss is 0.11621443927288055\n",
      "epoch: 5 step: 1526, loss is 0.001762803178280592\n",
      "epoch: 5 step: 1527, loss is 0.000542447145562619\n",
      "epoch: 5 step: 1528, loss is 0.10278687626123428\n",
      "epoch: 5 step: 1529, loss is 0.0020347856916487217\n",
      "epoch: 5 step: 1530, loss is 0.008017197251319885\n",
      "epoch: 5 step: 1531, loss is 0.0017267117509618402\n",
      "epoch: 5 step: 1532, loss is 0.14306791126728058\n",
      "epoch: 5 step: 1533, loss is 0.003932524006813765\n",
      "epoch: 5 step: 1534, loss is 0.0002917925303336233\n",
      "epoch: 5 step: 1535, loss is 0.0036296595353633165\n",
      "epoch: 5 step: 1536, loss is 0.033970415592193604\n",
      "epoch: 5 step: 1537, loss is 0.12164995074272156\n",
      "epoch: 5 step: 1538, loss is 0.04569508135318756\n",
      "epoch: 5 step: 1539, loss is 0.006872950587421656\n",
      "epoch: 5 step: 1540, loss is 0.0014843095559626818\n",
      "epoch: 5 step: 1541, loss is 0.09674036502838135\n",
      "epoch: 5 step: 1542, loss is 0.00025427472428418696\n",
      "epoch: 5 step: 1543, loss is 0.0026104580610990524\n",
      "epoch: 5 step: 1544, loss is 0.005313183180987835\n",
      "epoch: 5 step: 1545, loss is 0.0010004985379055142\n",
      "epoch: 5 step: 1546, loss is 0.0010001291520893574\n",
      "epoch: 5 step: 1547, loss is 0.04351423680782318\n",
      "epoch: 5 step: 1548, loss is 0.0014004780678078532\n",
      "epoch: 5 step: 1549, loss is 0.0888846293091774\n",
      "epoch: 5 step: 1550, loss is 0.005210306495428085\n",
      "epoch: 5 step: 1551, loss is 0.0015107083600014448\n",
      "epoch: 5 step: 1552, loss is 0.004971204325556755\n",
      "epoch: 5 step: 1553, loss is 0.010707237757742405\n",
      "epoch: 5 step: 1554, loss is 0.005177867133170366\n",
      "epoch: 5 step: 1555, loss is 0.0013095531612634659\n",
      "epoch: 5 step: 1556, loss is 0.0005047983722761273\n",
      "epoch: 5 step: 1557, loss is 0.0019360230071470141\n",
      "epoch: 5 step: 1558, loss is 0.09822747856378555\n",
      "epoch: 5 step: 1559, loss is 0.004918874707072973\n",
      "epoch: 5 step: 1560, loss is 0.006745296996086836\n",
      "epoch: 5 step: 1561, loss is 0.07585851103067398\n",
      "epoch: 5 step: 1562, loss is 0.23246268928050995\n",
      "epoch: 5 step: 1563, loss is 0.06914399564266205\n",
      "epoch: 5 step: 1564, loss is 0.09715816378593445\n",
      "epoch: 5 step: 1565, loss is 0.013024451211094856\n",
      "epoch: 5 step: 1566, loss is 0.0010340665467083454\n",
      "epoch: 5 step: 1567, loss is 0.058602482080459595\n",
      "epoch: 5 step: 1568, loss is 0.0011361310025677085\n",
      "epoch: 5 step: 1569, loss is 0.009588601067662239\n",
      "epoch: 5 step: 1570, loss is 0.0006766305305063725\n",
      "epoch: 5 step: 1571, loss is 0.0055917054414749146\n",
      "epoch: 5 step: 1572, loss is 0.011347826570272446\n",
      "epoch: 5 step: 1573, loss is 0.03836251422762871\n",
      "epoch: 5 step: 1574, loss is 0.004844237118959427\n",
      "epoch: 5 step: 1575, loss is 0.03129534050822258\n",
      "epoch: 5 step: 1576, loss is 0.013293415307998657\n",
      "epoch: 5 step: 1577, loss is 0.01340038888156414\n",
      "epoch: 5 step: 1578, loss is 0.015926597639918327\n",
      "epoch: 5 step: 1579, loss is 0.0038632317446172237\n",
      "epoch: 5 step: 1580, loss is 0.006306907162070274\n",
      "epoch: 5 step: 1581, loss is 0.009392957203090191\n",
      "epoch: 5 step: 1582, loss is 0.005583222955465317\n",
      "epoch: 5 step: 1583, loss is 0.015176122076809406\n",
      "epoch: 5 step: 1584, loss is 0.11112271994352341\n",
      "epoch: 5 step: 1585, loss is 0.06206716597080231\n",
      "epoch: 5 step: 1586, loss is 0.046052660793066025\n",
      "epoch: 5 step: 1587, loss is 0.011929118074476719\n",
      "epoch: 5 step: 1588, loss is 0.04776142165064812\n",
      "epoch: 5 step: 1589, loss is 0.039318960160017014\n",
      "epoch: 5 step: 1590, loss is 0.005823074374347925\n",
      "epoch: 5 step: 1591, loss is 0.050447553396224976\n",
      "epoch: 5 step: 1592, loss is 0.0016792098758742213\n",
      "epoch: 5 step: 1593, loss is 0.022318057715892792\n",
      "epoch: 5 step: 1594, loss is 0.001197600970044732\n",
      "epoch: 5 step: 1595, loss is 0.04234131798148155\n",
      "epoch: 5 step: 1596, loss is 0.004366610199213028\n",
      "epoch: 5 step: 1597, loss is 0.012678009457886219\n",
      "epoch: 5 step: 1598, loss is 0.000788866775110364\n",
      "epoch: 5 step: 1599, loss is 0.0003824492741841823\n",
      "epoch: 5 step: 1600, loss is 0.0014377316692844033\n",
      "epoch: 5 step: 1601, loss is 0.00018060996080748737\n",
      "epoch: 5 step: 1602, loss is 0.004335584118962288\n",
      "epoch: 5 step: 1603, loss is 0.004242138005793095\n",
      "epoch: 5 step: 1604, loss is 0.026020823046565056\n",
      "epoch: 5 step: 1605, loss is 0.01953316107392311\n",
      "epoch: 5 step: 1606, loss is 0.01457213331013918\n",
      "epoch: 5 step: 1607, loss is 0.0005266243242658675\n",
      "epoch: 5 step: 1608, loss is 0.004702987615019083\n",
      "epoch: 5 step: 1609, loss is 0.0009062328026629984\n",
      "epoch: 5 step: 1610, loss is 0.07615268975496292\n",
      "epoch: 5 step: 1611, loss is 0.005196437705308199\n",
      "epoch: 5 step: 1612, loss is 0.0045816246420145035\n",
      "epoch: 5 step: 1613, loss is 0.009146766737103462\n",
      "epoch: 5 step: 1614, loss is 0.011267455294728279\n",
      "epoch: 5 step: 1615, loss is 0.004615736659616232\n",
      "epoch: 5 step: 1616, loss is 0.0028811837546527386\n",
      "epoch: 5 step: 1617, loss is 0.007468526251614094\n",
      "epoch: 5 step: 1618, loss is 0.01698235236108303\n",
      "epoch: 5 step: 1619, loss is 0.1129387840628624\n",
      "epoch: 5 step: 1620, loss is 0.006312198005616665\n",
      "epoch: 5 step: 1621, loss is 0.028119532391428947\n",
      "epoch: 5 step: 1622, loss is 0.011864017695188522\n",
      "epoch: 5 step: 1623, loss is 0.0008519543334841728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1624, loss is 0.001102850423194468\n",
      "epoch: 5 step: 1625, loss is 0.0014606480253860354\n",
      "epoch: 5 step: 1626, loss is 0.025001658126711845\n",
      "epoch: 5 step: 1627, loss is 0.0041527473367750645\n",
      "epoch: 5 step: 1628, loss is 0.007586844731122255\n",
      "epoch: 5 step: 1629, loss is 0.000243142043473199\n",
      "epoch: 5 step: 1630, loss is 0.20673136413097382\n",
      "epoch: 5 step: 1631, loss is 0.0303166713565588\n",
      "epoch: 5 step: 1632, loss is 0.026748953387141228\n",
      "epoch: 5 step: 1633, loss is 0.10790412127971649\n",
      "epoch: 5 step: 1634, loss is 0.003286293474957347\n",
      "epoch: 5 step: 1635, loss is 0.012573492713272572\n",
      "epoch: 5 step: 1636, loss is 0.004977676551789045\n",
      "epoch: 5 step: 1637, loss is 0.0647391825914383\n",
      "epoch: 5 step: 1638, loss is 0.009296519681811333\n",
      "epoch: 5 step: 1639, loss is 0.000753256375901401\n",
      "epoch: 5 step: 1640, loss is 0.01296274084597826\n",
      "epoch: 5 step: 1641, loss is 0.02250721864402294\n",
      "epoch: 5 step: 1642, loss is 0.006693108007311821\n",
      "epoch: 5 step: 1643, loss is 0.029026539996266365\n",
      "epoch: 5 step: 1644, loss is 0.0010196918155997992\n",
      "epoch: 5 step: 1645, loss is 0.0047502461820840836\n",
      "epoch: 5 step: 1646, loss is 0.0019138514762744308\n",
      "epoch: 5 step: 1647, loss is 0.0005485084839165211\n",
      "epoch: 5 step: 1648, loss is 0.0014379537897184491\n",
      "epoch: 5 step: 1649, loss is 0.0008071118500083685\n",
      "epoch: 5 step: 1650, loss is 0.02159755490720272\n",
      "epoch: 5 step: 1651, loss is 0.00030388872255571187\n",
      "epoch: 5 step: 1652, loss is 0.0005812991294078529\n",
      "epoch: 5 step: 1653, loss is 0.0003488126676529646\n",
      "epoch: 5 step: 1654, loss is 0.0006093619158491492\n",
      "epoch: 5 step: 1655, loss is 0.050796907395124435\n",
      "epoch: 5 step: 1656, loss is 0.004698192700743675\n",
      "epoch: 5 step: 1657, loss is 0.07926206290721893\n",
      "epoch: 5 step: 1658, loss is 0.0160097386687994\n",
      "epoch: 5 step: 1659, loss is 0.00015452879597432911\n",
      "epoch: 5 step: 1660, loss is 0.0018452012445777655\n",
      "epoch: 5 step: 1661, loss is 0.0030641965568065643\n",
      "epoch: 5 step: 1662, loss is 0.001065072137862444\n",
      "epoch: 5 step: 1663, loss is 0.09405353665351868\n",
      "epoch: 5 step: 1664, loss is 0.1155056580901146\n",
      "epoch: 5 step: 1665, loss is 0.005807580891996622\n",
      "epoch: 5 step: 1666, loss is 0.002537599764764309\n",
      "epoch: 5 step: 1667, loss is 0.0002931820636149496\n",
      "epoch: 5 step: 1668, loss is 0.027126837521791458\n",
      "epoch: 5 step: 1669, loss is 0.0018595934379845858\n",
      "epoch: 5 step: 1670, loss is 0.01578672230243683\n",
      "epoch: 5 step: 1671, loss is 0.00021821628615725785\n",
      "epoch: 5 step: 1672, loss is 0.009048886597156525\n",
      "epoch: 5 step: 1673, loss is 0.0013019938487559557\n",
      "epoch: 5 step: 1674, loss is 0.03822404891252518\n",
      "epoch: 5 step: 1675, loss is 0.12110783159732819\n",
      "epoch: 5 step: 1676, loss is 0.003126445459201932\n",
      "epoch: 5 step: 1677, loss is 0.0012799660908058286\n",
      "epoch: 5 step: 1678, loss is 0.00925371516495943\n",
      "epoch: 5 step: 1679, loss is 0.02964882180094719\n",
      "epoch: 5 step: 1680, loss is 0.002178013324737549\n",
      "epoch: 5 step: 1681, loss is 0.0014162700390443206\n",
      "epoch: 5 step: 1682, loss is 0.46496647596359253\n",
      "epoch: 5 step: 1683, loss is 0.06206522136926651\n",
      "epoch: 5 step: 1684, loss is 0.022818317636847496\n",
      "epoch: 5 step: 1685, loss is 0.002789916004985571\n",
      "epoch: 5 step: 1686, loss is 0.0006463705212809145\n",
      "epoch: 5 step: 1687, loss is 0.004576072562485933\n",
      "epoch: 5 step: 1688, loss is 0.0016514582093805075\n",
      "epoch: 5 step: 1689, loss is 0.010934463702142239\n",
      "epoch: 5 step: 1690, loss is 0.0015040879370644689\n",
      "epoch: 5 step: 1691, loss is 0.0006499264272861183\n",
      "epoch: 5 step: 1692, loss is 0.050382573157548904\n",
      "epoch: 5 step: 1693, loss is 0.03333456069231033\n",
      "epoch: 5 step: 1694, loss is 0.0319492481648922\n",
      "epoch: 5 step: 1695, loss is 0.002742783399298787\n",
      "epoch: 5 step: 1696, loss is 0.04215674102306366\n",
      "epoch: 5 step: 1697, loss is 0.022744929417967796\n",
      "epoch: 5 step: 1698, loss is 0.002149689942598343\n",
      "epoch: 5 step: 1699, loss is 0.003599615301936865\n",
      "epoch: 5 step: 1700, loss is 0.0016671176999807358\n",
      "epoch: 5 step: 1701, loss is 0.00024187573581002653\n",
      "epoch: 5 step: 1702, loss is 0.007054449990391731\n",
      "epoch: 5 step: 1703, loss is 0.05355047062039375\n",
      "epoch: 5 step: 1704, loss is 0.04576447233557701\n",
      "epoch: 5 step: 1705, loss is 0.0012570968829095364\n",
      "epoch: 5 step: 1706, loss is 0.124799445271492\n",
      "epoch: 5 step: 1707, loss is 0.00016238178068306297\n",
      "epoch: 5 step: 1708, loss is 0.000330232986016199\n",
      "epoch: 5 step: 1709, loss is 0.004341950640082359\n",
      "epoch: 5 step: 1710, loss is 0.0005656119901686907\n",
      "epoch: 5 step: 1711, loss is 0.10051348805427551\n",
      "epoch: 5 step: 1712, loss is 0.00013498768385034055\n",
      "epoch: 5 step: 1713, loss is 0.015295117162168026\n",
      "epoch: 5 step: 1714, loss is 0.0058859712444245815\n",
      "epoch: 5 step: 1715, loss is 0.07504913210868835\n",
      "epoch: 5 step: 1716, loss is 0.004881117958575487\n",
      "epoch: 5 step: 1717, loss is 0.004070490598678589\n",
      "epoch: 5 step: 1718, loss is 0.0019541350193321705\n",
      "epoch: 5 step: 1719, loss is 0.012366287410259247\n",
      "epoch: 5 step: 1720, loss is 0.0010426630033180118\n",
      "epoch: 5 step: 1721, loss is 0.003594247857108712\n",
      "epoch: 5 step: 1722, loss is 0.0001668764161877334\n",
      "epoch: 5 step: 1723, loss is 0.0036133790854364634\n",
      "epoch: 5 step: 1724, loss is 0.014237687923014164\n",
      "epoch: 5 step: 1725, loss is 0.10461145639419556\n",
      "epoch: 5 step: 1726, loss is 0.004040178842842579\n",
      "epoch: 5 step: 1727, loss is 0.0012899970170110464\n",
      "epoch: 5 step: 1728, loss is 0.027608297765254974\n",
      "epoch: 5 step: 1729, loss is 0.0195565577596426\n",
      "epoch: 5 step: 1730, loss is 0.016185808926820755\n",
      "epoch: 5 step: 1731, loss is 0.0011550522176548839\n",
      "epoch: 5 step: 1732, loss is 0.00013468280667439103\n",
      "epoch: 5 step: 1733, loss is 0.019122058525681496\n",
      "epoch: 5 step: 1734, loss is 0.0010354039259254932\n",
      "epoch: 5 step: 1735, loss is 0.006160188931971788\n",
      "epoch: 5 step: 1736, loss is 0.06330792605876923\n",
      "epoch: 5 step: 1737, loss is 0.014233788475394249\n",
      "epoch: 5 step: 1738, loss is 0.0024804938584566116\n",
      "epoch: 5 step: 1739, loss is 0.004286691080778837\n",
      "epoch: 5 step: 1740, loss is 0.17855757474899292\n",
      "epoch: 5 step: 1741, loss is 0.00716329226270318\n",
      "epoch: 5 step: 1742, loss is 0.0019840889144688845\n",
      "epoch: 5 step: 1743, loss is 0.0047938404604792595\n",
      "epoch: 5 step: 1744, loss is 0.0010601236717775464\n",
      "epoch: 5 step: 1745, loss is 0.0007165367132984102\n",
      "epoch: 5 step: 1746, loss is 0.1122848242521286\n",
      "epoch: 5 step: 1747, loss is 0.0015902809100225568\n",
      "epoch: 5 step: 1748, loss is 0.002256407169625163\n",
      "epoch: 5 step: 1749, loss is 0.004247389268130064\n",
      "epoch: 5 step: 1750, loss is 0.04789763689041138\n",
      "epoch: 5 step: 1751, loss is 0.15349003672599792\n",
      "epoch: 5 step: 1752, loss is 0.0003869339998345822\n",
      "epoch: 5 step: 1753, loss is 0.0069280280731618404\n",
      "epoch: 5 step: 1754, loss is 0.016348548233509064\n",
      "epoch: 5 step: 1755, loss is 0.006169192027300596\n",
      "epoch: 5 step: 1756, loss is 0.1306154876947403\n",
      "epoch: 5 step: 1757, loss is 0.031144071370363235\n",
      "epoch: 5 step: 1758, loss is 0.0011370399734005332\n",
      "epoch: 5 step: 1759, loss is 0.07326698303222656\n",
      "epoch: 5 step: 1760, loss is 0.0019297670805826783\n",
      "epoch: 5 step: 1761, loss is 0.1485319882631302\n",
      "epoch: 5 step: 1762, loss is 0.01924179308116436\n",
      "epoch: 5 step: 1763, loss is 0.008226140402257442\n",
      "epoch: 5 step: 1764, loss is 0.07618699967861176\n",
      "epoch: 5 step: 1765, loss is 0.017167747020721436\n",
      "epoch: 5 step: 1766, loss is 0.002658305922523141\n",
      "epoch: 5 step: 1767, loss is 0.01377240102738142\n",
      "epoch: 5 step: 1768, loss is 0.15808992087841034\n",
      "epoch: 5 step: 1769, loss is 0.005274917930364609\n",
      "epoch: 5 step: 1770, loss is 0.00017841866065282375\n",
      "epoch: 5 step: 1771, loss is 0.05323221534490585\n",
      "epoch: 5 step: 1772, loss is 0.00129197898786515\n",
      "epoch: 5 step: 1773, loss is 0.05947982147336006\n",
      "epoch: 5 step: 1774, loss is 0.2082299441099167\n",
      "epoch: 5 step: 1775, loss is 0.003051074920222163\n",
      "epoch: 5 step: 1776, loss is 0.009144668467342854\n",
      "epoch: 5 step: 1777, loss is 0.032651543617248535\n",
      "epoch: 5 step: 1778, loss is 0.002846010960638523\n",
      "epoch: 5 step: 1779, loss is 0.04680214822292328\n",
      "epoch: 5 step: 1780, loss is 0.00043021320016123354\n",
      "epoch: 5 step: 1781, loss is 0.002055293181911111\n",
      "epoch: 5 step: 1782, loss is 0.000926057284232229\n",
      "epoch: 5 step: 1783, loss is 0.04371378570795059\n",
      "epoch: 5 step: 1784, loss is 0.00029167026514187455\n",
      "epoch: 5 step: 1785, loss is 0.0008115164237096906\n",
      "epoch: 5 step: 1786, loss is 0.0006696037598885596\n",
      "epoch: 5 step: 1787, loss is 0.005121162161231041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1788, loss is 0.0013233334757387638\n",
      "epoch: 5 step: 1789, loss is 0.00037246994907036424\n",
      "epoch: 5 step: 1790, loss is 0.0047182347625494\n",
      "epoch: 5 step: 1791, loss is 0.0001614639477338642\n",
      "epoch: 5 step: 1792, loss is 0.050879281014204025\n",
      "epoch: 5 step: 1793, loss is 0.007345279213041067\n",
      "epoch: 5 step: 1794, loss is 0.0008174647809937596\n",
      "epoch: 5 step: 1795, loss is 0.0970975011587143\n",
      "epoch: 5 step: 1796, loss is 0.0013437881134450436\n",
      "epoch: 5 step: 1797, loss is 0.006500488147139549\n",
      "epoch: 5 step: 1798, loss is 0.020495520904660225\n",
      "epoch: 5 step: 1799, loss is 0.012314426712691784\n",
      "epoch: 5 step: 1800, loss is 0.0267312154173851\n",
      "epoch: 5 step: 1801, loss is 0.04066097363829613\n",
      "epoch: 5 step: 1802, loss is 0.02121134288609028\n",
      "epoch: 5 step: 1803, loss is 0.058923959732055664\n",
      "epoch: 5 step: 1804, loss is 0.004369608126580715\n",
      "epoch: 5 step: 1805, loss is 0.0014190251240506768\n",
      "epoch: 5 step: 1806, loss is 0.0013418023008853197\n",
      "epoch: 5 step: 1807, loss is 0.0008022404508665204\n",
      "epoch: 5 step: 1808, loss is 0.002604380715638399\n",
      "epoch: 5 step: 1809, loss is 0.0384371280670166\n",
      "epoch: 5 step: 1810, loss is 0.1531689316034317\n",
      "epoch: 5 step: 1811, loss is 0.0007332180393859744\n",
      "epoch: 5 step: 1812, loss is 0.03234034776687622\n",
      "epoch: 5 step: 1813, loss is 0.0016951579600572586\n",
      "epoch: 5 step: 1814, loss is 0.0032879593782126904\n",
      "epoch: 5 step: 1815, loss is 0.007342244032770395\n",
      "epoch: 5 step: 1816, loss is 0.16330352425575256\n",
      "epoch: 5 step: 1817, loss is 0.04119740054011345\n",
      "epoch: 5 step: 1818, loss is 0.007415012922137976\n",
      "epoch: 5 step: 1819, loss is 0.010996740311384201\n",
      "epoch: 5 step: 1820, loss is 0.03552216291427612\n",
      "epoch: 5 step: 1821, loss is 0.21177250146865845\n",
      "epoch: 5 step: 1822, loss is 0.022935770452022552\n",
      "epoch: 5 step: 1823, loss is 0.0038622207939624786\n",
      "epoch: 5 step: 1824, loss is 0.00037776745739392936\n",
      "epoch: 5 step: 1825, loss is 0.0003704578848555684\n",
      "epoch: 5 step: 1826, loss is 0.006211187690496445\n",
      "epoch: 5 step: 1827, loss is 0.057226795703172684\n",
      "epoch: 5 step: 1828, loss is 0.15167193114757538\n",
      "epoch: 5 step: 1829, loss is 0.0006765032885596156\n",
      "epoch: 5 step: 1830, loss is 0.003721697721630335\n",
      "epoch: 5 step: 1831, loss is 0.0004274211241863668\n",
      "epoch: 5 step: 1832, loss is 0.005623907316476107\n",
      "epoch: 5 step: 1833, loss is 0.010647453367710114\n",
      "epoch: 5 step: 1834, loss is 0.001051587169058621\n",
      "epoch: 5 step: 1835, loss is 0.01215394213795662\n",
      "epoch: 5 step: 1836, loss is 0.00025389291113242507\n",
      "epoch: 5 step: 1837, loss is 0.01972815953195095\n",
      "epoch: 5 step: 1838, loss is 0.006107470486313105\n",
      "epoch: 5 step: 1839, loss is 0.0006616357713937759\n",
      "epoch: 5 step: 1840, loss is 0.0017401145305484533\n",
      "epoch: 5 step: 1841, loss is 0.0894443690776825\n",
      "epoch: 5 step: 1842, loss is 0.024422185495495796\n",
      "epoch: 5 step: 1843, loss is 0.02483947202563286\n",
      "epoch: 5 step: 1844, loss is 0.0032382532954216003\n",
      "epoch: 5 step: 1845, loss is 0.0011029340093955398\n",
      "epoch: 5 step: 1846, loss is 0.02101539447903633\n",
      "epoch: 5 step: 1847, loss is 0.01143411360681057\n",
      "epoch: 5 step: 1848, loss is 0.11068428307771683\n",
      "epoch: 5 step: 1849, loss is 0.005175319965928793\n",
      "epoch: 5 step: 1850, loss is 0.010998984798789024\n",
      "epoch: 5 step: 1851, loss is 0.0015162492636591196\n",
      "epoch: 5 step: 1852, loss is 0.06660263985395432\n",
      "epoch: 5 step: 1853, loss is 0.003610339481383562\n",
      "epoch: 5 step: 1854, loss is 0.012990409508347511\n",
      "epoch: 5 step: 1855, loss is 0.014048325829207897\n",
      "epoch: 5 step: 1856, loss is 0.004458779469132423\n",
      "epoch: 5 step: 1857, loss is 0.0004606075235642493\n",
      "epoch: 5 step: 1858, loss is 0.010761283338069916\n",
      "epoch: 5 step: 1859, loss is 0.011857674457132816\n",
      "epoch: 5 step: 1860, loss is 0.015698973089456558\n",
      "epoch: 5 step: 1861, loss is 0.004631893243640661\n",
      "epoch: 5 step: 1862, loss is 0.00417049927636981\n",
      "epoch: 5 step: 1863, loss is 0.0033884544391185045\n",
      "epoch: 5 step: 1864, loss is 0.10243590176105499\n",
      "epoch: 5 step: 1865, loss is 0.15271702408790588\n",
      "epoch: 5 step: 1866, loss is 0.004340068902820349\n",
      "epoch: 5 step: 1867, loss is 0.0017593097873032093\n",
      "epoch: 5 step: 1868, loss is 0.0006538945599459112\n",
      "epoch: 5 step: 1869, loss is 0.04592146724462509\n",
      "epoch: 5 step: 1870, loss is 0.0030145617201924324\n",
      "epoch: 5 step: 1871, loss is 0.0002668035158421844\n",
      "epoch: 5 step: 1872, loss is 0.00025497161550447345\n",
      "epoch: 5 step: 1873, loss is 0.008058251813054085\n",
      "epoch: 5 step: 1874, loss is 0.00457816943526268\n",
      "epoch: 5 step: 1875, loss is 0.00887314509600401\n",
      "epoch: 5 step: 1876, loss is 0.0013737308327108622\n",
      "epoch: 5 step: 1877, loss is 0.0022990393918007612\n",
      "epoch: 5 step: 1878, loss is 0.007176869083195925\n",
      "epoch: 5 step: 1879, loss is 8.970208000391722e-05\n",
      "epoch: 5 step: 1880, loss is 0.00014152078074403107\n",
      "epoch: 5 step: 1881, loss is 0.00929213222116232\n",
      "epoch: 5 step: 1882, loss is 0.05475357919931412\n",
      "epoch: 5 step: 1883, loss is 0.15531378984451294\n",
      "epoch: 5 step: 1884, loss is 0.05755408853292465\n",
      "epoch: 5 step: 1885, loss is 0.02396772988140583\n",
      "epoch: 5 step: 1886, loss is 0.00778648816049099\n",
      "epoch: 5 step: 1887, loss is 0.00032718380680307746\n",
      "epoch: 5 step: 1888, loss is 0.0013268108014017344\n",
      "epoch: 5 step: 1889, loss is 0.00883956253528595\n",
      "epoch: 5 step: 1890, loss is 0.000816164945717901\n",
      "epoch: 5 step: 1891, loss is 0.0008534732041880488\n",
      "epoch: 5 step: 1892, loss is 0.03582436591386795\n",
      "epoch: 5 step: 1893, loss is 0.19290873408317566\n",
      "epoch: 5 step: 1894, loss is 0.01345293689519167\n",
      "epoch: 5 step: 1895, loss is 0.003405715338885784\n",
      "epoch: 5 step: 1896, loss is 0.0016244057333096862\n",
      "epoch: 5 step: 1897, loss is 0.0004041349748149514\n",
      "epoch: 5 step: 1898, loss is 0.13591666519641876\n",
      "epoch: 5 step: 1899, loss is 0.01806838996708393\n",
      "epoch: 5 step: 1900, loss is 0.008098751306533813\n",
      "epoch: 5 step: 1901, loss is 0.0009790124604478478\n",
      "epoch: 5 step: 1902, loss is 0.013104196637868881\n",
      "epoch: 5 step: 1903, loss is 0.17212966084480286\n",
      "epoch: 5 step: 1904, loss is 0.00029471059679053724\n",
      "epoch: 5 step: 1905, loss is 0.0019964545499533415\n",
      "epoch: 5 step: 1906, loss is 0.004437622148543596\n",
      "epoch: 5 step: 1907, loss is 0.000288307957816869\n",
      "epoch: 5 step: 1908, loss is 0.0006029470241628587\n",
      "epoch: 5 step: 1909, loss is 0.013238462619483471\n",
      "epoch: 5 step: 1910, loss is 0.06418675184249878\n",
      "epoch: 5 step: 1911, loss is 0.003658585250377655\n",
      "epoch: 5 step: 1912, loss is 0.021188130602240562\n",
      "epoch: 5 step: 1913, loss is 0.029746340587735176\n",
      "epoch: 5 step: 1914, loss is 0.0012654300080612302\n",
      "epoch: 5 step: 1915, loss is 0.029176784679293633\n",
      "epoch: 5 step: 1916, loss is 0.019491786137223244\n",
      "epoch: 5 step: 1917, loss is 0.0017976287053897977\n",
      "epoch: 5 step: 1918, loss is 0.0005918641691096127\n",
      "epoch: 5 step: 1919, loss is 0.0040486338548362255\n",
      "epoch: 5 step: 1920, loss is 0.014379397965967655\n",
      "epoch: 5 step: 1921, loss is 0.0007387202349491417\n",
      "epoch: 5 step: 1922, loss is 0.14703573286533356\n",
      "epoch: 5 step: 1923, loss is 0.05213275924324989\n",
      "epoch: 5 step: 1924, loss is 0.18209433555603027\n",
      "epoch: 5 step: 1925, loss is 0.0017856667982414365\n",
      "epoch: 5 step: 1926, loss is 0.0001723817113088444\n",
      "epoch: 5 step: 1927, loss is 0.0008429507142864168\n",
      "epoch: 5 step: 1928, loss is 0.059237800538539886\n",
      "epoch: 5 step: 1929, loss is 0.000839424435980618\n",
      "epoch: 5 step: 1930, loss is 0.003063006093725562\n",
      "epoch: 5 step: 1931, loss is 0.0018840079428628087\n",
      "epoch: 5 step: 1932, loss is 0.013607081957161427\n",
      "epoch: 5 step: 1933, loss is 0.005150892771780491\n",
      "epoch: 5 step: 1934, loss is 0.00709522282704711\n",
      "epoch: 5 step: 1935, loss is 0.0013736006803810596\n",
      "epoch: 5 step: 1936, loss is 0.07415664941072464\n",
      "epoch: 5 step: 1937, loss is 0.000530964694917202\n",
      "epoch: 5 step: 1938, loss is 0.003847848391160369\n",
      "epoch: 5 step: 1939, loss is 0.035557013005018234\n",
      "epoch: 5 step: 1940, loss is 0.0005777558544650674\n",
      "epoch: 5 step: 1941, loss is 0.0010684082517400384\n",
      "epoch: 5 step: 1942, loss is 0.008852214552462101\n",
      "epoch: 5 step: 1943, loss is 0.020643236115574837\n",
      "epoch: 5 step: 1944, loss is 0.06696026027202606\n",
      "epoch: 5 step: 1945, loss is 0.017065079882740974\n",
      "epoch: 5 step: 1946, loss is 0.12564431130886078\n",
      "epoch: 5 step: 1947, loss is 0.00790355820208788\n",
      "epoch: 5 step: 1948, loss is 0.07241091877222061\n",
      "epoch: 5 step: 1949, loss is 0.0034417554270476103\n",
      "epoch: 5 step: 1950, loss is 0.0011406850535422564\n",
      "epoch: 5 step: 1951, loss is 0.0001685483439359814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1952, loss is 0.002268874319270253\n",
      "epoch: 5 step: 1953, loss is 0.010265680029988289\n",
      "epoch: 5 step: 1954, loss is 0.008026211522519588\n",
      "epoch: 5 step: 1955, loss is 0.10559074580669403\n",
      "epoch: 5 step: 1956, loss is 0.011496652849018574\n",
      "epoch: 5 step: 1957, loss is 0.028607888147234917\n",
      "epoch: 5 step: 1958, loss is 0.0008871215977706015\n",
      "epoch: 5 step: 1959, loss is 0.0005940819974057376\n",
      "epoch: 5 step: 1960, loss is 0.0006868904456496239\n",
      "epoch: 5 step: 1961, loss is 0.005151061341166496\n",
      "epoch: 5 step: 1962, loss is 0.0005524783045984805\n",
      "epoch: 5 step: 1963, loss is 0.02766314521431923\n",
      "epoch: 5 step: 1964, loss is 0.0012621904024854302\n",
      "epoch: 5 step: 1965, loss is 0.013595315627753735\n",
      "epoch: 5 step: 1966, loss is 0.000729482329916209\n",
      "epoch: 5 step: 1967, loss is 0.03408239409327507\n",
      "epoch: 5 step: 1968, loss is 0.000212421320611611\n",
      "epoch: 5 step: 1969, loss is 0.03756652772426605\n",
      "epoch: 5 step: 1970, loss is 0.0012457857374101877\n",
      "epoch: 5 step: 1971, loss is 0.0005388186546042562\n",
      "epoch: 5 step: 1972, loss is 0.0005041704280301929\n",
      "epoch: 5 step: 1973, loss is 0.1463487297296524\n",
      "epoch: 5 step: 1974, loss is 0.12496865540742874\n",
      "epoch: 5 step: 1975, loss is 0.13837595283985138\n",
      "epoch: 5 step: 1976, loss is 0.030179521068930626\n",
      "epoch: 5 step: 1977, loss is 0.0015759770758450031\n",
      "epoch: 5 step: 1978, loss is 0.0029851370491087437\n",
      "epoch: 5 step: 1979, loss is 0.0013787145726382732\n",
      "epoch: 5 step: 1980, loss is 0.00035910215228796005\n",
      "epoch: 5 step: 1981, loss is 0.018977079540491104\n",
      "epoch: 5 step: 1982, loss is 0.13447576761245728\n",
      "epoch: 5 step: 1983, loss is 0.05419674888253212\n",
      "epoch: 5 step: 1984, loss is 0.00017509503231849521\n",
      "epoch: 5 step: 1985, loss is 0.09773337095975876\n",
      "epoch: 5 step: 1986, loss is 0.033864594995975494\n",
      "epoch: 5 step: 1987, loss is 0.002454966539517045\n",
      "epoch: 5 step: 1988, loss is 0.008435647003352642\n",
      "epoch: 5 step: 1989, loss is 0.003374973777681589\n",
      "epoch: 5 step: 1990, loss is 0.00017534209473524243\n",
      "epoch: 5 step: 1991, loss is 0.0007990127196535468\n",
      "epoch: 5 step: 1992, loss is 0.0013156543718650937\n",
      "epoch: 5 step: 1993, loss is 0.008996594697237015\n",
      "epoch: 5 step: 1994, loss is 0.03243790194392204\n",
      "epoch: 5 step: 1995, loss is 0.0038437778130173683\n",
      "epoch: 5 step: 1996, loss is 0.000517701671924442\n",
      "epoch: 5 step: 1997, loss is 0.0010015075094997883\n",
      "epoch: 5 step: 1998, loss is 0.000746279489248991\n",
      "epoch: 5 step: 1999, loss is 0.0006664898828603327\n",
      "epoch: 5 step: 2000, loss is 0.027585532516241074\n",
      "epoch: 5 step: 2001, loss is 0.014195955358445644\n",
      "epoch: 5 step: 2002, loss is 0.0037479856982827187\n",
      "epoch: 5 step: 2003, loss is 0.00016656234220135957\n",
      "epoch: 5 step: 2004, loss is 0.05105320364236832\n",
      "epoch: 5 step: 2005, loss is 0.09712538123130798\n",
      "epoch: 5 step: 2006, loss is 0.07618247717618942\n",
      "epoch: 5 step: 2007, loss is 0.0003341942501720041\n",
      "epoch: 5 step: 2008, loss is 0.005432666279375553\n",
      "epoch: 5 step: 2009, loss is 0.00667976401746273\n",
      "epoch: 5 step: 2010, loss is 0.0042414916679263115\n",
      "epoch: 5 step: 2011, loss is 0.11359567195177078\n",
      "epoch: 5 step: 2012, loss is 0.17101244628429413\n",
      "epoch: 5 step: 2013, loss is 0.14705859124660492\n",
      "epoch: 5 step: 2014, loss is 0.011326163075864315\n",
      "epoch: 5 step: 2015, loss is 0.0652238205075264\n",
      "epoch: 5 step: 2016, loss is 0.006300246808677912\n",
      "epoch: 5 step: 2017, loss is 0.036363691091537476\n",
      "epoch: 5 step: 2018, loss is 0.014407070353627205\n",
      "epoch: 5 step: 2019, loss is 0.007417625747621059\n",
      "epoch: 5 step: 2020, loss is 0.0018825758015736938\n",
      "epoch: 5 step: 2021, loss is 0.008952600881457329\n",
      "epoch: 5 step: 2022, loss is 0.005964732728898525\n",
      "epoch: 5 step: 2023, loss is 0.010897119529545307\n",
      "epoch: 5 step: 2024, loss is 0.005637393333017826\n",
      "epoch: 5 step: 2025, loss is 0.007433694321662188\n",
      "epoch: 5 step: 2026, loss is 0.0022656931541860104\n",
      "epoch: 5 step: 2027, loss is 0.005847540218383074\n",
      "epoch: 5 step: 2028, loss is 0.017407981678843498\n",
      "epoch: 5 step: 2029, loss is 1.5315148630179465e-05\n",
      "epoch: 5 step: 2030, loss is 0.014107825234532356\n",
      "epoch: 5 step: 2031, loss is 0.015312496572732925\n",
      "epoch: 5 step: 2032, loss is 0.019569002091884613\n",
      "epoch: 5 step: 2033, loss is 0.0031979146879166365\n",
      "epoch: 5 step: 2034, loss is 0.04887813329696655\n",
      "epoch: 5 step: 2035, loss is 0.0005541060818359256\n",
      "epoch: 5 step: 2036, loss is 0.007627012208104134\n",
      "epoch: 5 step: 2037, loss is 0.039555296301841736\n",
      "epoch: 5 step: 2038, loss is 0.00019994625472463667\n",
      "epoch: 5 step: 2039, loss is 0.0006105359643697739\n",
      "epoch: 5 step: 2040, loss is 0.005478911101818085\n",
      "epoch: 5 step: 2041, loss is 0.0040223607793450356\n",
      "epoch: 5 step: 2042, loss is 0.010744119994342327\n",
      "epoch: 5 step: 2043, loss is 0.027839820832014084\n",
      "epoch: 5 step: 2044, loss is 0.029252182692289352\n",
      "epoch: 5 step: 2045, loss is 0.0021448954939842224\n",
      "epoch: 5 step: 2046, loss is 0.0001728174975141883\n",
      "epoch: 5 step: 2047, loss is 0.0014935302315279841\n",
      "epoch: 5 step: 2048, loss is 0.07691338658332825\n",
      "epoch: 5 step: 2049, loss is 0.0005128434859216213\n",
      "epoch: 5 step: 2050, loss is 0.06737374514341354\n",
      "epoch: 5 step: 2051, loss is 0.008114589378237724\n",
      "epoch: 5 step: 2052, loss is 0.07690133154392242\n",
      "epoch: 5 step: 2053, loss is 0.04011458903551102\n",
      "epoch: 5 step: 2054, loss is 0.00010376200953032821\n",
      "epoch: 5 step: 2055, loss is 0.0054890247993171215\n",
      "epoch: 5 step: 2056, loss is 0.0007783565088175237\n",
      "epoch: 5 step: 2057, loss is 0.004167459439486265\n",
      "epoch: 5 step: 2058, loss is 0.0014882059767842293\n",
      "epoch: 5 step: 2059, loss is 0.036563266068696976\n",
      "epoch: 5 step: 2060, loss is 0.04008433222770691\n",
      "epoch: 5 step: 2061, loss is 0.012282546609640121\n",
      "epoch: 5 step: 2062, loss is 0.0012414356460794806\n",
      "epoch: 5 step: 2063, loss is 0.018363460898399353\n",
      "epoch: 5 step: 2064, loss is 0.020243672654032707\n",
      "epoch: 5 step: 2065, loss is 0.02928617224097252\n",
      "epoch: 5 step: 2066, loss is 0.019071906805038452\n",
      "epoch: 5 step: 2067, loss is 0.28899532556533813\n",
      "epoch: 5 step: 2068, loss is 0.0005382825620472431\n",
      "epoch: 5 step: 2069, loss is 0.0001277256233152002\n",
      "epoch: 5 step: 2070, loss is 0.0007640246767550707\n",
      "epoch: 5 step: 2071, loss is 0.00010490899148862809\n",
      "epoch: 5 step: 2072, loss is 0.0007691523060202599\n",
      "epoch: 5 step: 2073, loss is 0.001679978216998279\n",
      "epoch: 5 step: 2074, loss is 0.008197341114282608\n",
      "epoch: 5 step: 2075, loss is 0.0037752739153802395\n",
      "epoch: 5 step: 2076, loss is 0.03355475887656212\n",
      "epoch: 5 step: 2077, loss is 0.048248957842588425\n",
      "epoch: 5 step: 2078, loss is 0.0005328187253326178\n",
      "epoch: 5 step: 2079, loss is 0.07418284565210342\n",
      "epoch: 5 step: 2080, loss is 0.026299547404050827\n",
      "epoch: 5 step: 2081, loss is 0.00042438667151145637\n",
      "epoch: 5 step: 2082, loss is 0.005056560039520264\n",
      "epoch: 5 step: 2083, loss is 0.19593121111392975\n",
      "epoch: 5 step: 2084, loss is 0.0034646200947463512\n",
      "epoch: 5 step: 2085, loss is 0.0009022982558235526\n",
      "epoch: 5 step: 2086, loss is 0.07851015776395798\n",
      "epoch: 5 step: 2087, loss is 0.01795501820743084\n",
      "epoch: 5 step: 2088, loss is 0.010889064520597458\n",
      "epoch: 5 step: 2089, loss is 0.04090557619929314\n",
      "epoch: 5 step: 2090, loss is 0.01818796806037426\n",
      "epoch: 5 step: 2091, loss is 0.0008341077482327819\n",
      "epoch: 5 step: 2092, loss is 0.0005882750847376883\n",
      "epoch: 5 step: 2093, loss is 0.03337419778108597\n",
      "epoch: 5 step: 2094, loss is 0.06633457541465759\n",
      "epoch: 5 step: 2095, loss is 0.006243516691029072\n",
      "epoch: 5 step: 2096, loss is 0.00230387388728559\n",
      "epoch: 5 step: 2097, loss is 0.0012320656096562743\n",
      "epoch: 5 step: 2098, loss is 0.03962927311658859\n",
      "epoch: 5 step: 2099, loss is 0.00036408190499059856\n",
      "epoch: 5 step: 2100, loss is 0.1977989226579666\n",
      "epoch: 5 step: 2101, loss is 0.0027899008709937334\n",
      "epoch: 5 step: 2102, loss is 0.031104357913136482\n",
      "epoch: 5 step: 2103, loss is 0.0005539479316212237\n",
      "epoch: 5 step: 2104, loss is 0.0010082508670166135\n",
      "epoch: 5 step: 2105, loss is 0.02546197548508644\n",
      "epoch: 5 step: 2106, loss is 0.0017260806635022163\n",
      "epoch: 5 step: 2107, loss is 0.0008326277020387352\n",
      "epoch: 5 step: 2108, loss is 0.009514817968010902\n",
      "epoch: 5 step: 2109, loss is 0.005681012757122517\n",
      "epoch: 5 step: 2110, loss is 0.0009709557052701712\n",
      "epoch: 5 step: 2111, loss is 0.0008607538184151053\n",
      "epoch: 5 step: 2112, loss is 0.11773104965686798\n",
      "epoch: 5 step: 2113, loss is 0.0032463609240949154\n",
      "epoch: 5 step: 2114, loss is 0.00040084432112053037\n",
      "epoch: 5 step: 2115, loss is 0.0009834434604272246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 2116, loss is 0.024160465225577354\n",
      "epoch: 5 step: 2117, loss is 0.0045380317606031895\n",
      "epoch: 5 step: 2118, loss is 0.0014727578964084387\n",
      "epoch: 5 step: 2119, loss is 0.2763710618019104\n",
      "epoch: 5 step: 2120, loss is 0.010049760341644287\n",
      "epoch: 5 step: 2121, loss is 0.0018879554700106382\n",
      "epoch: 5 step: 2122, loss is 0.0009679057984612882\n",
      "epoch: 5 step: 2123, loss is 0.03981543704867363\n",
      "epoch: 5 step: 2124, loss is 0.084697425365448\n",
      "epoch: 5 step: 2125, loss is 0.026846520602703094\n",
      "epoch: 5 step: 2126, loss is 0.0024985193740576506\n",
      "epoch: 5 step: 2127, loss is 0.006633525714278221\n",
      "epoch: 5 step: 2128, loss is 0.19642013311386108\n",
      "epoch: 5 step: 2129, loss is 0.02105562761425972\n",
      "epoch: 5 step: 2130, loss is 0.00024400300753768533\n",
      "epoch: 5 step: 2131, loss is 0.06189620867371559\n",
      "epoch: 5 step: 2132, loss is 0.07474080473184586\n",
      "epoch: 5 step: 2133, loss is 0.00958155281841755\n",
      "epoch: 5 step: 2134, loss is 0.0030639891047030687\n",
      "epoch: 5 step: 2135, loss is 0.0034425323829054832\n",
      "epoch: 5 step: 2136, loss is 0.025297455489635468\n",
      "epoch: 5 step: 2137, loss is 0.0018609147518873215\n",
      "epoch: 5 step: 2138, loss is 0.0036488266196101904\n",
      "epoch: 5 step: 2139, loss is 0.0013028397224843502\n",
      "epoch: 5 step: 2140, loss is 0.0002946361491922289\n",
      "epoch: 5 step: 2141, loss is 0.18229450285434723\n",
      "epoch: 5 step: 2142, loss is 0.0017284065252169967\n",
      "epoch: 5 step: 2143, loss is 0.09138427674770355\n",
      "epoch: 5 step: 2144, loss is 0.020833348855376244\n",
      "epoch: 5 step: 2145, loss is 0.009347671642899513\n",
      "epoch: 5 step: 2146, loss is 0.028598342090845108\n",
      "epoch: 5 step: 2147, loss is 0.11816921830177307\n",
      "epoch: 5 step: 2148, loss is 0.004118736367672682\n",
      "epoch: 5 step: 2149, loss is 0.005781549494713545\n",
      "epoch: 5 step: 2150, loss is 0.0009484659531153738\n",
      "epoch: 5 step: 2151, loss is 0.04612204059958458\n",
      "epoch: 5 step: 2152, loss is 0.0002918984682764858\n",
      "epoch: 5 step: 2153, loss is 0.0012737098149955273\n",
      "epoch: 5 step: 2154, loss is 0.0009510025847703218\n",
      "epoch: 5 step: 2155, loss is 0.29146161675453186\n",
      "epoch: 5 step: 2156, loss is 0.000363845843821764\n",
      "epoch: 5 step: 2157, loss is 0.07969950139522552\n",
      "epoch: 5 step: 2158, loss is 0.0010768474312499166\n",
      "epoch: 5 step: 2159, loss is 0.08082035928964615\n",
      "epoch: 5 step: 2160, loss is 0.03339804708957672\n",
      "epoch: 5 step: 2161, loss is 0.12245189398527145\n",
      "epoch: 5 step: 2162, loss is 0.06972939521074295\n",
      "epoch: 5 step: 2163, loss is 0.09947099536657333\n",
      "epoch: 5 step: 2164, loss is 0.058274589478969574\n",
      "epoch: 5 step: 2165, loss is 0.046804845333099365\n",
      "epoch: 5 step: 2166, loss is 0.014658093452453613\n",
      "epoch: 5 step: 2167, loss is 0.0050250813364982605\n",
      "epoch: 5 step: 2168, loss is 0.11414212733507156\n",
      "epoch: 5 step: 2169, loss is 0.05435403436422348\n",
      "epoch: 5 step: 2170, loss is 0.04729314148426056\n",
      "epoch: 5 step: 2171, loss is 0.0433882512152195\n",
      "epoch: 5 step: 2172, loss is 0.0005549245979636908\n",
      "epoch: 5 step: 2173, loss is 0.0040333387441933155\n",
      "epoch: 5 step: 2174, loss is 0.044549569487571716\n",
      "epoch: 5 step: 2175, loss is 0.004137668292969465\n",
      "epoch: 5 step: 2176, loss is 0.009062274359166622\n",
      "epoch: 5 step: 2177, loss is 0.010282067582011223\n",
      "epoch: 5 step: 2178, loss is 0.011537092737853527\n",
      "epoch: 5 step: 2179, loss is 0.05247993394732475\n",
      "epoch: 5 step: 2180, loss is 0.06690428406000137\n",
      "epoch: 5 step: 2181, loss is 0.005016545299440622\n",
      "epoch: 5 step: 2182, loss is 0.00212881900370121\n",
      "epoch: 5 step: 2183, loss is 0.0004014419100712985\n",
      "epoch: 5 step: 2184, loss is 0.006141203455626965\n",
      "epoch: 5 step: 2185, loss is 0.0037196900229901075\n",
      "epoch: 5 step: 2186, loss is 0.005438074003905058\n",
      "epoch: 5 step: 2187, loss is 0.030877629294991493\n",
      "epoch: 6 step: 1, loss is 0.062000907957553864\n",
      "epoch: 6 step: 2, loss is 0.0010778708383440971\n",
      "epoch: 6 step: 3, loss is 0.0009243622189387679\n",
      "epoch: 6 step: 4, loss is 0.024703094735741615\n",
      "epoch: 6 step: 5, loss is 0.0025051780976355076\n",
      "epoch: 6 step: 6, loss is 0.029148399829864502\n",
      "epoch: 6 step: 7, loss is 0.16834905743598938\n",
      "epoch: 6 step: 8, loss is 0.08451906591653824\n",
      "epoch: 6 step: 9, loss is 0.04891533777117729\n",
      "epoch: 6 step: 10, loss is 0.034665293991565704\n",
      "epoch: 6 step: 11, loss is 0.0036982703022658825\n",
      "epoch: 6 step: 12, loss is 0.0072189560160040855\n",
      "epoch: 6 step: 13, loss is 0.08638344705104828\n",
      "epoch: 6 step: 14, loss is 0.0010941331274807453\n",
      "epoch: 6 step: 15, loss is 0.001756076468154788\n",
      "epoch: 6 step: 16, loss is 0.00015719070506747812\n",
      "epoch: 6 step: 17, loss is 0.007970146834850311\n",
      "epoch: 6 step: 18, loss is 0.0029983599670231342\n",
      "epoch: 6 step: 19, loss is 0.10597161948680878\n",
      "epoch: 6 step: 20, loss is 0.0009794675279408693\n",
      "epoch: 6 step: 21, loss is 0.12806358933448792\n",
      "epoch: 6 step: 22, loss is 0.05449168011546135\n",
      "epoch: 6 step: 23, loss is 0.0020965568255633116\n",
      "epoch: 6 step: 24, loss is 0.0017116684466600418\n",
      "epoch: 6 step: 25, loss is 0.022360999137163162\n",
      "epoch: 6 step: 26, loss is 0.0292081106454134\n",
      "epoch: 6 step: 27, loss is 0.021643968299031258\n",
      "epoch: 6 step: 28, loss is 0.0003010063956025988\n",
      "epoch: 6 step: 29, loss is 0.0009720526868477464\n",
      "epoch: 6 step: 30, loss is 0.0762118473649025\n",
      "epoch: 6 step: 31, loss is 0.0003449156356509775\n",
      "epoch: 6 step: 32, loss is 0.010282381437718868\n",
      "epoch: 6 step: 33, loss is 0.004186967387795448\n",
      "epoch: 6 step: 34, loss is 0.0050301081500947475\n",
      "epoch: 6 step: 35, loss is 0.0013603715924546123\n",
      "epoch: 6 step: 36, loss is 0.007057346869260073\n",
      "epoch: 6 step: 37, loss is 0.004696446470916271\n",
      "epoch: 6 step: 38, loss is 0.012786511331796646\n",
      "epoch: 6 step: 39, loss is 0.0007443548529408872\n",
      "epoch: 6 step: 40, loss is 0.001011043437756598\n",
      "epoch: 6 step: 41, loss is 0.005752590950578451\n",
      "epoch: 6 step: 42, loss is 0.001058032619766891\n",
      "epoch: 6 step: 43, loss is 0.0010025189258158207\n",
      "epoch: 6 step: 44, loss is 0.002829697448760271\n",
      "epoch: 6 step: 45, loss is 0.004410949535667896\n",
      "epoch: 6 step: 46, loss is 0.0010821458417922258\n",
      "epoch: 6 step: 47, loss is 0.020158935338258743\n",
      "epoch: 6 step: 48, loss is 0.013768081553280354\n",
      "epoch: 6 step: 49, loss is 0.011592649854719639\n",
      "epoch: 6 step: 50, loss is 0.0006446888437494636\n",
      "epoch: 6 step: 51, loss is 0.004622275475412607\n",
      "epoch: 6 step: 52, loss is 0.004173025488853455\n",
      "epoch: 6 step: 53, loss is 0.005596276372671127\n",
      "epoch: 6 step: 54, loss is 0.005664958618581295\n",
      "epoch: 6 step: 55, loss is 0.0013048697728663683\n",
      "epoch: 6 step: 56, loss is 0.0006379738915711641\n",
      "epoch: 6 step: 57, loss is 0.002888406626880169\n",
      "epoch: 6 step: 58, loss is 0.00031269557075574994\n",
      "epoch: 6 step: 59, loss is 9.493852849118412e-05\n",
      "epoch: 6 step: 60, loss is 0.011937452480196953\n",
      "epoch: 6 step: 61, loss is 0.010129822418093681\n",
      "epoch: 6 step: 62, loss is 0.005388947203755379\n",
      "epoch: 6 step: 63, loss is 0.015032735653221607\n",
      "epoch: 6 step: 64, loss is 0.0020963402930647135\n",
      "epoch: 6 step: 65, loss is 0.0012017607223242521\n",
      "epoch: 6 step: 66, loss is 0.01860670931637287\n",
      "epoch: 6 step: 67, loss is 0.01263196486979723\n",
      "epoch: 6 step: 68, loss is 0.030656421557068825\n",
      "epoch: 6 step: 69, loss is 0.019386621192097664\n",
      "epoch: 6 step: 70, loss is 0.0013662559213116765\n",
      "epoch: 6 step: 71, loss is 0.015241059474647045\n",
      "epoch: 6 step: 72, loss is 0.02426266483962536\n",
      "epoch: 6 step: 73, loss is 0.07880440354347229\n",
      "epoch: 6 step: 74, loss is 0.013733635656535625\n",
      "epoch: 6 step: 75, loss is 0.000608905334956944\n",
      "epoch: 6 step: 76, loss is 0.02551463432610035\n",
      "epoch: 6 step: 77, loss is 0.0006363349384628236\n",
      "epoch: 6 step: 78, loss is 0.0005366370314732194\n",
      "epoch: 6 step: 79, loss is 0.0420452281832695\n",
      "epoch: 6 step: 80, loss is 0.01122675184160471\n",
      "epoch: 6 step: 81, loss is 0.0011056201765313745\n",
      "epoch: 6 step: 82, loss is 0.0002799337962642312\n",
      "epoch: 6 step: 83, loss is 0.003410340752452612\n",
      "epoch: 6 step: 84, loss is 0.00038269427022896707\n",
      "epoch: 6 step: 85, loss is 0.0010638654930517077\n",
      "epoch: 6 step: 86, loss is 0.003039321396499872\n",
      "epoch: 6 step: 87, loss is 0.01285291463136673\n",
      "epoch: 6 step: 88, loss is 0.03999962657690048\n",
      "epoch: 6 step: 89, loss is 0.0002529642079025507\n",
      "epoch: 6 step: 90, loss is 0.00011437215289333835\n",
      "epoch: 6 step: 91, loss is 0.004054438788443804\n",
      "epoch: 6 step: 92, loss is 0.05443406105041504\n",
      "epoch: 6 step: 93, loss is 0.00031899005989544094\n",
      "epoch: 6 step: 94, loss is 3.4527725802036e-05\n",
      "epoch: 6 step: 95, loss is 0.08211935311555862\n",
      "epoch: 6 step: 96, loss is 0.0021826864685863256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 97, loss is 0.008381729945540428\n",
      "epoch: 6 step: 98, loss is 0.003537857672199607\n",
      "epoch: 6 step: 99, loss is 0.005542451981455088\n",
      "epoch: 6 step: 100, loss is 0.0017011051531881094\n",
      "epoch: 6 step: 101, loss is 0.0003774815413635224\n",
      "epoch: 6 step: 102, loss is 0.00047506860573776066\n",
      "epoch: 6 step: 103, loss is 4.56584311905317e-05\n",
      "epoch: 6 step: 104, loss is 0.12858836352825165\n",
      "epoch: 6 step: 105, loss is 8.278548921225592e-05\n",
      "epoch: 6 step: 106, loss is 0.028313830494880676\n",
      "epoch: 6 step: 107, loss is 0.003284948179498315\n",
      "epoch: 6 step: 108, loss is 0.008197659626603127\n",
      "epoch: 6 step: 109, loss is 0.011084763333201408\n",
      "epoch: 6 step: 110, loss is 7.61530754971318e-05\n",
      "epoch: 6 step: 111, loss is 0.0025532194413244724\n",
      "epoch: 6 step: 112, loss is 0.019549133256077766\n",
      "epoch: 6 step: 113, loss is 0.002229012083262205\n",
      "epoch: 6 step: 114, loss is 0.00020280381431803107\n",
      "epoch: 6 step: 115, loss is 0.0013790101511403918\n",
      "epoch: 6 step: 116, loss is 0.008500535041093826\n",
      "epoch: 6 step: 117, loss is 0.05001243203878403\n",
      "epoch: 6 step: 118, loss is 0.023471347987651825\n",
      "epoch: 6 step: 119, loss is 0.012918415479362011\n",
      "epoch: 6 step: 120, loss is 0.00037660589441657066\n",
      "epoch: 6 step: 121, loss is 0.000678149692248553\n",
      "epoch: 6 step: 122, loss is 0.039438776671886444\n",
      "epoch: 6 step: 123, loss is 0.0009782107081264257\n",
      "epoch: 6 step: 124, loss is 0.000995545880869031\n",
      "epoch: 6 step: 125, loss is 0.003587648505344987\n",
      "epoch: 6 step: 126, loss is 0.001278995885513723\n",
      "epoch: 6 step: 127, loss is 5.385384429246187e-05\n",
      "epoch: 6 step: 128, loss is 0.003326922422274947\n",
      "epoch: 6 step: 129, loss is 0.0034134190063923597\n",
      "epoch: 6 step: 130, loss is 0.007261544466018677\n",
      "epoch: 6 step: 131, loss is 0.00041097725625149906\n",
      "epoch: 6 step: 132, loss is 1.499871814303333e-05\n",
      "epoch: 6 step: 133, loss is 0.0007717665866948664\n",
      "epoch: 6 step: 134, loss is 0.0020792861469089985\n",
      "epoch: 6 step: 135, loss is 0.04438565671443939\n",
      "epoch: 6 step: 136, loss is 0.0003120728943031281\n",
      "epoch: 6 step: 137, loss is 0.00013416551519185305\n",
      "epoch: 6 step: 138, loss is 0.005518525838851929\n",
      "epoch: 6 step: 139, loss is 0.001299937954172492\n",
      "epoch: 6 step: 140, loss is 0.05631641298532486\n",
      "epoch: 6 step: 141, loss is 0.06136645749211311\n",
      "epoch: 6 step: 142, loss is 1.484211315982975e-05\n",
      "epoch: 6 step: 143, loss is 0.07366723567247391\n",
      "epoch: 6 step: 144, loss is 0.0004986533895134926\n",
      "epoch: 6 step: 145, loss is 0.0014232613611966372\n",
      "epoch: 6 step: 146, loss is 0.0013412450207397342\n",
      "epoch: 6 step: 147, loss is 0.0012816390953958035\n",
      "epoch: 6 step: 148, loss is 7.398578600259498e-05\n",
      "epoch: 6 step: 149, loss is 0.0006916048587299883\n",
      "epoch: 6 step: 150, loss is 0.0003335115034133196\n",
      "epoch: 6 step: 151, loss is 0.00010708074842114002\n",
      "epoch: 6 step: 152, loss is 0.017543017864227295\n",
      "epoch: 6 step: 153, loss is 0.001673392252996564\n",
      "epoch: 6 step: 154, loss is 0.0013345233164727688\n",
      "epoch: 6 step: 155, loss is 0.14187973737716675\n",
      "epoch: 6 step: 156, loss is 0.007371002808213234\n",
      "epoch: 6 step: 157, loss is 0.003230780130252242\n",
      "epoch: 6 step: 158, loss is 0.1777467578649521\n",
      "epoch: 6 step: 159, loss is 0.00031800178112462163\n",
      "epoch: 6 step: 160, loss is 0.004606918897479773\n",
      "epoch: 6 step: 161, loss is 0.00019229279132559896\n",
      "epoch: 6 step: 162, loss is 0.00015598032041452825\n",
      "epoch: 6 step: 163, loss is 0.0015855238307267427\n",
      "epoch: 6 step: 164, loss is 6.714832852594554e-05\n",
      "epoch: 6 step: 165, loss is 0.00902064424008131\n",
      "epoch: 6 step: 166, loss is 0.0026452788151800632\n",
      "epoch: 6 step: 167, loss is 0.03364424407482147\n",
      "epoch: 6 step: 168, loss is 0.003282333491370082\n",
      "epoch: 6 step: 169, loss is 0.0001321624149568379\n",
      "epoch: 6 step: 170, loss is 0.0006249355501495302\n",
      "epoch: 6 step: 171, loss is 0.003556344425305724\n",
      "epoch: 6 step: 172, loss is 0.0419236458837986\n",
      "epoch: 6 step: 173, loss is 0.011893409304320812\n",
      "epoch: 6 step: 174, loss is 0.04538608342409134\n",
      "epoch: 6 step: 175, loss is 0.05435942858457565\n",
      "epoch: 6 step: 176, loss is 0.0013796923449262977\n",
      "epoch: 6 step: 177, loss is 4.405898289405741e-05\n",
      "epoch: 6 step: 178, loss is 0.0009796315571293235\n",
      "epoch: 6 step: 179, loss is 0.07558237016201019\n",
      "epoch: 6 step: 180, loss is 0.0028192331083118916\n",
      "epoch: 6 step: 181, loss is 0.0036609643138945103\n",
      "epoch: 6 step: 182, loss is 0.0013333118986338377\n",
      "epoch: 6 step: 183, loss is 0.00028346534236334264\n",
      "epoch: 6 step: 184, loss is 0.007240215316414833\n",
      "epoch: 6 step: 185, loss is 0.025152141228318214\n",
      "epoch: 6 step: 186, loss is 0.0007779868901707232\n",
      "epoch: 6 step: 187, loss is 0.0005666693905368447\n",
      "epoch: 6 step: 188, loss is 0.00355683546513319\n",
      "epoch: 6 step: 189, loss is 0.016665097326040268\n",
      "epoch: 6 step: 190, loss is 0.0003165441448800266\n",
      "epoch: 6 step: 191, loss is 0.0186738520860672\n",
      "epoch: 6 step: 192, loss is 0.0003394894301891327\n",
      "epoch: 6 step: 193, loss is 0.0028767953626811504\n",
      "epoch: 6 step: 194, loss is 0.0014597333502024412\n",
      "epoch: 6 step: 195, loss is 0.021034471690654755\n",
      "epoch: 6 step: 196, loss is 0.0012341664405539632\n",
      "epoch: 6 step: 197, loss is 0.00018348947924096137\n",
      "epoch: 6 step: 198, loss is 0.010032699443399906\n",
      "epoch: 6 step: 199, loss is 0.03936660289764404\n",
      "epoch: 6 step: 200, loss is 0.0006231252336874604\n",
      "epoch: 6 step: 201, loss is 0.03121558390557766\n",
      "epoch: 6 step: 202, loss is 3.732014010893181e-05\n",
      "epoch: 6 step: 203, loss is 0.014299849979579449\n",
      "epoch: 6 step: 204, loss is 0.010081039741635323\n",
      "epoch: 6 step: 205, loss is 0.006578194908797741\n",
      "epoch: 6 step: 206, loss is 0.0032447604462504387\n",
      "epoch: 6 step: 207, loss is 0.03474947810173035\n",
      "epoch: 6 step: 208, loss is 0.009046238847076893\n",
      "epoch: 6 step: 209, loss is 0.018102379515767097\n",
      "epoch: 6 step: 210, loss is 5.55043516214937e-05\n",
      "epoch: 6 step: 211, loss is 0.0005934903165325522\n",
      "epoch: 6 step: 212, loss is 2.067348214040976e-05\n",
      "epoch: 6 step: 213, loss is 0.06687188893556595\n",
      "epoch: 6 step: 214, loss is 0.0006678328500129282\n",
      "epoch: 6 step: 215, loss is 0.033806998282670975\n",
      "epoch: 6 step: 216, loss is 0.00045434755156747997\n",
      "epoch: 6 step: 217, loss is 0.003585086902603507\n",
      "epoch: 6 step: 218, loss is 0.005033324472606182\n",
      "epoch: 6 step: 219, loss is 0.0004927800036966801\n",
      "epoch: 6 step: 220, loss is 0.00012001700815744698\n",
      "epoch: 6 step: 221, loss is 0.048738181591033936\n",
      "epoch: 6 step: 222, loss is 0.0012595504522323608\n",
      "epoch: 6 step: 223, loss is 0.07887270301580429\n",
      "epoch: 6 step: 224, loss is 0.052545297890901566\n",
      "epoch: 6 step: 225, loss is 0.00029737773002125323\n",
      "epoch: 6 step: 226, loss is 0.017746184021234512\n",
      "epoch: 6 step: 227, loss is 0.00045426757424138486\n",
      "epoch: 6 step: 228, loss is 7.585890125483274e-05\n",
      "epoch: 6 step: 229, loss is 0.0031582240480929613\n",
      "epoch: 6 step: 230, loss is 0.0003198578779119998\n",
      "epoch: 6 step: 231, loss is 0.004189408849924803\n",
      "epoch: 6 step: 232, loss is 0.000838397303596139\n",
      "epoch: 6 step: 233, loss is 0.0009451634832657874\n",
      "epoch: 6 step: 234, loss is 0.0001859480544226244\n",
      "epoch: 6 step: 235, loss is 0.010549831204116344\n",
      "epoch: 6 step: 236, loss is 0.1389409303665161\n",
      "epoch: 6 step: 237, loss is 0.0014218940632417798\n",
      "epoch: 6 step: 238, loss is 0.0001991056778933853\n",
      "epoch: 6 step: 239, loss is 0.12000424414873123\n",
      "epoch: 6 step: 240, loss is 4.8063309805002064e-05\n",
      "epoch: 6 step: 241, loss is 0.0009009484201669693\n",
      "epoch: 6 step: 242, loss is 0.00048097388935275376\n",
      "epoch: 6 step: 243, loss is 0.017503712326288223\n",
      "epoch: 6 step: 244, loss is 0.115729920566082\n",
      "epoch: 6 step: 245, loss is 0.06755942851305008\n",
      "epoch: 6 step: 246, loss is 0.008012419566512108\n",
      "epoch: 6 step: 247, loss is 0.02679910697042942\n",
      "epoch: 6 step: 248, loss is 0.0020064169075340033\n",
      "epoch: 6 step: 249, loss is 0.0004997450159862638\n",
      "epoch: 6 step: 250, loss is 0.06971750408411026\n",
      "epoch: 6 step: 251, loss is 0.0001786157808965072\n",
      "epoch: 6 step: 252, loss is 0.0003311290347483009\n",
      "epoch: 6 step: 253, loss is 0.04589967802166939\n",
      "epoch: 6 step: 254, loss is 0.0011669908417388797\n",
      "epoch: 6 step: 255, loss is 0.10378368198871613\n",
      "epoch: 6 step: 256, loss is 0.00439696479588747\n",
      "epoch: 6 step: 257, loss is 0.0030753675382584333\n",
      "epoch: 6 step: 258, loss is 0.012748250737786293\n",
      "epoch: 6 step: 259, loss is 5.705053263227455e-05\n",
      "epoch: 6 step: 260, loss is 0.006939768325537443\n",
      "epoch: 6 step: 261, loss is 0.007114684674888849\n",
      "epoch: 6 step: 262, loss is 0.0767650306224823\n",
      "epoch: 6 step: 263, loss is 0.00019894061551894993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 264, loss is 0.05515401065349579\n",
      "epoch: 6 step: 265, loss is 0.00043640975491143763\n",
      "epoch: 6 step: 266, loss is 0.1547662615776062\n",
      "epoch: 6 step: 267, loss is 0.013439705595374107\n",
      "epoch: 6 step: 268, loss is 0.07623131573200226\n",
      "epoch: 6 step: 269, loss is 0.030623584985733032\n",
      "epoch: 6 step: 270, loss is 0.034196995198726654\n",
      "epoch: 6 step: 271, loss is 0.004545324016362429\n",
      "epoch: 6 step: 272, loss is 0.0018969121156260371\n",
      "epoch: 6 step: 273, loss is 0.011675454676151276\n",
      "epoch: 6 step: 274, loss is 0.0011868015863001347\n",
      "epoch: 6 step: 275, loss is 0.011396916583180428\n",
      "epoch: 6 step: 276, loss is 0.00031347075127996504\n",
      "epoch: 6 step: 277, loss is 0.005161077715456486\n",
      "epoch: 6 step: 278, loss is 0.00010258281690767035\n",
      "epoch: 6 step: 279, loss is 0.09328874200582504\n",
      "epoch: 6 step: 280, loss is 0.17703025043010712\n",
      "epoch: 6 step: 281, loss is 0.0036179404705762863\n",
      "epoch: 6 step: 282, loss is 0.00504701305180788\n",
      "epoch: 6 step: 283, loss is 0.0021534778643399477\n",
      "epoch: 6 step: 284, loss is 0.00016487471293658018\n",
      "epoch: 6 step: 285, loss is 0.15411710739135742\n",
      "epoch: 6 step: 286, loss is 0.007651252206414938\n",
      "epoch: 6 step: 287, loss is 0.04474041983485222\n",
      "epoch: 6 step: 288, loss is 0.00017690955428406596\n",
      "epoch: 6 step: 289, loss is 0.000809205521363765\n",
      "epoch: 6 step: 290, loss is 0.00038816023152321577\n",
      "epoch: 6 step: 291, loss is 0.0042683822102844715\n",
      "epoch: 6 step: 292, loss is 0.2215900421142578\n",
      "epoch: 6 step: 293, loss is 0.002691625850275159\n",
      "epoch: 6 step: 294, loss is 0.0026505901478230953\n",
      "epoch: 6 step: 295, loss is 0.0018972293473780155\n",
      "epoch: 6 step: 296, loss is 0.08754117786884308\n",
      "epoch: 6 step: 297, loss is 0.005175562109798193\n",
      "epoch: 6 step: 298, loss is 0.007729490287601948\n",
      "epoch: 6 step: 299, loss is 0.020771749317646027\n",
      "epoch: 6 step: 300, loss is 0.0008446325082331896\n",
      "epoch: 6 step: 301, loss is 0.006890155840665102\n",
      "epoch: 6 step: 302, loss is 0.01593398116528988\n",
      "epoch: 6 step: 303, loss is 0.0004728565691038966\n",
      "epoch: 6 step: 304, loss is 0.004106930922716856\n",
      "epoch: 6 step: 305, loss is 0.0006331056356430054\n",
      "epoch: 6 step: 306, loss is 0.11371192336082458\n",
      "epoch: 6 step: 307, loss is 0.0027554293628782034\n",
      "epoch: 6 step: 308, loss is 0.01819963939487934\n",
      "epoch: 6 step: 309, loss is 0.0017109316540881991\n",
      "epoch: 6 step: 310, loss is 0.0014276562724262476\n",
      "epoch: 6 step: 311, loss is 0.03724316507577896\n",
      "epoch: 6 step: 312, loss is 0.008935365825891495\n",
      "epoch: 6 step: 313, loss is 0.003472551004961133\n",
      "epoch: 6 step: 314, loss is 0.01286392379552126\n",
      "epoch: 6 step: 315, loss is 0.32455381751060486\n",
      "epoch: 6 step: 316, loss is 0.00024321644741576165\n",
      "epoch: 6 step: 317, loss is 0.0004117543576285243\n",
      "epoch: 6 step: 318, loss is 0.03838286176323891\n",
      "epoch: 6 step: 319, loss is 0.039389751851558685\n",
      "epoch: 6 step: 320, loss is 0.00026149663608521223\n",
      "epoch: 6 step: 321, loss is 0.03809627890586853\n",
      "epoch: 6 step: 322, loss is 0.10217045992612839\n",
      "epoch: 6 step: 323, loss is 0.0018408781616017222\n",
      "epoch: 6 step: 324, loss is 0.06152022257447243\n",
      "epoch: 6 step: 325, loss is 0.09398926794528961\n",
      "epoch: 6 step: 326, loss is 0.008822165429592133\n",
      "epoch: 6 step: 327, loss is 0.037362705916166306\n",
      "epoch: 6 step: 328, loss is 0.044710464775562286\n",
      "epoch: 6 step: 329, loss is 0.004095085430890322\n",
      "epoch: 6 step: 330, loss is 0.006328817922621965\n",
      "epoch: 6 step: 331, loss is 0.0011136200046166778\n",
      "epoch: 6 step: 332, loss is 0.011770106852054596\n",
      "epoch: 6 step: 333, loss is 0.003009202191606164\n",
      "epoch: 6 step: 334, loss is 0.1398703008890152\n",
      "epoch: 6 step: 335, loss is 0.019811293110251427\n",
      "epoch: 6 step: 336, loss is 0.02315688505768776\n",
      "epoch: 6 step: 337, loss is 0.0027226919773966074\n",
      "epoch: 6 step: 338, loss is 0.0003117548767477274\n",
      "epoch: 6 step: 339, loss is 0.040721263736486435\n",
      "epoch: 6 step: 340, loss is 0.023742347955703735\n",
      "epoch: 6 step: 341, loss is 0.0003063652548007667\n",
      "epoch: 6 step: 342, loss is 0.01260882057249546\n",
      "epoch: 6 step: 343, loss is 0.001725469483062625\n",
      "epoch: 6 step: 344, loss is 0.034820057451725006\n",
      "epoch: 6 step: 345, loss is 0.01278721448034048\n",
      "epoch: 6 step: 346, loss is 0.0006333680357784033\n",
      "epoch: 6 step: 347, loss is 0.011075833812355995\n",
      "epoch: 6 step: 348, loss is 0.0007700062706135213\n",
      "epoch: 6 step: 349, loss is 0.011124802753329277\n",
      "epoch: 6 step: 350, loss is 0.004923325963318348\n",
      "epoch: 6 step: 351, loss is 0.00021801564435008913\n",
      "epoch: 6 step: 352, loss is 0.0013887924142181873\n",
      "epoch: 6 step: 353, loss is 0.0015108983498066664\n",
      "epoch: 6 step: 354, loss is 0.00046720169484615326\n",
      "epoch: 6 step: 355, loss is 0.006183489225804806\n",
      "epoch: 6 step: 356, loss is 0.0012733959592878819\n",
      "epoch: 6 step: 357, loss is 0.10219284892082214\n",
      "epoch: 6 step: 358, loss is 0.0002780549111776054\n",
      "epoch: 6 step: 359, loss is 0.0005283762002363801\n",
      "epoch: 6 step: 360, loss is 0.0032280830200761557\n",
      "epoch: 6 step: 361, loss is 0.0021286492701619864\n",
      "epoch: 6 step: 362, loss is 0.049704257398843765\n",
      "epoch: 6 step: 363, loss is 0.004401123151183128\n",
      "epoch: 6 step: 364, loss is 0.008401017636060715\n",
      "epoch: 6 step: 365, loss is 0.14350350201129913\n",
      "epoch: 6 step: 366, loss is 0.015686534345149994\n",
      "epoch: 6 step: 367, loss is 0.023168982937932014\n",
      "epoch: 6 step: 368, loss is 0.02555938810110092\n",
      "epoch: 6 step: 369, loss is 0.011733403429389\n",
      "epoch: 6 step: 370, loss is 0.004593740217387676\n",
      "epoch: 6 step: 371, loss is 0.0019860328175127506\n",
      "epoch: 6 step: 372, loss is 0.00022819297737441957\n",
      "epoch: 6 step: 373, loss is 0.018547091633081436\n",
      "epoch: 6 step: 374, loss is 0.005691065452992916\n",
      "epoch: 6 step: 375, loss is 0.15040546655654907\n",
      "epoch: 6 step: 376, loss is 0.006251527927815914\n",
      "epoch: 6 step: 377, loss is 0.009460476227104664\n",
      "epoch: 6 step: 378, loss is 0.05345696210861206\n",
      "epoch: 6 step: 379, loss is 0.0005542995641008019\n",
      "epoch: 6 step: 380, loss is 0.09174815565347672\n",
      "epoch: 6 step: 381, loss is 6.451116496464238e-05\n",
      "epoch: 6 step: 382, loss is 0.0017544985748827457\n",
      "epoch: 6 step: 383, loss is 0.0005924823926761746\n",
      "epoch: 6 step: 384, loss is 0.0007508780108764768\n",
      "epoch: 6 step: 385, loss is 0.0006150169647298753\n",
      "epoch: 6 step: 386, loss is 0.0007600590470246971\n",
      "epoch: 6 step: 387, loss is 0.010282222181558609\n",
      "epoch: 6 step: 388, loss is 0.038249872624874115\n",
      "epoch: 6 step: 389, loss is 0.00020815509196836501\n",
      "epoch: 6 step: 390, loss is 0.017420224845409393\n",
      "epoch: 6 step: 391, loss is 0.005806583911180496\n",
      "epoch: 6 step: 392, loss is 0.12421394884586334\n",
      "epoch: 6 step: 393, loss is 0.000654869363643229\n",
      "epoch: 6 step: 394, loss is 0.002099899807944894\n",
      "epoch: 6 step: 395, loss is 0.00024640513584017754\n",
      "epoch: 6 step: 396, loss is 0.01209544949233532\n",
      "epoch: 6 step: 397, loss is 0.0005384669057093561\n",
      "epoch: 6 step: 398, loss is 0.01052374392747879\n",
      "epoch: 6 step: 399, loss is 0.017485739663243294\n",
      "epoch: 6 step: 400, loss is 0.001107558375224471\n",
      "epoch: 6 step: 401, loss is 0.08245430886745453\n",
      "epoch: 6 step: 402, loss is 0.0004428850661497563\n",
      "epoch: 6 step: 403, loss is 0.0006698655779473484\n",
      "epoch: 6 step: 404, loss is 0.0038696120027452707\n",
      "epoch: 6 step: 405, loss is 0.01720227301120758\n",
      "epoch: 6 step: 406, loss is 0.002418121788650751\n",
      "epoch: 6 step: 407, loss is 0.002710753120481968\n",
      "epoch: 6 step: 408, loss is 0.01170096080750227\n",
      "epoch: 6 step: 409, loss is 0.0031590107828378677\n",
      "epoch: 6 step: 410, loss is 0.16702498495578766\n",
      "epoch: 6 step: 411, loss is 0.0003860565775539726\n",
      "epoch: 6 step: 412, loss is 0.0034066676162183285\n",
      "epoch: 6 step: 413, loss is 3.3013529900927097e-05\n",
      "epoch: 6 step: 414, loss is 0.04966123774647713\n",
      "epoch: 6 step: 415, loss is 0.005475544836372137\n",
      "epoch: 6 step: 416, loss is 0.10373064130544662\n",
      "epoch: 6 step: 417, loss is 0.00011020985402865335\n",
      "epoch: 6 step: 418, loss is 0.0313531719148159\n",
      "epoch: 6 step: 419, loss is 0.00033751490991562605\n",
      "epoch: 6 step: 420, loss is 0.04863286018371582\n",
      "epoch: 6 step: 421, loss is 0.0005998341366648674\n",
      "epoch: 6 step: 422, loss is 0.006847325246781111\n",
      "epoch: 6 step: 423, loss is 0.00017787283286452293\n",
      "epoch: 6 step: 424, loss is 0.09130575507879257\n",
      "epoch: 6 step: 425, loss is 0.008008635602891445\n",
      "epoch: 6 step: 426, loss is 0.01042217668145895\n",
      "epoch: 6 step: 427, loss is 0.02044891193509102\n",
      "epoch: 6 step: 428, loss is 9.50695393839851e-05\n",
      "epoch: 6 step: 429, loss is 0.001976171974092722\n",
      "epoch: 6 step: 430, loss is 0.004178384318947792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 431, loss is 0.0043802689760923386\n",
      "epoch: 6 step: 432, loss is 0.011942184530198574\n",
      "epoch: 6 step: 433, loss is 0.007147309370338917\n",
      "epoch: 6 step: 434, loss is 0.020548410713672638\n",
      "epoch: 6 step: 435, loss is 0.0006144419894553721\n",
      "epoch: 6 step: 436, loss is 0.001495671458542347\n",
      "epoch: 6 step: 437, loss is 0.06043655425310135\n",
      "epoch: 6 step: 438, loss is 0.01241485308855772\n",
      "epoch: 6 step: 439, loss is 0.002484402619302273\n",
      "epoch: 6 step: 440, loss is 0.002011893317103386\n",
      "epoch: 6 step: 441, loss is 0.008371192961931229\n",
      "epoch: 6 step: 442, loss is 0.001504305168054998\n",
      "epoch: 6 step: 443, loss is 0.0017501042457297444\n",
      "epoch: 6 step: 444, loss is 0.1906982809305191\n",
      "epoch: 6 step: 445, loss is 0.07445881515741348\n",
      "epoch: 6 step: 446, loss is 0.0006979210302233696\n",
      "epoch: 6 step: 447, loss is 0.07242599874734879\n",
      "epoch: 6 step: 448, loss is 0.0014822317752987146\n",
      "epoch: 6 step: 449, loss is 0.0034406865015625954\n",
      "epoch: 6 step: 450, loss is 4.3807929614558816e-05\n",
      "epoch: 6 step: 451, loss is 0.02625197544693947\n",
      "epoch: 6 step: 452, loss is 0.03138105943799019\n",
      "epoch: 6 step: 453, loss is 0.0078031099401414394\n",
      "epoch: 6 step: 454, loss is 0.0010465526720508933\n",
      "epoch: 6 step: 455, loss is 0.06218283250927925\n",
      "epoch: 6 step: 456, loss is 0.040124040096998215\n",
      "epoch: 6 step: 457, loss is 0.002958016935735941\n",
      "epoch: 6 step: 458, loss is 0.0009558324818499386\n",
      "epoch: 6 step: 459, loss is 0.024813968688249588\n",
      "epoch: 6 step: 460, loss is 0.0019175027264282107\n",
      "epoch: 6 step: 461, loss is 0.0027984606567770243\n",
      "epoch: 6 step: 462, loss is 0.0012899520806968212\n",
      "epoch: 6 step: 463, loss is 0.00012560162576846778\n",
      "epoch: 6 step: 464, loss is 0.07173413038253784\n",
      "epoch: 6 step: 465, loss is 0.0005497679812833667\n",
      "epoch: 6 step: 466, loss is 0.00012128188245696947\n",
      "epoch: 6 step: 467, loss is 0.0030672831926494837\n",
      "epoch: 6 step: 468, loss is 0.0013426764635369182\n",
      "epoch: 6 step: 469, loss is 0.06284183263778687\n",
      "epoch: 6 step: 470, loss is 0.0005599093856289983\n",
      "epoch: 6 step: 471, loss is 0.0010553878964856267\n",
      "epoch: 6 step: 472, loss is 0.00038105319254100323\n",
      "epoch: 6 step: 473, loss is 0.10303962230682373\n",
      "epoch: 6 step: 474, loss is 0.0005443781265057623\n",
      "epoch: 6 step: 475, loss is 0.002249601762741804\n",
      "epoch: 6 step: 476, loss is 4.229508340358734e-05\n",
      "epoch: 6 step: 477, loss is 0.00014970224583521485\n",
      "epoch: 6 step: 478, loss is 0.08646968007087708\n",
      "epoch: 6 step: 479, loss is 0.007569226436316967\n",
      "epoch: 6 step: 480, loss is 0.001279380638152361\n",
      "epoch: 6 step: 481, loss is 0.014992104843258858\n",
      "epoch: 6 step: 482, loss is 0.17750369012355804\n",
      "epoch: 6 step: 483, loss is 0.0008187099010683596\n",
      "epoch: 6 step: 484, loss is 0.00042251177364960313\n",
      "epoch: 6 step: 485, loss is 0.0019982634112238884\n",
      "epoch: 6 step: 486, loss is 0.000774452171754092\n",
      "epoch: 6 step: 487, loss is 0.01417104434221983\n",
      "epoch: 6 step: 488, loss is 0.0012124739587306976\n",
      "epoch: 6 step: 489, loss is 0.0535736009478569\n",
      "epoch: 6 step: 490, loss is 4.835195795749314e-05\n",
      "epoch: 6 step: 491, loss is 0.001938417088240385\n",
      "epoch: 6 step: 492, loss is 0.03182139992713928\n",
      "epoch: 6 step: 493, loss is 0.004885478876531124\n",
      "epoch: 6 step: 494, loss is 0.024287356063723564\n",
      "epoch: 6 step: 495, loss is 0.022513659670948982\n",
      "epoch: 6 step: 496, loss is 0.0028649240266531706\n",
      "epoch: 6 step: 497, loss is 0.0042144907638430595\n",
      "epoch: 6 step: 498, loss is 0.0172526054084301\n",
      "epoch: 6 step: 499, loss is 0.0067662266083061695\n",
      "epoch: 6 step: 500, loss is 0.005909640807658434\n",
      "epoch: 6 step: 501, loss is 0.004122493788599968\n",
      "epoch: 6 step: 502, loss is 0.0021133015397936106\n",
      "epoch: 6 step: 503, loss is 5.536614480661228e-05\n",
      "epoch: 6 step: 504, loss is 0.00025090755661949515\n",
      "epoch: 6 step: 505, loss is 0.0011062676785513759\n",
      "epoch: 6 step: 506, loss is 0.0002672488917596638\n",
      "epoch: 6 step: 507, loss is 0.0023239548318088055\n",
      "epoch: 6 step: 508, loss is 0.0012430566130205989\n",
      "epoch: 6 step: 509, loss is 0.008763515390455723\n",
      "epoch: 6 step: 510, loss is 0.00040359230479225516\n",
      "epoch: 6 step: 511, loss is 0.00024810631293803453\n",
      "epoch: 6 step: 512, loss is 0.0033453532960265875\n",
      "epoch: 6 step: 513, loss is 0.032492078840732574\n",
      "epoch: 6 step: 514, loss is 0.004792789928615093\n",
      "epoch: 6 step: 515, loss is 0.0027309192810207605\n",
      "epoch: 6 step: 516, loss is 0.0007684067240916193\n",
      "epoch: 6 step: 517, loss is 0.00013189933088142425\n",
      "epoch: 6 step: 518, loss is 0.00014216986892279238\n",
      "epoch: 6 step: 519, loss is 0.039140734821558\n",
      "epoch: 6 step: 520, loss is 0.0006188878905959427\n",
      "epoch: 6 step: 521, loss is 6.109325477154925e-05\n",
      "epoch: 6 step: 522, loss is 0.003202492371201515\n",
      "epoch: 6 step: 523, loss is 4.9180998757947236e-05\n",
      "epoch: 6 step: 524, loss is 0.00033428461756557226\n",
      "epoch: 6 step: 525, loss is 0.21651825308799744\n",
      "epoch: 6 step: 526, loss is 0.0018304630648344755\n",
      "epoch: 6 step: 527, loss is 0.004725063219666481\n",
      "epoch: 6 step: 528, loss is 0.08289841562509537\n",
      "epoch: 6 step: 529, loss is 0.003595677437260747\n",
      "epoch: 6 step: 530, loss is 0.12897375226020813\n",
      "epoch: 6 step: 531, loss is 0.0010436685988679528\n",
      "epoch: 6 step: 532, loss is 0.00021938436839263886\n",
      "epoch: 6 step: 533, loss is 0.00237827654927969\n",
      "epoch: 6 step: 534, loss is 7.44155840948224e-05\n",
      "epoch: 6 step: 535, loss is 0.00019215296197216958\n",
      "epoch: 6 step: 536, loss is 0.0008621541783213615\n",
      "epoch: 6 step: 537, loss is 0.01074892096221447\n",
      "epoch: 6 step: 538, loss is 0.0031923006754368544\n",
      "epoch: 6 step: 539, loss is 0.000711871893145144\n",
      "epoch: 6 step: 540, loss is 0.06183929741382599\n",
      "epoch: 6 step: 541, loss is 0.022669248282909393\n",
      "epoch: 6 step: 542, loss is 0.0022812443785369396\n",
      "epoch: 6 step: 543, loss is 0.015318701043725014\n",
      "epoch: 6 step: 544, loss is 0.03960246965289116\n",
      "epoch: 6 step: 545, loss is 0.00020930026948917657\n",
      "epoch: 6 step: 546, loss is 0.0003187033871654421\n",
      "epoch: 6 step: 547, loss is 0.015152708627283573\n",
      "epoch: 6 step: 548, loss is 0.0019204289419576526\n",
      "epoch: 6 step: 549, loss is 0.005740758962929249\n",
      "epoch: 6 step: 550, loss is 0.0008145798346959054\n",
      "epoch: 6 step: 551, loss is 0.08061524480581284\n",
      "epoch: 6 step: 552, loss is 0.0014094465877860785\n",
      "epoch: 6 step: 553, loss is 0.003309400985017419\n",
      "epoch: 6 step: 554, loss is 0.003503254381939769\n",
      "epoch: 6 step: 555, loss is 0.0029852879233658314\n",
      "epoch: 6 step: 556, loss is 0.094630166888237\n",
      "epoch: 6 step: 557, loss is 0.2825242578983307\n",
      "epoch: 6 step: 558, loss is 0.00019174649787601084\n",
      "epoch: 6 step: 559, loss is 9.245909313904122e-05\n",
      "epoch: 6 step: 560, loss is 0.052808646112680435\n",
      "epoch: 6 step: 561, loss is 0.03445987030863762\n",
      "epoch: 6 step: 562, loss is 0.0007436062442138791\n",
      "epoch: 6 step: 563, loss is 0.008321573957800865\n",
      "epoch: 6 step: 564, loss is 0.014054108411073685\n",
      "epoch: 6 step: 565, loss is 0.0028259640093892813\n",
      "epoch: 6 step: 566, loss is 0.0012201715726405382\n",
      "epoch: 6 step: 567, loss is 0.0008302775677293539\n",
      "epoch: 6 step: 568, loss is 0.0022014095447957516\n",
      "epoch: 6 step: 569, loss is 0.06954898685216904\n",
      "epoch: 6 step: 570, loss is 0.03479141741991043\n",
      "epoch: 6 step: 571, loss is 0.0004982365062460303\n",
      "epoch: 6 step: 572, loss is 0.012471118941903114\n",
      "epoch: 6 step: 573, loss is 0.010850317776203156\n",
      "epoch: 6 step: 574, loss is 0.00038372419658116996\n",
      "epoch: 6 step: 575, loss is 0.030880901962518692\n",
      "epoch: 6 step: 576, loss is 0.018321674317121506\n",
      "epoch: 6 step: 577, loss is 0.2637902498245239\n",
      "epoch: 6 step: 578, loss is 0.0007571371970698237\n",
      "epoch: 6 step: 579, loss is 0.0032347317319363356\n",
      "epoch: 6 step: 580, loss is 0.03209581598639488\n",
      "epoch: 6 step: 581, loss is 0.001626842305995524\n",
      "epoch: 6 step: 582, loss is 0.0004422398342285305\n",
      "epoch: 6 step: 583, loss is 0.019153323024511337\n",
      "epoch: 6 step: 584, loss is 0.0096137635409832\n",
      "epoch: 6 step: 585, loss is 0.03638741374015808\n",
      "epoch: 6 step: 586, loss is 0.21022158861160278\n",
      "epoch: 6 step: 587, loss is 0.013474185019731522\n",
      "epoch: 6 step: 588, loss is 0.002412404865026474\n",
      "epoch: 6 step: 589, loss is 0.0005430743331089616\n",
      "epoch: 6 step: 590, loss is 0.0002474052016623318\n",
      "epoch: 6 step: 591, loss is 0.00018089885998051614\n",
      "epoch: 6 step: 592, loss is 0.0034150558058172464\n",
      "epoch: 6 step: 593, loss is 0.0008861428359523416\n",
      "epoch: 6 step: 594, loss is 0.016179993748664856\n",
      "epoch: 6 step: 595, loss is 0.010139967314898968\n",
      "epoch: 6 step: 596, loss is 0.001906233956106007\n",
      "epoch: 6 step: 597, loss is 0.058239758014678955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 598, loss is 0.023782355710864067\n",
      "epoch: 6 step: 599, loss is 0.10155247896909714\n",
      "epoch: 6 step: 600, loss is 0.006430500652641058\n",
      "epoch: 6 step: 601, loss is 0.04844170808792114\n",
      "epoch: 6 step: 602, loss is 0.001370635349303484\n",
      "epoch: 6 step: 603, loss is 0.0004967778804711998\n",
      "epoch: 6 step: 604, loss is 0.1406586915254593\n",
      "epoch: 6 step: 605, loss is 0.00010708665649872273\n",
      "epoch: 6 step: 606, loss is 0.01499185711145401\n",
      "epoch: 6 step: 607, loss is 0.0019870614632964134\n",
      "epoch: 6 step: 608, loss is 0.0015692997258156538\n",
      "epoch: 6 step: 609, loss is 0.0530841089785099\n",
      "epoch: 6 step: 610, loss is 0.01779266819357872\n",
      "epoch: 6 step: 611, loss is 0.012051754631102085\n",
      "epoch: 6 step: 612, loss is 0.0056890505366027355\n",
      "epoch: 6 step: 613, loss is 0.012853538617491722\n",
      "epoch: 6 step: 614, loss is 0.007920215837657452\n",
      "epoch: 6 step: 615, loss is 0.006413882132619619\n",
      "epoch: 6 step: 616, loss is 0.0007221066043712199\n",
      "epoch: 6 step: 617, loss is 0.0015030470676720142\n",
      "epoch: 6 step: 618, loss is 0.0030371397733688354\n",
      "epoch: 6 step: 619, loss is 0.0005786622641608119\n",
      "epoch: 6 step: 620, loss is 0.0002884749264921993\n",
      "epoch: 6 step: 621, loss is 0.0024424989242106676\n",
      "epoch: 6 step: 622, loss is 0.03666877746582031\n",
      "epoch: 6 step: 623, loss is 0.0009894343093037605\n",
      "epoch: 6 step: 624, loss is 0.012274167500436306\n",
      "epoch: 6 step: 625, loss is 0.12061024457216263\n",
      "epoch: 6 step: 626, loss is 0.07090479135513306\n",
      "epoch: 6 step: 627, loss is 0.0024303069803863764\n",
      "epoch: 6 step: 628, loss is 0.07271258533000946\n",
      "epoch: 6 step: 629, loss is 0.018367264419794083\n",
      "epoch: 6 step: 630, loss is 0.004348967224359512\n",
      "epoch: 6 step: 631, loss is 0.006212611682713032\n",
      "epoch: 6 step: 632, loss is 0.004130078945308924\n",
      "epoch: 6 step: 633, loss is 0.008189069107174873\n",
      "epoch: 6 step: 634, loss is 0.009734043851494789\n",
      "epoch: 6 step: 635, loss is 0.005903568584471941\n",
      "epoch: 6 step: 636, loss is 0.011144387535750866\n",
      "epoch: 6 step: 637, loss is 0.0003756046062335372\n",
      "epoch: 6 step: 638, loss is 0.02200961299240589\n",
      "epoch: 6 step: 639, loss is 0.0011050866451114416\n",
      "epoch: 6 step: 640, loss is 0.000483205309137702\n",
      "epoch: 6 step: 641, loss is 0.08928334712982178\n",
      "epoch: 6 step: 642, loss is 0.022277848795056343\n",
      "epoch: 6 step: 643, loss is 0.00124836852774024\n",
      "epoch: 6 step: 644, loss is 0.014718006365001202\n",
      "epoch: 6 step: 645, loss is 0.0015057220589369535\n",
      "epoch: 6 step: 646, loss is 0.024296747520565987\n",
      "epoch: 6 step: 647, loss is 0.0006175515009090304\n",
      "epoch: 6 step: 648, loss is 0.00027881914866156876\n",
      "epoch: 6 step: 649, loss is 0.0001677915279287845\n",
      "epoch: 6 step: 650, loss is 0.0007209227769635618\n",
      "epoch: 6 step: 651, loss is 0.008847001940011978\n",
      "epoch: 6 step: 652, loss is 0.00046296956134028733\n",
      "epoch: 6 step: 653, loss is 0.011687313206493855\n",
      "epoch: 6 step: 654, loss is 0.05729714408516884\n",
      "epoch: 6 step: 655, loss is 0.004607051610946655\n",
      "epoch: 6 step: 656, loss is 0.00023248746583703905\n",
      "epoch: 6 step: 657, loss is 0.020566415041685104\n",
      "epoch: 6 step: 658, loss is 0.00016958020569290966\n",
      "epoch: 6 step: 659, loss is 0.0006082985200919211\n",
      "epoch: 6 step: 660, loss is 0.00012682647502515465\n",
      "epoch: 6 step: 661, loss is 0.006543813273310661\n",
      "epoch: 6 step: 662, loss is 0.011908300220966339\n",
      "epoch: 6 step: 663, loss is 0.125568225979805\n",
      "epoch: 6 step: 664, loss is 0.09877163171768188\n",
      "epoch: 6 step: 665, loss is 0.012274406850337982\n",
      "epoch: 6 step: 666, loss is 0.036083757877349854\n",
      "epoch: 6 step: 667, loss is 0.0010405763750895858\n",
      "epoch: 6 step: 668, loss is 0.0060780467465519905\n",
      "epoch: 6 step: 669, loss is 0.003892553271725774\n",
      "epoch: 6 step: 670, loss is 0.01771433651447296\n",
      "epoch: 6 step: 671, loss is 0.002963337581604719\n",
      "epoch: 6 step: 672, loss is 0.008323661983013153\n",
      "epoch: 6 step: 673, loss is 0.010679446160793304\n",
      "epoch: 6 step: 674, loss is 4.43137287220452e-05\n",
      "epoch: 6 step: 675, loss is 0.011402111500501633\n",
      "epoch: 6 step: 676, loss is 0.13370457291603088\n",
      "epoch: 6 step: 677, loss is 0.0005614717956632376\n",
      "epoch: 6 step: 678, loss is 0.0002287774987053126\n",
      "epoch: 6 step: 679, loss is 0.0004169500607531518\n",
      "epoch: 6 step: 680, loss is 0.052181895822286606\n",
      "epoch: 6 step: 681, loss is 0.043699540197849274\n",
      "epoch: 6 step: 682, loss is 0.020812539383769035\n",
      "epoch: 6 step: 683, loss is 0.0032443501986563206\n",
      "epoch: 6 step: 684, loss is 0.0052498397417366505\n",
      "epoch: 6 step: 685, loss is 0.028141092509031296\n",
      "epoch: 6 step: 686, loss is 0.0001045056851580739\n",
      "epoch: 6 step: 687, loss is 0.013588236644864082\n",
      "epoch: 6 step: 688, loss is 0.007227037567645311\n",
      "epoch: 6 step: 689, loss is 0.009633422829210758\n",
      "epoch: 6 step: 690, loss is 0.005635169800370932\n",
      "epoch: 6 step: 691, loss is 0.007752582430839539\n",
      "epoch: 6 step: 692, loss is 0.05578099563717842\n",
      "epoch: 6 step: 693, loss is 0.07290242612361908\n",
      "epoch: 6 step: 694, loss is 0.0015738680958747864\n",
      "epoch: 6 step: 695, loss is 0.010089247487485409\n",
      "epoch: 6 step: 696, loss is 0.12934640049934387\n",
      "epoch: 6 step: 697, loss is 0.011424707248806953\n",
      "epoch: 6 step: 698, loss is 0.013018541038036346\n",
      "epoch: 6 step: 699, loss is 0.0007203748682513833\n",
      "epoch: 6 step: 700, loss is 0.0013240814441815019\n",
      "epoch: 6 step: 701, loss is 0.0005237839068286121\n",
      "epoch: 6 step: 702, loss is 0.0011391752632334828\n",
      "epoch: 6 step: 703, loss is 0.00469785975292325\n",
      "epoch: 6 step: 704, loss is 0.03563655540347099\n",
      "epoch: 6 step: 705, loss is 0.1190628781914711\n",
      "epoch: 6 step: 706, loss is 0.09348969906568527\n",
      "epoch: 6 step: 707, loss is 0.08021555095911026\n",
      "epoch: 6 step: 708, loss is 0.0038274433463811874\n",
      "epoch: 6 step: 709, loss is 0.0002683255879674107\n",
      "epoch: 6 step: 710, loss is 0.0034076704178005457\n",
      "epoch: 6 step: 711, loss is 0.0006695993361063302\n",
      "epoch: 6 step: 712, loss is 0.022901102900505066\n",
      "epoch: 6 step: 713, loss is 0.04020247980952263\n",
      "epoch: 6 step: 714, loss is 0.0005876036593690515\n",
      "epoch: 6 step: 715, loss is 0.005650617647916079\n",
      "epoch: 6 step: 716, loss is 0.009830232709646225\n",
      "epoch: 6 step: 717, loss is 0.00803549587726593\n",
      "epoch: 6 step: 718, loss is 0.004664189647883177\n",
      "epoch: 6 step: 719, loss is 0.0010349963558837771\n",
      "epoch: 6 step: 720, loss is 0.06398455798625946\n",
      "epoch: 6 step: 721, loss is 0.005868259817361832\n",
      "epoch: 6 step: 722, loss is 7.299623393919319e-05\n",
      "epoch: 6 step: 723, loss is 0.019814016297459602\n",
      "epoch: 6 step: 724, loss is 0.07592026889324188\n",
      "epoch: 6 step: 725, loss is 0.022154664620757103\n",
      "epoch: 6 step: 726, loss is 0.008255203254520893\n",
      "epoch: 6 step: 727, loss is 0.00852627120912075\n",
      "epoch: 6 step: 728, loss is 0.11833074688911438\n",
      "epoch: 6 step: 729, loss is 0.00053475919412449\n",
      "epoch: 6 step: 730, loss is 0.00033234705915674567\n",
      "epoch: 6 step: 731, loss is 0.15557096898555756\n",
      "epoch: 6 step: 732, loss is 0.008137316443026066\n",
      "epoch: 6 step: 733, loss is 0.0009666107944212854\n",
      "epoch: 6 step: 734, loss is 0.003685170551761985\n",
      "epoch: 6 step: 735, loss is 0.0049081165343523026\n",
      "epoch: 6 step: 736, loss is 0.06312885880470276\n",
      "epoch: 6 step: 737, loss is 0.002721860771998763\n",
      "epoch: 6 step: 738, loss is 0.0027899371925741434\n",
      "epoch: 6 step: 739, loss is 0.042430274188518524\n",
      "epoch: 6 step: 740, loss is 0.0024176205042749643\n",
      "epoch: 6 step: 741, loss is 0.010881348513066769\n",
      "epoch: 6 step: 742, loss is 0.004162202589213848\n",
      "epoch: 6 step: 743, loss is 0.06071314588189125\n",
      "epoch: 6 step: 744, loss is 0.0009900639997795224\n",
      "epoch: 6 step: 745, loss is 0.0015690360451117158\n",
      "epoch: 6 step: 746, loss is 0.009219587780535221\n",
      "epoch: 6 step: 747, loss is 0.18959490954875946\n",
      "epoch: 6 step: 748, loss is 0.002235212130472064\n",
      "epoch: 6 step: 749, loss is 0.0006293242913670838\n",
      "epoch: 6 step: 750, loss is 0.0005689404206350446\n",
      "epoch: 6 step: 751, loss is 0.016404343768954277\n",
      "epoch: 6 step: 752, loss is 0.0040885889902710915\n",
      "epoch: 6 step: 753, loss is 0.025095682591199875\n",
      "epoch: 6 step: 754, loss is 0.03074226714670658\n",
      "epoch: 6 step: 755, loss is 0.0014678320148959756\n",
      "epoch: 6 step: 756, loss is 0.0016138541977852583\n",
      "epoch: 6 step: 757, loss is 0.1732769012451172\n",
      "epoch: 6 step: 758, loss is 0.16262121498584747\n",
      "epoch: 6 step: 759, loss is 0.0012729635927826166\n",
      "epoch: 6 step: 760, loss is 0.0003720320528373122\n",
      "epoch: 6 step: 761, loss is 0.005828771740198135\n",
      "epoch: 6 step: 762, loss is 0.0030899771954864264\n",
      "epoch: 6 step: 763, loss is 0.003116206731647253\n",
      "epoch: 6 step: 764, loss is 0.03065069578588009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 765, loss is 0.09916450083255768\n",
      "epoch: 6 step: 766, loss is 0.0214563999325037\n",
      "epoch: 6 step: 767, loss is 0.00010878287866944447\n",
      "epoch: 6 step: 768, loss is 0.0031432807445526123\n",
      "epoch: 6 step: 769, loss is 0.0037705169524997473\n",
      "epoch: 6 step: 770, loss is 0.0004006297676824033\n",
      "epoch: 6 step: 771, loss is 0.1065831333398819\n",
      "epoch: 6 step: 772, loss is 0.0034300200641155243\n",
      "epoch: 6 step: 773, loss is 0.025194933637976646\n",
      "epoch: 6 step: 774, loss is 0.0026949094608426094\n",
      "epoch: 6 step: 775, loss is 0.04711446166038513\n",
      "epoch: 6 step: 776, loss is 0.0056105791591107845\n",
      "epoch: 6 step: 777, loss is 0.008449885062873363\n",
      "epoch: 6 step: 778, loss is 0.0773174837231636\n",
      "epoch: 6 step: 779, loss is 0.0029525146819651127\n",
      "epoch: 6 step: 780, loss is 0.00531220156699419\n",
      "epoch: 6 step: 781, loss is 0.0005608474602922797\n",
      "epoch: 6 step: 782, loss is 0.0008878347580321133\n",
      "epoch: 6 step: 783, loss is 0.0012247641570866108\n",
      "epoch: 6 step: 784, loss is 0.0014337495667859912\n",
      "epoch: 6 step: 785, loss is 0.001113104517571628\n",
      "epoch: 6 step: 786, loss is 0.0006775217480026186\n",
      "epoch: 6 step: 787, loss is 0.003372996812686324\n",
      "epoch: 6 step: 788, loss is 0.0010437378659844398\n",
      "epoch: 6 step: 789, loss is 0.007914268411695957\n",
      "epoch: 6 step: 790, loss is 0.0011872283648699522\n",
      "epoch: 6 step: 791, loss is 0.004165132064372301\n",
      "epoch: 6 step: 792, loss is 0.0003024192701559514\n",
      "epoch: 6 step: 793, loss is 0.01157680619508028\n",
      "epoch: 6 step: 794, loss is 0.0011986353201791644\n",
      "epoch: 6 step: 795, loss is 0.044425565749406815\n",
      "epoch: 6 step: 796, loss is 0.00044882649672217667\n",
      "epoch: 6 step: 797, loss is 0.052694860845804214\n",
      "epoch: 6 step: 798, loss is 0.038348667323589325\n",
      "epoch: 6 step: 799, loss is 0.003171399235725403\n",
      "epoch: 6 step: 800, loss is 0.007227757014334202\n",
      "epoch: 6 step: 801, loss is 0.012137552723288536\n",
      "epoch: 6 step: 802, loss is 0.008261403068900108\n",
      "epoch: 6 step: 803, loss is 0.0005211431416682899\n",
      "epoch: 6 step: 804, loss is 0.006431177724152803\n",
      "epoch: 6 step: 805, loss is 0.0021512529347091913\n",
      "epoch: 6 step: 806, loss is 0.0013528666459023952\n",
      "epoch: 6 step: 807, loss is 0.014225516468286514\n",
      "epoch: 6 step: 808, loss is 0.02174069918692112\n",
      "epoch: 6 step: 809, loss is 0.005550002679228783\n",
      "epoch: 6 step: 810, loss is 0.0008719058241695166\n",
      "epoch: 6 step: 811, loss is 0.00019471127598080784\n",
      "epoch: 6 step: 812, loss is 0.0006551587139256299\n",
      "epoch: 6 step: 813, loss is 0.008739323355257511\n",
      "epoch: 6 step: 814, loss is 0.007003748323768377\n",
      "epoch: 6 step: 815, loss is 0.0012030372163280845\n",
      "epoch: 6 step: 816, loss is 0.00115635572001338\n",
      "epoch: 6 step: 817, loss is 0.007404864765703678\n",
      "epoch: 6 step: 818, loss is 0.026377256959676743\n",
      "epoch: 6 step: 819, loss is 0.0011968630133196712\n",
      "epoch: 6 step: 820, loss is 0.027350932359695435\n",
      "epoch: 6 step: 821, loss is 8.929346222430468e-05\n",
      "epoch: 6 step: 822, loss is 0.0005266807856969535\n",
      "epoch: 6 step: 823, loss is 0.0004467392573133111\n",
      "epoch: 6 step: 824, loss is 0.001086386851966381\n",
      "epoch: 6 step: 825, loss is 0.04281369224190712\n",
      "epoch: 6 step: 826, loss is 0.007282630540430546\n",
      "epoch: 6 step: 827, loss is 0.1362893432378769\n",
      "epoch: 6 step: 828, loss is 0.0009303658152930439\n",
      "epoch: 6 step: 829, loss is 0.06000662222504616\n",
      "epoch: 6 step: 830, loss is 0.01916820928454399\n",
      "epoch: 6 step: 831, loss is 0.002469778759405017\n",
      "epoch: 6 step: 832, loss is 0.018603762611746788\n",
      "epoch: 6 step: 833, loss is 0.0031216463539749384\n",
      "epoch: 6 step: 834, loss is 0.10153655707836151\n",
      "epoch: 6 step: 835, loss is 0.0006997042219154537\n",
      "epoch: 6 step: 836, loss is 0.003369380719959736\n",
      "epoch: 6 step: 837, loss is 0.00014897763321641833\n",
      "epoch: 6 step: 838, loss is 0.002791664795950055\n",
      "epoch: 6 step: 839, loss is 0.015338472090661526\n",
      "epoch: 6 step: 840, loss is 0.017909567803144455\n",
      "epoch: 6 step: 841, loss is 0.005050022155046463\n",
      "epoch: 6 step: 842, loss is 0.0006273488397710025\n",
      "epoch: 6 step: 843, loss is 0.003986021038144827\n",
      "epoch: 6 step: 844, loss is 0.1092846691608429\n",
      "epoch: 6 step: 845, loss is 4.6806213504169136e-05\n",
      "epoch: 6 step: 846, loss is 0.00029331305995583534\n",
      "epoch: 6 step: 847, loss is 0.0013182430993765593\n",
      "epoch: 6 step: 848, loss is 1.4119485967967194e-05\n",
      "epoch: 6 step: 849, loss is 0.0034011416137218475\n",
      "epoch: 6 step: 850, loss is 0.10702991485595703\n",
      "epoch: 6 step: 851, loss is 0.0006473992834798992\n",
      "epoch: 6 step: 852, loss is 0.0003079232410527766\n",
      "epoch: 6 step: 853, loss is 0.022134041413664818\n",
      "epoch: 6 step: 854, loss is 7.772001845296472e-05\n",
      "epoch: 6 step: 855, loss is 0.1161234974861145\n",
      "epoch: 6 step: 856, loss is 0.01212820690125227\n",
      "epoch: 6 step: 857, loss is 0.036798540502786636\n",
      "epoch: 6 step: 858, loss is 0.026997586712241173\n",
      "epoch: 6 step: 859, loss is 0.008681105449795723\n",
      "epoch: 6 step: 860, loss is 0.0025509896222501993\n",
      "epoch: 6 step: 861, loss is 0.04566827043890953\n",
      "epoch: 6 step: 862, loss is 0.00015747660654596984\n",
      "epoch: 6 step: 863, loss is 0.0023084941785782576\n",
      "epoch: 6 step: 864, loss is 9.320470417151228e-05\n",
      "epoch: 6 step: 865, loss is 0.008217651396989822\n",
      "epoch: 6 step: 866, loss is 0.05756453052163124\n",
      "epoch: 6 step: 867, loss is 0.006761210039258003\n",
      "epoch: 6 step: 868, loss is 0.00030666490783914924\n",
      "epoch: 6 step: 869, loss is 0.025777069851756096\n",
      "epoch: 6 step: 870, loss is 0.002363208681344986\n",
      "epoch: 6 step: 871, loss is 0.01684536226093769\n",
      "epoch: 6 step: 872, loss is 0.0027131515089422464\n",
      "epoch: 6 step: 873, loss is 0.0007752255187369883\n",
      "epoch: 6 step: 874, loss is 0.00508534349501133\n",
      "epoch: 6 step: 875, loss is 0.0004609604075085372\n",
      "epoch: 6 step: 876, loss is 0.00010047811520053074\n",
      "epoch: 6 step: 877, loss is 0.0028010811656713486\n",
      "epoch: 6 step: 878, loss is 0.003311475971713662\n",
      "epoch: 6 step: 879, loss is 0.0028557106852531433\n",
      "epoch: 6 step: 880, loss is 0.012047858908772469\n",
      "epoch: 6 step: 881, loss is 0.006872010882943869\n",
      "epoch: 6 step: 882, loss is 0.005106092896312475\n",
      "epoch: 6 step: 883, loss is 0.0009475405677221715\n",
      "epoch: 6 step: 884, loss is 0.01613433286547661\n",
      "epoch: 6 step: 885, loss is 0.016668401658535004\n",
      "epoch: 6 step: 886, loss is 0.011767938733100891\n",
      "epoch: 6 step: 887, loss is 0.005176234990358353\n",
      "epoch: 6 step: 888, loss is 0.0008790182764641941\n",
      "epoch: 6 step: 889, loss is 0.0019474830478429794\n",
      "epoch: 6 step: 890, loss is 0.00010500123607926071\n",
      "epoch: 6 step: 891, loss is 0.00019151966262143105\n",
      "epoch: 6 step: 892, loss is 0.14727890491485596\n",
      "epoch: 6 step: 893, loss is 0.004895064979791641\n",
      "epoch: 6 step: 894, loss is 0.01077321171760559\n",
      "epoch: 6 step: 895, loss is 0.005055894143879414\n",
      "epoch: 6 step: 896, loss is 0.0027966764755547047\n",
      "epoch: 6 step: 897, loss is 0.0017978270770981908\n",
      "epoch: 6 step: 898, loss is 0.0014064224669709802\n",
      "epoch: 6 step: 899, loss is 0.02277444489300251\n",
      "epoch: 6 step: 900, loss is 0.001783131156116724\n",
      "epoch: 6 step: 901, loss is 0.12153548002243042\n",
      "epoch: 6 step: 902, loss is 0.0028113857842981815\n",
      "epoch: 6 step: 903, loss is 0.00023900925589259714\n",
      "epoch: 6 step: 904, loss is 0.0009486803319305182\n",
      "epoch: 6 step: 905, loss is 0.08973678201436996\n",
      "epoch: 6 step: 906, loss is 3.849912900477648e-05\n",
      "epoch: 6 step: 907, loss is 0.03828159719705582\n",
      "epoch: 6 step: 908, loss is 0.02319798246026039\n",
      "epoch: 6 step: 909, loss is 0.004698449280112982\n",
      "epoch: 6 step: 910, loss is 0.0008591520600020885\n",
      "epoch: 6 step: 911, loss is 0.019812582060694695\n",
      "epoch: 6 step: 912, loss is 4.8872803745325655e-05\n",
      "epoch: 6 step: 913, loss is 0.033173490315675735\n",
      "epoch: 6 step: 914, loss is 0.018733996897935867\n",
      "epoch: 6 step: 915, loss is 0.0002614968689158559\n",
      "epoch: 6 step: 916, loss is 0.06442909687757492\n",
      "epoch: 6 step: 917, loss is 0.0004744778561871499\n",
      "epoch: 6 step: 918, loss is 0.0041035315953195095\n",
      "epoch: 6 step: 919, loss is 0.0022073457948863506\n",
      "epoch: 6 step: 920, loss is 0.0006775620277039707\n",
      "epoch: 6 step: 921, loss is 0.005263858009129763\n",
      "epoch: 6 step: 922, loss is 0.044638581573963165\n",
      "epoch: 6 step: 923, loss is 0.04046853631734848\n",
      "epoch: 6 step: 924, loss is 0.0008317818865180016\n",
      "epoch: 6 step: 925, loss is 0.00027524802135303617\n",
      "epoch: 6 step: 926, loss is 0.0002848446019925177\n",
      "epoch: 6 step: 927, loss is 0.00015467537741642445\n",
      "epoch: 6 step: 928, loss is 0.0013609265442937613\n",
      "epoch: 6 step: 929, loss is 0.006073188968002796\n",
      "epoch: 6 step: 930, loss is 0.0037660461384803057\n",
      "epoch: 6 step: 931, loss is 2.965258499898482e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 932, loss is 0.0005363494856283069\n",
      "epoch: 6 step: 933, loss is 0.017933476716279984\n",
      "epoch: 6 step: 934, loss is 0.00013468465476762503\n",
      "epoch: 6 step: 935, loss is 0.03505619615316391\n",
      "epoch: 6 step: 936, loss is 0.0005470272735692561\n",
      "epoch: 6 step: 937, loss is 0.0019694920629262924\n",
      "epoch: 6 step: 938, loss is 0.00014494160132016987\n",
      "epoch: 6 step: 939, loss is 0.003572799265384674\n",
      "epoch: 6 step: 940, loss is 0.00034534247242845595\n",
      "epoch: 6 step: 941, loss is 0.0004522491944953799\n",
      "epoch: 6 step: 942, loss is 0.005352908279746771\n",
      "epoch: 6 step: 943, loss is 0.03567750006914139\n",
      "epoch: 6 step: 944, loss is 0.0015641044592484832\n",
      "epoch: 6 step: 945, loss is 0.0029932919424027205\n",
      "epoch: 6 step: 946, loss is 0.012211035005748272\n",
      "epoch: 6 step: 947, loss is 0.0006407481851056218\n",
      "epoch: 6 step: 948, loss is 0.0006160723860375583\n",
      "epoch: 6 step: 949, loss is 0.0008356171892955899\n",
      "epoch: 6 step: 950, loss is 0.0024233346339315176\n",
      "epoch: 6 step: 951, loss is 0.00010158165969187394\n",
      "epoch: 6 step: 952, loss is 0.0034195708576589823\n",
      "epoch: 6 step: 953, loss is 0.0002920088591054082\n",
      "epoch: 6 step: 954, loss is 2.908352507802192e-05\n",
      "epoch: 6 step: 955, loss is 0.006461771205067635\n",
      "epoch: 6 step: 956, loss is 0.01249662321060896\n",
      "epoch: 6 step: 957, loss is 9.208088158629835e-05\n",
      "epoch: 6 step: 958, loss is 0.0001627219025976956\n",
      "epoch: 6 step: 959, loss is 0.00034169034915976226\n",
      "epoch: 6 step: 960, loss is 0.0064279246143996716\n",
      "epoch: 6 step: 961, loss is 0.001339384471066296\n",
      "epoch: 6 step: 962, loss is 0.0009359515970572829\n",
      "epoch: 6 step: 963, loss is 0.07763274013996124\n",
      "epoch: 6 step: 964, loss is 0.0396137498319149\n",
      "epoch: 6 step: 965, loss is 0.145894855260849\n",
      "epoch: 6 step: 966, loss is 0.0005600645090453327\n",
      "epoch: 6 step: 967, loss is 0.004531421698629856\n",
      "epoch: 6 step: 968, loss is 0.00032511926838196814\n",
      "epoch: 6 step: 969, loss is 0.003245655447244644\n",
      "epoch: 6 step: 970, loss is 7.427508535329252e-05\n",
      "epoch: 6 step: 971, loss is 0.0022798923309892416\n",
      "epoch: 6 step: 972, loss is 0.0001731147785903886\n",
      "epoch: 6 step: 973, loss is 0.009705941192805767\n",
      "epoch: 6 step: 974, loss is 0.0008099687402136624\n",
      "epoch: 6 step: 975, loss is 6.363763532135636e-05\n",
      "epoch: 6 step: 976, loss is 0.010388555005192757\n",
      "epoch: 6 step: 977, loss is 0.06498316675424576\n",
      "epoch: 6 step: 978, loss is 0.00047918836935423315\n",
      "epoch: 6 step: 979, loss is 0.00012327914009802043\n",
      "epoch: 6 step: 980, loss is 0.02665708214044571\n",
      "epoch: 6 step: 981, loss is 0.0003451306838542223\n",
      "epoch: 6 step: 982, loss is 0.00012919881555717438\n",
      "epoch: 6 step: 983, loss is 0.0008283136994577944\n",
      "epoch: 6 step: 984, loss is 0.006327836308628321\n",
      "epoch: 6 step: 985, loss is 0.0006075858836993575\n",
      "epoch: 6 step: 986, loss is 0.0020117193926125765\n",
      "epoch: 6 step: 987, loss is 0.002051240997388959\n",
      "epoch: 6 step: 988, loss is 0.07648171484470367\n",
      "epoch: 6 step: 989, loss is 0.001189746311865747\n",
      "epoch: 6 step: 990, loss is 0.00037624628748744726\n",
      "epoch: 6 step: 991, loss is 8.178936695912853e-05\n",
      "epoch: 6 step: 992, loss is 0.00638157082721591\n",
      "epoch: 6 step: 993, loss is 0.000787243596278131\n",
      "epoch: 6 step: 994, loss is 0.002815954852849245\n",
      "epoch: 6 step: 995, loss is 0.008155576884746552\n",
      "epoch: 6 step: 996, loss is 0.008394233882427216\n",
      "epoch: 6 step: 997, loss is 0.032188814133405685\n",
      "epoch: 6 step: 998, loss is 0.0005968048935756087\n",
      "epoch: 6 step: 999, loss is 0.00039903889410197735\n",
      "epoch: 6 step: 1000, loss is 0.03616437688469887\n",
      "epoch: 6 step: 1001, loss is 0.04879356920719147\n",
      "epoch: 6 step: 1002, loss is 0.005272789858281612\n",
      "epoch: 6 step: 1003, loss is 0.013176788575947285\n",
      "epoch: 6 step: 1004, loss is 0.009472551755607128\n",
      "epoch: 6 step: 1005, loss is 0.04093189537525177\n",
      "epoch: 6 step: 1006, loss is 0.049625180661678314\n",
      "epoch: 6 step: 1007, loss is 1.6547539416933432e-05\n",
      "epoch: 6 step: 1008, loss is 0.018939731642603874\n",
      "epoch: 6 step: 1009, loss is 0.0034706536680459976\n",
      "epoch: 6 step: 1010, loss is 0.13384127616882324\n",
      "epoch: 6 step: 1011, loss is 0.008810666389763355\n",
      "epoch: 6 step: 1012, loss is 0.00508774584159255\n",
      "epoch: 6 step: 1013, loss is 0.0003233911993447691\n",
      "epoch: 6 step: 1014, loss is 0.013539373874664307\n",
      "epoch: 6 step: 1015, loss is 0.013472282327711582\n",
      "epoch: 6 step: 1016, loss is 0.0001227621833095327\n",
      "epoch: 6 step: 1017, loss is 0.0013554025208577514\n",
      "epoch: 6 step: 1018, loss is 0.001449105329811573\n",
      "epoch: 6 step: 1019, loss is 0.017400385811924934\n",
      "epoch: 6 step: 1020, loss is 0.002238882938399911\n",
      "epoch: 6 step: 1021, loss is 0.016956398263573647\n",
      "epoch: 6 step: 1022, loss is 0.00041239510755985975\n",
      "epoch: 6 step: 1023, loss is 3.440168802626431e-05\n",
      "epoch: 6 step: 1024, loss is 0.027461163699626923\n",
      "epoch: 6 step: 1025, loss is 0.00034954064176417887\n",
      "epoch: 6 step: 1026, loss is 0.04395649954676628\n",
      "epoch: 6 step: 1027, loss is 0.129041388630867\n",
      "epoch: 6 step: 1028, loss is 0.03817076236009598\n",
      "epoch: 6 step: 1029, loss is 0.03568216785788536\n",
      "epoch: 6 step: 1030, loss is 0.0011224456829950213\n",
      "epoch: 6 step: 1031, loss is 0.0014294191496446729\n",
      "epoch: 6 step: 1032, loss is 0.0053001451306045055\n",
      "epoch: 6 step: 1033, loss is 1.5265239198924974e-05\n",
      "epoch: 6 step: 1034, loss is 0.04183834418654442\n",
      "epoch: 6 step: 1035, loss is 0.0010665800655260682\n",
      "epoch: 6 step: 1036, loss is 0.034183673560619354\n",
      "epoch: 6 step: 1037, loss is 0.0016678499523550272\n",
      "epoch: 6 step: 1038, loss is 0.0003821177233476192\n",
      "epoch: 6 step: 1039, loss is 0.012456302531063557\n",
      "epoch: 6 step: 1040, loss is 8.304804214276373e-05\n",
      "epoch: 6 step: 1041, loss is 0.02175135351717472\n",
      "epoch: 6 step: 1042, loss is 0.0008947263122536242\n",
      "epoch: 6 step: 1043, loss is 0.001938653877004981\n",
      "epoch: 6 step: 1044, loss is 0.09499674290418625\n",
      "epoch: 6 step: 1045, loss is 0.0007215948426164687\n",
      "epoch: 6 step: 1046, loss is 0.022769104689359665\n",
      "epoch: 6 step: 1047, loss is 0.16485822200775146\n",
      "epoch: 6 step: 1048, loss is 0.0023877075873315334\n",
      "epoch: 6 step: 1049, loss is 2.3821525246603414e-05\n",
      "epoch: 6 step: 1050, loss is 0.001633055624552071\n",
      "epoch: 6 step: 1051, loss is 0.03560902550816536\n",
      "epoch: 6 step: 1052, loss is 0.002175569301471114\n",
      "epoch: 6 step: 1053, loss is 0.22327269613742828\n",
      "epoch: 6 step: 1054, loss is 0.012566177174448967\n",
      "epoch: 6 step: 1055, loss is 0.0070287929847836494\n",
      "epoch: 6 step: 1056, loss is 0.008240018971264362\n",
      "epoch: 6 step: 1057, loss is 0.009713306091725826\n",
      "epoch: 6 step: 1058, loss is 0.052403632551431656\n",
      "epoch: 6 step: 1059, loss is 0.05860811471939087\n",
      "epoch: 6 step: 1060, loss is 0.0015303759137168527\n",
      "epoch: 6 step: 1061, loss is 0.16636066138744354\n",
      "epoch: 6 step: 1062, loss is 0.0014652576064690948\n",
      "epoch: 6 step: 1063, loss is 0.20434395968914032\n",
      "epoch: 6 step: 1064, loss is 0.007632284890860319\n",
      "epoch: 6 step: 1065, loss is 0.20845694839954376\n",
      "epoch: 6 step: 1066, loss is 0.006101509556174278\n",
      "epoch: 6 step: 1067, loss is 0.0018441701540723443\n",
      "epoch: 6 step: 1068, loss is 0.08466336131095886\n",
      "epoch: 6 step: 1069, loss is 0.0003823194419965148\n",
      "epoch: 6 step: 1070, loss is 0.0006642937078140676\n",
      "epoch: 6 step: 1071, loss is 0.013457716442644596\n",
      "epoch: 6 step: 1072, loss is 0.009816224686801434\n",
      "epoch: 6 step: 1073, loss is 0.026013825088739395\n",
      "epoch: 6 step: 1074, loss is 0.001757846213877201\n",
      "epoch: 6 step: 1075, loss is 0.051015034317970276\n",
      "epoch: 6 step: 1076, loss is 0.004648631904274225\n",
      "epoch: 6 step: 1077, loss is 0.000596625788602978\n",
      "epoch: 6 step: 1078, loss is 0.0005176553386263549\n",
      "epoch: 6 step: 1079, loss is 0.0002586250484455377\n",
      "epoch: 6 step: 1080, loss is 0.0011389157734811306\n",
      "epoch: 6 step: 1081, loss is 0.015104744583368301\n",
      "epoch: 6 step: 1082, loss is 0.034916382282972336\n",
      "epoch: 6 step: 1083, loss is 0.00794162880629301\n",
      "epoch: 6 step: 1084, loss is 0.010715672746300697\n",
      "epoch: 6 step: 1085, loss is 0.009341510944068432\n",
      "epoch: 6 step: 1086, loss is 0.0075351158156991005\n",
      "epoch: 6 step: 1087, loss is 0.00860476866364479\n",
      "epoch: 6 step: 1088, loss is 9.629283886170015e-05\n",
      "epoch: 6 step: 1089, loss is 0.0013161925598978996\n",
      "epoch: 6 step: 1090, loss is 0.02023189701139927\n",
      "epoch: 6 step: 1091, loss is 0.0013423159252852201\n",
      "epoch: 6 step: 1092, loss is 0.02614631876349449\n",
      "epoch: 6 step: 1093, loss is 0.022765591740608215\n",
      "epoch: 6 step: 1094, loss is 0.0005401796079240739\n",
      "epoch: 6 step: 1095, loss is 0.14888931810855865\n",
      "epoch: 6 step: 1096, loss is 0.018010014668107033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1097, loss is 0.0003976905718445778\n",
      "epoch: 6 step: 1098, loss is 0.058530647307634354\n",
      "epoch: 6 step: 1099, loss is 5.6497356126783416e-05\n",
      "epoch: 6 step: 1100, loss is 0.0187783595174551\n",
      "epoch: 6 step: 1101, loss is 0.002998743671923876\n",
      "epoch: 6 step: 1102, loss is 0.0002757807669695467\n",
      "epoch: 6 step: 1103, loss is 0.00026649737264961004\n",
      "epoch: 6 step: 1104, loss is 0.00014606531476601958\n",
      "epoch: 6 step: 1105, loss is 0.0005141861038282514\n",
      "epoch: 6 step: 1106, loss is 0.0011799228377640247\n",
      "epoch: 6 step: 1107, loss is 0.004724771250039339\n",
      "epoch: 6 step: 1108, loss is 0.039723873138427734\n",
      "epoch: 6 step: 1109, loss is 0.003158119274303317\n",
      "epoch: 6 step: 1110, loss is 0.0004065932589583099\n",
      "epoch: 6 step: 1111, loss is 0.010839271359145641\n",
      "epoch: 6 step: 1112, loss is 0.006409002933651209\n",
      "epoch: 6 step: 1113, loss is 0.04170304164290428\n",
      "epoch: 6 step: 1114, loss is 0.0010786782950162888\n",
      "epoch: 6 step: 1115, loss is 0.004527668468654156\n",
      "epoch: 6 step: 1116, loss is 0.00010310434299753979\n",
      "epoch: 6 step: 1117, loss is 0.014223789796233177\n",
      "epoch: 6 step: 1118, loss is 0.011198810301721096\n",
      "epoch: 6 step: 1119, loss is 0.0011694420827552676\n",
      "epoch: 6 step: 1120, loss is 0.000288930197712034\n",
      "epoch: 6 step: 1121, loss is 0.003663745941594243\n",
      "epoch: 6 step: 1122, loss is 0.009778361767530441\n",
      "epoch: 6 step: 1123, loss is 0.0020172304939478636\n",
      "epoch: 6 step: 1124, loss is 0.0002571325749158859\n",
      "epoch: 6 step: 1125, loss is 0.027601338922977448\n",
      "epoch: 6 step: 1126, loss is 0.0002887406444642693\n",
      "epoch: 6 step: 1127, loss is 0.005500368308275938\n",
      "epoch: 6 step: 1128, loss is 0.006856889463961124\n",
      "epoch: 6 step: 1129, loss is 0.0007999817607924342\n",
      "epoch: 6 step: 1130, loss is 0.00023382389917969704\n",
      "epoch: 6 step: 1131, loss is 0.0007052088039927185\n",
      "epoch: 6 step: 1132, loss is 0.005273271817713976\n",
      "epoch: 6 step: 1133, loss is 0.00019878936291206628\n",
      "epoch: 6 step: 1134, loss is 0.0002066710585495457\n",
      "epoch: 6 step: 1135, loss is 0.001118666143156588\n",
      "epoch: 6 step: 1136, loss is 0.03684215620160103\n",
      "epoch: 6 step: 1137, loss is 0.004748974926769733\n",
      "epoch: 6 step: 1138, loss is 0.0032869847491383553\n",
      "epoch: 6 step: 1139, loss is 0.005171674769371748\n",
      "epoch: 6 step: 1140, loss is 0.008000936359167099\n",
      "epoch: 6 step: 1141, loss is 0.009276368655264378\n",
      "epoch: 6 step: 1142, loss is 0.009194131940603256\n",
      "epoch: 6 step: 1143, loss is 0.00692294305190444\n",
      "epoch: 6 step: 1144, loss is 0.009729426354169846\n",
      "epoch: 6 step: 1145, loss is 0.02319900505244732\n",
      "epoch: 6 step: 1146, loss is 0.0013604604173451662\n",
      "epoch: 6 step: 1147, loss is 0.004339656792581081\n",
      "epoch: 6 step: 1148, loss is 0.00017402505909558386\n",
      "epoch: 6 step: 1149, loss is 4.188346065348014e-05\n",
      "epoch: 6 step: 1150, loss is 0.0018287530401721597\n",
      "epoch: 6 step: 1151, loss is 0.0001611767365830019\n",
      "epoch: 6 step: 1152, loss is 0.029349468648433685\n",
      "epoch: 6 step: 1153, loss is 9.949030936695635e-05\n",
      "epoch: 6 step: 1154, loss is 1.498856636317214e-05\n",
      "epoch: 6 step: 1155, loss is 0.007902484387159348\n",
      "epoch: 6 step: 1156, loss is 0.007390155456960201\n",
      "epoch: 6 step: 1157, loss is 0.003885975806042552\n",
      "epoch: 6 step: 1158, loss is 0.0030234158039093018\n",
      "epoch: 6 step: 1159, loss is 0.00217980844900012\n",
      "epoch: 6 step: 1160, loss is 0.0005932246567681432\n",
      "epoch: 6 step: 1161, loss is 0.0005618269206024706\n",
      "epoch: 6 step: 1162, loss is 0.0006885114125907421\n",
      "epoch: 6 step: 1163, loss is 0.00016850051179062575\n",
      "epoch: 6 step: 1164, loss is 0.005663954187184572\n",
      "epoch: 6 step: 1165, loss is 0.0006368581089191139\n",
      "epoch: 6 step: 1166, loss is 0.07879078388214111\n",
      "epoch: 6 step: 1167, loss is 0.00045911193592473865\n",
      "epoch: 6 step: 1168, loss is 0.000659605604596436\n",
      "epoch: 6 step: 1169, loss is 0.024394378066062927\n",
      "epoch: 6 step: 1170, loss is 0.001015783054754138\n",
      "epoch: 6 step: 1171, loss is 0.006275206338614225\n",
      "epoch: 6 step: 1172, loss is 0.005079586990177631\n",
      "epoch: 6 step: 1173, loss is 0.003118044463917613\n",
      "epoch: 6 step: 1174, loss is 0.019244780763983727\n",
      "epoch: 6 step: 1175, loss is 0.00039544622995890677\n",
      "epoch: 6 step: 1176, loss is 0.1567276269197464\n",
      "epoch: 6 step: 1177, loss is 0.0022404694464057684\n",
      "epoch: 6 step: 1178, loss is 0.021483084186911583\n",
      "epoch: 6 step: 1179, loss is 7.089648715918884e-05\n",
      "epoch: 6 step: 1180, loss is 0.02545955218374729\n",
      "epoch: 6 step: 1181, loss is 0.00038655009120702744\n",
      "epoch: 6 step: 1182, loss is 0.05381901562213898\n",
      "epoch: 6 step: 1183, loss is 0.1052846908569336\n",
      "epoch: 6 step: 1184, loss is 0.0025320693384855986\n",
      "epoch: 6 step: 1185, loss is 0.0033504958264529705\n",
      "epoch: 6 step: 1186, loss is 0.0015640000347048044\n",
      "epoch: 6 step: 1187, loss is 0.01633371412754059\n",
      "epoch: 6 step: 1188, loss is 1.1062901648983825e-05\n",
      "epoch: 6 step: 1189, loss is 0.038864996284246445\n",
      "epoch: 6 step: 1190, loss is 3.250016015954316e-05\n",
      "epoch: 6 step: 1191, loss is 0.00742205698043108\n",
      "epoch: 6 step: 1192, loss is 0.0003444908943492919\n",
      "epoch: 6 step: 1193, loss is 0.00142422947101295\n",
      "epoch: 6 step: 1194, loss is 0.03903583064675331\n",
      "epoch: 6 step: 1195, loss is 0.04157397523522377\n",
      "epoch: 6 step: 1196, loss is 0.0006201154319569468\n",
      "epoch: 6 step: 1197, loss is 0.0005403825780376792\n",
      "epoch: 6 step: 1198, loss is 9.550810500513762e-05\n",
      "epoch: 6 step: 1199, loss is 0.000507772492710501\n",
      "epoch: 6 step: 1200, loss is 0.00036533144884742796\n",
      "epoch: 6 step: 1201, loss is 0.03220526501536369\n",
      "epoch: 6 step: 1202, loss is 5.997743573971093e-05\n",
      "epoch: 6 step: 1203, loss is 0.0001073557577910833\n",
      "epoch: 6 step: 1204, loss is 0.3005184531211853\n",
      "epoch: 6 step: 1205, loss is 0.00010069687414215878\n",
      "epoch: 6 step: 1206, loss is 0.001194137497805059\n",
      "epoch: 6 step: 1207, loss is 0.019564401358366013\n",
      "epoch: 6 step: 1208, loss is 2.8491136617958546e-05\n",
      "epoch: 6 step: 1209, loss is 0.0007600999670103192\n",
      "epoch: 6 step: 1210, loss is 0.0017348801484331489\n",
      "epoch: 6 step: 1211, loss is 0.00013741386646870524\n",
      "epoch: 6 step: 1212, loss is 0.00909555796533823\n",
      "epoch: 6 step: 1213, loss is 0.0026165901217609644\n",
      "epoch: 6 step: 1214, loss is 0.0012865468161180615\n",
      "epoch: 6 step: 1215, loss is 0.03886574134230614\n",
      "epoch: 6 step: 1216, loss is 0.008169624023139477\n",
      "epoch: 6 step: 1217, loss is 0.006911910139024258\n",
      "epoch: 6 step: 1218, loss is 0.0032631848007440567\n",
      "epoch: 6 step: 1219, loss is 0.005784659646451473\n",
      "epoch: 6 step: 1220, loss is 0.0005125789903104305\n",
      "epoch: 6 step: 1221, loss is 0.12983734905719757\n",
      "epoch: 6 step: 1222, loss is 0.0005023232661187649\n",
      "epoch: 6 step: 1223, loss is 0.0006042111781425774\n",
      "epoch: 6 step: 1224, loss is 0.2087344080209732\n",
      "epoch: 6 step: 1225, loss is 0.06162406876683235\n",
      "epoch: 6 step: 1226, loss is 0.00010438075696583837\n",
      "epoch: 6 step: 1227, loss is 0.0012675324687734246\n",
      "epoch: 6 step: 1228, loss is 0.07196716964244843\n",
      "epoch: 6 step: 1229, loss is 0.0064553082920610905\n",
      "epoch: 6 step: 1230, loss is 0.005158351268619299\n",
      "epoch: 6 step: 1231, loss is 0.0035738961305469275\n",
      "epoch: 6 step: 1232, loss is 0.023452114313840866\n",
      "epoch: 6 step: 1233, loss is 0.00013106886763125658\n",
      "epoch: 6 step: 1234, loss is 0.00012307790166232735\n",
      "epoch: 6 step: 1235, loss is 0.0035924986004829407\n",
      "epoch: 6 step: 1236, loss is 0.0641256794333458\n",
      "epoch: 6 step: 1237, loss is 0.00010613298218231648\n",
      "epoch: 6 step: 1238, loss is 0.038889359682798386\n",
      "epoch: 6 step: 1239, loss is 0.3538263142108917\n",
      "epoch: 6 step: 1240, loss is 0.0013081826036795974\n",
      "epoch: 6 step: 1241, loss is 0.004022903740406036\n",
      "epoch: 6 step: 1242, loss is 0.01795010268688202\n",
      "epoch: 6 step: 1243, loss is 0.018500905483961105\n",
      "epoch: 6 step: 1244, loss is 0.0016904837684705853\n",
      "epoch: 6 step: 1245, loss is 0.031339287757873535\n",
      "epoch: 6 step: 1246, loss is 0.13376225531101227\n",
      "epoch: 6 step: 1247, loss is 0.006031057797372341\n",
      "epoch: 6 step: 1248, loss is 0.002528153592720628\n",
      "epoch: 6 step: 1249, loss is 0.00724647706374526\n",
      "epoch: 6 step: 1250, loss is 0.040552545338869095\n",
      "epoch: 6 step: 1251, loss is 0.0012272491585463285\n",
      "epoch: 6 step: 1252, loss is 0.011879026889801025\n",
      "epoch: 6 step: 1253, loss is 0.027223126962780952\n",
      "epoch: 6 step: 1254, loss is 0.021660007536411285\n",
      "epoch: 6 step: 1255, loss is 0.0022731448989361525\n",
      "epoch: 6 step: 1256, loss is 0.01430011261254549\n",
      "epoch: 6 step: 1257, loss is 0.00014999260019976646\n",
      "epoch: 6 step: 1258, loss is 0.015208806842565536\n",
      "epoch: 6 step: 1259, loss is 0.131352037191391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1260, loss is 0.008246202021837234\n",
      "epoch: 6 step: 1261, loss is 0.08796371519565582\n",
      "epoch: 6 step: 1262, loss is 0.09617379307746887\n",
      "epoch: 6 step: 1263, loss is 0.00011922145495191216\n",
      "epoch: 6 step: 1264, loss is 0.017609702423214912\n",
      "epoch: 6 step: 1265, loss is 0.008073361590504646\n",
      "epoch: 6 step: 1266, loss is 0.005299510434269905\n",
      "epoch: 6 step: 1267, loss is 0.010249961167573929\n",
      "epoch: 6 step: 1268, loss is 0.0005612664390355349\n",
      "epoch: 6 step: 1269, loss is 0.000220859597902745\n",
      "epoch: 6 step: 1270, loss is 0.0002763147640507668\n",
      "epoch: 6 step: 1271, loss is 0.0007788603543303907\n",
      "epoch: 6 step: 1272, loss is 0.0001748076465446502\n",
      "epoch: 6 step: 1273, loss is 0.004087656736373901\n",
      "epoch: 6 step: 1274, loss is 0.000248286611167714\n",
      "epoch: 6 step: 1275, loss is 0.003456728532910347\n",
      "epoch: 6 step: 1276, loss is 0.0004697756958194077\n",
      "epoch: 6 step: 1277, loss is 0.06255431473255157\n",
      "epoch: 6 step: 1278, loss is 0.0025910555850714445\n",
      "epoch: 6 step: 1279, loss is 0.00566431600600481\n",
      "epoch: 6 step: 1280, loss is 0.011406941339373589\n",
      "epoch: 6 step: 1281, loss is 0.0012793679488822818\n",
      "epoch: 6 step: 1282, loss is 0.002126839943230152\n",
      "epoch: 6 step: 1283, loss is 0.12815403938293457\n",
      "epoch: 6 step: 1284, loss is 0.005817362107336521\n",
      "epoch: 6 step: 1285, loss is 0.001824295031838119\n",
      "epoch: 6 step: 1286, loss is 0.026387671008706093\n",
      "epoch: 6 step: 1287, loss is 0.003977976273745298\n",
      "epoch: 6 step: 1288, loss is 0.005117662716656923\n",
      "epoch: 6 step: 1289, loss is 0.0034587187692523003\n",
      "epoch: 6 step: 1290, loss is 0.07699649780988693\n",
      "epoch: 6 step: 1291, loss is 0.11151742935180664\n",
      "epoch: 6 step: 1292, loss is 0.007442852482199669\n",
      "epoch: 6 step: 1293, loss is 0.1011379212141037\n",
      "epoch: 6 step: 1294, loss is 0.002520860405638814\n",
      "epoch: 6 step: 1295, loss is 0.00047992978943511844\n",
      "epoch: 6 step: 1296, loss is 0.0725787803530693\n",
      "epoch: 6 step: 1297, loss is 0.003314028726890683\n",
      "epoch: 6 step: 1298, loss is 0.0009929741499945521\n",
      "epoch: 6 step: 1299, loss is 0.007028523366898298\n",
      "epoch: 6 step: 1300, loss is 0.002375194802880287\n",
      "epoch: 6 step: 1301, loss is 0.05117179825901985\n",
      "epoch: 6 step: 1302, loss is 0.03523074835538864\n",
      "epoch: 6 step: 1303, loss is 0.019792161881923676\n",
      "epoch: 6 step: 1304, loss is 0.004737639334052801\n",
      "epoch: 6 step: 1305, loss is 0.0010392609983682632\n",
      "epoch: 6 step: 1306, loss is 0.0019192032050341368\n",
      "epoch: 6 step: 1307, loss is 0.03516869992017746\n",
      "epoch: 6 step: 1308, loss is 0.005601769313216209\n",
      "epoch: 6 step: 1309, loss is 6.030002987245098e-05\n",
      "epoch: 6 step: 1310, loss is 0.007396349683403969\n",
      "epoch: 6 step: 1311, loss is 0.14803540706634521\n",
      "epoch: 6 step: 1312, loss is 0.017846139147877693\n",
      "epoch: 6 step: 1313, loss is 0.05895555391907692\n",
      "epoch: 6 step: 1314, loss is 0.00991051271557808\n",
      "epoch: 6 step: 1315, loss is 0.00609159329906106\n",
      "epoch: 6 step: 1316, loss is 0.0001229182817041874\n",
      "epoch: 6 step: 1317, loss is 0.0009487076895311475\n",
      "epoch: 6 step: 1318, loss is 0.07034724205732346\n",
      "epoch: 6 step: 1319, loss is 0.0016348109347745776\n",
      "epoch: 6 step: 1320, loss is 0.002009265124797821\n",
      "epoch: 6 step: 1321, loss is 0.020986974239349365\n",
      "epoch: 6 step: 1322, loss is 0.0040394640527665615\n",
      "epoch: 6 step: 1323, loss is 0.2524767518043518\n",
      "epoch: 6 step: 1324, loss is 6.928243965376168e-05\n",
      "epoch: 6 step: 1325, loss is 0.004299205262213945\n",
      "epoch: 6 step: 1326, loss is 0.010213165543973446\n",
      "epoch: 6 step: 1327, loss is 0.00011444871051935479\n",
      "epoch: 6 step: 1328, loss is 0.10374701768159866\n",
      "epoch: 6 step: 1329, loss is 0.09258850663900375\n",
      "epoch: 6 step: 1330, loss is 0.0020541702397167683\n",
      "epoch: 6 step: 1331, loss is 0.0010879503097385168\n",
      "epoch: 6 step: 1332, loss is 0.0735013484954834\n",
      "epoch: 6 step: 1333, loss is 0.004702417645603418\n",
      "epoch: 6 step: 1334, loss is 0.0012592258863151073\n",
      "epoch: 6 step: 1335, loss is 0.00014022596587892622\n",
      "epoch: 6 step: 1336, loss is 0.005448988638818264\n",
      "epoch: 6 step: 1337, loss is 0.001211863593198359\n",
      "epoch: 6 step: 1338, loss is 0.14057505130767822\n",
      "epoch: 6 step: 1339, loss is 0.023241451010107994\n",
      "epoch: 6 step: 1340, loss is 0.0883515328168869\n",
      "epoch: 6 step: 1341, loss is 0.011223312467336655\n",
      "epoch: 6 step: 1342, loss is 0.00077168078860268\n",
      "epoch: 6 step: 1343, loss is 0.00528777576982975\n",
      "epoch: 6 step: 1344, loss is 0.006747440434992313\n",
      "epoch: 6 step: 1345, loss is 0.005174849182367325\n",
      "epoch: 6 step: 1346, loss is 0.08679764717817307\n",
      "epoch: 6 step: 1347, loss is 0.003626856952905655\n",
      "epoch: 6 step: 1348, loss is 0.04691634327173233\n",
      "epoch: 6 step: 1349, loss is 0.0183483324944973\n",
      "epoch: 6 step: 1350, loss is 0.0009155412553809583\n",
      "epoch: 6 step: 1351, loss is 0.025926340371370316\n",
      "epoch: 6 step: 1352, loss is 0.013871151022613049\n",
      "epoch: 6 step: 1353, loss is 0.00939927063882351\n",
      "epoch: 6 step: 1354, loss is 0.1556350141763687\n",
      "epoch: 6 step: 1355, loss is 0.019590994343161583\n",
      "epoch: 6 step: 1356, loss is 0.0009453704115003347\n",
      "epoch: 6 step: 1357, loss is 0.013818987645208836\n",
      "epoch: 6 step: 1358, loss is 0.0140631552785635\n",
      "epoch: 6 step: 1359, loss is 0.0023911618627607822\n",
      "epoch: 6 step: 1360, loss is 0.00040075407014228404\n",
      "epoch: 6 step: 1361, loss is 0.0018909653881564736\n",
      "epoch: 6 step: 1362, loss is 0.00029285799246281385\n",
      "epoch: 6 step: 1363, loss is 0.0008497170056216419\n",
      "epoch: 6 step: 1364, loss is 0.0052551645785570145\n",
      "epoch: 6 step: 1365, loss is 0.03695567324757576\n",
      "epoch: 6 step: 1366, loss is 0.008814550936222076\n",
      "epoch: 6 step: 1367, loss is 0.10039287060499191\n",
      "epoch: 6 step: 1368, loss is 0.08545958995819092\n",
      "epoch: 6 step: 1369, loss is 0.0030675583984702826\n",
      "epoch: 6 step: 1370, loss is 3.9040896808728576e-05\n",
      "epoch: 6 step: 1371, loss is 0.0013208709424361587\n",
      "epoch: 6 step: 1372, loss is 0.0023957444354891777\n",
      "epoch: 6 step: 1373, loss is 0.0038820712361484766\n",
      "epoch: 6 step: 1374, loss is 0.001243963255546987\n",
      "epoch: 6 step: 1375, loss is 0.006255266256630421\n",
      "epoch: 6 step: 1376, loss is 0.00688601890578866\n",
      "epoch: 6 step: 1377, loss is 0.00028031814144924283\n",
      "epoch: 6 step: 1378, loss is 0.003517587436363101\n",
      "epoch: 6 step: 1379, loss is 0.0210553165525198\n",
      "epoch: 6 step: 1380, loss is 0.00031673835474066436\n",
      "epoch: 6 step: 1381, loss is 0.1480255424976349\n",
      "epoch: 6 step: 1382, loss is 1.8866729078581557e-05\n",
      "epoch: 6 step: 1383, loss is 0.009165965020656586\n",
      "epoch: 6 step: 1384, loss is 0.0007194859790615737\n",
      "epoch: 6 step: 1385, loss is 0.006910727359354496\n",
      "epoch: 6 step: 1386, loss is 0.0011416416382417083\n",
      "epoch: 6 step: 1387, loss is 0.009721064940094948\n",
      "epoch: 6 step: 1388, loss is 0.004416132811456919\n",
      "epoch: 6 step: 1389, loss is 0.0021222473587840796\n",
      "epoch: 6 step: 1390, loss is 0.018317390233278275\n",
      "epoch: 6 step: 1391, loss is 0.00023055348719935864\n",
      "epoch: 6 step: 1392, loss is 0.001029058126732707\n",
      "epoch: 6 step: 1393, loss is 0.01135510765016079\n",
      "epoch: 6 step: 1394, loss is 0.018658816814422607\n",
      "epoch: 6 step: 1395, loss is 0.29058215022087097\n",
      "epoch: 6 step: 1396, loss is 0.00017032244068104774\n",
      "epoch: 6 step: 1397, loss is 0.0014079953543841839\n",
      "epoch: 6 step: 1398, loss is 0.0062986998818814754\n",
      "epoch: 6 step: 1399, loss is 0.0028938367031514645\n",
      "epoch: 6 step: 1400, loss is 0.01860874332487583\n",
      "epoch: 6 step: 1401, loss is 0.0006977225420996547\n",
      "epoch: 6 step: 1402, loss is 0.00013199345266912133\n",
      "epoch: 6 step: 1403, loss is 0.00029278642614372075\n",
      "epoch: 6 step: 1404, loss is 0.00478666415438056\n",
      "epoch: 6 step: 1405, loss is 0.025286104530096054\n",
      "epoch: 6 step: 1406, loss is 0.0035568815656006336\n",
      "epoch: 6 step: 1407, loss is 0.010983235202729702\n",
      "epoch: 6 step: 1408, loss is 0.0002044645370915532\n",
      "epoch: 6 step: 1409, loss is 0.0032779406756162643\n",
      "epoch: 6 step: 1410, loss is 0.008089649491012096\n",
      "epoch: 6 step: 1411, loss is 0.0036387306172400713\n",
      "epoch: 6 step: 1412, loss is 0.007913216017186642\n",
      "epoch: 6 step: 1413, loss is 0.017293546348810196\n",
      "epoch: 6 step: 1414, loss is 1.4132718206383288e-05\n",
      "epoch: 6 step: 1415, loss is 0.006026311777532101\n",
      "epoch: 6 step: 1416, loss is 0.010202077217400074\n",
      "epoch: 6 step: 1417, loss is 0.00017825377290137112\n",
      "epoch: 6 step: 1418, loss is 0.0003264254191890359\n",
      "epoch: 6 step: 1419, loss is 0.0007924374076537788\n",
      "epoch: 6 step: 1420, loss is 0.00014739122707396746\n",
      "epoch: 6 step: 1421, loss is 0.0017548541072756052\n",
      "epoch: 6 step: 1422, loss is 0.09011960029602051\n",
      "epoch: 6 step: 1423, loss is 0.0031301456037908792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1424, loss is 0.0006342654814943671\n",
      "epoch: 6 step: 1425, loss is 0.0011181477457284927\n",
      "epoch: 6 step: 1426, loss is 0.00024803957785479724\n",
      "epoch: 6 step: 1427, loss is 0.01137431338429451\n",
      "epoch: 6 step: 1428, loss is 0.0012204350205138326\n",
      "epoch: 6 step: 1429, loss is 0.0017537305830046535\n",
      "epoch: 6 step: 1430, loss is 0.001769990660250187\n",
      "epoch: 6 step: 1431, loss is 4.0690396417630836e-05\n",
      "epoch: 6 step: 1432, loss is 0.002864197827875614\n",
      "epoch: 6 step: 1433, loss is 0.0006290242308750749\n",
      "epoch: 6 step: 1434, loss is 6.649995339103043e-05\n",
      "epoch: 6 step: 1435, loss is 0.0030670897103846073\n",
      "epoch: 6 step: 1436, loss is 0.0001688086922513321\n",
      "epoch: 6 step: 1437, loss is 0.0006739059463143349\n",
      "epoch: 6 step: 1438, loss is 0.00035600009141489863\n",
      "epoch: 6 step: 1439, loss is 0.0290495827794075\n",
      "epoch: 6 step: 1440, loss is 4.8287733079632744e-05\n",
      "epoch: 6 step: 1441, loss is 0.08071418106555939\n",
      "epoch: 6 step: 1442, loss is 0.006109063513576984\n",
      "epoch: 6 step: 1443, loss is 0.015235374681651592\n",
      "epoch: 6 step: 1444, loss is 0.0003336849622428417\n",
      "epoch: 6 step: 1445, loss is 0.0006942873005755246\n",
      "epoch: 6 step: 1446, loss is 0.004773352295160294\n",
      "epoch: 6 step: 1447, loss is 8.365368557861075e-05\n",
      "epoch: 6 step: 1448, loss is 0.006993137765675783\n",
      "epoch: 6 step: 1449, loss is 0.004550047218799591\n",
      "epoch: 6 step: 1450, loss is 5.240581958787516e-05\n",
      "epoch: 6 step: 1451, loss is 0.011783050373196602\n",
      "epoch: 6 step: 1452, loss is 0.0003018106799572706\n",
      "epoch: 6 step: 1453, loss is 0.0007042594952508807\n",
      "epoch: 6 step: 1454, loss is 0.0030820630490779877\n",
      "epoch: 6 step: 1455, loss is 0.016058355569839478\n",
      "epoch: 6 step: 1456, loss is 4.544527473626658e-05\n",
      "epoch: 6 step: 1457, loss is 0.0031303579453378916\n",
      "epoch: 6 step: 1458, loss is 0.026394514366984367\n",
      "epoch: 6 step: 1459, loss is 0.011534971185028553\n",
      "epoch: 6 step: 1460, loss is 1.3575466255133506e-05\n",
      "epoch: 6 step: 1461, loss is 0.0009641559445299208\n",
      "epoch: 6 step: 1462, loss is 9.955538553185761e-05\n",
      "epoch: 6 step: 1463, loss is 0.003625001758337021\n",
      "epoch: 6 step: 1464, loss is 0.030710408464074135\n",
      "epoch: 6 step: 1465, loss is 0.0008516436791978776\n",
      "epoch: 6 step: 1466, loss is 0.0018894427921622992\n",
      "epoch: 6 step: 1467, loss is 0.09826385229825974\n",
      "epoch: 6 step: 1468, loss is 0.004665528889745474\n",
      "epoch: 6 step: 1469, loss is 0.0008934017387218773\n",
      "epoch: 6 step: 1470, loss is 0.022485068067908287\n",
      "epoch: 6 step: 1471, loss is 0.09988726675510406\n",
      "epoch: 6 step: 1472, loss is 0.03307601064443588\n",
      "epoch: 6 step: 1473, loss is 0.0014278626767918468\n",
      "epoch: 6 step: 1474, loss is 8.215334673877805e-05\n",
      "epoch: 6 step: 1475, loss is 7.460446795448661e-05\n",
      "epoch: 6 step: 1476, loss is 0.029785120859742165\n",
      "epoch: 6 step: 1477, loss is 0.00010365168418502435\n",
      "epoch: 6 step: 1478, loss is 0.005229882430285215\n",
      "epoch: 6 step: 1479, loss is 6.149394175736234e-05\n",
      "epoch: 6 step: 1480, loss is 0.14963045716285706\n",
      "epoch: 6 step: 1481, loss is 0.006291735917329788\n",
      "epoch: 6 step: 1482, loss is 0.08696070313453674\n",
      "epoch: 6 step: 1483, loss is 9.554437565384433e-05\n",
      "epoch: 6 step: 1484, loss is 0.001877877744846046\n",
      "epoch: 6 step: 1485, loss is 0.008560744114220142\n",
      "epoch: 6 step: 1486, loss is 0.0006517938454635441\n",
      "epoch: 6 step: 1487, loss is 0.0004928804119117558\n",
      "epoch: 6 step: 1488, loss is 0.0009057686547748744\n",
      "epoch: 6 step: 1489, loss is 0.0007343616452999413\n",
      "epoch: 6 step: 1490, loss is 0.09090649336576462\n",
      "epoch: 6 step: 1491, loss is 0.0021703201346099377\n",
      "epoch: 6 step: 1492, loss is 0.0016846152720972896\n",
      "epoch: 6 step: 1493, loss is 2.794018291751854e-05\n",
      "epoch: 6 step: 1494, loss is 0.0046173520386219025\n",
      "epoch: 6 step: 1495, loss is 0.0004345784545876086\n",
      "epoch: 6 step: 1496, loss is 0.008677300997078419\n",
      "epoch: 6 step: 1497, loss is 0.00045605143532156944\n",
      "epoch: 6 step: 1498, loss is 0.2844930589199066\n",
      "epoch: 6 step: 1499, loss is 2.812628554238472e-05\n",
      "epoch: 6 step: 1500, loss is 0.0007931026048026979\n",
      "epoch: 6 step: 1501, loss is 0.006723730359226465\n",
      "epoch: 6 step: 1502, loss is 0.00014042579277884215\n",
      "epoch: 6 step: 1503, loss is 0.00583958625793457\n",
      "epoch: 6 step: 1504, loss is 0.07771018892526627\n",
      "epoch: 6 step: 1505, loss is 0.0002255473518744111\n",
      "epoch: 6 step: 1506, loss is 0.055629756301641464\n",
      "epoch: 6 step: 1507, loss is 0.017842406406998634\n",
      "epoch: 6 step: 1508, loss is 0.01423337310552597\n",
      "epoch: 6 step: 1509, loss is 0.004373366478830576\n",
      "epoch: 6 step: 1510, loss is 0.05631287395954132\n",
      "epoch: 6 step: 1511, loss is 0.003951690159738064\n",
      "epoch: 6 step: 1512, loss is 0.0001300887524848804\n",
      "epoch: 6 step: 1513, loss is 0.0006161300698295236\n",
      "epoch: 6 step: 1514, loss is 0.07283689826726913\n",
      "epoch: 6 step: 1515, loss is 0.018913252279162407\n",
      "epoch: 6 step: 1516, loss is 0.0011741418857127428\n",
      "epoch: 6 step: 1517, loss is 0.0026482860557734966\n",
      "epoch: 6 step: 1518, loss is 0.001333763124421239\n",
      "epoch: 6 step: 1519, loss is 0.16550768911838531\n",
      "epoch: 6 step: 1520, loss is 0.0014010651502758265\n",
      "epoch: 6 step: 1521, loss is 0.013866500928997993\n",
      "epoch: 6 step: 1522, loss is 0.0015629347180947661\n",
      "epoch: 6 step: 1523, loss is 0.003713196376338601\n",
      "epoch: 6 step: 1524, loss is 0.0031412180978804827\n",
      "epoch: 6 step: 1525, loss is 0.0007077931077219546\n",
      "epoch: 6 step: 1526, loss is 0.004652905277907848\n",
      "epoch: 6 step: 1527, loss is 0.028243573382496834\n",
      "epoch: 6 step: 1528, loss is 0.0007087222766131163\n",
      "epoch: 6 step: 1529, loss is 0.002209943253546953\n",
      "epoch: 6 step: 1530, loss is 0.037468407303094864\n",
      "epoch: 6 step: 1531, loss is 0.00011983107833657414\n",
      "epoch: 6 step: 1532, loss is 0.10563898831605911\n",
      "epoch: 6 step: 1533, loss is 0.08006580173969269\n",
      "epoch: 6 step: 1534, loss is 0.00021126450155861676\n",
      "epoch: 6 step: 1535, loss is 4.752285167342052e-05\n",
      "epoch: 6 step: 1536, loss is 0.04175699129700661\n",
      "epoch: 6 step: 1537, loss is 0.0005200732266530395\n",
      "epoch: 6 step: 1538, loss is 7.762618770357221e-05\n",
      "epoch: 6 step: 1539, loss is 0.01760086603462696\n",
      "epoch: 6 step: 1540, loss is 0.0006700577796436846\n",
      "epoch: 6 step: 1541, loss is 0.038104623556137085\n",
      "epoch: 6 step: 1542, loss is 0.0027141249738633633\n",
      "epoch: 6 step: 1543, loss is 0.0009754033526405692\n",
      "epoch: 6 step: 1544, loss is 0.00045751812285743654\n",
      "epoch: 6 step: 1545, loss is 0.0002470707695465535\n",
      "epoch: 6 step: 1546, loss is 6.105841021053493e-05\n",
      "epoch: 6 step: 1547, loss is 0.001905547920614481\n",
      "epoch: 6 step: 1548, loss is 0.009182445704936981\n",
      "epoch: 6 step: 1549, loss is 3.8120997487567365e-05\n",
      "epoch: 6 step: 1550, loss is 0.0003222526574973017\n",
      "epoch: 6 step: 1551, loss is 0.020860465243458748\n",
      "epoch: 6 step: 1552, loss is 0.04851173982024193\n",
      "epoch: 6 step: 1553, loss is 0.0015508062206208706\n",
      "epoch: 6 step: 1554, loss is 0.0007078146445564926\n",
      "epoch: 6 step: 1555, loss is 0.02546755224466324\n",
      "epoch: 6 step: 1556, loss is 0.07989296317100525\n",
      "epoch: 6 step: 1557, loss is 0.027509240433573723\n",
      "epoch: 6 step: 1558, loss is 0.02036336436867714\n",
      "epoch: 6 step: 1559, loss is 0.004953992087393999\n",
      "epoch: 6 step: 1560, loss is 0.004231193568557501\n",
      "epoch: 6 step: 1561, loss is 0.011036986485123634\n",
      "epoch: 6 step: 1562, loss is 0.000696464441716671\n",
      "epoch: 6 step: 1563, loss is 0.02003714069724083\n",
      "epoch: 6 step: 1564, loss is 0.0005461036344058812\n",
      "epoch: 6 step: 1565, loss is 0.05740676447749138\n",
      "epoch: 6 step: 1566, loss is 0.03140740469098091\n",
      "epoch: 6 step: 1567, loss is 0.0014237788273021579\n",
      "epoch: 6 step: 1568, loss is 0.19297343492507935\n",
      "epoch: 6 step: 1569, loss is 0.04088287428021431\n",
      "epoch: 6 step: 1570, loss is 0.00038250090437941253\n",
      "epoch: 6 step: 1571, loss is 0.0001796601718524471\n",
      "epoch: 6 step: 1572, loss is 0.0007743191672489047\n",
      "epoch: 6 step: 1573, loss is 0.0015488992212340236\n",
      "epoch: 6 step: 1574, loss is 0.018564065918326378\n",
      "epoch: 6 step: 1575, loss is 0.19015464186668396\n",
      "epoch: 6 step: 1576, loss is 0.002770983148366213\n",
      "epoch: 6 step: 1577, loss is 0.0059220572002232075\n",
      "epoch: 6 step: 1578, loss is 0.04395327717065811\n",
      "epoch: 6 step: 1579, loss is 4.244181764079258e-05\n",
      "epoch: 6 step: 1580, loss is 9.234558820025995e-05\n",
      "epoch: 6 step: 1581, loss is 0.002234730636700988\n",
      "epoch: 6 step: 1582, loss is 0.010842283256351948\n",
      "epoch: 6 step: 1583, loss is 0.0018051849910989404\n",
      "epoch: 6 step: 1584, loss is 0.034661490470170975\n",
      "epoch: 6 step: 1585, loss is 0.009697044268250465\n",
      "epoch: 6 step: 1586, loss is 0.17594604194164276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1587, loss is 0.00858574640005827\n",
      "epoch: 6 step: 1588, loss is 0.24871449172496796\n",
      "epoch: 6 step: 1589, loss is 0.004922174848616123\n",
      "epoch: 6 step: 1590, loss is 0.0005036554066464305\n",
      "epoch: 6 step: 1591, loss is 0.009034346789121628\n",
      "epoch: 6 step: 1592, loss is 0.13874433934688568\n",
      "epoch: 6 step: 1593, loss is 0.0009735453641042113\n",
      "epoch: 6 step: 1594, loss is 0.0515141487121582\n",
      "epoch: 6 step: 1595, loss is 0.4904383420944214\n",
      "epoch: 6 step: 1596, loss is 0.0023512172047048807\n",
      "epoch: 6 step: 1597, loss is 0.003406388685107231\n",
      "epoch: 6 step: 1598, loss is 0.028489572927355766\n",
      "epoch: 6 step: 1599, loss is 0.08498553186655045\n",
      "epoch: 6 step: 1600, loss is 0.005821714643388987\n",
      "epoch: 6 step: 1601, loss is 0.00036051133065484464\n",
      "epoch: 6 step: 1602, loss is 0.3047128915786743\n",
      "epoch: 6 step: 1603, loss is 0.0021704332903027534\n",
      "epoch: 6 step: 1604, loss is 0.044714879244565964\n",
      "epoch: 6 step: 1605, loss is 0.09261570125818253\n",
      "epoch: 6 step: 1606, loss is 0.037536293268203735\n",
      "epoch: 6 step: 1607, loss is 0.019184619188308716\n",
      "epoch: 6 step: 1608, loss is 0.0047461893409490585\n",
      "epoch: 6 step: 1609, loss is 0.005894475616514683\n",
      "epoch: 6 step: 1610, loss is 0.0052824500016868114\n",
      "epoch: 6 step: 1611, loss is 0.0006508531514555216\n",
      "epoch: 6 step: 1612, loss is 0.028252072632312775\n",
      "epoch: 6 step: 1613, loss is 0.002476930385455489\n",
      "epoch: 6 step: 1614, loss is 0.0037593941669911146\n",
      "epoch: 6 step: 1615, loss is 0.0005371656152419746\n",
      "epoch: 6 step: 1616, loss is 0.1279221922159195\n",
      "epoch: 6 step: 1617, loss is 0.00299115595407784\n",
      "epoch: 6 step: 1618, loss is 0.0017482086550444365\n",
      "epoch: 6 step: 1619, loss is 0.0004578392836265266\n",
      "epoch: 6 step: 1620, loss is 0.007777244783937931\n",
      "epoch: 6 step: 1621, loss is 0.03963923826813698\n",
      "epoch: 6 step: 1622, loss is 0.0008297463646158576\n",
      "epoch: 6 step: 1623, loss is 0.0011677999282255769\n",
      "epoch: 6 step: 1624, loss is 0.0001337675203103572\n",
      "epoch: 6 step: 1625, loss is 0.0010470319539308548\n",
      "epoch: 6 step: 1626, loss is 0.16257645189762115\n",
      "epoch: 6 step: 1627, loss is 0.002155385911464691\n",
      "epoch: 6 step: 1628, loss is 0.0022176261991262436\n",
      "epoch: 6 step: 1629, loss is 0.002549021039158106\n",
      "epoch: 6 step: 1630, loss is 0.014817916788160801\n",
      "epoch: 6 step: 1631, loss is 0.05636581405997276\n",
      "epoch: 6 step: 1632, loss is 0.03334391862154007\n",
      "epoch: 6 step: 1633, loss is 0.0002010362222790718\n",
      "epoch: 6 step: 1634, loss is 0.0013023152714595199\n",
      "epoch: 6 step: 1635, loss is 0.06866218149662018\n",
      "epoch: 6 step: 1636, loss is 0.10246723145246506\n",
      "epoch: 6 step: 1637, loss is 0.0014539307449012995\n",
      "epoch: 6 step: 1638, loss is 0.004056064877659082\n",
      "epoch: 6 step: 1639, loss is 0.07240252196788788\n",
      "epoch: 6 step: 1640, loss is 0.0004659299738705158\n",
      "epoch: 6 step: 1641, loss is 0.00038246551412157714\n",
      "epoch: 6 step: 1642, loss is 0.14374639093875885\n",
      "epoch: 6 step: 1643, loss is 0.003435396123677492\n",
      "epoch: 6 step: 1644, loss is 0.07230997085571289\n",
      "epoch: 6 step: 1645, loss is 0.00769048510119319\n",
      "epoch: 6 step: 1646, loss is 0.0016150964656844735\n",
      "epoch: 6 step: 1647, loss is 0.01547296717762947\n",
      "epoch: 6 step: 1648, loss is 0.0001280050491914153\n",
      "epoch: 6 step: 1649, loss is 0.022967979311943054\n",
      "epoch: 6 step: 1650, loss is 0.022385360673069954\n",
      "epoch: 6 step: 1651, loss is 0.0013239523395895958\n",
      "epoch: 6 step: 1652, loss is 0.0028022672049701214\n",
      "epoch: 6 step: 1653, loss is 0.00013659395335707814\n",
      "epoch: 6 step: 1654, loss is 0.011794442310929298\n",
      "epoch: 6 step: 1655, loss is 0.0014999903505668044\n",
      "epoch: 6 step: 1656, loss is 0.0005350523861125112\n",
      "epoch: 6 step: 1657, loss is 0.007519335951656103\n",
      "epoch: 6 step: 1658, loss is 0.010777062736451626\n",
      "epoch: 6 step: 1659, loss is 0.046668972820043564\n",
      "epoch: 6 step: 1660, loss is 0.0041042510420084\n",
      "epoch: 6 step: 1661, loss is 0.0344422310590744\n",
      "epoch: 6 step: 1662, loss is 0.00023525464348495007\n",
      "epoch: 6 step: 1663, loss is 0.0065940977074205875\n",
      "epoch: 6 step: 1664, loss is 0.0005692183622159064\n",
      "epoch: 6 step: 1665, loss is 0.010336888022720814\n",
      "epoch: 6 step: 1666, loss is 6.433139787986875e-05\n",
      "epoch: 6 step: 1667, loss is 0.03013860620558262\n",
      "epoch: 6 step: 1668, loss is 0.00576429208740592\n",
      "epoch: 6 step: 1669, loss is 0.012863860465586185\n",
      "epoch: 6 step: 1670, loss is 0.04543166607618332\n",
      "epoch: 6 step: 1671, loss is 0.0007389367092400789\n",
      "epoch: 6 step: 1672, loss is 0.0008388219284825027\n",
      "epoch: 6 step: 1673, loss is 0.00183507998008281\n",
      "epoch: 6 step: 1674, loss is 0.0009124617790803313\n",
      "epoch: 6 step: 1675, loss is 0.001827297848649323\n",
      "epoch: 6 step: 1676, loss is 0.003633257932960987\n",
      "epoch: 6 step: 1677, loss is 0.0008401790983043611\n",
      "epoch: 6 step: 1678, loss is 0.0003322371921967715\n",
      "epoch: 6 step: 1679, loss is 0.00039649836253374815\n",
      "epoch: 6 step: 1680, loss is 0.0011173257371410728\n",
      "epoch: 6 step: 1681, loss is 0.021185757592320442\n",
      "epoch: 6 step: 1682, loss is 0.004272391088306904\n",
      "epoch: 6 step: 1683, loss is 0.0013745914911851287\n",
      "epoch: 6 step: 1684, loss is 0.004870575852692127\n",
      "epoch: 6 step: 1685, loss is 0.0001906837715068832\n",
      "epoch: 6 step: 1686, loss is 0.015721773728728294\n",
      "epoch: 6 step: 1687, loss is 0.05382923781871796\n",
      "epoch: 6 step: 1688, loss is 0.0009282768005505204\n",
      "epoch: 6 step: 1689, loss is 0.0002025096764555201\n",
      "epoch: 6 step: 1690, loss is 0.00046135022421367466\n",
      "epoch: 6 step: 1691, loss is 0.004475060384720564\n",
      "epoch: 6 step: 1692, loss is 0.0008900458342395723\n",
      "epoch: 6 step: 1693, loss is 0.000993302441202104\n",
      "epoch: 6 step: 1694, loss is 0.007003963924944401\n",
      "epoch: 6 step: 1695, loss is 0.002725093625485897\n",
      "epoch: 6 step: 1696, loss is 1.743898610584438e-05\n",
      "epoch: 6 step: 1697, loss is 0.000630874652415514\n",
      "epoch: 6 step: 1698, loss is 0.003113459562882781\n",
      "epoch: 6 step: 1699, loss is 0.005403705406934023\n",
      "epoch: 6 step: 1700, loss is 0.00019929099653381854\n",
      "epoch: 6 step: 1701, loss is 0.0017708914820104837\n",
      "epoch: 6 step: 1702, loss is 0.003903368953615427\n",
      "epoch: 6 step: 1703, loss is 0.0032141050323843956\n",
      "epoch: 6 step: 1704, loss is 0.0029489079024642706\n",
      "epoch: 6 step: 1705, loss is 0.00891850609332323\n",
      "epoch: 6 step: 1706, loss is 0.02513851970434189\n",
      "epoch: 6 step: 1707, loss is 0.0010538831120356917\n",
      "epoch: 6 step: 1708, loss is 0.001244412618689239\n",
      "epoch: 6 step: 1709, loss is 0.0011552531505003572\n",
      "epoch: 6 step: 1710, loss is 0.000753026339225471\n",
      "epoch: 6 step: 1711, loss is 0.020949840545654297\n",
      "epoch: 6 step: 1712, loss is 0.00012826346210204065\n",
      "epoch: 6 step: 1713, loss is 0.0002258547319797799\n",
      "epoch: 6 step: 1714, loss is 0.00013639984535984695\n",
      "epoch: 6 step: 1715, loss is 0.0020401061046868563\n",
      "epoch: 6 step: 1716, loss is 0.012784971855580807\n",
      "epoch: 6 step: 1717, loss is 0.005908372811973095\n",
      "epoch: 6 step: 1718, loss is 7.557942444691435e-05\n",
      "epoch: 6 step: 1719, loss is 0.03270130604505539\n",
      "epoch: 6 step: 1720, loss is 0.1144232377409935\n",
      "epoch: 6 step: 1721, loss is 7.676160021219403e-05\n",
      "epoch: 6 step: 1722, loss is 0.045957986265420914\n",
      "epoch: 6 step: 1723, loss is 0.0004082554951310158\n",
      "epoch: 6 step: 1724, loss is 0.00028154844767414033\n",
      "epoch: 6 step: 1725, loss is 0.003754216246306896\n",
      "epoch: 6 step: 1726, loss is 0.0001773523836163804\n",
      "epoch: 6 step: 1727, loss is 0.03588458150625229\n",
      "epoch: 6 step: 1728, loss is 0.0020642844028770924\n",
      "epoch: 6 step: 1729, loss is 0.00022925663506612182\n",
      "epoch: 6 step: 1730, loss is 0.012780535034835339\n",
      "epoch: 6 step: 1731, loss is 0.000433735636761412\n",
      "epoch: 6 step: 1732, loss is 0.0002505420125089586\n",
      "epoch: 6 step: 1733, loss is 0.004780655261129141\n",
      "epoch: 6 step: 1734, loss is 0.0007612476474605501\n",
      "epoch: 6 step: 1735, loss is 0.001518081990070641\n",
      "epoch: 6 step: 1736, loss is 0.0018846549792215228\n",
      "epoch: 6 step: 1737, loss is 0.0004991915193386376\n",
      "epoch: 6 step: 1738, loss is 0.0030323241371661425\n",
      "epoch: 6 step: 1739, loss is 0.0004270870122127235\n",
      "epoch: 6 step: 1740, loss is 0.0025498936884105206\n",
      "epoch: 6 step: 1741, loss is 0.007922546938061714\n",
      "epoch: 6 step: 1742, loss is 0.1514556109905243\n",
      "epoch: 6 step: 1743, loss is 0.09108854085206985\n",
      "epoch: 6 step: 1744, loss is 0.007944706827402115\n",
      "epoch: 6 step: 1745, loss is 0.012677323073148727\n",
      "epoch: 6 step: 1746, loss is 0.014878896996378899\n",
      "epoch: 6 step: 1747, loss is 0.006231027189642191\n",
      "epoch: 6 step: 1748, loss is 0.001815610215999186\n",
      "epoch: 6 step: 1749, loss is 0.12408837676048279\n",
      "epoch: 6 step: 1750, loss is 0.013082829304039478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1751, loss is 0.00035068747820332646\n",
      "epoch: 6 step: 1752, loss is 0.004714310634881258\n",
      "epoch: 6 step: 1753, loss is 0.0020016536582261324\n",
      "epoch: 6 step: 1754, loss is 0.003675845917314291\n",
      "epoch: 6 step: 1755, loss is 0.002179704373702407\n",
      "epoch: 6 step: 1756, loss is 0.025869373232126236\n",
      "epoch: 6 step: 1757, loss is 0.00047061871737241745\n",
      "epoch: 6 step: 1758, loss is 0.007669023238122463\n",
      "epoch: 6 step: 1759, loss is 0.010137042962014675\n",
      "epoch: 6 step: 1760, loss is 0.0048813181929290295\n",
      "epoch: 6 step: 1761, loss is 0.005364764016121626\n",
      "epoch: 6 step: 1762, loss is 0.0036956495605409145\n",
      "epoch: 6 step: 1763, loss is 0.003398809116333723\n",
      "epoch: 6 step: 1764, loss is 0.0008047574665397406\n",
      "epoch: 6 step: 1765, loss is 0.00339583121240139\n",
      "epoch: 6 step: 1766, loss is 0.00022545257525052875\n",
      "epoch: 6 step: 1767, loss is 0.08356957882642746\n",
      "epoch: 6 step: 1768, loss is 0.005774850491434336\n",
      "epoch: 6 step: 1769, loss is 0.00031076461891643703\n",
      "epoch: 6 step: 1770, loss is 0.21926189959049225\n",
      "epoch: 6 step: 1771, loss is 0.0030067237094044685\n",
      "epoch: 6 step: 1772, loss is 0.16554173827171326\n",
      "epoch: 6 step: 1773, loss is 0.0005583141464740038\n",
      "epoch: 6 step: 1774, loss is 0.0006160010234452784\n",
      "epoch: 6 step: 1775, loss is 0.04035987704992294\n",
      "epoch: 6 step: 1776, loss is 0.00025551184080541134\n",
      "epoch: 6 step: 1777, loss is 0.0010414018761366606\n",
      "epoch: 6 step: 1778, loss is 0.02221367321908474\n",
      "epoch: 6 step: 1779, loss is 0.0013268645852804184\n",
      "epoch: 6 step: 1780, loss is 0.0015321121318265796\n",
      "epoch: 6 step: 1781, loss is 0.00011290347174508497\n",
      "epoch: 6 step: 1782, loss is 0.00032946871942840517\n",
      "epoch: 6 step: 1783, loss is 0.001038647722452879\n",
      "epoch: 6 step: 1784, loss is 0.05082162097096443\n",
      "epoch: 6 step: 1785, loss is 0.0002102943108184263\n",
      "epoch: 6 step: 1786, loss is 0.0008337095496244729\n",
      "epoch: 6 step: 1787, loss is 0.021058356389403343\n",
      "epoch: 6 step: 1788, loss is 0.00029030904988758266\n",
      "epoch: 6 step: 1789, loss is 4.695809548138641e-05\n",
      "epoch: 6 step: 1790, loss is 0.0016926631797105074\n",
      "epoch: 6 step: 1791, loss is 0.0003809938207268715\n",
      "epoch: 6 step: 1792, loss is 0.0010804713238030672\n",
      "epoch: 6 step: 1793, loss is 0.006350263021886349\n",
      "epoch: 6 step: 1794, loss is 0.0004908693372271955\n",
      "epoch: 6 step: 1795, loss is 0.0004079192294739187\n",
      "epoch: 6 step: 1796, loss is 0.02187572978436947\n",
      "epoch: 6 step: 1797, loss is 0.015145952813327312\n",
      "epoch: 6 step: 1798, loss is 0.04388124868273735\n",
      "epoch: 6 step: 1799, loss is 0.02077297493815422\n",
      "epoch: 6 step: 1800, loss is 0.0012969011440873146\n",
      "epoch: 6 step: 1801, loss is 0.0015049307839944959\n",
      "epoch: 6 step: 1802, loss is 0.0005120011628605425\n",
      "epoch: 6 step: 1803, loss is 0.04983070492744446\n",
      "epoch: 6 step: 1804, loss is 0.0854053795337677\n",
      "epoch: 6 step: 1805, loss is 0.0024629023391753435\n",
      "epoch: 6 step: 1806, loss is 0.0025591186713427305\n",
      "epoch: 6 step: 1807, loss is 0.0003223057428840548\n",
      "epoch: 6 step: 1808, loss is 0.009217229671776295\n",
      "epoch: 6 step: 1809, loss is 0.009776969440281391\n",
      "epoch: 6 step: 1810, loss is 0.0007679246482439339\n",
      "epoch: 6 step: 1811, loss is 0.002118652919307351\n",
      "epoch: 6 step: 1812, loss is 0.3893432021141052\n",
      "epoch: 6 step: 1813, loss is 0.00011335499584674835\n",
      "epoch: 6 step: 1814, loss is 0.0015635439194738865\n",
      "epoch: 6 step: 1815, loss is 0.05870649218559265\n",
      "epoch: 6 step: 1816, loss is 0.010352002456784248\n",
      "epoch: 6 step: 1817, loss is 0.013764223083853722\n",
      "epoch: 6 step: 1818, loss is 0.012292250990867615\n",
      "epoch: 6 step: 1819, loss is 0.09377765655517578\n",
      "epoch: 6 step: 1820, loss is 0.0007389110396616161\n",
      "epoch: 6 step: 1821, loss is 0.004281807225197554\n",
      "epoch: 6 step: 1822, loss is 0.0015711493324488401\n",
      "epoch: 6 step: 1823, loss is 6.265001866267994e-05\n",
      "epoch: 6 step: 1824, loss is 0.036961428821086884\n",
      "epoch: 6 step: 1825, loss is 0.007004988845437765\n",
      "epoch: 6 step: 1826, loss is 0.0035176542587578297\n",
      "epoch: 6 step: 1827, loss is 0.023507706820964813\n",
      "epoch: 6 step: 1828, loss is 0.003940569702535868\n",
      "epoch: 6 step: 1829, loss is 0.011972613632678986\n",
      "epoch: 6 step: 1830, loss is 0.016168411821126938\n",
      "epoch: 6 step: 1831, loss is 0.00019522967340890318\n",
      "epoch: 6 step: 1832, loss is 0.02042365074157715\n",
      "epoch: 6 step: 1833, loss is 0.0005480135441757739\n",
      "epoch: 6 step: 1834, loss is 0.0015100858872756362\n",
      "epoch: 6 step: 1835, loss is 0.01394798792898655\n",
      "epoch: 6 step: 1836, loss is 0.0067475466057658195\n",
      "epoch: 6 step: 1837, loss is 0.0008719501784071326\n",
      "epoch: 6 step: 1838, loss is 0.11404404044151306\n",
      "epoch: 6 step: 1839, loss is 0.006395446136593819\n",
      "epoch: 6 step: 1840, loss is 0.0064627681858837605\n",
      "epoch: 6 step: 1841, loss is 6.366646266542375e-05\n",
      "epoch: 6 step: 1842, loss is 0.012694688513875008\n",
      "epoch: 6 step: 1843, loss is 0.01242801919579506\n",
      "epoch: 6 step: 1844, loss is 0.006438222713768482\n",
      "epoch: 6 step: 1845, loss is 0.07968264073133469\n",
      "epoch: 6 step: 1846, loss is 0.0067548491060733795\n",
      "epoch: 6 step: 1847, loss is 0.016912324354052544\n",
      "epoch: 6 step: 1848, loss is 0.00010901852510869503\n",
      "epoch: 6 step: 1849, loss is 4.6183289668988436e-05\n",
      "epoch: 6 step: 1850, loss is 0.020310429856181145\n",
      "epoch: 6 step: 1851, loss is 0.0008464212878607213\n",
      "epoch: 6 step: 1852, loss is 1.030841849569697e-05\n",
      "epoch: 6 step: 1853, loss is 0.0036354265175759792\n",
      "epoch: 6 step: 1854, loss is 0.22487232089042664\n",
      "epoch: 6 step: 1855, loss is 0.00578627735376358\n",
      "epoch: 6 step: 1856, loss is 7.06166320014745e-05\n",
      "epoch: 6 step: 1857, loss is 0.00012174115545349196\n",
      "epoch: 6 step: 1858, loss is 0.1262010782957077\n",
      "epoch: 6 step: 1859, loss is 0.18940047919750214\n",
      "epoch: 6 step: 1860, loss is 0.007168617099523544\n",
      "epoch: 6 step: 1861, loss is 0.0005601726588793099\n",
      "epoch: 6 step: 1862, loss is 0.003327698213979602\n",
      "epoch: 6 step: 1863, loss is 0.0020933635532855988\n",
      "epoch: 6 step: 1864, loss is 0.0005162335000932217\n",
      "epoch: 6 step: 1865, loss is 0.12501640617847443\n",
      "epoch: 6 step: 1866, loss is 0.006674829870462418\n",
      "epoch: 6 step: 1867, loss is 0.0027185785584151745\n",
      "epoch: 6 step: 1868, loss is 0.017073800787329674\n",
      "epoch: 6 step: 1869, loss is 0.008808881044387817\n",
      "epoch: 6 step: 1870, loss is 0.14569532871246338\n",
      "epoch: 6 step: 1871, loss is 0.012673371471464634\n",
      "epoch: 6 step: 1872, loss is 0.0038100581150501966\n",
      "epoch: 6 step: 1873, loss is 0.0005479037063196301\n",
      "epoch: 6 step: 1874, loss is 0.1269836574792862\n",
      "epoch: 6 step: 1875, loss is 0.03414416313171387\n",
      "epoch: 6 step: 1876, loss is 0.0019100714707747102\n",
      "epoch: 6 step: 1877, loss is 0.04363744705915451\n",
      "epoch: 6 step: 1878, loss is 0.0006894918624311686\n",
      "epoch: 6 step: 1879, loss is 0.0005290855187922716\n",
      "epoch: 6 step: 1880, loss is 0.14770524203777313\n",
      "epoch: 6 step: 1881, loss is 0.06048273295164108\n",
      "epoch: 6 step: 1882, loss is 0.0025525307282805443\n",
      "epoch: 6 step: 1883, loss is 0.0014992767246440053\n",
      "epoch: 6 step: 1884, loss is 0.0008893139893189073\n",
      "epoch: 6 step: 1885, loss is 0.024430427700281143\n",
      "epoch: 6 step: 1886, loss is 0.0020310566760599613\n",
      "epoch: 6 step: 1887, loss is 0.0014761068159714341\n",
      "epoch: 6 step: 1888, loss is 0.09906302392482758\n",
      "epoch: 6 step: 1889, loss is 0.047322362661361694\n",
      "epoch: 6 step: 1890, loss is 0.00022089233971200883\n",
      "epoch: 6 step: 1891, loss is 0.002747462596744299\n",
      "epoch: 6 step: 1892, loss is 0.00012365511793177575\n",
      "epoch: 6 step: 1893, loss is 0.00033066311152651906\n",
      "epoch: 6 step: 1894, loss is 0.0001353735278826207\n",
      "epoch: 6 step: 1895, loss is 0.0034577578771859407\n",
      "epoch: 6 step: 1896, loss is 0.22076138854026794\n",
      "epoch: 6 step: 1897, loss is 0.008020353503525257\n",
      "epoch: 6 step: 1898, loss is 0.007584018632769585\n",
      "epoch: 6 step: 1899, loss is 0.003333061933517456\n",
      "epoch: 6 step: 1900, loss is 0.04210413619875908\n",
      "epoch: 6 step: 1901, loss is 0.0031649251468479633\n",
      "epoch: 6 step: 1902, loss is 0.0004745754413306713\n",
      "epoch: 6 step: 1903, loss is 0.0005487503949552774\n",
      "epoch: 6 step: 1904, loss is 0.013033038005232811\n",
      "epoch: 6 step: 1905, loss is 0.0003016953414771706\n",
      "epoch: 6 step: 1906, loss is 0.0006270753801800311\n",
      "epoch: 6 step: 1907, loss is 0.0002659087476786226\n",
      "epoch: 6 step: 1908, loss is 0.0031168016139417887\n",
      "epoch: 6 step: 1909, loss is 0.004051562864333391\n",
      "epoch: 6 step: 1910, loss is 0.14888110756874084\n",
      "epoch: 6 step: 1911, loss is 0.00985134206712246\n",
      "epoch: 6 step: 1912, loss is 0.059968508780002594\n",
      "epoch: 6 step: 1913, loss is 0.0027732192538678646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 1914, loss is 0.011082187294960022\n",
      "epoch: 6 step: 1915, loss is 0.013485964387655258\n",
      "epoch: 6 step: 1916, loss is 0.0008629020303487778\n",
      "epoch: 6 step: 1917, loss is 0.00440451642498374\n",
      "epoch: 6 step: 1918, loss is 0.00077523646177724\n",
      "epoch: 6 step: 1919, loss is 0.009510746225714684\n",
      "epoch: 6 step: 1920, loss is 0.0005237485747784376\n",
      "epoch: 6 step: 1921, loss is 0.009036771953105927\n",
      "epoch: 6 step: 1922, loss is 0.00149122707080096\n",
      "epoch: 6 step: 1923, loss is 0.09613257646560669\n",
      "epoch: 6 step: 1924, loss is 0.02750980667769909\n",
      "epoch: 6 step: 1925, loss is 0.005420111119747162\n",
      "epoch: 6 step: 1926, loss is 0.0006967562949284911\n",
      "epoch: 6 step: 1927, loss is 0.11011827737092972\n",
      "epoch: 6 step: 1928, loss is 0.0013503709342330694\n",
      "epoch: 6 step: 1929, loss is 0.005022686440497637\n",
      "epoch: 6 step: 1930, loss is 0.018669353798031807\n",
      "epoch: 6 step: 1931, loss is 0.00037679544766433537\n",
      "epoch: 6 step: 1932, loss is 0.021792786195874214\n",
      "epoch: 6 step: 1933, loss is 0.001947564771398902\n",
      "epoch: 6 step: 1934, loss is 0.024330003187060356\n",
      "epoch: 6 step: 1935, loss is 0.08979695290327072\n",
      "epoch: 6 step: 1936, loss is 7.36253205104731e-05\n",
      "epoch: 6 step: 1937, loss is 0.0005153488600626588\n",
      "epoch: 6 step: 1938, loss is 0.0005849663866683841\n",
      "epoch: 6 step: 1939, loss is 0.0019073683070018888\n",
      "epoch: 6 step: 1940, loss is 0.003471506293863058\n",
      "epoch: 6 step: 1941, loss is 0.13216552138328552\n",
      "epoch: 6 step: 1942, loss is 0.0008569772471673787\n",
      "epoch: 6 step: 1943, loss is 0.005483883433043957\n",
      "epoch: 6 step: 1944, loss is 0.06112438067793846\n",
      "epoch: 6 step: 1945, loss is 0.005551764275878668\n",
      "epoch: 6 step: 1946, loss is 0.0032989615574479103\n",
      "epoch: 6 step: 1947, loss is 0.0016011130064725876\n",
      "epoch: 6 step: 1948, loss is 0.0004513298626989126\n",
      "epoch: 6 step: 1949, loss is 0.00790236983448267\n",
      "epoch: 6 step: 1950, loss is 0.00690038874745369\n",
      "epoch: 6 step: 1951, loss is 0.014766408130526543\n",
      "epoch: 6 step: 1952, loss is 0.0006559470202773809\n",
      "epoch: 6 step: 1953, loss is 0.042170796543359756\n",
      "epoch: 6 step: 1954, loss is 0.016323691233992577\n",
      "epoch: 6 step: 1955, loss is 0.06540980190038681\n",
      "epoch: 6 step: 1956, loss is 0.0009582773200236261\n",
      "epoch: 6 step: 1957, loss is 0.11449813097715378\n",
      "epoch: 6 step: 1958, loss is 0.000506601994857192\n",
      "epoch: 6 step: 1959, loss is 0.024429544806480408\n",
      "epoch: 6 step: 1960, loss is 0.008261127397418022\n",
      "epoch: 6 step: 1961, loss is 0.012951512821018696\n",
      "epoch: 6 step: 1962, loss is 0.00552797457203269\n",
      "epoch: 6 step: 1963, loss is 0.00016722492000553757\n",
      "epoch: 6 step: 1964, loss is 0.00246449070982635\n",
      "epoch: 6 step: 1965, loss is 0.00041827166569419205\n",
      "epoch: 6 step: 1966, loss is 0.006975583732128143\n",
      "epoch: 6 step: 1967, loss is 0.01811770163476467\n",
      "epoch: 6 step: 1968, loss is 0.0035488407593220472\n",
      "epoch: 6 step: 1969, loss is 0.001832572859711945\n",
      "epoch: 6 step: 1970, loss is 0.22597502171993256\n",
      "epoch: 6 step: 1971, loss is 0.000548581825569272\n",
      "epoch: 6 step: 1972, loss is 0.0018655371386557817\n",
      "epoch: 6 step: 1973, loss is 0.012793358415365219\n",
      "epoch: 6 step: 1974, loss is 0.010295660234987736\n",
      "epoch: 6 step: 1975, loss is 0.0021792054176330566\n",
      "epoch: 6 step: 1976, loss is 0.0003150213451590389\n",
      "epoch: 6 step: 1977, loss is 0.000788659555837512\n",
      "epoch: 6 step: 1978, loss is 0.0009301265235990286\n",
      "epoch: 6 step: 1979, loss is 0.027415651828050613\n",
      "epoch: 6 step: 1980, loss is 0.03876601532101631\n",
      "epoch: 6 step: 1981, loss is 0.0012209482956677675\n",
      "epoch: 6 step: 1982, loss is 6.255586049519479e-05\n",
      "epoch: 6 step: 1983, loss is 0.0170671958476305\n",
      "epoch: 6 step: 1984, loss is 0.00031269469764083624\n",
      "epoch: 6 step: 1985, loss is 0.0035537038929760456\n",
      "epoch: 6 step: 1986, loss is 0.03986501321196556\n",
      "epoch: 6 step: 1987, loss is 0.010966356843709946\n",
      "epoch: 6 step: 1988, loss is 0.0032590958289802074\n",
      "epoch: 6 step: 1989, loss is 0.020575610920786858\n",
      "epoch: 6 step: 1990, loss is 0.03522399812936783\n",
      "epoch: 6 step: 1991, loss is 0.010948695242404938\n",
      "epoch: 6 step: 1992, loss is 0.0005072258063592017\n",
      "epoch: 6 step: 1993, loss is 0.03915068134665489\n",
      "epoch: 6 step: 1994, loss is 0.00466959411278367\n",
      "epoch: 6 step: 1995, loss is 0.0028817204292863607\n",
      "epoch: 6 step: 1996, loss is 0.05095219239592552\n",
      "epoch: 6 step: 1997, loss is 0.00511219073086977\n",
      "epoch: 6 step: 1998, loss is 0.00886177085340023\n",
      "epoch: 6 step: 1999, loss is 0.0017208100762218237\n",
      "epoch: 6 step: 2000, loss is 0.044827863574028015\n",
      "epoch: 6 step: 2001, loss is 0.0043510375544428825\n",
      "epoch: 6 step: 2002, loss is 0.005340928211808205\n",
      "epoch: 6 step: 2003, loss is 0.000262920162640512\n",
      "epoch: 6 step: 2004, loss is 0.007826761342585087\n",
      "epoch: 6 step: 2005, loss is 0.0074653420597314835\n",
      "epoch: 6 step: 2006, loss is 0.0031875306740403175\n",
      "epoch: 6 step: 2007, loss is 0.003648853860795498\n",
      "epoch: 6 step: 2008, loss is 0.004371738992631435\n",
      "epoch: 6 step: 2009, loss is 0.00039786906563676894\n",
      "epoch: 6 step: 2010, loss is 0.06635618209838867\n",
      "epoch: 6 step: 2011, loss is 0.20209187269210815\n",
      "epoch: 6 step: 2012, loss is 8.95206267159665e-06\n",
      "epoch: 6 step: 2013, loss is 0.0025451716501265764\n",
      "epoch: 6 step: 2014, loss is 0.004469381179660559\n",
      "epoch: 6 step: 2015, loss is 0.00019387301290407777\n",
      "epoch: 6 step: 2016, loss is 0.08308054506778717\n",
      "epoch: 6 step: 2017, loss is 0.01843707635998726\n",
      "epoch: 6 step: 2018, loss is 3.471851232461631e-05\n",
      "epoch: 6 step: 2019, loss is 0.0005883460398763418\n",
      "epoch: 6 step: 2020, loss is 2.252457124995999e-05\n",
      "epoch: 6 step: 2021, loss is 0.003353280480951071\n",
      "epoch: 6 step: 2022, loss is 0.00037882401375100017\n",
      "epoch: 6 step: 2023, loss is 0.0007361730677075684\n",
      "epoch: 6 step: 2024, loss is 0.0019623753614723682\n",
      "epoch: 6 step: 2025, loss is 0.001367922523058951\n",
      "epoch: 6 step: 2026, loss is 0.0030460550915449858\n",
      "epoch: 6 step: 2027, loss is 0.01805013045668602\n",
      "epoch: 6 step: 2028, loss is 0.12314510345458984\n",
      "epoch: 6 step: 2029, loss is 0.00010611807374516502\n",
      "epoch: 6 step: 2030, loss is 0.0004427004896569997\n",
      "epoch: 6 step: 2031, loss is 0.017786169424653053\n",
      "epoch: 6 step: 2032, loss is 0.04772188887000084\n",
      "epoch: 6 step: 2033, loss is 0.03790518641471863\n",
      "epoch: 6 step: 2034, loss is 0.01343186479061842\n",
      "epoch: 6 step: 2035, loss is 9.851669165072963e-05\n",
      "epoch: 6 step: 2036, loss is 0.002428351901471615\n",
      "epoch: 6 step: 2037, loss is 0.001028616214171052\n",
      "epoch: 6 step: 2038, loss is 0.059524647891521454\n",
      "epoch: 6 step: 2039, loss is 0.011250044219195843\n",
      "epoch: 6 step: 2040, loss is 0.0005771999713033438\n",
      "epoch: 6 step: 2041, loss is 0.006632612552493811\n",
      "epoch: 6 step: 2042, loss is 0.01784198358654976\n",
      "epoch: 6 step: 2043, loss is 0.005592587869614363\n",
      "epoch: 6 step: 2044, loss is 0.07571188360452652\n",
      "epoch: 6 step: 2045, loss is 0.0011878141667693853\n",
      "epoch: 6 step: 2046, loss is 0.0010357071878388524\n",
      "epoch: 6 step: 2047, loss is 0.004240422509610653\n",
      "epoch: 6 step: 2048, loss is 0.00010149014997296035\n",
      "epoch: 6 step: 2049, loss is 0.00045327539555728436\n",
      "epoch: 6 step: 2050, loss is 0.0011083862045779824\n",
      "epoch: 6 step: 2051, loss is 9.445584146305919e-05\n",
      "epoch: 6 step: 2052, loss is 0.1303817480802536\n",
      "epoch: 6 step: 2053, loss is 0.0398680604994297\n",
      "epoch: 6 step: 2054, loss is 0.0003361570416018367\n",
      "epoch: 6 step: 2055, loss is 0.0007776367128826678\n",
      "epoch: 6 step: 2056, loss is 0.08160839974880219\n",
      "epoch: 6 step: 2057, loss is 0.027119968086481094\n",
      "epoch: 6 step: 2058, loss is 0.014879945665597916\n",
      "epoch: 6 step: 2059, loss is 0.00044114887714385986\n",
      "epoch: 6 step: 2060, loss is 0.00130639155395329\n",
      "epoch: 6 step: 2061, loss is 0.0011853653704747558\n",
      "epoch: 6 step: 2062, loss is 0.0008347979746758938\n",
      "epoch: 6 step: 2063, loss is 0.007424245588481426\n",
      "epoch: 6 step: 2064, loss is 0.000830816978123039\n",
      "epoch: 6 step: 2065, loss is 0.0819484144449234\n",
      "epoch: 6 step: 2066, loss is 0.00014132284559309483\n",
      "epoch: 6 step: 2067, loss is 0.01985759846866131\n",
      "epoch: 6 step: 2068, loss is 0.007139555644243956\n",
      "epoch: 6 step: 2069, loss is 0.0006414771196432412\n",
      "epoch: 6 step: 2070, loss is 0.02543051727116108\n",
      "epoch: 6 step: 2071, loss is 0.002246046904474497\n",
      "epoch: 6 step: 2072, loss is 3.7131874705664814e-05\n",
      "epoch: 6 step: 2073, loss is 0.05209412798285484\n",
      "epoch: 6 step: 2074, loss is 0.002818983281031251\n",
      "epoch: 6 step: 2075, loss is 0.031063225120306015\n",
      "epoch: 6 step: 2076, loss is 0.013628695160150528\n",
      "epoch: 6 step: 2077, loss is 0.02577224001288414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 2078, loss is 0.006011787801980972\n",
      "epoch: 6 step: 2079, loss is 0.0012236351612955332\n",
      "epoch: 6 step: 2080, loss is 0.009676230140030384\n",
      "epoch: 6 step: 2081, loss is 0.00016622585826553404\n",
      "epoch: 6 step: 2082, loss is 0.0011032713809981942\n",
      "epoch: 6 step: 2083, loss is 0.018748242408037186\n",
      "epoch: 6 step: 2084, loss is 0.003174732206389308\n",
      "epoch: 6 step: 2085, loss is 0.03596893697977066\n",
      "epoch: 6 step: 2086, loss is 0.005233734380453825\n",
      "epoch: 6 step: 2087, loss is 0.00037776367389597\n",
      "epoch: 6 step: 2088, loss is 0.0006508402875624597\n",
      "epoch: 6 step: 2089, loss is 0.005301196128129959\n",
      "epoch: 6 step: 2090, loss is 0.0007323760073632002\n",
      "epoch: 6 step: 2091, loss is 0.006187063176184893\n",
      "epoch: 6 step: 2092, loss is 0.002165386453270912\n",
      "epoch: 6 step: 2093, loss is 0.00019491063721943647\n",
      "epoch: 6 step: 2094, loss is 0.0009586732485331595\n",
      "epoch: 6 step: 2095, loss is 0.06946467608213425\n",
      "epoch: 6 step: 2096, loss is 0.0014236101415008307\n",
      "epoch: 6 step: 2097, loss is 0.011474806815385818\n",
      "epoch: 6 step: 2098, loss is 0.11137492954730988\n",
      "epoch: 6 step: 2099, loss is 0.0019328498747199774\n",
      "epoch: 6 step: 2100, loss is 6.920612941030413e-05\n",
      "epoch: 6 step: 2101, loss is 0.002120339311659336\n",
      "epoch: 6 step: 2102, loss is 0.009085236117243767\n",
      "epoch: 6 step: 2103, loss is 0.00016347301425412297\n",
      "epoch: 6 step: 2104, loss is 0.0013509419513866305\n",
      "epoch: 6 step: 2105, loss is 0.02003815583884716\n",
      "epoch: 6 step: 2106, loss is 0.0034594140015542507\n",
      "epoch: 6 step: 2107, loss is 0.01396652776747942\n",
      "epoch: 6 step: 2108, loss is 0.0035823993384838104\n",
      "epoch: 6 step: 2109, loss is 0.002789172576740384\n",
      "epoch: 6 step: 2110, loss is 0.00670541450381279\n",
      "epoch: 6 step: 2111, loss is 0.08988265693187714\n",
      "epoch: 6 step: 2112, loss is 0.0013183271512389183\n",
      "epoch: 6 step: 2113, loss is 0.02770976535975933\n",
      "epoch: 6 step: 2114, loss is 0.0011054683709517121\n",
      "epoch: 6 step: 2115, loss is 0.002639814279973507\n",
      "epoch: 6 step: 2116, loss is 0.0009015492396429181\n",
      "epoch: 6 step: 2117, loss is 0.005416615400463343\n",
      "epoch: 6 step: 2118, loss is 0.0033973976969718933\n",
      "epoch: 6 step: 2119, loss is 0.007880184799432755\n",
      "epoch: 6 step: 2120, loss is 0.06881634891033173\n",
      "epoch: 6 step: 2121, loss is 0.10263931006193161\n",
      "epoch: 6 step: 2122, loss is 0.011338915675878525\n",
      "epoch: 6 step: 2123, loss is 0.0498637855052948\n",
      "epoch: 6 step: 2124, loss is 0.008721341378986835\n",
      "epoch: 6 step: 2125, loss is 7.571368769276887e-05\n",
      "epoch: 6 step: 2126, loss is 0.050715964287519455\n",
      "epoch: 6 step: 2127, loss is 8.677808364154771e-05\n",
      "epoch: 6 step: 2128, loss is 0.022958187386393547\n",
      "epoch: 6 step: 2129, loss is 0.0018549143569543958\n",
      "epoch: 6 step: 2130, loss is 0.0001665569725446403\n",
      "epoch: 6 step: 2131, loss is 0.009198012761771679\n",
      "epoch: 6 step: 2132, loss is 0.007997511886060238\n",
      "epoch: 6 step: 2133, loss is 0.0267866812646389\n",
      "epoch: 6 step: 2134, loss is 0.0003567625826690346\n",
      "epoch: 6 step: 2135, loss is 0.00011395628825994208\n",
      "epoch: 6 step: 2136, loss is 0.023518245667219162\n",
      "epoch: 6 step: 2137, loss is 0.0004340636951383203\n",
      "epoch: 6 step: 2138, loss is 0.036508478224277496\n",
      "epoch: 6 step: 2139, loss is 0.08478999137878418\n",
      "epoch: 6 step: 2140, loss is 0.1233835443854332\n",
      "epoch: 6 step: 2141, loss is 0.007476072758436203\n",
      "epoch: 6 step: 2142, loss is 0.1018650233745575\n",
      "epoch: 6 step: 2143, loss is 0.006004702765494585\n",
      "epoch: 6 step: 2144, loss is 0.005872504319995642\n",
      "epoch: 6 step: 2145, loss is 0.01414929423481226\n",
      "epoch: 6 step: 2146, loss is 0.017450442537665367\n",
      "epoch: 6 step: 2147, loss is 0.003778176149353385\n",
      "epoch: 6 step: 2148, loss is 0.0009482114692218602\n",
      "epoch: 6 step: 2149, loss is 0.03232689946889877\n",
      "epoch: 6 step: 2150, loss is 0.04478586092591286\n",
      "epoch: 6 step: 2151, loss is 0.005704458337277174\n",
      "epoch: 6 step: 2152, loss is 0.005746733397245407\n",
      "epoch: 6 step: 2153, loss is 4.1873314330587164e-05\n",
      "epoch: 6 step: 2154, loss is 0.021056262776255608\n",
      "epoch: 6 step: 2155, loss is 0.0006602221401408315\n",
      "epoch: 6 step: 2156, loss is 0.011957411654293537\n",
      "epoch: 6 step: 2157, loss is 7.373589323833585e-05\n",
      "epoch: 6 step: 2158, loss is 6.054413825040683e-05\n",
      "epoch: 6 step: 2159, loss is 0.3271460235118866\n",
      "epoch: 6 step: 2160, loss is 0.0011557182297110558\n",
      "epoch: 6 step: 2161, loss is 0.0006562889320775867\n",
      "epoch: 6 step: 2162, loss is 0.129072904586792\n",
      "epoch: 6 step: 2163, loss is 0.022991321980953217\n",
      "epoch: 6 step: 2164, loss is 0.0035404583904892206\n",
      "epoch: 6 step: 2165, loss is 0.0008130368660204113\n",
      "epoch: 6 step: 2166, loss is 0.00019493253785185516\n",
      "epoch: 6 step: 2167, loss is 0.09037643671035767\n",
      "epoch: 6 step: 2168, loss is 0.05293191596865654\n",
      "epoch: 6 step: 2169, loss is 0.0003589748521335423\n",
      "epoch: 6 step: 2170, loss is 0.0009116028086282313\n",
      "epoch: 6 step: 2171, loss is 0.0026503955014050007\n",
      "epoch: 6 step: 2172, loss is 0.01889481022953987\n",
      "epoch: 6 step: 2173, loss is 0.025481820106506348\n",
      "epoch: 6 step: 2174, loss is 0.020478978753089905\n",
      "epoch: 6 step: 2175, loss is 0.006810723803937435\n",
      "epoch: 6 step: 2176, loss is 0.008205359801650047\n",
      "epoch: 6 step: 2177, loss is 0.0005589637439697981\n",
      "epoch: 6 step: 2178, loss is 0.00029204002930782735\n",
      "epoch: 6 step: 2179, loss is 0.0060166725888848305\n",
      "epoch: 6 step: 2180, loss is 0.05439479649066925\n",
      "epoch: 6 step: 2181, loss is 0.0002757542533800006\n",
      "epoch: 6 step: 2182, loss is 0.002498718909919262\n",
      "epoch: 6 step: 2183, loss is 0.01227451954036951\n",
      "epoch: 6 step: 2184, loss is 0.0005824493709951639\n",
      "epoch: 6 step: 2185, loss is 0.0016879012109711766\n",
      "epoch: 6 step: 2186, loss is 0.00579479057341814\n",
      "epoch: 6 step: 2187, loss is 0.0014374711317941546\n",
      "epoch: 7 step: 1, loss is 9.794885409064591e-05\n",
      "epoch: 7 step: 2, loss is 0.0014570584753528237\n",
      "epoch: 7 step: 3, loss is 0.026618236675858498\n",
      "epoch: 7 step: 4, loss is 0.0013023419305682182\n",
      "epoch: 7 step: 5, loss is 0.0002560168213676661\n",
      "epoch: 7 step: 6, loss is 5.6050295825116336e-05\n",
      "epoch: 7 step: 7, loss is 0.0002265918446937576\n",
      "epoch: 7 step: 8, loss is 0.00031680299434810877\n",
      "epoch: 7 step: 9, loss is 0.02786041609942913\n",
      "epoch: 7 step: 10, loss is 0.0007470606942661107\n",
      "epoch: 7 step: 11, loss is 0.0001934362226165831\n",
      "epoch: 7 step: 12, loss is 0.021414589136838913\n",
      "epoch: 7 step: 13, loss is 0.0001689861819613725\n",
      "epoch: 7 step: 14, loss is 0.0026903008110821247\n",
      "epoch: 7 step: 15, loss is 0.0007176997023634613\n",
      "epoch: 7 step: 16, loss is 0.0006685085245408118\n",
      "epoch: 7 step: 17, loss is 0.03116973675787449\n",
      "epoch: 7 step: 18, loss is 0.0015038646524772048\n",
      "epoch: 7 step: 19, loss is 0.002661975799128413\n",
      "epoch: 7 step: 20, loss is 0.0002194062399212271\n",
      "epoch: 7 step: 21, loss is 0.022574961185455322\n",
      "epoch: 7 step: 22, loss is 0.021634357050061226\n",
      "epoch: 7 step: 23, loss is 0.009137335233390331\n",
      "epoch: 7 step: 24, loss is 0.05134684592485428\n",
      "epoch: 7 step: 25, loss is 0.0004285758186597377\n",
      "epoch: 7 step: 26, loss is 0.00044180898112244904\n",
      "epoch: 7 step: 27, loss is 0.06381455808877945\n",
      "epoch: 7 step: 28, loss is 0.00226439512334764\n",
      "epoch: 7 step: 29, loss is 0.005836206488311291\n",
      "epoch: 7 step: 30, loss is 0.0005116687971167266\n",
      "epoch: 7 step: 31, loss is 0.0016700862906873226\n",
      "epoch: 7 step: 32, loss is 0.10065124928951263\n",
      "epoch: 7 step: 33, loss is 0.0016634673811495304\n",
      "epoch: 7 step: 34, loss is 0.001769743743352592\n",
      "epoch: 7 step: 35, loss is 0.15201400220394135\n",
      "epoch: 7 step: 36, loss is 7.574062328785658e-05\n",
      "epoch: 7 step: 37, loss is 0.025934701785445213\n",
      "epoch: 7 step: 38, loss is 0.0039468323811888695\n",
      "epoch: 7 step: 39, loss is 0.00032097159419208765\n",
      "epoch: 7 step: 40, loss is 0.11230005323886871\n",
      "epoch: 7 step: 41, loss is 8.41684959596023e-05\n",
      "epoch: 7 step: 42, loss is 0.00011749770055757836\n",
      "epoch: 7 step: 43, loss is 0.005656637251377106\n",
      "epoch: 7 step: 44, loss is 0.00028978753834962845\n",
      "epoch: 7 step: 45, loss is 0.0045481096021831036\n",
      "epoch: 7 step: 46, loss is 0.014088972471654415\n",
      "epoch: 7 step: 47, loss is 0.01390073075890541\n",
      "epoch: 7 step: 48, loss is 0.06919369846582413\n",
      "epoch: 7 step: 49, loss is 0.003296456066891551\n",
      "epoch: 7 step: 50, loss is 0.0008380720391869545\n",
      "epoch: 7 step: 51, loss is 0.0001631547202123329\n",
      "epoch: 7 step: 52, loss is 0.0005825560656376183\n",
      "epoch: 7 step: 53, loss is 0.0015975042479112744\n",
      "epoch: 7 step: 54, loss is 0.0004689016495831311\n",
      "epoch: 7 step: 55, loss is 0.003860792610794306\n",
      "epoch: 7 step: 56, loss is 0.0006895629921928048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 57, loss is 0.0004092292510904372\n",
      "epoch: 7 step: 58, loss is 0.004465295933187008\n",
      "epoch: 7 step: 59, loss is 0.00046483881305903196\n",
      "epoch: 7 step: 60, loss is 5.237782170297578e-05\n",
      "epoch: 7 step: 61, loss is 0.004343531560152769\n",
      "epoch: 7 step: 62, loss is 0.005302842240780592\n",
      "epoch: 7 step: 63, loss is 0.005415725987404585\n",
      "epoch: 7 step: 64, loss is 0.000735576031729579\n",
      "epoch: 7 step: 65, loss is 0.0005064081051386893\n",
      "epoch: 7 step: 66, loss is 0.051847320050001144\n",
      "epoch: 7 step: 67, loss is 0.015020701102912426\n",
      "epoch: 7 step: 68, loss is 0.00036306248512119055\n",
      "epoch: 7 step: 69, loss is 0.0052267746068537235\n",
      "epoch: 7 step: 70, loss is 0.004703313112258911\n",
      "epoch: 7 step: 71, loss is 9.414361556991935e-06\n",
      "epoch: 7 step: 72, loss is 0.0068551781587302685\n",
      "epoch: 7 step: 73, loss is 0.008247233927249908\n",
      "epoch: 7 step: 74, loss is 0.00036535284016281366\n",
      "epoch: 7 step: 75, loss is 0.0018629113910719752\n",
      "epoch: 7 step: 76, loss is 0.023733660578727722\n",
      "epoch: 7 step: 77, loss is 0.07209733128547668\n",
      "epoch: 7 step: 78, loss is 0.0001606234727660194\n",
      "epoch: 7 step: 79, loss is 0.0006427880725823343\n",
      "epoch: 7 step: 80, loss is 0.00677820248529315\n",
      "epoch: 7 step: 81, loss is 0.0036944421008229256\n",
      "epoch: 7 step: 82, loss is 0.0008057511877268553\n",
      "epoch: 7 step: 83, loss is 5.936684101470746e-05\n",
      "epoch: 7 step: 84, loss is 0.0006509432569146156\n",
      "epoch: 7 step: 85, loss is 3.9496939280070364e-05\n",
      "epoch: 7 step: 86, loss is 0.011783147230744362\n",
      "epoch: 7 step: 87, loss is 0.006713171023875475\n",
      "epoch: 7 step: 88, loss is 0.006620137020945549\n",
      "epoch: 7 step: 89, loss is 0.020144687965512276\n",
      "epoch: 7 step: 90, loss is 0.00250450661405921\n",
      "epoch: 7 step: 91, loss is 0.00018075077969115227\n",
      "epoch: 7 step: 92, loss is 0.00010544944962020963\n",
      "epoch: 7 step: 93, loss is 4.1294857510365546e-05\n",
      "epoch: 7 step: 94, loss is 0.0003091262769885361\n",
      "epoch: 7 step: 95, loss is 0.001085046329535544\n",
      "epoch: 7 step: 96, loss is 0.023068688809871674\n",
      "epoch: 7 step: 97, loss is 0.00017196836415678263\n",
      "epoch: 7 step: 98, loss is 0.03928934037685394\n",
      "epoch: 7 step: 99, loss is 0.0006900118314661086\n",
      "epoch: 7 step: 100, loss is 0.00014362254296429455\n",
      "epoch: 7 step: 101, loss is 0.11033044010400772\n",
      "epoch: 7 step: 102, loss is 2.0152430806774646e-05\n",
      "epoch: 7 step: 103, loss is 0.034110795706510544\n",
      "epoch: 7 step: 104, loss is 0.0005804951069876552\n",
      "epoch: 7 step: 105, loss is 0.00010421696788398549\n",
      "epoch: 7 step: 106, loss is 0.0025336039252579212\n",
      "epoch: 7 step: 107, loss is 0.0005033420748077333\n",
      "epoch: 7 step: 108, loss is 0.004496301524341106\n",
      "epoch: 7 step: 109, loss is 0.0005254863062873483\n",
      "epoch: 7 step: 110, loss is 0.040063150227069855\n",
      "epoch: 7 step: 111, loss is 0.0034092033747583628\n",
      "epoch: 7 step: 112, loss is 0.000335887772962451\n",
      "epoch: 7 step: 113, loss is 0.011036464013159275\n",
      "epoch: 7 step: 114, loss is 0.06922633945941925\n",
      "epoch: 7 step: 115, loss is 0.0028628152795135975\n",
      "epoch: 7 step: 116, loss is 0.00040973760769702494\n",
      "epoch: 7 step: 117, loss is 0.026037683710455894\n",
      "epoch: 7 step: 118, loss is 0.006928869988769293\n",
      "epoch: 7 step: 119, loss is 0.00013467339158523828\n",
      "epoch: 7 step: 120, loss is 0.005916649475693703\n",
      "epoch: 7 step: 121, loss is 0.0025013245176523924\n",
      "epoch: 7 step: 122, loss is 0.009373792447149754\n",
      "epoch: 7 step: 123, loss is 0.010492892004549503\n",
      "epoch: 7 step: 124, loss is 5.550617788685486e-05\n",
      "epoch: 7 step: 125, loss is 0.03769093006849289\n",
      "epoch: 7 step: 126, loss is 0.006778493523597717\n",
      "epoch: 7 step: 127, loss is 0.0007348082726821303\n",
      "epoch: 7 step: 128, loss is 0.00011946754239033908\n",
      "epoch: 7 step: 129, loss is 0.007286510430276394\n",
      "epoch: 7 step: 130, loss is 0.001956949010491371\n",
      "epoch: 7 step: 131, loss is 0.0054025775752961636\n",
      "epoch: 7 step: 132, loss is 0.0001743940229061991\n",
      "epoch: 7 step: 133, loss is 0.0004181138938292861\n",
      "epoch: 7 step: 134, loss is 0.007016654126346111\n",
      "epoch: 7 step: 135, loss is 3.247128915973008e-05\n",
      "epoch: 7 step: 136, loss is 0.0010349588701501489\n",
      "epoch: 7 step: 137, loss is 0.0002273223508382216\n",
      "epoch: 7 step: 138, loss is 0.0006289242301136255\n",
      "epoch: 7 step: 139, loss is 0.027778491377830505\n",
      "epoch: 7 step: 140, loss is 0.05695111304521561\n",
      "epoch: 7 step: 141, loss is 0.037775661796331406\n",
      "epoch: 7 step: 142, loss is 0.00032435261528007686\n",
      "epoch: 7 step: 143, loss is 0.015164713375270367\n",
      "epoch: 7 step: 144, loss is 0.07954232394695282\n",
      "epoch: 7 step: 145, loss is 0.001659800997003913\n",
      "epoch: 7 step: 146, loss is 0.00018667806580197066\n",
      "epoch: 7 step: 147, loss is 0.0003375019005034119\n",
      "epoch: 7 step: 148, loss is 0.0005764483939856291\n",
      "epoch: 7 step: 149, loss is 0.004647477529942989\n",
      "epoch: 7 step: 150, loss is 0.01626189798116684\n",
      "epoch: 7 step: 151, loss is 0.024226289242506027\n",
      "epoch: 7 step: 152, loss is 0.13251878321170807\n",
      "epoch: 7 step: 153, loss is 0.05162205547094345\n",
      "epoch: 7 step: 154, loss is 0.036709558218717575\n",
      "epoch: 7 step: 155, loss is 0.05077878758311272\n",
      "epoch: 7 step: 156, loss is 0.13247284293174744\n",
      "epoch: 7 step: 157, loss is 0.0007174533675424755\n",
      "epoch: 7 step: 158, loss is 0.2701510488986969\n",
      "epoch: 7 step: 159, loss is 0.00037665333366021514\n",
      "epoch: 7 step: 160, loss is 0.08345102518796921\n",
      "epoch: 7 step: 161, loss is 0.0002685533545445651\n",
      "epoch: 7 step: 162, loss is 0.049405086785554886\n",
      "epoch: 7 step: 163, loss is 0.0004963069222867489\n",
      "epoch: 7 step: 164, loss is 0.0002875210193451494\n",
      "epoch: 7 step: 165, loss is 0.005238932557404041\n",
      "epoch: 7 step: 166, loss is 0.015851804986596107\n",
      "epoch: 7 step: 167, loss is 0.05380485579371452\n",
      "epoch: 7 step: 168, loss is 0.0011276358272880316\n",
      "epoch: 7 step: 169, loss is 0.003472851123660803\n",
      "epoch: 7 step: 170, loss is 0.04446158930659294\n",
      "epoch: 7 step: 171, loss is 0.001936452928930521\n",
      "epoch: 7 step: 172, loss is 0.002293149009346962\n",
      "epoch: 7 step: 173, loss is 0.001502590486779809\n",
      "epoch: 7 step: 174, loss is 0.0026292777620255947\n",
      "epoch: 7 step: 175, loss is 0.01620103418827057\n",
      "epoch: 7 step: 176, loss is 0.0015716890338808298\n",
      "epoch: 7 step: 177, loss is 0.006459523923695087\n",
      "epoch: 7 step: 178, loss is 0.01041899248957634\n",
      "epoch: 7 step: 179, loss is 5.1405826525297016e-05\n",
      "epoch: 7 step: 180, loss is 0.004188003949820995\n",
      "epoch: 7 step: 181, loss is 2.468344973749481e-05\n",
      "epoch: 7 step: 182, loss is 0.0001161221953225322\n",
      "epoch: 7 step: 183, loss is 0.00117562897503376\n",
      "epoch: 7 step: 184, loss is 0.0019400690216571093\n",
      "epoch: 7 step: 185, loss is 0.0003035101108253002\n",
      "epoch: 7 step: 186, loss is 9.479439904680476e-05\n",
      "epoch: 7 step: 187, loss is 0.0008242239709943533\n",
      "epoch: 7 step: 188, loss is 0.004286581184715033\n",
      "epoch: 7 step: 189, loss is 0.01763424649834633\n",
      "epoch: 7 step: 190, loss is 0.009361526928842068\n",
      "epoch: 7 step: 191, loss is 0.004033609293401241\n",
      "epoch: 7 step: 192, loss is 0.006244382821023464\n",
      "epoch: 7 step: 193, loss is 0.1310078203678131\n",
      "epoch: 7 step: 194, loss is 0.001213854760862887\n",
      "epoch: 7 step: 195, loss is 0.05759989470243454\n",
      "epoch: 7 step: 196, loss is 0.0002640409511514008\n",
      "epoch: 7 step: 197, loss is 0.011734637431800365\n",
      "epoch: 7 step: 198, loss is 2.235928513982799e-05\n",
      "epoch: 7 step: 199, loss is 0.09199916571378708\n",
      "epoch: 7 step: 200, loss is 0.026954006403684616\n",
      "epoch: 7 step: 201, loss is 0.0006583546637557447\n",
      "epoch: 7 step: 202, loss is 0.0034141705837100744\n",
      "epoch: 7 step: 203, loss is 0.005454724188894033\n",
      "epoch: 7 step: 204, loss is 4.413847273099236e-05\n",
      "epoch: 7 step: 205, loss is 0.0022639757953584194\n",
      "epoch: 7 step: 206, loss is 0.0019291929202154279\n",
      "epoch: 7 step: 207, loss is 4.305973925511353e-05\n",
      "epoch: 7 step: 208, loss is 0.0025433674454689026\n",
      "epoch: 7 step: 209, loss is 0.006497567053884268\n",
      "epoch: 7 step: 210, loss is 0.00019396324933040887\n",
      "epoch: 7 step: 211, loss is 0.0007766098133288324\n",
      "epoch: 7 step: 212, loss is 0.06049531698226929\n",
      "epoch: 7 step: 213, loss is 0.00917349848896265\n",
      "epoch: 7 step: 214, loss is 0.006569122429937124\n",
      "epoch: 7 step: 215, loss is 0.013744588941335678\n",
      "epoch: 7 step: 216, loss is 0.0008877422660589218\n",
      "epoch: 7 step: 217, loss is 0.06701730191707611\n",
      "epoch: 7 step: 218, loss is 0.0007545922417193651\n",
      "epoch: 7 step: 219, loss is 0.0003292378969490528\n",
      "epoch: 7 step: 220, loss is 0.006974057760089636\n",
      "epoch: 7 step: 221, loss is 0.05534912273287773\n",
      "epoch: 7 step: 222, loss is 6.024134563631378e-05\n",
      "epoch: 7 step: 223, loss is 0.0001664471928961575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 224, loss is 0.009662728756666183\n",
      "epoch: 7 step: 225, loss is 0.008976947516202927\n",
      "epoch: 7 step: 226, loss is 0.03874506428837776\n",
      "epoch: 7 step: 227, loss is 0.007120535708963871\n",
      "epoch: 7 step: 228, loss is 0.002255744766443968\n",
      "epoch: 7 step: 229, loss is 0.0049845874309539795\n",
      "epoch: 7 step: 230, loss is 0.012102097272872925\n",
      "epoch: 7 step: 231, loss is 0.000939693592954427\n",
      "epoch: 7 step: 232, loss is 0.00038918067002668977\n",
      "epoch: 7 step: 233, loss is 0.0020025221165269613\n",
      "epoch: 7 step: 234, loss is 0.049840811640024185\n",
      "epoch: 7 step: 235, loss is 0.0033035073429346085\n",
      "epoch: 7 step: 236, loss is 7.689270205446519e-06\n",
      "epoch: 7 step: 237, loss is 0.042356960475444794\n",
      "epoch: 7 step: 238, loss is 0.00437817582860589\n",
      "epoch: 7 step: 239, loss is 0.0021460470743477345\n",
      "epoch: 7 step: 240, loss is 0.004246702417731285\n",
      "epoch: 7 step: 241, loss is 0.00017318299796897918\n",
      "epoch: 7 step: 242, loss is 0.0002671743859536946\n",
      "epoch: 7 step: 243, loss is 0.0002975461829919368\n",
      "epoch: 7 step: 244, loss is 0.01302589476108551\n",
      "epoch: 7 step: 245, loss is 0.024160262197256088\n",
      "epoch: 7 step: 246, loss is 0.0002123560116160661\n",
      "epoch: 7 step: 247, loss is 0.002824031747877598\n",
      "epoch: 7 step: 248, loss is 0.013068892061710358\n",
      "epoch: 7 step: 249, loss is 0.0002036621590377763\n",
      "epoch: 7 step: 250, loss is 0.011870778165757656\n",
      "epoch: 7 step: 251, loss is 0.00018974466365762055\n",
      "epoch: 7 step: 252, loss is 0.0009391208877786994\n",
      "epoch: 7 step: 253, loss is 0.0026080862153321505\n",
      "epoch: 7 step: 254, loss is 1.3597751603811048e-05\n",
      "epoch: 7 step: 255, loss is 0.0009945888305082917\n",
      "epoch: 7 step: 256, loss is 0.0005622125463560224\n",
      "epoch: 7 step: 257, loss is 0.0007800362654961646\n",
      "epoch: 7 step: 258, loss is 7.124279363779351e-05\n",
      "epoch: 7 step: 259, loss is 0.011460459791123867\n",
      "epoch: 7 step: 260, loss is 0.0153371412307024\n",
      "epoch: 7 step: 261, loss is 0.0021325326524674892\n",
      "epoch: 7 step: 262, loss is 0.00014802024816162884\n",
      "epoch: 7 step: 263, loss is 0.00010619925160426646\n",
      "epoch: 7 step: 264, loss is 9.699443762656301e-05\n",
      "epoch: 7 step: 265, loss is 0.0002699850301723927\n",
      "epoch: 7 step: 266, loss is 0.0034304680302739143\n",
      "epoch: 7 step: 267, loss is 4.3660911615006626e-05\n",
      "epoch: 7 step: 268, loss is 0.00016651967598591\n",
      "epoch: 7 step: 269, loss is 0.01055788155645132\n",
      "epoch: 7 step: 270, loss is 0.02311992645263672\n",
      "epoch: 7 step: 271, loss is 0.0005529580521397293\n",
      "epoch: 7 step: 272, loss is 7.052289583953097e-05\n",
      "epoch: 7 step: 273, loss is 0.00020478447549976408\n",
      "epoch: 7 step: 274, loss is 0.15914547443389893\n",
      "epoch: 7 step: 275, loss is 8.262927622126881e-06\n",
      "epoch: 7 step: 276, loss is 0.013663641177117825\n",
      "epoch: 7 step: 277, loss is 0.0003635954635683447\n",
      "epoch: 7 step: 278, loss is 4.8359797801822424e-05\n",
      "epoch: 7 step: 279, loss is 0.02026546373963356\n",
      "epoch: 7 step: 280, loss is 0.007375956978648901\n",
      "epoch: 7 step: 281, loss is 0.0034162632655352354\n",
      "epoch: 7 step: 282, loss is 0.0018030203646048903\n",
      "epoch: 7 step: 283, loss is 0.0008378042257390916\n",
      "epoch: 7 step: 284, loss is 0.01788823865354061\n",
      "epoch: 7 step: 285, loss is 0.011578201316297054\n",
      "epoch: 7 step: 286, loss is 0.0042792209424078465\n",
      "epoch: 7 step: 287, loss is 0.00014786618703510612\n",
      "epoch: 7 step: 288, loss is 0.0004277299449313432\n",
      "epoch: 7 step: 289, loss is 0.001392335630953312\n",
      "epoch: 7 step: 290, loss is 0.14046117663383484\n",
      "epoch: 7 step: 291, loss is 0.0013249729527160525\n",
      "epoch: 7 step: 292, loss is 0.015383029356598854\n",
      "epoch: 7 step: 293, loss is 0.016527209430933\n",
      "epoch: 7 step: 294, loss is 0.001054698950611055\n",
      "epoch: 7 step: 295, loss is 0.05049576610326767\n",
      "epoch: 7 step: 296, loss is 0.0003168139955960214\n",
      "epoch: 7 step: 297, loss is 0.02574848383665085\n",
      "epoch: 7 step: 298, loss is 0.0021087639033794403\n",
      "epoch: 7 step: 299, loss is 0.023763692006468773\n",
      "epoch: 7 step: 300, loss is 0.002041734755039215\n",
      "epoch: 7 step: 301, loss is 0.0016069869743660092\n",
      "epoch: 7 step: 302, loss is 0.12772944569587708\n",
      "epoch: 7 step: 303, loss is 0.004000845830887556\n",
      "epoch: 7 step: 304, loss is 0.0020920189563184977\n",
      "epoch: 7 step: 305, loss is 0.0012502921745181084\n",
      "epoch: 7 step: 306, loss is 0.0011194179533049464\n",
      "epoch: 7 step: 307, loss is 0.0014239427400752902\n",
      "epoch: 7 step: 308, loss is 0.0003585302329156548\n",
      "epoch: 7 step: 309, loss is 0.0004199792165309191\n",
      "epoch: 7 step: 310, loss is 0.0031614694744348526\n",
      "epoch: 7 step: 311, loss is 0.00017368540284223855\n",
      "epoch: 7 step: 312, loss is 0.03024921379983425\n",
      "epoch: 7 step: 313, loss is 0.03962244465947151\n",
      "epoch: 7 step: 314, loss is 0.00015451481158379465\n",
      "epoch: 7 step: 315, loss is 0.0006326533039100468\n",
      "epoch: 7 step: 316, loss is 0.02566598355770111\n",
      "epoch: 7 step: 317, loss is 0.0010880355257540941\n",
      "epoch: 7 step: 318, loss is 0.0012928139185532928\n",
      "epoch: 7 step: 319, loss is 0.0024155168794095516\n",
      "epoch: 7 step: 320, loss is 0.00012742989929392934\n",
      "epoch: 7 step: 321, loss is 0.0026730848476290703\n",
      "epoch: 7 step: 322, loss is 6.136559386504814e-05\n",
      "epoch: 7 step: 323, loss is 0.004036317579448223\n",
      "epoch: 7 step: 324, loss is 0.0016280817799270153\n",
      "epoch: 7 step: 325, loss is 0.005262112244963646\n",
      "epoch: 7 step: 326, loss is 0.00120845518540591\n",
      "epoch: 7 step: 327, loss is 0.0041899653151631355\n",
      "epoch: 7 step: 328, loss is 0.002456375863403082\n",
      "epoch: 7 step: 329, loss is 0.008011306636035442\n",
      "epoch: 7 step: 330, loss is 0.11640322208404541\n",
      "epoch: 7 step: 331, loss is 0.00024962396128103137\n",
      "epoch: 7 step: 332, loss is 0.010146040469408035\n",
      "epoch: 7 step: 333, loss is 0.0005764606175944209\n",
      "epoch: 7 step: 334, loss is 0.0005103919538669288\n",
      "epoch: 7 step: 335, loss is 0.16047503054141998\n",
      "epoch: 7 step: 336, loss is 0.03925032168626785\n",
      "epoch: 7 step: 337, loss is 0.08994974941015244\n",
      "epoch: 7 step: 338, loss is 0.00028505895170383155\n",
      "epoch: 7 step: 339, loss is 0.09056112170219421\n",
      "epoch: 7 step: 340, loss is 0.00020046927966177464\n",
      "epoch: 7 step: 341, loss is 0.00035165532608516514\n",
      "epoch: 7 step: 342, loss is 0.0007373110856860876\n",
      "epoch: 7 step: 343, loss is 0.05958488583564758\n",
      "epoch: 7 step: 344, loss is 0.0002323762164451182\n",
      "epoch: 7 step: 345, loss is 0.0009083984768949449\n",
      "epoch: 7 step: 346, loss is 0.011256374418735504\n",
      "epoch: 7 step: 347, loss is 0.024513844400644302\n",
      "epoch: 7 step: 348, loss is 0.0008836198830977082\n",
      "epoch: 7 step: 349, loss is 0.004124550614506006\n",
      "epoch: 7 step: 350, loss is 0.010311604477465153\n",
      "epoch: 7 step: 351, loss is 0.0002734377922024578\n",
      "epoch: 7 step: 352, loss is 7.566841668449342e-05\n",
      "epoch: 7 step: 353, loss is 0.06226341426372528\n",
      "epoch: 7 step: 354, loss is 0.0007302709855139256\n",
      "epoch: 7 step: 355, loss is 0.0001627944002393633\n",
      "epoch: 7 step: 356, loss is 0.009690641425549984\n",
      "epoch: 7 step: 357, loss is 5.4888485465198755e-05\n",
      "epoch: 7 step: 358, loss is 0.00039993913378566504\n",
      "epoch: 7 step: 359, loss is 0.00039022357668727636\n",
      "epoch: 7 step: 360, loss is 0.0031000834424048662\n",
      "epoch: 7 step: 361, loss is 0.0009174811420962214\n",
      "epoch: 7 step: 362, loss is 0.0051271868869662285\n",
      "epoch: 7 step: 363, loss is 0.00016040397167671472\n",
      "epoch: 7 step: 364, loss is 0.00014940297114662826\n",
      "epoch: 7 step: 365, loss is 0.007844474166631699\n",
      "epoch: 7 step: 366, loss is 0.00034678290830925107\n",
      "epoch: 7 step: 367, loss is 0.0006823253352195024\n",
      "epoch: 7 step: 368, loss is 0.00016104915994219482\n",
      "epoch: 7 step: 369, loss is 0.006592644844204187\n",
      "epoch: 7 step: 370, loss is 0.0005182524328120053\n",
      "epoch: 7 step: 371, loss is 0.0008197647402994335\n",
      "epoch: 7 step: 372, loss is 2.7483454687171616e-05\n",
      "epoch: 7 step: 373, loss is 0.003543115220963955\n",
      "epoch: 7 step: 374, loss is 0.0011126560857519507\n",
      "epoch: 7 step: 375, loss is 0.001453078119084239\n",
      "epoch: 7 step: 376, loss is 0.00011261129111517221\n",
      "epoch: 7 step: 377, loss is 0.00021209860278759152\n",
      "epoch: 7 step: 378, loss is 0.0014723954955115914\n",
      "epoch: 7 step: 379, loss is 0.001154051860794425\n",
      "epoch: 7 step: 380, loss is 0.001071039354428649\n",
      "epoch: 7 step: 381, loss is 0.0013043800136074424\n",
      "epoch: 7 step: 382, loss is 0.00965105276554823\n",
      "epoch: 7 step: 383, loss is 0.0005614840192720294\n",
      "epoch: 7 step: 384, loss is 0.00013771108933724463\n",
      "epoch: 7 step: 385, loss is 0.03628639131784439\n",
      "epoch: 7 step: 386, loss is 0.004685745108872652\n",
      "epoch: 7 step: 387, loss is 0.00010016428859671578\n",
      "epoch: 7 step: 388, loss is 0.0006402608123607934\n",
      "epoch: 7 step: 389, loss is 0.003092039842158556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 390, loss is 7.894927693996578e-05\n",
      "epoch: 7 step: 391, loss is 0.0003846618055831641\n",
      "epoch: 7 step: 392, loss is 0.00043262209510430694\n",
      "epoch: 7 step: 393, loss is 0.006630514282733202\n",
      "epoch: 7 step: 394, loss is 0.003956445027142763\n",
      "epoch: 7 step: 395, loss is 0.11084303259849548\n",
      "epoch: 7 step: 396, loss is 0.025379030033946037\n",
      "epoch: 7 step: 397, loss is 0.00044402058119885623\n",
      "epoch: 7 step: 398, loss is 0.0006949265371076763\n",
      "epoch: 7 step: 399, loss is 0.0014424278633669019\n",
      "epoch: 7 step: 400, loss is 0.0011621264275163412\n",
      "epoch: 7 step: 401, loss is 0.00010667987953638658\n",
      "epoch: 7 step: 402, loss is 0.00015366179286502302\n",
      "epoch: 7 step: 403, loss is 0.009532179683446884\n",
      "epoch: 7 step: 404, loss is 0.0009201045613735914\n",
      "epoch: 7 step: 405, loss is 0.0027681542560458183\n",
      "epoch: 7 step: 406, loss is 0.025632914155721664\n",
      "epoch: 7 step: 407, loss is 0.006777246482670307\n",
      "epoch: 7 step: 408, loss is 0.0008446623105555773\n",
      "epoch: 7 step: 409, loss is 0.000672082242090255\n",
      "epoch: 7 step: 410, loss is 0.00025583538808859885\n",
      "epoch: 7 step: 411, loss is 0.0013459414476528764\n",
      "epoch: 7 step: 412, loss is 0.0001328436628682539\n",
      "epoch: 7 step: 413, loss is 0.015605670399963856\n",
      "epoch: 7 step: 414, loss is 0.03380328044295311\n",
      "epoch: 7 step: 415, loss is 0.036360736936330795\n",
      "epoch: 7 step: 416, loss is 9.643613884691149e-05\n",
      "epoch: 7 step: 417, loss is 0.004857172723859549\n",
      "epoch: 7 step: 418, loss is 0.00016036178567446768\n",
      "epoch: 7 step: 419, loss is 0.026440469548106194\n",
      "epoch: 7 step: 420, loss is 0.02785443514585495\n",
      "epoch: 7 step: 421, loss is 0.09746699780225754\n",
      "epoch: 7 step: 422, loss is 5.8139001339441165e-05\n",
      "epoch: 7 step: 423, loss is 0.0006250021979212761\n",
      "epoch: 7 step: 424, loss is 0.007918719202280045\n",
      "epoch: 7 step: 425, loss is 0.0005494318320415914\n",
      "epoch: 7 step: 426, loss is 0.009699462912976742\n",
      "epoch: 7 step: 427, loss is 0.0006537983426824212\n",
      "epoch: 7 step: 428, loss is 0.0015485960757359862\n",
      "epoch: 7 step: 429, loss is 0.014857645146548748\n",
      "epoch: 7 step: 430, loss is 0.00029223249293863773\n",
      "epoch: 7 step: 431, loss is 0.10501199960708618\n",
      "epoch: 7 step: 432, loss is 0.04329292103648186\n",
      "epoch: 7 step: 433, loss is 0.20965375006198883\n",
      "epoch: 7 step: 434, loss is 0.0002771180006675422\n",
      "epoch: 7 step: 435, loss is 0.006614172365516424\n",
      "epoch: 7 step: 436, loss is 0.003100502770394087\n",
      "epoch: 7 step: 437, loss is 0.003548399545252323\n",
      "epoch: 7 step: 438, loss is 0.005306572187691927\n",
      "epoch: 7 step: 439, loss is 4.270690624252893e-05\n",
      "epoch: 7 step: 440, loss is 0.033868733793497086\n",
      "epoch: 7 step: 441, loss is 0.0002826901327352971\n",
      "epoch: 7 step: 442, loss is 0.0018136086873710155\n",
      "epoch: 7 step: 443, loss is 0.0002870777389034629\n",
      "epoch: 7 step: 444, loss is 0.004907752852886915\n",
      "epoch: 7 step: 445, loss is 0.031562440097332\n",
      "epoch: 7 step: 446, loss is 0.00019528121629264206\n",
      "epoch: 7 step: 447, loss is 5.994020466459915e-05\n",
      "epoch: 7 step: 448, loss is 0.00782738532871008\n",
      "epoch: 7 step: 449, loss is 0.0003449401701800525\n",
      "epoch: 7 step: 450, loss is 0.0018854986410588026\n",
      "epoch: 7 step: 451, loss is 0.022505061700940132\n",
      "epoch: 7 step: 452, loss is 0.0036077648401260376\n",
      "epoch: 7 step: 453, loss is 0.003310964908450842\n",
      "epoch: 7 step: 454, loss is 0.007452800869941711\n",
      "epoch: 7 step: 455, loss is 0.004066180437803268\n",
      "epoch: 7 step: 456, loss is 0.01872289925813675\n",
      "epoch: 7 step: 457, loss is 0.0015259748324751854\n",
      "epoch: 7 step: 458, loss is 0.002920196857303381\n",
      "epoch: 7 step: 459, loss is 0.00043489970266819\n",
      "epoch: 7 step: 460, loss is 0.00015878370322752744\n",
      "epoch: 7 step: 461, loss is 0.0008366244146600366\n",
      "epoch: 7 step: 462, loss is 0.01230995450168848\n",
      "epoch: 7 step: 463, loss is 0.001796836731955409\n",
      "epoch: 7 step: 464, loss is 0.0191357359290123\n",
      "epoch: 7 step: 465, loss is 0.0027599812019616365\n",
      "epoch: 7 step: 466, loss is 0.0005844103288836777\n",
      "epoch: 7 step: 467, loss is 0.0004949973081238568\n",
      "epoch: 7 step: 468, loss is 0.010171144269406796\n",
      "epoch: 7 step: 469, loss is 0.022018402814865112\n",
      "epoch: 7 step: 470, loss is 0.0047125378623604774\n",
      "epoch: 7 step: 471, loss is 0.0009659268544055521\n",
      "epoch: 7 step: 472, loss is 0.0024286722764372826\n",
      "epoch: 7 step: 473, loss is 0.0005726038943976164\n",
      "epoch: 7 step: 474, loss is 4.1579602111596614e-05\n",
      "epoch: 7 step: 475, loss is 0.007688359823077917\n",
      "epoch: 7 step: 476, loss is 0.00020699271408375353\n",
      "epoch: 7 step: 477, loss is 0.15585418045520782\n",
      "epoch: 7 step: 478, loss is 0.023802071809768677\n",
      "epoch: 7 step: 479, loss is 0.0004909049603156745\n",
      "epoch: 7 step: 480, loss is 5.757425969932228e-05\n",
      "epoch: 7 step: 481, loss is 0.0003286795108579099\n",
      "epoch: 7 step: 482, loss is 0.0016608339501544833\n",
      "epoch: 7 step: 483, loss is 0.0011527620954439044\n",
      "epoch: 7 step: 484, loss is 0.004103566519916058\n",
      "epoch: 7 step: 485, loss is 5.6227661843877286e-05\n",
      "epoch: 7 step: 486, loss is 0.04582912474870682\n",
      "epoch: 7 step: 487, loss is 0.00012388225877657533\n",
      "epoch: 7 step: 488, loss is 0.011971421539783478\n",
      "epoch: 7 step: 489, loss is 0.012120918370783329\n",
      "epoch: 7 step: 490, loss is 0.027670172974467278\n",
      "epoch: 7 step: 491, loss is 0.00019481146591715515\n",
      "epoch: 7 step: 492, loss is 0.0052219582721591\n",
      "epoch: 7 step: 493, loss is 0.011547872796654701\n",
      "epoch: 7 step: 494, loss is 0.00013011082774028182\n",
      "epoch: 7 step: 495, loss is 0.2315789759159088\n",
      "epoch: 7 step: 496, loss is 0.07172883301973343\n",
      "epoch: 7 step: 497, loss is 0.00041477748891338706\n",
      "epoch: 7 step: 498, loss is 0.0008851766469888389\n",
      "epoch: 7 step: 499, loss is 7.16906797606498e-05\n",
      "epoch: 7 step: 500, loss is 0.0002486875746399164\n",
      "epoch: 7 step: 501, loss is 0.00037930652615614235\n",
      "epoch: 7 step: 502, loss is 0.027283400297164917\n",
      "epoch: 7 step: 503, loss is 0.00014683186600450426\n",
      "epoch: 7 step: 504, loss is 0.007562914397567511\n",
      "epoch: 7 step: 505, loss is 0.004337167367339134\n",
      "epoch: 7 step: 506, loss is 0.08298900723457336\n",
      "epoch: 7 step: 507, loss is 0.0006347412709146738\n",
      "epoch: 7 step: 508, loss is 0.0026158287655562162\n",
      "epoch: 7 step: 509, loss is 0.0032770491670817137\n",
      "epoch: 7 step: 510, loss is 0.009636261500418186\n",
      "epoch: 7 step: 511, loss is 0.0019918244797736406\n",
      "epoch: 7 step: 512, loss is 0.0003479743318166584\n",
      "epoch: 7 step: 513, loss is 0.0015115217538550496\n",
      "epoch: 7 step: 514, loss is 0.0005760452477261424\n",
      "epoch: 7 step: 515, loss is 3.859187199850567e-05\n",
      "epoch: 7 step: 516, loss is 0.0008331593126058578\n",
      "epoch: 7 step: 517, loss is 0.004502164199948311\n",
      "epoch: 7 step: 518, loss is 8.918633830035105e-05\n",
      "epoch: 7 step: 519, loss is 5.713139398721978e-05\n",
      "epoch: 7 step: 520, loss is 0.01738237962126732\n",
      "epoch: 7 step: 521, loss is 0.00025109894340857863\n",
      "epoch: 7 step: 522, loss is 0.011125561781227589\n",
      "epoch: 7 step: 523, loss is 0.002054328564554453\n",
      "epoch: 7 step: 524, loss is 9.446278272662312e-05\n",
      "epoch: 7 step: 525, loss is 0.00010760805889731273\n",
      "epoch: 7 step: 526, loss is 0.017775772139430046\n",
      "epoch: 7 step: 527, loss is 6.523995398310944e-05\n",
      "epoch: 7 step: 528, loss is 0.041884176433086395\n",
      "epoch: 7 step: 529, loss is 0.007736228406429291\n",
      "epoch: 7 step: 530, loss is 0.00013012843555770814\n",
      "epoch: 7 step: 531, loss is 0.005240961443632841\n",
      "epoch: 7 step: 532, loss is 0.01969251036643982\n",
      "epoch: 7 step: 533, loss is 0.0006736068753525615\n",
      "epoch: 7 step: 534, loss is 0.0013581322273239493\n",
      "epoch: 7 step: 535, loss is 0.0053527685813605785\n",
      "epoch: 7 step: 536, loss is 0.11034002900123596\n",
      "epoch: 7 step: 537, loss is 0.00189246388617903\n",
      "epoch: 7 step: 538, loss is 9.537203004583716e-05\n",
      "epoch: 7 step: 539, loss is 0.002043758053332567\n",
      "epoch: 7 step: 540, loss is 2.1661266146111302e-05\n",
      "epoch: 7 step: 541, loss is 0.0006084330379962921\n",
      "epoch: 7 step: 542, loss is 0.00012704895925708115\n",
      "epoch: 7 step: 543, loss is 0.0033650326076895\n",
      "epoch: 7 step: 544, loss is 9.159444744000211e-06\n",
      "epoch: 7 step: 545, loss is 0.0031278368551284075\n",
      "epoch: 7 step: 546, loss is 5.9283389418851584e-05\n",
      "epoch: 7 step: 547, loss is 0.00021934347751084715\n",
      "epoch: 7 step: 548, loss is 0.0077443355694413185\n",
      "epoch: 7 step: 549, loss is 0.08726565539836884\n",
      "epoch: 7 step: 550, loss is 0.00010292421939084306\n",
      "epoch: 7 step: 551, loss is 0.00025230366736650467\n",
      "epoch: 7 step: 552, loss is 0.1267029494047165\n",
      "epoch: 7 step: 553, loss is 0.14206142723560333\n",
      "epoch: 7 step: 554, loss is 0.0005087608005851507\n",
      "epoch: 7 step: 555, loss is 0.006501924246549606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 556, loss is 0.0002994842070620507\n",
      "epoch: 7 step: 557, loss is 0.004450957756489515\n",
      "epoch: 7 step: 558, loss is 0.006897383835166693\n",
      "epoch: 7 step: 559, loss is 0.001007018145173788\n",
      "epoch: 7 step: 560, loss is 0.00023794957087375224\n",
      "epoch: 7 step: 561, loss is 0.0033384861890226603\n",
      "epoch: 7 step: 562, loss is 2.757049151114188e-05\n",
      "epoch: 7 step: 563, loss is 0.1256057769060135\n",
      "epoch: 7 step: 564, loss is 0.12409573793411255\n",
      "epoch: 7 step: 565, loss is 0.00012319082452449948\n",
      "epoch: 7 step: 566, loss is 0.0005508086760528386\n",
      "epoch: 7 step: 567, loss is 0.0002815366897266358\n",
      "epoch: 7 step: 568, loss is 0.0001405081566190347\n",
      "epoch: 7 step: 569, loss is 0.027586305513978004\n",
      "epoch: 7 step: 570, loss is 0.07790766656398773\n",
      "epoch: 7 step: 571, loss is 0.001063343952409923\n",
      "epoch: 7 step: 572, loss is 0.0010433479910716414\n",
      "epoch: 7 step: 573, loss is 0.028701430186629295\n",
      "epoch: 7 step: 574, loss is 0.0025845735799521208\n",
      "epoch: 7 step: 575, loss is 0.1353013962507248\n",
      "epoch: 7 step: 576, loss is 0.0007847698288969696\n",
      "epoch: 7 step: 577, loss is 0.0011664143530651927\n",
      "epoch: 7 step: 578, loss is 0.010012819431722164\n",
      "epoch: 7 step: 579, loss is 0.13247165083885193\n",
      "epoch: 7 step: 580, loss is 0.0031171117443591356\n",
      "epoch: 7 step: 581, loss is 0.0010150503367185593\n",
      "epoch: 7 step: 582, loss is 0.0046532247215509415\n",
      "epoch: 7 step: 583, loss is 0.1441454142332077\n",
      "epoch: 7 step: 584, loss is 0.04782237112522125\n",
      "epoch: 7 step: 585, loss is 0.00010817521979333833\n",
      "epoch: 7 step: 586, loss is 0.0027284356765449047\n",
      "epoch: 7 step: 587, loss is 0.00018470648501534015\n",
      "epoch: 7 step: 588, loss is 0.00021899618150200695\n",
      "epoch: 7 step: 589, loss is 0.00035799836041405797\n",
      "epoch: 7 step: 590, loss is 0.0016195880016312003\n",
      "epoch: 7 step: 591, loss is 0.0037871687673032284\n",
      "epoch: 7 step: 592, loss is 0.0001551905443193391\n",
      "epoch: 7 step: 593, loss is 0.00024972998653538525\n",
      "epoch: 7 step: 594, loss is 0.001130484975874424\n",
      "epoch: 7 step: 595, loss is 0.003107029013335705\n",
      "epoch: 7 step: 596, loss is 0.005460765212774277\n",
      "epoch: 7 step: 597, loss is 0.0012066331692039967\n",
      "epoch: 7 step: 598, loss is 0.03976026177406311\n",
      "epoch: 7 step: 599, loss is 0.018377935513854027\n",
      "epoch: 7 step: 600, loss is 0.028890859335660934\n",
      "epoch: 7 step: 601, loss is 0.001639871159568429\n",
      "epoch: 7 step: 602, loss is 0.0551273375749588\n",
      "epoch: 7 step: 603, loss is 0.10882832854986191\n",
      "epoch: 7 step: 604, loss is 0.016804255545139313\n",
      "epoch: 7 step: 605, loss is 0.00011304908548481762\n",
      "epoch: 7 step: 606, loss is 0.0009385207085870206\n",
      "epoch: 7 step: 607, loss is 0.005789787508547306\n",
      "epoch: 7 step: 608, loss is 0.005493628792464733\n",
      "epoch: 7 step: 609, loss is 0.04238897189497948\n",
      "epoch: 7 step: 610, loss is 0.0010845162905752659\n",
      "epoch: 7 step: 611, loss is 0.0003042822063434869\n",
      "epoch: 7 step: 612, loss is 0.0002247499505756423\n",
      "epoch: 7 step: 613, loss is 0.0029315194115042686\n",
      "epoch: 7 step: 614, loss is 0.010312988422811031\n",
      "epoch: 7 step: 615, loss is 0.000645884545519948\n",
      "epoch: 7 step: 616, loss is 0.012892140075564384\n",
      "epoch: 7 step: 617, loss is 0.02509409561753273\n",
      "epoch: 7 step: 618, loss is 0.00036137798451818526\n",
      "epoch: 7 step: 619, loss is 0.034002140164375305\n",
      "epoch: 7 step: 620, loss is 0.0005296106683090329\n",
      "epoch: 7 step: 621, loss is 0.06457021087408066\n",
      "epoch: 7 step: 622, loss is 0.005658071022480726\n",
      "epoch: 7 step: 623, loss is 0.05859776958823204\n",
      "epoch: 7 step: 624, loss is 0.0015598302707076073\n",
      "epoch: 7 step: 625, loss is 4.4588854507310316e-05\n",
      "epoch: 7 step: 626, loss is 0.00033460426493547857\n",
      "epoch: 7 step: 627, loss is 0.010264270938932896\n",
      "epoch: 7 step: 628, loss is 0.007021831814199686\n",
      "epoch: 7 step: 629, loss is 0.041941337287425995\n",
      "epoch: 7 step: 630, loss is 0.00045219954336062074\n",
      "epoch: 7 step: 631, loss is 0.00251606828533113\n",
      "epoch: 7 step: 632, loss is 0.0007062103832140565\n",
      "epoch: 7 step: 633, loss is 0.003369140438735485\n",
      "epoch: 7 step: 634, loss is 0.003788428846746683\n",
      "epoch: 7 step: 635, loss is 0.12838007509708405\n",
      "epoch: 7 step: 636, loss is 1.1183630704181269e-05\n",
      "epoch: 7 step: 637, loss is 0.00024214510631281883\n",
      "epoch: 7 step: 638, loss is 1.2985261491849087e-05\n",
      "epoch: 7 step: 639, loss is 0.006694595329463482\n",
      "epoch: 7 step: 640, loss is 0.043504081666469574\n",
      "epoch: 7 step: 641, loss is 0.00021904661844018847\n",
      "epoch: 7 step: 642, loss is 0.00015836674720048904\n",
      "epoch: 7 step: 643, loss is 0.0001618034002603963\n",
      "epoch: 7 step: 644, loss is 2.733533074206207e-05\n",
      "epoch: 7 step: 645, loss is 0.0003784167638514191\n",
      "epoch: 7 step: 646, loss is 0.0002919216931331903\n",
      "epoch: 7 step: 647, loss is 0.0006148061947897077\n",
      "epoch: 7 step: 648, loss is 0.08736038953065872\n",
      "epoch: 7 step: 649, loss is 0.0005713828140869737\n",
      "epoch: 7 step: 650, loss is 0.00023999933910090476\n",
      "epoch: 7 step: 651, loss is 0.07756975293159485\n",
      "epoch: 7 step: 652, loss is 0.000251273944741115\n",
      "epoch: 7 step: 653, loss is 0.0007357457070611417\n",
      "epoch: 7 step: 654, loss is 0.08100206404924393\n",
      "epoch: 7 step: 655, loss is 0.029789745807647705\n",
      "epoch: 7 step: 656, loss is 0.002972043352201581\n",
      "epoch: 7 step: 657, loss is 0.2071901112794876\n",
      "epoch: 7 step: 658, loss is 0.0008201876189559698\n",
      "epoch: 7 step: 659, loss is 0.00020235679403413087\n",
      "epoch: 7 step: 660, loss is 1.7413858586223796e-05\n",
      "epoch: 7 step: 661, loss is 0.0037614789325743914\n",
      "epoch: 7 step: 662, loss is 0.010438250377774239\n",
      "epoch: 7 step: 663, loss is 0.004860759247094393\n",
      "epoch: 7 step: 664, loss is 0.006715224590152502\n",
      "epoch: 7 step: 665, loss is 0.015707559883594513\n",
      "epoch: 7 step: 666, loss is 0.01708066649734974\n",
      "epoch: 7 step: 667, loss is 0.22237500548362732\n",
      "epoch: 7 step: 668, loss is 0.006732256151735783\n",
      "epoch: 7 step: 669, loss is 0.020005833357572556\n",
      "epoch: 7 step: 670, loss is 0.00968086440116167\n",
      "epoch: 7 step: 671, loss is 0.14832477271556854\n",
      "epoch: 7 step: 672, loss is 0.00017769196711014956\n",
      "epoch: 7 step: 673, loss is 0.15933023393154144\n",
      "epoch: 7 step: 674, loss is 0.006027014460414648\n",
      "epoch: 7 step: 675, loss is 0.1397155523300171\n",
      "epoch: 7 step: 676, loss is 0.25984951853752136\n",
      "epoch: 7 step: 677, loss is 0.0025448950473219156\n",
      "epoch: 7 step: 678, loss is 0.0036033731885254383\n",
      "epoch: 7 step: 679, loss is 0.046164922416210175\n",
      "epoch: 7 step: 680, loss is 0.0004175255016889423\n",
      "epoch: 7 step: 681, loss is 0.007153917104005814\n",
      "epoch: 7 step: 682, loss is 0.0007000298937782645\n",
      "epoch: 7 step: 683, loss is 0.00012864837481174618\n",
      "epoch: 7 step: 684, loss is 0.09193423390388489\n",
      "epoch: 7 step: 685, loss is 0.1481943130493164\n",
      "epoch: 7 step: 686, loss is 0.008046833798289299\n",
      "epoch: 7 step: 687, loss is 0.0048454334028065205\n",
      "epoch: 7 step: 688, loss is 0.07422713190317154\n",
      "epoch: 7 step: 689, loss is 0.00017583930457476526\n",
      "epoch: 7 step: 690, loss is 0.011982401832938194\n",
      "epoch: 7 step: 691, loss is 0.012812300585210323\n",
      "epoch: 7 step: 692, loss is 0.008832346647977829\n",
      "epoch: 7 step: 693, loss is 0.06888850033283234\n",
      "epoch: 7 step: 694, loss is 0.17595019936561584\n",
      "epoch: 7 step: 695, loss is 0.03516088053584099\n",
      "epoch: 7 step: 696, loss is 0.008909063413739204\n",
      "epoch: 7 step: 697, loss is 0.003872415516525507\n",
      "epoch: 7 step: 698, loss is 0.0016615729546174407\n",
      "epoch: 7 step: 699, loss is 0.0089919064193964\n",
      "epoch: 7 step: 700, loss is 0.00044129870366305113\n",
      "epoch: 7 step: 701, loss is 0.0012531244428828359\n",
      "epoch: 7 step: 702, loss is 0.1313135325908661\n",
      "epoch: 7 step: 703, loss is 0.08375221490859985\n",
      "epoch: 7 step: 704, loss is 0.0031590715516358614\n",
      "epoch: 7 step: 705, loss is 0.0006479009171016514\n",
      "epoch: 7 step: 706, loss is 0.007156958803534508\n",
      "epoch: 7 step: 707, loss is 0.0020762737840414047\n",
      "epoch: 7 step: 708, loss is 0.00012352816702332348\n",
      "epoch: 7 step: 709, loss is 0.013920597732067108\n",
      "epoch: 7 step: 710, loss is 0.005040943156927824\n",
      "epoch: 7 step: 711, loss is 0.002278994768857956\n",
      "epoch: 7 step: 712, loss is 0.00638187862932682\n",
      "epoch: 7 step: 713, loss is 0.015339639037847519\n",
      "epoch: 7 step: 714, loss is 0.005786751862615347\n",
      "epoch: 7 step: 715, loss is 0.02725560963153839\n",
      "epoch: 7 step: 716, loss is 0.014883005991578102\n",
      "epoch: 7 step: 717, loss is 0.00024309605942107737\n",
      "epoch: 7 step: 718, loss is 0.0024075903929769993\n",
      "epoch: 7 step: 719, loss is 0.0020720004104077816\n",
      "epoch: 7 step: 720, loss is 0.000444887817138806\n",
      "epoch: 7 step: 721, loss is 0.005921255797147751\n",
      "epoch: 7 step: 722, loss is 0.21680058538913727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 723, loss is 0.01432808581739664\n",
      "epoch: 7 step: 724, loss is 0.0007445061346516013\n",
      "epoch: 7 step: 725, loss is 0.0022245431318879128\n",
      "epoch: 7 step: 726, loss is 0.003892923006787896\n",
      "epoch: 7 step: 727, loss is 0.00016868746024556458\n",
      "epoch: 7 step: 728, loss is 0.01820141077041626\n",
      "epoch: 7 step: 729, loss is 0.027334291487932205\n",
      "epoch: 7 step: 730, loss is 0.013719672337174416\n",
      "epoch: 7 step: 731, loss is 0.005127054639160633\n",
      "epoch: 7 step: 732, loss is 0.0384712815284729\n",
      "epoch: 7 step: 733, loss is 0.0037831689696758986\n",
      "epoch: 7 step: 734, loss is 0.005466314498335123\n",
      "epoch: 7 step: 735, loss is 0.025967171415686607\n",
      "epoch: 7 step: 736, loss is 0.0002596579142846167\n",
      "epoch: 7 step: 737, loss is 0.042877405881881714\n",
      "epoch: 7 step: 738, loss is 0.05043094605207443\n",
      "epoch: 7 step: 739, loss is 0.00027301651425659657\n",
      "epoch: 7 step: 740, loss is 0.04670821130275726\n",
      "epoch: 7 step: 741, loss is 0.11888010054826736\n",
      "epoch: 7 step: 742, loss is 0.009016809053719044\n",
      "epoch: 7 step: 743, loss is 0.0007809140370227396\n",
      "epoch: 7 step: 744, loss is 0.06411048024892807\n",
      "epoch: 7 step: 745, loss is 0.0011451808968558908\n",
      "epoch: 7 step: 746, loss is 0.14383095502853394\n",
      "epoch: 7 step: 747, loss is 0.008033495396375656\n",
      "epoch: 7 step: 748, loss is 0.0002001849643420428\n",
      "epoch: 7 step: 749, loss is 0.0004124317201785743\n",
      "epoch: 7 step: 750, loss is 0.002857539104297757\n",
      "epoch: 7 step: 751, loss is 0.013456332497298717\n",
      "epoch: 7 step: 752, loss is 0.05671309307217598\n",
      "epoch: 7 step: 753, loss is 0.01453530415892601\n",
      "epoch: 7 step: 754, loss is 0.002522204304113984\n",
      "epoch: 7 step: 755, loss is 0.1564510315656662\n",
      "epoch: 7 step: 756, loss is 0.002885640598833561\n",
      "epoch: 7 step: 757, loss is 0.026779452338814735\n",
      "epoch: 7 step: 758, loss is 0.04340957850217819\n",
      "epoch: 7 step: 759, loss is 0.055618636310100555\n",
      "epoch: 7 step: 760, loss is 0.006313937250524759\n",
      "epoch: 7 step: 761, loss is 0.00572123983874917\n",
      "epoch: 7 step: 762, loss is 0.0014224163023754954\n",
      "epoch: 7 step: 763, loss is 0.0006364007713273168\n",
      "epoch: 7 step: 764, loss is 0.007435353472828865\n",
      "epoch: 7 step: 765, loss is 0.017024023458361626\n",
      "epoch: 7 step: 766, loss is 0.0006730938912369311\n",
      "epoch: 7 step: 767, loss is 0.005850835703313351\n",
      "epoch: 7 step: 768, loss is 0.04130004346370697\n",
      "epoch: 7 step: 769, loss is 0.03307957574725151\n",
      "epoch: 7 step: 770, loss is 0.02500448375940323\n",
      "epoch: 7 step: 771, loss is 0.006591737736016512\n",
      "epoch: 7 step: 772, loss is 0.00045844566193409264\n",
      "epoch: 7 step: 773, loss is 0.0042281802743673325\n",
      "epoch: 7 step: 774, loss is 0.03322592005133629\n",
      "epoch: 7 step: 775, loss is 0.005242191255092621\n",
      "epoch: 7 step: 776, loss is 0.0004339350271038711\n",
      "epoch: 7 step: 777, loss is 0.0012301936512812972\n",
      "epoch: 7 step: 778, loss is 0.00848320871591568\n",
      "epoch: 7 step: 779, loss is 0.05577285960316658\n",
      "epoch: 7 step: 780, loss is 0.002018429571762681\n",
      "epoch: 7 step: 781, loss is 1.4559048395312857e-05\n",
      "epoch: 7 step: 782, loss is 0.013879099860787392\n",
      "epoch: 7 step: 783, loss is 0.023820742964744568\n",
      "epoch: 7 step: 784, loss is 0.0014436815399676561\n",
      "epoch: 7 step: 785, loss is 0.11663196235895157\n",
      "epoch: 7 step: 786, loss is 0.0002385775587754324\n",
      "epoch: 7 step: 787, loss is 0.002164300065487623\n",
      "epoch: 7 step: 788, loss is 0.0007290570647455752\n",
      "epoch: 7 step: 789, loss is 0.011895634233951569\n",
      "epoch: 7 step: 790, loss is 0.08224982023239136\n",
      "epoch: 7 step: 791, loss is 0.004293559119105339\n",
      "epoch: 7 step: 792, loss is 0.00026017770869657397\n",
      "epoch: 7 step: 793, loss is 0.0021569759119302034\n",
      "epoch: 7 step: 794, loss is 0.027284730225801468\n",
      "epoch: 7 step: 795, loss is 0.0002091157657559961\n",
      "epoch: 7 step: 796, loss is 0.2576397657394409\n",
      "epoch: 7 step: 797, loss is 0.04612121731042862\n",
      "epoch: 7 step: 798, loss is 0.006147028878331184\n",
      "epoch: 7 step: 799, loss is 0.022873681038618088\n",
      "epoch: 7 step: 800, loss is 0.023948457092046738\n",
      "epoch: 7 step: 801, loss is 0.004223750904202461\n",
      "epoch: 7 step: 802, loss is 0.013291195034980774\n",
      "epoch: 7 step: 803, loss is 0.14204831421375275\n",
      "epoch: 7 step: 804, loss is 0.0009120992617681623\n",
      "epoch: 7 step: 805, loss is 0.0007736292900517583\n",
      "epoch: 7 step: 806, loss is 0.017251305282115936\n",
      "epoch: 7 step: 807, loss is 0.030422277748584747\n",
      "epoch: 7 step: 808, loss is 0.003685723291710019\n",
      "epoch: 7 step: 809, loss is 0.01400055456906557\n",
      "epoch: 7 step: 810, loss is 0.016658969223499298\n",
      "epoch: 7 step: 811, loss is 0.000701053359080106\n",
      "epoch: 7 step: 812, loss is 0.23426489531993866\n",
      "epoch: 7 step: 813, loss is 0.013937692157924175\n",
      "epoch: 7 step: 814, loss is 0.00012775925279129297\n",
      "epoch: 7 step: 815, loss is 0.058712031692266464\n",
      "epoch: 7 step: 816, loss is 0.000262882502283901\n",
      "epoch: 7 step: 817, loss is 0.022445667535066605\n",
      "epoch: 7 step: 818, loss is 0.01352393627166748\n",
      "epoch: 7 step: 819, loss is 0.0055114892311394215\n",
      "epoch: 7 step: 820, loss is 0.002672633621841669\n",
      "epoch: 7 step: 821, loss is 0.0009607446845620871\n",
      "epoch: 7 step: 822, loss is 0.0185637716203928\n",
      "epoch: 7 step: 823, loss is 0.00021419253607746214\n",
      "epoch: 7 step: 824, loss is 0.005590486340224743\n",
      "epoch: 7 step: 825, loss is 0.10757944732904434\n",
      "epoch: 7 step: 826, loss is 0.00026257371064275503\n",
      "epoch: 7 step: 827, loss is 0.0001253542141057551\n",
      "epoch: 7 step: 828, loss is 0.003420562483370304\n",
      "epoch: 7 step: 829, loss is 0.0013714521192014217\n",
      "epoch: 7 step: 830, loss is 0.0009749359451234341\n",
      "epoch: 7 step: 831, loss is 0.011898753233253956\n",
      "epoch: 7 step: 832, loss is 0.0007786688511259854\n",
      "epoch: 7 step: 833, loss is 0.04066680371761322\n",
      "epoch: 7 step: 834, loss is 0.0003657353518065065\n",
      "epoch: 7 step: 835, loss is 0.0032728882506489754\n",
      "epoch: 7 step: 836, loss is 0.0045897383242845535\n",
      "epoch: 7 step: 837, loss is 0.00029371463460847735\n",
      "epoch: 7 step: 838, loss is 0.0006641319487243891\n",
      "epoch: 7 step: 839, loss is 0.005840828642249107\n",
      "epoch: 7 step: 840, loss is 0.00042871455661952496\n",
      "epoch: 7 step: 841, loss is 0.003222001250833273\n",
      "epoch: 7 step: 842, loss is 0.0003223912790417671\n",
      "epoch: 7 step: 843, loss is 0.008645941503345966\n",
      "epoch: 7 step: 844, loss is 0.00923772994428873\n",
      "epoch: 7 step: 845, loss is 0.0005235003773123026\n",
      "epoch: 7 step: 846, loss is 0.002177877351641655\n",
      "epoch: 7 step: 847, loss is 0.0004872927675023675\n",
      "epoch: 7 step: 848, loss is 0.0016387745272368193\n",
      "epoch: 7 step: 849, loss is 0.0009562836494296789\n",
      "epoch: 7 step: 850, loss is 0.0031455131247639656\n",
      "epoch: 7 step: 851, loss is 0.010079613886773586\n",
      "epoch: 7 step: 852, loss is 0.00032208493212237954\n",
      "epoch: 7 step: 853, loss is 0.00427132798358798\n",
      "epoch: 7 step: 854, loss is 0.0007069234852679074\n",
      "epoch: 7 step: 855, loss is 0.0005162492161616683\n",
      "epoch: 7 step: 856, loss is 0.0017197771230712533\n",
      "epoch: 7 step: 857, loss is 0.01706601120531559\n",
      "epoch: 7 step: 858, loss is 0.0002230524696642533\n",
      "epoch: 7 step: 859, loss is 0.0014626282500103116\n",
      "epoch: 7 step: 860, loss is 0.0035267916973680258\n",
      "epoch: 7 step: 861, loss is 0.00015260315558407456\n",
      "epoch: 7 step: 862, loss is 0.005675959400832653\n",
      "epoch: 7 step: 863, loss is 0.1539742797613144\n",
      "epoch: 7 step: 864, loss is 0.000267196970526129\n",
      "epoch: 7 step: 865, loss is 2.8136106266174465e-05\n",
      "epoch: 7 step: 866, loss is 0.08255945891141891\n",
      "epoch: 7 step: 867, loss is 0.0026643401943147182\n",
      "epoch: 7 step: 868, loss is 0.008124850690364838\n",
      "epoch: 7 step: 869, loss is 0.00010726927575888112\n",
      "epoch: 7 step: 870, loss is 0.01921721361577511\n",
      "epoch: 7 step: 871, loss is 0.0001307185593759641\n",
      "epoch: 7 step: 872, loss is 0.0012662208173424006\n",
      "epoch: 7 step: 873, loss is 0.001569889485836029\n",
      "epoch: 7 step: 874, loss is 3.777996244025417e-05\n",
      "epoch: 7 step: 875, loss is 7.275238749571145e-05\n",
      "epoch: 7 step: 876, loss is 0.0012988077942281961\n",
      "epoch: 7 step: 877, loss is 0.009961473755538464\n",
      "epoch: 7 step: 878, loss is 0.07626625150442123\n",
      "epoch: 7 step: 879, loss is 0.0009310613968409598\n",
      "epoch: 7 step: 880, loss is 0.020572341978549957\n",
      "epoch: 7 step: 881, loss is 0.0004024713416583836\n",
      "epoch: 7 step: 882, loss is 0.0013696147361770272\n",
      "epoch: 7 step: 883, loss is 0.0027928927447646856\n",
      "epoch: 7 step: 884, loss is 0.002946442924439907\n",
      "epoch: 7 step: 885, loss is 0.06528212130069733\n",
      "epoch: 7 step: 886, loss is 0.0012491005472838879\n",
      "epoch: 7 step: 887, loss is 0.03484383597970009\n",
      "epoch: 7 step: 888, loss is 0.17428714036941528\n",
      "epoch: 7 step: 889, loss is 0.0013389913365244865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 890, loss is 0.09076210856437683\n",
      "epoch: 7 step: 891, loss is 0.0010780392913147807\n",
      "epoch: 7 step: 892, loss is 0.004119380377233028\n",
      "epoch: 7 step: 893, loss is 0.010556797496974468\n",
      "epoch: 7 step: 894, loss is 0.0016041048802435398\n",
      "epoch: 7 step: 895, loss is 0.018917197361588478\n",
      "epoch: 7 step: 896, loss is 0.0019571208395063877\n",
      "epoch: 7 step: 897, loss is 0.0010411725379526615\n",
      "epoch: 7 step: 898, loss is 0.001933358609676361\n",
      "epoch: 7 step: 899, loss is 0.00029740339959971607\n",
      "epoch: 7 step: 900, loss is 0.00012811089982278645\n",
      "epoch: 7 step: 901, loss is 0.0003303307748865336\n",
      "epoch: 7 step: 902, loss is 0.16492559015750885\n",
      "epoch: 7 step: 903, loss is 0.03008405864238739\n",
      "epoch: 7 step: 904, loss is 0.010737370699644089\n",
      "epoch: 7 step: 905, loss is 0.003154266392812133\n",
      "epoch: 7 step: 906, loss is 0.004550352226942778\n",
      "epoch: 7 step: 907, loss is 0.008989939466118813\n",
      "epoch: 7 step: 908, loss is 0.005504348315298557\n",
      "epoch: 7 step: 909, loss is 0.029679065570235252\n",
      "epoch: 7 step: 910, loss is 0.003932005260139704\n",
      "epoch: 7 step: 911, loss is 0.008429771289229393\n",
      "epoch: 7 step: 912, loss is 0.0010543637908995152\n",
      "epoch: 7 step: 913, loss is 0.12927255034446716\n",
      "epoch: 7 step: 914, loss is 0.001991875469684601\n",
      "epoch: 7 step: 915, loss is 0.08276031166315079\n",
      "epoch: 7 step: 916, loss is 0.12733086943626404\n",
      "epoch: 7 step: 917, loss is 0.002642377046868205\n",
      "epoch: 7 step: 918, loss is 0.014748437330126762\n",
      "epoch: 7 step: 919, loss is 0.012906117364764214\n",
      "epoch: 7 step: 920, loss is 0.002473880536854267\n",
      "epoch: 7 step: 921, loss is 0.006608146242797375\n",
      "epoch: 7 step: 922, loss is 0.0014830469153821468\n",
      "epoch: 7 step: 923, loss is 0.0004693754599429667\n",
      "epoch: 7 step: 924, loss is 0.0003865528851747513\n",
      "epoch: 7 step: 925, loss is 0.016584059223532677\n",
      "epoch: 7 step: 926, loss is 0.001756031415425241\n",
      "epoch: 7 step: 927, loss is 0.0034320191480219364\n",
      "epoch: 7 step: 928, loss is 0.06649813055992126\n",
      "epoch: 7 step: 929, loss is 0.0049474891275167465\n",
      "epoch: 7 step: 930, loss is 0.0284581258893013\n",
      "epoch: 7 step: 931, loss is 0.00023878335196059197\n",
      "epoch: 7 step: 932, loss is 0.00765717588365078\n",
      "epoch: 7 step: 933, loss is 0.007463441230356693\n",
      "epoch: 7 step: 934, loss is 0.0023843946401029825\n",
      "epoch: 7 step: 935, loss is 0.056236062198877335\n",
      "epoch: 7 step: 936, loss is 0.035811372101306915\n",
      "epoch: 7 step: 937, loss is 0.006319278851151466\n",
      "epoch: 7 step: 938, loss is 0.21411705017089844\n",
      "epoch: 7 step: 939, loss is 0.00016638028318993747\n",
      "epoch: 7 step: 940, loss is 0.00046401904546655715\n",
      "epoch: 7 step: 941, loss is 0.00033639188040979207\n",
      "epoch: 7 step: 942, loss is 0.00027686843532137573\n",
      "epoch: 7 step: 943, loss is 1.9750728824874386e-05\n",
      "epoch: 7 step: 944, loss is 0.0002662161714397371\n",
      "epoch: 7 step: 945, loss is 0.001195751130580902\n",
      "epoch: 7 step: 946, loss is 0.0018543710466474295\n",
      "epoch: 7 step: 947, loss is 0.0009836609242483974\n",
      "epoch: 7 step: 948, loss is 0.03369855135679245\n",
      "epoch: 7 step: 949, loss is 0.0059100063517689705\n",
      "epoch: 7 step: 950, loss is 0.08348715305328369\n",
      "epoch: 7 step: 951, loss is 0.017377037554979324\n",
      "epoch: 7 step: 952, loss is 0.0003294138005003333\n",
      "epoch: 7 step: 953, loss is 0.0028112041763961315\n",
      "epoch: 7 step: 954, loss is 0.001326097990386188\n",
      "epoch: 7 step: 955, loss is 0.00039238008321262896\n",
      "epoch: 7 step: 956, loss is 0.009130935184657574\n",
      "epoch: 7 step: 957, loss is 0.032497331500053406\n",
      "epoch: 7 step: 958, loss is 0.015239865519106388\n",
      "epoch: 7 step: 959, loss is 6.772374763386324e-05\n",
      "epoch: 7 step: 960, loss is 0.011366121470928192\n",
      "epoch: 7 step: 961, loss is 0.0008509185281582177\n",
      "epoch: 7 step: 962, loss is 0.00010171625763177872\n",
      "epoch: 7 step: 963, loss is 0.0003277533105574548\n",
      "epoch: 7 step: 964, loss is 0.00014109056792221963\n",
      "epoch: 7 step: 965, loss is 0.04728337749838829\n",
      "epoch: 7 step: 966, loss is 0.005776261445134878\n",
      "epoch: 7 step: 967, loss is 0.09855248779058456\n",
      "epoch: 7 step: 968, loss is 0.002165691228583455\n",
      "epoch: 7 step: 969, loss is 0.0001600121904630214\n",
      "epoch: 7 step: 970, loss is 0.0009791026823222637\n",
      "epoch: 7 step: 971, loss is 0.0005316860042512417\n",
      "epoch: 7 step: 972, loss is 0.048594675958156586\n",
      "epoch: 7 step: 973, loss is 0.00025463165366090834\n",
      "epoch: 7 step: 974, loss is 0.0003048877988476306\n",
      "epoch: 7 step: 975, loss is 9.37379154493101e-05\n",
      "epoch: 7 step: 976, loss is 0.020994501188397408\n",
      "epoch: 7 step: 977, loss is 8.520061237504706e-05\n",
      "epoch: 7 step: 978, loss is 0.0027085058391094208\n",
      "epoch: 7 step: 979, loss is 0.000333567411871627\n",
      "epoch: 7 step: 980, loss is 0.0372333861887455\n",
      "epoch: 7 step: 981, loss is 0.046219129115343094\n",
      "epoch: 7 step: 982, loss is 0.042058080434799194\n",
      "epoch: 7 step: 983, loss is 0.0023814027663320303\n",
      "epoch: 7 step: 984, loss is 0.0005491251358762383\n",
      "epoch: 7 step: 985, loss is 0.047787364572286606\n",
      "epoch: 7 step: 986, loss is 0.000741037423722446\n",
      "epoch: 7 step: 987, loss is 0.002482061041519046\n",
      "epoch: 7 step: 988, loss is 0.0001781268510967493\n",
      "epoch: 7 step: 989, loss is 0.00016259406402241439\n",
      "epoch: 7 step: 990, loss is 0.007585391867905855\n",
      "epoch: 7 step: 991, loss is 0.0029362491331994534\n",
      "epoch: 7 step: 992, loss is 0.0005618596915155649\n",
      "epoch: 7 step: 993, loss is 0.002394949086010456\n",
      "epoch: 7 step: 994, loss is 0.001235684147104621\n",
      "epoch: 7 step: 995, loss is 0.1137237474322319\n",
      "epoch: 7 step: 996, loss is 0.00036671964335255325\n",
      "epoch: 7 step: 997, loss is 0.0063650826923549175\n",
      "epoch: 7 step: 998, loss is 0.0021188471000641584\n",
      "epoch: 7 step: 999, loss is 0.056552860885858536\n",
      "epoch: 7 step: 1000, loss is 0.0003604987286962569\n",
      "epoch: 7 step: 1001, loss is 0.002235114574432373\n",
      "epoch: 7 step: 1002, loss is 0.007075591012835503\n",
      "epoch: 7 step: 1003, loss is 0.04331317916512489\n",
      "epoch: 7 step: 1004, loss is 0.04507536068558693\n",
      "epoch: 7 step: 1005, loss is 0.009104217402637005\n",
      "epoch: 7 step: 1006, loss is 0.0016445934306830168\n",
      "epoch: 7 step: 1007, loss is 0.07915201783180237\n",
      "epoch: 7 step: 1008, loss is 0.043274376541376114\n",
      "epoch: 7 step: 1009, loss is 0.001931512262672186\n",
      "epoch: 7 step: 1010, loss is 0.003690640674903989\n",
      "epoch: 7 step: 1011, loss is 0.053321417421102524\n",
      "epoch: 7 step: 1012, loss is 0.002418980235233903\n",
      "epoch: 7 step: 1013, loss is 0.011972514912486076\n",
      "epoch: 7 step: 1014, loss is 0.00668193306773901\n",
      "epoch: 7 step: 1015, loss is 0.001270062755793333\n",
      "epoch: 7 step: 1016, loss is 0.03689134493470192\n",
      "epoch: 7 step: 1017, loss is 0.07883879542350769\n",
      "epoch: 7 step: 1018, loss is 0.0005996575346216559\n",
      "epoch: 7 step: 1019, loss is 0.0009815855883061886\n",
      "epoch: 7 step: 1020, loss is 4.257098044035956e-05\n",
      "epoch: 7 step: 1021, loss is 0.0016362142050638795\n",
      "epoch: 7 step: 1022, loss is 0.0006296489736996591\n",
      "epoch: 7 step: 1023, loss is 0.01985527016222477\n",
      "epoch: 7 step: 1024, loss is 3.962593473261222e-05\n",
      "epoch: 7 step: 1025, loss is 0.0012670039432123303\n",
      "epoch: 7 step: 1026, loss is 0.000298987899441272\n",
      "epoch: 7 step: 1027, loss is 0.0009287380962632596\n",
      "epoch: 7 step: 1028, loss is 0.0006308723823167384\n",
      "epoch: 7 step: 1029, loss is 0.1771569848060608\n",
      "epoch: 7 step: 1030, loss is 0.009726325049996376\n",
      "epoch: 7 step: 1031, loss is 0.1930147111415863\n",
      "epoch: 7 step: 1032, loss is 0.004453294910490513\n",
      "epoch: 7 step: 1033, loss is 0.0032620569691061974\n",
      "epoch: 7 step: 1034, loss is 0.00018480863946024328\n",
      "epoch: 7 step: 1035, loss is 0.06444592773914337\n",
      "epoch: 7 step: 1036, loss is 0.0003100369649473578\n",
      "epoch: 7 step: 1037, loss is 0.012263497337698936\n",
      "epoch: 7 step: 1038, loss is 0.07943827658891678\n",
      "epoch: 7 step: 1039, loss is 0.00038520610542036593\n",
      "epoch: 7 step: 1040, loss is 0.14172475039958954\n",
      "epoch: 7 step: 1041, loss is 0.01621459797024727\n",
      "epoch: 7 step: 1042, loss is 0.000779798487201333\n",
      "epoch: 7 step: 1043, loss is 0.0005499181570485234\n",
      "epoch: 7 step: 1044, loss is 0.05139582231640816\n",
      "epoch: 7 step: 1045, loss is 8.049311873037368e-05\n",
      "epoch: 7 step: 1046, loss is 0.00017625483451411128\n",
      "epoch: 7 step: 1047, loss is 0.0013237918028607965\n",
      "epoch: 7 step: 1048, loss is 0.017640836536884308\n",
      "epoch: 7 step: 1049, loss is 0.007909756153821945\n",
      "epoch: 7 step: 1050, loss is 0.003938914276659489\n",
      "epoch: 7 step: 1051, loss is 0.01281712669879198\n",
      "epoch: 7 step: 1052, loss is 0.000597944890614599\n",
      "epoch: 7 step: 1053, loss is 0.1398778110742569\n",
      "epoch: 7 step: 1054, loss is 0.0009078463772311807\n",
      "epoch: 7 step: 1055, loss is 0.004233870189636946\n",
      "epoch: 7 step: 1056, loss is 0.0009471318335272372\n",
      "epoch: 7 step: 1057, loss is 0.0018011757638305426\n",
      "epoch: 7 step: 1058, loss is 0.023910334333777428\n",
      "epoch: 7 step: 1059, loss is 0.00216065626591444\n",
      "epoch: 7 step: 1060, loss is 0.00022498206817544997\n",
      "epoch: 7 step: 1061, loss is 0.0016560099320486188\n",
      "epoch: 7 step: 1062, loss is 0.001577518880367279\n",
      "epoch: 7 step: 1063, loss is 0.005332217551767826\n",
      "epoch: 7 step: 1064, loss is 0.0009095382411032915\n",
      "epoch: 7 step: 1065, loss is 3.3691496355459094e-05\n",
      "epoch: 7 step: 1066, loss is 0.0019348831847310066\n",
      "epoch: 7 step: 1067, loss is 0.005893467925488949\n",
      "epoch: 7 step: 1068, loss is 0.08798669278621674\n",
      "epoch: 7 step: 1069, loss is 0.003471269039437175\n",
      "epoch: 7 step: 1070, loss is 0.00028883162303827703\n",
      "epoch: 7 step: 1071, loss is 0.022305628284811974\n",
      "epoch: 7 step: 1072, loss is 0.004379113204777241\n",
      "epoch: 7 step: 1073, loss is 0.0029031771700829268\n",
      "epoch: 7 step: 1074, loss is 0.0012792983325198293\n",
      "epoch: 7 step: 1075, loss is 0.001358406851068139\n",
      "epoch: 7 step: 1076, loss is 0.00024776210193522274\n",
      "epoch: 7 step: 1077, loss is 0.01121559925377369\n",
      "epoch: 7 step: 1078, loss is 0.0008531687781214714\n",
      "epoch: 7 step: 1079, loss is 0.0003557914460543543\n",
      "epoch: 7 step: 1080, loss is 0.0017070723697543144\n",
      "epoch: 7 step: 1081, loss is 0.014516133815050125\n",
      "epoch: 7 step: 1082, loss is 8.39695621834835e-06\n",
      "epoch: 7 step: 1083, loss is 0.00061778788222\n",
      "epoch: 7 step: 1084, loss is 0.00025571309379301965\n",
      "epoch: 7 step: 1085, loss is 0.016125163063406944\n",
      "epoch: 7 step: 1086, loss is 0.003099666675552726\n",
      "epoch: 7 step: 1087, loss is 0.0005968200275674462\n",
      "epoch: 7 step: 1088, loss is 0.091114841401577\n",
      "epoch: 7 step: 1089, loss is 0.006720144301652908\n",
      "epoch: 7 step: 1090, loss is 0.009528343565762043\n",
      "epoch: 7 step: 1091, loss is 8.618475840194151e-05\n",
      "epoch: 7 step: 1092, loss is 0.00028309732442721725\n",
      "epoch: 7 step: 1093, loss is 0.025754006579518318\n",
      "epoch: 7 step: 1094, loss is 0.0008102309657260776\n",
      "epoch: 7 step: 1095, loss is 0.00042186392238363624\n",
      "epoch: 7 step: 1096, loss is 0.009331172332167625\n",
      "epoch: 7 step: 1097, loss is 0.0028178575448691845\n",
      "epoch: 7 step: 1098, loss is 0.010696029290556908\n",
      "epoch: 7 step: 1099, loss is 0.006878220941871405\n",
      "epoch: 7 step: 1100, loss is 0.02776506170630455\n",
      "epoch: 7 step: 1101, loss is 0.0014715978177264333\n",
      "epoch: 7 step: 1102, loss is 0.06597966700792313\n",
      "epoch: 7 step: 1103, loss is 0.00021218053007032722\n",
      "epoch: 7 step: 1104, loss is 0.016437649726867676\n",
      "epoch: 7 step: 1105, loss is 0.001660570502281189\n",
      "epoch: 7 step: 1106, loss is 0.016065465286374092\n",
      "epoch: 7 step: 1107, loss is 4.553552935249172e-05\n",
      "epoch: 7 step: 1108, loss is 0.0010982423555105925\n",
      "epoch: 7 step: 1109, loss is 0.029355287551879883\n",
      "epoch: 7 step: 1110, loss is 0.0007920680218376219\n",
      "epoch: 7 step: 1111, loss is 0.040204524993896484\n",
      "epoch: 7 step: 1112, loss is 0.0008402599487453699\n",
      "epoch: 7 step: 1113, loss is 0.000925285741686821\n",
      "epoch: 7 step: 1114, loss is 0.003980246838182211\n",
      "epoch: 7 step: 1115, loss is 7.900057244114578e-05\n",
      "epoch: 7 step: 1116, loss is 0.039439648389816284\n",
      "epoch: 7 step: 1117, loss is 7.885420200182125e-05\n",
      "epoch: 7 step: 1118, loss is 0.00413379305973649\n",
      "epoch: 7 step: 1119, loss is 0.04303616285324097\n",
      "epoch: 7 step: 1120, loss is 0.0035901207011193037\n",
      "epoch: 7 step: 1121, loss is 0.002230178564786911\n",
      "epoch: 7 step: 1122, loss is 0.008568725548684597\n",
      "epoch: 7 step: 1123, loss is 0.003870225977152586\n",
      "epoch: 7 step: 1124, loss is 0.0435611754655838\n",
      "epoch: 7 step: 1125, loss is 0.02089330367743969\n",
      "epoch: 7 step: 1126, loss is 0.034649334847927094\n",
      "epoch: 7 step: 1127, loss is 0.08664033561944962\n",
      "epoch: 7 step: 1128, loss is 0.012553650885820389\n",
      "epoch: 7 step: 1129, loss is 0.011218339204788208\n",
      "epoch: 7 step: 1130, loss is 0.06852354854345322\n",
      "epoch: 7 step: 1131, loss is 0.12095746397972107\n",
      "epoch: 7 step: 1132, loss is 0.001620511175133288\n",
      "epoch: 7 step: 1133, loss is 7.88911638665013e-05\n",
      "epoch: 7 step: 1134, loss is 0.0004219177644699812\n",
      "epoch: 7 step: 1135, loss is 0.0007821035105735064\n",
      "epoch: 7 step: 1136, loss is 0.00022570785949938\n",
      "epoch: 7 step: 1137, loss is 0.0018868029583245516\n",
      "epoch: 7 step: 1138, loss is 0.002637651516124606\n",
      "epoch: 7 step: 1139, loss is 0.00016739952843636274\n",
      "epoch: 7 step: 1140, loss is 0.0006344584980979562\n",
      "epoch: 7 step: 1141, loss is 0.07009679079055786\n",
      "epoch: 7 step: 1142, loss is 0.08709936589002609\n",
      "epoch: 7 step: 1143, loss is 0.0016821130411699414\n",
      "epoch: 7 step: 1144, loss is 0.00017111445777118206\n",
      "epoch: 7 step: 1145, loss is 0.005417277105152607\n",
      "epoch: 7 step: 1146, loss is 0.0022204527631402016\n",
      "epoch: 7 step: 1147, loss is 0.0007539309444837272\n",
      "epoch: 7 step: 1148, loss is 0.0002527642354834825\n",
      "epoch: 7 step: 1149, loss is 0.09227100014686584\n",
      "epoch: 7 step: 1150, loss is 0.00023082213010638952\n",
      "epoch: 7 step: 1151, loss is 0.008179991506040096\n",
      "epoch: 7 step: 1152, loss is 0.002876252867281437\n",
      "epoch: 7 step: 1153, loss is 0.1077675148844719\n",
      "epoch: 7 step: 1154, loss is 0.0005926546873524785\n",
      "epoch: 7 step: 1155, loss is 0.0002620279265101999\n",
      "epoch: 7 step: 1156, loss is 3.737771839951165e-05\n",
      "epoch: 7 step: 1157, loss is 8.110128874250222e-06\n",
      "epoch: 7 step: 1158, loss is 0.00882126297801733\n",
      "epoch: 7 step: 1159, loss is 0.06642632186412811\n",
      "epoch: 7 step: 1160, loss is 0.016700122505426407\n",
      "epoch: 7 step: 1161, loss is 0.004416726529598236\n",
      "epoch: 7 step: 1162, loss is 0.1312166452407837\n",
      "epoch: 7 step: 1163, loss is 3.6084442399442196e-05\n",
      "epoch: 7 step: 1164, loss is 5.911667176405899e-05\n",
      "epoch: 7 step: 1165, loss is 0.00024394632782787085\n",
      "epoch: 7 step: 1166, loss is 0.00042944104643538594\n",
      "epoch: 7 step: 1167, loss is 0.0001146847935160622\n",
      "epoch: 7 step: 1168, loss is 1.0069912605104037e-05\n",
      "epoch: 7 step: 1169, loss is 0.00016184487321879715\n",
      "epoch: 7 step: 1170, loss is 0.0017098243115469813\n",
      "epoch: 7 step: 1171, loss is 0.010415744967758656\n",
      "epoch: 7 step: 1172, loss is 0.0010762366000562906\n",
      "epoch: 7 step: 1173, loss is 0.0034531839191913605\n",
      "epoch: 7 step: 1174, loss is 0.004480260889977217\n",
      "epoch: 7 step: 1175, loss is 0.007147240452468395\n",
      "epoch: 7 step: 1176, loss is 0.0008369164424948394\n",
      "epoch: 7 step: 1177, loss is 9.573205898050219e-05\n",
      "epoch: 7 step: 1178, loss is 0.008078834973275661\n",
      "epoch: 7 step: 1179, loss is 0.0016667690360918641\n",
      "epoch: 7 step: 1180, loss is 0.008494308218359947\n",
      "epoch: 7 step: 1181, loss is 0.014960532076656818\n",
      "epoch: 7 step: 1182, loss is 0.0005126907490193844\n",
      "epoch: 7 step: 1183, loss is 0.002825820352882147\n",
      "epoch: 7 step: 1184, loss is 0.0013103070668876171\n",
      "epoch: 7 step: 1185, loss is 0.00303235393948853\n",
      "epoch: 7 step: 1186, loss is 9.82718265731819e-05\n",
      "epoch: 7 step: 1187, loss is 0.007292531430721283\n",
      "epoch: 7 step: 1188, loss is 0.016352852806448936\n",
      "epoch: 7 step: 1189, loss is 0.0010379975428804755\n",
      "epoch: 7 step: 1190, loss is 0.03510916233062744\n",
      "epoch: 7 step: 1191, loss is 0.026613252237439156\n",
      "epoch: 7 step: 1192, loss is 0.0012821233831346035\n",
      "epoch: 7 step: 1193, loss is 0.001211221911944449\n",
      "epoch: 7 step: 1194, loss is 8.782069926382974e-05\n",
      "epoch: 7 step: 1195, loss is 7.336277485592291e-05\n",
      "epoch: 7 step: 1196, loss is 0.0026355283334851265\n",
      "epoch: 7 step: 1197, loss is 0.14313280582427979\n",
      "epoch: 7 step: 1198, loss is 0.00011778826592490077\n",
      "epoch: 7 step: 1199, loss is 0.004385972395539284\n",
      "epoch: 7 step: 1200, loss is 0.0047143991105258465\n",
      "epoch: 7 step: 1201, loss is 5.767939001088962e-05\n",
      "epoch: 7 step: 1202, loss is 2.726432285271585e-05\n",
      "epoch: 7 step: 1203, loss is 0.005798953585326672\n",
      "epoch: 7 step: 1204, loss is 0.000746395904570818\n",
      "epoch: 7 step: 1205, loss is 0.0006614598096348345\n",
      "epoch: 7 step: 1206, loss is 6.527930963784456e-05\n",
      "epoch: 7 step: 1207, loss is 0.017268836498260498\n",
      "epoch: 7 step: 1208, loss is 0.028526773676276207\n",
      "epoch: 7 step: 1209, loss is 0.10660647600889206\n",
      "epoch: 7 step: 1210, loss is 0.0019942736253142357\n",
      "epoch: 7 step: 1211, loss is 0.05379908159375191\n",
      "epoch: 7 step: 1212, loss is 0.006103295832872391\n",
      "epoch: 7 step: 1213, loss is 0.0012476922711357474\n",
      "epoch: 7 step: 1214, loss is 0.09941849857568741\n",
      "epoch: 7 step: 1215, loss is 0.00021936681878287345\n",
      "epoch: 7 step: 1216, loss is 0.008070835843682289\n",
      "epoch: 7 step: 1217, loss is 0.0030463135335594416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1218, loss is 0.09210539609193802\n",
      "epoch: 7 step: 1219, loss is 0.2318515032529831\n",
      "epoch: 7 step: 1220, loss is 0.00031585307442583144\n",
      "epoch: 7 step: 1221, loss is 0.024981696158647537\n",
      "epoch: 7 step: 1222, loss is 0.0006633377633988857\n",
      "epoch: 7 step: 1223, loss is 0.0016364709008485079\n",
      "epoch: 7 step: 1224, loss is 0.07315466552972794\n",
      "epoch: 7 step: 1225, loss is 0.00014984422887209803\n",
      "epoch: 7 step: 1226, loss is 0.0379800908267498\n",
      "epoch: 7 step: 1227, loss is 0.0030346510466188192\n",
      "epoch: 7 step: 1228, loss is 0.0029368659015744925\n",
      "epoch: 7 step: 1229, loss is 5.317914474289864e-05\n",
      "epoch: 7 step: 1230, loss is 0.00013975633191876113\n",
      "epoch: 7 step: 1231, loss is 0.05000580847263336\n",
      "epoch: 7 step: 1232, loss is 0.0005592789384536445\n",
      "epoch: 7 step: 1233, loss is 0.0012471415102481842\n",
      "epoch: 7 step: 1234, loss is 0.0005470750038512051\n",
      "epoch: 7 step: 1235, loss is 0.0005740021006204188\n",
      "epoch: 7 step: 1236, loss is 0.07657106965780258\n",
      "epoch: 7 step: 1237, loss is 0.01668657548725605\n",
      "epoch: 7 step: 1238, loss is 0.00038667014450766146\n",
      "epoch: 7 step: 1239, loss is 0.1246272623538971\n",
      "epoch: 7 step: 1240, loss is 0.05029731243848801\n",
      "epoch: 7 step: 1241, loss is 0.019237203523516655\n",
      "epoch: 7 step: 1242, loss is 5.272344424156472e-05\n",
      "epoch: 7 step: 1243, loss is 0.0029875566251575947\n",
      "epoch: 7 step: 1244, loss is 0.0015038305427879095\n",
      "epoch: 7 step: 1245, loss is 0.0013019077014178038\n",
      "epoch: 7 step: 1246, loss is 0.017458969727158546\n",
      "epoch: 7 step: 1247, loss is 0.04652881994843483\n",
      "epoch: 7 step: 1248, loss is 0.17830336093902588\n",
      "epoch: 7 step: 1249, loss is 0.0034832078963518143\n",
      "epoch: 7 step: 1250, loss is 0.003480857238173485\n",
      "epoch: 7 step: 1251, loss is 0.0003398484841454774\n",
      "epoch: 7 step: 1252, loss is 0.00036056930548511446\n",
      "epoch: 7 step: 1253, loss is 0.00041834585135802627\n",
      "epoch: 7 step: 1254, loss is 0.0997283086180687\n",
      "epoch: 7 step: 1255, loss is 0.00016901304479688406\n",
      "epoch: 7 step: 1256, loss is 0.03740273043513298\n",
      "epoch: 7 step: 1257, loss is 0.01425028033554554\n",
      "epoch: 7 step: 1258, loss is 0.005109043791890144\n",
      "epoch: 7 step: 1259, loss is 0.005557547323405743\n",
      "epoch: 7 step: 1260, loss is 0.003933961037546396\n",
      "epoch: 7 step: 1261, loss is 0.023932788521051407\n",
      "epoch: 7 step: 1262, loss is 0.07756871730089188\n",
      "epoch: 7 step: 1263, loss is 0.0028749057091772556\n",
      "epoch: 7 step: 1264, loss is 0.005666518118232489\n",
      "epoch: 7 step: 1265, loss is 0.0010035004233941436\n",
      "epoch: 7 step: 1266, loss is 0.19244542717933655\n",
      "epoch: 7 step: 1267, loss is 0.0014805826358497143\n",
      "epoch: 7 step: 1268, loss is 0.004952958784997463\n",
      "epoch: 7 step: 1269, loss is 0.03037109225988388\n",
      "epoch: 7 step: 1270, loss is 8.56441620271653e-05\n",
      "epoch: 7 step: 1271, loss is 0.001844623009674251\n",
      "epoch: 7 step: 1272, loss is 3.598017792683095e-05\n",
      "epoch: 7 step: 1273, loss is 3.236551128793508e-05\n",
      "epoch: 7 step: 1274, loss is 0.0010589966550469398\n",
      "epoch: 7 step: 1275, loss is 0.0004902571672573686\n",
      "epoch: 7 step: 1276, loss is 2.720727388805244e-05\n",
      "epoch: 7 step: 1277, loss is 0.016420166939496994\n",
      "epoch: 7 step: 1278, loss is 0.0012321569956839085\n",
      "epoch: 7 step: 1279, loss is 2.6380894269095734e-05\n",
      "epoch: 7 step: 1280, loss is 0.0026649869978427887\n",
      "epoch: 7 step: 1281, loss is 0.12208222597837448\n",
      "epoch: 7 step: 1282, loss is 0.007180929649621248\n",
      "epoch: 7 step: 1283, loss is 0.0031674131751060486\n",
      "epoch: 7 step: 1284, loss is 0.15986575186252594\n",
      "epoch: 7 step: 1285, loss is 0.004764936864376068\n",
      "epoch: 7 step: 1286, loss is 0.02156437560915947\n",
      "epoch: 7 step: 1287, loss is 0.0009805667214095592\n",
      "epoch: 7 step: 1288, loss is 0.001268127467483282\n",
      "epoch: 7 step: 1289, loss is 0.0003093591658398509\n",
      "epoch: 7 step: 1290, loss is 0.001001157215796411\n",
      "epoch: 7 step: 1291, loss is 0.0014466874999925494\n",
      "epoch: 7 step: 1292, loss is 0.0019872074481099844\n",
      "epoch: 7 step: 1293, loss is 0.0080686304718256\n",
      "epoch: 7 step: 1294, loss is 0.06483366340398788\n",
      "epoch: 7 step: 1295, loss is 0.00992544461041689\n",
      "epoch: 7 step: 1296, loss is 0.002875157631933689\n",
      "epoch: 7 step: 1297, loss is 0.054065246134996414\n",
      "epoch: 7 step: 1298, loss is 0.09272807836532593\n",
      "epoch: 7 step: 1299, loss is 0.015057273209095001\n",
      "epoch: 7 step: 1300, loss is 0.00038361508632078767\n",
      "epoch: 7 step: 1301, loss is 0.04925377294421196\n",
      "epoch: 7 step: 1302, loss is 0.0010099727660417557\n",
      "epoch: 7 step: 1303, loss is 0.0001998136576730758\n",
      "epoch: 7 step: 1304, loss is 0.11369460821151733\n",
      "epoch: 7 step: 1305, loss is 0.03359396383166313\n",
      "epoch: 7 step: 1306, loss is 0.0044738720171153545\n",
      "epoch: 7 step: 1307, loss is 0.00016892685380298644\n",
      "epoch: 7 step: 1308, loss is 0.007554975338280201\n",
      "epoch: 7 step: 1309, loss is 0.0009834440425038338\n",
      "epoch: 7 step: 1310, loss is 0.06669427454471588\n",
      "epoch: 7 step: 1311, loss is 0.1932535320520401\n",
      "epoch: 7 step: 1312, loss is 0.04232556372880936\n",
      "epoch: 7 step: 1313, loss is 0.00017958111129701138\n",
      "epoch: 7 step: 1314, loss is 0.010433542542159557\n",
      "epoch: 7 step: 1315, loss is 0.0005199071601964533\n",
      "epoch: 7 step: 1316, loss is 0.007471881341189146\n",
      "epoch: 7 step: 1317, loss is 0.008655629120767117\n",
      "epoch: 7 step: 1318, loss is 0.010624200105667114\n",
      "epoch: 7 step: 1319, loss is 0.0267815962433815\n",
      "epoch: 7 step: 1320, loss is 0.0851224735379219\n",
      "epoch: 7 step: 1321, loss is 0.027443023398518562\n",
      "epoch: 7 step: 1322, loss is 0.011244211345911026\n",
      "epoch: 7 step: 1323, loss is 0.027912558987736702\n",
      "epoch: 7 step: 1324, loss is 0.001215553842484951\n",
      "epoch: 7 step: 1325, loss is 0.07844755798578262\n",
      "epoch: 7 step: 1326, loss is 0.0010074955644086003\n",
      "epoch: 7 step: 1327, loss is 0.00035988097079098225\n",
      "epoch: 7 step: 1328, loss is 0.006301185116171837\n",
      "epoch: 7 step: 1329, loss is 0.009836667217314243\n",
      "epoch: 7 step: 1330, loss is 0.006028641480952501\n",
      "epoch: 7 step: 1331, loss is 0.00024268552078865469\n",
      "epoch: 7 step: 1332, loss is 0.021827558055520058\n",
      "epoch: 7 step: 1333, loss is 0.0007481294451281428\n",
      "epoch: 7 step: 1334, loss is 0.06722971796989441\n",
      "epoch: 7 step: 1335, loss is 0.002373657189309597\n",
      "epoch: 7 step: 1336, loss is 0.00020968039461877197\n",
      "epoch: 7 step: 1337, loss is 0.012019257061183453\n",
      "epoch: 7 step: 1338, loss is 0.004330815747380257\n",
      "epoch: 7 step: 1339, loss is 0.016018971800804138\n",
      "epoch: 7 step: 1340, loss is 0.005041579250246286\n",
      "epoch: 7 step: 1341, loss is 0.022910110652446747\n",
      "epoch: 7 step: 1342, loss is 0.0018575433641672134\n",
      "epoch: 7 step: 1343, loss is 0.0007080741925165057\n",
      "epoch: 7 step: 1344, loss is 0.00331893190741539\n",
      "epoch: 7 step: 1345, loss is 0.008662656880915165\n",
      "epoch: 7 step: 1346, loss is 0.05449797958135605\n",
      "epoch: 7 step: 1347, loss is 0.001740808947943151\n",
      "epoch: 7 step: 1348, loss is 0.00023802775831427425\n",
      "epoch: 7 step: 1349, loss is 0.00896724034100771\n",
      "epoch: 7 step: 1350, loss is 0.0050767213106155396\n",
      "epoch: 7 step: 1351, loss is 0.011013341136276722\n",
      "epoch: 7 step: 1352, loss is 0.1923576146364212\n",
      "epoch: 7 step: 1353, loss is 0.0003649764694273472\n",
      "epoch: 7 step: 1354, loss is 0.0005044900462962687\n",
      "epoch: 7 step: 1355, loss is 0.06969266384840012\n",
      "epoch: 7 step: 1356, loss is 0.00226230057887733\n",
      "epoch: 7 step: 1357, loss is 0.0006860862486064434\n",
      "epoch: 7 step: 1358, loss is 0.001915734144859016\n",
      "epoch: 7 step: 1359, loss is 0.02169189602136612\n",
      "epoch: 7 step: 1360, loss is 4.506696859607473e-05\n",
      "epoch: 7 step: 1361, loss is 0.006754617672413588\n",
      "epoch: 7 step: 1362, loss is 9.876037438516505e-06\n",
      "epoch: 7 step: 1363, loss is 0.0006555971340276301\n",
      "epoch: 7 step: 1364, loss is 0.0015209332341328263\n",
      "epoch: 7 step: 1365, loss is 0.01310410350561142\n",
      "epoch: 7 step: 1366, loss is 0.00694017019122839\n",
      "epoch: 7 step: 1367, loss is 1.7493557606940158e-05\n",
      "epoch: 7 step: 1368, loss is 0.07240395992994308\n",
      "epoch: 7 step: 1369, loss is 9.202690125675872e-05\n",
      "epoch: 7 step: 1370, loss is 0.023960376158356667\n",
      "epoch: 7 step: 1371, loss is 0.0016294410452246666\n",
      "epoch: 7 step: 1372, loss is 0.01652243547141552\n",
      "epoch: 7 step: 1373, loss is 0.003298278898000717\n",
      "epoch: 7 step: 1374, loss is 0.00444976007565856\n",
      "epoch: 7 step: 1375, loss is 0.0021370965987443924\n",
      "epoch: 7 step: 1376, loss is 0.00116255646571517\n",
      "epoch: 7 step: 1377, loss is 0.25577017664909363\n",
      "epoch: 7 step: 1378, loss is 0.06059521064162254\n",
      "epoch: 7 step: 1379, loss is 0.0003701866080518812\n",
      "epoch: 7 step: 1380, loss is 0.0012436896795406938\n",
      "epoch: 7 step: 1381, loss is 0.0005520914564840496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1382, loss is 0.028246285393834114\n",
      "epoch: 7 step: 1383, loss is 0.05179382115602493\n",
      "epoch: 7 step: 1384, loss is 0.003089748788625002\n",
      "epoch: 7 step: 1385, loss is 0.008233626373112202\n",
      "epoch: 7 step: 1386, loss is 0.007730837445706129\n",
      "epoch: 7 step: 1387, loss is 0.04264755919575691\n",
      "epoch: 7 step: 1388, loss is 0.0008027951116673648\n",
      "epoch: 7 step: 1389, loss is 0.046547312289476395\n",
      "epoch: 7 step: 1390, loss is 0.0013258903054520488\n",
      "epoch: 7 step: 1391, loss is 0.043212417513132095\n",
      "epoch: 7 step: 1392, loss is 0.0014021380338817835\n",
      "epoch: 7 step: 1393, loss is 0.021591760218143463\n",
      "epoch: 7 step: 1394, loss is 0.24047398567199707\n",
      "epoch: 7 step: 1395, loss is 0.023640958592295647\n",
      "epoch: 7 step: 1396, loss is 0.10877758264541626\n",
      "epoch: 7 step: 1397, loss is 0.01778126321732998\n",
      "epoch: 7 step: 1398, loss is 0.001004945719614625\n",
      "epoch: 7 step: 1399, loss is 0.0051836431957781315\n",
      "epoch: 7 step: 1400, loss is 0.02598254382610321\n",
      "epoch: 7 step: 1401, loss is 0.11566762626171112\n",
      "epoch: 7 step: 1402, loss is 0.002835433231666684\n",
      "epoch: 7 step: 1403, loss is 0.00026449610595591366\n",
      "epoch: 7 step: 1404, loss is 0.013936404138803482\n",
      "epoch: 7 step: 1405, loss is 0.0006699945079162717\n",
      "epoch: 7 step: 1406, loss is 6.357936217682436e-05\n",
      "epoch: 7 step: 1407, loss is 0.002002677647396922\n",
      "epoch: 7 step: 1408, loss is 0.00410065334290266\n",
      "epoch: 7 step: 1409, loss is 0.0018426222959533334\n",
      "epoch: 7 step: 1410, loss is 0.00032991511397995055\n",
      "epoch: 7 step: 1411, loss is 0.015219911932945251\n",
      "epoch: 7 step: 1412, loss is 0.011744748800992966\n",
      "epoch: 7 step: 1413, loss is 0.04046080633997917\n",
      "epoch: 7 step: 1414, loss is 0.00011480650573503226\n",
      "epoch: 7 step: 1415, loss is 0.003235421609133482\n",
      "epoch: 7 step: 1416, loss is 0.0005517984391190112\n",
      "epoch: 7 step: 1417, loss is 0.0024895763490349054\n",
      "epoch: 7 step: 1418, loss is 0.0326969213783741\n",
      "epoch: 7 step: 1419, loss is 0.00048267797683365643\n",
      "epoch: 7 step: 1420, loss is 0.01968291588127613\n",
      "epoch: 7 step: 1421, loss is 0.11662959307432175\n",
      "epoch: 7 step: 1422, loss is 0.08495362848043442\n",
      "epoch: 7 step: 1423, loss is 0.020735351368784904\n",
      "epoch: 7 step: 1424, loss is 0.09450789541006088\n",
      "epoch: 7 step: 1425, loss is 0.0015375141520053148\n",
      "epoch: 7 step: 1426, loss is 0.0026885217521339655\n",
      "epoch: 7 step: 1427, loss is 0.007514371536672115\n",
      "epoch: 7 step: 1428, loss is 0.042438726872205734\n",
      "epoch: 7 step: 1429, loss is 0.14230753481388092\n",
      "epoch: 7 step: 1430, loss is 0.00014198519056662917\n",
      "epoch: 7 step: 1431, loss is 0.0007785221678204834\n",
      "epoch: 7 step: 1432, loss is 0.012193472124636173\n",
      "epoch: 7 step: 1433, loss is 0.2740720510482788\n",
      "epoch: 7 step: 1434, loss is 0.0012504477053880692\n",
      "epoch: 7 step: 1435, loss is 0.0020103324204683304\n",
      "epoch: 7 step: 1436, loss is 0.0008399734506383538\n",
      "epoch: 7 step: 1437, loss is 0.00853852927684784\n",
      "epoch: 7 step: 1438, loss is 0.0021650874987244606\n",
      "epoch: 7 step: 1439, loss is 0.04721004143357277\n",
      "epoch: 7 step: 1440, loss is 7.582797843497247e-05\n",
      "epoch: 7 step: 1441, loss is 0.0570271760225296\n",
      "epoch: 7 step: 1442, loss is 0.0012281349627301097\n",
      "epoch: 7 step: 1443, loss is 0.09365466982126236\n",
      "epoch: 7 step: 1444, loss is 0.2396865040063858\n",
      "epoch: 7 step: 1445, loss is 0.014912538230419159\n",
      "epoch: 7 step: 1446, loss is 0.0005974088562652469\n",
      "epoch: 7 step: 1447, loss is 0.004930752795189619\n",
      "epoch: 7 step: 1448, loss is 0.0027191368862986565\n",
      "epoch: 7 step: 1449, loss is 0.0013366849161684513\n",
      "epoch: 7 step: 1450, loss is 0.0009635361493565142\n",
      "epoch: 7 step: 1451, loss is 0.000990255386568606\n",
      "epoch: 7 step: 1452, loss is 0.017603712156414986\n",
      "epoch: 7 step: 1453, loss is 0.018091343343257904\n",
      "epoch: 7 step: 1454, loss is 0.0005435936618596315\n",
      "epoch: 7 step: 1455, loss is 0.0013577905483543873\n",
      "epoch: 7 step: 1456, loss is 0.004930785857141018\n",
      "epoch: 7 step: 1457, loss is 0.030049528926610947\n",
      "epoch: 7 step: 1458, loss is 0.0016196293290704489\n",
      "epoch: 7 step: 1459, loss is 0.00016817841969896108\n",
      "epoch: 7 step: 1460, loss is 0.0028625705745071173\n",
      "epoch: 7 step: 1461, loss is 0.06579697877168655\n",
      "epoch: 7 step: 1462, loss is 0.0005045383586548269\n",
      "epoch: 7 step: 1463, loss is 0.022291559725999832\n",
      "epoch: 7 step: 1464, loss is 0.00695300055667758\n",
      "epoch: 7 step: 1465, loss is 0.024190831929445267\n",
      "epoch: 7 step: 1466, loss is 0.0008085389854386449\n",
      "epoch: 7 step: 1467, loss is 0.0002752330037765205\n",
      "epoch: 7 step: 1468, loss is 8.511221676599234e-05\n",
      "epoch: 7 step: 1469, loss is 0.02527637407183647\n",
      "epoch: 7 step: 1470, loss is 8.327218529302627e-05\n",
      "epoch: 7 step: 1471, loss is 0.004818340763449669\n",
      "epoch: 7 step: 1472, loss is 0.0006960724131204188\n",
      "epoch: 7 step: 1473, loss is 0.024430247023701668\n",
      "epoch: 7 step: 1474, loss is 0.0011154749663546681\n",
      "epoch: 7 step: 1475, loss is 0.030462205410003662\n",
      "epoch: 7 step: 1476, loss is 0.005233719013631344\n",
      "epoch: 7 step: 1477, loss is 0.0003581777564249933\n",
      "epoch: 7 step: 1478, loss is 0.021549763157963753\n",
      "epoch: 7 step: 1479, loss is 0.0001992712204810232\n",
      "epoch: 7 step: 1480, loss is 0.07866256684064865\n",
      "epoch: 7 step: 1481, loss is 0.042604971677064896\n",
      "epoch: 7 step: 1482, loss is 0.010129746049642563\n",
      "epoch: 7 step: 1483, loss is 0.0007644223514944315\n",
      "epoch: 7 step: 1484, loss is 0.0010808666702359915\n",
      "epoch: 7 step: 1485, loss is 0.001878444105386734\n",
      "epoch: 7 step: 1486, loss is 0.0006047628121450543\n",
      "epoch: 7 step: 1487, loss is 0.0449368953704834\n",
      "epoch: 7 step: 1488, loss is 0.05821195989847183\n",
      "epoch: 7 step: 1489, loss is 0.01320187933743\n",
      "epoch: 7 step: 1490, loss is 0.0019897569436579943\n",
      "epoch: 7 step: 1491, loss is 0.002950370544567704\n",
      "epoch: 7 step: 1492, loss is 0.004664439707994461\n",
      "epoch: 7 step: 1493, loss is 0.0012121753534302115\n",
      "epoch: 7 step: 1494, loss is 0.0008645486668683589\n",
      "epoch: 7 step: 1495, loss is 0.007218100130558014\n",
      "epoch: 7 step: 1496, loss is 0.00015502836322411895\n",
      "epoch: 7 step: 1497, loss is 0.0013725620228797197\n",
      "epoch: 7 step: 1498, loss is 4.828190867556259e-05\n",
      "epoch: 7 step: 1499, loss is 0.026552924886345863\n",
      "epoch: 7 step: 1500, loss is 0.0004831259429920465\n",
      "epoch: 7 step: 1501, loss is 0.019950760528445244\n",
      "epoch: 7 step: 1502, loss is 0.17289894819259644\n",
      "epoch: 7 step: 1503, loss is 0.025053218007087708\n",
      "epoch: 7 step: 1504, loss is 0.029487937688827515\n",
      "epoch: 7 step: 1505, loss is 0.0002270443510496989\n",
      "epoch: 7 step: 1506, loss is 0.004679848439991474\n",
      "epoch: 7 step: 1507, loss is 0.00012349485768936574\n",
      "epoch: 7 step: 1508, loss is 0.3951040506362915\n",
      "epoch: 7 step: 1509, loss is 0.024669388309121132\n",
      "epoch: 7 step: 1510, loss is 0.0016043917275965214\n",
      "epoch: 7 step: 1511, loss is 0.015591898001730442\n",
      "epoch: 7 step: 1512, loss is 0.061400387436151505\n",
      "epoch: 7 step: 1513, loss is 0.008562738075852394\n",
      "epoch: 7 step: 1514, loss is 0.015650292858481407\n",
      "epoch: 7 step: 1515, loss is 0.04513097181916237\n",
      "epoch: 7 step: 1516, loss is 0.003028652397915721\n",
      "epoch: 7 step: 1517, loss is 0.003808309556916356\n",
      "epoch: 7 step: 1518, loss is 0.0030143919866532087\n",
      "epoch: 7 step: 1519, loss is 0.01230493001639843\n",
      "epoch: 7 step: 1520, loss is 0.013286463916301727\n",
      "epoch: 7 step: 1521, loss is 0.0016691392520442605\n",
      "epoch: 7 step: 1522, loss is 0.000991734443232417\n",
      "epoch: 7 step: 1523, loss is 0.009277989156544209\n",
      "epoch: 7 step: 1524, loss is 0.048466045409440994\n",
      "epoch: 7 step: 1525, loss is 0.0014447603607550263\n",
      "epoch: 7 step: 1526, loss is 0.016697289422154427\n",
      "epoch: 7 step: 1527, loss is 0.18176744878292084\n",
      "epoch: 7 step: 1528, loss is 0.0071358527056872845\n",
      "epoch: 7 step: 1529, loss is 0.0034693190827965736\n",
      "epoch: 7 step: 1530, loss is 0.0023471894674003124\n",
      "epoch: 7 step: 1531, loss is 0.00028807928902097046\n",
      "epoch: 7 step: 1532, loss is 0.12099143862724304\n",
      "epoch: 7 step: 1533, loss is 0.00023933238117024302\n",
      "epoch: 7 step: 1534, loss is 0.0006054475088603795\n",
      "epoch: 7 step: 1535, loss is 0.0014435278717428446\n",
      "epoch: 7 step: 1536, loss is 0.0038779033347964287\n",
      "epoch: 7 step: 1537, loss is 0.11258959025144577\n",
      "epoch: 7 step: 1538, loss is 0.0004303116584196687\n",
      "epoch: 7 step: 1539, loss is 0.03226368501782417\n",
      "epoch: 7 step: 1540, loss is 0.0021976183634251356\n",
      "epoch: 7 step: 1541, loss is 0.0038134963251650333\n",
      "epoch: 7 step: 1542, loss is 0.021717065945267677\n",
      "epoch: 7 step: 1543, loss is 0.013777608051896095\n",
      "epoch: 7 step: 1544, loss is 0.17547781765460968\n",
      "epoch: 7 step: 1545, loss is 0.0010488000698387623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1546, loss is 0.0006191559368744493\n",
      "epoch: 7 step: 1547, loss is 0.011498727835714817\n",
      "epoch: 7 step: 1548, loss is 0.004076859448105097\n",
      "epoch: 7 step: 1549, loss is 0.0010333806276321411\n",
      "epoch: 7 step: 1550, loss is 0.00031976267928257585\n",
      "epoch: 7 step: 1551, loss is 0.00031727907480672\n",
      "epoch: 7 step: 1552, loss is 0.0008326507522724569\n",
      "epoch: 7 step: 1553, loss is 0.045668020844459534\n",
      "epoch: 7 step: 1554, loss is 0.0020760789047926664\n",
      "epoch: 7 step: 1555, loss is 0.00027526760823093355\n",
      "epoch: 7 step: 1556, loss is 0.0027920864522457123\n",
      "epoch: 7 step: 1557, loss is 0.00030638230964541435\n",
      "epoch: 7 step: 1558, loss is 0.0017449415754526854\n",
      "epoch: 7 step: 1559, loss is 0.06926049292087555\n",
      "epoch: 7 step: 1560, loss is 0.0014911192702129483\n",
      "epoch: 7 step: 1561, loss is 0.011372880078852177\n",
      "epoch: 7 step: 1562, loss is 0.005012515000998974\n",
      "epoch: 7 step: 1563, loss is 0.0008605981711298227\n",
      "epoch: 7 step: 1564, loss is 0.0005000384408049285\n",
      "epoch: 7 step: 1565, loss is 0.0044074589386582375\n",
      "epoch: 7 step: 1566, loss is 0.06317871063947678\n",
      "epoch: 7 step: 1567, loss is 0.014327912591397762\n",
      "epoch: 7 step: 1568, loss is 0.0024614727590233088\n",
      "epoch: 7 step: 1569, loss is 0.0052492255344986916\n",
      "epoch: 7 step: 1570, loss is 0.0031330178026109934\n",
      "epoch: 7 step: 1571, loss is 0.0017620017752051353\n",
      "epoch: 7 step: 1572, loss is 0.0009886850602924824\n",
      "epoch: 7 step: 1573, loss is 0.0010676516685634851\n",
      "epoch: 7 step: 1574, loss is 3.701322202687152e-05\n",
      "epoch: 7 step: 1575, loss is 0.0018264295067638159\n",
      "epoch: 7 step: 1576, loss is 0.005313691217452288\n",
      "epoch: 7 step: 1577, loss is 0.3031885027885437\n",
      "epoch: 7 step: 1578, loss is 0.002209857339039445\n",
      "epoch: 7 step: 1579, loss is 0.014756979420781136\n",
      "epoch: 7 step: 1580, loss is 0.006103919818997383\n",
      "epoch: 7 step: 1581, loss is 0.01238306611776352\n",
      "epoch: 7 step: 1582, loss is 0.18298417329788208\n",
      "epoch: 7 step: 1583, loss is 0.1473606824874878\n",
      "epoch: 7 step: 1584, loss is 0.015374178066849709\n",
      "epoch: 7 step: 1585, loss is 0.11968957632780075\n",
      "epoch: 7 step: 1586, loss is 0.007278223987668753\n",
      "epoch: 7 step: 1587, loss is 0.29920491576194763\n",
      "epoch: 7 step: 1588, loss is 0.005561701487749815\n",
      "epoch: 7 step: 1589, loss is 0.11015838384628296\n",
      "epoch: 7 step: 1590, loss is 0.0029841847717761993\n",
      "epoch: 7 step: 1591, loss is 0.025918589904904366\n",
      "epoch: 7 step: 1592, loss is 9.662233787821606e-05\n",
      "epoch: 7 step: 1593, loss is 0.009215818718075752\n",
      "epoch: 7 step: 1594, loss is 0.0021653661970049143\n",
      "epoch: 7 step: 1595, loss is 0.0018330286256968975\n",
      "epoch: 7 step: 1596, loss is 0.0006128450622782111\n",
      "epoch: 7 step: 1597, loss is 0.003558867610991001\n",
      "epoch: 7 step: 1598, loss is 0.0006959928432479501\n",
      "epoch: 7 step: 1599, loss is 0.1263652741909027\n",
      "epoch: 7 step: 1600, loss is 0.01501226145774126\n",
      "epoch: 7 step: 1601, loss is 0.1257641762495041\n",
      "epoch: 7 step: 1602, loss is 0.022186920046806335\n",
      "epoch: 7 step: 1603, loss is 0.0034465882927179337\n",
      "epoch: 7 step: 1604, loss is 0.006200852338224649\n",
      "epoch: 7 step: 1605, loss is 0.00018150819232687354\n",
      "epoch: 7 step: 1606, loss is 0.005061245057731867\n",
      "epoch: 7 step: 1607, loss is 0.007405679672956467\n",
      "epoch: 7 step: 1608, loss is 0.007493471726775169\n",
      "epoch: 7 step: 1609, loss is 0.012357719242572784\n",
      "epoch: 7 step: 1610, loss is 0.020270034670829773\n",
      "epoch: 7 step: 1611, loss is 0.0012955953134223819\n",
      "epoch: 7 step: 1612, loss is 0.05032781511545181\n",
      "epoch: 7 step: 1613, loss is 0.012198441661894321\n",
      "epoch: 7 step: 1614, loss is 4.0109491237672046e-05\n",
      "epoch: 7 step: 1615, loss is 0.03630718216300011\n",
      "epoch: 7 step: 1616, loss is 0.05835545435547829\n",
      "epoch: 7 step: 1617, loss is 0.0015668324194848537\n",
      "epoch: 7 step: 1618, loss is 0.005210737232118845\n",
      "epoch: 7 step: 1619, loss is 0.0072283074259757996\n",
      "epoch: 7 step: 1620, loss is 0.1556999534368515\n",
      "epoch: 7 step: 1621, loss is 0.00443244818598032\n",
      "epoch: 7 step: 1622, loss is 0.016502030193805695\n",
      "epoch: 7 step: 1623, loss is 0.0011962830321863294\n",
      "epoch: 7 step: 1624, loss is 0.002570933662354946\n",
      "epoch: 7 step: 1625, loss is 0.02307353913784027\n",
      "epoch: 7 step: 1626, loss is 0.010266288183629513\n",
      "epoch: 7 step: 1627, loss is 0.02730402536690235\n",
      "epoch: 7 step: 1628, loss is 0.053760237991809845\n",
      "epoch: 7 step: 1629, loss is 0.20854023098945618\n",
      "epoch: 7 step: 1630, loss is 0.014710322953760624\n",
      "epoch: 7 step: 1631, loss is 0.008028768934309483\n",
      "epoch: 7 step: 1632, loss is 0.0005843156250193715\n",
      "epoch: 7 step: 1633, loss is 0.02702099271118641\n",
      "epoch: 7 step: 1634, loss is 0.013078667223453522\n",
      "epoch: 7 step: 1635, loss is 0.011512259021401405\n",
      "epoch: 7 step: 1636, loss is 0.0008088746690191329\n",
      "epoch: 7 step: 1637, loss is 0.0002144161844626069\n",
      "epoch: 7 step: 1638, loss is 0.00021250516874715686\n",
      "epoch: 7 step: 1639, loss is 2.419668817310594e-05\n",
      "epoch: 7 step: 1640, loss is 0.2591918408870697\n",
      "epoch: 7 step: 1641, loss is 0.00027027743635699153\n",
      "epoch: 7 step: 1642, loss is 0.0002872509940061718\n",
      "epoch: 7 step: 1643, loss is 0.003974258899688721\n",
      "epoch: 7 step: 1644, loss is 0.0018018529517576098\n",
      "epoch: 7 step: 1645, loss is 0.04045473039150238\n",
      "epoch: 7 step: 1646, loss is 0.0028674155473709106\n",
      "epoch: 7 step: 1647, loss is 0.021980755031108856\n",
      "epoch: 7 step: 1648, loss is 0.00023424420214723796\n",
      "epoch: 7 step: 1649, loss is 0.003315230831503868\n",
      "epoch: 7 step: 1650, loss is 0.042173586785793304\n",
      "epoch: 7 step: 1651, loss is 0.00023818323097657412\n",
      "epoch: 7 step: 1652, loss is 0.0011454886989668012\n",
      "epoch: 7 step: 1653, loss is 0.016257692128419876\n",
      "epoch: 7 step: 1654, loss is 0.007841928862035275\n",
      "epoch: 7 step: 1655, loss is 0.1770467311143875\n",
      "epoch: 7 step: 1656, loss is 0.000805477611720562\n",
      "epoch: 7 step: 1657, loss is 0.006904745940119028\n",
      "epoch: 7 step: 1658, loss is 0.01504599954932928\n",
      "epoch: 7 step: 1659, loss is 0.0010190570028498769\n",
      "epoch: 7 step: 1660, loss is 0.018108585849404335\n",
      "epoch: 7 step: 1661, loss is 0.0017114211805164814\n",
      "epoch: 7 step: 1662, loss is 0.0007941738585941494\n",
      "epoch: 7 step: 1663, loss is 0.07415997982025146\n",
      "epoch: 7 step: 1664, loss is 0.0006849170313216746\n",
      "epoch: 7 step: 1665, loss is 0.001413225196301937\n",
      "epoch: 7 step: 1666, loss is 0.12943579256534576\n",
      "epoch: 7 step: 1667, loss is 0.004375405143946409\n",
      "epoch: 7 step: 1668, loss is 0.00036046115565113723\n",
      "epoch: 7 step: 1669, loss is 0.05812050402164459\n",
      "epoch: 7 step: 1670, loss is 0.0004902116488665342\n",
      "epoch: 7 step: 1671, loss is 0.018294522538781166\n",
      "epoch: 7 step: 1672, loss is 0.009830759838223457\n",
      "epoch: 7 step: 1673, loss is 9.199087071465328e-05\n",
      "epoch: 7 step: 1674, loss is 0.029421649873256683\n",
      "epoch: 7 step: 1675, loss is 0.0022707567550241947\n",
      "epoch: 7 step: 1676, loss is 0.00023536475782748312\n",
      "epoch: 7 step: 1677, loss is 0.001506761647760868\n",
      "epoch: 7 step: 1678, loss is 0.06631981581449509\n",
      "epoch: 7 step: 1679, loss is 0.001492649782449007\n",
      "epoch: 7 step: 1680, loss is 0.0007507011760026217\n",
      "epoch: 7 step: 1681, loss is 5.793684613308869e-05\n",
      "epoch: 7 step: 1682, loss is 0.0002907105954363942\n",
      "epoch: 7 step: 1683, loss is 0.012684810906648636\n",
      "epoch: 7 step: 1684, loss is 0.011653553694486618\n",
      "epoch: 7 step: 1685, loss is 0.006920299958437681\n",
      "epoch: 7 step: 1686, loss is 0.0015969459200277925\n",
      "epoch: 7 step: 1687, loss is 0.03575300797820091\n",
      "epoch: 7 step: 1688, loss is 0.004635755438357592\n",
      "epoch: 7 step: 1689, loss is 0.010233690962195396\n",
      "epoch: 7 step: 1690, loss is 0.006863381713628769\n",
      "epoch: 7 step: 1691, loss is 0.0013550638686865568\n",
      "epoch: 7 step: 1692, loss is 0.012081135995686054\n",
      "epoch: 7 step: 1693, loss is 0.008944821543991566\n",
      "epoch: 7 step: 1694, loss is 0.0010426809312775731\n",
      "epoch: 7 step: 1695, loss is 0.003291678847745061\n",
      "epoch: 7 step: 1696, loss is 0.01973962038755417\n",
      "epoch: 7 step: 1697, loss is 0.006807546131312847\n",
      "epoch: 7 step: 1698, loss is 0.00025439728051424026\n",
      "epoch: 7 step: 1699, loss is 0.004283077549189329\n",
      "epoch: 7 step: 1700, loss is 0.1104826107621193\n",
      "epoch: 7 step: 1701, loss is 0.0009504244662821293\n",
      "epoch: 7 step: 1702, loss is 0.007194769103080034\n",
      "epoch: 7 step: 1703, loss is 0.00023704330669716\n",
      "epoch: 7 step: 1704, loss is 0.004316490143537521\n",
      "epoch: 7 step: 1705, loss is 0.000524973263964057\n",
      "epoch: 7 step: 1706, loss is 0.0008521327399648726\n",
      "epoch: 7 step: 1707, loss is 0.0005350972060114145\n",
      "epoch: 7 step: 1708, loss is 0.010474137030541897\n",
      "epoch: 7 step: 1709, loss is 0.004418863449245691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1710, loss is 0.0005093252984806895\n",
      "epoch: 7 step: 1711, loss is 0.003957164473831654\n",
      "epoch: 7 step: 1712, loss is 0.0014202401507645845\n",
      "epoch: 7 step: 1713, loss is 0.00011012264440068975\n",
      "epoch: 7 step: 1714, loss is 0.004860961344093084\n",
      "epoch: 7 step: 1715, loss is 0.001971979858353734\n",
      "epoch: 7 step: 1716, loss is 0.00521398801356554\n",
      "epoch: 7 step: 1717, loss is 0.023325622081756592\n",
      "epoch: 7 step: 1718, loss is 0.028421834111213684\n",
      "epoch: 7 step: 1719, loss is 0.002202288480475545\n",
      "epoch: 7 step: 1720, loss is 0.00044288759818300605\n",
      "epoch: 7 step: 1721, loss is 0.0007941951625980437\n",
      "epoch: 7 step: 1722, loss is 0.017083412036299706\n",
      "epoch: 7 step: 1723, loss is 0.0048385863192379475\n",
      "epoch: 7 step: 1724, loss is 0.0021610644180327654\n",
      "epoch: 7 step: 1725, loss is 0.0021970432717353106\n",
      "epoch: 7 step: 1726, loss is 0.0017936872318387032\n",
      "epoch: 7 step: 1727, loss is 0.0010913170408457518\n",
      "epoch: 7 step: 1728, loss is 0.0036404491402208805\n",
      "epoch: 7 step: 1729, loss is 0.0020861520897597075\n",
      "epoch: 7 step: 1730, loss is 0.0003999743494205177\n",
      "epoch: 7 step: 1731, loss is 0.012805032543838024\n",
      "epoch: 7 step: 1732, loss is 0.0004972752067260444\n",
      "epoch: 7 step: 1733, loss is 0.03446449339389801\n",
      "epoch: 7 step: 1734, loss is 0.0009510362287983298\n",
      "epoch: 7 step: 1735, loss is 0.0006824126467108727\n",
      "epoch: 7 step: 1736, loss is 0.0007523271488025784\n",
      "epoch: 7 step: 1737, loss is 0.0003261773381382227\n",
      "epoch: 7 step: 1738, loss is 0.002347272355109453\n",
      "epoch: 7 step: 1739, loss is 0.0056906891986727715\n",
      "epoch: 7 step: 1740, loss is 0.0003328132152091712\n",
      "epoch: 7 step: 1741, loss is 0.003894300200045109\n",
      "epoch: 7 step: 1742, loss is 0.0014627747004851699\n",
      "epoch: 7 step: 1743, loss is 0.0010897991014644504\n",
      "epoch: 7 step: 1744, loss is 3.52782808477059e-05\n",
      "epoch: 7 step: 1745, loss is 0.02040037326514721\n",
      "epoch: 7 step: 1746, loss is 0.0014172402443364263\n",
      "epoch: 7 step: 1747, loss is 6.235965702217072e-05\n",
      "epoch: 7 step: 1748, loss is 0.013125024735927582\n",
      "epoch: 7 step: 1749, loss is 0.0734543576836586\n",
      "epoch: 7 step: 1750, loss is 0.012386423535645008\n",
      "epoch: 7 step: 1751, loss is 0.0001821615151129663\n",
      "epoch: 7 step: 1752, loss is 0.004882283508777618\n",
      "epoch: 7 step: 1753, loss is 0.0005082167917862535\n",
      "epoch: 7 step: 1754, loss is 3.046729034394957e-05\n",
      "epoch: 7 step: 1755, loss is 0.00414495961740613\n",
      "epoch: 7 step: 1756, loss is 0.000432262837421149\n",
      "epoch: 7 step: 1757, loss is 0.00018624993390403688\n",
      "epoch: 7 step: 1758, loss is 0.006070007104426622\n",
      "epoch: 7 step: 1759, loss is 0.0025119499769061804\n",
      "epoch: 7 step: 1760, loss is 0.0005649036611430347\n",
      "epoch: 7 step: 1761, loss is 0.0014333007857203484\n",
      "epoch: 7 step: 1762, loss is 0.0010319079738110304\n",
      "epoch: 7 step: 1763, loss is 0.00032758392626419663\n",
      "epoch: 7 step: 1764, loss is 0.056023139506578445\n",
      "epoch: 7 step: 1765, loss is 0.0030038452241569757\n",
      "epoch: 7 step: 1766, loss is 0.0003006101178470999\n",
      "epoch: 7 step: 1767, loss is 0.02032577060163021\n",
      "epoch: 7 step: 1768, loss is 0.00020725256763398647\n",
      "epoch: 7 step: 1769, loss is 0.0005213080439716578\n",
      "epoch: 7 step: 1770, loss is 2.8119855414843187e-05\n",
      "epoch: 7 step: 1771, loss is 0.04330803453922272\n",
      "epoch: 7 step: 1772, loss is 0.002223934745416045\n",
      "epoch: 7 step: 1773, loss is 0.00021526329510379583\n",
      "epoch: 7 step: 1774, loss is 0.013462083414196968\n",
      "epoch: 7 step: 1775, loss is 0.0021961061283946037\n",
      "epoch: 7 step: 1776, loss is 8.606407209299505e-05\n",
      "epoch: 7 step: 1777, loss is 0.00627535954117775\n",
      "epoch: 7 step: 1778, loss is 0.00029509543674066663\n",
      "epoch: 7 step: 1779, loss is 0.10445589572191238\n",
      "epoch: 7 step: 1780, loss is 0.0024399664252996445\n",
      "epoch: 7 step: 1781, loss is 0.00028038679738529027\n",
      "epoch: 7 step: 1782, loss is 0.0003328192688059062\n",
      "epoch: 7 step: 1783, loss is 0.00014406336413230747\n",
      "epoch: 7 step: 1784, loss is 0.0007470729178749025\n",
      "epoch: 7 step: 1785, loss is 0.00022442563204094768\n",
      "epoch: 7 step: 1786, loss is 0.0012385603040456772\n",
      "epoch: 7 step: 1787, loss is 0.0016874405555427074\n",
      "epoch: 7 step: 1788, loss is 0.0006227648700587451\n",
      "epoch: 7 step: 1789, loss is 0.0025523086078464985\n",
      "epoch: 7 step: 1790, loss is 0.00025325690512545407\n",
      "epoch: 7 step: 1791, loss is 0.1201511099934578\n",
      "epoch: 7 step: 1792, loss is 0.0016234214417636395\n",
      "epoch: 7 step: 1793, loss is 0.0007331840461120009\n",
      "epoch: 7 step: 1794, loss is 0.0024523574393242598\n",
      "epoch: 7 step: 1795, loss is 0.0015671788714826107\n",
      "epoch: 7 step: 1796, loss is 0.0077252136543393135\n",
      "epoch: 7 step: 1797, loss is 0.00046021907473914325\n",
      "epoch: 7 step: 1798, loss is 0.00045456993393599987\n",
      "epoch: 7 step: 1799, loss is 0.0015047489432618022\n",
      "epoch: 7 step: 1800, loss is 0.11833321303129196\n",
      "epoch: 7 step: 1801, loss is 0.00021751821623183787\n",
      "epoch: 7 step: 1802, loss is 0.0042349486611783504\n",
      "epoch: 7 step: 1803, loss is 0.0005917996168136597\n",
      "epoch: 7 step: 1804, loss is 0.0004138442745897919\n",
      "epoch: 7 step: 1805, loss is 0.14096437394618988\n",
      "epoch: 7 step: 1806, loss is 6.079759987187572e-05\n",
      "epoch: 7 step: 1807, loss is 0.006196347996592522\n",
      "epoch: 7 step: 1808, loss is 0.017789971083402634\n",
      "epoch: 7 step: 1809, loss is 2.5000565074151382e-05\n",
      "epoch: 7 step: 1810, loss is 0.00018977202125824988\n",
      "epoch: 7 step: 1811, loss is 0.00010031875717686489\n",
      "epoch: 7 step: 1812, loss is 0.008983314968645573\n",
      "epoch: 7 step: 1813, loss is 0.018421785905957222\n",
      "epoch: 7 step: 1814, loss is 0.012355650775134563\n",
      "epoch: 7 step: 1815, loss is 0.009314160794019699\n",
      "epoch: 7 step: 1816, loss is 0.0005877565708942711\n",
      "epoch: 7 step: 1817, loss is 0.0015866458415985107\n",
      "epoch: 7 step: 1818, loss is 0.1416761577129364\n",
      "epoch: 7 step: 1819, loss is 7.912932051112875e-05\n",
      "epoch: 7 step: 1820, loss is 0.0023491482716053724\n",
      "epoch: 7 step: 1821, loss is 0.008723007515072823\n",
      "epoch: 7 step: 1822, loss is 0.00011191683734068647\n",
      "epoch: 7 step: 1823, loss is 0.00022982252994552255\n",
      "epoch: 7 step: 1824, loss is 0.0017025466077029705\n",
      "epoch: 7 step: 1825, loss is 0.002848355332389474\n",
      "epoch: 7 step: 1826, loss is 0.03645472973585129\n",
      "epoch: 7 step: 1827, loss is 0.0009000244317576289\n",
      "epoch: 7 step: 1828, loss is 0.001208636211231351\n",
      "epoch: 7 step: 1829, loss is 0.004291201010346413\n",
      "epoch: 7 step: 1830, loss is 0.000483541312860325\n",
      "epoch: 7 step: 1831, loss is 0.01593557745218277\n",
      "epoch: 7 step: 1832, loss is 0.015871349722146988\n",
      "epoch: 7 step: 1833, loss is 0.003289448097348213\n",
      "epoch: 7 step: 1834, loss is 0.0021255342289805412\n",
      "epoch: 7 step: 1835, loss is 0.02181042544543743\n",
      "epoch: 7 step: 1836, loss is 0.006751555949449539\n",
      "epoch: 7 step: 1837, loss is 0.01364782266318798\n",
      "epoch: 7 step: 1838, loss is 0.00025559848290868104\n",
      "epoch: 7 step: 1839, loss is 0.005877980496734381\n",
      "epoch: 7 step: 1840, loss is 0.0027462830767035484\n",
      "epoch: 7 step: 1841, loss is 0.00013441282499115914\n",
      "epoch: 7 step: 1842, loss is 0.006185401696711779\n",
      "epoch: 7 step: 1843, loss is 0.060041215270757675\n",
      "epoch: 7 step: 1844, loss is 0.015448443591594696\n",
      "epoch: 7 step: 1845, loss is 0.02649141475558281\n",
      "epoch: 7 step: 1846, loss is 0.0003918258589692414\n",
      "epoch: 7 step: 1847, loss is 0.0029118978418409824\n",
      "epoch: 7 step: 1848, loss is 2.5064489818760194e-05\n",
      "epoch: 7 step: 1849, loss is 0.011068055406212807\n",
      "epoch: 7 step: 1850, loss is 0.00012231196160428226\n",
      "epoch: 7 step: 1851, loss is 0.0012415099190548062\n",
      "epoch: 7 step: 1852, loss is 0.009499551728367805\n",
      "epoch: 7 step: 1853, loss is 0.02043982408940792\n",
      "epoch: 7 step: 1854, loss is 3.0623948987340555e-05\n",
      "epoch: 7 step: 1855, loss is 0.005729518365114927\n",
      "epoch: 7 step: 1856, loss is 0.0005642942269332707\n",
      "epoch: 7 step: 1857, loss is 0.0004276264226064086\n",
      "epoch: 7 step: 1858, loss is 0.2580717206001282\n",
      "epoch: 7 step: 1859, loss is 0.017990177497267723\n",
      "epoch: 7 step: 1860, loss is 0.08254389464855194\n",
      "epoch: 7 step: 1861, loss is 0.0001825621584430337\n",
      "epoch: 7 step: 1862, loss is 0.00022806975175626576\n",
      "epoch: 7 step: 1863, loss is 0.0017922327388077974\n",
      "epoch: 7 step: 1864, loss is 0.00097512302454561\n",
      "epoch: 7 step: 1865, loss is 0.00021088693756610155\n",
      "epoch: 7 step: 1866, loss is 0.00043674130574800074\n",
      "epoch: 7 step: 1867, loss is 0.01691594161093235\n",
      "epoch: 7 step: 1868, loss is 2.2321615688269958e-05\n",
      "epoch: 7 step: 1869, loss is 0.032280292361974716\n",
      "epoch: 7 step: 1870, loss is 0.00010177049989579245\n",
      "epoch: 7 step: 1871, loss is 9.688970021670684e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 1872, loss is 0.0016938778571784496\n",
      "epoch: 7 step: 1873, loss is 4.798404188477434e-05\n",
      "epoch: 7 step: 1874, loss is 0.03581617400050163\n",
      "epoch: 7 step: 1875, loss is 0.001019329996779561\n",
      "epoch: 7 step: 1876, loss is 0.0004970520967617631\n",
      "epoch: 7 step: 1877, loss is 3.6911827919539064e-05\n",
      "epoch: 7 step: 1878, loss is 2.308693183294963e-05\n",
      "epoch: 7 step: 1879, loss is 0.010048910044133663\n",
      "epoch: 7 step: 1880, loss is 0.00354521325789392\n",
      "epoch: 7 step: 1881, loss is 0.01763826608657837\n",
      "epoch: 7 step: 1882, loss is 0.02395791932940483\n",
      "epoch: 7 step: 1883, loss is 0.0012991048861294985\n",
      "epoch: 7 step: 1884, loss is 4.297003761166707e-05\n",
      "epoch: 7 step: 1885, loss is 0.0016390448436141014\n",
      "epoch: 7 step: 1886, loss is 0.0008385325782001019\n",
      "epoch: 7 step: 1887, loss is 0.182110995054245\n",
      "epoch: 7 step: 1888, loss is 0.001190954353660345\n",
      "epoch: 7 step: 1889, loss is 0.0003108664241153747\n",
      "epoch: 7 step: 1890, loss is 0.39563220739364624\n",
      "epoch: 7 step: 1891, loss is 0.0007702713483013213\n",
      "epoch: 7 step: 1892, loss is 0.04573327675461769\n",
      "epoch: 7 step: 1893, loss is 0.006271750200539827\n",
      "epoch: 7 step: 1894, loss is 0.0024103098548948765\n",
      "epoch: 7 step: 1895, loss is 0.00020746744121424854\n",
      "epoch: 7 step: 1896, loss is 0.002601850079372525\n",
      "epoch: 7 step: 1897, loss is 9.397174289915711e-05\n",
      "epoch: 7 step: 1898, loss is 0.000207558783586137\n",
      "epoch: 7 step: 1899, loss is 0.00011483646812848747\n",
      "epoch: 7 step: 1900, loss is 0.004438009113073349\n",
      "epoch: 7 step: 1901, loss is 0.008445847779512405\n",
      "epoch: 7 step: 1902, loss is 0.004573877900838852\n",
      "epoch: 7 step: 1903, loss is 0.001508014160208404\n",
      "epoch: 7 step: 1904, loss is 0.025645192712545395\n",
      "epoch: 7 step: 1905, loss is 0.007617298047989607\n",
      "epoch: 7 step: 1906, loss is 0.00034325552405789495\n",
      "epoch: 7 step: 1907, loss is 0.0012153774732723832\n",
      "epoch: 7 step: 1908, loss is 0.01149927731603384\n",
      "epoch: 7 step: 1909, loss is 0.00548679381608963\n",
      "epoch: 7 step: 1910, loss is 0.03756483271718025\n",
      "epoch: 7 step: 1911, loss is 0.005709350109100342\n",
      "epoch: 7 step: 1912, loss is 0.001848924090154469\n",
      "epoch: 7 step: 1913, loss is 0.018431449308991432\n",
      "epoch: 7 step: 1914, loss is 0.001400364562869072\n",
      "epoch: 7 step: 1915, loss is 0.0044357613660395145\n",
      "epoch: 7 step: 1916, loss is 0.0004612369230017066\n",
      "epoch: 7 step: 1917, loss is 0.010491067543625832\n",
      "epoch: 7 step: 1918, loss is 0.0051675899885594845\n",
      "epoch: 7 step: 1919, loss is 0.004074550233781338\n",
      "epoch: 7 step: 1920, loss is 9.08517322386615e-05\n",
      "epoch: 7 step: 1921, loss is 0.0024920948781073093\n",
      "epoch: 7 step: 1922, loss is 0.0005424996488727629\n",
      "epoch: 7 step: 1923, loss is 0.001242027967236936\n",
      "epoch: 7 step: 1924, loss is 0.0011655298294499516\n",
      "epoch: 7 step: 1925, loss is 0.000762500858400017\n",
      "epoch: 7 step: 1926, loss is 0.10010198503732681\n",
      "epoch: 7 step: 1927, loss is 0.0013232717756181955\n",
      "epoch: 7 step: 1928, loss is 0.05038345977663994\n",
      "epoch: 7 step: 1929, loss is 0.04648957401514053\n",
      "epoch: 7 step: 1930, loss is 0.0020016885828226805\n",
      "epoch: 7 step: 1931, loss is 0.00040364975575357676\n",
      "epoch: 7 step: 1932, loss is 0.0013501648791134357\n",
      "epoch: 7 step: 1933, loss is 0.010527808219194412\n",
      "epoch: 7 step: 1934, loss is 0.026785502210259438\n",
      "epoch: 7 step: 1935, loss is 0.004974015057086945\n",
      "epoch: 7 step: 1936, loss is 0.0021418852265924215\n",
      "epoch: 7 step: 1937, loss is 0.002592657692730427\n",
      "epoch: 7 step: 1938, loss is 0.048558592796325684\n",
      "epoch: 7 step: 1939, loss is 0.0003275031631346792\n",
      "epoch: 7 step: 1940, loss is 0.0009178122272714972\n",
      "epoch: 7 step: 1941, loss is 0.014814196154475212\n",
      "epoch: 7 step: 1942, loss is 0.00048031326150521636\n",
      "epoch: 7 step: 1943, loss is 0.002629708731546998\n",
      "epoch: 7 step: 1944, loss is 1.780384627636522e-05\n",
      "epoch: 7 step: 1945, loss is 0.004700886085629463\n",
      "epoch: 7 step: 1946, loss is 0.0005242816987447441\n",
      "epoch: 7 step: 1947, loss is 0.0002479232207406312\n",
      "epoch: 7 step: 1948, loss is 0.0185925904661417\n",
      "epoch: 7 step: 1949, loss is 0.00435082521289587\n",
      "epoch: 7 step: 1950, loss is 0.0007663053111173213\n",
      "epoch: 7 step: 1951, loss is 0.0018985854694619775\n",
      "epoch: 7 step: 1952, loss is 0.05851159244775772\n",
      "epoch: 7 step: 1953, loss is 0.023273173719644547\n",
      "epoch: 7 step: 1954, loss is 0.0027916859835386276\n",
      "epoch: 7 step: 1955, loss is 0.001867176964879036\n",
      "epoch: 7 step: 1956, loss is 4.22839802922681e-05\n",
      "epoch: 7 step: 1957, loss is 0.016521070152521133\n",
      "epoch: 7 step: 1958, loss is 0.0913357138633728\n",
      "epoch: 7 step: 1959, loss is 0.0013555972836911678\n",
      "epoch: 7 step: 1960, loss is 0.0008159816497936845\n",
      "epoch: 7 step: 1961, loss is 0.004191228654235601\n",
      "epoch: 7 step: 1962, loss is 0.001746675930917263\n",
      "epoch: 7 step: 1963, loss is 0.0008935552905313671\n",
      "epoch: 7 step: 1964, loss is 0.008945254608988762\n",
      "epoch: 7 step: 1965, loss is 0.0020118714310228825\n",
      "epoch: 7 step: 1966, loss is 7.805541099514812e-05\n",
      "epoch: 7 step: 1967, loss is 0.00016825401689857244\n",
      "epoch: 7 step: 1968, loss is 5.549565321416594e-05\n",
      "epoch: 7 step: 1969, loss is 0.01947411149740219\n",
      "epoch: 7 step: 1970, loss is 0.0004466524987947196\n",
      "epoch: 7 step: 1971, loss is 4.268759221304208e-05\n",
      "epoch: 7 step: 1972, loss is 0.018021371215581894\n",
      "epoch: 7 step: 1973, loss is 0.018459849059581757\n",
      "epoch: 7 step: 1974, loss is 0.00020090634643565863\n",
      "epoch: 7 step: 1975, loss is 0.021395225077867508\n",
      "epoch: 7 step: 1976, loss is 0.020456979051232338\n",
      "epoch: 7 step: 1977, loss is 0.0006315879290923476\n",
      "epoch: 7 step: 1978, loss is 0.0015041586011648178\n",
      "epoch: 7 step: 1979, loss is 0.0019262266578152776\n",
      "epoch: 7 step: 1980, loss is 0.00036755827022716403\n",
      "epoch: 7 step: 1981, loss is 0.18844562768936157\n",
      "epoch: 7 step: 1982, loss is 7.52808409743011e-05\n",
      "epoch: 7 step: 1983, loss is 0.0036754922475665808\n",
      "epoch: 7 step: 1984, loss is 0.09512930363416672\n",
      "epoch: 7 step: 1985, loss is 0.0006060062441974878\n",
      "epoch: 7 step: 1986, loss is 0.0021377000957727432\n",
      "epoch: 7 step: 1987, loss is 0.00040686127613298595\n",
      "epoch: 7 step: 1988, loss is 0.011225259862840176\n",
      "epoch: 7 step: 1989, loss is 0.005586169194430113\n",
      "epoch: 7 step: 1990, loss is 0.009001387283205986\n",
      "epoch: 7 step: 1991, loss is 0.00399680994451046\n",
      "epoch: 7 step: 1992, loss is 0.0016879779286682606\n",
      "epoch: 7 step: 1993, loss is 0.00037330083432607353\n",
      "epoch: 7 step: 1994, loss is 0.00011509622709127143\n",
      "epoch: 7 step: 1995, loss is 0.023639384657144547\n",
      "epoch: 7 step: 1996, loss is 0.012304658070206642\n",
      "epoch: 7 step: 1997, loss is 0.017692426219582558\n",
      "epoch: 7 step: 1998, loss is 0.012837323360145092\n",
      "epoch: 7 step: 1999, loss is 0.00698841130360961\n",
      "epoch: 7 step: 2000, loss is 0.0004189386672805995\n",
      "epoch: 7 step: 2001, loss is 0.031525589525699615\n",
      "epoch: 7 step: 2002, loss is 0.00021470419596880674\n",
      "epoch: 7 step: 2003, loss is 0.21316753327846527\n",
      "epoch: 7 step: 2004, loss is 4.225322118145414e-05\n",
      "epoch: 7 step: 2005, loss is 0.018686791881918907\n",
      "epoch: 7 step: 2006, loss is 5.447103103506379e-05\n",
      "epoch: 7 step: 2007, loss is 0.0003155743470415473\n",
      "epoch: 7 step: 2008, loss is 0.10705781728029251\n",
      "epoch: 7 step: 2009, loss is 0.01689169742166996\n",
      "epoch: 7 step: 2010, loss is 0.009855780750513077\n",
      "epoch: 7 step: 2011, loss is 0.0023026985581964254\n",
      "epoch: 7 step: 2012, loss is 0.003443747293204069\n",
      "epoch: 7 step: 2013, loss is 0.005846276879310608\n",
      "epoch: 7 step: 2014, loss is 0.03409695252776146\n",
      "epoch: 7 step: 2015, loss is 0.00017709123494569212\n",
      "epoch: 7 step: 2016, loss is 0.0030210192780941725\n",
      "epoch: 7 step: 2017, loss is 0.0015947395004332066\n",
      "epoch: 7 step: 2018, loss is 0.17559969425201416\n",
      "epoch: 7 step: 2019, loss is 0.0007945711258798838\n",
      "epoch: 7 step: 2020, loss is 0.006240886636078358\n",
      "epoch: 7 step: 2021, loss is 0.11921229213476181\n",
      "epoch: 7 step: 2022, loss is 0.0055463737808167934\n",
      "epoch: 7 step: 2023, loss is 0.0021113643888384104\n",
      "epoch: 7 step: 2024, loss is 0.028013847768306732\n",
      "epoch: 7 step: 2025, loss is 0.0025232492480427027\n",
      "epoch: 7 step: 2026, loss is 0.08689925819635391\n",
      "epoch: 7 step: 2027, loss is 0.015437315218150616\n",
      "epoch: 7 step: 2028, loss is 0.12184491753578186\n",
      "epoch: 7 step: 2029, loss is 6.297760410234332e-05\n",
      "epoch: 7 step: 2030, loss is 0.0026609962806105614\n",
      "epoch: 7 step: 2031, loss is 0.0328657329082489\n",
      "epoch: 7 step: 2032, loss is 0.0008048369199968874\n",
      "epoch: 7 step: 2033, loss is 0.002445167861878872\n",
      "epoch: 7 step: 2034, loss is 0.0002450858009979129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 2035, loss is 0.012901515699923038\n",
      "epoch: 7 step: 2036, loss is 0.0002672494447324425\n",
      "epoch: 7 step: 2037, loss is 0.0021290697623044252\n",
      "epoch: 7 step: 2038, loss is 0.00075946981087327\n",
      "epoch: 7 step: 2039, loss is 0.00025927770184352994\n",
      "epoch: 7 step: 2040, loss is 0.02068304270505905\n",
      "epoch: 7 step: 2041, loss is 0.002428986830636859\n",
      "epoch: 7 step: 2042, loss is 0.04129410535097122\n",
      "epoch: 7 step: 2043, loss is 0.07272515445947647\n",
      "epoch: 7 step: 2044, loss is 0.0012307176366448402\n",
      "epoch: 7 step: 2045, loss is 0.07639680802822113\n",
      "epoch: 7 step: 2046, loss is 0.015406632795929909\n",
      "epoch: 7 step: 2047, loss is 0.008662747219204903\n",
      "epoch: 7 step: 2048, loss is 0.1978999227285385\n",
      "epoch: 7 step: 2049, loss is 1.8922884919447824e-05\n",
      "epoch: 7 step: 2050, loss is 0.00039726911927573383\n",
      "epoch: 7 step: 2051, loss is 0.011465783230960369\n",
      "epoch: 7 step: 2052, loss is 0.16254450380802155\n",
      "epoch: 7 step: 2053, loss is 0.00031998424674384296\n",
      "epoch: 7 step: 2054, loss is 0.0072998059913516045\n",
      "epoch: 7 step: 2055, loss is 0.0034765952732414007\n",
      "epoch: 7 step: 2056, loss is 0.0003335562360007316\n",
      "epoch: 7 step: 2057, loss is 0.0757802426815033\n",
      "epoch: 7 step: 2058, loss is 0.03620779141783714\n",
      "epoch: 7 step: 2059, loss is 0.09554282575845718\n",
      "epoch: 7 step: 2060, loss is 0.020209267735481262\n",
      "epoch: 7 step: 2061, loss is 0.004100572317838669\n",
      "epoch: 7 step: 2062, loss is 0.005824722349643707\n",
      "epoch: 7 step: 2063, loss is 0.0006746255676262081\n",
      "epoch: 7 step: 2064, loss is 0.057468343526124954\n",
      "epoch: 7 step: 2065, loss is 0.0064450534991919994\n",
      "epoch: 7 step: 2066, loss is 0.20220668613910675\n",
      "epoch: 7 step: 2067, loss is 0.009795344434678555\n",
      "epoch: 7 step: 2068, loss is 0.004566472489386797\n",
      "epoch: 7 step: 2069, loss is 0.011594824492931366\n",
      "epoch: 7 step: 2070, loss is 0.0013457415625452995\n",
      "epoch: 7 step: 2071, loss is 0.00019093659648206085\n",
      "epoch: 7 step: 2072, loss is 0.006667735520750284\n",
      "epoch: 7 step: 2073, loss is 0.059663325548172\n",
      "epoch: 7 step: 2074, loss is 0.0012804417638108134\n",
      "epoch: 7 step: 2075, loss is 0.0024990784004330635\n",
      "epoch: 7 step: 2076, loss is 0.12199283391237259\n",
      "epoch: 7 step: 2077, loss is 0.00027637853054329753\n",
      "epoch: 7 step: 2078, loss is 0.00015317140787374228\n",
      "epoch: 7 step: 2079, loss is 0.044519104063510895\n",
      "epoch: 7 step: 2080, loss is 0.0021345424465835094\n",
      "epoch: 7 step: 2081, loss is 0.0001828497479436919\n",
      "epoch: 7 step: 2082, loss is 0.0005120810237713158\n",
      "epoch: 7 step: 2083, loss is 0.010518432594835758\n",
      "epoch: 7 step: 2084, loss is 0.06355786323547363\n",
      "epoch: 7 step: 2085, loss is 0.008428497239947319\n",
      "epoch: 7 step: 2086, loss is 0.002857001032680273\n",
      "epoch: 7 step: 2087, loss is 0.0319732166826725\n",
      "epoch: 7 step: 2088, loss is 0.005792082287371159\n",
      "epoch: 7 step: 2089, loss is 0.0055331699550151825\n",
      "epoch: 7 step: 2090, loss is 0.002806101692840457\n",
      "epoch: 7 step: 2091, loss is 0.0003741716791409999\n",
      "epoch: 7 step: 2092, loss is 0.000879161583725363\n",
      "epoch: 7 step: 2093, loss is 0.008374227210879326\n",
      "epoch: 7 step: 2094, loss is 0.021875297650694847\n",
      "epoch: 7 step: 2095, loss is 0.0006648391135968268\n",
      "epoch: 7 step: 2096, loss is 0.0005812727613374591\n",
      "epoch: 7 step: 2097, loss is 0.0007001403137110174\n",
      "epoch: 7 step: 2098, loss is 0.0006339677493087947\n",
      "epoch: 7 step: 2099, loss is 0.04367342218756676\n",
      "epoch: 7 step: 2100, loss is 0.12263477593660355\n",
      "epoch: 7 step: 2101, loss is 0.009924011304974556\n",
      "epoch: 7 step: 2102, loss is 0.02011161297559738\n",
      "epoch: 7 step: 2103, loss is 0.004088624846190214\n",
      "epoch: 7 step: 2104, loss is 0.0011617899872362614\n",
      "epoch: 7 step: 2105, loss is 0.0005169599899090827\n",
      "epoch: 7 step: 2106, loss is 0.00044388597598299384\n",
      "epoch: 7 step: 2107, loss is 0.01826116256415844\n",
      "epoch: 7 step: 2108, loss is 0.001191282644867897\n",
      "epoch: 7 step: 2109, loss is 0.009959484450519085\n",
      "epoch: 7 step: 2110, loss is 0.0026858460623770952\n",
      "epoch: 7 step: 2111, loss is 0.07011290639638901\n",
      "epoch: 7 step: 2112, loss is 0.0004565572598949075\n",
      "epoch: 7 step: 2113, loss is 0.039846789091825485\n",
      "epoch: 7 step: 2114, loss is 0.0003529353707563132\n",
      "epoch: 7 step: 2115, loss is 0.04818381369113922\n",
      "epoch: 7 step: 2116, loss is 0.00022347160847857594\n",
      "epoch: 7 step: 2117, loss is 0.0011421097442507744\n",
      "epoch: 7 step: 2118, loss is 0.13404375314712524\n",
      "epoch: 7 step: 2119, loss is 0.005890669301152229\n",
      "epoch: 7 step: 2120, loss is 0.0029097103979438543\n",
      "epoch: 7 step: 2121, loss is 0.030846549198031425\n",
      "epoch: 7 step: 2122, loss is 0.07423032075166702\n",
      "epoch: 7 step: 2123, loss is 0.0005663990159519017\n",
      "epoch: 7 step: 2124, loss is 0.0004612055199686438\n",
      "epoch: 7 step: 2125, loss is 0.021113229915499687\n",
      "epoch: 7 step: 2126, loss is 0.001509571447968483\n",
      "epoch: 7 step: 2127, loss is 0.050279419869184494\n",
      "epoch: 7 step: 2128, loss is 0.00014247922808863223\n",
      "epoch: 7 step: 2129, loss is 0.05269382894039154\n",
      "epoch: 7 step: 2130, loss is 0.01560763269662857\n",
      "epoch: 7 step: 2131, loss is 0.0026491116732358932\n",
      "epoch: 7 step: 2132, loss is 0.0006750788306817412\n",
      "epoch: 7 step: 2133, loss is 0.03591843321919441\n",
      "epoch: 7 step: 2134, loss is 0.0027899490669369698\n",
      "epoch: 7 step: 2135, loss is 0.0006245276308618486\n",
      "epoch: 7 step: 2136, loss is 0.03434492275118828\n",
      "epoch: 7 step: 2137, loss is 0.00010231626947643235\n",
      "epoch: 7 step: 2138, loss is 0.028481949120759964\n",
      "epoch: 7 step: 2139, loss is 0.026322904974222183\n",
      "epoch: 7 step: 2140, loss is 0.0009376846137456596\n",
      "epoch: 7 step: 2141, loss is 0.00031524852965958416\n",
      "epoch: 7 step: 2142, loss is 0.003992858808487654\n",
      "epoch: 7 step: 2143, loss is 0.030472643673419952\n",
      "epoch: 7 step: 2144, loss is 0.050466544926166534\n",
      "epoch: 7 step: 2145, loss is 0.009070944972336292\n",
      "epoch: 7 step: 2146, loss is 0.021606124937534332\n",
      "epoch: 7 step: 2147, loss is 0.016318516805768013\n",
      "epoch: 7 step: 2148, loss is 0.0018518490251153708\n",
      "epoch: 7 step: 2149, loss is 0.00027114106342196465\n",
      "epoch: 7 step: 2150, loss is 0.021611472591757774\n",
      "epoch: 7 step: 2151, loss is 0.011170072481036186\n",
      "epoch: 7 step: 2152, loss is 0.013076992705464363\n",
      "epoch: 7 step: 2153, loss is 0.0006068825023248792\n",
      "epoch: 7 step: 2154, loss is 0.002130708657205105\n",
      "epoch: 7 step: 2155, loss is 0.053232233971357346\n",
      "epoch: 7 step: 2156, loss is 0.007441436871886253\n",
      "epoch: 7 step: 2157, loss is 0.02756483294069767\n",
      "epoch: 7 step: 2158, loss is 0.00023621729633305222\n",
      "epoch: 7 step: 2159, loss is 0.00018258702766615897\n",
      "epoch: 7 step: 2160, loss is 0.024856699630618095\n",
      "epoch: 7 step: 2161, loss is 0.022100046277046204\n",
      "epoch: 7 step: 2162, loss is 0.0010495840106159449\n",
      "epoch: 7 step: 2163, loss is 0.0003116305742878467\n",
      "epoch: 7 step: 2164, loss is 0.007307830732315779\n",
      "epoch: 7 step: 2165, loss is 0.00013999328075442463\n",
      "epoch: 7 step: 2166, loss is 0.001441202242858708\n",
      "epoch: 7 step: 2167, loss is 0.0002879382227547467\n",
      "epoch: 7 step: 2168, loss is 0.0004845813673455268\n",
      "epoch: 7 step: 2169, loss is 0.01544257439672947\n",
      "epoch: 7 step: 2170, loss is 0.013758405111730099\n",
      "epoch: 7 step: 2171, loss is 0.0006585884257219732\n",
      "epoch: 7 step: 2172, loss is 0.0001045486715156585\n",
      "epoch: 7 step: 2173, loss is 0.055643901228904724\n",
      "epoch: 7 step: 2174, loss is 0.0033695371821522713\n",
      "epoch: 7 step: 2175, loss is 0.00835702195763588\n",
      "epoch: 7 step: 2176, loss is 0.009684528224170208\n",
      "epoch: 7 step: 2177, loss is 0.00661767041310668\n",
      "epoch: 7 step: 2178, loss is 0.00015316222561523318\n",
      "epoch: 7 step: 2179, loss is 0.02281052991747856\n",
      "epoch: 7 step: 2180, loss is 0.0023966790176928043\n",
      "epoch: 7 step: 2181, loss is 0.0002823580871336162\n",
      "epoch: 7 step: 2182, loss is 1.8776519937091507e-05\n",
      "epoch: 7 step: 2183, loss is 0.00012336739746388048\n",
      "epoch: 7 step: 2184, loss is 0.0016032306011766195\n",
      "epoch: 7 step: 2185, loss is 9.332923946203664e-05\n",
      "epoch: 7 step: 2186, loss is 0.00045246066292747855\n",
      "epoch: 7 step: 2187, loss is 0.0837985947728157\n",
      "epoch: 8 step: 1, loss is 0.0076949717476964\n",
      "epoch: 8 step: 2, loss is 2.6791101845446974e-05\n",
      "epoch: 8 step: 3, loss is 0.0005168640054762363\n",
      "epoch: 8 step: 4, loss is 0.003908261191099882\n",
      "epoch: 8 step: 5, loss is 2.6731871912488714e-05\n",
      "epoch: 8 step: 6, loss is 0.0008482700795866549\n",
      "epoch: 8 step: 7, loss is 0.021071113646030426\n",
      "epoch: 8 step: 8, loss is 0.00013034188305027783\n",
      "epoch: 8 step: 9, loss is 0.028122004121541977\n",
      "epoch: 8 step: 10, loss is 0.0001828727254178375\n",
      "epoch: 8 step: 11, loss is 0.024935992434620857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 12, loss is 0.0001371465768897906\n",
      "epoch: 8 step: 13, loss is 0.0010047953110188246\n",
      "epoch: 8 step: 14, loss is 0.02876090444624424\n",
      "epoch: 8 step: 15, loss is 0.002320040948688984\n",
      "epoch: 8 step: 16, loss is 0.005722964648157358\n",
      "epoch: 8 step: 17, loss is 5.7289689721073955e-05\n",
      "epoch: 8 step: 18, loss is 0.006279833614826202\n",
      "epoch: 8 step: 19, loss is 0.005174627993255854\n",
      "epoch: 8 step: 20, loss is 0.009367181919515133\n",
      "epoch: 8 step: 21, loss is 0.05346628278493881\n",
      "epoch: 8 step: 22, loss is 0.0019790991209447384\n",
      "epoch: 8 step: 23, loss is 0.00010707984620239586\n",
      "epoch: 8 step: 24, loss is 0.0006306756404228508\n",
      "epoch: 8 step: 25, loss is 0.00017068586021196097\n",
      "epoch: 8 step: 26, loss is 0.020218610763549805\n",
      "epoch: 8 step: 27, loss is 0.00015722925309091806\n",
      "epoch: 8 step: 28, loss is 0.0012491918168962002\n",
      "epoch: 8 step: 29, loss is 2.1308828763721976e-06\n",
      "epoch: 8 step: 30, loss is 0.00025616056518629193\n",
      "epoch: 8 step: 31, loss is 0.0007712559308856726\n",
      "epoch: 8 step: 32, loss is 0.00019365786283742636\n",
      "epoch: 8 step: 33, loss is 2.0757577658514492e-05\n",
      "epoch: 8 step: 34, loss is 0.019718481227755547\n",
      "epoch: 8 step: 35, loss is 0.08105321228504181\n",
      "epoch: 8 step: 36, loss is 0.0017083226703107357\n",
      "epoch: 8 step: 37, loss is 0.0005101269343867898\n",
      "epoch: 8 step: 38, loss is 0.002719095442444086\n",
      "epoch: 8 step: 39, loss is 0.0011791785946115851\n",
      "epoch: 8 step: 40, loss is 0.008954734541475773\n",
      "epoch: 8 step: 41, loss is 8.012937905732542e-05\n",
      "epoch: 8 step: 42, loss is 0.0006762371631339192\n",
      "epoch: 8 step: 43, loss is 0.0011098879622295499\n",
      "epoch: 8 step: 44, loss is 0.004275359679013491\n",
      "epoch: 8 step: 45, loss is 0.0008564044255763292\n",
      "epoch: 8 step: 46, loss is 0.004773022141307592\n",
      "epoch: 8 step: 47, loss is 0.03394988924264908\n",
      "epoch: 8 step: 48, loss is 0.0002652078401297331\n",
      "epoch: 8 step: 49, loss is 0.06096760928630829\n",
      "epoch: 8 step: 50, loss is 0.013661769218742847\n",
      "epoch: 8 step: 51, loss is 0.00036508694756776094\n",
      "epoch: 8 step: 52, loss is 0.002840090775862336\n",
      "epoch: 8 step: 53, loss is 0.003032013075426221\n",
      "epoch: 8 step: 54, loss is 3.0079179850872606e-05\n",
      "epoch: 8 step: 55, loss is 9.468187636230141e-05\n",
      "epoch: 8 step: 56, loss is 0.0004073016461916268\n",
      "epoch: 8 step: 57, loss is 0.00010809526429511607\n",
      "epoch: 8 step: 58, loss is 0.00019971057190559804\n",
      "epoch: 8 step: 59, loss is 0.0029996889643371105\n",
      "epoch: 8 step: 60, loss is 0.0051518636755645275\n",
      "epoch: 8 step: 61, loss is 4.563386391964741e-05\n",
      "epoch: 8 step: 62, loss is 0.025354640558362007\n",
      "epoch: 8 step: 63, loss is 3.573431968106888e-05\n",
      "epoch: 8 step: 64, loss is 0.005641825497150421\n",
      "epoch: 8 step: 65, loss is 9.793567005544901e-05\n",
      "epoch: 8 step: 66, loss is 0.022945461794734\n",
      "epoch: 8 step: 67, loss is 0.00010937949264189228\n",
      "epoch: 8 step: 68, loss is 9.935606612998527e-06\n",
      "epoch: 8 step: 69, loss is 0.001145214308053255\n",
      "epoch: 8 step: 70, loss is 0.003937235102057457\n",
      "epoch: 8 step: 71, loss is 0.000949766137637198\n",
      "epoch: 8 step: 72, loss is 4.605283902492374e-05\n",
      "epoch: 8 step: 73, loss is 0.0005958951078355312\n",
      "epoch: 8 step: 74, loss is 0.0008451443281956017\n",
      "epoch: 8 step: 75, loss is 0.0008110528578981757\n",
      "epoch: 8 step: 76, loss is 0.0036945794709026814\n",
      "epoch: 8 step: 77, loss is 0.016492292284965515\n",
      "epoch: 8 step: 78, loss is 0.11659719794988632\n",
      "epoch: 8 step: 79, loss is 0.0011194577673450112\n",
      "epoch: 8 step: 80, loss is 0.01053980365395546\n",
      "epoch: 8 step: 81, loss is 0.01126931607723236\n",
      "epoch: 8 step: 82, loss is 0.00011163498857058585\n",
      "epoch: 8 step: 83, loss is 2.692373345780652e-05\n",
      "epoch: 8 step: 84, loss is 0.0016979784704744816\n",
      "epoch: 8 step: 85, loss is 0.0009288883884437382\n",
      "epoch: 8 step: 86, loss is 6.0623468016274273e-05\n",
      "epoch: 8 step: 87, loss is 0.0005890639149583876\n",
      "epoch: 8 step: 88, loss is 6.344478606479242e-05\n",
      "epoch: 8 step: 89, loss is 5.189434432395501e-06\n",
      "epoch: 8 step: 90, loss is 0.0001604659773875028\n",
      "epoch: 8 step: 91, loss is 0.0002562195004429668\n",
      "epoch: 8 step: 92, loss is 0.00026868563145399094\n",
      "epoch: 8 step: 93, loss is 0.001011691871099174\n",
      "epoch: 8 step: 94, loss is 0.013210768811404705\n",
      "epoch: 8 step: 95, loss is 1.8775563148665242e-06\n",
      "epoch: 8 step: 96, loss is 0.005935869179666042\n",
      "epoch: 8 step: 97, loss is 0.011046642437577248\n",
      "epoch: 8 step: 98, loss is 4.4035219616489485e-05\n",
      "epoch: 8 step: 99, loss is 0.011979704722762108\n",
      "epoch: 8 step: 100, loss is 0.06094435974955559\n",
      "epoch: 8 step: 101, loss is 0.009040569886565208\n",
      "epoch: 8 step: 102, loss is 1.796319156710524e-05\n",
      "epoch: 8 step: 103, loss is 0.0014028942678123713\n",
      "epoch: 8 step: 104, loss is 6.072087853681296e-05\n",
      "epoch: 8 step: 105, loss is 0.07054997235536575\n",
      "epoch: 8 step: 106, loss is 7.302279846044257e-05\n",
      "epoch: 8 step: 107, loss is 0.0012350288452580571\n",
      "epoch: 8 step: 108, loss is 0.00018158432794734836\n",
      "epoch: 8 step: 109, loss is 0.0002169611252611503\n",
      "epoch: 8 step: 110, loss is 3.744445712072775e-05\n",
      "epoch: 8 step: 111, loss is 0.00015286565758287907\n",
      "epoch: 8 step: 112, loss is 6.354093784466386e-05\n",
      "epoch: 8 step: 113, loss is 0.0002914567885454744\n",
      "epoch: 8 step: 114, loss is 0.00010359232692280784\n",
      "epoch: 8 step: 115, loss is 0.0016636847285553813\n",
      "epoch: 8 step: 116, loss is 3.452185046626255e-05\n",
      "epoch: 8 step: 117, loss is 0.005539403762668371\n",
      "epoch: 8 step: 118, loss is 0.0001371811085846275\n",
      "epoch: 8 step: 119, loss is 0.00037649014848284423\n",
      "epoch: 8 step: 120, loss is 0.0042371591553092\n",
      "epoch: 8 step: 121, loss is 0.0002751873398665339\n",
      "epoch: 8 step: 122, loss is 0.001408223295584321\n",
      "epoch: 8 step: 123, loss is 0.00015050219371914864\n",
      "epoch: 8 step: 124, loss is 0.00025561987422406673\n",
      "epoch: 8 step: 125, loss is 0.011648748070001602\n",
      "epoch: 8 step: 126, loss is 0.016911327838897705\n",
      "epoch: 8 step: 127, loss is 5.222881736699492e-05\n",
      "epoch: 8 step: 128, loss is 0.000561429827939719\n",
      "epoch: 8 step: 129, loss is 1.9416485883994028e-05\n",
      "epoch: 8 step: 130, loss is 0.03379380330443382\n",
      "epoch: 8 step: 131, loss is 0.0002930906193796545\n",
      "epoch: 8 step: 132, loss is 0.0038828253746032715\n",
      "epoch: 8 step: 133, loss is 0.05330473929643631\n",
      "epoch: 8 step: 134, loss is 9.651171421865001e-05\n",
      "epoch: 8 step: 135, loss is 0.0001872729480965063\n",
      "epoch: 8 step: 136, loss is 3.980158726335503e-05\n",
      "epoch: 8 step: 137, loss is 0.0006326822913251817\n",
      "epoch: 8 step: 138, loss is 0.21173085272312164\n",
      "epoch: 8 step: 139, loss is 0.0003029312938451767\n",
      "epoch: 8 step: 140, loss is 0.00012645682727452368\n",
      "epoch: 8 step: 141, loss is 0.007930180989205837\n",
      "epoch: 8 step: 142, loss is 0.00039657665183767676\n",
      "epoch: 8 step: 143, loss is 0.010324639268219471\n",
      "epoch: 8 step: 144, loss is 0.00041558523662388325\n",
      "epoch: 8 step: 145, loss is 0.016890833154320717\n",
      "epoch: 8 step: 146, loss is 0.0008495998336002231\n",
      "epoch: 8 step: 147, loss is 0.0009617783944122493\n",
      "epoch: 8 step: 148, loss is 0.013517419807612896\n",
      "epoch: 8 step: 149, loss is 0.08307517319917679\n",
      "epoch: 8 step: 150, loss is 2.8323327569523826e-05\n",
      "epoch: 8 step: 151, loss is 0.004692299757152796\n",
      "epoch: 8 step: 152, loss is 0.0003229288849979639\n",
      "epoch: 8 step: 153, loss is 0.011917500756680965\n",
      "epoch: 8 step: 154, loss is 6.795248282287503e-06\n",
      "epoch: 8 step: 155, loss is 0.0003894642577506602\n",
      "epoch: 8 step: 156, loss is 0.0009252580348402262\n",
      "epoch: 8 step: 157, loss is 0.006062799133360386\n",
      "epoch: 8 step: 158, loss is 0.00012664965470321476\n",
      "epoch: 8 step: 159, loss is 0.004128582775592804\n",
      "epoch: 8 step: 160, loss is 0.0015823689755052328\n",
      "epoch: 8 step: 161, loss is 0.02179093286395073\n",
      "epoch: 8 step: 162, loss is 8.010522287804633e-05\n",
      "epoch: 8 step: 163, loss is 5.517301906365901e-05\n",
      "epoch: 8 step: 164, loss is 0.004987701307982206\n",
      "epoch: 8 step: 165, loss is 0.0004417582240421325\n",
      "epoch: 8 step: 166, loss is 0.0007224708097055554\n",
      "epoch: 8 step: 167, loss is 0.001397808431647718\n",
      "epoch: 8 step: 168, loss is 0.0019169907318428159\n",
      "epoch: 8 step: 169, loss is 0.04999062046408653\n",
      "epoch: 8 step: 170, loss is 0.007687553763389587\n",
      "epoch: 8 step: 171, loss is 0.007629069034010172\n",
      "epoch: 8 step: 172, loss is 0.00018344484851695597\n",
      "epoch: 8 step: 173, loss is 0.006160417106002569\n",
      "epoch: 8 step: 174, loss is 5.688633336831117e-06\n",
      "epoch: 8 step: 175, loss is 0.02404831349849701\n",
      "epoch: 8 step: 176, loss is 0.036807239055633545\n",
      "epoch: 8 step: 177, loss is 0.018277768045663834\n",
      "epoch: 8 step: 178, loss is 0.0005982432048767805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 179, loss is 0.012042728252708912\n",
      "epoch: 8 step: 180, loss is 0.07190565764904022\n",
      "epoch: 8 step: 181, loss is 0.0001455613091820851\n",
      "epoch: 8 step: 182, loss is 0.016950545832514763\n",
      "epoch: 8 step: 183, loss is 0.0011866462882608175\n",
      "epoch: 8 step: 184, loss is 0.00035925774136558175\n",
      "epoch: 8 step: 185, loss is 0.0006114958086982369\n",
      "epoch: 8 step: 186, loss is 0.0001165478170150891\n",
      "epoch: 8 step: 187, loss is 0.013876081444323063\n",
      "epoch: 8 step: 188, loss is 4.682350481743924e-05\n",
      "epoch: 8 step: 189, loss is 0.001845056191086769\n",
      "epoch: 8 step: 190, loss is 1.6924728697631508e-05\n",
      "epoch: 8 step: 191, loss is 4.559867193165701e-06\n",
      "epoch: 8 step: 192, loss is 0.0002326728863408789\n",
      "epoch: 8 step: 193, loss is 0.017323996871709824\n",
      "epoch: 8 step: 194, loss is 0.0008282954804599285\n",
      "epoch: 8 step: 195, loss is 0.004245185758918524\n",
      "epoch: 8 step: 196, loss is 0.019497526809573174\n",
      "epoch: 8 step: 197, loss is 0.0005423796828836203\n",
      "epoch: 8 step: 198, loss is 0.04837127402424812\n",
      "epoch: 8 step: 199, loss is 0.0002231418911833316\n",
      "epoch: 8 step: 200, loss is 0.09813956171274185\n",
      "epoch: 8 step: 201, loss is 0.012273017317056656\n",
      "epoch: 8 step: 202, loss is 0.012774721719324589\n",
      "epoch: 8 step: 203, loss is 0.0002476225490681827\n",
      "epoch: 8 step: 204, loss is 3.1961422791937366e-05\n",
      "epoch: 8 step: 205, loss is 0.00866179820150137\n",
      "epoch: 8 step: 206, loss is 9.58174769039033e-06\n",
      "epoch: 8 step: 207, loss is 0.00028288931935094297\n",
      "epoch: 8 step: 208, loss is 0.0006884623435325921\n",
      "epoch: 8 step: 209, loss is 0.19284440577030182\n",
      "epoch: 8 step: 210, loss is 0.000180925359018147\n",
      "epoch: 8 step: 211, loss is 0.005084537900984287\n",
      "epoch: 8 step: 212, loss is 0.0002318855986231938\n",
      "epoch: 8 step: 213, loss is 0.029320012778043747\n",
      "epoch: 8 step: 214, loss is 0.00038248623604886234\n",
      "epoch: 8 step: 215, loss is 0.024601414799690247\n",
      "epoch: 8 step: 216, loss is 7.604462734889239e-05\n",
      "epoch: 8 step: 217, loss is 0.0011139592388644814\n",
      "epoch: 8 step: 218, loss is 0.00018597849702928215\n",
      "epoch: 8 step: 219, loss is 0.0012843518052250147\n",
      "epoch: 8 step: 220, loss is 0.004270749632269144\n",
      "epoch: 8 step: 221, loss is 0.0014204723993316293\n",
      "epoch: 8 step: 222, loss is 0.005716617219150066\n",
      "epoch: 8 step: 223, loss is 0.004759431350976229\n",
      "epoch: 8 step: 224, loss is 0.02352495677769184\n",
      "epoch: 8 step: 225, loss is 0.005338264629244804\n",
      "epoch: 8 step: 226, loss is 0.00613202853128314\n",
      "epoch: 8 step: 227, loss is 0.060380324721336365\n",
      "epoch: 8 step: 228, loss is 4.7382342017954215e-05\n",
      "epoch: 8 step: 229, loss is 0.08476759493350983\n",
      "epoch: 8 step: 230, loss is 0.00016160258383024484\n",
      "epoch: 8 step: 231, loss is 0.001580186653882265\n",
      "epoch: 8 step: 232, loss is 0.00015142644406296313\n",
      "epoch: 8 step: 233, loss is 7.871663547120988e-05\n",
      "epoch: 8 step: 234, loss is 0.00016353355022147298\n",
      "epoch: 8 step: 235, loss is 0.045751187950372696\n",
      "epoch: 8 step: 236, loss is 3.1195271731121466e-05\n",
      "epoch: 8 step: 237, loss is 0.051486432552337646\n",
      "epoch: 8 step: 238, loss is 7.27370788808912e-05\n",
      "epoch: 8 step: 239, loss is 0.01605384610593319\n",
      "epoch: 8 step: 240, loss is 0.04505221173167229\n",
      "epoch: 8 step: 241, loss is 0.05297354608774185\n",
      "epoch: 8 step: 242, loss is 0.0005825217231176794\n",
      "epoch: 8 step: 243, loss is 0.013105749152600765\n",
      "epoch: 8 step: 244, loss is 0.008780759759247303\n",
      "epoch: 8 step: 245, loss is 0.05378282442688942\n",
      "epoch: 8 step: 246, loss is 0.05448131263256073\n",
      "epoch: 8 step: 247, loss is 0.01576370559632778\n",
      "epoch: 8 step: 248, loss is 0.005363017320632935\n",
      "epoch: 8 step: 249, loss is 0.05562850087881088\n",
      "epoch: 8 step: 250, loss is 0.2633780539035797\n",
      "epoch: 8 step: 251, loss is 0.005338470451533794\n",
      "epoch: 8 step: 252, loss is 3.162569191772491e-05\n",
      "epoch: 8 step: 253, loss is 0.00015819011605344713\n",
      "epoch: 8 step: 254, loss is 7.503556116716936e-05\n",
      "epoch: 8 step: 255, loss is 0.04100172966718674\n",
      "epoch: 8 step: 256, loss is 0.00048210201202891767\n",
      "epoch: 8 step: 257, loss is 0.0028455825522542\n",
      "epoch: 8 step: 258, loss is 0.002989522647112608\n",
      "epoch: 8 step: 259, loss is 0.0009229961433447897\n",
      "epoch: 8 step: 260, loss is 0.004238520283252001\n",
      "epoch: 8 step: 261, loss is 0.0029683876782655716\n",
      "epoch: 8 step: 262, loss is 0.0007556005730293691\n",
      "epoch: 8 step: 263, loss is 0.017981503158807755\n",
      "epoch: 8 step: 264, loss is 0.0008025796851143241\n",
      "epoch: 8 step: 265, loss is 0.24824629724025726\n",
      "epoch: 8 step: 266, loss is 0.01250173058360815\n",
      "epoch: 8 step: 267, loss is 0.10525228828191757\n",
      "epoch: 8 step: 268, loss is 0.00031977042090147734\n",
      "epoch: 8 step: 269, loss is 0.09371540695428848\n",
      "epoch: 8 step: 270, loss is 0.00047641590936109424\n",
      "epoch: 8 step: 271, loss is 0.0017679068259894848\n",
      "epoch: 8 step: 272, loss is 0.04157128930091858\n",
      "epoch: 8 step: 273, loss is 0.0004457338072825223\n",
      "epoch: 8 step: 274, loss is 0.004670658614486456\n",
      "epoch: 8 step: 275, loss is 2.098662116623018e-05\n",
      "epoch: 8 step: 276, loss is 0.0021121781319379807\n",
      "epoch: 8 step: 277, loss is 0.006367173045873642\n",
      "epoch: 8 step: 278, loss is 9.840173152042553e-05\n",
      "epoch: 8 step: 279, loss is 5.409917503129691e-05\n",
      "epoch: 8 step: 280, loss is 0.01208585686981678\n",
      "epoch: 8 step: 281, loss is 0.005430988501757383\n",
      "epoch: 8 step: 282, loss is 0.0011781906941905618\n",
      "epoch: 8 step: 283, loss is 0.025447430089116096\n",
      "epoch: 8 step: 284, loss is 0.1976223737001419\n",
      "epoch: 8 step: 285, loss is 0.004918936640024185\n",
      "epoch: 8 step: 286, loss is 0.021612845361232758\n",
      "epoch: 8 step: 287, loss is 0.030455362051725388\n",
      "epoch: 8 step: 288, loss is 0.0009703713585622609\n",
      "epoch: 8 step: 289, loss is 0.0004195943765807897\n",
      "epoch: 8 step: 290, loss is 0.004270739853382111\n",
      "epoch: 8 step: 291, loss is 0.003955080173909664\n",
      "epoch: 8 step: 292, loss is 0.012741475366055965\n",
      "epoch: 8 step: 293, loss is 0.0018241660436615348\n",
      "epoch: 8 step: 294, loss is 0.029391853138804436\n",
      "epoch: 8 step: 295, loss is 0.1503816694021225\n",
      "epoch: 8 step: 296, loss is 0.25237396359443665\n",
      "epoch: 8 step: 297, loss is 0.0002859695232473314\n",
      "epoch: 8 step: 298, loss is 0.035860829055309296\n",
      "epoch: 8 step: 299, loss is 0.00021657974866684526\n",
      "epoch: 8 step: 300, loss is 7.879435725044459e-05\n",
      "epoch: 8 step: 301, loss is 0.0034564926754683256\n",
      "epoch: 8 step: 302, loss is 0.001028259634040296\n",
      "epoch: 8 step: 303, loss is 0.0012206658720970154\n",
      "epoch: 8 step: 304, loss is 0.0026555408257991076\n",
      "epoch: 8 step: 305, loss is 0.0029442221857607365\n",
      "epoch: 8 step: 306, loss is 0.0005317936302162707\n",
      "epoch: 8 step: 307, loss is 0.01416862290352583\n",
      "epoch: 8 step: 308, loss is 0.0018135493155568838\n",
      "epoch: 8 step: 309, loss is 0.0005321369972079992\n",
      "epoch: 8 step: 310, loss is 6.194578600116074e-05\n",
      "epoch: 8 step: 311, loss is 0.0002450068132020533\n",
      "epoch: 8 step: 312, loss is 0.0009417898254469037\n",
      "epoch: 8 step: 313, loss is 0.0006007188349030912\n",
      "epoch: 8 step: 314, loss is 0.0005112863145768642\n",
      "epoch: 8 step: 315, loss is 0.016269110143184662\n",
      "epoch: 8 step: 316, loss is 0.011078202165663242\n",
      "epoch: 8 step: 317, loss is 0.009407063946127892\n",
      "epoch: 8 step: 318, loss is 3.727995135704987e-05\n",
      "epoch: 8 step: 319, loss is 0.00025788339553400874\n",
      "epoch: 8 step: 320, loss is 0.019118227064609528\n",
      "epoch: 8 step: 321, loss is 0.0010950318537652493\n",
      "epoch: 8 step: 322, loss is 0.0033188790548592806\n",
      "epoch: 8 step: 323, loss is 0.0009693271713331342\n",
      "epoch: 8 step: 324, loss is 0.00015545917267445475\n",
      "epoch: 8 step: 325, loss is 0.0002763373777270317\n",
      "epoch: 8 step: 326, loss is 0.0003032602835446596\n",
      "epoch: 8 step: 327, loss is 0.021909356117248535\n",
      "epoch: 8 step: 328, loss is 0.0004077971098013222\n",
      "epoch: 8 step: 329, loss is 0.07388591766357422\n",
      "epoch: 8 step: 330, loss is 0.14494584500789642\n",
      "epoch: 8 step: 331, loss is 0.06505731493234634\n",
      "epoch: 8 step: 332, loss is 0.0009150387486442924\n",
      "epoch: 8 step: 333, loss is 0.09417083859443665\n",
      "epoch: 8 step: 334, loss is 0.003798208897933364\n",
      "epoch: 8 step: 335, loss is 0.0003470462979748845\n",
      "epoch: 8 step: 336, loss is 0.007050801534205675\n",
      "epoch: 8 step: 337, loss is 0.0037071839906275272\n",
      "epoch: 8 step: 338, loss is 0.02662978507578373\n",
      "epoch: 8 step: 339, loss is 0.0003304911369923502\n",
      "epoch: 8 step: 340, loss is 0.02027421072125435\n",
      "epoch: 8 step: 341, loss is 0.10909555852413177\n",
      "epoch: 8 step: 342, loss is 0.002678020391613245\n",
      "epoch: 8 step: 343, loss is 0.11216381937265396\n",
      "epoch: 8 step: 344, loss is 0.039249520748853683\n",
      "epoch: 8 step: 345, loss is 0.009051022119820118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 346, loss is 0.00208841310814023\n",
      "epoch: 8 step: 347, loss is 0.00477009080350399\n",
      "epoch: 8 step: 348, loss is 0.013991196639835835\n",
      "epoch: 8 step: 349, loss is 0.033563148230314255\n",
      "epoch: 8 step: 350, loss is 0.001123593421652913\n",
      "epoch: 8 step: 351, loss is 0.035084281116724014\n",
      "epoch: 8 step: 352, loss is 0.005486416630446911\n",
      "epoch: 8 step: 353, loss is 0.001277091447263956\n",
      "epoch: 8 step: 354, loss is 0.013429406099021435\n",
      "epoch: 8 step: 355, loss is 0.001955961575731635\n",
      "epoch: 8 step: 356, loss is 0.0001275614049518481\n",
      "epoch: 8 step: 357, loss is 0.0008343156659975648\n",
      "epoch: 8 step: 358, loss is 0.0017383990343660116\n",
      "epoch: 8 step: 359, loss is 0.08796258270740509\n",
      "epoch: 8 step: 360, loss is 0.11816376447677612\n",
      "epoch: 8 step: 361, loss is 0.003354695625603199\n",
      "epoch: 8 step: 362, loss is 0.01100388914346695\n",
      "epoch: 8 step: 363, loss is 7.56855879444629e-05\n",
      "epoch: 8 step: 364, loss is 0.0003593758156057447\n",
      "epoch: 8 step: 365, loss is 0.00015322522085625678\n",
      "epoch: 8 step: 366, loss is 0.00019583091489039361\n",
      "epoch: 8 step: 367, loss is 0.002531426725909114\n",
      "epoch: 8 step: 368, loss is 0.00010880903573706746\n",
      "epoch: 8 step: 369, loss is 0.021485352888703346\n",
      "epoch: 8 step: 370, loss is 0.009169208817183971\n",
      "epoch: 8 step: 371, loss is 0.03553974628448486\n",
      "epoch: 8 step: 372, loss is 0.0008370227878913283\n",
      "epoch: 8 step: 373, loss is 0.0014468120643869042\n",
      "epoch: 8 step: 374, loss is 0.008655398152768612\n",
      "epoch: 8 step: 375, loss is 6.755950016668066e-05\n",
      "epoch: 8 step: 376, loss is 0.009682412259280682\n",
      "epoch: 8 step: 377, loss is 0.059852343052625656\n",
      "epoch: 8 step: 378, loss is 0.00015683758829254657\n",
      "epoch: 8 step: 379, loss is 0.00016966258408501744\n",
      "epoch: 8 step: 380, loss is 0.0011478252708911896\n",
      "epoch: 8 step: 381, loss is 0.02702086605131626\n",
      "epoch: 8 step: 382, loss is 0.0002771978033706546\n",
      "epoch: 8 step: 383, loss is 0.0005114175146445632\n",
      "epoch: 8 step: 384, loss is 0.0006916309939697385\n",
      "epoch: 8 step: 385, loss is 0.05662676319479942\n",
      "epoch: 8 step: 386, loss is 5.164116373634897e-05\n",
      "epoch: 8 step: 387, loss is 0.01194625161588192\n",
      "epoch: 8 step: 388, loss is 0.14262710511684418\n",
      "epoch: 8 step: 389, loss is 0.03525066748261452\n",
      "epoch: 8 step: 390, loss is 0.00046269671292975545\n",
      "epoch: 8 step: 391, loss is 0.030198493972420692\n",
      "epoch: 8 step: 392, loss is 0.0012251856969669461\n",
      "epoch: 8 step: 393, loss is 0.030425235629081726\n",
      "epoch: 8 step: 394, loss is 0.00011834972974611446\n",
      "epoch: 8 step: 395, loss is 0.005009343847632408\n",
      "epoch: 8 step: 396, loss is 0.014727624133229256\n",
      "epoch: 8 step: 397, loss is 0.02834472432732582\n",
      "epoch: 8 step: 398, loss is 0.027836235240101814\n",
      "epoch: 8 step: 399, loss is 0.15690283477306366\n",
      "epoch: 8 step: 400, loss is 0.07577826827764511\n",
      "epoch: 8 step: 401, loss is 0.00025887993979267776\n",
      "epoch: 8 step: 402, loss is 0.00035108375595882535\n",
      "epoch: 8 step: 403, loss is 0.02284816838800907\n",
      "epoch: 8 step: 404, loss is 0.011576890014111996\n",
      "epoch: 8 step: 405, loss is 2.616273741296027e-05\n",
      "epoch: 8 step: 406, loss is 0.007403598167002201\n",
      "epoch: 8 step: 407, loss is 0.021836886182427406\n",
      "epoch: 8 step: 408, loss is 0.0052217342890799046\n",
      "epoch: 8 step: 409, loss is 0.000134432761115022\n",
      "epoch: 8 step: 410, loss is 0.0037308454047888517\n",
      "epoch: 8 step: 411, loss is 0.021793071180582047\n",
      "epoch: 8 step: 412, loss is 0.0026809212286025286\n",
      "epoch: 8 step: 413, loss is 6.161737110232934e-05\n",
      "epoch: 8 step: 414, loss is 0.017783857882022858\n",
      "epoch: 8 step: 415, loss is 0.02004983276128769\n",
      "epoch: 8 step: 416, loss is 0.003943985793739557\n",
      "epoch: 8 step: 417, loss is 8.877717482391745e-05\n",
      "epoch: 8 step: 418, loss is 0.022429607808589935\n",
      "epoch: 8 step: 419, loss is 0.0010394526179879904\n",
      "epoch: 8 step: 420, loss is 0.008979428559541702\n",
      "epoch: 8 step: 421, loss is 6.604212831007317e-05\n",
      "epoch: 8 step: 422, loss is 0.00022965186508372426\n",
      "epoch: 8 step: 423, loss is 0.00010805394413182512\n",
      "epoch: 8 step: 424, loss is 5.6982818932738155e-05\n",
      "epoch: 8 step: 425, loss is 0.0006575601873919368\n",
      "epoch: 8 step: 426, loss is 0.003106570802628994\n",
      "epoch: 8 step: 427, loss is 0.004842482972890139\n",
      "epoch: 8 step: 428, loss is 0.06148814409971237\n",
      "epoch: 8 step: 429, loss is 0.0009645906393416226\n",
      "epoch: 8 step: 430, loss is 0.0022162969689816236\n",
      "epoch: 8 step: 431, loss is 0.00034516630694270134\n",
      "epoch: 8 step: 432, loss is 0.0015203794464468956\n",
      "epoch: 8 step: 433, loss is 0.000907809124328196\n",
      "epoch: 8 step: 434, loss is 0.0001443181827198714\n",
      "epoch: 8 step: 435, loss is 0.004630551673471928\n",
      "epoch: 8 step: 436, loss is 0.0013102205703034997\n",
      "epoch: 8 step: 437, loss is 0.011102847754955292\n",
      "epoch: 8 step: 438, loss is 0.00014579507114831358\n",
      "epoch: 8 step: 439, loss is 0.0018693391466513276\n",
      "epoch: 8 step: 440, loss is 0.00457752263173461\n",
      "epoch: 8 step: 441, loss is 0.0013452998828142881\n",
      "epoch: 8 step: 442, loss is 0.024555476382374763\n",
      "epoch: 8 step: 443, loss is 0.06557755172252655\n",
      "epoch: 8 step: 444, loss is 0.001861400785855949\n",
      "epoch: 8 step: 445, loss is 0.002079422352835536\n",
      "epoch: 8 step: 446, loss is 0.0005756539758294821\n",
      "epoch: 8 step: 447, loss is 0.012950802221894264\n",
      "epoch: 8 step: 448, loss is 0.08404766768217087\n",
      "epoch: 8 step: 449, loss is 0.0007450111443176866\n",
      "epoch: 8 step: 450, loss is 0.029421266168355942\n",
      "epoch: 8 step: 451, loss is 4.6396631660172716e-05\n",
      "epoch: 8 step: 452, loss is 0.0930863693356514\n",
      "epoch: 8 step: 453, loss is 0.11476139724254608\n",
      "epoch: 8 step: 454, loss is 0.0007217660895548761\n",
      "epoch: 8 step: 455, loss is 0.00786906760185957\n",
      "epoch: 8 step: 456, loss is 0.006787961348891258\n",
      "epoch: 8 step: 457, loss is 2.465645047777798e-05\n",
      "epoch: 8 step: 458, loss is 1.488059206167236e-05\n",
      "epoch: 8 step: 459, loss is 0.0011182668386027217\n",
      "epoch: 8 step: 460, loss is 0.0008832509047351778\n",
      "epoch: 8 step: 461, loss is 0.0011815974721685052\n",
      "epoch: 8 step: 462, loss is 0.0026843238156288862\n",
      "epoch: 8 step: 463, loss is 0.0005930338520556688\n",
      "epoch: 8 step: 464, loss is 0.21225722134113312\n",
      "epoch: 8 step: 465, loss is 0.0029985939618200064\n",
      "epoch: 8 step: 466, loss is 0.002672862960025668\n",
      "epoch: 8 step: 467, loss is 0.0007866331725381315\n",
      "epoch: 8 step: 468, loss is 0.0023421174846589565\n",
      "epoch: 8 step: 469, loss is 0.022112756967544556\n",
      "epoch: 8 step: 470, loss is 0.024072807282209396\n",
      "epoch: 8 step: 471, loss is 0.12602336704730988\n",
      "epoch: 8 step: 472, loss is 0.04171755909919739\n",
      "epoch: 8 step: 473, loss is 0.0007493466255255044\n",
      "epoch: 8 step: 474, loss is 0.0008115482050925493\n",
      "epoch: 8 step: 475, loss is 0.00844328198581934\n",
      "epoch: 8 step: 476, loss is 0.0015659448690712452\n",
      "epoch: 8 step: 477, loss is 0.0009947593789547682\n",
      "epoch: 8 step: 478, loss is 0.007673508487641811\n",
      "epoch: 8 step: 479, loss is 0.00019865257490891963\n",
      "epoch: 8 step: 480, loss is 5.3375184506876394e-05\n",
      "epoch: 8 step: 481, loss is 0.00019833154510706663\n",
      "epoch: 8 step: 482, loss is 5.693347338819876e-05\n",
      "epoch: 8 step: 483, loss is 0.00543988449499011\n",
      "epoch: 8 step: 484, loss is 0.0001307093189097941\n",
      "epoch: 8 step: 485, loss is 0.0001933482853928581\n",
      "epoch: 8 step: 486, loss is 5.9142948884982616e-05\n",
      "epoch: 8 step: 487, loss is 0.0008071959600783885\n",
      "epoch: 8 step: 488, loss is 0.003569347085431218\n",
      "epoch: 8 step: 489, loss is 0.0004521263763308525\n",
      "epoch: 8 step: 490, loss is 0.032300688326358795\n",
      "epoch: 8 step: 491, loss is 0.0010002631461247802\n",
      "epoch: 8 step: 492, loss is 0.0006683104438707232\n",
      "epoch: 8 step: 493, loss is 0.14609433710575104\n",
      "epoch: 8 step: 494, loss is 0.0005851569003425539\n",
      "epoch: 8 step: 495, loss is 0.00013876601587980986\n",
      "epoch: 8 step: 496, loss is 0.00019616282952483743\n",
      "epoch: 8 step: 497, loss is 0.0007131180609576404\n",
      "epoch: 8 step: 498, loss is 0.00030692879226990044\n",
      "epoch: 8 step: 499, loss is 0.00023591105127707124\n",
      "epoch: 8 step: 500, loss is 0.0005937052774243057\n",
      "epoch: 8 step: 501, loss is 0.00036807404831051826\n",
      "epoch: 8 step: 502, loss is 0.0006060950108803809\n",
      "epoch: 8 step: 503, loss is 0.0015002931468188763\n",
      "epoch: 8 step: 504, loss is 0.028742708265781403\n",
      "epoch: 8 step: 505, loss is 0.025674041360616684\n",
      "epoch: 8 step: 506, loss is 3.417955304030329e-05\n",
      "epoch: 8 step: 507, loss is 0.0001273204543394968\n",
      "epoch: 8 step: 508, loss is 0.0028018420562148094\n",
      "epoch: 8 step: 509, loss is 0.00044387613888829947\n",
      "epoch: 8 step: 510, loss is 0.004199428018182516\n",
      "epoch: 8 step: 511, loss is 0.008784917183220387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 512, loss is 0.0005416267085820436\n",
      "epoch: 8 step: 513, loss is 0.00011538239778019488\n",
      "epoch: 8 step: 514, loss is 0.0004455014131963253\n",
      "epoch: 8 step: 515, loss is 0.0014924181159585714\n",
      "epoch: 8 step: 516, loss is 0.0007510001305490732\n",
      "epoch: 8 step: 517, loss is 0.0004983717808499932\n",
      "epoch: 8 step: 518, loss is 0.0005985167226754129\n",
      "epoch: 8 step: 519, loss is 0.0004652909410651773\n",
      "epoch: 8 step: 520, loss is 0.05327967181801796\n",
      "epoch: 8 step: 521, loss is 0.00022714851365890354\n",
      "epoch: 8 step: 522, loss is 0.17949610948562622\n",
      "epoch: 8 step: 523, loss is 0.00018114937120117247\n",
      "epoch: 8 step: 524, loss is 0.001790044130757451\n",
      "epoch: 8 step: 525, loss is 0.0003654437605291605\n",
      "epoch: 8 step: 526, loss is 0.004895065911114216\n",
      "epoch: 8 step: 527, loss is 0.0005781542859040201\n",
      "epoch: 8 step: 528, loss is 0.16183921694755554\n",
      "epoch: 8 step: 529, loss is 3.647348057711497e-05\n",
      "epoch: 8 step: 530, loss is 0.0007418525055982172\n",
      "epoch: 8 step: 531, loss is 0.0018482134910300374\n",
      "epoch: 8 step: 532, loss is 0.0005152184749022126\n",
      "epoch: 8 step: 533, loss is 0.006970476359128952\n",
      "epoch: 8 step: 534, loss is 0.00562044233083725\n",
      "epoch: 8 step: 535, loss is 0.008090421557426453\n",
      "epoch: 8 step: 536, loss is 0.0018259527860209346\n",
      "epoch: 8 step: 537, loss is 6.169560219859704e-05\n",
      "epoch: 8 step: 538, loss is 0.018867310136556625\n",
      "epoch: 8 step: 539, loss is 0.0011622103629633784\n",
      "epoch: 8 step: 540, loss is 0.0016938978806138039\n",
      "epoch: 8 step: 541, loss is 1.4657070096291136e-05\n",
      "epoch: 8 step: 542, loss is 0.0013068608241155744\n",
      "epoch: 8 step: 543, loss is 0.0015110421227291226\n",
      "epoch: 8 step: 544, loss is 1.7949307220987976e-05\n",
      "epoch: 8 step: 545, loss is 0.0013723064912483096\n",
      "epoch: 8 step: 546, loss is 0.14501895010471344\n",
      "epoch: 8 step: 547, loss is 0.008901138789951801\n",
      "epoch: 8 step: 548, loss is 0.0002781258663162589\n",
      "epoch: 8 step: 549, loss is 0.033127374947071075\n",
      "epoch: 8 step: 550, loss is 6.176235910970718e-05\n",
      "epoch: 8 step: 551, loss is 0.03955064341425896\n",
      "epoch: 8 step: 552, loss is 0.002226885175332427\n",
      "epoch: 8 step: 553, loss is 0.009273137897253036\n",
      "epoch: 8 step: 554, loss is 0.0006946967332623899\n",
      "epoch: 8 step: 555, loss is 0.0012588804820552468\n",
      "epoch: 8 step: 556, loss is 9.407941251993179e-05\n",
      "epoch: 8 step: 557, loss is 0.0016706936294212937\n",
      "epoch: 8 step: 558, loss is 0.0026880810037255287\n",
      "epoch: 8 step: 559, loss is 0.004399364348500967\n",
      "epoch: 8 step: 560, loss is 0.0004782517207786441\n",
      "epoch: 8 step: 561, loss is 0.0002319952182006091\n",
      "epoch: 8 step: 562, loss is 0.00029138123500160873\n",
      "epoch: 8 step: 563, loss is 0.024235382676124573\n",
      "epoch: 8 step: 564, loss is 0.00031259108800441027\n",
      "epoch: 8 step: 565, loss is 0.004718022886663675\n",
      "epoch: 8 step: 566, loss is 0.002227683551609516\n",
      "epoch: 8 step: 567, loss is 0.00013839629536960274\n",
      "epoch: 8 step: 568, loss is 0.00022816011914983392\n",
      "epoch: 8 step: 569, loss is 4.106776032131165e-05\n",
      "epoch: 8 step: 570, loss is 0.045239586383104324\n",
      "epoch: 8 step: 571, loss is 0.08577967435121536\n",
      "epoch: 8 step: 572, loss is 0.0011866475688293576\n",
      "epoch: 8 step: 573, loss is 7.118179928511381e-05\n",
      "epoch: 8 step: 574, loss is 3.2548534363741055e-05\n",
      "epoch: 8 step: 575, loss is 0.0012776731746271253\n",
      "epoch: 8 step: 576, loss is 0.0014113264624029398\n",
      "epoch: 8 step: 577, loss is 0.044823385775089264\n",
      "epoch: 8 step: 578, loss is 0.0029956207145005465\n",
      "epoch: 8 step: 579, loss is 0.011592474766075611\n",
      "epoch: 8 step: 580, loss is 0.002939879894256592\n",
      "epoch: 8 step: 581, loss is 0.00301212421618402\n",
      "epoch: 8 step: 582, loss is 2.0151363059994765e-05\n",
      "epoch: 8 step: 583, loss is 0.029612287878990173\n",
      "epoch: 8 step: 584, loss is 1.484606764279306e-05\n",
      "epoch: 8 step: 585, loss is 0.0006342869601212442\n",
      "epoch: 8 step: 586, loss is 0.06446195393800735\n",
      "epoch: 8 step: 587, loss is 2.342079642403405e-05\n",
      "epoch: 8 step: 588, loss is 0.0003447425551712513\n",
      "epoch: 8 step: 589, loss is 0.0021681920625269413\n",
      "epoch: 8 step: 590, loss is 0.04483605921268463\n",
      "epoch: 8 step: 591, loss is 0.00042057837708853185\n",
      "epoch: 8 step: 592, loss is 0.001277825445868075\n",
      "epoch: 8 step: 593, loss is 0.0003234910545870662\n",
      "epoch: 8 step: 594, loss is 0.01582050509750843\n",
      "epoch: 8 step: 595, loss is 0.006543116644024849\n",
      "epoch: 8 step: 596, loss is 0.012126710265874863\n",
      "epoch: 8 step: 597, loss is 2.570226206444204e-05\n",
      "epoch: 8 step: 598, loss is 0.008605992421507835\n",
      "epoch: 8 step: 599, loss is 0.08069824427366257\n",
      "epoch: 8 step: 600, loss is 0.000351336580934003\n",
      "epoch: 8 step: 601, loss is 0.00022269213513936847\n",
      "epoch: 8 step: 602, loss is 0.10414065420627594\n",
      "epoch: 8 step: 603, loss is 0.004205226898193359\n",
      "epoch: 8 step: 604, loss is 0.05042032524943352\n",
      "epoch: 8 step: 605, loss is 0.00010917239706031978\n",
      "epoch: 8 step: 606, loss is 0.0004055216850247234\n",
      "epoch: 8 step: 607, loss is 0.0038024834357202053\n",
      "epoch: 8 step: 608, loss is 0.0007549304282292724\n",
      "epoch: 8 step: 609, loss is 0.005479110404849052\n",
      "epoch: 8 step: 610, loss is 0.002441135933622718\n",
      "epoch: 8 step: 611, loss is 0.00010405842476757243\n",
      "epoch: 8 step: 612, loss is 1.2178187716926914e-05\n",
      "epoch: 8 step: 613, loss is 0.0024558398872613907\n",
      "epoch: 8 step: 614, loss is 0.002333234064280987\n",
      "epoch: 8 step: 615, loss is 0.007114325184375048\n",
      "epoch: 8 step: 616, loss is 0.003911025356501341\n",
      "epoch: 8 step: 617, loss is 0.028954608365893364\n",
      "epoch: 8 step: 618, loss is 0.011929584667086601\n",
      "epoch: 8 step: 619, loss is 0.0035426083486527205\n",
      "epoch: 8 step: 620, loss is 0.004603397101163864\n",
      "epoch: 8 step: 621, loss is 0.0282034520059824\n",
      "epoch: 8 step: 622, loss is 0.00020390914869494736\n",
      "epoch: 8 step: 623, loss is 0.00011148305929964408\n",
      "epoch: 8 step: 624, loss is 0.0013493600999936461\n",
      "epoch: 8 step: 625, loss is 0.0018014069646596909\n",
      "epoch: 8 step: 626, loss is 5.374311513151042e-05\n",
      "epoch: 8 step: 627, loss is 3.4488395613152534e-05\n",
      "epoch: 8 step: 628, loss is 0.0002629940863698721\n",
      "epoch: 8 step: 629, loss is 0.0021769495215266943\n",
      "epoch: 8 step: 630, loss is 0.0021343636326491833\n",
      "epoch: 8 step: 631, loss is 0.003314570290967822\n",
      "epoch: 8 step: 632, loss is 0.00509754940867424\n",
      "epoch: 8 step: 633, loss is 0.00028237735386937857\n",
      "epoch: 8 step: 634, loss is 0.0032107001170516014\n",
      "epoch: 8 step: 635, loss is 0.00010010013647843152\n",
      "epoch: 8 step: 636, loss is 0.0013263407163321972\n",
      "epoch: 8 step: 637, loss is 0.029015500098466873\n",
      "epoch: 8 step: 638, loss is 0.0006079670856706798\n",
      "epoch: 8 step: 639, loss is 0.0001837881573010236\n",
      "epoch: 8 step: 640, loss is 0.0064750243909657\n",
      "epoch: 8 step: 641, loss is 0.0003265506820753217\n",
      "epoch: 8 step: 642, loss is 0.0006369954789988697\n",
      "epoch: 8 step: 643, loss is 0.05775807052850723\n",
      "epoch: 8 step: 644, loss is 0.000483921030536294\n",
      "epoch: 8 step: 645, loss is 2.557018888182938e-05\n",
      "epoch: 8 step: 646, loss is 0.01133598480373621\n",
      "epoch: 8 step: 647, loss is 0.02999134175479412\n",
      "epoch: 8 step: 648, loss is 0.225240096449852\n",
      "epoch: 8 step: 649, loss is 0.0027164118364453316\n",
      "epoch: 8 step: 650, loss is 0.00870048813521862\n",
      "epoch: 8 step: 651, loss is 0.0012778474483639002\n",
      "epoch: 8 step: 652, loss is 0.008310445584356785\n",
      "epoch: 8 step: 653, loss is 0.024873897433280945\n",
      "epoch: 8 step: 654, loss is 0.03563948720693588\n",
      "epoch: 8 step: 655, loss is 0.02443542890250683\n",
      "epoch: 8 step: 656, loss is 0.01993316225707531\n",
      "epoch: 8 step: 657, loss is 0.007954392582178116\n",
      "epoch: 8 step: 658, loss is 0.0011098869144916534\n",
      "epoch: 8 step: 659, loss is 0.0012320487294346094\n",
      "epoch: 8 step: 660, loss is 0.04524281620979309\n",
      "epoch: 8 step: 661, loss is 0.1108514815568924\n",
      "epoch: 8 step: 662, loss is 0.0015444016316905618\n",
      "epoch: 8 step: 663, loss is 0.06452395766973495\n",
      "epoch: 8 step: 664, loss is 0.002857300452888012\n",
      "epoch: 8 step: 665, loss is 0.0059523629024624825\n",
      "epoch: 8 step: 666, loss is 0.017344282940030098\n",
      "epoch: 8 step: 667, loss is 0.000277823448413983\n",
      "epoch: 8 step: 668, loss is 0.03460998088121414\n",
      "epoch: 8 step: 669, loss is 0.004557638429105282\n",
      "epoch: 8 step: 670, loss is 0.13709399104118347\n",
      "epoch: 8 step: 671, loss is 0.00028817515703849494\n",
      "epoch: 8 step: 672, loss is 0.00930957030504942\n",
      "epoch: 8 step: 673, loss is 0.006289994809776545\n",
      "epoch: 8 step: 674, loss is 0.0012178056640550494\n",
      "epoch: 8 step: 675, loss is 0.001136390259489417\n",
      "epoch: 8 step: 676, loss is 0.010134227573871613\n",
      "epoch: 8 step: 677, loss is 0.002340895589441061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 678, loss is 0.001032415428198874\n",
      "epoch: 8 step: 679, loss is 0.000164903758559376\n",
      "epoch: 8 step: 680, loss is 0.0202624648809433\n",
      "epoch: 8 step: 681, loss is 0.0016020287293940783\n",
      "epoch: 8 step: 682, loss is 0.004471154417842627\n",
      "epoch: 8 step: 683, loss is 0.0018749407026916742\n",
      "epoch: 8 step: 684, loss is 0.001005938625894487\n",
      "epoch: 8 step: 685, loss is 0.0002189358347095549\n",
      "epoch: 8 step: 686, loss is 0.0004134728806093335\n",
      "epoch: 8 step: 687, loss is 0.016745340079069138\n",
      "epoch: 8 step: 688, loss is 0.0025624968111515045\n",
      "epoch: 8 step: 689, loss is 0.021294889971613884\n",
      "epoch: 8 step: 690, loss is 0.014784155413508415\n",
      "epoch: 8 step: 691, loss is 0.026844263076782227\n",
      "epoch: 8 step: 692, loss is 0.00040574936429038644\n",
      "epoch: 8 step: 693, loss is 0.15455006062984467\n",
      "epoch: 8 step: 694, loss is 0.015398794785141945\n",
      "epoch: 8 step: 695, loss is 0.0001338236907031387\n",
      "epoch: 8 step: 696, loss is 0.18258036673069\n",
      "epoch: 8 step: 697, loss is 0.0015680575743317604\n",
      "epoch: 8 step: 698, loss is 0.003203943371772766\n",
      "epoch: 8 step: 699, loss is 0.00018153036944568157\n",
      "epoch: 8 step: 700, loss is 0.013756792061030865\n",
      "epoch: 8 step: 701, loss is 0.010721063241362572\n",
      "epoch: 8 step: 702, loss is 0.0014261725591495633\n",
      "epoch: 8 step: 703, loss is 0.0022275119554251432\n",
      "epoch: 8 step: 704, loss is 0.011613478884100914\n",
      "epoch: 8 step: 705, loss is 0.004547514952719212\n",
      "epoch: 8 step: 706, loss is 0.049956176429986954\n",
      "epoch: 8 step: 707, loss is 0.002305363304913044\n",
      "epoch: 8 step: 708, loss is 0.0007915805908851326\n",
      "epoch: 8 step: 709, loss is 1.9359100406290963e-05\n",
      "epoch: 8 step: 710, loss is 0.04051557928323746\n",
      "epoch: 8 step: 711, loss is 0.00011179139983141795\n",
      "epoch: 8 step: 712, loss is 0.004311090335249901\n",
      "epoch: 8 step: 713, loss is 0.043458156287670135\n",
      "epoch: 8 step: 714, loss is 0.04747198894619942\n",
      "epoch: 8 step: 715, loss is 0.005319759249687195\n",
      "epoch: 8 step: 716, loss is 3.00911287922645e-05\n",
      "epoch: 8 step: 717, loss is 0.0002582663728389889\n",
      "epoch: 8 step: 718, loss is 0.00838708970695734\n",
      "epoch: 8 step: 719, loss is 0.035911716520786285\n",
      "epoch: 8 step: 720, loss is 0.04312049597501755\n",
      "epoch: 8 step: 721, loss is 0.00014206659398041666\n",
      "epoch: 8 step: 722, loss is 0.0035740940365940332\n",
      "epoch: 8 step: 723, loss is 0.0004443861835170537\n",
      "epoch: 8 step: 724, loss is 0.128604918718338\n",
      "epoch: 8 step: 725, loss is 0.004001281689852476\n",
      "epoch: 8 step: 726, loss is 0.02022925578057766\n",
      "epoch: 8 step: 727, loss is 0.0008768748957663774\n",
      "epoch: 8 step: 728, loss is 0.026286287233233452\n",
      "epoch: 8 step: 729, loss is 0.08998900651931763\n",
      "epoch: 8 step: 730, loss is 0.00036639306927099824\n",
      "epoch: 8 step: 731, loss is 0.0011821474181488156\n",
      "epoch: 8 step: 732, loss is 0.0003058590227738023\n",
      "epoch: 8 step: 733, loss is 0.0030664848163723946\n",
      "epoch: 8 step: 734, loss is 0.0007946843979880214\n",
      "epoch: 8 step: 735, loss is 0.0005097967805340886\n",
      "epoch: 8 step: 736, loss is 0.004983533639460802\n",
      "epoch: 8 step: 737, loss is 0.0019270055927336216\n",
      "epoch: 8 step: 738, loss is 0.000374599767383188\n",
      "epoch: 8 step: 739, loss is 0.015539517626166344\n",
      "epoch: 8 step: 740, loss is 0.0005797048797830939\n",
      "epoch: 8 step: 741, loss is 0.0016531440196558833\n",
      "epoch: 8 step: 742, loss is 0.0051830243319272995\n",
      "epoch: 8 step: 743, loss is 0.008702351711690426\n",
      "epoch: 8 step: 744, loss is 0.0014050949830561876\n",
      "epoch: 8 step: 745, loss is 0.0017545769223943353\n",
      "epoch: 8 step: 746, loss is 0.0018435767851769924\n",
      "epoch: 8 step: 747, loss is 0.09497907012701035\n",
      "epoch: 8 step: 748, loss is 1.26499780890299e-05\n",
      "epoch: 8 step: 749, loss is 1.607380181667395e-05\n",
      "epoch: 8 step: 750, loss is 3.517710501910187e-05\n",
      "epoch: 8 step: 751, loss is 0.0056634461507201195\n",
      "epoch: 8 step: 752, loss is 3.327745071146637e-05\n",
      "epoch: 8 step: 753, loss is 0.002901341300457716\n",
      "epoch: 8 step: 754, loss is 0.03858962282538414\n",
      "epoch: 8 step: 755, loss is 0.02335342951118946\n",
      "epoch: 8 step: 756, loss is 3.6276418541092426e-05\n",
      "epoch: 8 step: 757, loss is 0.0002074476651614532\n",
      "epoch: 8 step: 758, loss is 0.03190405294299126\n",
      "epoch: 8 step: 759, loss is 0.001431833254173398\n",
      "epoch: 8 step: 760, loss is 0.07977207005023956\n",
      "epoch: 8 step: 761, loss is 0.3963581323623657\n",
      "epoch: 8 step: 762, loss is 0.0006247645360417664\n",
      "epoch: 8 step: 763, loss is 0.03761782869696617\n",
      "epoch: 8 step: 764, loss is 0.0005305572412908077\n",
      "epoch: 8 step: 765, loss is 0.0032083638943731785\n",
      "epoch: 8 step: 766, loss is 2.8991244107601233e-05\n",
      "epoch: 8 step: 767, loss is 0.0001400792971253395\n",
      "epoch: 8 step: 768, loss is 0.009437919594347477\n",
      "epoch: 8 step: 769, loss is 4.553280450636521e-05\n",
      "epoch: 8 step: 770, loss is 0.05010466277599335\n",
      "epoch: 8 step: 771, loss is 0.004711522255092859\n",
      "epoch: 8 step: 772, loss is 0.0298033207654953\n",
      "epoch: 8 step: 773, loss is 0.0015624985098838806\n",
      "epoch: 8 step: 774, loss is 0.016866691410541534\n",
      "epoch: 8 step: 775, loss is 0.0001279526186408475\n",
      "epoch: 8 step: 776, loss is 0.0008455445058643818\n",
      "epoch: 8 step: 777, loss is 0.0064590079709887505\n",
      "epoch: 8 step: 778, loss is 0.013614383526146412\n",
      "epoch: 8 step: 779, loss is 0.0007012846763245761\n",
      "epoch: 8 step: 780, loss is 0.00022564016398973763\n",
      "epoch: 8 step: 781, loss is 0.0004883286892436445\n",
      "epoch: 8 step: 782, loss is 0.11525674909353256\n",
      "epoch: 8 step: 783, loss is 0.00020732042321469635\n",
      "epoch: 8 step: 784, loss is 0.0044632903300225735\n",
      "epoch: 8 step: 785, loss is 0.029846342280507088\n",
      "epoch: 8 step: 786, loss is 0.0010975339682772756\n",
      "epoch: 8 step: 787, loss is 0.02122039534151554\n",
      "epoch: 8 step: 788, loss is 0.01121280062943697\n",
      "epoch: 8 step: 789, loss is 0.0007786979549564421\n",
      "epoch: 8 step: 790, loss is 0.0006520913448184729\n",
      "epoch: 8 step: 791, loss is 0.003511400194838643\n",
      "epoch: 8 step: 792, loss is 0.06710952520370483\n",
      "epoch: 8 step: 793, loss is 0.10334508866071701\n",
      "epoch: 8 step: 794, loss is 0.0015449144411832094\n",
      "epoch: 8 step: 795, loss is 0.00012576307926792651\n",
      "epoch: 8 step: 796, loss is 0.0015897051198408008\n",
      "epoch: 8 step: 797, loss is 0.00030724878888577223\n",
      "epoch: 8 step: 798, loss is 0.005128607153892517\n",
      "epoch: 8 step: 799, loss is 0.0015836161328479648\n",
      "epoch: 8 step: 800, loss is 0.00028693178319372237\n",
      "epoch: 8 step: 801, loss is 0.003490957897156477\n",
      "epoch: 8 step: 802, loss is 0.01383853517472744\n",
      "epoch: 8 step: 803, loss is 0.022084984928369522\n",
      "epoch: 8 step: 804, loss is 0.0056602442637085915\n",
      "epoch: 8 step: 805, loss is 0.0040279473178088665\n",
      "epoch: 8 step: 806, loss is 0.016866156831383705\n",
      "epoch: 8 step: 807, loss is 0.006919072475284338\n",
      "epoch: 8 step: 808, loss is 0.000282308115856722\n",
      "epoch: 8 step: 809, loss is 0.0002607974165584892\n",
      "epoch: 8 step: 810, loss is 0.0329296737909317\n",
      "epoch: 8 step: 811, loss is 0.0008778364863246679\n",
      "epoch: 8 step: 812, loss is 0.01453995518386364\n",
      "epoch: 8 step: 813, loss is 3.6172230466036126e-05\n",
      "epoch: 8 step: 814, loss is 0.0014442183310166001\n",
      "epoch: 8 step: 815, loss is 0.00479560112580657\n",
      "epoch: 8 step: 816, loss is 0.0017828821437433362\n",
      "epoch: 8 step: 817, loss is 0.0020455578342080116\n",
      "epoch: 8 step: 818, loss is 0.0006127202068455517\n",
      "epoch: 8 step: 819, loss is 0.0008947974420152605\n",
      "epoch: 8 step: 820, loss is 0.0017867062706500292\n",
      "epoch: 8 step: 821, loss is 5.8834713854594156e-05\n",
      "epoch: 8 step: 822, loss is 0.00856858491897583\n",
      "epoch: 8 step: 823, loss is 0.0005181743181310594\n",
      "epoch: 8 step: 824, loss is 0.06155087426304817\n",
      "epoch: 8 step: 825, loss is 0.00020940173999406397\n",
      "epoch: 8 step: 826, loss is 9.786442387849092e-05\n",
      "epoch: 8 step: 827, loss is 0.015971163287758827\n",
      "epoch: 8 step: 828, loss is 0.0036279873456805944\n",
      "epoch: 8 step: 829, loss is 0.002361526247113943\n",
      "epoch: 8 step: 830, loss is 0.00042037415551021695\n",
      "epoch: 8 step: 831, loss is 9.112266707234085e-05\n",
      "epoch: 8 step: 832, loss is 0.2998071312904358\n",
      "epoch: 8 step: 833, loss is 0.00024043049779720604\n",
      "epoch: 8 step: 834, loss is 0.01494247280061245\n",
      "epoch: 8 step: 835, loss is 0.001572406617924571\n",
      "epoch: 8 step: 836, loss is 0.003300057491287589\n",
      "epoch: 8 step: 837, loss is 0.0008029788732528687\n",
      "epoch: 8 step: 838, loss is 0.0005436659557744861\n",
      "epoch: 8 step: 839, loss is 0.0009742443799041212\n",
      "epoch: 8 step: 840, loss is 0.0009597837342880666\n",
      "epoch: 8 step: 841, loss is 0.0002358839410590008\n",
      "epoch: 8 step: 842, loss is 9.559475984133314e-06\n",
      "epoch: 8 step: 843, loss is 0.0012171247508376837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 844, loss is 0.001124922069720924\n",
      "epoch: 8 step: 845, loss is 3.673957326100208e-05\n",
      "epoch: 8 step: 846, loss is 0.0006723101832903922\n",
      "epoch: 8 step: 847, loss is 0.007218648679554462\n",
      "epoch: 8 step: 848, loss is 0.02145770937204361\n",
      "epoch: 8 step: 849, loss is 0.0003527496592141688\n",
      "epoch: 8 step: 850, loss is 0.0002095987874781713\n",
      "epoch: 8 step: 851, loss is 0.0002215788117609918\n",
      "epoch: 8 step: 852, loss is 0.002883374923840165\n",
      "epoch: 8 step: 853, loss is 0.0005168019561097026\n",
      "epoch: 8 step: 854, loss is 0.0009838740807026625\n",
      "epoch: 8 step: 855, loss is 0.016671955585479736\n",
      "epoch: 8 step: 856, loss is 0.0002784340758807957\n",
      "epoch: 8 step: 857, loss is 0.0007298945565707982\n",
      "epoch: 8 step: 858, loss is 0.0006859026616439223\n",
      "epoch: 8 step: 859, loss is 0.000570396485272795\n",
      "epoch: 8 step: 860, loss is 0.0021902944426983595\n",
      "epoch: 8 step: 861, loss is 0.020568756386637688\n",
      "epoch: 8 step: 862, loss is 0.004018763080239296\n",
      "epoch: 8 step: 863, loss is 0.001313340268097818\n",
      "epoch: 8 step: 864, loss is 0.004745289217680693\n",
      "epoch: 8 step: 865, loss is 0.002229016739875078\n",
      "epoch: 8 step: 866, loss is 0.013205011375248432\n",
      "epoch: 8 step: 867, loss is 0.018744448199868202\n",
      "epoch: 8 step: 868, loss is 0.03666238114237785\n",
      "epoch: 8 step: 869, loss is 0.0004068140115123242\n",
      "epoch: 8 step: 870, loss is 0.0005382278468459845\n",
      "epoch: 8 step: 871, loss is 0.002317794831469655\n",
      "epoch: 8 step: 872, loss is 0.00018262374214828014\n",
      "epoch: 8 step: 873, loss is 0.0008238137234002352\n",
      "epoch: 8 step: 874, loss is 0.00029319876921363175\n",
      "epoch: 8 step: 875, loss is 0.00031503697391599417\n",
      "epoch: 8 step: 876, loss is 0.006506155710667372\n",
      "epoch: 8 step: 877, loss is 0.01144635770469904\n",
      "epoch: 8 step: 878, loss is 0.00010385294444859028\n",
      "epoch: 8 step: 879, loss is 0.0015587140806019306\n",
      "epoch: 8 step: 880, loss is 0.011569689027965069\n",
      "epoch: 8 step: 881, loss is 0.000966015039011836\n",
      "epoch: 8 step: 882, loss is 0.0009449158678762615\n",
      "epoch: 8 step: 883, loss is 0.04217524826526642\n",
      "epoch: 8 step: 884, loss is 0.018483899533748627\n",
      "epoch: 8 step: 885, loss is 0.03759950399398804\n",
      "epoch: 8 step: 886, loss is 0.00046496433787979186\n",
      "epoch: 8 step: 887, loss is 0.0004319261643104255\n",
      "epoch: 8 step: 888, loss is 0.002067518886178732\n",
      "epoch: 8 step: 889, loss is 0.0010592289036139846\n",
      "epoch: 8 step: 890, loss is 0.0008744957740418613\n",
      "epoch: 8 step: 891, loss is 0.14145104587078094\n",
      "epoch: 8 step: 892, loss is 0.046515949070453644\n",
      "epoch: 8 step: 893, loss is 0.00013187696458771825\n",
      "epoch: 8 step: 894, loss is 0.041636377573013306\n",
      "epoch: 8 step: 895, loss is 0.000949245470110327\n",
      "epoch: 8 step: 896, loss is 0.0010270520579069853\n",
      "epoch: 8 step: 897, loss is 8.69761934154667e-05\n",
      "epoch: 8 step: 898, loss is 2.787664925563149e-05\n",
      "epoch: 8 step: 899, loss is 0.000697474111802876\n",
      "epoch: 8 step: 900, loss is 0.001083806506358087\n",
      "epoch: 8 step: 901, loss is 0.002529577352106571\n",
      "epoch: 8 step: 902, loss is 0.005243949592113495\n",
      "epoch: 8 step: 903, loss is 0.03262842819094658\n",
      "epoch: 8 step: 904, loss is 0.0006604810478165746\n",
      "epoch: 8 step: 905, loss is 0.002736868569627404\n",
      "epoch: 8 step: 906, loss is 0.006974149961024523\n",
      "epoch: 8 step: 907, loss is 0.008794079534709454\n",
      "epoch: 8 step: 908, loss is 0.011122282594442368\n",
      "epoch: 8 step: 909, loss is 0.0029670498333871365\n",
      "epoch: 8 step: 910, loss is 0.026827573776245117\n",
      "epoch: 8 step: 911, loss is 0.004052160307765007\n",
      "epoch: 8 step: 912, loss is 0.001562547986395657\n",
      "epoch: 8 step: 913, loss is 0.0004758185241371393\n",
      "epoch: 8 step: 914, loss is 0.004460613243281841\n",
      "epoch: 8 step: 915, loss is 0.0026568882167339325\n",
      "epoch: 8 step: 916, loss is 2.5485420337645337e-05\n",
      "epoch: 8 step: 917, loss is 0.02378096431493759\n",
      "epoch: 8 step: 918, loss is 0.00048769445857033134\n",
      "epoch: 8 step: 919, loss is 1.343768963124603e-05\n",
      "epoch: 8 step: 920, loss is 0.00139104132540524\n",
      "epoch: 8 step: 921, loss is 0.0007234200602397323\n",
      "epoch: 8 step: 922, loss is 0.01316626276820898\n",
      "epoch: 8 step: 923, loss is 0.0010670260526239872\n",
      "epoch: 8 step: 924, loss is 0.0002488777390681207\n",
      "epoch: 8 step: 925, loss is 7.231289055198431e-05\n",
      "epoch: 8 step: 926, loss is 0.004313280805945396\n",
      "epoch: 8 step: 927, loss is 0.0001937485212692991\n",
      "epoch: 8 step: 928, loss is 0.061596594750881195\n",
      "epoch: 8 step: 929, loss is 0.04672407731413841\n",
      "epoch: 8 step: 930, loss is 0.001136367442086339\n",
      "epoch: 8 step: 931, loss is 2.3532846171292476e-05\n",
      "epoch: 8 step: 932, loss is 1.8442404325469397e-05\n",
      "epoch: 8 step: 933, loss is 0.00011021528916899115\n",
      "epoch: 8 step: 934, loss is 0.00010552319145062938\n",
      "epoch: 8 step: 935, loss is 0.004750832915306091\n",
      "epoch: 8 step: 936, loss is 0.0015178238973021507\n",
      "epoch: 8 step: 937, loss is 0.0006454206886701286\n",
      "epoch: 8 step: 938, loss is 0.0035538850352168083\n",
      "epoch: 8 step: 939, loss is 0.00023685167252551764\n",
      "epoch: 8 step: 940, loss is 1.256606810784433e-05\n",
      "epoch: 8 step: 941, loss is 0.004170401953160763\n",
      "epoch: 8 step: 942, loss is 0.00012818380491808057\n",
      "epoch: 8 step: 943, loss is 8.575200627092272e-05\n",
      "epoch: 8 step: 944, loss is 0.0005990869831293821\n",
      "epoch: 8 step: 945, loss is 0.005915616173297167\n",
      "epoch: 8 step: 946, loss is 0.006614784710109234\n",
      "epoch: 8 step: 947, loss is 0.00039756399928592145\n",
      "epoch: 8 step: 948, loss is 0.007050621788948774\n",
      "epoch: 8 step: 949, loss is 0.0007095211767591536\n",
      "epoch: 8 step: 950, loss is 0.0031525546219199896\n",
      "epoch: 8 step: 951, loss is 0.013875750824809074\n",
      "epoch: 8 step: 952, loss is 0.0009074939298443496\n",
      "epoch: 8 step: 953, loss is 0.041933994740247726\n",
      "epoch: 8 step: 954, loss is 0.0951457992196083\n",
      "epoch: 8 step: 955, loss is 0.0001399737666361034\n",
      "epoch: 8 step: 956, loss is 6.025655966368504e-05\n",
      "epoch: 8 step: 957, loss is 6.187721010064706e-05\n",
      "epoch: 8 step: 958, loss is 0.006973057519644499\n",
      "epoch: 8 step: 959, loss is 0.0006942644831724465\n",
      "epoch: 8 step: 960, loss is 0.035455234348773956\n",
      "epoch: 8 step: 961, loss is 0.0005297248135320842\n",
      "epoch: 8 step: 962, loss is 0.003199429716914892\n",
      "epoch: 8 step: 963, loss is 0.005666566547006369\n",
      "epoch: 8 step: 964, loss is 0.05054374784231186\n",
      "epoch: 8 step: 965, loss is 0.0001363275951007381\n",
      "epoch: 8 step: 966, loss is 0.026740679517388344\n",
      "epoch: 8 step: 967, loss is 0.001282577170059085\n",
      "epoch: 8 step: 968, loss is 0.0013023565988987684\n",
      "epoch: 8 step: 969, loss is 0.0004717429983429611\n",
      "epoch: 8 step: 970, loss is 0.0004800434107892215\n",
      "epoch: 8 step: 971, loss is 0.020803725346922874\n",
      "epoch: 8 step: 972, loss is 0.007678702939301729\n",
      "epoch: 8 step: 973, loss is 0.006812207400798798\n",
      "epoch: 8 step: 974, loss is 0.010572613216936588\n",
      "epoch: 8 step: 975, loss is 0.0005385751719586551\n",
      "epoch: 8 step: 976, loss is 0.00010198956442764029\n",
      "epoch: 8 step: 977, loss is 0.04530663788318634\n",
      "epoch: 8 step: 978, loss is 0.029883544892072678\n",
      "epoch: 8 step: 979, loss is 7.025171362329274e-05\n",
      "epoch: 8 step: 980, loss is 0.004343478940427303\n",
      "epoch: 8 step: 981, loss is 0.00012449690257199109\n",
      "epoch: 8 step: 982, loss is 0.011477399617433548\n",
      "epoch: 8 step: 983, loss is 0.002576851285994053\n",
      "epoch: 8 step: 984, loss is 4.606604125001468e-05\n",
      "epoch: 8 step: 985, loss is 0.0005995727842673659\n",
      "epoch: 8 step: 986, loss is 0.0011609685607254505\n",
      "epoch: 8 step: 987, loss is 9.199681517202407e-05\n",
      "epoch: 8 step: 988, loss is 0.00264900759793818\n",
      "epoch: 8 step: 989, loss is 0.00013719355047214776\n",
      "epoch: 8 step: 990, loss is 0.05319187790155411\n",
      "epoch: 8 step: 991, loss is 0.15554414689540863\n",
      "epoch: 8 step: 992, loss is 0.0006721823592670262\n",
      "epoch: 8 step: 993, loss is 0.0006982546183280647\n",
      "epoch: 8 step: 994, loss is 0.040103502571582794\n",
      "epoch: 8 step: 995, loss is 0.03279245272278786\n",
      "epoch: 8 step: 996, loss is 0.01767566241323948\n",
      "epoch: 8 step: 997, loss is 8.671466639498249e-05\n",
      "epoch: 8 step: 998, loss is 0.0017598140984773636\n",
      "epoch: 8 step: 999, loss is 6.86902494635433e-05\n",
      "epoch: 8 step: 1000, loss is 0.013494503684341908\n",
      "epoch: 8 step: 1001, loss is 0.0641169473528862\n",
      "epoch: 8 step: 1002, loss is 0.0013784072361886501\n",
      "epoch: 8 step: 1003, loss is 0.015297257341444492\n",
      "epoch: 8 step: 1004, loss is 0.0013978355564177036\n",
      "epoch: 8 step: 1005, loss is 9.110283281188458e-05\n",
      "epoch: 8 step: 1006, loss is 0.0006810600752942264\n",
      "epoch: 8 step: 1007, loss is 0.08603692054748535\n",
      "epoch: 8 step: 1008, loss is 0.0010118166683241725\n",
      "epoch: 8 step: 1009, loss is 0.00019252525817137212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1010, loss is 0.0045953113585710526\n",
      "epoch: 8 step: 1011, loss is 0.00018064389587379992\n",
      "epoch: 8 step: 1012, loss is 0.003970050252974033\n",
      "epoch: 8 step: 1013, loss is 0.0024061379954218864\n",
      "epoch: 8 step: 1014, loss is 0.003563348203897476\n",
      "epoch: 8 step: 1015, loss is 0.0003432838711887598\n",
      "epoch: 8 step: 1016, loss is 0.0023368571419268847\n",
      "epoch: 8 step: 1017, loss is 5.743365181842819e-05\n",
      "epoch: 8 step: 1018, loss is 0.020143119618296623\n",
      "epoch: 8 step: 1019, loss is 0.02374587580561638\n",
      "epoch: 8 step: 1020, loss is 0.007163024973124266\n",
      "epoch: 8 step: 1021, loss is 0.001068406505510211\n",
      "epoch: 8 step: 1022, loss is 0.00020304019562900066\n",
      "epoch: 8 step: 1023, loss is 0.029654335230588913\n",
      "epoch: 8 step: 1024, loss is 0.007417287211865187\n",
      "epoch: 8 step: 1025, loss is 0.003856611903756857\n",
      "epoch: 8 step: 1026, loss is 0.003000440075993538\n",
      "epoch: 8 step: 1027, loss is 0.001040649600327015\n",
      "epoch: 8 step: 1028, loss is 2.6467390853213146e-05\n",
      "epoch: 8 step: 1029, loss is 0.017938975244760513\n",
      "epoch: 8 step: 1030, loss is 0.015757374465465546\n",
      "epoch: 8 step: 1031, loss is 0.003972445148974657\n",
      "epoch: 8 step: 1032, loss is 0.0005040945252403617\n",
      "epoch: 8 step: 1033, loss is 0.0005740039050579071\n",
      "epoch: 8 step: 1034, loss is 0.016399823129177094\n",
      "epoch: 8 step: 1035, loss is 0.0002820098015945405\n",
      "epoch: 8 step: 1036, loss is 1.7839911379269324e-05\n",
      "epoch: 8 step: 1037, loss is 0.0009415800450369716\n",
      "epoch: 8 step: 1038, loss is 2.371976188442204e-05\n",
      "epoch: 8 step: 1039, loss is 0.09953181445598602\n",
      "epoch: 8 step: 1040, loss is 0.0004896938917227089\n",
      "epoch: 8 step: 1041, loss is 0.0005571848596446216\n",
      "epoch: 8 step: 1042, loss is 6.070623567211442e-05\n",
      "epoch: 8 step: 1043, loss is 0.0010053830919787288\n",
      "epoch: 8 step: 1044, loss is 4.666984750656411e-05\n",
      "epoch: 8 step: 1045, loss is 0.0022827687207609415\n",
      "epoch: 8 step: 1046, loss is 0.10246162861585617\n",
      "epoch: 8 step: 1047, loss is 0.011290617287158966\n",
      "epoch: 8 step: 1048, loss is 0.00017559799016453326\n",
      "epoch: 8 step: 1049, loss is 4.910684947390109e-05\n",
      "epoch: 8 step: 1050, loss is 0.019750211387872696\n",
      "epoch: 8 step: 1051, loss is 6.624742673011497e-05\n",
      "epoch: 8 step: 1052, loss is 0.0001548391446704045\n",
      "epoch: 8 step: 1053, loss is 0.0029742131009697914\n",
      "epoch: 8 step: 1054, loss is 0.0011217562714591622\n",
      "epoch: 8 step: 1055, loss is 0.0001523991668364033\n",
      "epoch: 8 step: 1056, loss is 0.010323545895516872\n",
      "epoch: 8 step: 1057, loss is 0.005922026466578245\n",
      "epoch: 8 step: 1058, loss is 8.154031092999503e-05\n",
      "epoch: 8 step: 1059, loss is 3.438097701291554e-05\n",
      "epoch: 8 step: 1060, loss is 0.00022717792307958007\n",
      "epoch: 8 step: 1061, loss is 0.02298928052186966\n",
      "epoch: 8 step: 1062, loss is 2.7925445465371013e-05\n",
      "epoch: 8 step: 1063, loss is 0.0642201155424118\n",
      "epoch: 8 step: 1064, loss is 0.129720076918602\n",
      "epoch: 8 step: 1065, loss is 0.0025189598090946674\n",
      "epoch: 8 step: 1066, loss is 0.0003279020602349192\n",
      "epoch: 8 step: 1067, loss is 0.004428402055054903\n",
      "epoch: 8 step: 1068, loss is 0.109523244202137\n",
      "epoch: 8 step: 1069, loss is 0.0004937451449222863\n",
      "epoch: 8 step: 1070, loss is 0.002319700550287962\n",
      "epoch: 8 step: 1071, loss is 0.0055891587398946285\n",
      "epoch: 8 step: 1072, loss is 0.0015313121257349849\n",
      "epoch: 8 step: 1073, loss is 0.0007345627527683973\n",
      "epoch: 8 step: 1074, loss is 0.07709664106369019\n",
      "epoch: 8 step: 1075, loss is 0.09928859025239944\n",
      "epoch: 8 step: 1076, loss is 0.004576100967824459\n",
      "epoch: 8 step: 1077, loss is 0.004736755043268204\n",
      "epoch: 8 step: 1078, loss is 0.0003040646843146533\n",
      "epoch: 8 step: 1079, loss is 0.002274692989885807\n",
      "epoch: 8 step: 1080, loss is 0.002503078430891037\n",
      "epoch: 8 step: 1081, loss is 0.0385943278670311\n",
      "epoch: 8 step: 1082, loss is 0.0015859416453167796\n",
      "epoch: 8 step: 1083, loss is 0.009948979131877422\n",
      "epoch: 8 step: 1084, loss is 0.00046178611228242517\n",
      "epoch: 8 step: 1085, loss is 0.0011817271588370204\n",
      "epoch: 8 step: 1086, loss is 0.03904679790139198\n",
      "epoch: 8 step: 1087, loss is 0.0003667044220492244\n",
      "epoch: 8 step: 1088, loss is 0.000299211562378332\n",
      "epoch: 8 step: 1089, loss is 3.745837966562249e-05\n",
      "epoch: 8 step: 1090, loss is 0.0010476295137777925\n",
      "epoch: 8 step: 1091, loss is 0.0017928655724972486\n",
      "epoch: 8 step: 1092, loss is 0.00446697324514389\n",
      "epoch: 8 step: 1093, loss is 0.00027456250973045826\n",
      "epoch: 8 step: 1094, loss is 0.005826752632856369\n",
      "epoch: 8 step: 1095, loss is 0.00027026113821193576\n",
      "epoch: 8 step: 1096, loss is 0.02622126415371895\n",
      "epoch: 8 step: 1097, loss is 0.08218041807413101\n",
      "epoch: 8 step: 1098, loss is 0.0007941175135783851\n",
      "epoch: 8 step: 1099, loss is 0.00027028698241338134\n",
      "epoch: 8 step: 1100, loss is 0.0007977942586876452\n",
      "epoch: 8 step: 1101, loss is 0.008276277221739292\n",
      "epoch: 8 step: 1102, loss is 0.0015599846374243498\n",
      "epoch: 8 step: 1103, loss is 0.3458581268787384\n",
      "epoch: 8 step: 1104, loss is 0.005582611542195082\n",
      "epoch: 8 step: 1105, loss is 0.00035047210985794663\n",
      "epoch: 8 step: 1106, loss is 0.015106535516679287\n",
      "epoch: 8 step: 1107, loss is 0.0006162215140648186\n",
      "epoch: 8 step: 1108, loss is 2.9868520869058557e-05\n",
      "epoch: 8 step: 1109, loss is 3.8129630411276594e-05\n",
      "epoch: 8 step: 1110, loss is 0.00015820864064153284\n",
      "epoch: 8 step: 1111, loss is 0.007860686630010605\n",
      "epoch: 8 step: 1112, loss is 2.2393103790818714e-05\n",
      "epoch: 8 step: 1113, loss is 0.0030708517879247665\n",
      "epoch: 8 step: 1114, loss is 0.00013854725693818182\n",
      "epoch: 8 step: 1115, loss is 0.0001679064880590886\n",
      "epoch: 8 step: 1116, loss is 0.05178872495889664\n",
      "epoch: 8 step: 1117, loss is 0.0034383777529001236\n",
      "epoch: 8 step: 1118, loss is 0.027952024713158607\n",
      "epoch: 8 step: 1119, loss is 0.0030287697445601225\n",
      "epoch: 8 step: 1120, loss is 0.004746244288980961\n",
      "epoch: 8 step: 1121, loss is 0.0013369538355618715\n",
      "epoch: 8 step: 1122, loss is 0.0013694360386580229\n",
      "epoch: 8 step: 1123, loss is 5.741233326261863e-05\n",
      "epoch: 8 step: 1124, loss is 0.08335305005311966\n",
      "epoch: 8 step: 1125, loss is 0.0021365699358284473\n",
      "epoch: 8 step: 1126, loss is 6.655694596702233e-05\n",
      "epoch: 8 step: 1127, loss is 0.13184109330177307\n",
      "epoch: 8 step: 1128, loss is 0.0005818843492306769\n",
      "epoch: 8 step: 1129, loss is 3.431935328990221e-05\n",
      "epoch: 8 step: 1130, loss is 6.962983206904028e-06\n",
      "epoch: 8 step: 1131, loss is 2.8402695534168743e-05\n",
      "epoch: 8 step: 1132, loss is 0.08203556388616562\n",
      "epoch: 8 step: 1133, loss is 0.001605343190021813\n",
      "epoch: 8 step: 1134, loss is 0.011311087757349014\n",
      "epoch: 8 step: 1135, loss is 0.0006628925912082195\n",
      "epoch: 8 step: 1136, loss is 0.1369321197271347\n",
      "epoch: 8 step: 1137, loss is 0.013889351859688759\n",
      "epoch: 8 step: 1138, loss is 8.599010470788926e-05\n",
      "epoch: 8 step: 1139, loss is 0.10473030060529709\n",
      "epoch: 8 step: 1140, loss is 0.03277871757745743\n",
      "epoch: 8 step: 1141, loss is 0.11427175253629684\n",
      "epoch: 8 step: 1142, loss is 0.0006486570928245783\n",
      "epoch: 8 step: 1143, loss is 8.336709288414568e-05\n",
      "epoch: 8 step: 1144, loss is 0.0659051463007927\n",
      "epoch: 8 step: 1145, loss is 5.695899744750932e-05\n",
      "epoch: 8 step: 1146, loss is 0.00014273246051743627\n",
      "epoch: 8 step: 1147, loss is 0.00021124347404111177\n",
      "epoch: 8 step: 1148, loss is 0.004175117239356041\n",
      "epoch: 8 step: 1149, loss is 0.000804619980044663\n",
      "epoch: 8 step: 1150, loss is 0.07558166980743408\n",
      "epoch: 8 step: 1151, loss is 2.5194789486704394e-05\n",
      "epoch: 8 step: 1152, loss is 6.140890036476776e-05\n",
      "epoch: 8 step: 1153, loss is 0.0015794287901371717\n",
      "epoch: 8 step: 1154, loss is 0.015516387298703194\n",
      "epoch: 8 step: 1155, loss is 0.0012287788558751345\n",
      "epoch: 8 step: 1156, loss is 0.013154072687029839\n",
      "epoch: 8 step: 1157, loss is 0.0031405624467879534\n",
      "epoch: 8 step: 1158, loss is 0.00010703649604693055\n",
      "epoch: 8 step: 1159, loss is 0.00016145221889019012\n",
      "epoch: 8 step: 1160, loss is 0.003703037044033408\n",
      "epoch: 8 step: 1161, loss is 0.08524835854768753\n",
      "epoch: 8 step: 1162, loss is 0.03875289857387543\n",
      "epoch: 8 step: 1163, loss is 0.0002794296888168901\n",
      "epoch: 8 step: 1164, loss is 0.0007197056547738612\n",
      "epoch: 8 step: 1165, loss is 0.00047492666635662317\n",
      "epoch: 8 step: 1166, loss is 0.0030001045670360327\n",
      "epoch: 8 step: 1167, loss is 0.005451550707221031\n",
      "epoch: 8 step: 1168, loss is 0.0013450499391183257\n",
      "epoch: 8 step: 1169, loss is 0.07258868217468262\n",
      "epoch: 8 step: 1170, loss is 0.00017741171177476645\n",
      "epoch: 8 step: 1171, loss is 0.083286352455616\n",
      "epoch: 8 step: 1172, loss is 0.001661015092395246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1173, loss is 0.011766830459237099\n",
      "epoch: 8 step: 1174, loss is 0.0008844069670885801\n",
      "epoch: 8 step: 1175, loss is 0.0006626935792155564\n",
      "epoch: 8 step: 1176, loss is 0.0004095822514500469\n",
      "epoch: 8 step: 1177, loss is 0.0011650394881144166\n",
      "epoch: 8 step: 1178, loss is 0.003065624972805381\n",
      "epoch: 8 step: 1179, loss is 0.0002769464335869998\n",
      "epoch: 8 step: 1180, loss is 0.0054915244691073895\n",
      "epoch: 8 step: 1181, loss is 0.04165825620293617\n",
      "epoch: 8 step: 1182, loss is 7.167650437622797e-06\n",
      "epoch: 8 step: 1183, loss is 0.0006471822271123528\n",
      "epoch: 8 step: 1184, loss is 0.0002797223278321326\n",
      "epoch: 8 step: 1185, loss is 0.0008312084246426821\n",
      "epoch: 8 step: 1186, loss is 0.016509464010596275\n",
      "epoch: 8 step: 1187, loss is 0.0012628288241103292\n",
      "epoch: 8 step: 1188, loss is 0.0017115053487941623\n",
      "epoch: 8 step: 1189, loss is 0.0005086880992166698\n",
      "epoch: 8 step: 1190, loss is 3.2731302781030536e-05\n",
      "epoch: 8 step: 1191, loss is 0.04459907114505768\n",
      "epoch: 8 step: 1192, loss is 0.08861272782087326\n",
      "epoch: 8 step: 1193, loss is 0.417420893907547\n",
      "epoch: 8 step: 1194, loss is 7.595975330332294e-05\n",
      "epoch: 8 step: 1195, loss is 0.004450267646461725\n",
      "epoch: 8 step: 1196, loss is 0.0009194730082526803\n",
      "epoch: 8 step: 1197, loss is 0.0006943101761862636\n",
      "epoch: 8 step: 1198, loss is 0.000846308539621532\n",
      "epoch: 8 step: 1199, loss is 0.0005609766812995076\n",
      "epoch: 8 step: 1200, loss is 0.0001386995572829619\n",
      "epoch: 8 step: 1201, loss is 4.468009865377098e-05\n",
      "epoch: 8 step: 1202, loss is 0.0016703919973224401\n",
      "epoch: 8 step: 1203, loss is 0.00010723291779868305\n",
      "epoch: 8 step: 1204, loss is 0.007298920303583145\n",
      "epoch: 8 step: 1205, loss is 0.01348970178514719\n",
      "epoch: 8 step: 1206, loss is 0.00533033674582839\n",
      "epoch: 8 step: 1207, loss is 0.000474545027827844\n",
      "epoch: 8 step: 1208, loss is 0.0026295529678463936\n",
      "epoch: 8 step: 1209, loss is 0.019274162128567696\n",
      "epoch: 8 step: 1210, loss is 8.030934986891225e-05\n",
      "epoch: 8 step: 1211, loss is 0.0014701002510264516\n",
      "epoch: 8 step: 1212, loss is 0.0017670491943135858\n",
      "epoch: 8 step: 1213, loss is 0.0010416426230221987\n",
      "epoch: 8 step: 1214, loss is 0.03451623022556305\n",
      "epoch: 8 step: 1215, loss is 0.09983864426612854\n",
      "epoch: 8 step: 1216, loss is 0.030557220801711082\n",
      "epoch: 8 step: 1217, loss is 0.07058984041213989\n",
      "epoch: 8 step: 1218, loss is 0.09932122379541397\n",
      "epoch: 8 step: 1219, loss is 0.007045336067676544\n",
      "epoch: 8 step: 1220, loss is 0.0001365356147289276\n",
      "epoch: 8 step: 1221, loss is 9.59502358455211e-06\n",
      "epoch: 8 step: 1222, loss is 0.0004211380728520453\n",
      "epoch: 8 step: 1223, loss is 0.05347573384642601\n",
      "epoch: 8 step: 1224, loss is 0.02899348735809326\n",
      "epoch: 8 step: 1225, loss is 0.00211196206510067\n",
      "epoch: 8 step: 1226, loss is 0.0006212659063749015\n",
      "epoch: 8 step: 1227, loss is 0.00014989700866863132\n",
      "epoch: 8 step: 1228, loss is 0.1335536539554596\n",
      "epoch: 8 step: 1229, loss is 0.0012766428990289569\n",
      "epoch: 8 step: 1230, loss is 0.001861486118286848\n",
      "epoch: 8 step: 1231, loss is 0.0162337776273489\n",
      "epoch: 8 step: 1232, loss is 0.0005834713811054826\n",
      "epoch: 8 step: 1233, loss is 0.016488593071699142\n",
      "epoch: 8 step: 1234, loss is 9.630154818296432e-05\n",
      "epoch: 8 step: 1235, loss is 0.05389709770679474\n",
      "epoch: 8 step: 1236, loss is 0.0008270143298432231\n",
      "epoch: 8 step: 1237, loss is 0.0018473692471161485\n",
      "epoch: 8 step: 1238, loss is 0.006389388348907232\n",
      "epoch: 8 step: 1239, loss is 0.00432167574763298\n",
      "epoch: 8 step: 1240, loss is 0.0001286818296648562\n",
      "epoch: 8 step: 1241, loss is 0.008606716990470886\n",
      "epoch: 8 step: 1242, loss is 0.003576515708118677\n",
      "epoch: 8 step: 1243, loss is 0.00010887130338232964\n",
      "epoch: 8 step: 1244, loss is 0.01328252162784338\n",
      "epoch: 8 step: 1245, loss is 0.0019326343899592757\n",
      "epoch: 8 step: 1246, loss is 0.00010747173655545339\n",
      "epoch: 8 step: 1247, loss is 0.02790389023721218\n",
      "epoch: 8 step: 1248, loss is 0.0008638726430945098\n",
      "epoch: 8 step: 1249, loss is 0.08612460643053055\n",
      "epoch: 8 step: 1250, loss is 0.0054544745944440365\n",
      "epoch: 8 step: 1251, loss is 0.0008570575155317783\n",
      "epoch: 8 step: 1252, loss is 0.009149760007858276\n",
      "epoch: 8 step: 1253, loss is 0.13968980312347412\n",
      "epoch: 8 step: 1254, loss is 1.3752727682003751e-05\n",
      "epoch: 8 step: 1255, loss is 0.0005248608067631721\n",
      "epoch: 8 step: 1256, loss is 0.010388653725385666\n",
      "epoch: 8 step: 1257, loss is 0.0023493291810154915\n",
      "epoch: 8 step: 1258, loss is 0.007657909765839577\n",
      "epoch: 8 step: 1259, loss is 0.0012551441323012114\n",
      "epoch: 8 step: 1260, loss is 0.0028622313402593136\n",
      "epoch: 8 step: 1261, loss is 0.0017171690706163645\n",
      "epoch: 8 step: 1262, loss is 0.3331414461135864\n",
      "epoch: 8 step: 1263, loss is 0.06319992989301682\n",
      "epoch: 8 step: 1264, loss is 0.03330383449792862\n",
      "epoch: 8 step: 1265, loss is 0.0028039871249347925\n",
      "epoch: 8 step: 1266, loss is 0.007323184981942177\n",
      "epoch: 8 step: 1267, loss is 0.02574259415268898\n",
      "epoch: 8 step: 1268, loss is 0.0014556547394022346\n",
      "epoch: 8 step: 1269, loss is 0.002607649425044656\n",
      "epoch: 8 step: 1270, loss is 7.30618994566612e-05\n",
      "epoch: 8 step: 1271, loss is 0.00029258339782245457\n",
      "epoch: 8 step: 1272, loss is 0.0035824007354676723\n",
      "epoch: 8 step: 1273, loss is 0.0002334272430744022\n",
      "epoch: 8 step: 1274, loss is 3.402720540179871e-05\n",
      "epoch: 8 step: 1275, loss is 0.011675067245960236\n",
      "epoch: 8 step: 1276, loss is 0.0004493917222134769\n",
      "epoch: 8 step: 1277, loss is 0.023063985630869865\n",
      "epoch: 8 step: 1278, loss is 0.0013723979936912656\n",
      "epoch: 8 step: 1279, loss is 0.0012987146619707346\n",
      "epoch: 8 step: 1280, loss is 0.024792514741420746\n",
      "epoch: 8 step: 1281, loss is 0.0024133066181093454\n",
      "epoch: 8 step: 1282, loss is 0.00011810605792561546\n",
      "epoch: 8 step: 1283, loss is 0.11527933925390244\n",
      "epoch: 8 step: 1284, loss is 0.03073030896484852\n",
      "epoch: 8 step: 1285, loss is 0.0006415030220523477\n",
      "epoch: 8 step: 1286, loss is 0.0028932050336152315\n",
      "epoch: 8 step: 1287, loss is 0.0007751878583803773\n",
      "epoch: 8 step: 1288, loss is 0.00023455001064576209\n",
      "epoch: 8 step: 1289, loss is 0.002522108843550086\n",
      "epoch: 8 step: 1290, loss is 0.0002382938691880554\n",
      "epoch: 8 step: 1291, loss is 0.06250710785388947\n",
      "epoch: 8 step: 1292, loss is 0.072025828063488\n",
      "epoch: 8 step: 1293, loss is 0.00022921555500943214\n",
      "epoch: 8 step: 1294, loss is 0.001014126930385828\n",
      "epoch: 8 step: 1295, loss is 0.0014410644071176648\n",
      "epoch: 8 step: 1296, loss is 0.020424025133252144\n",
      "epoch: 8 step: 1297, loss is 0.0064077493734657764\n",
      "epoch: 8 step: 1298, loss is 0.0028388104401528835\n",
      "epoch: 8 step: 1299, loss is 0.009482866153120995\n",
      "epoch: 8 step: 1300, loss is 0.00024836527882143855\n",
      "epoch: 8 step: 1301, loss is 0.0003108894161414355\n",
      "epoch: 8 step: 1302, loss is 0.0441170334815979\n",
      "epoch: 8 step: 1303, loss is 0.0018375851213932037\n",
      "epoch: 8 step: 1304, loss is 0.0013011805713176727\n",
      "epoch: 8 step: 1305, loss is 0.0009744382696226239\n",
      "epoch: 8 step: 1306, loss is 0.013489007018506527\n",
      "epoch: 8 step: 1307, loss is 0.00016883463831618428\n",
      "epoch: 8 step: 1308, loss is 0.012279273942112923\n",
      "epoch: 8 step: 1309, loss is 1.8804677893058397e-05\n",
      "epoch: 8 step: 1310, loss is 0.0018587782979011536\n",
      "epoch: 8 step: 1311, loss is 0.17350473999977112\n",
      "epoch: 8 step: 1312, loss is 0.12462400645017624\n",
      "epoch: 8 step: 1313, loss is 0.0025936325546354055\n",
      "epoch: 8 step: 1314, loss is 0.016307855024933815\n",
      "epoch: 8 step: 1315, loss is 0.0027433393988758326\n",
      "epoch: 8 step: 1316, loss is 0.0032179271802306175\n",
      "epoch: 8 step: 1317, loss is 0.00013400634634308517\n",
      "epoch: 8 step: 1318, loss is 0.0009498699801042676\n",
      "epoch: 8 step: 1319, loss is 0.0006752854096703231\n",
      "epoch: 8 step: 1320, loss is 0.00286464998498559\n",
      "epoch: 8 step: 1321, loss is 0.000793228973634541\n",
      "epoch: 8 step: 1322, loss is 0.0022048288956284523\n",
      "epoch: 8 step: 1323, loss is 0.0020917647052556276\n",
      "epoch: 8 step: 1324, loss is 0.0009452109807170928\n",
      "epoch: 8 step: 1325, loss is 0.0005594220128841698\n",
      "epoch: 8 step: 1326, loss is 0.0039657652378082275\n",
      "epoch: 8 step: 1327, loss is 0.0005570616922341287\n",
      "epoch: 8 step: 1328, loss is 0.005674073006957769\n",
      "epoch: 8 step: 1329, loss is 0.00027891420177184045\n",
      "epoch: 8 step: 1330, loss is 0.04115757346153259\n",
      "epoch: 8 step: 1331, loss is 0.0013598700752481818\n",
      "epoch: 8 step: 1332, loss is 0.0019814097322523594\n",
      "epoch: 8 step: 1333, loss is 0.005206233821809292\n",
      "epoch: 8 step: 1334, loss is 0.01987900584936142\n",
      "epoch: 8 step: 1335, loss is 0.003041960531845689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1336, loss is 0.0034637730568647385\n",
      "epoch: 8 step: 1337, loss is 0.00020494908676482737\n",
      "epoch: 8 step: 1338, loss is 0.007787935435771942\n",
      "epoch: 8 step: 1339, loss is 0.023600107058882713\n",
      "epoch: 8 step: 1340, loss is 0.0008077427628450096\n",
      "epoch: 8 step: 1341, loss is 0.000144757199450396\n",
      "epoch: 8 step: 1342, loss is 0.01700347103178501\n",
      "epoch: 8 step: 1343, loss is 0.00030168212833814323\n",
      "epoch: 8 step: 1344, loss is 0.0010357239516451955\n",
      "epoch: 8 step: 1345, loss is 0.014804075472056866\n",
      "epoch: 8 step: 1346, loss is 0.0024145874194800854\n",
      "epoch: 8 step: 1347, loss is 7.128831384761725e-06\n",
      "epoch: 8 step: 1348, loss is 0.0005455594509840012\n",
      "epoch: 8 step: 1349, loss is 0.00012826075544580817\n",
      "epoch: 8 step: 1350, loss is 0.00020865298574790359\n",
      "epoch: 8 step: 1351, loss is 0.0007172783371061087\n",
      "epoch: 8 step: 1352, loss is 0.0016345266485586762\n",
      "epoch: 8 step: 1353, loss is 0.0006579512264579535\n",
      "epoch: 8 step: 1354, loss is 0.0005499114631675184\n",
      "epoch: 8 step: 1355, loss is 0.004868749529123306\n",
      "epoch: 8 step: 1356, loss is 0.00023624161258339882\n",
      "epoch: 8 step: 1357, loss is 0.00020356752793304622\n",
      "epoch: 8 step: 1358, loss is 0.008544949814677238\n",
      "epoch: 8 step: 1359, loss is 0.00012972876720596105\n",
      "epoch: 8 step: 1360, loss is 4.291058939998038e-05\n",
      "epoch: 8 step: 1361, loss is 0.006935570389032364\n",
      "epoch: 8 step: 1362, loss is 0.06311613321304321\n",
      "epoch: 8 step: 1363, loss is 0.0002468283346388489\n",
      "epoch: 8 step: 1364, loss is 7.0525573391933e-05\n",
      "epoch: 8 step: 1365, loss is 5.83414439461194e-05\n",
      "epoch: 8 step: 1366, loss is 0.025540560483932495\n",
      "epoch: 8 step: 1367, loss is 0.0003438870480749756\n",
      "epoch: 8 step: 1368, loss is 0.0027121754828840494\n",
      "epoch: 8 step: 1369, loss is 4.378927769721486e-05\n",
      "epoch: 8 step: 1370, loss is 0.0008679940947331488\n",
      "epoch: 8 step: 1371, loss is 0.01771606132388115\n",
      "epoch: 8 step: 1372, loss is 0.12865717709064484\n",
      "epoch: 8 step: 1373, loss is 0.05303504317998886\n",
      "epoch: 8 step: 1374, loss is 5.8193254517391324e-05\n",
      "epoch: 8 step: 1375, loss is 0.030577925965189934\n",
      "epoch: 8 step: 1376, loss is 0.00360110797919333\n",
      "epoch: 8 step: 1377, loss is 0.0004416783631313592\n",
      "epoch: 8 step: 1378, loss is 0.07226775586605072\n",
      "epoch: 8 step: 1379, loss is 0.001056111534126103\n",
      "epoch: 8 step: 1380, loss is 0.00024406614829786122\n",
      "epoch: 8 step: 1381, loss is 0.06608593463897705\n",
      "epoch: 8 step: 1382, loss is 0.00036812934558838606\n",
      "epoch: 8 step: 1383, loss is 0.0005952226347289979\n",
      "epoch: 8 step: 1384, loss is 0.0020013561006635427\n",
      "epoch: 8 step: 1385, loss is 0.017947407439351082\n",
      "epoch: 8 step: 1386, loss is 5.203066029935144e-05\n",
      "epoch: 8 step: 1387, loss is 0.0347694456577301\n",
      "epoch: 8 step: 1388, loss is 0.00046365702291950583\n",
      "epoch: 8 step: 1389, loss is 0.014947522431612015\n",
      "epoch: 8 step: 1390, loss is 0.004489635117352009\n",
      "epoch: 8 step: 1391, loss is 0.044168226420879364\n",
      "epoch: 8 step: 1392, loss is 8.074565266724676e-05\n",
      "epoch: 8 step: 1393, loss is 1.0975293662340846e-05\n",
      "epoch: 8 step: 1394, loss is 0.014390656724572182\n",
      "epoch: 8 step: 1395, loss is 0.000269196490989998\n",
      "epoch: 8 step: 1396, loss is 0.002980762394145131\n",
      "epoch: 8 step: 1397, loss is 0.0004172329790890217\n",
      "epoch: 8 step: 1398, loss is 0.025395454838871956\n",
      "epoch: 8 step: 1399, loss is 0.00055815459927544\n",
      "epoch: 8 step: 1400, loss is 0.0038681491278111935\n",
      "epoch: 8 step: 1401, loss is 0.0015867917099967599\n",
      "epoch: 8 step: 1402, loss is 0.00015578239981550723\n",
      "epoch: 8 step: 1403, loss is 0.00012257928028702736\n",
      "epoch: 8 step: 1404, loss is 0.0005031768814660609\n",
      "epoch: 8 step: 1405, loss is 0.028231486678123474\n",
      "epoch: 8 step: 1406, loss is 9.905973456625361e-06\n",
      "epoch: 8 step: 1407, loss is 0.0004162178374826908\n",
      "epoch: 8 step: 1408, loss is 0.027428966015577316\n",
      "epoch: 8 step: 1409, loss is 0.001891377498395741\n",
      "epoch: 8 step: 1410, loss is 0.0017793040024116635\n",
      "epoch: 8 step: 1411, loss is 0.00020532688358798623\n",
      "epoch: 8 step: 1412, loss is 0.015853343531489372\n",
      "epoch: 8 step: 1413, loss is 3.605572055676021e-05\n",
      "epoch: 8 step: 1414, loss is 0.00022980070207268\n",
      "epoch: 8 step: 1415, loss is 0.0035835900343954563\n",
      "epoch: 8 step: 1416, loss is 9.542971383780241e-06\n",
      "epoch: 8 step: 1417, loss is 0.0005586667102761567\n",
      "epoch: 8 step: 1418, loss is 0.003822677070274949\n",
      "epoch: 8 step: 1419, loss is 0.044272471219301224\n",
      "epoch: 8 step: 1420, loss is 0.014073478057980537\n",
      "epoch: 8 step: 1421, loss is 0.019037025049328804\n",
      "epoch: 8 step: 1422, loss is 0.001101078581996262\n",
      "epoch: 8 step: 1423, loss is 2.904814937210176e-05\n",
      "epoch: 8 step: 1424, loss is 0.0003003160236403346\n",
      "epoch: 8 step: 1425, loss is 0.00815983209758997\n",
      "epoch: 8 step: 1426, loss is 0.00022925835219211876\n",
      "epoch: 8 step: 1427, loss is 8.705290383659303e-05\n",
      "epoch: 8 step: 1428, loss is 0.0005338227492757142\n",
      "epoch: 8 step: 1429, loss is 1.485549637436634e-05\n",
      "epoch: 8 step: 1430, loss is 0.0010010272962972522\n",
      "epoch: 8 step: 1431, loss is 0.004456025548279285\n",
      "epoch: 8 step: 1432, loss is 0.00018652727885637432\n",
      "epoch: 8 step: 1433, loss is 0.0019881739281117916\n",
      "epoch: 8 step: 1434, loss is 0.0004845932126045227\n",
      "epoch: 8 step: 1435, loss is 0.051676250994205475\n",
      "epoch: 8 step: 1436, loss is 2.0066730940015987e-05\n",
      "epoch: 8 step: 1437, loss is 9.567898086970672e-05\n",
      "epoch: 8 step: 1438, loss is 0.051567476242780685\n",
      "epoch: 8 step: 1439, loss is 0.00026169224292971194\n",
      "epoch: 8 step: 1440, loss is 0.0007024580845609307\n",
      "epoch: 8 step: 1441, loss is 0.000413645087974146\n",
      "epoch: 8 step: 1442, loss is 0.001601533847860992\n",
      "epoch: 8 step: 1443, loss is 0.033441562205553055\n",
      "epoch: 8 step: 1444, loss is 0.0021045852918177843\n",
      "epoch: 8 step: 1445, loss is 0.0006631853757426143\n",
      "epoch: 8 step: 1446, loss is 0.002657047938555479\n",
      "epoch: 8 step: 1447, loss is 4.592572076944634e-05\n",
      "epoch: 8 step: 1448, loss is 0.009858694858849049\n",
      "epoch: 8 step: 1449, loss is 0.00028093025321140885\n",
      "epoch: 8 step: 1450, loss is 0.05792774260044098\n",
      "epoch: 8 step: 1451, loss is 0.0003502689069136977\n",
      "epoch: 8 step: 1452, loss is 0.056260861456394196\n",
      "epoch: 8 step: 1453, loss is 0.0007416150765493512\n",
      "epoch: 8 step: 1454, loss is 0.0001927601551869884\n",
      "epoch: 8 step: 1455, loss is 3.578723772079684e-05\n",
      "epoch: 8 step: 1456, loss is 0.21330124139785767\n",
      "epoch: 8 step: 1457, loss is 3.0082333978498355e-05\n",
      "epoch: 8 step: 1458, loss is 7.030158303678036e-05\n",
      "epoch: 8 step: 1459, loss is 0.0001638359244680032\n",
      "epoch: 8 step: 1460, loss is 0.0016093768645077944\n",
      "epoch: 8 step: 1461, loss is 0.0023219825234264135\n",
      "epoch: 8 step: 1462, loss is 0.0011663454351946712\n",
      "epoch: 8 step: 1463, loss is 0.00436442531645298\n",
      "epoch: 8 step: 1464, loss is 0.0028761422727257013\n",
      "epoch: 8 step: 1465, loss is 0.02946152724325657\n",
      "epoch: 8 step: 1466, loss is 0.016452202573418617\n",
      "epoch: 8 step: 1467, loss is 0.00034294382203370333\n",
      "epoch: 8 step: 1468, loss is 0.3003677427768707\n",
      "epoch: 8 step: 1469, loss is 0.03432886675000191\n",
      "epoch: 8 step: 1470, loss is 0.00037724943831562996\n",
      "epoch: 8 step: 1471, loss is 0.025163929909467697\n",
      "epoch: 8 step: 1472, loss is 0.00980758760124445\n",
      "epoch: 8 step: 1473, loss is 0.0014729825779795647\n",
      "epoch: 8 step: 1474, loss is 0.005447018891572952\n",
      "epoch: 8 step: 1475, loss is 0.0028692660853266716\n",
      "epoch: 8 step: 1476, loss is 4.007857569376938e-05\n",
      "epoch: 8 step: 1477, loss is 0.0006850628415122628\n",
      "epoch: 8 step: 1478, loss is 0.0006348511669784784\n",
      "epoch: 8 step: 1479, loss is 0.0010943050729110837\n",
      "epoch: 8 step: 1480, loss is 0.031108643859624863\n",
      "epoch: 8 step: 1481, loss is 0.00045108768972568214\n",
      "epoch: 8 step: 1482, loss is 0.05179458484053612\n",
      "epoch: 8 step: 1483, loss is 0.005495999939739704\n",
      "epoch: 8 step: 1484, loss is 0.002922060200944543\n",
      "epoch: 8 step: 1485, loss is 0.005192618351429701\n",
      "epoch: 8 step: 1486, loss is 0.00016804189363028854\n",
      "epoch: 8 step: 1487, loss is 0.11330900341272354\n",
      "epoch: 8 step: 1488, loss is 8.243927732110023e-05\n",
      "epoch: 8 step: 1489, loss is 0.01590581238269806\n",
      "epoch: 8 step: 1490, loss is 0.11630526930093765\n",
      "epoch: 8 step: 1491, loss is 0.0004629494796972722\n",
      "epoch: 8 step: 1492, loss is 0.015388068743050098\n",
      "epoch: 8 step: 1493, loss is 0.00023546699958387762\n",
      "epoch: 8 step: 1494, loss is 0.004390587564557791\n",
      "epoch: 8 step: 1495, loss is 0.01660097949206829\n",
      "epoch: 8 step: 1496, loss is 0.003909670282155275\n",
      "epoch: 8 step: 1497, loss is 0.009572146460413933\n",
      "epoch: 8 step: 1498, loss is 0.10510143637657166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1499, loss is 0.00024454412050545216\n",
      "epoch: 8 step: 1500, loss is 0.009093568660318851\n",
      "epoch: 8 step: 1501, loss is 0.0014155165990814567\n",
      "epoch: 8 step: 1502, loss is 0.009336697869002819\n",
      "epoch: 8 step: 1503, loss is 0.010370484553277493\n",
      "epoch: 8 step: 1504, loss is 0.0010200536344200373\n",
      "epoch: 8 step: 1505, loss is 0.0314926914870739\n",
      "epoch: 8 step: 1506, loss is 3.942625698982738e-05\n",
      "epoch: 8 step: 1507, loss is 0.00806478876620531\n",
      "epoch: 8 step: 1508, loss is 0.0010508957784622908\n",
      "epoch: 8 step: 1509, loss is 0.00016468421381432563\n",
      "epoch: 8 step: 1510, loss is 0.00013239319378044456\n",
      "epoch: 8 step: 1511, loss is 2.9688302674912848e-05\n",
      "epoch: 8 step: 1512, loss is 0.00020104508439544588\n",
      "epoch: 8 step: 1513, loss is 0.00042238071910105646\n",
      "epoch: 8 step: 1514, loss is 0.017721230164170265\n",
      "epoch: 8 step: 1515, loss is 2.215893800894264e-05\n",
      "epoch: 8 step: 1516, loss is 0.06482192128896713\n",
      "epoch: 8 step: 1517, loss is 0.002459299750626087\n",
      "epoch: 8 step: 1518, loss is 0.16522715985774994\n",
      "epoch: 8 step: 1519, loss is 2.941200182249304e-05\n",
      "epoch: 8 step: 1520, loss is 0.0005452540935948491\n",
      "epoch: 8 step: 1521, loss is 0.000641435501165688\n",
      "epoch: 8 step: 1522, loss is 0.002016960410401225\n",
      "epoch: 8 step: 1523, loss is 0.0017172006191685796\n",
      "epoch: 8 step: 1524, loss is 0.0019258278189226985\n",
      "epoch: 8 step: 1525, loss is 3.180954809067771e-05\n",
      "epoch: 8 step: 1526, loss is 0.00228351098485291\n",
      "epoch: 8 step: 1527, loss is 0.001277290633879602\n",
      "epoch: 8 step: 1528, loss is 1.7625847249291837e-05\n",
      "epoch: 8 step: 1529, loss is 0.00317854480817914\n",
      "epoch: 8 step: 1530, loss is 0.0018430392956361175\n",
      "epoch: 8 step: 1531, loss is 9.080409654416144e-05\n",
      "epoch: 8 step: 1532, loss is 0.0007494014571420848\n",
      "epoch: 8 step: 1533, loss is 0.00010164110426558182\n",
      "epoch: 8 step: 1534, loss is 4.168043233221397e-05\n",
      "epoch: 8 step: 1535, loss is 0.09570983797311783\n",
      "epoch: 8 step: 1536, loss is 0.012262123636901379\n",
      "epoch: 8 step: 1537, loss is 0.008511846885085106\n",
      "epoch: 8 step: 1538, loss is 0.04398130252957344\n",
      "epoch: 8 step: 1539, loss is 0.11924061179161072\n",
      "epoch: 8 step: 1540, loss is 0.0013088297564536333\n",
      "epoch: 8 step: 1541, loss is 0.0010941711952909827\n",
      "epoch: 8 step: 1542, loss is 0.010748184286057949\n",
      "epoch: 8 step: 1543, loss is 6.421531725209206e-05\n",
      "epoch: 8 step: 1544, loss is 0.03298376873135567\n",
      "epoch: 8 step: 1545, loss is 0.020055649802088737\n",
      "epoch: 8 step: 1546, loss is 0.2209225445985794\n",
      "epoch: 8 step: 1547, loss is 3.1278083042707294e-05\n",
      "epoch: 8 step: 1548, loss is 0.1603054702281952\n",
      "epoch: 8 step: 1549, loss is 0.003243554849177599\n",
      "epoch: 8 step: 1550, loss is 0.0007662464631721377\n",
      "epoch: 8 step: 1551, loss is 0.026037180796265602\n",
      "epoch: 8 step: 1552, loss is 0.005197648890316486\n",
      "epoch: 8 step: 1553, loss is 0.00029386411188170314\n",
      "epoch: 8 step: 1554, loss is 0.0003634549502748996\n",
      "epoch: 8 step: 1555, loss is 0.0039488147012889385\n",
      "epoch: 8 step: 1556, loss is 0.060954827815294266\n",
      "epoch: 8 step: 1557, loss is 0.00033361013629473746\n",
      "epoch: 8 step: 1558, loss is 0.00026364965015091\n",
      "epoch: 8 step: 1559, loss is 0.037733159959316254\n",
      "epoch: 8 step: 1560, loss is 0.030241921544075012\n",
      "epoch: 8 step: 1561, loss is 0.007076778449118137\n",
      "epoch: 8 step: 1562, loss is 0.001567131606861949\n",
      "epoch: 8 step: 1563, loss is 0.0746224895119667\n",
      "epoch: 8 step: 1564, loss is 0.0004412689304444939\n",
      "epoch: 8 step: 1565, loss is 0.002584298374131322\n",
      "epoch: 8 step: 1566, loss is 0.0017336858436465263\n",
      "epoch: 8 step: 1567, loss is 0.01380041055381298\n",
      "epoch: 8 step: 1568, loss is 0.018477842211723328\n",
      "epoch: 8 step: 1569, loss is 0.0004218930844217539\n",
      "epoch: 8 step: 1570, loss is 0.009894239716231823\n",
      "epoch: 8 step: 1571, loss is 0.000330545095494017\n",
      "epoch: 8 step: 1572, loss is 0.008865856565535069\n",
      "epoch: 8 step: 1573, loss is 0.002955604810267687\n",
      "epoch: 8 step: 1574, loss is 0.00021908702910877764\n",
      "epoch: 8 step: 1575, loss is 0.008100800216197968\n",
      "epoch: 8 step: 1576, loss is 0.020215503871440887\n",
      "epoch: 8 step: 1577, loss is 0.04348244145512581\n",
      "epoch: 8 step: 1578, loss is 0.4281454086303711\n",
      "epoch: 8 step: 1579, loss is 0.005193638615310192\n",
      "epoch: 8 step: 1580, loss is 0.01431211456656456\n",
      "epoch: 8 step: 1581, loss is 0.006457851734012365\n",
      "epoch: 8 step: 1582, loss is 0.0038057726342231035\n",
      "epoch: 8 step: 1583, loss is 0.008627582341432571\n",
      "epoch: 8 step: 1584, loss is 0.13838998973369598\n",
      "epoch: 8 step: 1585, loss is 0.007490303833037615\n",
      "epoch: 8 step: 1586, loss is 0.0015610507689416409\n",
      "epoch: 8 step: 1587, loss is 0.003901083255186677\n",
      "epoch: 8 step: 1588, loss is 0.0025581917725503445\n",
      "epoch: 8 step: 1589, loss is 0.005177872721105814\n",
      "epoch: 8 step: 1590, loss is 7.56717927288264e-05\n",
      "epoch: 8 step: 1591, loss is 0.0651632696390152\n",
      "epoch: 8 step: 1592, loss is 0.0027019537519663572\n",
      "epoch: 8 step: 1593, loss is 0.0011366670951247215\n",
      "epoch: 8 step: 1594, loss is 0.0005336253670975566\n",
      "epoch: 8 step: 1595, loss is 0.00047906459076330066\n",
      "epoch: 8 step: 1596, loss is 0.0017653040122240782\n",
      "epoch: 8 step: 1597, loss is 0.0002471180632710457\n",
      "epoch: 8 step: 1598, loss is 0.0001313739048782736\n",
      "epoch: 8 step: 1599, loss is 0.0025249093305319548\n",
      "epoch: 8 step: 1600, loss is 0.0006386601598933339\n",
      "epoch: 8 step: 1601, loss is 0.00021895584359299392\n",
      "epoch: 8 step: 1602, loss is 0.001515777432359755\n",
      "epoch: 8 step: 1603, loss is 0.0003335059736855328\n",
      "epoch: 8 step: 1604, loss is 0.2569040060043335\n",
      "epoch: 8 step: 1605, loss is 0.0005047564627602696\n",
      "epoch: 8 step: 1606, loss is 0.0010631547775119543\n",
      "epoch: 8 step: 1607, loss is 0.018268268555402756\n",
      "epoch: 8 step: 1608, loss is 0.0073048705235123634\n",
      "epoch: 8 step: 1609, loss is 0.019374089315533638\n",
      "epoch: 8 step: 1610, loss is 2.721698911045678e-05\n",
      "epoch: 8 step: 1611, loss is 0.0004139925877097994\n",
      "epoch: 8 step: 1612, loss is 8.086178422672674e-05\n",
      "epoch: 8 step: 1613, loss is 2.526263597246725e-05\n",
      "epoch: 8 step: 1614, loss is 0.0005167233175598085\n",
      "epoch: 8 step: 1615, loss is 0.0035933791659772396\n",
      "epoch: 8 step: 1616, loss is 0.0006908088107593358\n",
      "epoch: 8 step: 1617, loss is 0.0071335844695568085\n",
      "epoch: 8 step: 1618, loss is 0.000136401824420318\n",
      "epoch: 8 step: 1619, loss is 0.007070245686918497\n",
      "epoch: 8 step: 1620, loss is 0.0007895772578194737\n",
      "epoch: 8 step: 1621, loss is 0.03601504862308502\n",
      "epoch: 8 step: 1622, loss is 0.01822073571383953\n",
      "epoch: 8 step: 1623, loss is 0.00018880852439906448\n",
      "epoch: 8 step: 1624, loss is 0.01746705174446106\n",
      "epoch: 8 step: 1625, loss is 0.00027314337785355747\n",
      "epoch: 8 step: 1626, loss is 0.001529822126030922\n",
      "epoch: 8 step: 1627, loss is 0.0004365253262221813\n",
      "epoch: 8 step: 1628, loss is 0.08152755349874496\n",
      "epoch: 8 step: 1629, loss is 0.017460908740758896\n",
      "epoch: 8 step: 1630, loss is 0.006943184416741133\n",
      "epoch: 8 step: 1631, loss is 0.0011779459891840816\n",
      "epoch: 8 step: 1632, loss is 0.001120277913287282\n",
      "epoch: 8 step: 1633, loss is 0.011341127566993237\n",
      "epoch: 8 step: 1634, loss is 0.00018948945216834545\n",
      "epoch: 8 step: 1635, loss is 0.013131897896528244\n",
      "epoch: 8 step: 1636, loss is 0.007213858421891928\n",
      "epoch: 8 step: 1637, loss is 0.0003585604135878384\n",
      "epoch: 8 step: 1638, loss is 0.021009355783462524\n",
      "epoch: 8 step: 1639, loss is 0.002562736626714468\n",
      "epoch: 8 step: 1640, loss is 0.0009454097598791122\n",
      "epoch: 8 step: 1641, loss is 0.0008196213748306036\n",
      "epoch: 8 step: 1642, loss is 0.001394541934132576\n",
      "epoch: 8 step: 1643, loss is 0.00034873015829361975\n",
      "epoch: 8 step: 1644, loss is 0.00017163011943921447\n",
      "epoch: 8 step: 1645, loss is 2.6462425012141466e-05\n",
      "epoch: 8 step: 1646, loss is 0.00281973066739738\n",
      "epoch: 8 step: 1647, loss is 0.0006982845370657742\n",
      "epoch: 8 step: 1648, loss is 0.013447635807096958\n",
      "epoch: 8 step: 1649, loss is 0.00296301138587296\n",
      "epoch: 8 step: 1650, loss is 0.0006319585372693837\n",
      "epoch: 8 step: 1651, loss is 0.007717860862612724\n",
      "epoch: 8 step: 1652, loss is 0.002957744523882866\n",
      "epoch: 8 step: 1653, loss is 0.0001908647536765784\n",
      "epoch: 8 step: 1654, loss is 0.0017171381041407585\n",
      "epoch: 8 step: 1655, loss is 3.8208399928407744e-05\n",
      "epoch: 8 step: 1656, loss is 0.17806097865104675\n",
      "epoch: 8 step: 1657, loss is 0.004505659453570843\n",
      "epoch: 8 step: 1658, loss is 8.85731351445429e-05\n",
      "epoch: 8 step: 1659, loss is 0.004025245551019907\n",
      "epoch: 8 step: 1660, loss is 0.006694809999316931\n",
      "epoch: 8 step: 1661, loss is 0.001351440791040659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1662, loss is 0.005450048018246889\n",
      "epoch: 8 step: 1663, loss is 1.48385479405988e-05\n",
      "epoch: 8 step: 1664, loss is 0.00028422579634934664\n",
      "epoch: 8 step: 1665, loss is 0.0031740600243210793\n",
      "epoch: 8 step: 1666, loss is 0.0003666484262794256\n",
      "epoch: 8 step: 1667, loss is 0.019223321229219437\n",
      "epoch: 8 step: 1668, loss is 0.002564972499385476\n",
      "epoch: 8 step: 1669, loss is 0.0365091934800148\n",
      "epoch: 8 step: 1670, loss is 0.022151483222842216\n",
      "epoch: 8 step: 1671, loss is 0.12442047148942947\n",
      "epoch: 8 step: 1672, loss is 0.013022453524172306\n",
      "epoch: 8 step: 1673, loss is 5.081420385977253e-05\n",
      "epoch: 8 step: 1674, loss is 0.002562687499448657\n",
      "epoch: 8 step: 1675, loss is 0.005321758799254894\n",
      "epoch: 8 step: 1676, loss is 0.0007242219871841371\n",
      "epoch: 8 step: 1677, loss is 0.005325745325535536\n",
      "epoch: 8 step: 1678, loss is 0.0025492303539067507\n",
      "epoch: 8 step: 1679, loss is 0.0004234377120155841\n",
      "epoch: 8 step: 1680, loss is 3.5947170545114204e-05\n",
      "epoch: 8 step: 1681, loss is 0.00023587221221532673\n",
      "epoch: 8 step: 1682, loss is 0.00012118097947677597\n",
      "epoch: 8 step: 1683, loss is 0.0027122360188513994\n",
      "epoch: 8 step: 1684, loss is 0.0005727945826947689\n",
      "epoch: 8 step: 1685, loss is 0.0003209113492630422\n",
      "epoch: 8 step: 1686, loss is 0.013823088258504868\n",
      "epoch: 8 step: 1687, loss is 0.000853748235385865\n",
      "epoch: 8 step: 1688, loss is 0.05987144261598587\n",
      "epoch: 8 step: 1689, loss is 1.259573946299497e-05\n",
      "epoch: 8 step: 1690, loss is 0.0023761906195431948\n",
      "epoch: 8 step: 1691, loss is 0.0012126812944188714\n",
      "epoch: 8 step: 1692, loss is 0.09987064450979233\n",
      "epoch: 8 step: 1693, loss is 0.03670435771346092\n",
      "epoch: 8 step: 1694, loss is 0.04990896210074425\n",
      "epoch: 8 step: 1695, loss is 0.00038611385389231145\n",
      "epoch: 8 step: 1696, loss is 0.018049389123916626\n",
      "epoch: 8 step: 1697, loss is 0.05075410380959511\n",
      "epoch: 8 step: 1698, loss is 0.0002958876430056989\n",
      "epoch: 8 step: 1699, loss is 0.0011341585777699947\n",
      "epoch: 8 step: 1700, loss is 0.002470843493938446\n",
      "epoch: 8 step: 1701, loss is 0.0003886024933308363\n",
      "epoch: 8 step: 1702, loss is 0.011968596838414669\n",
      "epoch: 8 step: 1703, loss is 0.0031254568602889776\n",
      "epoch: 8 step: 1704, loss is 0.015510240569710732\n",
      "epoch: 8 step: 1705, loss is 0.00018195979646407068\n",
      "epoch: 8 step: 1706, loss is 0.004162830300629139\n",
      "epoch: 8 step: 1707, loss is 4.514297324931249e-05\n",
      "epoch: 8 step: 1708, loss is 0.030153751373291016\n",
      "epoch: 8 step: 1709, loss is 0.0008067049202509224\n",
      "epoch: 8 step: 1710, loss is 0.00030903550214134157\n",
      "epoch: 8 step: 1711, loss is 0.00019294345111120492\n",
      "epoch: 8 step: 1712, loss is 0.0030896137468516827\n",
      "epoch: 8 step: 1713, loss is 0.00032312353141605854\n",
      "epoch: 8 step: 1714, loss is 0.010537715628743172\n",
      "epoch: 8 step: 1715, loss is 0.0013364930637180805\n",
      "epoch: 8 step: 1716, loss is 0.08775709569454193\n",
      "epoch: 8 step: 1717, loss is 0.046443141996860504\n",
      "epoch: 8 step: 1718, loss is 0.024813363328576088\n",
      "epoch: 8 step: 1719, loss is 0.2633734345436096\n",
      "epoch: 8 step: 1720, loss is 0.00014749958063475788\n",
      "epoch: 8 step: 1721, loss is 0.06859522312879562\n",
      "epoch: 8 step: 1722, loss is 0.0034426648635417223\n",
      "epoch: 8 step: 1723, loss is 0.0007089748978614807\n",
      "epoch: 8 step: 1724, loss is 0.04943213611841202\n",
      "epoch: 8 step: 1725, loss is 0.000295083416858688\n",
      "epoch: 8 step: 1726, loss is 0.00015050967340357602\n",
      "epoch: 8 step: 1727, loss is 0.0005802467348985374\n",
      "epoch: 8 step: 1728, loss is 0.00443677045404911\n",
      "epoch: 8 step: 1729, loss is 0.010331682860851288\n",
      "epoch: 8 step: 1730, loss is 0.003776881378144026\n",
      "epoch: 8 step: 1731, loss is 0.0008363552624359727\n",
      "epoch: 8 step: 1732, loss is 0.004228994250297546\n",
      "epoch: 8 step: 1733, loss is 0.0003427534829825163\n",
      "epoch: 8 step: 1734, loss is 0.002061730483546853\n",
      "epoch: 8 step: 1735, loss is 7.326180639211088e-05\n",
      "epoch: 8 step: 1736, loss is 0.013106622733175755\n",
      "epoch: 8 step: 1737, loss is 0.00250790873542428\n",
      "epoch: 8 step: 1738, loss is 0.005072310566902161\n",
      "epoch: 8 step: 1739, loss is 0.0035368776880204678\n",
      "epoch: 8 step: 1740, loss is 1.1951161468459759e-05\n",
      "epoch: 8 step: 1741, loss is 0.01021782960742712\n",
      "epoch: 8 step: 1742, loss is 0.002263000700622797\n",
      "epoch: 8 step: 1743, loss is 0.004737764596939087\n",
      "epoch: 8 step: 1744, loss is 0.004957388620823622\n",
      "epoch: 8 step: 1745, loss is 0.0001039105118252337\n",
      "epoch: 8 step: 1746, loss is 0.01523075345903635\n",
      "epoch: 8 step: 1747, loss is 0.0010501836659386754\n",
      "epoch: 8 step: 1748, loss is 0.0010630895849317312\n",
      "epoch: 8 step: 1749, loss is 0.0007206590962596238\n",
      "epoch: 8 step: 1750, loss is 0.0002331910509383306\n",
      "epoch: 8 step: 1751, loss is 0.017951758578419685\n",
      "epoch: 8 step: 1752, loss is 0.0003725843271240592\n",
      "epoch: 8 step: 1753, loss is 0.00047829741379246116\n",
      "epoch: 8 step: 1754, loss is 0.0013764894101768732\n",
      "epoch: 8 step: 1755, loss is 0.0363553985953331\n",
      "epoch: 8 step: 1756, loss is 0.044875066727399826\n",
      "epoch: 8 step: 1757, loss is 0.011447359807789326\n",
      "epoch: 8 step: 1758, loss is 0.00019374953990336508\n",
      "epoch: 8 step: 1759, loss is 0.028720613569021225\n",
      "epoch: 8 step: 1760, loss is 0.003227558685466647\n",
      "epoch: 8 step: 1761, loss is 8.764550875639543e-05\n",
      "epoch: 8 step: 1762, loss is 0.010586880147457123\n",
      "epoch: 8 step: 1763, loss is 0.014829105697572231\n",
      "epoch: 8 step: 1764, loss is 0.00023242278257384896\n",
      "epoch: 8 step: 1765, loss is 0.05121190473437309\n",
      "epoch: 8 step: 1766, loss is 0.008191103115677834\n",
      "epoch: 8 step: 1767, loss is 0.0004891303251497447\n",
      "epoch: 8 step: 1768, loss is 5.216106728767045e-05\n",
      "epoch: 8 step: 1769, loss is 0.04507812485098839\n",
      "epoch: 8 step: 1770, loss is 0.01868046261370182\n",
      "epoch: 8 step: 1771, loss is 0.000556267739739269\n",
      "epoch: 8 step: 1772, loss is 0.004884996451437473\n",
      "epoch: 8 step: 1773, loss is 0.07168872654438019\n",
      "epoch: 8 step: 1774, loss is 0.0007185359136201441\n",
      "epoch: 8 step: 1775, loss is 0.02396310120820999\n",
      "epoch: 8 step: 1776, loss is 4.688220360549167e-05\n",
      "epoch: 8 step: 1777, loss is 0.00879353005439043\n",
      "epoch: 8 step: 1778, loss is 0.00024846423184499145\n",
      "epoch: 8 step: 1779, loss is 0.000941199716180563\n",
      "epoch: 8 step: 1780, loss is 0.0017947221640497446\n",
      "epoch: 8 step: 1781, loss is 0.00954983476549387\n",
      "epoch: 8 step: 1782, loss is 6.863580347271636e-05\n",
      "epoch: 8 step: 1783, loss is 0.09189164638519287\n",
      "epoch: 8 step: 1784, loss is 0.0003523936029523611\n",
      "epoch: 8 step: 1785, loss is 0.017901021987199783\n",
      "epoch: 8 step: 1786, loss is 0.0002950729976873845\n",
      "epoch: 8 step: 1787, loss is 0.0023614305537194014\n",
      "epoch: 8 step: 1788, loss is 0.00244374037720263\n",
      "epoch: 8 step: 1789, loss is 0.05155935138463974\n",
      "epoch: 8 step: 1790, loss is 0.00019500475900713354\n",
      "epoch: 8 step: 1791, loss is 0.000159753137268126\n",
      "epoch: 8 step: 1792, loss is 0.0028386812191456556\n",
      "epoch: 8 step: 1793, loss is 3.122477210126817e-05\n",
      "epoch: 8 step: 1794, loss is 5.399941801442765e-05\n",
      "epoch: 8 step: 1795, loss is 0.006810375954955816\n",
      "epoch: 8 step: 1796, loss is 6.802775169489905e-05\n",
      "epoch: 8 step: 1797, loss is 0.000683894322719425\n",
      "epoch: 8 step: 1798, loss is 0.0002123540180036798\n",
      "epoch: 8 step: 1799, loss is 0.0003068398800678551\n",
      "epoch: 8 step: 1800, loss is 0.00980474054813385\n",
      "epoch: 8 step: 1801, loss is 0.014717398211359978\n",
      "epoch: 8 step: 1802, loss is 0.00019738395349122584\n",
      "epoch: 8 step: 1803, loss is 0.0003044740005861968\n",
      "epoch: 8 step: 1804, loss is 0.0003956671862397343\n",
      "epoch: 8 step: 1805, loss is 0.22303010523319244\n",
      "epoch: 8 step: 1806, loss is 0.000847373332362622\n",
      "epoch: 8 step: 1807, loss is 0.0009681283263489604\n",
      "epoch: 8 step: 1808, loss is 0.0004600185784511268\n",
      "epoch: 8 step: 1809, loss is 2.01754410227295e-05\n",
      "epoch: 8 step: 1810, loss is 0.08216764032840729\n",
      "epoch: 8 step: 1811, loss is 5.8606325183063745e-05\n",
      "epoch: 8 step: 1812, loss is 0.02034137398004532\n",
      "epoch: 8 step: 1813, loss is 0.0019366105552762747\n",
      "epoch: 8 step: 1814, loss is 0.0005790835712105036\n",
      "epoch: 8 step: 1815, loss is 6.516480061691254e-05\n",
      "epoch: 8 step: 1816, loss is 0.0001356688590021804\n",
      "epoch: 8 step: 1817, loss is 1.9942361177527346e-05\n",
      "epoch: 8 step: 1818, loss is 0.0008117867400869727\n",
      "epoch: 8 step: 1819, loss is 0.0001089691577362828\n",
      "epoch: 8 step: 1820, loss is 0.0022504900116473436\n",
      "epoch: 8 step: 1821, loss is 0.00024593828129582107\n",
      "epoch: 8 step: 1822, loss is 0.00046379328705370426\n",
      "epoch: 8 step: 1823, loss is 2.522622889955528e-05\n",
      "epoch: 8 step: 1824, loss is 0.0006713189650326967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1825, loss is 0.02087157592177391\n",
      "epoch: 8 step: 1826, loss is 4.108864959562197e-05\n",
      "epoch: 8 step: 1827, loss is 1.2379678992147092e-05\n",
      "epoch: 8 step: 1828, loss is 0.02915564365684986\n",
      "epoch: 8 step: 1829, loss is 0.06915941834449768\n",
      "epoch: 8 step: 1830, loss is 0.0016516773030161858\n",
      "epoch: 8 step: 1831, loss is 0.001271235872991383\n",
      "epoch: 8 step: 1832, loss is 0.2239920049905777\n",
      "epoch: 8 step: 1833, loss is 0.0013736551627516747\n",
      "epoch: 8 step: 1834, loss is 0.0005487115122377872\n",
      "epoch: 8 step: 1835, loss is 0.10613226890563965\n",
      "epoch: 8 step: 1836, loss is 2.948474866570905e-05\n",
      "epoch: 8 step: 1837, loss is 0.00805068202316761\n",
      "epoch: 8 step: 1838, loss is 0.0007311654626391828\n",
      "epoch: 8 step: 1839, loss is 0.022004472091794014\n",
      "epoch: 8 step: 1840, loss is 0.015997543931007385\n",
      "epoch: 8 step: 1841, loss is 0.0013866833178326488\n",
      "epoch: 8 step: 1842, loss is 0.010548226535320282\n",
      "epoch: 8 step: 1843, loss is 0.049275562167167664\n",
      "epoch: 8 step: 1844, loss is 0.01541865523904562\n",
      "epoch: 8 step: 1845, loss is 0.03329959884285927\n",
      "epoch: 8 step: 1846, loss is 0.0006032490637153387\n",
      "epoch: 8 step: 1847, loss is 0.02739511802792549\n",
      "epoch: 8 step: 1848, loss is 0.000588498602155596\n",
      "epoch: 8 step: 1849, loss is 0.00010658262181095779\n",
      "epoch: 8 step: 1850, loss is 0.015607560984790325\n",
      "epoch: 8 step: 1851, loss is 0.13641603291034698\n",
      "epoch: 8 step: 1852, loss is 0.00039244414074346423\n",
      "epoch: 8 step: 1853, loss is 0.04911147058010101\n",
      "epoch: 8 step: 1854, loss is 3.941572504118085e-05\n",
      "epoch: 8 step: 1855, loss is 0.0010654942598193884\n",
      "epoch: 8 step: 1856, loss is 0.003310937900096178\n",
      "epoch: 8 step: 1857, loss is 0.0015405918238684535\n",
      "epoch: 8 step: 1858, loss is 0.004464765544980764\n",
      "epoch: 8 step: 1859, loss is 0.044709447771310806\n",
      "epoch: 8 step: 1860, loss is 0.001814632210880518\n",
      "epoch: 8 step: 1861, loss is 0.000884253007825464\n",
      "epoch: 8 step: 1862, loss is 0.0037560192868113518\n",
      "epoch: 8 step: 1863, loss is 0.3601166307926178\n",
      "epoch: 8 step: 1864, loss is 0.0001455244782846421\n",
      "epoch: 8 step: 1865, loss is 0.0004907372058369219\n",
      "epoch: 8 step: 1866, loss is 0.00016086209507193416\n",
      "epoch: 8 step: 1867, loss is 0.0007460025954060256\n",
      "epoch: 8 step: 1868, loss is 0.02985510602593422\n",
      "epoch: 8 step: 1869, loss is 0.0005428001168183982\n",
      "epoch: 8 step: 1870, loss is 0.04661932587623596\n",
      "epoch: 8 step: 1871, loss is 0.13438917696475983\n",
      "epoch: 8 step: 1872, loss is 0.031008629128336906\n",
      "epoch: 8 step: 1873, loss is 0.0005901188123971224\n",
      "epoch: 8 step: 1874, loss is 0.00016836806025821716\n",
      "epoch: 8 step: 1875, loss is 0.00017637629935052246\n",
      "epoch: 8 step: 1876, loss is 0.00020877955830655992\n",
      "epoch: 8 step: 1877, loss is 0.030406301841139793\n",
      "epoch: 8 step: 1878, loss is 0.0029976465739309788\n",
      "epoch: 8 step: 1879, loss is 0.0006882539018988609\n",
      "epoch: 8 step: 1880, loss is 0.0004571453027892858\n",
      "epoch: 8 step: 1881, loss is 0.004271066281944513\n",
      "epoch: 8 step: 1882, loss is 0.0013293002266436815\n",
      "epoch: 8 step: 1883, loss is 0.00020363691146485507\n",
      "epoch: 8 step: 1884, loss is 0.05359626188874245\n",
      "epoch: 8 step: 1885, loss is 0.006544962525367737\n",
      "epoch: 8 step: 1886, loss is 0.001886869315057993\n",
      "epoch: 8 step: 1887, loss is 0.0076357703655958176\n",
      "epoch: 8 step: 1888, loss is 0.005130312405526638\n",
      "epoch: 8 step: 1889, loss is 0.002543159993365407\n",
      "epoch: 8 step: 1890, loss is 0.022694433107972145\n",
      "epoch: 8 step: 1891, loss is 0.061666715890169144\n",
      "epoch: 8 step: 1892, loss is 0.23533502221107483\n",
      "epoch: 8 step: 1893, loss is 0.005351498257368803\n",
      "epoch: 8 step: 1894, loss is 0.00024149479577317834\n",
      "epoch: 8 step: 1895, loss is 0.02914181537926197\n",
      "epoch: 8 step: 1896, loss is 2.3495511413784698e-05\n",
      "epoch: 8 step: 1897, loss is 0.00022936919413041323\n",
      "epoch: 8 step: 1898, loss is 0.0014292929554358125\n",
      "epoch: 8 step: 1899, loss is 0.09987226873636246\n",
      "epoch: 8 step: 1900, loss is 0.02050654962658882\n",
      "epoch: 8 step: 1901, loss is 0.04476298391819\n",
      "epoch: 8 step: 1902, loss is 0.07545533031225204\n",
      "epoch: 8 step: 1903, loss is 9.47598964557983e-05\n",
      "epoch: 8 step: 1904, loss is 0.07948774099349976\n",
      "epoch: 8 step: 1905, loss is 0.0019618715159595013\n",
      "epoch: 8 step: 1906, loss is 0.0009245484252460301\n",
      "epoch: 8 step: 1907, loss is 0.041131071746349335\n",
      "epoch: 8 step: 1908, loss is 0.02595640905201435\n",
      "epoch: 8 step: 1909, loss is 0.14247414469718933\n",
      "epoch: 8 step: 1910, loss is 0.00031503173522651196\n",
      "epoch: 8 step: 1911, loss is 0.04502434283494949\n",
      "epoch: 8 step: 1912, loss is 0.00029589131008833647\n",
      "epoch: 8 step: 1913, loss is 0.006399448495358229\n",
      "epoch: 8 step: 1914, loss is 0.012174170464277267\n",
      "epoch: 8 step: 1915, loss is 0.000350073300069198\n",
      "epoch: 8 step: 1916, loss is 0.00015554031415376812\n",
      "epoch: 8 step: 1917, loss is 0.0017921627731993794\n",
      "epoch: 8 step: 1918, loss is 0.06278763711452484\n",
      "epoch: 8 step: 1919, loss is 0.00019501270435284823\n",
      "epoch: 8 step: 1920, loss is 0.011153657920658588\n",
      "epoch: 8 step: 1921, loss is 0.00039907178143039346\n",
      "epoch: 8 step: 1922, loss is 0.03140074387192726\n",
      "epoch: 8 step: 1923, loss is 0.0003713949990924448\n",
      "epoch: 8 step: 1924, loss is 0.0009207829716615379\n",
      "epoch: 8 step: 1925, loss is 0.002941147657111287\n",
      "epoch: 8 step: 1926, loss is 0.000967974541708827\n",
      "epoch: 8 step: 1927, loss is 0.001790159847587347\n",
      "epoch: 8 step: 1928, loss is 0.05252275988459587\n",
      "epoch: 8 step: 1929, loss is 0.021426012739539146\n",
      "epoch: 8 step: 1930, loss is 0.004692378919571638\n",
      "epoch: 8 step: 1931, loss is 0.02106868289411068\n",
      "epoch: 8 step: 1932, loss is 0.07476833462715149\n",
      "epoch: 8 step: 1933, loss is 0.00035775190917775035\n",
      "epoch: 8 step: 1934, loss is 0.0071382890455424786\n",
      "epoch: 8 step: 1935, loss is 0.0004154552589170635\n",
      "epoch: 8 step: 1936, loss is 0.0037532011047005653\n",
      "epoch: 8 step: 1937, loss is 0.00012099170999135822\n",
      "epoch: 8 step: 1938, loss is 9.04533953871578e-06\n",
      "epoch: 8 step: 1939, loss is 0.002186998724937439\n",
      "epoch: 8 step: 1940, loss is 0.0015089581720530987\n",
      "epoch: 8 step: 1941, loss is 0.0001675644307397306\n",
      "epoch: 8 step: 1942, loss is 0.0036028637550771236\n",
      "epoch: 8 step: 1943, loss is 0.3121193051338196\n",
      "epoch: 8 step: 1944, loss is 0.00041304860496893525\n",
      "epoch: 8 step: 1945, loss is 0.0024050623178482056\n",
      "epoch: 8 step: 1946, loss is 0.0037805342581123114\n",
      "epoch: 8 step: 1947, loss is 0.00020233273971825838\n",
      "epoch: 8 step: 1948, loss is 4.2123254388570786e-05\n",
      "epoch: 8 step: 1949, loss is 0.004605581052601337\n",
      "epoch: 8 step: 1950, loss is 0.009883591905236244\n",
      "epoch: 8 step: 1951, loss is 0.0005491378251463175\n",
      "epoch: 8 step: 1952, loss is 0.0011915673967450857\n",
      "epoch: 8 step: 1953, loss is 3.3190859539899975e-05\n",
      "epoch: 8 step: 1954, loss is 0.005343714728951454\n",
      "epoch: 8 step: 1955, loss is 0.003972964361310005\n",
      "epoch: 8 step: 1956, loss is 0.03911199793219566\n",
      "epoch: 8 step: 1957, loss is 0.00019072197028435767\n",
      "epoch: 8 step: 1958, loss is 0.0005942968418821692\n",
      "epoch: 8 step: 1959, loss is 0.00026445367257110775\n",
      "epoch: 8 step: 1960, loss is 0.0018242101650685072\n",
      "epoch: 8 step: 1961, loss is 0.00023830399732105434\n",
      "epoch: 8 step: 1962, loss is 0.04011436924338341\n",
      "epoch: 8 step: 1963, loss is 0.022584596648812294\n",
      "epoch: 8 step: 1964, loss is 0.055606190115213394\n",
      "epoch: 8 step: 1965, loss is 8.93908945727162e-05\n",
      "epoch: 8 step: 1966, loss is 0.0002909271861426532\n",
      "epoch: 8 step: 1967, loss is 0.009596512652933598\n",
      "epoch: 8 step: 1968, loss is 0.035424549132585526\n",
      "epoch: 8 step: 1969, loss is 0.025580210611224174\n",
      "epoch: 8 step: 1970, loss is 0.0010423860512673855\n",
      "epoch: 8 step: 1971, loss is 0.06537369638681412\n",
      "epoch: 8 step: 1972, loss is 0.0006274127517826855\n",
      "epoch: 8 step: 1973, loss is 0.01311404723674059\n",
      "epoch: 8 step: 1974, loss is 0.003420008812099695\n",
      "epoch: 8 step: 1975, loss is 0.0009673826862126589\n",
      "epoch: 8 step: 1976, loss is 0.011701276525855064\n",
      "epoch: 8 step: 1977, loss is 0.03295193612575531\n",
      "epoch: 8 step: 1978, loss is 0.0006052806274965405\n",
      "epoch: 8 step: 1979, loss is 0.0002429717715131119\n",
      "epoch: 8 step: 1980, loss is 0.0007038134499453008\n",
      "epoch: 8 step: 1981, loss is 0.007310195825994015\n",
      "epoch: 8 step: 1982, loss is 0.0019165141275152564\n",
      "epoch: 8 step: 1983, loss is 0.025402994826436043\n",
      "epoch: 8 step: 1984, loss is 0.0014624092727899551\n",
      "epoch: 8 step: 1985, loss is 0.0006906449561938643\n",
      "epoch: 8 step: 1986, loss is 0.0020295120775699615\n",
      "epoch: 8 step: 1987, loss is 0.0031211315654218197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1988, loss is 0.007127983029931784\n",
      "epoch: 8 step: 1989, loss is 8.597604028182104e-05\n",
      "epoch: 8 step: 1990, loss is 0.004320589359849691\n",
      "epoch: 8 step: 1991, loss is 0.012340674176812172\n",
      "epoch: 8 step: 1992, loss is 0.00011524988076416776\n",
      "epoch: 8 step: 1993, loss is 0.03507809340953827\n",
      "epoch: 8 step: 1994, loss is 0.01741374470293522\n",
      "epoch: 8 step: 1995, loss is 0.00010452375136082992\n",
      "epoch: 8 step: 1996, loss is 0.0002704031066969037\n",
      "epoch: 8 step: 1997, loss is 1.2051674275426194e-05\n",
      "epoch: 8 step: 1998, loss is 0.0002687532687559724\n",
      "epoch: 8 step: 1999, loss is 0.0007145149284042418\n",
      "epoch: 8 step: 2000, loss is 0.008860844187438488\n",
      "epoch: 8 step: 2001, loss is 0.09905251115560532\n",
      "epoch: 8 step: 2002, loss is 0.015221036039292812\n",
      "epoch: 8 step: 2003, loss is 0.035424914211034775\n",
      "epoch: 8 step: 2004, loss is 0.12328691780567169\n",
      "epoch: 8 step: 2005, loss is 1.6503956430824474e-05\n",
      "epoch: 8 step: 2006, loss is 0.001999608241021633\n",
      "epoch: 8 step: 2007, loss is 0.010074064135551453\n",
      "epoch: 8 step: 2008, loss is 8.411810995312408e-05\n",
      "epoch: 8 step: 2009, loss is 7.07823783159256e-05\n",
      "epoch: 8 step: 2010, loss is 0.005555459763854742\n",
      "epoch: 8 step: 2011, loss is 0.00039725645910948515\n",
      "epoch: 8 step: 2012, loss is 0.004611106589436531\n",
      "epoch: 8 step: 2013, loss is 0.004567040596157312\n",
      "epoch: 8 step: 2014, loss is 0.0001798329467419535\n",
      "epoch: 8 step: 2015, loss is 0.0027723214589059353\n",
      "epoch: 8 step: 2016, loss is 6.573112477781251e-05\n",
      "epoch: 8 step: 2017, loss is 0.0004024494846817106\n",
      "epoch: 8 step: 2018, loss is 0.009908303618431091\n",
      "epoch: 8 step: 2019, loss is 0.000740395684260875\n",
      "epoch: 8 step: 2020, loss is 0.011420122347772121\n",
      "epoch: 8 step: 2021, loss is 0.022274192422628403\n",
      "epoch: 8 step: 2022, loss is 0.0014135647797957063\n",
      "epoch: 8 step: 2023, loss is 0.0019385218620300293\n",
      "epoch: 8 step: 2024, loss is 2.6686595447245054e-05\n",
      "epoch: 8 step: 2025, loss is 0.001255100010894239\n",
      "epoch: 8 step: 2026, loss is 0.01564321480691433\n",
      "epoch: 8 step: 2027, loss is 0.004927743226289749\n",
      "epoch: 8 step: 2028, loss is 0.00014394632307812572\n",
      "epoch: 8 step: 2029, loss is 0.00024664716329425573\n",
      "epoch: 8 step: 2030, loss is 0.0011439445661380887\n",
      "epoch: 8 step: 2031, loss is 9.020621655508876e-05\n",
      "epoch: 8 step: 2032, loss is 0.00014883637777529657\n",
      "epoch: 8 step: 2033, loss is 0.015740402042865753\n",
      "epoch: 8 step: 2034, loss is 0.011346984654664993\n",
      "epoch: 8 step: 2035, loss is 0.027112968266010284\n",
      "epoch: 8 step: 2036, loss is 0.06812012195587158\n",
      "epoch: 8 step: 2037, loss is 0.005584084894508123\n",
      "epoch: 8 step: 2038, loss is 7.474670564988628e-05\n",
      "epoch: 8 step: 2039, loss is 0.0010127131827175617\n",
      "epoch: 8 step: 2040, loss is 0.00239903898909688\n",
      "epoch: 8 step: 2041, loss is 4.00157950934954e-05\n",
      "epoch: 8 step: 2042, loss is 0.006022939924150705\n",
      "epoch: 8 step: 2043, loss is 0.025402182713150978\n",
      "epoch: 8 step: 2044, loss is 0.000300361163681373\n",
      "epoch: 8 step: 2045, loss is 0.049182385206222534\n",
      "epoch: 8 step: 2046, loss is 0.0008238211157731712\n",
      "epoch: 8 step: 2047, loss is 0.00033817876828834414\n",
      "epoch: 8 step: 2048, loss is 0.07459325343370438\n",
      "epoch: 8 step: 2049, loss is 0.0048750825226306915\n",
      "epoch: 8 step: 2050, loss is 0.00011462172551546246\n",
      "epoch: 8 step: 2051, loss is 0.04383332282304764\n",
      "epoch: 8 step: 2052, loss is 0.002317465841770172\n",
      "epoch: 8 step: 2053, loss is 0.0005005265702493489\n",
      "epoch: 8 step: 2054, loss is 0.056696824729442596\n",
      "epoch: 8 step: 2055, loss is 0.002613039454445243\n",
      "epoch: 8 step: 2056, loss is 0.0034414164256304502\n",
      "epoch: 8 step: 2057, loss is 0.002372182672843337\n",
      "epoch: 8 step: 2058, loss is 0.0001309950021095574\n",
      "epoch: 8 step: 2059, loss is 0.10232791304588318\n",
      "epoch: 8 step: 2060, loss is 0.000132871326059103\n",
      "epoch: 8 step: 2061, loss is 0.13817287981510162\n",
      "epoch: 8 step: 2062, loss is 0.0002094118535751477\n",
      "epoch: 8 step: 2063, loss is 0.13865862786769867\n",
      "epoch: 8 step: 2064, loss is 0.00016973128367681056\n",
      "epoch: 8 step: 2065, loss is 0.09242503345012665\n",
      "epoch: 8 step: 2066, loss is 0.00025478689349256456\n",
      "epoch: 8 step: 2067, loss is 0.0008714930154383183\n",
      "epoch: 8 step: 2068, loss is 0.13293538987636566\n",
      "epoch: 8 step: 2069, loss is 0.000770522456150502\n",
      "epoch: 8 step: 2070, loss is 0.0005088764009997249\n",
      "epoch: 8 step: 2071, loss is 0.00019132200395688415\n",
      "epoch: 8 step: 2072, loss is 0.13309499621391296\n",
      "epoch: 8 step: 2073, loss is 8.625256305094808e-05\n",
      "epoch: 8 step: 2074, loss is 0.011033526621758938\n",
      "epoch: 8 step: 2075, loss is 0.004445266909897327\n",
      "epoch: 8 step: 2076, loss is 0.00042445873259566724\n",
      "epoch: 8 step: 2077, loss is 0.0008311485289596021\n",
      "epoch: 8 step: 2078, loss is 0.002710760571062565\n",
      "epoch: 8 step: 2079, loss is 0.14235149323940277\n",
      "epoch: 8 step: 2080, loss is 0.0009032392990775406\n",
      "epoch: 8 step: 2081, loss is 0.003591756569221616\n",
      "epoch: 8 step: 2082, loss is 0.0002953821967821568\n",
      "epoch: 8 step: 2083, loss is 0.0038110758177936077\n",
      "epoch: 8 step: 2084, loss is 0.04060124233365059\n",
      "epoch: 8 step: 2085, loss is 0.003105775685980916\n",
      "epoch: 8 step: 2086, loss is 0.0013163917465135455\n",
      "epoch: 8 step: 2087, loss is 0.00039376021595671773\n",
      "epoch: 8 step: 2088, loss is 0.02064100094139576\n",
      "epoch: 8 step: 2089, loss is 0.00014204259787220508\n",
      "epoch: 8 step: 2090, loss is 0.014812744222581387\n",
      "epoch: 8 step: 2091, loss is 0.0011910927714779973\n",
      "epoch: 8 step: 2092, loss is 0.0006099752499721944\n",
      "epoch: 8 step: 2093, loss is 0.0008031775359995663\n",
      "epoch: 8 step: 2094, loss is 0.00011547015310497954\n",
      "epoch: 8 step: 2095, loss is 0.009664911776781082\n",
      "epoch: 8 step: 2096, loss is 0.03883415460586548\n",
      "epoch: 8 step: 2097, loss is 0.012633250094950199\n",
      "epoch: 8 step: 2098, loss is 0.0022211316972970963\n",
      "epoch: 8 step: 2099, loss is 0.019911551848053932\n",
      "epoch: 8 step: 2100, loss is 0.00018760647799354047\n",
      "epoch: 8 step: 2101, loss is 0.0006243522511795163\n",
      "epoch: 8 step: 2102, loss is 0.004335800651460886\n",
      "epoch: 8 step: 2103, loss is 0.0027895558159798384\n",
      "epoch: 8 step: 2104, loss is 0.004370575305074453\n",
      "epoch: 8 step: 2105, loss is 0.0055504352785646915\n",
      "epoch: 8 step: 2106, loss is 0.00016616401262581348\n",
      "epoch: 8 step: 2107, loss is 0.1798793524503708\n",
      "epoch: 8 step: 2108, loss is 0.024662384763360023\n",
      "epoch: 8 step: 2109, loss is 0.17545872926712036\n",
      "epoch: 8 step: 2110, loss is 0.022643066942691803\n",
      "epoch: 8 step: 2111, loss is 0.09505755454301834\n",
      "epoch: 8 step: 2112, loss is 0.00031693748314864933\n",
      "epoch: 8 step: 2113, loss is 0.00027426506858319044\n",
      "epoch: 8 step: 2114, loss is 0.006346970796585083\n",
      "epoch: 8 step: 2115, loss is 0.019274570047855377\n",
      "epoch: 8 step: 2116, loss is 0.000539537169970572\n",
      "epoch: 8 step: 2117, loss is 0.004294290207326412\n",
      "epoch: 8 step: 2118, loss is 0.0013535046018660069\n",
      "epoch: 8 step: 2119, loss is 0.001947937998920679\n",
      "epoch: 8 step: 2120, loss is 0.001034331158734858\n",
      "epoch: 8 step: 2121, loss is 0.02438562922179699\n",
      "epoch: 8 step: 2122, loss is 0.0032891544979065657\n",
      "epoch: 8 step: 2123, loss is 0.0036702968645840883\n",
      "epoch: 8 step: 2124, loss is 0.0065361433662474155\n",
      "epoch: 8 step: 2125, loss is 0.04304325208067894\n",
      "epoch: 8 step: 2126, loss is 0.0021095527336001396\n",
      "epoch: 8 step: 2127, loss is 0.04514382779598236\n",
      "epoch: 8 step: 2128, loss is 0.0005296356976032257\n",
      "epoch: 8 step: 2129, loss is 0.019598137587308884\n",
      "epoch: 8 step: 2130, loss is 0.17679233849048615\n",
      "epoch: 8 step: 2131, loss is 0.012686747126281261\n",
      "epoch: 8 step: 2132, loss is 0.010389979928731918\n",
      "epoch: 8 step: 2133, loss is 0.03652198612689972\n",
      "epoch: 8 step: 2134, loss is 0.0008887509466148913\n",
      "epoch: 8 step: 2135, loss is 0.0014034740161150694\n",
      "epoch: 8 step: 2136, loss is 0.004356519319117069\n",
      "epoch: 8 step: 2137, loss is 0.001045105280354619\n",
      "epoch: 8 step: 2138, loss is 0.006831542123109102\n",
      "epoch: 8 step: 2139, loss is 0.016553184017539024\n",
      "epoch: 8 step: 2140, loss is 0.00020338896138127893\n",
      "epoch: 8 step: 2141, loss is 0.00040683153201825917\n",
      "epoch: 8 step: 2142, loss is 0.0024637936148792505\n",
      "epoch: 8 step: 2143, loss is 0.0009080417221412063\n",
      "epoch: 8 step: 2144, loss is 0.01884521171450615\n",
      "epoch: 8 step: 2145, loss is 0.0002297747996635735\n",
      "epoch: 8 step: 2146, loss is 0.0013499186607077718\n",
      "epoch: 8 step: 2147, loss is 0.15312358736991882\n",
      "epoch: 8 step: 2148, loss is 0.0015666268300265074\n",
      "epoch: 8 step: 2149, loss is 0.08451879024505615\n",
      "epoch: 8 step: 2150, loss is 0.0004626648733392358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 2151, loss is 0.0026053886394947767\n",
      "epoch: 8 step: 2152, loss is 8.840137888910249e-05\n",
      "epoch: 8 step: 2153, loss is 0.0034521659836173058\n",
      "epoch: 8 step: 2154, loss is 0.049729373306035995\n",
      "epoch: 8 step: 2155, loss is 0.0002034986246144399\n",
      "epoch: 8 step: 2156, loss is 0.0017253676196560264\n",
      "epoch: 8 step: 2157, loss is 0.004485637415200472\n",
      "epoch: 8 step: 2158, loss is 0.004880872555077076\n",
      "epoch: 8 step: 2159, loss is 0.0002772677398752421\n",
      "epoch: 8 step: 2160, loss is 0.006165204104036093\n",
      "epoch: 8 step: 2161, loss is 0.0011872815666720271\n",
      "epoch: 8 step: 2162, loss is 0.004313481505960226\n",
      "epoch: 8 step: 2163, loss is 0.0005551623180508614\n",
      "epoch: 8 step: 2164, loss is 0.0012666676193475723\n",
      "epoch: 8 step: 2165, loss is 0.016744717955589294\n",
      "epoch: 8 step: 2166, loss is 0.04235866665840149\n",
      "epoch: 8 step: 2167, loss is 0.0037760736886411905\n",
      "epoch: 8 step: 2168, loss is 0.0010133133037015796\n",
      "epoch: 8 step: 2169, loss is 0.000794844760093838\n",
      "epoch: 8 step: 2170, loss is 0.0029837321490049362\n",
      "epoch: 8 step: 2171, loss is 0.003236451419070363\n",
      "epoch: 8 step: 2172, loss is 0.0013206496369093657\n",
      "epoch: 8 step: 2173, loss is 0.004943097475916147\n",
      "epoch: 8 step: 2174, loss is 0.0001259569253306836\n",
      "epoch: 8 step: 2175, loss is 0.00013162862160243094\n",
      "epoch: 8 step: 2176, loss is 0.0021385394502431154\n",
      "epoch: 8 step: 2177, loss is 2.0979417968192138e-05\n",
      "epoch: 8 step: 2178, loss is 0.0008982804138213396\n",
      "epoch: 8 step: 2179, loss is 0.19722604751586914\n",
      "epoch: 8 step: 2180, loss is 0.0009046961204148829\n",
      "epoch: 8 step: 2181, loss is 0.001611302956007421\n",
      "epoch: 8 step: 2182, loss is 0.0902608260512352\n",
      "epoch: 8 step: 2183, loss is 0.003942335024476051\n",
      "epoch: 8 step: 2184, loss is 0.00021032345830462873\n",
      "epoch: 8 step: 2185, loss is 0.003713697660714388\n",
      "epoch: 8 step: 2186, loss is 0.005057108588516712\n",
      "epoch: 8 step: 2187, loss is 0.10149471461772919\n",
      "epoch: 9 step: 1, loss is 0.018472861498594284\n",
      "epoch: 9 step: 2, loss is 0.005407275632023811\n",
      "epoch: 9 step: 3, loss is 0.0002408321452094242\n",
      "epoch: 9 step: 4, loss is 0.0004367802175693214\n",
      "epoch: 9 step: 5, loss is 0.053983114659786224\n",
      "epoch: 9 step: 6, loss is 0.00037480282480828464\n",
      "epoch: 9 step: 7, loss is 0.0028214340563863516\n",
      "epoch: 9 step: 8, loss is 0.006701777223497629\n",
      "epoch: 9 step: 9, loss is 0.005511792842298746\n",
      "epoch: 9 step: 10, loss is 0.0026150960475206375\n",
      "epoch: 9 step: 11, loss is 0.0004548959550447762\n",
      "epoch: 9 step: 12, loss is 0.00036031039780937135\n",
      "epoch: 9 step: 13, loss is 0.00044832154526375234\n",
      "epoch: 9 step: 14, loss is 0.0016349562210962176\n",
      "epoch: 9 step: 15, loss is 0.0002505468437448144\n",
      "epoch: 9 step: 16, loss is 0.00023891878663562238\n",
      "epoch: 9 step: 17, loss is 0.00456557422876358\n",
      "epoch: 9 step: 18, loss is 0.0010377964936196804\n",
      "epoch: 9 step: 19, loss is 0.00688940891996026\n",
      "epoch: 9 step: 20, loss is 0.0001602107658982277\n",
      "epoch: 9 step: 21, loss is 0.01871972158551216\n",
      "epoch: 9 step: 22, loss is 0.01744767650961876\n",
      "epoch: 9 step: 23, loss is 0.0017199781723320484\n",
      "epoch: 9 step: 24, loss is 0.03812183812260628\n",
      "epoch: 9 step: 25, loss is 0.002727157436311245\n",
      "epoch: 9 step: 26, loss is 0.11459778249263763\n",
      "epoch: 9 step: 27, loss is 0.0063342321664094925\n",
      "epoch: 9 step: 28, loss is 0.0020290629472583532\n",
      "epoch: 9 step: 29, loss is 0.0002543664595577866\n",
      "epoch: 9 step: 30, loss is 0.00464597949758172\n",
      "epoch: 9 step: 31, loss is 0.0031378231942653656\n",
      "epoch: 9 step: 32, loss is 0.0014164845924824476\n",
      "epoch: 9 step: 33, loss is 0.00016456074081361294\n",
      "epoch: 9 step: 34, loss is 0.034883931279182434\n",
      "epoch: 9 step: 35, loss is 0.000655492942314595\n",
      "epoch: 9 step: 36, loss is 0.021078424528241158\n",
      "epoch: 9 step: 37, loss is 0.05803656205534935\n",
      "epoch: 9 step: 38, loss is 0.0007003839127719402\n",
      "epoch: 9 step: 39, loss is 0.0722399652004242\n",
      "epoch: 9 step: 40, loss is 0.0012497205752879381\n",
      "epoch: 9 step: 41, loss is 0.001352444407530129\n",
      "epoch: 9 step: 42, loss is 0.12812523543834686\n",
      "epoch: 9 step: 43, loss is 0.008045678026974201\n",
      "epoch: 9 step: 44, loss is 0.0019692436326295137\n",
      "epoch: 9 step: 45, loss is 0.018488887697458267\n",
      "epoch: 9 step: 46, loss is 0.015441951341927052\n",
      "epoch: 9 step: 47, loss is 0.03806914761662483\n",
      "epoch: 9 step: 48, loss is 0.04240665212273598\n",
      "epoch: 9 step: 49, loss is 0.0053358860313892365\n",
      "epoch: 9 step: 50, loss is 0.00046331319026649\n",
      "epoch: 9 step: 51, loss is 0.0043127266690135\n",
      "epoch: 9 step: 52, loss is 0.0005221088649705052\n",
      "epoch: 9 step: 53, loss is 0.000176066008862108\n",
      "epoch: 9 step: 54, loss is 0.00022227289446163923\n",
      "epoch: 9 step: 55, loss is 0.008790896274149418\n",
      "epoch: 9 step: 56, loss is 0.0020076262298971415\n",
      "epoch: 9 step: 57, loss is 0.0013275713426992297\n",
      "epoch: 9 step: 58, loss is 0.00011223051842534915\n",
      "epoch: 9 step: 59, loss is 0.10419851541519165\n",
      "epoch: 9 step: 60, loss is 0.00011608941713348031\n",
      "epoch: 9 step: 61, loss is 0.00010723434388637543\n",
      "epoch: 9 step: 62, loss is 0.00010660717816790566\n",
      "epoch: 9 step: 63, loss is 3.498310979921371e-05\n",
      "epoch: 9 step: 64, loss is 2.8965299861738458e-05\n",
      "epoch: 9 step: 65, loss is 0.005978312809020281\n",
      "epoch: 9 step: 66, loss is 0.0005287613021209836\n",
      "epoch: 9 step: 67, loss is 0.0009302039397880435\n",
      "epoch: 9 step: 68, loss is 0.008462992496788502\n",
      "epoch: 9 step: 69, loss is 0.000523555965628475\n",
      "epoch: 9 step: 70, loss is 0.0005245666834525764\n",
      "epoch: 9 step: 71, loss is 8.510500629199669e-05\n",
      "epoch: 9 step: 72, loss is 0.0007021284545771778\n",
      "epoch: 9 step: 73, loss is 0.12557880580425262\n",
      "epoch: 9 step: 74, loss is 0.001068545039743185\n",
      "epoch: 9 step: 75, loss is 0.004108656197786331\n",
      "epoch: 9 step: 76, loss is 3.791748167714104e-05\n",
      "epoch: 9 step: 77, loss is 0.008176705799996853\n",
      "epoch: 9 step: 78, loss is 5.796999539597891e-05\n",
      "epoch: 9 step: 79, loss is 0.0005637060385197401\n",
      "epoch: 9 step: 80, loss is 0.00011985238961642608\n",
      "epoch: 9 step: 81, loss is 0.00024598962045274675\n",
      "epoch: 9 step: 82, loss is 0.0005785006214864552\n",
      "epoch: 9 step: 83, loss is 0.0006044359761290252\n",
      "epoch: 9 step: 84, loss is 0.040227994322776794\n",
      "epoch: 9 step: 85, loss is 0.00047002965584397316\n",
      "epoch: 9 step: 86, loss is 0.00033195168361999094\n",
      "epoch: 9 step: 87, loss is 0.00012394711666274816\n",
      "epoch: 9 step: 88, loss is 0.0004228560137562454\n",
      "epoch: 9 step: 89, loss is 0.00045269716065376997\n",
      "epoch: 9 step: 90, loss is 0.016464268788695335\n",
      "epoch: 9 step: 91, loss is 0.01613737642765045\n",
      "epoch: 9 step: 92, loss is 0.0005090273334644735\n",
      "epoch: 9 step: 93, loss is 0.0027008247561752796\n",
      "epoch: 9 step: 94, loss is 0.0023570999037474394\n",
      "epoch: 9 step: 95, loss is 0.00024089126964099705\n",
      "epoch: 9 step: 96, loss is 0.0010721542639657855\n",
      "epoch: 9 step: 97, loss is 0.0020766458474099636\n",
      "epoch: 9 step: 98, loss is 0.018262207508087158\n",
      "epoch: 9 step: 99, loss is 0.0032996200025081635\n",
      "epoch: 9 step: 100, loss is 0.00021514763648156077\n",
      "epoch: 9 step: 101, loss is 3.3619769965298474e-05\n",
      "epoch: 9 step: 102, loss is 0.0007629880565218627\n",
      "epoch: 9 step: 103, loss is 0.0010646668961271644\n",
      "epoch: 9 step: 104, loss is 0.007099833805114031\n",
      "epoch: 9 step: 105, loss is 0.0007459050975739956\n",
      "epoch: 9 step: 106, loss is 0.00023712942493148148\n",
      "epoch: 9 step: 107, loss is 0.0011597538832575083\n",
      "epoch: 9 step: 108, loss is 0.009230947121977806\n",
      "epoch: 9 step: 109, loss is 0.00031513217254541814\n",
      "epoch: 9 step: 110, loss is 0.00010045097587862983\n",
      "epoch: 9 step: 111, loss is 1.6567071725148708e-05\n",
      "epoch: 9 step: 112, loss is 0.0536358468234539\n",
      "epoch: 9 step: 113, loss is 0.00012562252231873572\n",
      "epoch: 9 step: 114, loss is 0.004155746195465326\n",
      "epoch: 9 step: 115, loss is 5.3099160140845925e-05\n",
      "epoch: 9 step: 116, loss is 0.001720291213132441\n",
      "epoch: 9 step: 117, loss is 0.00015972000255715102\n",
      "epoch: 9 step: 118, loss is 0.0004119837249163538\n",
      "epoch: 9 step: 119, loss is 0.0013993263710290194\n",
      "epoch: 9 step: 120, loss is 4.749307845486328e-05\n",
      "epoch: 9 step: 121, loss is 0.004741894546896219\n",
      "epoch: 9 step: 122, loss is 0.001637939945794642\n",
      "epoch: 9 step: 123, loss is 0.00970581267029047\n",
      "epoch: 9 step: 124, loss is 0.0010129724396392703\n",
      "epoch: 9 step: 125, loss is 0.025156062096357346\n",
      "epoch: 9 step: 126, loss is 0.027220549061894417\n",
      "epoch: 9 step: 127, loss is 0.06777825206518173\n",
      "epoch: 9 step: 128, loss is 0.0003977366432081908\n",
      "epoch: 9 step: 129, loss is 0.0009172129211947322\n",
      "epoch: 9 step: 130, loss is 0.00035443887463770807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 131, loss is 0.006547859869897366\n",
      "epoch: 9 step: 132, loss is 0.000650206464342773\n",
      "epoch: 9 step: 133, loss is 0.0013149543665349483\n",
      "epoch: 9 step: 134, loss is 0.009651902131736279\n",
      "epoch: 9 step: 135, loss is 0.003147939220070839\n",
      "epoch: 9 step: 136, loss is 0.03605087101459503\n",
      "epoch: 9 step: 137, loss is 0.0157094094902277\n",
      "epoch: 9 step: 138, loss is 0.00013247938477434218\n",
      "epoch: 9 step: 139, loss is 0.00048743817023932934\n",
      "epoch: 9 step: 140, loss is 0.0005579598946496844\n",
      "epoch: 9 step: 141, loss is 0.008545142598450184\n",
      "epoch: 9 step: 142, loss is 0.0008324474911205471\n",
      "epoch: 9 step: 143, loss is 0.013405011966824532\n",
      "epoch: 9 step: 144, loss is 0.0037985490635037422\n",
      "epoch: 9 step: 145, loss is 0.23637869954109192\n",
      "epoch: 9 step: 146, loss is 0.0013444451615214348\n",
      "epoch: 9 step: 147, loss is 0.0007317417184822261\n",
      "epoch: 9 step: 148, loss is 0.0017427181592211127\n",
      "epoch: 9 step: 149, loss is 0.000505783420521766\n",
      "epoch: 9 step: 150, loss is 0.0002644640626385808\n",
      "epoch: 9 step: 151, loss is 0.019921354949474335\n",
      "epoch: 9 step: 152, loss is 0.016127265989780426\n",
      "epoch: 9 step: 153, loss is 0.0003916864807251841\n",
      "epoch: 9 step: 154, loss is 0.0008473820053040981\n",
      "epoch: 9 step: 155, loss is 0.0014556993264704943\n",
      "epoch: 9 step: 156, loss is 0.003193369833752513\n",
      "epoch: 9 step: 157, loss is 0.00032399629708379507\n",
      "epoch: 9 step: 158, loss is 0.007079719565808773\n",
      "epoch: 9 step: 159, loss is 0.00039495632518082857\n",
      "epoch: 9 step: 160, loss is 0.0003440041618887335\n",
      "epoch: 9 step: 161, loss is 0.08019338548183441\n",
      "epoch: 9 step: 162, loss is 0.003239368787035346\n",
      "epoch: 9 step: 163, loss is 0.0006464683101512492\n",
      "epoch: 9 step: 164, loss is 0.0007558375946246088\n",
      "epoch: 9 step: 165, loss is 4.144015838392079e-05\n",
      "epoch: 9 step: 166, loss is 0.024344755336642265\n",
      "epoch: 9 step: 167, loss is 0.00014702115731779486\n",
      "epoch: 9 step: 168, loss is 0.0008481609984301031\n",
      "epoch: 9 step: 169, loss is 0.001384638249874115\n",
      "epoch: 9 step: 170, loss is 0.16320815682411194\n",
      "epoch: 9 step: 171, loss is 4.516033368417993e-05\n",
      "epoch: 9 step: 172, loss is 0.001905182609334588\n",
      "epoch: 9 step: 173, loss is 0.00025799163267947733\n",
      "epoch: 9 step: 174, loss is 0.1198909655213356\n",
      "epoch: 9 step: 175, loss is 0.008963880129158497\n",
      "epoch: 9 step: 176, loss is 0.00017400678189005703\n",
      "epoch: 9 step: 177, loss is 0.02099831961095333\n",
      "epoch: 9 step: 178, loss is 0.0029164908919483423\n",
      "epoch: 9 step: 179, loss is 0.00010086751717608422\n",
      "epoch: 9 step: 180, loss is 0.0011278425808995962\n",
      "epoch: 9 step: 181, loss is 0.0011961954878643155\n",
      "epoch: 9 step: 182, loss is 0.000592809054069221\n",
      "epoch: 9 step: 183, loss is 0.008839553222060204\n",
      "epoch: 9 step: 184, loss is 0.0036638560704886913\n",
      "epoch: 9 step: 185, loss is 8.70514995767735e-05\n",
      "epoch: 9 step: 186, loss is 0.0005626191268675029\n",
      "epoch: 9 step: 187, loss is 1.5360052202595398e-05\n",
      "epoch: 9 step: 188, loss is 0.00045954601955600083\n",
      "epoch: 9 step: 189, loss is 2.7074422177975066e-05\n",
      "epoch: 9 step: 190, loss is 0.006937344558537006\n",
      "epoch: 9 step: 191, loss is 0.0029060421511530876\n",
      "epoch: 9 step: 192, loss is 0.0009510649833828211\n",
      "epoch: 9 step: 193, loss is 0.0004076352925039828\n",
      "epoch: 9 step: 194, loss is 0.05150698870420456\n",
      "epoch: 9 step: 195, loss is 0.017796317115426064\n",
      "epoch: 9 step: 196, loss is 7.543736865045503e-05\n",
      "epoch: 9 step: 197, loss is 0.00246474239975214\n",
      "epoch: 9 step: 198, loss is 0.00019982826779596508\n",
      "epoch: 9 step: 199, loss is 0.0002886697184294462\n",
      "epoch: 9 step: 200, loss is 0.06776048988103867\n",
      "epoch: 9 step: 201, loss is 0.001452374504879117\n",
      "epoch: 9 step: 202, loss is 0.006206497550010681\n",
      "epoch: 9 step: 203, loss is 0.0013095689937472343\n",
      "epoch: 9 step: 204, loss is 2.747278631431982e-05\n",
      "epoch: 9 step: 205, loss is 0.00013959423813503236\n",
      "epoch: 9 step: 206, loss is 0.0018730789888650179\n",
      "epoch: 9 step: 207, loss is 0.0025429963134229183\n",
      "epoch: 9 step: 208, loss is 0.013810397125780582\n",
      "epoch: 9 step: 209, loss is 0.00031356376712210476\n",
      "epoch: 9 step: 210, loss is 0.0002230676618637517\n",
      "epoch: 9 step: 211, loss is 0.0009561332990415394\n",
      "epoch: 9 step: 212, loss is 6.214889435796067e-05\n",
      "epoch: 9 step: 213, loss is 0.0001200624683406204\n",
      "epoch: 9 step: 214, loss is 0.00013355478586163372\n",
      "epoch: 9 step: 215, loss is 0.0011980796698480844\n",
      "epoch: 9 step: 216, loss is 0.00014932300837244838\n",
      "epoch: 9 step: 217, loss is 0.0043027885258197784\n",
      "epoch: 9 step: 218, loss is 0.0009499923326075077\n",
      "epoch: 9 step: 219, loss is 0.00025704698055051267\n",
      "epoch: 9 step: 220, loss is 0.004519806243479252\n",
      "epoch: 9 step: 221, loss is 0.005869455169886351\n",
      "epoch: 9 step: 222, loss is 0.001164891174994409\n",
      "epoch: 9 step: 223, loss is 0.0009277416975237429\n",
      "epoch: 9 step: 224, loss is 0.00027142546605318785\n",
      "epoch: 9 step: 225, loss is 0.016309266909956932\n",
      "epoch: 9 step: 226, loss is 0.007668857928365469\n",
      "epoch: 9 step: 227, loss is 0.0009447559132240713\n",
      "epoch: 9 step: 228, loss is 0.00035505450796335936\n",
      "epoch: 9 step: 229, loss is 0.0006469557993113995\n",
      "epoch: 9 step: 230, loss is 0.0003329543396830559\n",
      "epoch: 9 step: 231, loss is 0.0011773768346756697\n",
      "epoch: 9 step: 232, loss is 0.007965014316141605\n",
      "epoch: 9 step: 233, loss is 0.0002555737446527928\n",
      "epoch: 9 step: 234, loss is 0.0022483416832983494\n",
      "epoch: 9 step: 235, loss is 0.0002983970916830003\n",
      "epoch: 9 step: 236, loss is 0.025630908086895943\n",
      "epoch: 9 step: 237, loss is 0.0001852638233685866\n",
      "epoch: 9 step: 238, loss is 0.00023780390620231628\n",
      "epoch: 9 step: 239, loss is 0.00046971606207080185\n",
      "epoch: 9 step: 240, loss is 0.00021491690131369978\n",
      "epoch: 9 step: 241, loss is 0.013879039324820042\n",
      "epoch: 9 step: 242, loss is 0.06897891312837601\n",
      "epoch: 9 step: 243, loss is 0.00026549852918833494\n",
      "epoch: 9 step: 244, loss is 0.0022014507558196783\n",
      "epoch: 9 step: 245, loss is 0.00821614172309637\n",
      "epoch: 9 step: 246, loss is 0.0015175002627074718\n",
      "epoch: 9 step: 247, loss is 7.689849735470489e-05\n",
      "epoch: 9 step: 248, loss is 0.04920598492026329\n",
      "epoch: 9 step: 249, loss is 0.003476599929854274\n",
      "epoch: 9 step: 250, loss is 0.011745922267436981\n",
      "epoch: 9 step: 251, loss is 0.00019845493079628795\n",
      "epoch: 9 step: 252, loss is 0.0006308294832706451\n",
      "epoch: 9 step: 253, loss is 0.008685484528541565\n",
      "epoch: 9 step: 254, loss is 0.1496313214302063\n",
      "epoch: 9 step: 255, loss is 0.0037409882061183453\n",
      "epoch: 9 step: 256, loss is 0.0002443933335598558\n",
      "epoch: 9 step: 257, loss is 0.028502007946372032\n",
      "epoch: 9 step: 258, loss is 0.00015274329052772373\n",
      "epoch: 9 step: 259, loss is 0.002605204936116934\n",
      "epoch: 9 step: 260, loss is 0.00013805199705529958\n",
      "epoch: 9 step: 261, loss is 0.0023172488436102867\n",
      "epoch: 9 step: 262, loss is 0.001712032244540751\n",
      "epoch: 9 step: 263, loss is 0.04055684432387352\n",
      "epoch: 9 step: 264, loss is 4.812538463738747e-05\n",
      "epoch: 9 step: 265, loss is 0.0018801063997671008\n",
      "epoch: 9 step: 266, loss is 0.000610100687481463\n",
      "epoch: 9 step: 267, loss is 0.002967950189486146\n",
      "epoch: 9 step: 268, loss is 0.0005442919791676104\n",
      "epoch: 9 step: 269, loss is 0.1272774189710617\n",
      "epoch: 9 step: 270, loss is 0.03193008899688721\n",
      "epoch: 9 step: 271, loss is 3.256654235883616e-05\n",
      "epoch: 9 step: 272, loss is 0.009524497203528881\n",
      "epoch: 9 step: 273, loss is 0.0005277810851112008\n",
      "epoch: 9 step: 274, loss is 0.00020504245185293257\n",
      "epoch: 9 step: 275, loss is 0.0019087424734607339\n",
      "epoch: 9 step: 276, loss is 0.016278477385640144\n",
      "epoch: 9 step: 277, loss is 0.0002813741739373654\n",
      "epoch: 9 step: 278, loss is 0.0032452745363116264\n",
      "epoch: 9 step: 279, loss is 0.0021824073046445847\n",
      "epoch: 9 step: 280, loss is 0.0013288049958646297\n",
      "epoch: 9 step: 281, loss is 0.0011455253697931767\n",
      "epoch: 9 step: 282, loss is 0.0010013849241659045\n",
      "epoch: 9 step: 283, loss is 0.042442046105861664\n",
      "epoch: 9 step: 284, loss is 0.00038232392398640513\n",
      "epoch: 9 step: 285, loss is 0.006972795352339745\n",
      "epoch: 9 step: 286, loss is 0.011183343827724457\n",
      "epoch: 9 step: 287, loss is 3.472034222795628e-05\n",
      "epoch: 9 step: 288, loss is 7.210051990114152e-05\n",
      "epoch: 9 step: 289, loss is 0.03881791979074478\n",
      "epoch: 9 step: 290, loss is 0.001475600409321487\n",
      "epoch: 9 step: 291, loss is 0.0005962633294984698\n",
      "epoch: 9 step: 292, loss is 0.03618037328124046\n",
      "epoch: 9 step: 293, loss is 0.0009616177994757891\n",
      "epoch: 9 step: 294, loss is 0.0019285384332761168\n",
      "epoch: 9 step: 295, loss is 0.001031298073939979\n",
      "epoch: 9 step: 296, loss is 0.0003081928298342973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 297, loss is 0.003587181679904461\n",
      "epoch: 9 step: 298, loss is 0.0004144490521866828\n",
      "epoch: 9 step: 299, loss is 6.55636249575764e-05\n",
      "epoch: 9 step: 300, loss is 0.001170068746432662\n",
      "epoch: 9 step: 301, loss is 0.0006305272690951824\n",
      "epoch: 9 step: 302, loss is 0.013856273144483566\n",
      "epoch: 9 step: 303, loss is 2.9186401661718264e-05\n",
      "epoch: 9 step: 304, loss is 0.00013522920198738575\n",
      "epoch: 9 step: 305, loss is 0.05790663883090019\n",
      "epoch: 9 step: 306, loss is 0.00011376685870345682\n",
      "epoch: 9 step: 307, loss is 0.0007668755715712905\n",
      "epoch: 9 step: 308, loss is 3.511616887408309e-05\n",
      "epoch: 9 step: 309, loss is 0.00022332598746288568\n",
      "epoch: 9 step: 310, loss is 0.029952537268400192\n",
      "epoch: 9 step: 311, loss is 0.00012622159556485713\n",
      "epoch: 9 step: 312, loss is 0.0005265271756798029\n",
      "epoch: 9 step: 313, loss is 0.0012135562719777226\n",
      "epoch: 9 step: 314, loss is 0.022208435460925102\n",
      "epoch: 9 step: 315, loss is 0.0001517571072326973\n",
      "epoch: 9 step: 316, loss is 0.012415656819939613\n",
      "epoch: 9 step: 317, loss is 0.00013688651961274445\n",
      "epoch: 9 step: 318, loss is 0.014395221136510372\n",
      "epoch: 9 step: 319, loss is 0.00215890328399837\n",
      "epoch: 9 step: 320, loss is 0.00022502017964143306\n",
      "epoch: 9 step: 321, loss is 0.00458176713436842\n",
      "epoch: 9 step: 322, loss is 0.0007191426120698452\n",
      "epoch: 9 step: 323, loss is 0.002320579718798399\n",
      "epoch: 9 step: 324, loss is 0.025673775002360344\n",
      "epoch: 9 step: 325, loss is 0.0032447651028633118\n",
      "epoch: 9 step: 326, loss is 8.229530067183077e-05\n",
      "epoch: 9 step: 327, loss is 4.998895383323543e-05\n",
      "epoch: 9 step: 328, loss is 0.00016624032286927104\n",
      "epoch: 9 step: 329, loss is 0.06831999868154526\n",
      "epoch: 9 step: 330, loss is 0.0021897307597100735\n",
      "epoch: 9 step: 331, loss is 0.047994472086429596\n",
      "epoch: 9 step: 332, loss is 0.004883336368948221\n",
      "epoch: 9 step: 333, loss is 0.0008917087106965482\n",
      "epoch: 9 step: 334, loss is 0.0010729744099080563\n",
      "epoch: 9 step: 335, loss is 4.995411291019991e-05\n",
      "epoch: 9 step: 336, loss is 0.00010090216528624296\n",
      "epoch: 9 step: 337, loss is 0.009826062247157097\n",
      "epoch: 9 step: 338, loss is 0.0010552980238571763\n",
      "epoch: 9 step: 339, loss is 0.0008042220142669976\n",
      "epoch: 9 step: 340, loss is 0.0006573077407665551\n",
      "epoch: 9 step: 341, loss is 0.00017166673205792904\n",
      "epoch: 9 step: 342, loss is 4.76966961286962e-05\n",
      "epoch: 9 step: 343, loss is 0.006761206313967705\n",
      "epoch: 9 step: 344, loss is 3.631987783592194e-05\n",
      "epoch: 9 step: 345, loss is 0.00046155464951880276\n",
      "epoch: 9 step: 346, loss is 0.000872099946718663\n",
      "epoch: 9 step: 347, loss is 0.00043703432311303914\n",
      "epoch: 9 step: 348, loss is 6.471793312812224e-05\n",
      "epoch: 9 step: 349, loss is 0.00011902637197636068\n",
      "epoch: 9 step: 350, loss is 0.026417477056384087\n",
      "epoch: 9 step: 351, loss is 0.0013963888632133603\n",
      "epoch: 9 step: 352, loss is 0.003277072450146079\n",
      "epoch: 9 step: 353, loss is 0.0029878581408411264\n",
      "epoch: 9 step: 354, loss is 0.0002763280353974551\n",
      "epoch: 9 step: 355, loss is 0.0003100387111771852\n",
      "epoch: 9 step: 356, loss is 0.0003168693510815501\n",
      "epoch: 9 step: 357, loss is 0.004090472124516964\n",
      "epoch: 9 step: 358, loss is 3.8662299630232155e-05\n",
      "epoch: 9 step: 359, loss is 6.282606045715511e-05\n",
      "epoch: 9 step: 360, loss is 0.000341786042554304\n",
      "epoch: 9 step: 361, loss is 0.0001997339422814548\n",
      "epoch: 9 step: 362, loss is 0.043652523308992386\n",
      "epoch: 9 step: 363, loss is 0.0002491158666089177\n",
      "epoch: 9 step: 364, loss is 0.024556169286370277\n",
      "epoch: 9 step: 365, loss is 0.0009822944412007928\n",
      "epoch: 9 step: 366, loss is 0.00034569023409858346\n",
      "epoch: 9 step: 367, loss is 2.661948383320123e-05\n",
      "epoch: 9 step: 368, loss is 0.0008655989659018815\n",
      "epoch: 9 step: 369, loss is 0.0007140101515688002\n",
      "epoch: 9 step: 370, loss is 2.5580075089237653e-05\n",
      "epoch: 9 step: 371, loss is 0.0012871281942352653\n",
      "epoch: 9 step: 372, loss is 0.014245362021028996\n",
      "epoch: 9 step: 373, loss is 0.00011538595572346821\n",
      "epoch: 9 step: 374, loss is 0.003365627024322748\n",
      "epoch: 9 step: 375, loss is 0.000634658383205533\n",
      "epoch: 9 step: 376, loss is 0.018537111580371857\n",
      "epoch: 9 step: 377, loss is 6.8583890424633864e-06\n",
      "epoch: 9 step: 378, loss is 0.000738091126549989\n",
      "epoch: 9 step: 379, loss is 0.001317436690442264\n",
      "epoch: 9 step: 380, loss is 0.029510999098420143\n",
      "epoch: 9 step: 381, loss is 0.0004318574210628867\n",
      "epoch: 9 step: 382, loss is 0.0027330233715474606\n",
      "epoch: 9 step: 383, loss is 0.0003344199212733656\n",
      "epoch: 9 step: 384, loss is 0.0009019791032187641\n",
      "epoch: 9 step: 385, loss is 0.0001141462053055875\n",
      "epoch: 9 step: 386, loss is 0.0001644546864554286\n",
      "epoch: 9 step: 387, loss is 0.010489767417311668\n",
      "epoch: 9 step: 388, loss is 0.029111232608556747\n",
      "epoch: 9 step: 389, loss is 0.037106309086084366\n",
      "epoch: 9 step: 390, loss is 0.0019518608460202813\n",
      "epoch: 9 step: 391, loss is 0.00023975945077836514\n",
      "epoch: 9 step: 392, loss is 1.5667686966480687e-05\n",
      "epoch: 9 step: 393, loss is 2.7466321625979617e-05\n",
      "epoch: 9 step: 394, loss is 0.0020336161833256483\n",
      "epoch: 9 step: 395, loss is 0.0008515500230714679\n",
      "epoch: 9 step: 396, loss is 0.0005686882068403065\n",
      "epoch: 9 step: 397, loss is 0.008112120442092419\n",
      "epoch: 9 step: 398, loss is 0.0011291460832580924\n",
      "epoch: 9 step: 399, loss is 0.00028108127298764884\n",
      "epoch: 9 step: 400, loss is 0.006015409249812365\n",
      "epoch: 9 step: 401, loss is 0.00010394972923677415\n",
      "epoch: 9 step: 402, loss is 0.0005221450701355934\n",
      "epoch: 9 step: 403, loss is 5.5284585869230796e-06\n",
      "epoch: 9 step: 404, loss is 0.001976447179913521\n",
      "epoch: 9 step: 405, loss is 0.027038320899009705\n",
      "epoch: 9 step: 406, loss is 0.00037480221362784505\n",
      "epoch: 9 step: 407, loss is 0.0004937822232022882\n",
      "epoch: 9 step: 408, loss is 0.00032412607106380165\n",
      "epoch: 9 step: 409, loss is 0.0003743184788618237\n",
      "epoch: 9 step: 410, loss is 0.00013513449812307954\n",
      "epoch: 9 step: 411, loss is 0.008968653157353401\n",
      "epoch: 9 step: 412, loss is 9.677445632405579e-06\n",
      "epoch: 9 step: 413, loss is 0.0027422700077295303\n",
      "epoch: 9 step: 414, loss is 0.00014838346396572888\n",
      "epoch: 9 step: 415, loss is 0.0010534373577684164\n",
      "epoch: 9 step: 416, loss is 0.00010273578664055094\n",
      "epoch: 9 step: 417, loss is 0.000319392274832353\n",
      "epoch: 9 step: 418, loss is 6.027140625519678e-05\n",
      "epoch: 9 step: 419, loss is 0.00588820967823267\n",
      "epoch: 9 step: 420, loss is 0.00036929058842360973\n",
      "epoch: 9 step: 421, loss is 0.009297233074903488\n",
      "epoch: 9 step: 422, loss is 0.011374986730515957\n",
      "epoch: 9 step: 423, loss is 0.0015194714069366455\n",
      "epoch: 9 step: 424, loss is 0.01136071141809225\n",
      "epoch: 9 step: 425, loss is 0.00021941389422863722\n",
      "epoch: 9 step: 426, loss is 0.001941655413247645\n",
      "epoch: 9 step: 427, loss is 0.0004631236952263862\n",
      "epoch: 9 step: 428, loss is 4.9586024033487774e-06\n",
      "epoch: 9 step: 429, loss is 0.0021781164687126875\n",
      "epoch: 9 step: 430, loss is 0.00022327086480800062\n",
      "epoch: 9 step: 431, loss is 0.00032940658275038004\n",
      "epoch: 9 step: 432, loss is 0.0003310928586870432\n",
      "epoch: 9 step: 433, loss is 0.0005774697638116777\n",
      "epoch: 9 step: 434, loss is 0.0014325124211609364\n",
      "epoch: 9 step: 435, loss is 0.0014844750985503197\n",
      "epoch: 9 step: 436, loss is 0.00016023933130782098\n",
      "epoch: 9 step: 437, loss is 0.01863780990242958\n",
      "epoch: 9 step: 438, loss is 0.00039646661025471985\n",
      "epoch: 9 step: 439, loss is 0.005860299803316593\n",
      "epoch: 9 step: 440, loss is 0.022871503606438637\n",
      "epoch: 9 step: 441, loss is 0.01527500431984663\n",
      "epoch: 9 step: 442, loss is 0.008912753313779831\n",
      "epoch: 9 step: 443, loss is 0.0005719431210309267\n",
      "epoch: 9 step: 444, loss is 0.0016083710361272097\n",
      "epoch: 9 step: 445, loss is 0.0001369170204270631\n",
      "epoch: 9 step: 446, loss is 0.01641857624053955\n",
      "epoch: 9 step: 447, loss is 0.0011537206592038274\n",
      "epoch: 9 step: 448, loss is 6.768888124497607e-05\n",
      "epoch: 9 step: 449, loss is 0.0016458564205095172\n",
      "epoch: 9 step: 450, loss is 0.0757608711719513\n",
      "epoch: 9 step: 451, loss is 2.1209913029451855e-05\n",
      "epoch: 9 step: 452, loss is 0.11770958453416824\n",
      "epoch: 9 step: 453, loss is 5.116901593282819e-05\n",
      "epoch: 9 step: 454, loss is 4.348336369730532e-05\n",
      "epoch: 9 step: 455, loss is 0.043385881930589676\n",
      "epoch: 9 step: 456, loss is 7.615894719492644e-05\n",
      "epoch: 9 step: 457, loss is 0.00012519456504378468\n",
      "epoch: 9 step: 458, loss is 0.05289441719651222\n",
      "epoch: 9 step: 459, loss is 0.002086132997646928\n",
      "epoch: 9 step: 460, loss is 0.00016482893261127174\n",
      "epoch: 9 step: 461, loss is 0.00019308304763399065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 462, loss is 1.9939732737839222e-05\n",
      "epoch: 9 step: 463, loss is 0.0003640193026512861\n",
      "epoch: 9 step: 464, loss is 0.01891556940972805\n",
      "epoch: 9 step: 465, loss is 0.005316249094903469\n",
      "epoch: 9 step: 466, loss is 2.4978908186312765e-05\n",
      "epoch: 9 step: 467, loss is 8.33320154924877e-05\n",
      "epoch: 9 step: 468, loss is 0.004523308016359806\n",
      "epoch: 9 step: 469, loss is 0.00017695077985990793\n",
      "epoch: 9 step: 470, loss is 0.0027408944442868233\n",
      "epoch: 9 step: 471, loss is 1.1466760042821988e-05\n",
      "epoch: 9 step: 472, loss is 0.049584392458200455\n",
      "epoch: 9 step: 473, loss is 4.387836088426411e-05\n",
      "epoch: 9 step: 474, loss is 2.4660119379404932e-05\n",
      "epoch: 9 step: 475, loss is 0.00036842169356532395\n",
      "epoch: 9 step: 476, loss is 0.02032114751636982\n",
      "epoch: 9 step: 477, loss is 0.004250925965607166\n",
      "epoch: 9 step: 478, loss is 0.0010232736822217703\n",
      "epoch: 9 step: 479, loss is 0.0008170733926817775\n",
      "epoch: 9 step: 480, loss is 0.0001771982351783663\n",
      "epoch: 9 step: 481, loss is 0.0022353928070515394\n",
      "epoch: 9 step: 482, loss is 0.00039948103949427605\n",
      "epoch: 9 step: 483, loss is 9.202852379530668e-05\n",
      "epoch: 9 step: 484, loss is 0.0020541378762573004\n",
      "epoch: 9 step: 485, loss is 0.0015442477306351066\n",
      "epoch: 9 step: 486, loss is 0.0005001433310098946\n",
      "epoch: 9 step: 487, loss is 0.0010117903584614396\n",
      "epoch: 9 step: 488, loss is 0.003206832567229867\n",
      "epoch: 9 step: 489, loss is 0.0018491536611691117\n",
      "epoch: 9 step: 490, loss is 0.0014916680520400405\n",
      "epoch: 9 step: 491, loss is 0.0019253544742241502\n",
      "epoch: 9 step: 492, loss is 0.007414412684738636\n",
      "epoch: 9 step: 493, loss is 0.02664990723133087\n",
      "epoch: 9 step: 494, loss is 3.108828968834132e-05\n",
      "epoch: 9 step: 495, loss is 0.00037655612686648965\n",
      "epoch: 9 step: 496, loss is 4.246326716383919e-05\n",
      "epoch: 9 step: 497, loss is 0.019631095230579376\n",
      "epoch: 9 step: 498, loss is 1.1948688552365638e-05\n",
      "epoch: 9 step: 499, loss is 0.0087074413895607\n",
      "epoch: 9 step: 500, loss is 9.763460184331052e-06\n",
      "epoch: 9 step: 501, loss is 0.00017397226474713534\n",
      "epoch: 9 step: 502, loss is 3.9466605812776834e-05\n",
      "epoch: 9 step: 503, loss is 0.0033376237843185663\n",
      "epoch: 9 step: 504, loss is 4.719362550531514e-05\n",
      "epoch: 9 step: 505, loss is 0.025064688175916672\n",
      "epoch: 9 step: 506, loss is 0.00030951632652431726\n",
      "epoch: 9 step: 507, loss is 0.0032786864321678877\n",
      "epoch: 9 step: 508, loss is 0.0011628331849351525\n",
      "epoch: 9 step: 509, loss is 0.002743298886343837\n",
      "epoch: 9 step: 510, loss is 0.0005119487177580595\n",
      "epoch: 9 step: 511, loss is 0.00048714649165049195\n",
      "epoch: 9 step: 512, loss is 0.0001768705842550844\n",
      "epoch: 9 step: 513, loss is 0.04187984764575958\n",
      "epoch: 9 step: 514, loss is 0.00010038915934273973\n",
      "epoch: 9 step: 515, loss is 0.0003972680715378374\n",
      "epoch: 9 step: 516, loss is 0.005106314085423946\n",
      "epoch: 9 step: 517, loss is 0.0006474045221693814\n",
      "epoch: 9 step: 518, loss is 0.002316658152267337\n",
      "epoch: 9 step: 519, loss is 0.0019931686110794544\n",
      "epoch: 9 step: 520, loss is 0.000329991162288934\n",
      "epoch: 9 step: 521, loss is 0.005765855778008699\n",
      "epoch: 9 step: 522, loss is 0.0007761364104226232\n",
      "epoch: 9 step: 523, loss is 0.00022845619241707027\n",
      "epoch: 9 step: 524, loss is 5.8325800637248904e-05\n",
      "epoch: 9 step: 525, loss is 0.014412078075110912\n",
      "epoch: 9 step: 526, loss is 0.00038810516707599163\n",
      "epoch: 9 step: 527, loss is 0.005465115420520306\n",
      "epoch: 9 step: 528, loss is 3.7589215935440734e-06\n",
      "epoch: 9 step: 529, loss is 0.00020007761486340314\n",
      "epoch: 9 step: 530, loss is 0.001705204020254314\n",
      "epoch: 9 step: 531, loss is 0.0004865126102231443\n",
      "epoch: 9 step: 532, loss is 0.001065797172486782\n",
      "epoch: 9 step: 533, loss is 0.010607283562421799\n",
      "epoch: 9 step: 534, loss is 0.005832164082676172\n",
      "epoch: 9 step: 535, loss is 2.3500670067733154e-05\n",
      "epoch: 9 step: 536, loss is 0.003592688823118806\n",
      "epoch: 9 step: 537, loss is 0.04314135015010834\n",
      "epoch: 9 step: 538, loss is 0.021224137395620346\n",
      "epoch: 9 step: 539, loss is 0.0723312720656395\n",
      "epoch: 9 step: 540, loss is 0.00011427398567320779\n",
      "epoch: 9 step: 541, loss is 0.0001934674073709175\n",
      "epoch: 9 step: 542, loss is 2.957945298476261e-06\n",
      "epoch: 9 step: 543, loss is 0.012893257662653923\n",
      "epoch: 9 step: 544, loss is 3.123062924714759e-05\n",
      "epoch: 9 step: 545, loss is 0.000183405150892213\n",
      "epoch: 9 step: 546, loss is 0.00020150865020696074\n",
      "epoch: 9 step: 547, loss is 0.00020655700063798577\n",
      "epoch: 9 step: 548, loss is 0.0005281030898913741\n",
      "epoch: 9 step: 549, loss is 0.003720469307154417\n",
      "epoch: 9 step: 550, loss is 0.04565208777785301\n",
      "epoch: 9 step: 551, loss is 0.015668118372559547\n",
      "epoch: 9 step: 552, loss is 3.0063949907344067e-06\n",
      "epoch: 9 step: 553, loss is 7.707819349889178e-06\n",
      "epoch: 9 step: 554, loss is 0.0005378389614634216\n",
      "epoch: 9 step: 555, loss is 0.001865077530965209\n",
      "epoch: 9 step: 556, loss is 7.865602674428374e-05\n",
      "epoch: 9 step: 557, loss is 0.0006823438452556729\n",
      "epoch: 9 step: 558, loss is 0.0063153719529509544\n",
      "epoch: 9 step: 559, loss is 0.005962824914604425\n",
      "epoch: 9 step: 560, loss is 0.07599242776632309\n",
      "epoch: 9 step: 561, loss is 8.194877591449767e-05\n",
      "epoch: 9 step: 562, loss is 0.0013794393744319677\n",
      "epoch: 9 step: 563, loss is 0.0002377932978561148\n",
      "epoch: 9 step: 564, loss is 0.00011417105270083994\n",
      "epoch: 9 step: 565, loss is 0.029985472559928894\n",
      "epoch: 9 step: 566, loss is 0.00032345965155400336\n",
      "epoch: 9 step: 567, loss is 0.0009205550304614007\n",
      "epoch: 9 step: 568, loss is 0.013056734576821327\n",
      "epoch: 9 step: 569, loss is 0.0003506257780827582\n",
      "epoch: 9 step: 570, loss is 0.013302178122103214\n",
      "epoch: 9 step: 571, loss is 0.004676179960370064\n",
      "epoch: 9 step: 572, loss is 0.0005669370293617249\n",
      "epoch: 9 step: 573, loss is 0.0009224907262250781\n",
      "epoch: 9 step: 574, loss is 1.8799786630552262e-05\n",
      "epoch: 9 step: 575, loss is 0.001301801996305585\n",
      "epoch: 9 step: 576, loss is 0.00013899985060561448\n",
      "epoch: 9 step: 577, loss is 0.0675588846206665\n",
      "epoch: 9 step: 578, loss is 0.0001367898948956281\n",
      "epoch: 9 step: 579, loss is 4.537724453257397e-05\n",
      "epoch: 9 step: 580, loss is 5.2906681958120316e-05\n",
      "epoch: 9 step: 581, loss is 2.6712434191722423e-05\n",
      "epoch: 9 step: 582, loss is 0.0001540921803098172\n",
      "epoch: 9 step: 583, loss is 4.3381500290706754e-05\n",
      "epoch: 9 step: 584, loss is 0.000718176132068038\n",
      "epoch: 9 step: 585, loss is 0.00011800060019595549\n",
      "epoch: 9 step: 586, loss is 0.0031423375476151705\n",
      "epoch: 9 step: 587, loss is 8.100445847958326e-05\n",
      "epoch: 9 step: 588, loss is 9.399231930729002e-05\n",
      "epoch: 9 step: 589, loss is 0.00018683035159483552\n",
      "epoch: 9 step: 590, loss is 1.2695267287199385e-05\n",
      "epoch: 9 step: 591, loss is 0.00021629159164149314\n",
      "epoch: 9 step: 592, loss is 0.18102683126926422\n",
      "epoch: 9 step: 593, loss is 3.157420360366814e-05\n",
      "epoch: 9 step: 594, loss is 0.00056341418530792\n",
      "epoch: 9 step: 595, loss is 0.004224519710987806\n",
      "epoch: 9 step: 596, loss is 3.3981905289692804e-05\n",
      "epoch: 9 step: 597, loss is 0.09297867119312286\n",
      "epoch: 9 step: 598, loss is 0.001777726924046874\n",
      "epoch: 9 step: 599, loss is 7.096927220118232e-06\n",
      "epoch: 9 step: 600, loss is 3.59909790859092e-05\n",
      "epoch: 9 step: 601, loss is 0.0027860586997121572\n",
      "epoch: 9 step: 602, loss is 0.00855876225978136\n",
      "epoch: 9 step: 603, loss is 0.00012364213762339205\n",
      "epoch: 9 step: 604, loss is 0.07410266250371933\n",
      "epoch: 9 step: 605, loss is 0.00029978129896335304\n",
      "epoch: 9 step: 606, loss is 0.0004963058163411915\n",
      "epoch: 9 step: 607, loss is 0.00015366921434178948\n",
      "epoch: 9 step: 608, loss is 0.006810804363340139\n",
      "epoch: 9 step: 609, loss is 0.00020441679225768894\n",
      "epoch: 9 step: 610, loss is 0.002064415253698826\n",
      "epoch: 9 step: 611, loss is 0.003163460176438093\n",
      "epoch: 9 step: 612, loss is 0.004926213528960943\n",
      "epoch: 9 step: 613, loss is 0.016276968643069267\n",
      "epoch: 9 step: 614, loss is 0.0003376673848833889\n",
      "epoch: 9 step: 615, loss is 7.644508150406182e-05\n",
      "epoch: 9 step: 616, loss is 0.00024378718808293343\n",
      "epoch: 9 step: 617, loss is 0.0003496025165077299\n",
      "epoch: 9 step: 618, loss is 0.001362691167742014\n",
      "epoch: 9 step: 619, loss is 0.008478449657559395\n",
      "epoch: 9 step: 620, loss is 0.0011007414432242513\n",
      "epoch: 9 step: 621, loss is 0.006095986347645521\n",
      "epoch: 9 step: 622, loss is 0.00010320136789232492\n",
      "epoch: 9 step: 623, loss is 0.0011080563999712467\n",
      "epoch: 9 step: 624, loss is 0.006170985288918018\n",
      "epoch: 9 step: 625, loss is 7.21123069524765e-05\n",
      "epoch: 9 step: 626, loss is 0.0004986238782294095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 627, loss is 1.857104871305637e-05\n",
      "epoch: 9 step: 628, loss is 0.00018219620687887073\n",
      "epoch: 9 step: 629, loss is 0.02630256675183773\n",
      "epoch: 9 step: 630, loss is 4.64178629044909e-06\n",
      "epoch: 9 step: 631, loss is 0.0001297804992645979\n",
      "epoch: 9 step: 632, loss is 0.20480382442474365\n",
      "epoch: 9 step: 633, loss is 0.0006249917787499726\n",
      "epoch: 9 step: 634, loss is 2.933206815214362e-05\n",
      "epoch: 9 step: 635, loss is 0.0012070330558344722\n",
      "epoch: 9 step: 636, loss is 0.0312182754278183\n",
      "epoch: 9 step: 637, loss is 0.016962487250566483\n",
      "epoch: 9 step: 638, loss is 0.07771823555231094\n",
      "epoch: 9 step: 639, loss is 0.009330159053206444\n",
      "epoch: 9 step: 640, loss is 0.0003187826951034367\n",
      "epoch: 9 step: 641, loss is 0.00027309238794259727\n",
      "epoch: 9 step: 642, loss is 4.86393146275077e-05\n",
      "epoch: 9 step: 643, loss is 0.03390329331159592\n",
      "epoch: 9 step: 644, loss is 0.0003587193787097931\n",
      "epoch: 9 step: 645, loss is 0.07019754499197006\n",
      "epoch: 9 step: 646, loss is 0.006789627484977245\n",
      "epoch: 9 step: 647, loss is 0.006439782679080963\n",
      "epoch: 9 step: 648, loss is 0.015649566426873207\n",
      "epoch: 9 step: 649, loss is 0.000831843470223248\n",
      "epoch: 9 step: 650, loss is 0.06437948346138\n",
      "epoch: 9 step: 651, loss is 0.0001390083780279383\n",
      "epoch: 9 step: 652, loss is 0.10112632066011429\n",
      "epoch: 9 step: 653, loss is 6.044103793101385e-05\n",
      "epoch: 9 step: 654, loss is 0.24593091011047363\n",
      "epoch: 9 step: 655, loss is 5.845229225087678e-06\n",
      "epoch: 9 step: 656, loss is 0.00048438613885082304\n",
      "epoch: 9 step: 657, loss is 5.271460395306349e-06\n",
      "epoch: 9 step: 658, loss is 0.0022606817074120045\n",
      "epoch: 9 step: 659, loss is 0.00014287246449384838\n",
      "epoch: 9 step: 660, loss is 0.010393471457064152\n",
      "epoch: 9 step: 661, loss is 0.006203694734722376\n",
      "epoch: 9 step: 662, loss is 0.003016802715137601\n",
      "epoch: 9 step: 663, loss is 0.00675297761335969\n",
      "epoch: 9 step: 664, loss is 0.0009551503462716937\n",
      "epoch: 9 step: 665, loss is 0.0017003943212330341\n",
      "epoch: 9 step: 666, loss is 0.0008161792065948248\n",
      "epoch: 9 step: 667, loss is 0.0003583722864277661\n",
      "epoch: 9 step: 668, loss is 0.00016256500384770334\n",
      "epoch: 9 step: 669, loss is 0.00042379111982882023\n",
      "epoch: 9 step: 670, loss is 0.0005013913614675403\n",
      "epoch: 9 step: 671, loss is 0.00036439907853491604\n",
      "epoch: 9 step: 672, loss is 0.0006488515646196902\n",
      "epoch: 9 step: 673, loss is 0.015118800103664398\n",
      "epoch: 9 step: 674, loss is 0.0003478137368801981\n",
      "epoch: 9 step: 675, loss is 0.00023747574596200138\n",
      "epoch: 9 step: 676, loss is 0.009315988048911095\n",
      "epoch: 9 step: 677, loss is 0.09720202535390854\n",
      "epoch: 9 step: 678, loss is 0.008459720760583878\n",
      "epoch: 9 step: 679, loss is 0.11420976370573044\n",
      "epoch: 9 step: 680, loss is 7.089609880495118e-06\n",
      "epoch: 9 step: 681, loss is 0.13550738990306854\n",
      "epoch: 9 step: 682, loss is 0.07899635285139084\n",
      "epoch: 9 step: 683, loss is 0.12623721361160278\n",
      "epoch: 9 step: 684, loss is 0.03456363454461098\n",
      "epoch: 9 step: 685, loss is 0.0016452653799206018\n",
      "epoch: 9 step: 686, loss is 0.0008982956642284989\n",
      "epoch: 9 step: 687, loss is 0.0007371248211711645\n",
      "epoch: 9 step: 688, loss is 4.5839820813853294e-05\n",
      "epoch: 9 step: 689, loss is 0.0018502320162951946\n",
      "epoch: 9 step: 690, loss is 0.10139551758766174\n",
      "epoch: 9 step: 691, loss is 0.00040441061719320714\n",
      "epoch: 9 step: 692, loss is 0.017995191738009453\n",
      "epoch: 9 step: 693, loss is 0.0003644012613222003\n",
      "epoch: 9 step: 694, loss is 0.027271607890725136\n",
      "epoch: 9 step: 695, loss is 0.0004471602733246982\n",
      "epoch: 9 step: 696, loss is 0.0013105588732287288\n",
      "epoch: 9 step: 697, loss is 0.003917294554412365\n",
      "epoch: 9 step: 698, loss is 0.09412168711423874\n",
      "epoch: 9 step: 699, loss is 0.00035955716157332063\n",
      "epoch: 9 step: 700, loss is 0.18945862352848053\n",
      "epoch: 9 step: 701, loss is 0.011186153627932072\n",
      "epoch: 9 step: 702, loss is 0.002241050126031041\n",
      "epoch: 9 step: 703, loss is 7.475426536984742e-05\n",
      "epoch: 9 step: 704, loss is 0.0013633978087455034\n",
      "epoch: 9 step: 705, loss is 0.08985354751348495\n",
      "epoch: 9 step: 706, loss is 0.0010118924546986818\n",
      "epoch: 9 step: 707, loss is 0.00030005117878317833\n",
      "epoch: 9 step: 708, loss is 0.022603467106819153\n",
      "epoch: 9 step: 709, loss is 0.001931076287291944\n",
      "epoch: 9 step: 710, loss is 0.06372044235467911\n",
      "epoch: 9 step: 711, loss is 0.0027015211526304483\n",
      "epoch: 9 step: 712, loss is 0.03449904918670654\n",
      "epoch: 9 step: 713, loss is 0.0005538758705370128\n",
      "epoch: 9 step: 714, loss is 0.007062871940433979\n",
      "epoch: 9 step: 715, loss is 0.00803630892187357\n",
      "epoch: 9 step: 716, loss is 0.07668595016002655\n",
      "epoch: 9 step: 717, loss is 0.05673733726143837\n",
      "epoch: 9 step: 718, loss is 0.015156418085098267\n",
      "epoch: 9 step: 719, loss is 0.012704454362392426\n",
      "epoch: 9 step: 720, loss is 0.00026245706249028444\n",
      "epoch: 9 step: 721, loss is 0.00023440548102371395\n",
      "epoch: 9 step: 722, loss is 0.07940708100795746\n",
      "epoch: 9 step: 723, loss is 0.18962521851062775\n",
      "epoch: 9 step: 724, loss is 0.002099857432767749\n",
      "epoch: 9 step: 725, loss is 7.269575871760026e-05\n",
      "epoch: 9 step: 726, loss is 0.007843957282602787\n",
      "epoch: 9 step: 727, loss is 0.0007032256107777357\n",
      "epoch: 9 step: 728, loss is 0.0022925501689314842\n",
      "epoch: 9 step: 729, loss is 0.0008271434926427901\n",
      "epoch: 9 step: 730, loss is 5.8070527302334085e-05\n",
      "epoch: 9 step: 731, loss is 0.007381371688097715\n",
      "epoch: 9 step: 732, loss is 0.00010854249558178708\n",
      "epoch: 9 step: 733, loss is 0.03845195472240448\n",
      "epoch: 9 step: 734, loss is 0.11743985861539841\n",
      "epoch: 9 step: 735, loss is 0.00010148928413400427\n",
      "epoch: 9 step: 736, loss is 0.0003372336213942617\n",
      "epoch: 9 step: 737, loss is 0.00045998208224773407\n",
      "epoch: 9 step: 738, loss is 0.00367841892875731\n",
      "epoch: 9 step: 739, loss is 0.00014210403605829924\n",
      "epoch: 9 step: 740, loss is 6.817943358328193e-05\n",
      "epoch: 9 step: 741, loss is 0.0024629035033285618\n",
      "epoch: 9 step: 742, loss is 0.019441846758127213\n",
      "epoch: 9 step: 743, loss is 0.0016698497347533703\n",
      "epoch: 9 step: 744, loss is 3.336460576974787e-05\n",
      "epoch: 9 step: 745, loss is 6.736866635037586e-05\n",
      "epoch: 9 step: 746, loss is 0.0005147623596712947\n",
      "epoch: 9 step: 747, loss is 0.0004612885823007673\n",
      "epoch: 9 step: 748, loss is 0.003946822136640549\n",
      "epoch: 9 step: 749, loss is 0.0012074382975697517\n",
      "epoch: 9 step: 750, loss is 0.0014470062451437116\n",
      "epoch: 9 step: 751, loss is 0.05074692517518997\n",
      "epoch: 9 step: 752, loss is 0.0006839688867330551\n",
      "epoch: 9 step: 753, loss is 0.0013446839293465018\n",
      "epoch: 9 step: 754, loss is 0.0035721363965421915\n",
      "epoch: 9 step: 755, loss is 0.001102316309697926\n",
      "epoch: 9 step: 756, loss is 0.005711700301617384\n",
      "epoch: 9 step: 757, loss is 0.00020974034850951284\n",
      "epoch: 9 step: 758, loss is 0.00298922136425972\n",
      "epoch: 9 step: 759, loss is 0.0005050141480751336\n",
      "epoch: 9 step: 760, loss is 0.009699014015495777\n",
      "epoch: 9 step: 761, loss is 0.11568721383810043\n",
      "epoch: 9 step: 762, loss is 0.001429258962161839\n",
      "epoch: 9 step: 763, loss is 9.843885345617309e-05\n",
      "epoch: 9 step: 764, loss is 0.005648651160299778\n",
      "epoch: 9 step: 765, loss is 0.00021022239525336772\n",
      "epoch: 9 step: 766, loss is 0.0162957776337862\n",
      "epoch: 9 step: 767, loss is 1.8577304217615165e-05\n",
      "epoch: 9 step: 768, loss is 0.0001510551228420809\n",
      "epoch: 9 step: 769, loss is 0.12314612418413162\n",
      "epoch: 9 step: 770, loss is 0.0003846937033813447\n",
      "epoch: 9 step: 771, loss is 0.0009436883847229183\n",
      "epoch: 9 step: 772, loss is 0.00030986915226094425\n",
      "epoch: 9 step: 773, loss is 0.003156400518491864\n",
      "epoch: 9 step: 774, loss is 0.0009332709014415741\n",
      "epoch: 9 step: 775, loss is 0.0004965216503478587\n",
      "epoch: 9 step: 776, loss is 0.006512977182865143\n",
      "epoch: 9 step: 777, loss is 0.0013854269636794925\n",
      "epoch: 9 step: 778, loss is 0.0013651482295244932\n",
      "epoch: 9 step: 779, loss is 0.000951681868173182\n",
      "epoch: 9 step: 780, loss is 0.012203659862279892\n",
      "epoch: 9 step: 781, loss is 0.009945087134838104\n",
      "epoch: 9 step: 782, loss is 0.004095669370144606\n",
      "epoch: 9 step: 783, loss is 0.0008612165111117065\n",
      "epoch: 9 step: 784, loss is 0.0008611571392975748\n",
      "epoch: 9 step: 785, loss is 1.9565881302696653e-05\n",
      "epoch: 9 step: 786, loss is 0.0001817799056880176\n",
      "epoch: 9 step: 787, loss is 8.582616283092648e-05\n",
      "epoch: 9 step: 788, loss is 0.0009148320532403886\n",
      "epoch: 9 step: 789, loss is 0.0401352196931839\n",
      "epoch: 9 step: 790, loss is 0.000515501422341913\n",
      "epoch: 9 step: 791, loss is 0.022395191714167595\n",
      "epoch: 9 step: 792, loss is 0.012239580973982811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 793, loss is 0.047741346061229706\n",
      "epoch: 9 step: 794, loss is 0.1265183985233307\n",
      "epoch: 9 step: 795, loss is 0.0004907412803731859\n",
      "epoch: 9 step: 796, loss is 0.07802523672580719\n",
      "epoch: 9 step: 797, loss is 0.002581819659098983\n",
      "epoch: 9 step: 798, loss is 1.94063140952494e-05\n",
      "epoch: 9 step: 799, loss is 0.0034413014072924852\n",
      "epoch: 9 step: 800, loss is 6.366204615915194e-05\n",
      "epoch: 9 step: 801, loss is 0.0007290023495443165\n",
      "epoch: 9 step: 802, loss is 0.0004919478087686002\n",
      "epoch: 9 step: 803, loss is 0.00035754317650571465\n",
      "epoch: 9 step: 804, loss is 0.009945315308868885\n",
      "epoch: 9 step: 805, loss is 0.0015448760241270065\n",
      "epoch: 9 step: 806, loss is 0.009801640175282955\n",
      "epoch: 9 step: 807, loss is 0.00010461748752277344\n",
      "epoch: 9 step: 808, loss is 0.003526050830259919\n",
      "epoch: 9 step: 809, loss is 0.003198113990947604\n",
      "epoch: 9 step: 810, loss is 0.000134641450131312\n",
      "epoch: 9 step: 811, loss is 0.014910134486854076\n",
      "epoch: 9 step: 812, loss is 5.723564754589461e-05\n",
      "epoch: 9 step: 813, loss is 9.798869723454118e-05\n",
      "epoch: 9 step: 814, loss is 0.00034039607271552086\n",
      "epoch: 9 step: 815, loss is 0.001056021312251687\n",
      "epoch: 9 step: 816, loss is 0.0002778666093945503\n",
      "epoch: 9 step: 817, loss is 0.004130261484533548\n",
      "epoch: 9 step: 818, loss is 0.00019225801224820316\n",
      "epoch: 9 step: 819, loss is 0.0027565795462578535\n",
      "epoch: 9 step: 820, loss is 0.0012223399244248867\n",
      "epoch: 9 step: 821, loss is 0.002418669406324625\n",
      "epoch: 9 step: 822, loss is 0.0035322813782840967\n",
      "epoch: 9 step: 823, loss is 0.001121784676797688\n",
      "epoch: 9 step: 824, loss is 0.00013355830742511898\n",
      "epoch: 9 step: 825, loss is 0.0002971052017528564\n",
      "epoch: 9 step: 826, loss is 0.004070577677339315\n",
      "epoch: 9 step: 827, loss is 4.308241113903932e-05\n",
      "epoch: 9 step: 828, loss is 9.856863471213728e-05\n",
      "epoch: 9 step: 829, loss is 0.00010317336273146793\n",
      "epoch: 9 step: 830, loss is 0.0022935441229492426\n",
      "epoch: 9 step: 831, loss is 0.004154387395828962\n",
      "epoch: 9 step: 832, loss is 0.011040114797651768\n",
      "epoch: 9 step: 833, loss is 0.0001449650153517723\n",
      "epoch: 9 step: 834, loss is 1.2937121937284246e-05\n",
      "epoch: 9 step: 835, loss is 6.727515574311838e-05\n",
      "epoch: 9 step: 836, loss is 0.004585282411426306\n",
      "epoch: 9 step: 837, loss is 5.1352377340663224e-05\n",
      "epoch: 9 step: 838, loss is 0.005117921624332666\n",
      "epoch: 9 step: 839, loss is 0.2271575927734375\n",
      "epoch: 9 step: 840, loss is 5.356768815545365e-05\n",
      "epoch: 9 step: 841, loss is 1.62978503794875e-05\n",
      "epoch: 9 step: 842, loss is 0.0003227155830245465\n",
      "epoch: 9 step: 843, loss is 8.389595677726902e-06\n",
      "epoch: 9 step: 844, loss is 0.05394343286752701\n",
      "epoch: 9 step: 845, loss is 0.0003254218026995659\n",
      "epoch: 9 step: 846, loss is 0.005676340311765671\n",
      "epoch: 9 step: 847, loss is 5.4733762226533145e-05\n",
      "epoch: 9 step: 848, loss is 0.0014403531095013022\n",
      "epoch: 9 step: 849, loss is 0.0033097227569669485\n",
      "epoch: 9 step: 850, loss is 0.05503648892045021\n",
      "epoch: 9 step: 851, loss is 0.03360510617494583\n",
      "epoch: 9 step: 852, loss is 0.00941529218107462\n",
      "epoch: 9 step: 853, loss is 0.08918295800685883\n",
      "epoch: 9 step: 854, loss is 0.000942739425227046\n",
      "epoch: 9 step: 855, loss is 0.00023441071971319616\n",
      "epoch: 9 step: 856, loss is 0.04224221035838127\n",
      "epoch: 9 step: 857, loss is 0.00016278056136798114\n",
      "epoch: 9 step: 858, loss is 0.005245920270681381\n",
      "epoch: 9 step: 859, loss is 0.00037145058740861714\n",
      "epoch: 9 step: 860, loss is 0.016643324866890907\n",
      "epoch: 9 step: 861, loss is 0.0003412940714042634\n",
      "epoch: 9 step: 862, loss is 0.001165189896710217\n",
      "epoch: 9 step: 863, loss is 0.03026200830936432\n",
      "epoch: 9 step: 864, loss is 0.0049171228893101215\n",
      "epoch: 9 step: 865, loss is 0.001397605985403061\n",
      "epoch: 9 step: 866, loss is 0.0006114994175732136\n",
      "epoch: 9 step: 867, loss is 0.002915096702054143\n",
      "epoch: 9 step: 868, loss is 0.0006444567115977407\n",
      "epoch: 9 step: 869, loss is 0.000655233976431191\n",
      "epoch: 9 step: 870, loss is 0.00011356148024788126\n",
      "epoch: 9 step: 871, loss is 0.002207300392910838\n",
      "epoch: 9 step: 872, loss is 0.032113976776599884\n",
      "epoch: 9 step: 873, loss is 0.0007309569045901299\n",
      "epoch: 9 step: 874, loss is 0.005613151006400585\n",
      "epoch: 9 step: 875, loss is 3.764099528780207e-05\n",
      "epoch: 9 step: 876, loss is 0.00019517655891831964\n",
      "epoch: 9 step: 877, loss is 0.012664200738072395\n",
      "epoch: 9 step: 878, loss is 8.773520676186308e-06\n",
      "epoch: 9 step: 879, loss is 0.03229173645377159\n",
      "epoch: 9 step: 880, loss is 0.00043290271423757076\n",
      "epoch: 9 step: 881, loss is 0.0006489544757641852\n",
      "epoch: 9 step: 882, loss is 4.203857315587811e-05\n",
      "epoch: 9 step: 883, loss is 0.0016488751862198114\n",
      "epoch: 9 step: 884, loss is 0.02603529393672943\n",
      "epoch: 9 step: 885, loss is 3.2686795748304576e-05\n",
      "epoch: 9 step: 886, loss is 0.00011580778664210811\n",
      "epoch: 9 step: 887, loss is 0.0008120447164401412\n",
      "epoch: 9 step: 888, loss is 4.790551611222327e-05\n",
      "epoch: 9 step: 889, loss is 0.014259308576583862\n",
      "epoch: 9 step: 890, loss is 0.0007881890051066875\n",
      "epoch: 9 step: 891, loss is 0.00018172489944845438\n",
      "epoch: 9 step: 892, loss is 0.005680963862687349\n",
      "epoch: 9 step: 893, loss is 0.00037987419636920094\n",
      "epoch: 9 step: 894, loss is 0.012458980083465576\n",
      "epoch: 9 step: 895, loss is 0.0007724403403699398\n",
      "epoch: 9 step: 896, loss is 0.0006630118587054312\n",
      "epoch: 9 step: 897, loss is 0.00029064714908599854\n",
      "epoch: 9 step: 898, loss is 5.4279083997244015e-05\n",
      "epoch: 9 step: 899, loss is 0.0002803247480187565\n",
      "epoch: 9 step: 900, loss is 0.00023376655008178204\n",
      "epoch: 9 step: 901, loss is 0.0001852386922109872\n",
      "epoch: 9 step: 902, loss is 0.0074780769646167755\n",
      "epoch: 9 step: 903, loss is 0.0007301379228010774\n",
      "epoch: 9 step: 904, loss is 0.012352497316896915\n",
      "epoch: 9 step: 905, loss is 5.094586595077999e-05\n",
      "epoch: 9 step: 906, loss is 0.001197279547341168\n",
      "epoch: 9 step: 907, loss is 0.005821274593472481\n",
      "epoch: 9 step: 908, loss is 0.0031382341403514147\n",
      "epoch: 9 step: 909, loss is 0.0004702387086581439\n",
      "epoch: 9 step: 910, loss is 0.02661227062344551\n",
      "epoch: 9 step: 911, loss is 8.182744204532355e-05\n",
      "epoch: 9 step: 912, loss is 0.0023608591873198748\n",
      "epoch: 9 step: 913, loss is 0.00015379427350126207\n",
      "epoch: 9 step: 914, loss is 0.006767020095139742\n",
      "epoch: 9 step: 915, loss is 8.124201121972874e-05\n",
      "epoch: 9 step: 916, loss is 0.00015190757403615862\n",
      "epoch: 9 step: 917, loss is 0.0026700010057538748\n",
      "epoch: 9 step: 918, loss is 0.012584134936332703\n",
      "epoch: 9 step: 919, loss is 2.3594313461217098e-05\n",
      "epoch: 9 step: 920, loss is 6.354945071507245e-05\n",
      "epoch: 9 step: 921, loss is 7.009549881331623e-05\n",
      "epoch: 9 step: 922, loss is 0.00025591551093384624\n",
      "epoch: 9 step: 923, loss is 0.0014424290275201201\n",
      "epoch: 9 step: 924, loss is 3.724019188666716e-05\n",
      "epoch: 9 step: 925, loss is 2.7054957172367722e-05\n",
      "epoch: 9 step: 926, loss is 0.0003117000451311469\n",
      "epoch: 9 step: 927, loss is 0.0006569844554178417\n",
      "epoch: 9 step: 928, loss is 0.036999620497226715\n",
      "epoch: 9 step: 929, loss is 0.0011330769630149007\n",
      "epoch: 9 step: 930, loss is 0.0022723570000380278\n",
      "epoch: 9 step: 931, loss is 0.020486019551753998\n",
      "epoch: 9 step: 932, loss is 0.0008036228828132153\n",
      "epoch: 9 step: 933, loss is 0.00019676129159051925\n",
      "epoch: 9 step: 934, loss is 0.0012927737552672625\n",
      "epoch: 9 step: 935, loss is 1.8234381059301086e-05\n",
      "epoch: 9 step: 936, loss is 0.0037520742043852806\n",
      "epoch: 9 step: 937, loss is 0.0031977519392967224\n",
      "epoch: 9 step: 938, loss is 0.0007984781987033784\n",
      "epoch: 9 step: 939, loss is 0.02045035921037197\n",
      "epoch: 9 step: 940, loss is 0.02876567840576172\n",
      "epoch: 9 step: 941, loss is 0.008643394336104393\n",
      "epoch: 9 step: 942, loss is 1.2609429177246056e-05\n",
      "epoch: 9 step: 943, loss is 0.0010795812122523785\n",
      "epoch: 9 step: 944, loss is 0.0002499068505130708\n",
      "epoch: 9 step: 945, loss is 0.00046991746057756245\n",
      "epoch: 9 step: 946, loss is 1.5187663848337252e-05\n",
      "epoch: 9 step: 947, loss is 0.007986697368323803\n",
      "epoch: 9 step: 948, loss is 0.0012894723331555724\n",
      "epoch: 9 step: 949, loss is 0.0017679237062111497\n",
      "epoch: 9 step: 950, loss is 0.00038924673572182655\n",
      "epoch: 9 step: 951, loss is 0.009553472511470318\n",
      "epoch: 9 step: 952, loss is 0.006906024180352688\n",
      "epoch: 9 step: 953, loss is 0.0036373597104102373\n",
      "epoch: 9 step: 954, loss is 0.007177327293902636\n",
      "epoch: 9 step: 955, loss is 0.0001272413064725697\n",
      "epoch: 9 step: 956, loss is 0.01852230913937092\n",
      "epoch: 9 step: 957, loss is 9.385441080667078e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 958, loss is 1.2161963240941986e-05\n",
      "epoch: 9 step: 959, loss is 0.0007268796907737851\n",
      "epoch: 9 step: 960, loss is 2.9130358598195016e-05\n",
      "epoch: 9 step: 961, loss is 0.011770918034017086\n",
      "epoch: 9 step: 962, loss is 0.08202173560857773\n",
      "epoch: 9 step: 963, loss is 0.00045167357893660665\n",
      "epoch: 9 step: 964, loss is 0.00029324457864277065\n",
      "epoch: 9 step: 965, loss is 0.00020410532306414098\n",
      "epoch: 9 step: 966, loss is 0.00042803853284567595\n",
      "epoch: 9 step: 967, loss is 2.6361047275713645e-05\n",
      "epoch: 9 step: 968, loss is 0.014182155951857567\n",
      "epoch: 9 step: 969, loss is 0.0004397781449370086\n",
      "epoch: 9 step: 970, loss is 0.000765516422688961\n",
      "epoch: 9 step: 971, loss is 2.045534893113654e-05\n",
      "epoch: 9 step: 972, loss is 0.0007967643905431032\n",
      "epoch: 9 step: 973, loss is 2.546682117099408e-05\n",
      "epoch: 9 step: 974, loss is 0.0001913805608637631\n",
      "epoch: 9 step: 975, loss is 0.018543632701039314\n",
      "epoch: 9 step: 976, loss is 0.0313267707824707\n",
      "epoch: 9 step: 977, loss is 0.00011161286965943873\n",
      "epoch: 9 step: 978, loss is 0.0009025302715599537\n",
      "epoch: 9 step: 979, loss is 0.049738600850105286\n",
      "epoch: 9 step: 980, loss is 0.0005056351656094193\n",
      "epoch: 9 step: 981, loss is 0.0024171217810362577\n",
      "epoch: 9 step: 982, loss is 0.003356377827003598\n",
      "epoch: 9 step: 983, loss is 0.00015553669072687626\n",
      "epoch: 9 step: 984, loss is 0.015747006982564926\n",
      "epoch: 9 step: 985, loss is 0.0005142552545294166\n",
      "epoch: 9 step: 986, loss is 3.185121749993414e-05\n",
      "epoch: 9 step: 987, loss is 0.0002536780957598239\n",
      "epoch: 9 step: 988, loss is 0.00015615303709637374\n",
      "epoch: 9 step: 989, loss is 0.0010229843901470304\n",
      "epoch: 9 step: 990, loss is 0.0054326485842466354\n",
      "epoch: 9 step: 991, loss is 0.0011673815315589309\n",
      "epoch: 9 step: 992, loss is 2.8534253942780197e-05\n",
      "epoch: 9 step: 993, loss is 0.0004840705369133502\n",
      "epoch: 9 step: 994, loss is 0.001965023810043931\n",
      "epoch: 9 step: 995, loss is 0.007965213619172573\n",
      "epoch: 9 step: 996, loss is 0.00011364142847014591\n",
      "epoch: 9 step: 997, loss is 0.0015793748898431659\n",
      "epoch: 9 step: 998, loss is 3.438154817558825e-05\n",
      "epoch: 9 step: 999, loss is 0.00019021374464500695\n",
      "epoch: 9 step: 1000, loss is 8.653680561110377e-05\n",
      "epoch: 9 step: 1001, loss is 0.0013590221060439944\n",
      "epoch: 9 step: 1002, loss is 5.579569551628083e-05\n",
      "epoch: 9 step: 1003, loss is 0.013187193311750889\n",
      "epoch: 9 step: 1004, loss is 7.541203376604244e-05\n",
      "epoch: 9 step: 1005, loss is 0.0004762945754919201\n",
      "epoch: 9 step: 1006, loss is 0.00022503452782984823\n",
      "epoch: 9 step: 1007, loss is 7.156954234233126e-05\n",
      "epoch: 9 step: 1008, loss is 0.0002878321392927319\n",
      "epoch: 9 step: 1009, loss is 5.577687988989055e-05\n",
      "epoch: 9 step: 1010, loss is 0.0009031064109876752\n",
      "epoch: 9 step: 1011, loss is 0.09773991256952286\n",
      "epoch: 9 step: 1012, loss is 0.002059296239167452\n",
      "epoch: 9 step: 1013, loss is 0.012512419372797012\n",
      "epoch: 9 step: 1014, loss is 0.00014738927711732686\n",
      "epoch: 9 step: 1015, loss is 4.476825415622443e-05\n",
      "epoch: 9 step: 1016, loss is 0.04698389023542404\n",
      "epoch: 9 step: 1017, loss is 6.214191671460867e-06\n",
      "epoch: 9 step: 1018, loss is 0.0011965951416641474\n",
      "epoch: 9 step: 1019, loss is 0.03345607593655586\n",
      "epoch: 9 step: 1020, loss is 0.0012859252747148275\n",
      "epoch: 9 step: 1021, loss is 7.431974518112838e-05\n",
      "epoch: 9 step: 1022, loss is 0.00019964846433140337\n",
      "epoch: 9 step: 1023, loss is 0.011525196954607964\n",
      "epoch: 9 step: 1024, loss is 5.251539914752357e-05\n",
      "epoch: 9 step: 1025, loss is 0.0063967015594244\n",
      "epoch: 9 step: 1026, loss is 0.003844867693260312\n",
      "epoch: 9 step: 1027, loss is 0.00019628583686426282\n",
      "epoch: 9 step: 1028, loss is 3.26041154039558e-05\n",
      "epoch: 9 step: 1029, loss is 0.012319718487560749\n",
      "epoch: 9 step: 1030, loss is 1.9557999166863738e-06\n",
      "epoch: 9 step: 1031, loss is 0.0009618723415769637\n",
      "epoch: 9 step: 1032, loss is 0.00045386498095467687\n",
      "epoch: 9 step: 1033, loss is 8.799502211331856e-06\n",
      "epoch: 9 step: 1034, loss is 0.0004526938428170979\n",
      "epoch: 9 step: 1035, loss is 0.002121987286955118\n",
      "epoch: 9 step: 1036, loss is 0.00014143729640636593\n",
      "epoch: 9 step: 1037, loss is 0.0006496130954474211\n",
      "epoch: 9 step: 1038, loss is 0.04072180762887001\n",
      "epoch: 9 step: 1039, loss is 0.12567174434661865\n",
      "epoch: 9 step: 1040, loss is 5.225743734627031e-05\n",
      "epoch: 9 step: 1041, loss is 8.709998655831441e-05\n",
      "epoch: 9 step: 1042, loss is 0.001219418947584927\n",
      "epoch: 9 step: 1043, loss is 6.0078247770434245e-05\n",
      "epoch: 9 step: 1044, loss is 0.06666412204504013\n",
      "epoch: 9 step: 1045, loss is 1.2691249139606953e-05\n",
      "epoch: 9 step: 1046, loss is 0.043383460491895676\n",
      "epoch: 9 step: 1047, loss is 0.00031338652479462326\n",
      "epoch: 9 step: 1048, loss is 0.00013277094694785774\n",
      "epoch: 9 step: 1049, loss is 0.00022545667889062315\n",
      "epoch: 9 step: 1050, loss is 3.250854933867231e-05\n",
      "epoch: 9 step: 1051, loss is 0.000990719418041408\n",
      "epoch: 9 step: 1052, loss is 1.0485499842616264e-05\n",
      "epoch: 9 step: 1053, loss is 0.0016123753739520907\n",
      "epoch: 9 step: 1054, loss is 0.0007934984751045704\n",
      "epoch: 9 step: 1055, loss is 0.0401507243514061\n",
      "epoch: 9 step: 1056, loss is 0.013941165991127491\n",
      "epoch: 9 step: 1057, loss is 8.722117490833625e-05\n",
      "epoch: 9 step: 1058, loss is 8.475837239529938e-05\n",
      "epoch: 9 step: 1059, loss is 0.002291504293680191\n",
      "epoch: 9 step: 1060, loss is 0.15817111730575562\n",
      "epoch: 9 step: 1061, loss is 0.0020814216695725918\n",
      "epoch: 9 step: 1062, loss is 0.0038672140799462795\n",
      "epoch: 9 step: 1063, loss is 0.07574770599603653\n",
      "epoch: 9 step: 1064, loss is 0.005601412151008844\n",
      "epoch: 9 step: 1065, loss is 0.06655832380056381\n",
      "epoch: 9 step: 1066, loss is 0.018203210085630417\n",
      "epoch: 9 step: 1067, loss is 0.00026203025481663644\n",
      "epoch: 9 step: 1068, loss is 0.0006833498482592404\n",
      "epoch: 9 step: 1069, loss is 0.006456249393522739\n",
      "epoch: 9 step: 1070, loss is 8.921997505240142e-05\n",
      "epoch: 9 step: 1071, loss is 0.005111264530569315\n",
      "epoch: 9 step: 1072, loss is 0.006122128572314978\n",
      "epoch: 9 step: 1073, loss is 0.0017023353138938546\n",
      "epoch: 9 step: 1074, loss is 0.013997359201312065\n",
      "epoch: 9 step: 1075, loss is 0.00025547388941049576\n",
      "epoch: 9 step: 1076, loss is 0.0021504953037947416\n",
      "epoch: 9 step: 1077, loss is 0.0005588899366557598\n",
      "epoch: 9 step: 1078, loss is 7.329980871872976e-05\n",
      "epoch: 9 step: 1079, loss is 8.745583181735128e-05\n",
      "epoch: 9 step: 1080, loss is 0.0007456645835191011\n",
      "epoch: 9 step: 1081, loss is 7.293116505024955e-05\n",
      "epoch: 9 step: 1082, loss is 4.626404552254826e-05\n",
      "epoch: 9 step: 1083, loss is 0.00036234856816008687\n",
      "epoch: 9 step: 1084, loss is 0.017444228753447533\n",
      "epoch: 9 step: 1085, loss is 0.0037811705842614174\n",
      "epoch: 9 step: 1086, loss is 0.10316967964172363\n",
      "epoch: 9 step: 1087, loss is 0.0002603069879114628\n",
      "epoch: 9 step: 1088, loss is 0.03467274457216263\n",
      "epoch: 9 step: 1089, loss is 0.00012750709720421582\n",
      "epoch: 9 step: 1090, loss is 5.71373529965058e-05\n",
      "epoch: 9 step: 1091, loss is 3.063764961552806e-05\n",
      "epoch: 9 step: 1092, loss is 0.00012042334128636867\n",
      "epoch: 9 step: 1093, loss is 0.0021521328017115593\n",
      "epoch: 9 step: 1094, loss is 0.00034359251731075346\n",
      "epoch: 9 step: 1095, loss is 0.0004666633321903646\n",
      "epoch: 9 step: 1096, loss is 0.004621804691851139\n",
      "epoch: 9 step: 1097, loss is 1.6370486264349893e-05\n",
      "epoch: 9 step: 1098, loss is 9.622343350201845e-05\n",
      "epoch: 9 step: 1099, loss is 0.00020346316159702837\n",
      "epoch: 9 step: 1100, loss is 0.0001581823598826304\n",
      "epoch: 9 step: 1101, loss is 1.311882988375146e-05\n",
      "epoch: 9 step: 1102, loss is 0.0028465758077800274\n",
      "epoch: 9 step: 1103, loss is 0.00346206221729517\n",
      "epoch: 9 step: 1104, loss is 0.0017151067731902003\n",
      "epoch: 9 step: 1105, loss is 8.129116758937016e-05\n",
      "epoch: 9 step: 1106, loss is 0.00019726624304894358\n",
      "epoch: 9 step: 1107, loss is 0.00010329919314244762\n",
      "epoch: 9 step: 1108, loss is 0.00036222912603989244\n",
      "epoch: 9 step: 1109, loss is 0.006202807184308767\n",
      "epoch: 9 step: 1110, loss is 0.1431654393672943\n",
      "epoch: 9 step: 1111, loss is 0.0021025061141699553\n",
      "epoch: 9 step: 1112, loss is 0.0008514190558344126\n",
      "epoch: 9 step: 1113, loss is 4.6903141992515884e-06\n",
      "epoch: 9 step: 1114, loss is 0.0027922107838094234\n",
      "epoch: 9 step: 1115, loss is 0.002106184372678399\n",
      "epoch: 9 step: 1116, loss is 0.00395527109503746\n",
      "epoch: 9 step: 1117, loss is 2.3336893718806095e-05\n",
      "epoch: 9 step: 1118, loss is 0.0004542813403531909\n",
      "epoch: 9 step: 1119, loss is 0.0048882304690778255\n",
      "epoch: 9 step: 1120, loss is 0.013678274117410183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1121, loss is 3.080331953242421e-05\n",
      "epoch: 9 step: 1122, loss is 7.652756903553382e-05\n",
      "epoch: 9 step: 1123, loss is 0.0002614373224787414\n",
      "epoch: 9 step: 1124, loss is 1.3614447198051494e-05\n",
      "epoch: 9 step: 1125, loss is 0.000955544994212687\n",
      "epoch: 9 step: 1126, loss is 0.00018361772526986897\n",
      "epoch: 9 step: 1127, loss is 0.024780811741948128\n",
      "epoch: 9 step: 1128, loss is 4.373729098006152e-06\n",
      "epoch: 9 step: 1129, loss is 0.00045856653014197946\n",
      "epoch: 9 step: 1130, loss is 0.0003729390155058354\n",
      "epoch: 9 step: 1131, loss is 0.0027524521574378014\n",
      "epoch: 9 step: 1132, loss is 1.0181584002566524e-05\n",
      "epoch: 9 step: 1133, loss is 0.0057495469227433205\n",
      "epoch: 9 step: 1134, loss is 0.0004858759930357337\n",
      "epoch: 9 step: 1135, loss is 0.0002867126895580441\n",
      "epoch: 9 step: 1136, loss is 0.002355583244934678\n",
      "epoch: 9 step: 1137, loss is 0.00027672515716403723\n",
      "epoch: 9 step: 1138, loss is 2.7903179216082208e-06\n",
      "epoch: 9 step: 1139, loss is 0.0007196224760264158\n",
      "epoch: 9 step: 1140, loss is 0.016573596745729446\n",
      "epoch: 9 step: 1141, loss is 0.055658064782619476\n",
      "epoch: 9 step: 1142, loss is 0.0002017555380007252\n",
      "epoch: 9 step: 1143, loss is 8.38696796563454e-05\n",
      "epoch: 9 step: 1144, loss is 9.655776375439018e-05\n",
      "epoch: 9 step: 1145, loss is 3.4289427276235074e-05\n",
      "epoch: 9 step: 1146, loss is 1.0997871868312359e-05\n",
      "epoch: 9 step: 1147, loss is 0.038435738533735275\n",
      "epoch: 9 step: 1148, loss is 0.00012191341375000775\n",
      "epoch: 9 step: 1149, loss is 3.91535104427021e-06\n",
      "epoch: 9 step: 1150, loss is 1.6094627426355146e-05\n",
      "epoch: 9 step: 1151, loss is 7.903676305431873e-05\n",
      "epoch: 9 step: 1152, loss is 1.110923221858684e-05\n",
      "epoch: 9 step: 1153, loss is 0.0006516812718473375\n",
      "epoch: 9 step: 1154, loss is 0.00013831385876983404\n",
      "epoch: 9 step: 1155, loss is 0.011615696363151073\n",
      "epoch: 9 step: 1156, loss is 0.00017998323892243207\n",
      "epoch: 9 step: 1157, loss is 0.008629022166132927\n",
      "epoch: 9 step: 1158, loss is 4.3049632949987426e-05\n",
      "epoch: 9 step: 1159, loss is 3.678528810269199e-05\n",
      "epoch: 9 step: 1160, loss is 0.0027422981802374125\n",
      "epoch: 9 step: 1161, loss is 8.103498112177476e-05\n",
      "epoch: 9 step: 1162, loss is 0.10840197652578354\n",
      "epoch: 9 step: 1163, loss is 0.0006888208445161581\n",
      "epoch: 9 step: 1164, loss is 0.0011177884880453348\n",
      "epoch: 9 step: 1165, loss is 0.07745315879583359\n",
      "epoch: 9 step: 1166, loss is 0.00017893909534905106\n",
      "epoch: 9 step: 1167, loss is 0.001255464507266879\n",
      "epoch: 9 step: 1168, loss is 3.920928793377243e-05\n",
      "epoch: 9 step: 1169, loss is 0.031842026859521866\n",
      "epoch: 9 step: 1170, loss is 0.00014327628014143556\n",
      "epoch: 9 step: 1171, loss is 0.0005405321717262268\n",
      "epoch: 9 step: 1172, loss is 4.017673199996352e-05\n",
      "epoch: 9 step: 1173, loss is 0.0012281867675483227\n",
      "epoch: 9 step: 1174, loss is 2.0167080947430804e-05\n",
      "epoch: 9 step: 1175, loss is 0.0034549348056316376\n",
      "epoch: 9 step: 1176, loss is 0.007995108142495155\n",
      "epoch: 9 step: 1177, loss is 0.02012275718152523\n",
      "epoch: 9 step: 1178, loss is 0.00027035840321332216\n",
      "epoch: 9 step: 1179, loss is 0.0028008429799228907\n",
      "epoch: 9 step: 1180, loss is 0.00017907493747770786\n",
      "epoch: 9 step: 1181, loss is 0.00011122148862341419\n",
      "epoch: 9 step: 1182, loss is 0.003653589403256774\n",
      "epoch: 9 step: 1183, loss is 0.08173717558383942\n",
      "epoch: 9 step: 1184, loss is 0.0010089492425322533\n",
      "epoch: 9 step: 1185, loss is 0.0013486983953043818\n",
      "epoch: 9 step: 1186, loss is 0.0013613298069685698\n",
      "epoch: 9 step: 1187, loss is 0.1237291619181633\n",
      "epoch: 9 step: 1188, loss is 0.0018836549716070294\n",
      "epoch: 9 step: 1189, loss is 0.0001335507695330307\n",
      "epoch: 9 step: 1190, loss is 0.00033715504105202854\n",
      "epoch: 9 step: 1191, loss is 0.0013768563512712717\n",
      "epoch: 9 step: 1192, loss is 0.002989813918247819\n",
      "epoch: 9 step: 1193, loss is 3.158466279273853e-05\n",
      "epoch: 9 step: 1194, loss is 0.01861879602074623\n",
      "epoch: 9 step: 1195, loss is 1.034917113429401e-05\n",
      "epoch: 9 step: 1196, loss is 0.00261661596596241\n",
      "epoch: 9 step: 1197, loss is 1.518667249911232e-05\n",
      "epoch: 9 step: 1198, loss is 0.004817287437617779\n",
      "epoch: 9 step: 1199, loss is 0.00047254806850105524\n",
      "epoch: 9 step: 1200, loss is 0.002719363896176219\n",
      "epoch: 9 step: 1201, loss is 0.06352779269218445\n",
      "epoch: 9 step: 1202, loss is 7.956457557156682e-05\n",
      "epoch: 9 step: 1203, loss is 0.00035004361416213214\n",
      "epoch: 9 step: 1204, loss is 0.00021928615751676261\n",
      "epoch: 9 step: 1205, loss is 0.0013501631328836083\n",
      "epoch: 9 step: 1206, loss is 0.00010413949348730966\n",
      "epoch: 9 step: 1207, loss is 0.0027076173573732376\n",
      "epoch: 9 step: 1208, loss is 0.00835479237139225\n",
      "epoch: 9 step: 1209, loss is 0.00011665679630823433\n",
      "epoch: 9 step: 1210, loss is 5.433860496850684e-05\n",
      "epoch: 9 step: 1211, loss is 0.00018627815006766468\n",
      "epoch: 9 step: 1212, loss is 0.000917966419365257\n",
      "epoch: 9 step: 1213, loss is 0.004540194757282734\n",
      "epoch: 9 step: 1214, loss is 0.00010699436097638682\n",
      "epoch: 9 step: 1215, loss is 0.11011239141225815\n",
      "epoch: 9 step: 1216, loss is 2.391533416812308e-05\n",
      "epoch: 9 step: 1217, loss is 0.0053893993608653545\n",
      "epoch: 9 step: 1218, loss is 7.763374014757574e-05\n",
      "epoch: 9 step: 1219, loss is 2.6710608835855965e-06\n",
      "epoch: 9 step: 1220, loss is 0.002135963412001729\n",
      "epoch: 9 step: 1221, loss is 0.0014033782063052058\n",
      "epoch: 9 step: 1222, loss is 0.0003222742525395006\n",
      "epoch: 9 step: 1223, loss is 0.00226984778419137\n",
      "epoch: 9 step: 1224, loss is 0.0002457547525409609\n",
      "epoch: 9 step: 1225, loss is 7.827267836546525e-05\n",
      "epoch: 9 step: 1226, loss is 0.00017374141316395253\n",
      "epoch: 9 step: 1227, loss is 0.003489557420834899\n",
      "epoch: 9 step: 1228, loss is 0.0020776442252099514\n",
      "epoch: 9 step: 1229, loss is 0.001733022159896791\n",
      "epoch: 9 step: 1230, loss is 1.613500171515625e-05\n",
      "epoch: 9 step: 1231, loss is 7.600471144542098e-05\n",
      "epoch: 9 step: 1232, loss is 0.00019426507060416043\n",
      "epoch: 9 step: 1233, loss is 0.0071555147878825665\n",
      "epoch: 9 step: 1234, loss is 0.0011188506614416838\n",
      "epoch: 9 step: 1235, loss is 0.0003345166624058038\n",
      "epoch: 9 step: 1236, loss is 0.012129717506468296\n",
      "epoch: 9 step: 1237, loss is 4.683625957113691e-05\n",
      "epoch: 9 step: 1238, loss is 0.0025324970483779907\n",
      "epoch: 9 step: 1239, loss is 0.0005216346471570432\n",
      "epoch: 9 step: 1240, loss is 0.02295553870499134\n",
      "epoch: 9 step: 1241, loss is 2.4562186808907427e-05\n",
      "epoch: 9 step: 1242, loss is 0.00010314326209481806\n",
      "epoch: 9 step: 1243, loss is 0.0007275227690115571\n",
      "epoch: 9 step: 1244, loss is 9.656586371420417e-06\n",
      "epoch: 9 step: 1245, loss is 0.0007962853414937854\n",
      "epoch: 9 step: 1246, loss is 0.01702551729977131\n",
      "epoch: 9 step: 1247, loss is 5.9529429563554004e-05\n",
      "epoch: 9 step: 1248, loss is 0.01762067899107933\n",
      "epoch: 9 step: 1249, loss is 0.0002196200512116775\n",
      "epoch: 9 step: 1250, loss is 0.0005411317688412964\n",
      "epoch: 9 step: 1251, loss is 0.0021844017319381237\n",
      "epoch: 9 step: 1252, loss is 0.0014659063890576363\n",
      "epoch: 9 step: 1253, loss is 1.1879166777362116e-05\n",
      "epoch: 9 step: 1254, loss is 0.04818189889192581\n",
      "epoch: 9 step: 1255, loss is 4.9137292080558836e-05\n",
      "epoch: 9 step: 1256, loss is 0.0003879343275912106\n",
      "epoch: 9 step: 1257, loss is 0.0013641428668051958\n",
      "epoch: 9 step: 1258, loss is 1.0132887382496847e-06\n",
      "epoch: 9 step: 1259, loss is 0.0070853447541594505\n",
      "epoch: 9 step: 1260, loss is 5.301239525579149e-06\n",
      "epoch: 9 step: 1261, loss is 0.01277963537722826\n",
      "epoch: 9 step: 1262, loss is 0.0017336849123239517\n",
      "epoch: 9 step: 1263, loss is 0.00019341368169989437\n",
      "epoch: 9 step: 1264, loss is 0.01904933527112007\n",
      "epoch: 9 step: 1265, loss is 0.0006929738447070122\n",
      "epoch: 9 step: 1266, loss is 0.00027569010853767395\n",
      "epoch: 9 step: 1267, loss is 2.0858124116784893e-05\n",
      "epoch: 9 step: 1268, loss is 9.009931818582118e-05\n",
      "epoch: 9 step: 1269, loss is 0.004612463992089033\n",
      "epoch: 9 step: 1270, loss is 0.01042023953050375\n",
      "epoch: 9 step: 1271, loss is 0.0008081773412413895\n",
      "epoch: 9 step: 1272, loss is 0.030001889914274216\n",
      "epoch: 9 step: 1273, loss is 0.00014713994460180402\n",
      "epoch: 9 step: 1274, loss is 0.00038667142507620156\n",
      "epoch: 9 step: 1275, loss is 6.418208067771047e-05\n",
      "epoch: 9 step: 1276, loss is 0.03948087617754936\n",
      "epoch: 9 step: 1277, loss is 0.0022484520450234413\n",
      "epoch: 9 step: 1278, loss is 0.0027361370157450438\n",
      "epoch: 9 step: 1279, loss is 7.655724402866326e-06\n",
      "epoch: 9 step: 1280, loss is 3.4423214856360573e-06\n",
      "epoch: 9 step: 1281, loss is 1.4872248357278295e-05\n",
      "epoch: 9 step: 1282, loss is 0.00018985792121384293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1283, loss is 0.0007121172966435552\n",
      "epoch: 9 step: 1284, loss is 0.01774395816028118\n",
      "epoch: 9 step: 1285, loss is 0.0024347109720110893\n",
      "epoch: 9 step: 1286, loss is 3.3978114515775815e-05\n",
      "epoch: 9 step: 1287, loss is 0.00018956430722028017\n",
      "epoch: 9 step: 1288, loss is 0.0013200759422034025\n",
      "epoch: 9 step: 1289, loss is 0.00040925905341282487\n",
      "epoch: 9 step: 1290, loss is 0.02612622268497944\n",
      "epoch: 9 step: 1291, loss is 0.0007263785810209811\n",
      "epoch: 9 step: 1292, loss is 0.0017065549036487937\n",
      "epoch: 9 step: 1293, loss is 1.5081734090927057e-05\n",
      "epoch: 9 step: 1294, loss is 0.00025958637706935406\n",
      "epoch: 9 step: 1295, loss is 0.00022087864635977894\n",
      "epoch: 9 step: 1296, loss is 0.00032314821146428585\n",
      "epoch: 9 step: 1297, loss is 0.000825977826025337\n",
      "epoch: 9 step: 1298, loss is 0.0016487040556967258\n",
      "epoch: 9 step: 1299, loss is 1.408181219630933e-06\n",
      "epoch: 9 step: 1300, loss is 0.00013034870789851993\n",
      "epoch: 9 step: 1301, loss is 0.0019060500198975205\n",
      "epoch: 9 step: 1302, loss is 0.004784092307090759\n",
      "epoch: 9 step: 1303, loss is 6.187849066918716e-06\n",
      "epoch: 9 step: 1304, loss is 0.0005800333456136286\n",
      "epoch: 9 step: 1305, loss is 0.007004923187196255\n",
      "epoch: 9 step: 1306, loss is 0.005690296646207571\n",
      "epoch: 9 step: 1307, loss is 0.0001349777594441548\n",
      "epoch: 9 step: 1308, loss is 3.151635610265657e-05\n",
      "epoch: 9 step: 1309, loss is 4.563501715892926e-05\n",
      "epoch: 9 step: 1310, loss is 5.267002779874019e-05\n",
      "epoch: 9 step: 1311, loss is 0.048357412219047546\n",
      "epoch: 9 step: 1312, loss is 0.00010035552986664698\n",
      "epoch: 9 step: 1313, loss is 0.0005712130223400891\n",
      "epoch: 9 step: 1314, loss is 2.6355948648415506e-05\n",
      "epoch: 9 step: 1315, loss is 9.242902706319e-06\n",
      "epoch: 9 step: 1316, loss is 0.0010359594598412514\n",
      "epoch: 9 step: 1317, loss is 0.001000064890831709\n",
      "epoch: 9 step: 1318, loss is 0.00019693879585247487\n",
      "epoch: 9 step: 1319, loss is 0.0058936551213264465\n",
      "epoch: 9 step: 1320, loss is 0.005499858874827623\n",
      "epoch: 9 step: 1321, loss is 0.0018046917393803596\n",
      "epoch: 9 step: 1322, loss is 9.977107765735127e-06\n",
      "epoch: 9 step: 1323, loss is 0.00422010337933898\n",
      "epoch: 9 step: 1324, loss is 0.00011816677579190582\n",
      "epoch: 9 step: 1325, loss is 5.737041283282451e-05\n",
      "epoch: 9 step: 1326, loss is 0.0001253516529686749\n",
      "epoch: 9 step: 1327, loss is 0.00020643547759391367\n",
      "epoch: 9 step: 1328, loss is 0.002518201246857643\n",
      "epoch: 9 step: 1329, loss is 1.524131675978424e-05\n",
      "epoch: 9 step: 1330, loss is 0.0023142718710005283\n",
      "epoch: 9 step: 1331, loss is 7.197389641078189e-05\n",
      "epoch: 9 step: 1332, loss is 0.011852549389004707\n",
      "epoch: 9 step: 1333, loss is 1.5135278772504535e-05\n",
      "epoch: 9 step: 1334, loss is 0.015750166028738022\n",
      "epoch: 9 step: 1335, loss is 0.0009406418539583683\n",
      "epoch: 9 step: 1336, loss is 0.0007382102194242179\n",
      "epoch: 9 step: 1337, loss is 0.24839496612548828\n",
      "epoch: 9 step: 1338, loss is 0.0004779876908287406\n",
      "epoch: 9 step: 1339, loss is 1.5124292076507118e-05\n",
      "epoch: 9 step: 1340, loss is 0.031797681003808975\n",
      "epoch: 9 step: 1341, loss is 0.01821155659854412\n",
      "epoch: 9 step: 1342, loss is 0.00727404048666358\n",
      "epoch: 9 step: 1343, loss is 0.0010850413236767054\n",
      "epoch: 9 step: 1344, loss is 4.366139819467207e-06\n",
      "epoch: 9 step: 1345, loss is 0.00010293654486304149\n",
      "epoch: 9 step: 1346, loss is 0.1880989521741867\n",
      "epoch: 9 step: 1347, loss is 0.0003883018798660487\n",
      "epoch: 9 step: 1348, loss is 2.216562097601127e-05\n",
      "epoch: 9 step: 1349, loss is 0.00010893388389376923\n",
      "epoch: 9 step: 1350, loss is 1.9921570128644817e-05\n",
      "epoch: 9 step: 1351, loss is 0.0016488959081470966\n",
      "epoch: 9 step: 1352, loss is 0.00019296740356367081\n",
      "epoch: 9 step: 1353, loss is 6.531295366585255e-05\n",
      "epoch: 9 step: 1354, loss is 0.0025279223918914795\n",
      "epoch: 9 step: 1355, loss is 0.0002308402326889336\n",
      "epoch: 9 step: 1356, loss is 0.011743543669581413\n",
      "epoch: 9 step: 1357, loss is 0.003299911506474018\n",
      "epoch: 9 step: 1358, loss is 0.0019016230944544077\n",
      "epoch: 9 step: 1359, loss is 0.0007297526462934911\n",
      "epoch: 9 step: 1360, loss is 0.006271782331168652\n",
      "epoch: 9 step: 1361, loss is 9.041632438311353e-06\n",
      "epoch: 9 step: 1362, loss is 1.3827826478518546e-05\n",
      "epoch: 9 step: 1363, loss is 0.01911417581140995\n",
      "epoch: 9 step: 1364, loss is 1.0235806257696822e-05\n",
      "epoch: 9 step: 1365, loss is 0.00015574735880363733\n",
      "epoch: 9 step: 1366, loss is 0.0013523524394258857\n",
      "epoch: 9 step: 1367, loss is 0.0003970004618167877\n",
      "epoch: 9 step: 1368, loss is 0.08465797454118729\n",
      "epoch: 9 step: 1369, loss is 0.001441383734345436\n",
      "epoch: 9 step: 1370, loss is 6.276150816120207e-05\n",
      "epoch: 9 step: 1371, loss is 0.0028489157557487488\n",
      "epoch: 9 step: 1372, loss is 5.3020576160633937e-05\n",
      "epoch: 9 step: 1373, loss is 0.07464819401502609\n",
      "epoch: 9 step: 1374, loss is 0.028834186494350433\n",
      "epoch: 9 step: 1375, loss is 0.0003341557167004794\n",
      "epoch: 9 step: 1376, loss is 0.014020453207194805\n",
      "epoch: 9 step: 1377, loss is 0.006644065026193857\n",
      "epoch: 9 step: 1378, loss is 0.00028085883241146803\n",
      "epoch: 9 step: 1379, loss is 0.0008817905909381807\n",
      "epoch: 9 step: 1380, loss is 1.183801214210689e-05\n",
      "epoch: 9 step: 1381, loss is 0.00011653846013359725\n",
      "epoch: 9 step: 1382, loss is 0.04816530644893646\n",
      "epoch: 9 step: 1383, loss is 0.00012061469897162169\n",
      "epoch: 9 step: 1384, loss is 0.0008514877408742905\n",
      "epoch: 9 step: 1385, loss is 0.0008448809385299683\n",
      "epoch: 9 step: 1386, loss is 0.01886744424700737\n",
      "epoch: 9 step: 1387, loss is 3.662550079752691e-05\n",
      "epoch: 9 step: 1388, loss is 0.00036910257767885923\n",
      "epoch: 9 step: 1389, loss is 0.017128553241491318\n",
      "epoch: 9 step: 1390, loss is 0.0005589106003753841\n",
      "epoch: 9 step: 1391, loss is 0.00090902263764292\n",
      "epoch: 9 step: 1392, loss is 0.15068882703781128\n",
      "epoch: 9 step: 1393, loss is 0.0039906431920826435\n",
      "epoch: 9 step: 1394, loss is 0.0012191312853246927\n",
      "epoch: 9 step: 1395, loss is 5.669591701007448e-05\n",
      "epoch: 9 step: 1396, loss is 0.004178243689239025\n",
      "epoch: 9 step: 1397, loss is 0.00040371829527430236\n",
      "epoch: 9 step: 1398, loss is 4.6865206968504936e-06\n",
      "epoch: 9 step: 1399, loss is 0.002007486531510949\n",
      "epoch: 9 step: 1400, loss is 0.010458274744451046\n",
      "epoch: 9 step: 1401, loss is 0.02891978994011879\n",
      "epoch: 9 step: 1402, loss is 0.0022743234876543283\n",
      "epoch: 9 step: 1403, loss is 0.015034472569823265\n",
      "epoch: 9 step: 1404, loss is 8.615383194410242e-06\n",
      "epoch: 9 step: 1405, loss is 3.63906983693596e-05\n",
      "epoch: 9 step: 1406, loss is 0.017540961503982544\n",
      "epoch: 9 step: 1407, loss is 0.00175991072319448\n",
      "epoch: 9 step: 1408, loss is 0.0015499484725296497\n",
      "epoch: 9 step: 1409, loss is 1.580333264428191e-05\n",
      "epoch: 9 step: 1410, loss is 9.407516336068511e-05\n",
      "epoch: 9 step: 1411, loss is 0.0028117042966187\n",
      "epoch: 9 step: 1412, loss is 0.00861633662134409\n",
      "epoch: 9 step: 1413, loss is 7.912887667771429e-06\n",
      "epoch: 9 step: 1414, loss is 0.009893490932881832\n",
      "epoch: 9 step: 1415, loss is 0.044078510254621506\n",
      "epoch: 9 step: 1416, loss is 0.0005084325093775988\n",
      "epoch: 9 step: 1417, loss is 0.0029457733035087585\n",
      "epoch: 9 step: 1418, loss is 0.015450634993612766\n",
      "epoch: 9 step: 1419, loss is 0.00028836907586082816\n",
      "epoch: 9 step: 1420, loss is 0.0010410085087642074\n",
      "epoch: 9 step: 1421, loss is 0.0012190602719783783\n",
      "epoch: 9 step: 1422, loss is 0.0013155497144907713\n",
      "epoch: 9 step: 1423, loss is 0.03773590922355652\n",
      "epoch: 9 step: 1424, loss is 0.009429584257304668\n",
      "epoch: 9 step: 1425, loss is 0.0005609412910416722\n",
      "epoch: 9 step: 1426, loss is 0.0021746158599853516\n",
      "epoch: 9 step: 1427, loss is 0.03247358277440071\n",
      "epoch: 9 step: 1428, loss is 0.001746167428791523\n",
      "epoch: 9 step: 1429, loss is 0.005214402452111244\n",
      "epoch: 9 step: 1430, loss is 0.000603809196036309\n",
      "epoch: 9 step: 1431, loss is 0.037169769406318665\n",
      "epoch: 9 step: 1432, loss is 5.170385702513158e-05\n",
      "epoch: 9 step: 1433, loss is 1.608180537004955e-05\n",
      "epoch: 9 step: 1434, loss is 0.0008307602256536484\n",
      "epoch: 9 step: 1435, loss is 0.023519454523921013\n",
      "epoch: 9 step: 1436, loss is 0.002831208286806941\n",
      "epoch: 9 step: 1437, loss is 0.000790129357483238\n",
      "epoch: 9 step: 1438, loss is 0.11701437830924988\n",
      "epoch: 9 step: 1439, loss is 1.3644827049574815e-05\n",
      "epoch: 9 step: 1440, loss is 0.0003417526895646006\n",
      "epoch: 9 step: 1441, loss is 0.004356075543910265\n",
      "epoch: 9 step: 1442, loss is 0.00019876143778674304\n",
      "epoch: 9 step: 1443, loss is 0.021102819591760635\n",
      "epoch: 9 step: 1444, loss is 0.00022243254352360964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1445, loss is 0.00023941784456837922\n",
      "epoch: 9 step: 1446, loss is 0.0025037750601768494\n",
      "epoch: 9 step: 1447, loss is 5.096291715744883e-06\n",
      "epoch: 9 step: 1448, loss is 0.0004126543353777379\n",
      "epoch: 9 step: 1449, loss is 0.0002121000870829448\n",
      "epoch: 9 step: 1450, loss is 0.021562781184911728\n",
      "epoch: 9 step: 1451, loss is 0.0003674672043416649\n",
      "epoch: 9 step: 1452, loss is 0.0260800588876009\n",
      "epoch: 9 step: 1453, loss is 5.322486686054617e-05\n",
      "epoch: 9 step: 1454, loss is 9.545122156850994e-05\n",
      "epoch: 9 step: 1455, loss is 0.013881364837288857\n",
      "epoch: 9 step: 1456, loss is 0.0034028824884444475\n",
      "epoch: 9 step: 1457, loss is 0.04702680930495262\n",
      "epoch: 9 step: 1458, loss is 7.561154052382335e-05\n",
      "epoch: 9 step: 1459, loss is 0.18343454599380493\n",
      "epoch: 9 step: 1460, loss is 0.00022443020134232938\n",
      "epoch: 9 step: 1461, loss is 0.0020687119103968143\n",
      "epoch: 9 step: 1462, loss is 0.00010216467489954084\n",
      "epoch: 9 step: 1463, loss is 8.022929250728339e-06\n",
      "epoch: 9 step: 1464, loss is 9.473494719713926e-05\n",
      "epoch: 9 step: 1465, loss is 0.0004889254341833293\n",
      "epoch: 9 step: 1466, loss is 0.0374344065785408\n",
      "epoch: 9 step: 1467, loss is 0.086070217192173\n",
      "epoch: 9 step: 1468, loss is 0.0004470236599445343\n",
      "epoch: 9 step: 1469, loss is 0.007753146346658468\n",
      "epoch: 9 step: 1470, loss is 0.08138655126094818\n",
      "epoch: 9 step: 1471, loss is 0.001348772319033742\n",
      "epoch: 9 step: 1472, loss is 0.060736484825611115\n",
      "epoch: 9 step: 1473, loss is 3.006359293067362e-06\n",
      "epoch: 9 step: 1474, loss is 0.0015827241586521268\n",
      "epoch: 9 step: 1475, loss is 0.045277632772922516\n",
      "epoch: 9 step: 1476, loss is 0.0007297335541807115\n",
      "epoch: 9 step: 1477, loss is 0.0016892710700631142\n",
      "epoch: 9 step: 1478, loss is 2.3327214876189828e-05\n",
      "epoch: 9 step: 1479, loss is 0.08352868258953094\n",
      "epoch: 9 step: 1480, loss is 0.12115420401096344\n",
      "epoch: 9 step: 1481, loss is 0.00015473047096747905\n",
      "epoch: 9 step: 1482, loss is 1.4895502317813225e-05\n",
      "epoch: 9 step: 1483, loss is 0.10723377764225006\n",
      "epoch: 9 step: 1484, loss is 7.908591214800254e-05\n",
      "epoch: 9 step: 1485, loss is 3.106512303929776e-05\n",
      "epoch: 9 step: 1486, loss is 0.001076225540600717\n",
      "epoch: 9 step: 1487, loss is 6.806262717873324e-06\n",
      "epoch: 9 step: 1488, loss is 0.05145571380853653\n",
      "epoch: 9 step: 1489, loss is 0.0003853798843920231\n",
      "epoch: 9 step: 1490, loss is 0.004220014438033104\n",
      "epoch: 9 step: 1491, loss is 0.02011481486260891\n",
      "epoch: 9 step: 1492, loss is 0.06264696270227432\n",
      "epoch: 9 step: 1493, loss is 0.012670736759901047\n",
      "epoch: 9 step: 1494, loss is 0.0016047043027356267\n",
      "epoch: 9 step: 1495, loss is 4.690318291977746e-06\n",
      "epoch: 9 step: 1496, loss is 6.792303611291572e-05\n",
      "epoch: 9 step: 1497, loss is 6.81933161104098e-05\n",
      "epoch: 9 step: 1498, loss is 5.1948532927781343e-05\n",
      "epoch: 9 step: 1499, loss is 4.480806092033163e-05\n",
      "epoch: 9 step: 1500, loss is 0.000672649999614805\n",
      "epoch: 9 step: 1501, loss is 0.02196759171783924\n",
      "epoch: 9 step: 1502, loss is 0.02177194133400917\n",
      "epoch: 9 step: 1503, loss is 0.00035903381649404764\n",
      "epoch: 9 step: 1504, loss is 0.0008100265404209495\n",
      "epoch: 9 step: 1505, loss is 0.0012433978263288736\n",
      "epoch: 9 step: 1506, loss is 0.00046579440822824836\n",
      "epoch: 9 step: 1507, loss is 0.0026725998613983393\n",
      "epoch: 9 step: 1508, loss is 0.004555205348879099\n",
      "epoch: 9 step: 1509, loss is 0.006617472507059574\n",
      "epoch: 9 step: 1510, loss is 0.0035284452605992556\n",
      "epoch: 9 step: 1511, loss is 9.178946493193507e-05\n",
      "epoch: 9 step: 1512, loss is 0.00021715594630222768\n",
      "epoch: 9 step: 1513, loss is 0.005938905291259289\n",
      "epoch: 9 step: 1514, loss is 0.001297677750699222\n",
      "epoch: 9 step: 1515, loss is 0.0003856648982036859\n",
      "epoch: 9 step: 1516, loss is 0.02060673199594021\n",
      "epoch: 9 step: 1517, loss is 0.004070485010743141\n",
      "epoch: 9 step: 1518, loss is 1.5782194168423302e-05\n",
      "epoch: 9 step: 1519, loss is 0.004060620907694101\n",
      "epoch: 9 step: 1520, loss is 0.1476457715034485\n",
      "epoch: 9 step: 1521, loss is 1.1387308404664509e-05\n",
      "epoch: 9 step: 1522, loss is 0.011330809444189072\n",
      "epoch: 9 step: 1523, loss is 0.07873591035604477\n",
      "epoch: 9 step: 1524, loss is 0.00032109743915498257\n",
      "epoch: 9 step: 1525, loss is 0.0001593196502653882\n",
      "epoch: 9 step: 1526, loss is 0.0005308634135872126\n",
      "epoch: 9 step: 1527, loss is 0.004806340206414461\n",
      "epoch: 9 step: 1528, loss is 0.0008672254625707865\n",
      "epoch: 9 step: 1529, loss is 9.131067599810194e-06\n",
      "epoch: 9 step: 1530, loss is 0.007661953568458557\n",
      "epoch: 9 step: 1531, loss is 1.2698863429250196e-05\n",
      "epoch: 9 step: 1532, loss is 0.11605759710073471\n",
      "epoch: 9 step: 1533, loss is 0.00013811129610985518\n",
      "epoch: 9 step: 1534, loss is 0.003658549627289176\n",
      "epoch: 9 step: 1535, loss is 0.01641600951552391\n",
      "epoch: 9 step: 1536, loss is 0.00251982850022614\n",
      "epoch: 9 step: 1537, loss is 0.04287376254796982\n",
      "epoch: 9 step: 1538, loss is 8.963832078734413e-05\n",
      "epoch: 9 step: 1539, loss is 6.083205153117888e-05\n",
      "epoch: 9 step: 1540, loss is 0.0006007109768688679\n",
      "epoch: 9 step: 1541, loss is 0.001199654070660472\n",
      "epoch: 9 step: 1542, loss is 0.01894538477063179\n",
      "epoch: 9 step: 1543, loss is 7.69815596868284e-05\n",
      "epoch: 9 step: 1544, loss is 0.0004906996036879718\n",
      "epoch: 9 step: 1545, loss is 0.08976354449987411\n",
      "epoch: 9 step: 1546, loss is 0.002232614438980818\n",
      "epoch: 9 step: 1547, loss is 0.0006611062563024461\n",
      "epoch: 9 step: 1548, loss is 0.00043655000627040863\n",
      "epoch: 9 step: 1549, loss is 0.09016085416078568\n",
      "epoch: 9 step: 1550, loss is 0.10586440563201904\n",
      "epoch: 9 step: 1551, loss is 0.0004598865343723446\n",
      "epoch: 9 step: 1552, loss is 0.004202946554869413\n",
      "epoch: 9 step: 1553, loss is 0.001403630943968892\n",
      "epoch: 9 step: 1554, loss is 0.21055364608764648\n",
      "epoch: 9 step: 1555, loss is 0.020644476637244225\n",
      "epoch: 9 step: 1556, loss is 0.001977583859115839\n",
      "epoch: 9 step: 1557, loss is 0.006218543276190758\n",
      "epoch: 9 step: 1558, loss is 8.959573278843891e-06\n",
      "epoch: 9 step: 1559, loss is 0.05184582993388176\n",
      "epoch: 9 step: 1560, loss is 0.00014872440078761429\n",
      "epoch: 9 step: 1561, loss is 0.04823939874768257\n",
      "epoch: 9 step: 1562, loss is 0.00013995784684084356\n",
      "epoch: 9 step: 1563, loss is 0.0018558934098109603\n",
      "epoch: 9 step: 1564, loss is 0.003230224596336484\n",
      "epoch: 9 step: 1565, loss is 0.000822367612272501\n",
      "epoch: 9 step: 1566, loss is 0.0014598565176129341\n",
      "epoch: 9 step: 1567, loss is 0.0010279265698045492\n",
      "epoch: 9 step: 1568, loss is 0.00013272919750306755\n",
      "epoch: 9 step: 1569, loss is 5.384440009947866e-05\n",
      "epoch: 9 step: 1570, loss is 0.0001361460890620947\n",
      "epoch: 9 step: 1571, loss is 8.574663297622465e-06\n",
      "epoch: 9 step: 1572, loss is 0.03202513977885246\n",
      "epoch: 9 step: 1573, loss is 0.00011627671483438462\n",
      "epoch: 9 step: 1574, loss is 0.0010712638031691313\n",
      "epoch: 9 step: 1575, loss is 5.730580596718937e-05\n",
      "epoch: 9 step: 1576, loss is 4.566801362670958e-05\n",
      "epoch: 9 step: 1577, loss is 0.02901296690106392\n",
      "epoch: 9 step: 1578, loss is 6.105973170633661e-06\n",
      "epoch: 9 step: 1579, loss is 0.0005264464998617768\n",
      "epoch: 9 step: 1580, loss is 3.4370921639492735e-05\n",
      "epoch: 9 step: 1581, loss is 0.07896516472101212\n",
      "epoch: 9 step: 1582, loss is 0.01743130199611187\n",
      "epoch: 9 step: 1583, loss is 0.0012294880580157042\n",
      "epoch: 9 step: 1584, loss is 0.0003575726877897978\n",
      "epoch: 9 step: 1585, loss is 0.01935281604528427\n",
      "epoch: 9 step: 1586, loss is 0.009808557108044624\n",
      "epoch: 9 step: 1587, loss is 0.04584144055843353\n",
      "epoch: 9 step: 1588, loss is 0.14010336995124817\n",
      "epoch: 9 step: 1589, loss is 0.08342243731021881\n",
      "epoch: 9 step: 1590, loss is 0.0038509098812937737\n",
      "epoch: 9 step: 1591, loss is 0.00010587293945718557\n",
      "epoch: 9 step: 1592, loss is 0.0006502731121145189\n",
      "epoch: 9 step: 1593, loss is 0.002055681310594082\n",
      "epoch: 9 step: 1594, loss is 0.03862399235367775\n",
      "epoch: 9 step: 1595, loss is 0.0018063685856759548\n",
      "epoch: 9 step: 1596, loss is 0.0006397692486643791\n",
      "epoch: 9 step: 1597, loss is 0.34801074862480164\n",
      "epoch: 9 step: 1598, loss is 0.00013753441453445703\n",
      "epoch: 9 step: 1599, loss is 0.10148048400878906\n",
      "epoch: 9 step: 1600, loss is 0.002495316555723548\n",
      "epoch: 9 step: 1601, loss is 0.0025650637689977884\n",
      "epoch: 9 step: 1602, loss is 0.011732639744877815\n",
      "epoch: 9 step: 1603, loss is 7.182143599493429e-05\n",
      "epoch: 9 step: 1604, loss is 0.0013625600840896368\n",
      "epoch: 9 step: 1605, loss is 0.0015346449799835682\n",
      "epoch: 9 step: 1606, loss is 0.00036231696140021086\n",
      "epoch: 9 step: 1607, loss is 0.0016023636562749743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1608, loss is 0.0033068587072193623\n",
      "epoch: 9 step: 1609, loss is 0.003550594439730048\n",
      "epoch: 9 step: 1610, loss is 0.07126114517450333\n",
      "epoch: 9 step: 1611, loss is 0.004114414565265179\n",
      "epoch: 9 step: 1612, loss is 0.0050161839462816715\n",
      "epoch: 9 step: 1613, loss is 0.0024344115518033504\n",
      "epoch: 9 step: 1614, loss is 5.685925862053409e-05\n",
      "epoch: 9 step: 1615, loss is 0.0003023177559953183\n",
      "epoch: 9 step: 1616, loss is 0.0022774271201342344\n",
      "epoch: 9 step: 1617, loss is 0.0018774302443489432\n",
      "epoch: 9 step: 1618, loss is 0.0021791609469801188\n",
      "epoch: 9 step: 1619, loss is 0.0009917825227603316\n",
      "epoch: 9 step: 1620, loss is 0.0013649595202878118\n",
      "epoch: 9 step: 1621, loss is 0.057742808014154434\n",
      "epoch: 9 step: 1622, loss is 5.938059985055588e-05\n",
      "epoch: 9 step: 1623, loss is 0.024830490350723267\n",
      "epoch: 9 step: 1624, loss is 0.006980247795581818\n",
      "epoch: 9 step: 1625, loss is 0.027095181867480278\n",
      "epoch: 9 step: 1626, loss is 0.0001517814671387896\n",
      "epoch: 9 step: 1627, loss is 0.00014305436343420297\n",
      "epoch: 9 step: 1628, loss is 0.004877010360360146\n",
      "epoch: 9 step: 1629, loss is 3.868846033583395e-05\n",
      "epoch: 9 step: 1630, loss is 0.00012094654812244698\n",
      "epoch: 9 step: 1631, loss is 0.0004191743500996381\n",
      "epoch: 9 step: 1632, loss is 0.00016569424769841135\n",
      "epoch: 9 step: 1633, loss is 0.00020502299594227225\n",
      "epoch: 9 step: 1634, loss is 0.0002961027785204351\n",
      "epoch: 9 step: 1635, loss is 0.0011855041375383735\n",
      "epoch: 9 step: 1636, loss is 0.002885387744754553\n",
      "epoch: 9 step: 1637, loss is 0.0014193950919434428\n",
      "epoch: 9 step: 1638, loss is 0.00806164275854826\n",
      "epoch: 9 step: 1639, loss is 0.10180746018886566\n",
      "epoch: 9 step: 1640, loss is 0.00029467541025951505\n",
      "epoch: 9 step: 1641, loss is 0.000502761104144156\n",
      "epoch: 9 step: 1642, loss is 0.0008273189887404442\n",
      "epoch: 9 step: 1643, loss is 0.0033684363588690758\n",
      "epoch: 9 step: 1644, loss is 0.06645525991916656\n",
      "epoch: 9 step: 1645, loss is 0.0013180311070755124\n",
      "epoch: 9 step: 1646, loss is 0.00010122093954123557\n",
      "epoch: 9 step: 1647, loss is 0.0036884937435388565\n",
      "epoch: 9 step: 1648, loss is 0.0017473811749368906\n",
      "epoch: 9 step: 1649, loss is 0.00036642025224864483\n",
      "epoch: 9 step: 1650, loss is 0.029834402725100517\n",
      "epoch: 9 step: 1651, loss is 6.444774385272467e-07\n",
      "epoch: 9 step: 1652, loss is 0.001564333913847804\n",
      "epoch: 9 step: 1653, loss is 0.00014247374201659113\n",
      "epoch: 9 step: 1654, loss is 8.030129538383335e-05\n",
      "epoch: 9 step: 1655, loss is 1.2400532796164043e-05\n",
      "epoch: 9 step: 1656, loss is 0.000882965512573719\n",
      "epoch: 9 step: 1657, loss is 0.0014629552606493235\n",
      "epoch: 9 step: 1658, loss is 0.0007584469858556986\n",
      "epoch: 9 step: 1659, loss is 0.015491274185478687\n",
      "epoch: 9 step: 1660, loss is 0.00016888647223822773\n",
      "epoch: 9 step: 1661, loss is 0.019143544137477875\n",
      "epoch: 9 step: 1662, loss is 0.00040929397800937295\n",
      "epoch: 9 step: 1663, loss is 0.0020809071138501167\n",
      "epoch: 9 step: 1664, loss is 0.008050888776779175\n",
      "epoch: 9 step: 1665, loss is 0.0012358243111521006\n",
      "epoch: 9 step: 1666, loss is 0.003379406873136759\n",
      "epoch: 9 step: 1667, loss is 1.537880234536715e-05\n",
      "epoch: 9 step: 1668, loss is 0.0002957014658022672\n",
      "epoch: 9 step: 1669, loss is 0.02601035125553608\n",
      "epoch: 9 step: 1670, loss is 1.3073883565084543e-05\n",
      "epoch: 9 step: 1671, loss is 0.014244992285966873\n",
      "epoch: 9 step: 1672, loss is 0.06283894926309586\n",
      "epoch: 9 step: 1673, loss is 1.06325414890307e-05\n",
      "epoch: 9 step: 1674, loss is 0.00461655855178833\n",
      "epoch: 9 step: 1675, loss is 3.0332335882121697e-05\n",
      "epoch: 9 step: 1676, loss is 0.01909128949046135\n",
      "epoch: 9 step: 1677, loss is 0.0012304030824452639\n",
      "epoch: 9 step: 1678, loss is 0.0006660466897301376\n",
      "epoch: 9 step: 1679, loss is 0.0007938484195619822\n",
      "epoch: 9 step: 1680, loss is 4.024368172395043e-05\n",
      "epoch: 9 step: 1681, loss is 0.0013310760259628296\n",
      "epoch: 9 step: 1682, loss is 0.020507942885160446\n",
      "epoch: 9 step: 1683, loss is 0.03741852194070816\n",
      "epoch: 9 step: 1684, loss is 3.907666905433871e-05\n",
      "epoch: 9 step: 1685, loss is 0.048470187932252884\n",
      "epoch: 9 step: 1686, loss is 0.0018006301252171397\n",
      "epoch: 9 step: 1687, loss is 0.0011281048646196723\n",
      "epoch: 9 step: 1688, loss is 0.009965840727090836\n",
      "epoch: 9 step: 1689, loss is 0.0006516117136925459\n",
      "epoch: 9 step: 1690, loss is 0.004833432380110025\n",
      "epoch: 9 step: 1691, loss is 0.003415194805711508\n",
      "epoch: 9 step: 1692, loss is 0.06879600882530212\n",
      "epoch: 9 step: 1693, loss is 0.0024849316105246544\n",
      "epoch: 9 step: 1694, loss is 5.014162525185384e-05\n",
      "epoch: 9 step: 1695, loss is 0.0006202185759320855\n",
      "epoch: 9 step: 1696, loss is 0.05683029815554619\n",
      "epoch: 9 step: 1697, loss is 0.0001901359937619418\n",
      "epoch: 9 step: 1698, loss is 0.006451609078794718\n",
      "epoch: 9 step: 1699, loss is 3.10696595988702e-05\n",
      "epoch: 9 step: 1700, loss is 0.0017619539285078645\n",
      "epoch: 9 step: 1701, loss is 0.056611452251672745\n",
      "epoch: 9 step: 1702, loss is 0.0028902599588036537\n",
      "epoch: 9 step: 1703, loss is 0.006109932437539101\n",
      "epoch: 9 step: 1704, loss is 0.00290510687045753\n",
      "epoch: 9 step: 1705, loss is 0.0005193788092583418\n",
      "epoch: 9 step: 1706, loss is 0.00025008758530020714\n",
      "epoch: 9 step: 1707, loss is 0.122012659907341\n",
      "epoch: 9 step: 1708, loss is 0.0001021512653096579\n",
      "epoch: 9 step: 1709, loss is 1.3282943655212875e-05\n",
      "epoch: 9 step: 1710, loss is 0.0024392015766352415\n",
      "epoch: 9 step: 1711, loss is 0.0003160964697599411\n",
      "epoch: 9 step: 1712, loss is 7.184439891716465e-05\n",
      "epoch: 9 step: 1713, loss is 8.633504330646247e-05\n",
      "epoch: 9 step: 1714, loss is 0.006217045709490776\n",
      "epoch: 9 step: 1715, loss is 0.17795735597610474\n",
      "epoch: 9 step: 1716, loss is 9.315587521996349e-05\n",
      "epoch: 9 step: 1717, loss is 0.0001405563671141863\n",
      "epoch: 9 step: 1718, loss is 0.018037403002381325\n",
      "epoch: 9 step: 1719, loss is 0.0019112697336822748\n",
      "epoch: 9 step: 1720, loss is 0.07298728823661804\n",
      "epoch: 9 step: 1721, loss is 0.00018929463112726808\n",
      "epoch: 9 step: 1722, loss is 0.015222989022731781\n",
      "epoch: 9 step: 1723, loss is 0.049878496676683426\n",
      "epoch: 9 step: 1724, loss is 0.2165653109550476\n",
      "epoch: 9 step: 1725, loss is 0.0025674335192888975\n",
      "epoch: 9 step: 1726, loss is 0.015198424458503723\n",
      "epoch: 9 step: 1727, loss is 0.0002779884380288422\n",
      "epoch: 9 step: 1728, loss is 5.705167131964117e-05\n",
      "epoch: 9 step: 1729, loss is 6.642833614023402e-05\n",
      "epoch: 9 step: 1730, loss is 0.03419005498290062\n",
      "epoch: 9 step: 1731, loss is 3.848816777463071e-05\n",
      "epoch: 9 step: 1732, loss is 0.00014271578402258456\n",
      "epoch: 9 step: 1733, loss is 0.011668210849165916\n",
      "epoch: 9 step: 1734, loss is 0.0004633219796232879\n",
      "epoch: 9 step: 1735, loss is 0.0021047471091151237\n",
      "epoch: 9 step: 1736, loss is 0.00800943560898304\n",
      "epoch: 9 step: 1737, loss is 0.0036505868192762136\n",
      "epoch: 9 step: 1738, loss is 0.00029845378594473004\n",
      "epoch: 9 step: 1739, loss is 0.05683696269989014\n",
      "epoch: 9 step: 1740, loss is 0.011416970752179623\n",
      "epoch: 9 step: 1741, loss is 0.0004580808454193175\n",
      "epoch: 9 step: 1742, loss is 0.00843129027634859\n",
      "epoch: 9 step: 1743, loss is 2.974146991618909e-05\n",
      "epoch: 9 step: 1744, loss is 0.04054701328277588\n",
      "epoch: 9 step: 1745, loss is 0.0012088492512702942\n",
      "epoch: 9 step: 1746, loss is 0.012889214791357517\n",
      "epoch: 9 step: 1747, loss is 0.0029133602511137724\n",
      "epoch: 9 step: 1748, loss is 0.00011214391997782513\n",
      "epoch: 9 step: 1749, loss is 6.892123928992078e-05\n",
      "epoch: 9 step: 1750, loss is 0.015080214478075504\n",
      "epoch: 9 step: 1751, loss is 0.006502606440335512\n",
      "epoch: 9 step: 1752, loss is 0.0001590187894180417\n",
      "epoch: 9 step: 1753, loss is 8.13341248431243e-05\n",
      "epoch: 9 step: 1754, loss is 9.257238707505167e-05\n",
      "epoch: 9 step: 1755, loss is 0.00036207883385941386\n",
      "epoch: 9 step: 1756, loss is 0.02089434489607811\n",
      "epoch: 9 step: 1757, loss is 0.002994801616296172\n",
      "epoch: 9 step: 1758, loss is 3.952079714508727e-05\n",
      "epoch: 9 step: 1759, loss is 0.0011384825920686126\n",
      "epoch: 9 step: 1760, loss is 0.023464679718017578\n",
      "epoch: 9 step: 1761, loss is 0.00016902991046663374\n",
      "epoch: 9 step: 1762, loss is 9.824294102145359e-05\n",
      "epoch: 9 step: 1763, loss is 0.0015402818098664284\n",
      "epoch: 9 step: 1764, loss is 0.004012818913906813\n",
      "epoch: 9 step: 1765, loss is 0.062040362507104874\n",
      "epoch: 9 step: 1766, loss is 0.037178415805101395\n",
      "epoch: 9 step: 1767, loss is 3.370322156115435e-05\n",
      "epoch: 9 step: 1768, loss is 0.000218328699702397\n",
      "epoch: 9 step: 1769, loss is 0.00040235696360468864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1770, loss is 0.00145138765219599\n",
      "epoch: 9 step: 1771, loss is 0.006941813975572586\n",
      "epoch: 9 step: 1772, loss is 0.0010383209446445107\n",
      "epoch: 9 step: 1773, loss is 0.0005110047641210258\n",
      "epoch: 9 step: 1774, loss is 0.0673428550362587\n",
      "epoch: 9 step: 1775, loss is 0.0027146348729729652\n",
      "epoch: 9 step: 1776, loss is 0.07685501128435135\n",
      "epoch: 9 step: 1777, loss is 0.0003436596889514476\n",
      "epoch: 9 step: 1778, loss is 0.08395267277956009\n",
      "epoch: 9 step: 1779, loss is 6.603258952964097e-05\n",
      "epoch: 9 step: 1780, loss is 0.08863562345504761\n",
      "epoch: 9 step: 1781, loss is 9.877714910544455e-05\n",
      "epoch: 9 step: 1782, loss is 0.10801764577627182\n",
      "epoch: 9 step: 1783, loss is 0.05359506979584694\n",
      "epoch: 9 step: 1784, loss is 0.0004888817202299833\n",
      "epoch: 9 step: 1785, loss is 0.0005726478411816061\n",
      "epoch: 9 step: 1786, loss is 0.020925600081682205\n",
      "epoch: 9 step: 1787, loss is 0.0013203996932134032\n",
      "epoch: 9 step: 1788, loss is 0.14396721124649048\n",
      "epoch: 9 step: 1789, loss is 0.022120276466012\n",
      "epoch: 9 step: 1790, loss is 0.1232432946562767\n",
      "epoch: 9 step: 1791, loss is 0.0018597214948385954\n",
      "epoch: 9 step: 1792, loss is 3.850603025057353e-05\n",
      "epoch: 9 step: 1793, loss is 9.107909863814712e-05\n",
      "epoch: 9 step: 1794, loss is 0.0002482486015651375\n",
      "epoch: 9 step: 1795, loss is 0.0006396335083991289\n",
      "epoch: 9 step: 1796, loss is 0.001428996678441763\n",
      "epoch: 9 step: 1797, loss is 0.00029467520653270185\n",
      "epoch: 9 step: 1798, loss is 0.0014371597208082676\n",
      "epoch: 9 step: 1799, loss is 0.04170162230730057\n",
      "epoch: 9 step: 1800, loss is 0.009615479037165642\n",
      "epoch: 9 step: 1801, loss is 0.005608549807220697\n",
      "epoch: 9 step: 1802, loss is 5.4032683692639694e-05\n",
      "epoch: 9 step: 1803, loss is 0.0023827282711863518\n",
      "epoch: 9 step: 1804, loss is 0.11932169646024704\n",
      "epoch: 9 step: 1805, loss is 6.3780321397644e-06\n",
      "epoch: 9 step: 1806, loss is 0.05445688217878342\n",
      "epoch: 9 step: 1807, loss is 0.014886404387652874\n",
      "epoch: 9 step: 1808, loss is 2.3664477339480072e-05\n",
      "epoch: 9 step: 1809, loss is 0.13334602117538452\n",
      "epoch: 9 step: 1810, loss is 0.002610130701214075\n",
      "epoch: 9 step: 1811, loss is 0.001855836482718587\n",
      "epoch: 9 step: 1812, loss is 0.0030368620064109564\n",
      "epoch: 9 step: 1813, loss is 0.00021107232896611094\n",
      "epoch: 9 step: 1814, loss is 0.0009365155128762126\n",
      "epoch: 9 step: 1815, loss is 0.00039087168988771737\n",
      "epoch: 9 step: 1816, loss is 0.010038799606263638\n",
      "epoch: 9 step: 1817, loss is 0.08039733022451401\n",
      "epoch: 9 step: 1818, loss is 8.737772441236302e-05\n",
      "epoch: 9 step: 1819, loss is 0.09001152217388153\n",
      "epoch: 9 step: 1820, loss is 3.571860725060105e-05\n",
      "epoch: 9 step: 1821, loss is 0.0007411442347802222\n",
      "epoch: 9 step: 1822, loss is 4.902135697193444e-05\n",
      "epoch: 9 step: 1823, loss is 0.15709854662418365\n",
      "epoch: 9 step: 1824, loss is 0.0019805675838142633\n",
      "epoch: 9 step: 1825, loss is 5.358550333767198e-05\n",
      "epoch: 9 step: 1826, loss is 0.0004279082058928907\n",
      "epoch: 9 step: 1827, loss is 4.654306758311577e-05\n",
      "epoch: 9 step: 1828, loss is 0.015586063265800476\n",
      "epoch: 9 step: 1829, loss is 0.00033477379474788904\n",
      "epoch: 9 step: 1830, loss is 1.0483541700523347e-05\n",
      "epoch: 9 step: 1831, loss is 0.0636562928557396\n",
      "epoch: 9 step: 1832, loss is 0.018054740503430367\n",
      "epoch: 9 step: 1833, loss is 0.2527806758880615\n",
      "epoch: 9 step: 1834, loss is 0.03152528777718544\n",
      "epoch: 9 step: 1835, loss is 0.007500304840505123\n",
      "epoch: 9 step: 1836, loss is 0.15923042595386505\n",
      "epoch: 9 step: 1837, loss is 0.02782433107495308\n",
      "epoch: 9 step: 1838, loss is 0.0005324590601958334\n",
      "epoch: 9 step: 1839, loss is 0.002165188081562519\n",
      "epoch: 9 step: 1840, loss is 0.013695234432816505\n",
      "epoch: 9 step: 1841, loss is 0.0013980889925733209\n",
      "epoch: 9 step: 1842, loss is 0.07795067131519318\n",
      "epoch: 9 step: 1843, loss is 0.23498862981796265\n",
      "epoch: 9 step: 1844, loss is 0.41660457849502563\n",
      "epoch: 9 step: 1845, loss is 0.0008379046921618283\n",
      "epoch: 9 step: 1846, loss is 0.0005377703346312046\n",
      "epoch: 9 step: 1847, loss is 0.00020684368791989982\n",
      "epoch: 9 step: 1848, loss is 0.03964966535568237\n",
      "epoch: 9 step: 1849, loss is 0.0005597283598035574\n",
      "epoch: 9 step: 1850, loss is 0.21824860572814941\n",
      "epoch: 9 step: 1851, loss is 0.0004663659492507577\n",
      "epoch: 9 step: 1852, loss is 0.010765680111944675\n",
      "epoch: 9 step: 1853, loss is 0.014638768509030342\n",
      "epoch: 9 step: 1854, loss is 0.0004483716911636293\n",
      "epoch: 9 step: 1855, loss is 0.004631903953850269\n",
      "epoch: 9 step: 1856, loss is 0.0001669062621658668\n",
      "epoch: 9 step: 1857, loss is 0.0027121109887957573\n",
      "epoch: 9 step: 1858, loss is 0.0007824406493455172\n",
      "epoch: 9 step: 1859, loss is 0.01836482062935829\n",
      "epoch: 9 step: 1860, loss is 0.003730406053364277\n",
      "epoch: 9 step: 1861, loss is 0.5079610347747803\n",
      "epoch: 9 step: 1862, loss is 0.008305849507451057\n",
      "epoch: 9 step: 1863, loss is 0.010472356341779232\n",
      "epoch: 9 step: 1864, loss is 0.008288566954433918\n",
      "epoch: 9 step: 1865, loss is 0.02090734988451004\n",
      "epoch: 9 step: 1866, loss is 0.2210143655538559\n",
      "epoch: 9 step: 1867, loss is 0.16482289135456085\n",
      "epoch: 9 step: 1868, loss is 0.001037993817590177\n",
      "epoch: 9 step: 1869, loss is 0.0006305765127763152\n",
      "epoch: 9 step: 1870, loss is 0.0007721345173195004\n",
      "epoch: 9 step: 1871, loss is 0.08401740342378616\n",
      "epoch: 9 step: 1872, loss is 0.08211889863014221\n",
      "epoch: 9 step: 1873, loss is 0.16948240995407104\n",
      "epoch: 9 step: 1874, loss is 0.000421326607465744\n",
      "epoch: 9 step: 1875, loss is 0.002450925298035145\n",
      "epoch: 9 step: 1876, loss is 0.003088951576501131\n",
      "epoch: 9 step: 1877, loss is 0.05025014281272888\n",
      "epoch: 9 step: 1878, loss is 0.031319115310907364\n",
      "epoch: 9 step: 1879, loss is 0.0017330803675577044\n",
      "epoch: 9 step: 1880, loss is 0.0011677806032821536\n",
      "epoch: 9 step: 1881, loss is 0.054475512355566025\n",
      "epoch: 9 step: 1882, loss is 0.14524103701114655\n",
      "epoch: 9 step: 1883, loss is 0.010761543177068233\n",
      "epoch: 9 step: 1884, loss is 0.011501265689730644\n",
      "epoch: 9 step: 1885, loss is 0.09337487071752548\n",
      "epoch: 9 step: 1886, loss is 0.002806191798299551\n",
      "epoch: 9 step: 1887, loss is 0.0023345411755144596\n",
      "epoch: 9 step: 1888, loss is 0.0013535777106881142\n",
      "epoch: 9 step: 1889, loss is 0.006547641009092331\n",
      "epoch: 9 step: 1890, loss is 0.012400091625750065\n",
      "epoch: 9 step: 1891, loss is 0.00876224972307682\n",
      "epoch: 9 step: 1892, loss is 0.01431760098785162\n",
      "epoch: 9 step: 1893, loss is 0.15155307948589325\n",
      "epoch: 9 step: 1894, loss is 0.0016296942485496402\n",
      "epoch: 9 step: 1895, loss is 0.1634994000196457\n",
      "epoch: 9 step: 1896, loss is 0.00213064718991518\n",
      "epoch: 9 step: 1897, loss is 0.013865398243069649\n",
      "epoch: 9 step: 1898, loss is 0.018689831718802452\n",
      "epoch: 9 step: 1899, loss is 0.0029046200215816498\n",
      "epoch: 9 step: 1900, loss is 0.005325159057974815\n",
      "epoch: 9 step: 1901, loss is 0.0016862348420545459\n",
      "epoch: 9 step: 1902, loss is 0.044001612812280655\n",
      "epoch: 9 step: 1903, loss is 0.042099729180336\n",
      "epoch: 9 step: 1904, loss is 0.03306492045521736\n",
      "epoch: 9 step: 1905, loss is 0.028923600912094116\n",
      "epoch: 9 step: 1906, loss is 0.012040095403790474\n",
      "epoch: 9 step: 1907, loss is 0.005768974311649799\n",
      "epoch: 9 step: 1908, loss is 0.0047777737490832806\n",
      "epoch: 9 step: 1909, loss is 0.0002933062787633389\n",
      "epoch: 9 step: 1910, loss is 0.0006852163933217525\n",
      "epoch: 9 step: 1911, loss is 0.006762291770428419\n",
      "epoch: 9 step: 1912, loss is 0.011583076789975166\n",
      "epoch: 9 step: 1913, loss is 0.00011286760855000466\n",
      "epoch: 9 step: 1914, loss is 0.006659046746790409\n",
      "epoch: 9 step: 1915, loss is 0.0015634526498615742\n",
      "epoch: 9 step: 1916, loss is 0.00020058410882484168\n",
      "epoch: 9 step: 1917, loss is 0.06622129678726196\n",
      "epoch: 9 step: 1918, loss is 0.0003868183121085167\n",
      "epoch: 9 step: 1919, loss is 0.000585205212701112\n",
      "epoch: 9 step: 1920, loss is 0.013565367087721825\n",
      "epoch: 9 step: 1921, loss is 0.013912724331021309\n",
      "epoch: 9 step: 1922, loss is 0.0027711153961718082\n",
      "epoch: 9 step: 1923, loss is 0.0019974764436483383\n",
      "epoch: 9 step: 1924, loss is 0.00032907468266785145\n",
      "epoch: 9 step: 1925, loss is 0.013696023263037205\n",
      "epoch: 9 step: 1926, loss is 0.00032977681257762015\n",
      "epoch: 9 step: 1927, loss is 0.000473143212730065\n",
      "epoch: 9 step: 1928, loss is 0.0014157281257212162\n",
      "epoch: 9 step: 1929, loss is 0.02119193971157074\n",
      "epoch: 9 step: 1930, loss is 0.00083490478573367\n",
      "epoch: 9 step: 1931, loss is 0.0020748432725667953\n",
      "epoch: 9 step: 1932, loss is 0.00011249067028984427\n",
      "epoch: 9 step: 1933, loss is 0.001925139338709414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 1934, loss is 0.0025613028556108475\n",
      "epoch: 9 step: 1935, loss is 0.00012132401025155559\n",
      "epoch: 9 step: 1936, loss is 0.0160873681306839\n",
      "epoch: 9 step: 1937, loss is 0.0007064471137709916\n",
      "epoch: 9 step: 1938, loss is 0.00019821224850602448\n",
      "epoch: 9 step: 1939, loss is 0.0031461163889616728\n",
      "epoch: 9 step: 1940, loss is 0.0011153591331094503\n",
      "epoch: 9 step: 1941, loss is 0.0008374491590075195\n",
      "epoch: 9 step: 1942, loss is 0.000875825178809464\n",
      "epoch: 9 step: 1943, loss is 0.035549234598875046\n",
      "epoch: 9 step: 1944, loss is 8.011210593394935e-05\n",
      "epoch: 9 step: 1945, loss is 0.02064254693686962\n",
      "epoch: 9 step: 1946, loss is 0.059938620775938034\n",
      "epoch: 9 step: 1947, loss is 0.0006812359788455069\n",
      "epoch: 9 step: 1948, loss is 0.0037726883310824633\n",
      "epoch: 9 step: 1949, loss is 0.042384788393974304\n",
      "epoch: 9 step: 1950, loss is 0.0008506268495693803\n",
      "epoch: 9 step: 1951, loss is 0.020210377871990204\n",
      "epoch: 9 step: 1952, loss is 0.0008164588361978531\n",
      "epoch: 9 step: 1953, loss is 5.2988943934906274e-05\n",
      "epoch: 9 step: 1954, loss is 0.001301097683608532\n",
      "epoch: 9 step: 1955, loss is 0.001297652954235673\n",
      "epoch: 9 step: 1956, loss is 0.00029269931837916374\n",
      "epoch: 9 step: 1957, loss is 0.02417655661702156\n",
      "epoch: 9 step: 1958, loss is 0.008078636601567268\n",
      "epoch: 9 step: 1959, loss is 0.0011128964833915234\n",
      "epoch: 9 step: 1960, loss is 0.006398992612957954\n",
      "epoch: 9 step: 1961, loss is 0.0007717421976849437\n",
      "epoch: 9 step: 1962, loss is 0.00016144677647389472\n",
      "epoch: 9 step: 1963, loss is 0.0493224672973156\n",
      "epoch: 9 step: 1964, loss is 0.0006923937471583486\n",
      "epoch: 9 step: 1965, loss is 0.003459243569523096\n",
      "epoch: 9 step: 1966, loss is 0.012453185394406319\n",
      "epoch: 9 step: 1967, loss is 0.25963911414146423\n",
      "epoch: 9 step: 1968, loss is 0.0016281341668218374\n",
      "epoch: 9 step: 1969, loss is 0.0004843491187784821\n",
      "epoch: 9 step: 1970, loss is 0.001757526071742177\n",
      "epoch: 9 step: 1971, loss is 0.0001239656121470034\n",
      "epoch: 9 step: 1972, loss is 0.02704392559826374\n",
      "epoch: 9 step: 1973, loss is 0.27381575107574463\n",
      "epoch: 9 step: 1974, loss is 0.04157686233520508\n",
      "epoch: 9 step: 1975, loss is 0.010237467475235462\n",
      "epoch: 9 step: 1976, loss is 0.0009121728362515569\n",
      "epoch: 9 step: 1977, loss is 0.001629097037948668\n",
      "epoch: 9 step: 1978, loss is 0.01753450371325016\n",
      "epoch: 9 step: 1979, loss is 0.033575285226106644\n",
      "epoch: 9 step: 1980, loss is 0.012134670279920101\n",
      "epoch: 9 step: 1981, loss is 0.015622700564563274\n",
      "epoch: 9 step: 1982, loss is 0.0681149810552597\n",
      "epoch: 9 step: 1983, loss is 0.008798320777714252\n",
      "epoch: 9 step: 1984, loss is 0.007838353514671326\n",
      "epoch: 9 step: 1985, loss is 0.0015932574169710279\n",
      "epoch: 9 step: 1986, loss is 0.0007334256079047918\n",
      "epoch: 9 step: 1987, loss is 0.0017727488884702325\n",
      "epoch: 9 step: 1988, loss is 0.003809344954788685\n",
      "epoch: 9 step: 1989, loss is 0.0036963848397135735\n",
      "epoch: 9 step: 1990, loss is 0.01992524228990078\n",
      "epoch: 9 step: 1991, loss is 0.009501762688159943\n",
      "epoch: 9 step: 1992, loss is 0.008707632310688496\n",
      "epoch: 9 step: 1993, loss is 0.025072487071156502\n",
      "epoch: 9 step: 1994, loss is 0.004969258792698383\n",
      "epoch: 9 step: 1995, loss is 0.007348483894020319\n",
      "epoch: 9 step: 1996, loss is 0.002694656141102314\n",
      "epoch: 9 step: 1997, loss is 0.002992655849084258\n",
      "epoch: 9 step: 1998, loss is 0.019916249439120293\n",
      "epoch: 9 step: 1999, loss is 0.009226839989423752\n",
      "epoch: 9 step: 2000, loss is 0.0004613888158928603\n",
      "epoch: 9 step: 2001, loss is 0.0018929988145828247\n",
      "epoch: 9 step: 2002, loss is 0.003439518390223384\n",
      "epoch: 9 step: 2003, loss is 0.000594201497733593\n",
      "epoch: 9 step: 2004, loss is 0.010919958353042603\n",
      "epoch: 9 step: 2005, loss is 0.006126553285866976\n",
      "epoch: 9 step: 2006, loss is 0.001231157686561346\n",
      "epoch: 9 step: 2007, loss is 0.026283076032996178\n",
      "epoch: 9 step: 2008, loss is 0.0011630709050223231\n",
      "epoch: 9 step: 2009, loss is 0.073905810713768\n",
      "epoch: 9 step: 2010, loss is 0.0012666763504967093\n",
      "epoch: 9 step: 2011, loss is 0.00024543257313780487\n",
      "epoch: 9 step: 2012, loss is 5.1558312406996265e-05\n",
      "epoch: 9 step: 2013, loss is 0.001076775137335062\n",
      "epoch: 9 step: 2014, loss is 0.0009540836326777935\n",
      "epoch: 9 step: 2015, loss is 0.00067049142671749\n",
      "epoch: 9 step: 2016, loss is 0.004223837051540613\n",
      "epoch: 9 step: 2017, loss is 0.0063307881355285645\n",
      "epoch: 9 step: 2018, loss is 0.0021173767745494843\n",
      "epoch: 9 step: 2019, loss is 0.011046202853322029\n",
      "epoch: 9 step: 2020, loss is 0.02356814593076706\n",
      "epoch: 9 step: 2021, loss is 0.08337674289941788\n",
      "epoch: 9 step: 2022, loss is 0.008689945563673973\n",
      "epoch: 9 step: 2023, loss is 7.018490578047931e-05\n",
      "epoch: 9 step: 2024, loss is 0.003090818412601948\n",
      "epoch: 9 step: 2025, loss is 0.0026069667655974627\n",
      "epoch: 9 step: 2026, loss is 0.006705440580844879\n",
      "epoch: 9 step: 2027, loss is 0.0005324427038431168\n",
      "epoch: 9 step: 2028, loss is 0.012353711761534214\n",
      "epoch: 9 step: 2029, loss is 0.0011733195278793573\n",
      "epoch: 9 step: 2030, loss is 0.0003653620951808989\n",
      "epoch: 9 step: 2031, loss is 0.0010928374249488115\n",
      "epoch: 9 step: 2032, loss is 0.0002335915924049914\n",
      "epoch: 9 step: 2033, loss is 0.00034952975693158805\n",
      "epoch: 9 step: 2034, loss is 0.04348328709602356\n",
      "epoch: 9 step: 2035, loss is 0.030348394066095352\n",
      "epoch: 9 step: 2036, loss is 0.0018932675011456013\n",
      "epoch: 9 step: 2037, loss is 0.004262314643710852\n",
      "epoch: 9 step: 2038, loss is 0.00013119015784468502\n",
      "epoch: 9 step: 2039, loss is 0.005624024663120508\n",
      "epoch: 9 step: 2040, loss is 0.003548786975443363\n",
      "epoch: 9 step: 2041, loss is 0.0004536775522865355\n",
      "epoch: 9 step: 2042, loss is 0.007353432476520538\n",
      "epoch: 9 step: 2043, loss is 0.02060450240969658\n",
      "epoch: 9 step: 2044, loss is 0.007896785624325275\n",
      "epoch: 9 step: 2045, loss is 0.0008790752617642283\n",
      "epoch: 9 step: 2046, loss is 0.0003017779381480068\n",
      "epoch: 9 step: 2047, loss is 0.014913185499608517\n",
      "epoch: 9 step: 2048, loss is 0.0009315696661360562\n",
      "epoch: 9 step: 2049, loss is 0.011243792250752449\n",
      "epoch: 9 step: 2050, loss is 0.06712737679481506\n",
      "epoch: 9 step: 2051, loss is 0.00021428533364087343\n",
      "epoch: 9 step: 2052, loss is 0.0017716449219733477\n",
      "epoch: 9 step: 2053, loss is 0.00993890967220068\n",
      "epoch: 9 step: 2054, loss is 0.0010776515118777752\n",
      "epoch: 9 step: 2055, loss is 0.1719731241464615\n",
      "epoch: 9 step: 2056, loss is 0.003676619380712509\n",
      "epoch: 9 step: 2057, loss is 0.0002681712503544986\n",
      "epoch: 9 step: 2058, loss is 0.0004834798746742308\n",
      "epoch: 9 step: 2059, loss is 0.0013877522433176637\n",
      "epoch: 9 step: 2060, loss is 0.006970881950110197\n",
      "epoch: 9 step: 2061, loss is 0.10483928769826889\n",
      "epoch: 9 step: 2062, loss is 0.002081496175378561\n",
      "epoch: 9 step: 2063, loss is 0.031384870409965515\n",
      "epoch: 9 step: 2064, loss is 0.005353465210646391\n",
      "epoch: 9 step: 2065, loss is 0.009698604233562946\n",
      "epoch: 9 step: 2066, loss is 0.002989077940583229\n",
      "epoch: 9 step: 2067, loss is 0.0022477474994957447\n",
      "epoch: 9 step: 2068, loss is 0.005680058617144823\n",
      "epoch: 9 step: 2069, loss is 0.02562876045703888\n",
      "epoch: 9 step: 2070, loss is 0.13054047524929047\n",
      "epoch: 9 step: 2071, loss is 0.00023544827126897871\n",
      "epoch: 9 step: 2072, loss is 0.03120408207178116\n",
      "epoch: 9 step: 2073, loss is 0.02830313704907894\n",
      "epoch: 9 step: 2074, loss is 0.00031906896037980914\n",
      "epoch: 9 step: 2075, loss is 0.0038774057757109404\n",
      "epoch: 9 step: 2076, loss is 0.005276456940919161\n",
      "epoch: 9 step: 2077, loss is 0.012080376036465168\n",
      "epoch: 9 step: 2078, loss is 0.02317408286035061\n",
      "epoch: 9 step: 2079, loss is 0.10042096674442291\n",
      "epoch: 9 step: 2080, loss is 0.0339864082634449\n",
      "epoch: 9 step: 2081, loss is 0.00025644004927016795\n",
      "epoch: 9 step: 2082, loss is 0.002780770882964134\n",
      "epoch: 9 step: 2083, loss is 0.0003544851497281343\n",
      "epoch: 9 step: 2084, loss is 0.004304730799049139\n",
      "epoch: 9 step: 2085, loss is 0.002389152767136693\n",
      "epoch: 9 step: 2086, loss is 0.009107500314712524\n",
      "epoch: 9 step: 2087, loss is 0.002312050899490714\n",
      "epoch: 9 step: 2088, loss is 0.06199450045824051\n",
      "epoch: 9 step: 2089, loss is 9.00197119335644e-05\n",
      "epoch: 9 step: 2090, loss is 0.061412129551172256\n",
      "epoch: 9 step: 2091, loss is 0.020900271832942963\n",
      "epoch: 9 step: 2092, loss is 0.0011894464259967208\n",
      "epoch: 9 step: 2093, loss is 0.0020009076688438654\n",
      "epoch: 9 step: 2094, loss is 0.11565469950437546\n",
      "epoch: 9 step: 2095, loss is 0.0006220487412065268\n",
      "epoch: 9 step: 2096, loss is 5.67946772207506e-05\n",
      "epoch: 9 step: 2097, loss is 0.017494192346930504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 2098, loss is 0.0738028883934021\n",
      "epoch: 9 step: 2099, loss is 0.0012404860462993383\n",
      "epoch: 9 step: 2100, loss is 0.0019055299926549196\n",
      "epoch: 9 step: 2101, loss is 0.00010034519073087722\n",
      "epoch: 9 step: 2102, loss is 0.001300634117797017\n",
      "epoch: 9 step: 2103, loss is 0.0410333052277565\n",
      "epoch: 9 step: 2104, loss is 0.0013276825193315744\n",
      "epoch: 9 step: 2105, loss is 0.007396540604531765\n",
      "epoch: 9 step: 2106, loss is 0.0006021861918270588\n",
      "epoch: 9 step: 2107, loss is 0.0048584905453026295\n",
      "epoch: 9 step: 2108, loss is 0.006151460576802492\n",
      "epoch: 9 step: 2109, loss is 5.567109110415913e-05\n",
      "epoch: 9 step: 2110, loss is 0.005186447873711586\n",
      "epoch: 9 step: 2111, loss is 0.0004735433903988451\n",
      "epoch: 9 step: 2112, loss is 0.001472820877097547\n",
      "epoch: 9 step: 2113, loss is 0.0004974660114385188\n",
      "epoch: 9 step: 2114, loss is 0.00924626737833023\n",
      "epoch: 9 step: 2115, loss is 0.05666538327932358\n",
      "epoch: 9 step: 2116, loss is 0.003298156661912799\n",
      "epoch: 9 step: 2117, loss is 6.497017693618545e-06\n",
      "epoch: 9 step: 2118, loss is 0.006734767928719521\n",
      "epoch: 9 step: 2119, loss is 8.490254913340323e-06\n",
      "epoch: 9 step: 2120, loss is 4.154041744186543e-05\n",
      "epoch: 9 step: 2121, loss is 0.00010455034498590976\n",
      "epoch: 9 step: 2122, loss is 0.010970458388328552\n",
      "epoch: 9 step: 2123, loss is 0.09040194004774094\n",
      "epoch: 9 step: 2124, loss is 0.00014241848839446902\n",
      "epoch: 9 step: 2125, loss is 0.003083061194047332\n",
      "epoch: 9 step: 2126, loss is 0.006228265352547169\n",
      "epoch: 9 step: 2127, loss is 0.0013998830690979958\n",
      "epoch: 9 step: 2128, loss is 0.0007312948582693934\n",
      "epoch: 9 step: 2129, loss is 0.0072647216729819775\n",
      "epoch: 9 step: 2130, loss is 0.00043909624218940735\n",
      "epoch: 9 step: 2131, loss is 0.04921497777104378\n",
      "epoch: 9 step: 2132, loss is 0.0017434889450669289\n",
      "epoch: 9 step: 2133, loss is 0.00023993921058718115\n",
      "epoch: 9 step: 2134, loss is 0.004565844312310219\n",
      "epoch: 9 step: 2135, loss is 0.0031702108681201935\n",
      "epoch: 9 step: 2136, loss is 0.0008483836427330971\n",
      "epoch: 9 step: 2137, loss is 0.0028840885497629642\n",
      "epoch: 9 step: 2138, loss is 0.004122435115277767\n",
      "epoch: 9 step: 2139, loss is 0.0003353964420966804\n",
      "epoch: 9 step: 2140, loss is 8.670112583786249e-05\n",
      "epoch: 9 step: 2141, loss is 0.004226703196763992\n",
      "epoch: 9 step: 2142, loss is 0.00015020088176243007\n",
      "epoch: 9 step: 2143, loss is 0.0003640678769443184\n",
      "epoch: 9 step: 2144, loss is 0.0004979053628630936\n",
      "epoch: 9 step: 2145, loss is 8.880316454451531e-05\n",
      "epoch: 9 step: 2146, loss is 0.0019225127762183547\n",
      "epoch: 9 step: 2147, loss is 0.00021873170044273138\n",
      "epoch: 9 step: 2148, loss is 0.00028843909967690706\n",
      "epoch: 9 step: 2149, loss is 0.0019029396353289485\n",
      "epoch: 9 step: 2150, loss is 3.246558117098175e-05\n",
      "epoch: 9 step: 2151, loss is 5.2442275773501024e-05\n",
      "epoch: 9 step: 2152, loss is 0.00010327572817914188\n",
      "epoch: 9 step: 2153, loss is 0.0013110493309795856\n",
      "epoch: 9 step: 2154, loss is 0.0003983249480370432\n",
      "epoch: 9 step: 2155, loss is 0.0016143277753144503\n",
      "epoch: 9 step: 2156, loss is 0.0012748525477945805\n",
      "epoch: 9 step: 2157, loss is 3.6032182833878323e-05\n",
      "epoch: 9 step: 2158, loss is 0.0001672083599260077\n",
      "epoch: 9 step: 2159, loss is 0.022254565730690956\n",
      "epoch: 9 step: 2160, loss is 1.4008310245117173e-05\n",
      "epoch: 9 step: 2161, loss is 0.02931635081768036\n",
      "epoch: 9 step: 2162, loss is 0.001560557633638382\n",
      "epoch: 9 step: 2163, loss is 0.011820496059954166\n",
      "epoch: 9 step: 2164, loss is 3.715009370353073e-05\n",
      "epoch: 9 step: 2165, loss is 0.0012499084696173668\n",
      "epoch: 9 step: 2166, loss is 0.00012796830560546368\n",
      "epoch: 9 step: 2167, loss is 0.00024172532721422613\n",
      "epoch: 9 step: 2168, loss is 0.018586402758955956\n",
      "epoch: 9 step: 2169, loss is 0.000597801641561091\n",
      "epoch: 9 step: 2170, loss is 0.022396652027964592\n",
      "epoch: 9 step: 2171, loss is 0.0007319833966903389\n",
      "epoch: 9 step: 2172, loss is 0.031042419373989105\n",
      "epoch: 9 step: 2173, loss is 0.0015823463909327984\n",
      "epoch: 9 step: 2174, loss is 0.0030306156259030104\n",
      "epoch: 9 step: 2175, loss is 0.002880053361877799\n",
      "epoch: 9 step: 2176, loss is 4.377729055704549e-05\n",
      "epoch: 9 step: 2177, loss is 0.006042162422090769\n",
      "epoch: 9 step: 2178, loss is 0.0005190735100768507\n",
      "epoch: 9 step: 2179, loss is 0.11443661898374557\n",
      "epoch: 9 step: 2180, loss is 4.731952503789216e-05\n",
      "epoch: 9 step: 2181, loss is 0.0005430568708106875\n",
      "epoch: 9 step: 2182, loss is 4.9870261136675254e-05\n",
      "epoch: 9 step: 2183, loss is 0.0006656628102064133\n",
      "epoch: 9 step: 2184, loss is 0.006609177682548761\n",
      "epoch: 9 step: 2185, loss is 5.2257979405112565e-05\n",
      "epoch: 9 step: 2186, loss is 0.040036238729953766\n",
      "epoch: 9 step: 2187, loss is 0.002330108778551221\n",
      "epoch: 10 step: 1, loss is 1.9233444618294016e-05\n",
      "epoch: 10 step: 2, loss is 0.01247316412627697\n",
      "epoch: 10 step: 3, loss is 0.014399639330804348\n",
      "epoch: 10 step: 4, loss is 0.001805400475859642\n",
      "epoch: 10 step: 5, loss is 0.0014864453114569187\n",
      "epoch: 10 step: 6, loss is 0.01190098188817501\n",
      "epoch: 10 step: 7, loss is 0.04619130492210388\n",
      "epoch: 10 step: 8, loss is 0.00027749905711971223\n",
      "epoch: 10 step: 9, loss is 0.011887275613844395\n",
      "epoch: 10 step: 10, loss is 0.0018560020253062248\n",
      "epoch: 10 step: 11, loss is 0.006332815159112215\n",
      "epoch: 10 step: 12, loss is 0.002418830757960677\n",
      "epoch: 10 step: 13, loss is 2.8535914680105634e-06\n",
      "epoch: 10 step: 14, loss is 0.1294621378183365\n",
      "epoch: 10 step: 15, loss is 0.022281911224126816\n",
      "epoch: 10 step: 16, loss is 0.0021942518651485443\n",
      "epoch: 10 step: 17, loss is 0.10081038624048233\n",
      "epoch: 10 step: 18, loss is 6.209983257576823e-05\n",
      "epoch: 10 step: 19, loss is 0.0018124178750440478\n",
      "epoch: 10 step: 20, loss is 8.300407898786943e-06\n",
      "epoch: 10 step: 21, loss is 0.0006006130133755505\n",
      "epoch: 10 step: 22, loss is 0.05787253379821777\n",
      "epoch: 10 step: 23, loss is 5.792403680970892e-05\n",
      "epoch: 10 step: 24, loss is 0.00019749820057768375\n",
      "epoch: 10 step: 25, loss is 0.08070945739746094\n",
      "epoch: 10 step: 26, loss is 0.0010427040979266167\n",
      "epoch: 10 step: 27, loss is 0.004894530400633812\n",
      "epoch: 10 step: 28, loss is 0.07325312495231628\n",
      "epoch: 10 step: 29, loss is 0.022306956350803375\n",
      "epoch: 10 step: 30, loss is 0.1679335981607437\n",
      "epoch: 10 step: 31, loss is 0.013690715655684471\n",
      "epoch: 10 step: 32, loss is 0.0016324195312336087\n",
      "epoch: 10 step: 33, loss is 0.00017119289259426296\n",
      "epoch: 10 step: 34, loss is 7.532806193921715e-05\n",
      "epoch: 10 step: 35, loss is 0.036003515124320984\n",
      "epoch: 10 step: 36, loss is 0.00042813882464542985\n",
      "epoch: 10 step: 37, loss is 0.0030627723317593336\n",
      "epoch: 10 step: 38, loss is 0.0004885904490947723\n",
      "epoch: 10 step: 39, loss is 0.08387661725282669\n",
      "epoch: 10 step: 40, loss is 0.029601097106933594\n",
      "epoch: 10 step: 41, loss is 0.0027472253423184156\n",
      "epoch: 10 step: 42, loss is 0.005052690394222736\n",
      "epoch: 10 step: 43, loss is 0.03374505415558815\n",
      "epoch: 10 step: 44, loss is 0.0009881951846182346\n",
      "epoch: 10 step: 45, loss is 0.009648358449339867\n",
      "epoch: 10 step: 46, loss is 0.00020800669153686613\n",
      "epoch: 10 step: 47, loss is 0.00135326967574656\n",
      "epoch: 10 step: 48, loss is 0.003146408125758171\n",
      "epoch: 10 step: 49, loss is 0.0027528603095561266\n",
      "epoch: 10 step: 50, loss is 0.0006572178099304438\n",
      "epoch: 10 step: 51, loss is 0.07498529553413391\n",
      "epoch: 10 step: 52, loss is 0.00579591142013669\n",
      "epoch: 10 step: 53, loss is 0.006729867309331894\n",
      "epoch: 10 step: 54, loss is 0.004544781055301428\n",
      "epoch: 10 step: 55, loss is 0.0002572295197751373\n",
      "epoch: 10 step: 56, loss is 0.10546544939279556\n",
      "epoch: 10 step: 57, loss is 0.00035048421705141664\n",
      "epoch: 10 step: 58, loss is 0.010261891409754753\n",
      "epoch: 10 step: 59, loss is 0.02749478630721569\n",
      "epoch: 10 step: 60, loss is 0.0008201951859518886\n",
      "epoch: 10 step: 61, loss is 0.00013918762851972133\n",
      "epoch: 10 step: 62, loss is 0.003228378714993596\n",
      "epoch: 10 step: 63, loss is 5.734440128435381e-05\n",
      "epoch: 10 step: 64, loss is 0.0004172584740445018\n",
      "epoch: 10 step: 65, loss is 0.029265422374010086\n",
      "epoch: 10 step: 66, loss is 0.0002780153008643538\n",
      "epoch: 10 step: 67, loss is 0.01466187834739685\n",
      "epoch: 10 step: 68, loss is 0.0017003393732011318\n",
      "epoch: 10 step: 69, loss is 0.00014986249152570963\n",
      "epoch: 10 step: 70, loss is 0.001521209953352809\n",
      "epoch: 10 step: 71, loss is 0.031034674495458603\n",
      "epoch: 10 step: 72, loss is 0.00013221011613495648\n",
      "epoch: 10 step: 73, loss is 7.146417920012027e-05\n",
      "epoch: 10 step: 74, loss is 0.0002701743214856833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 75, loss is 0.0006128660752438009\n",
      "epoch: 10 step: 76, loss is 0.07072819024324417\n",
      "epoch: 10 step: 77, loss is 0.0013761825393885374\n",
      "epoch: 10 step: 78, loss is 0.003130721626803279\n",
      "epoch: 10 step: 79, loss is 0.018802275881171227\n",
      "epoch: 10 step: 80, loss is 0.0027623253408819437\n",
      "epoch: 10 step: 81, loss is 0.0017190567450597882\n",
      "epoch: 10 step: 82, loss is 0.003958104643970728\n",
      "epoch: 10 step: 83, loss is 0.04525960236787796\n",
      "epoch: 10 step: 84, loss is 0.09473162144422531\n",
      "epoch: 10 step: 85, loss is 5.123410664964467e-05\n",
      "epoch: 10 step: 86, loss is 3.377264874870889e-05\n",
      "epoch: 10 step: 87, loss is 0.0005737175815738738\n",
      "epoch: 10 step: 88, loss is 0.011161654256284237\n",
      "epoch: 10 step: 89, loss is 0.0031942487694323063\n",
      "epoch: 10 step: 90, loss is 0.009540051221847534\n",
      "epoch: 10 step: 91, loss is 0.00016943090304266661\n",
      "epoch: 10 step: 92, loss is 0.000300336949294433\n",
      "epoch: 10 step: 93, loss is 6.897888852108736e-06\n",
      "epoch: 10 step: 94, loss is 0.000373104092432186\n",
      "epoch: 10 step: 95, loss is 0.0007813159027136862\n",
      "epoch: 10 step: 96, loss is 0.04981331527233124\n",
      "epoch: 10 step: 97, loss is 0.002321729902178049\n",
      "epoch: 10 step: 98, loss is 0.00021718132484238595\n",
      "epoch: 10 step: 99, loss is 0.0021095643751323223\n",
      "epoch: 10 step: 100, loss is 0.0001966735435416922\n",
      "epoch: 10 step: 101, loss is 0.18728508055210114\n",
      "epoch: 10 step: 102, loss is 0.00012298100045882165\n",
      "epoch: 10 step: 103, loss is 9.28196677705273e-05\n",
      "epoch: 10 step: 104, loss is 0.0004964554682374001\n",
      "epoch: 10 step: 105, loss is 0.002926245331764221\n",
      "epoch: 10 step: 106, loss is 0.00013212484191171825\n",
      "epoch: 10 step: 107, loss is 5.618756767944433e-05\n",
      "epoch: 10 step: 108, loss is 0.0005431830650195479\n",
      "epoch: 10 step: 109, loss is 0.0015999539755284786\n",
      "epoch: 10 step: 110, loss is 0.001864016056060791\n",
      "epoch: 10 step: 111, loss is 0.000290682160994038\n",
      "epoch: 10 step: 112, loss is 0.005600903648883104\n",
      "epoch: 10 step: 113, loss is 0.09866217523813248\n",
      "epoch: 10 step: 114, loss is 0.020949751138687134\n",
      "epoch: 10 step: 115, loss is 0.0002302031934959814\n",
      "epoch: 10 step: 116, loss is 0.35386210680007935\n",
      "epoch: 10 step: 117, loss is 0.00043271557660773396\n",
      "epoch: 10 step: 118, loss is 0.00032994296634569764\n",
      "epoch: 10 step: 119, loss is 0.10599520802497864\n",
      "epoch: 10 step: 120, loss is 0.00012875876564066857\n",
      "epoch: 10 step: 121, loss is 9.004426101455465e-05\n",
      "epoch: 10 step: 122, loss is 0.0004451801651157439\n",
      "epoch: 10 step: 123, loss is 0.0009918103460222483\n",
      "epoch: 10 step: 124, loss is 3.2296502467943355e-05\n",
      "epoch: 10 step: 125, loss is 0.04973660781979561\n",
      "epoch: 10 step: 126, loss is 0.15103141963481903\n",
      "epoch: 10 step: 127, loss is 0.0004934378666803241\n",
      "epoch: 10 step: 128, loss is 0.0041062356904149055\n",
      "epoch: 10 step: 129, loss is 4.637184611056e-05\n",
      "epoch: 10 step: 130, loss is 0.07655426114797592\n",
      "epoch: 10 step: 131, loss is 4.722066660178825e-05\n",
      "epoch: 10 step: 132, loss is 0.002082998864352703\n",
      "epoch: 10 step: 133, loss is 0.07587699592113495\n",
      "epoch: 10 step: 134, loss is 0.00043519583414308727\n",
      "epoch: 10 step: 135, loss is 0.0001599010720383376\n",
      "epoch: 10 step: 136, loss is 3.9966740587260574e-05\n",
      "epoch: 10 step: 137, loss is 0.00022037242888472974\n",
      "epoch: 10 step: 138, loss is 0.06896626949310303\n",
      "epoch: 10 step: 139, loss is 0.008271745406091213\n",
      "epoch: 10 step: 140, loss is 0.01077481172978878\n",
      "epoch: 10 step: 141, loss is 0.008650136180222034\n",
      "epoch: 10 step: 142, loss is 0.0016681383131071925\n",
      "epoch: 10 step: 143, loss is 0.00019871113181579858\n",
      "epoch: 10 step: 144, loss is 0.017562735825777054\n",
      "epoch: 10 step: 145, loss is 0.0003020988078787923\n",
      "epoch: 10 step: 146, loss is 0.006983380299061537\n",
      "epoch: 10 step: 147, loss is 0.005014505703002214\n",
      "epoch: 10 step: 148, loss is 0.004797846544533968\n",
      "epoch: 10 step: 149, loss is 0.04157771170139313\n",
      "epoch: 10 step: 150, loss is 0.37574559450149536\n",
      "epoch: 10 step: 151, loss is 0.00457048648968339\n",
      "epoch: 10 step: 152, loss is 0.01728092133998871\n",
      "epoch: 10 step: 153, loss is 0.010936995968222618\n",
      "epoch: 10 step: 154, loss is 0.013097568415105343\n",
      "epoch: 10 step: 155, loss is 1.2475272342271637e-05\n",
      "epoch: 10 step: 156, loss is 0.037679582834243774\n",
      "epoch: 10 step: 157, loss is 0.004158002324402332\n",
      "epoch: 10 step: 158, loss is 0.0028893828857690096\n",
      "epoch: 10 step: 159, loss is 0.04103468731045723\n",
      "epoch: 10 step: 160, loss is 0.07382247596979141\n",
      "epoch: 10 step: 161, loss is 0.0029848141130059958\n",
      "epoch: 10 step: 162, loss is 0.0001320544834015891\n",
      "epoch: 10 step: 163, loss is 0.004736986942589283\n",
      "epoch: 10 step: 164, loss is 0.0708899274468422\n",
      "epoch: 10 step: 165, loss is 0.019467081874608994\n",
      "epoch: 10 step: 166, loss is 0.012853113934397697\n",
      "epoch: 10 step: 167, loss is 0.0026807747781276703\n",
      "epoch: 10 step: 168, loss is 3.030597508768551e-05\n",
      "epoch: 10 step: 169, loss is 0.0010361757595092058\n",
      "epoch: 10 step: 170, loss is 0.0008089362527243793\n",
      "epoch: 10 step: 171, loss is 0.038441430777311325\n",
      "epoch: 10 step: 172, loss is 5.8335768699180335e-05\n",
      "epoch: 10 step: 173, loss is 0.08777080476284027\n",
      "epoch: 10 step: 174, loss is 0.07430671155452728\n",
      "epoch: 10 step: 175, loss is 0.014947185292840004\n",
      "epoch: 10 step: 176, loss is 7.185474532889202e-05\n",
      "epoch: 10 step: 177, loss is 0.0049568586982786655\n",
      "epoch: 10 step: 178, loss is 0.0005412951577454805\n",
      "epoch: 10 step: 179, loss is 8.001794049050659e-05\n",
      "epoch: 10 step: 180, loss is 0.005390019156038761\n",
      "epoch: 10 step: 181, loss is 0.017888832837343216\n",
      "epoch: 10 step: 182, loss is 0.0005437908694148064\n",
      "epoch: 10 step: 183, loss is 0.002538246102631092\n",
      "epoch: 10 step: 184, loss is 0.0008283008937723935\n",
      "epoch: 10 step: 185, loss is 0.2015426903963089\n",
      "epoch: 10 step: 186, loss is 3.7972164136590436e-05\n",
      "epoch: 10 step: 187, loss is 0.003789584618061781\n",
      "epoch: 10 step: 188, loss is 0.011260157451033592\n",
      "epoch: 10 step: 189, loss is 2.031292751780711e-05\n",
      "epoch: 10 step: 190, loss is 0.0005011780303902924\n",
      "epoch: 10 step: 191, loss is 0.00015188691031653434\n",
      "epoch: 10 step: 192, loss is 0.0013080101925879717\n",
      "epoch: 10 step: 193, loss is 0.007479671388864517\n",
      "epoch: 10 step: 194, loss is 0.0011309162946417928\n",
      "epoch: 10 step: 195, loss is 0.0006100457394495606\n",
      "epoch: 10 step: 196, loss is 0.02079576998949051\n",
      "epoch: 10 step: 197, loss is 0.05148858577013016\n",
      "epoch: 10 step: 198, loss is 0.04253040999174118\n",
      "epoch: 10 step: 199, loss is 0.0016885170480236411\n",
      "epoch: 10 step: 200, loss is 0.0004246333264745772\n",
      "epoch: 10 step: 201, loss is 0.06347393989562988\n",
      "epoch: 10 step: 202, loss is 0.001028700266033411\n",
      "epoch: 10 step: 203, loss is 0.0005806609988212585\n",
      "epoch: 10 step: 204, loss is 0.012918050400912762\n",
      "epoch: 10 step: 205, loss is 5.245803913567215e-05\n",
      "epoch: 10 step: 206, loss is 0.1626976877450943\n",
      "epoch: 10 step: 207, loss is 0.00030357876676134765\n",
      "epoch: 10 step: 208, loss is 0.0020069628953933716\n",
      "epoch: 10 step: 209, loss is 0.013183314353227615\n",
      "epoch: 10 step: 210, loss is 0.0012783266138285398\n",
      "epoch: 10 step: 211, loss is 0.0001383354829158634\n",
      "epoch: 10 step: 212, loss is 0.006046186666935682\n",
      "epoch: 10 step: 213, loss is 0.0015772696351632476\n",
      "epoch: 10 step: 214, loss is 0.0006185724050737917\n",
      "epoch: 10 step: 215, loss is 0.0032501607201993465\n",
      "epoch: 10 step: 216, loss is 0.0047964490950107574\n",
      "epoch: 10 step: 217, loss is 0.0027410355396568775\n",
      "epoch: 10 step: 218, loss is 0.0028699589893221855\n",
      "epoch: 10 step: 219, loss is 8.542247815057635e-05\n",
      "epoch: 10 step: 220, loss is 0.0202336385846138\n",
      "epoch: 10 step: 221, loss is 2.1265137547743507e-05\n",
      "epoch: 10 step: 222, loss is 0.006876269355416298\n",
      "epoch: 10 step: 223, loss is 0.0015295209595933557\n",
      "epoch: 10 step: 224, loss is 0.06595037877559662\n",
      "epoch: 10 step: 225, loss is 0.0005864984705112875\n",
      "epoch: 10 step: 226, loss is 0.0002511622151359916\n",
      "epoch: 10 step: 227, loss is 0.0024867907632142305\n",
      "epoch: 10 step: 228, loss is 0.007783101871609688\n",
      "epoch: 10 step: 229, loss is 0.0004642627027351409\n",
      "epoch: 10 step: 230, loss is 0.0013896788004785776\n",
      "epoch: 10 step: 231, loss is 1.778910700522829e-05\n",
      "epoch: 10 step: 232, loss is 0.015488702803850174\n",
      "epoch: 10 step: 233, loss is 0.00019422097830101848\n",
      "epoch: 10 step: 234, loss is 0.00023002586385700852\n",
      "epoch: 10 step: 235, loss is 0.0010219793766736984\n",
      "epoch: 10 step: 236, loss is 0.00010296191612724215\n",
      "epoch: 10 step: 237, loss is 0.009289651177823544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 238, loss is 0.004392295144498348\n",
      "epoch: 10 step: 239, loss is 0.00012224225793033838\n",
      "epoch: 10 step: 240, loss is 0.0002977510157506913\n",
      "epoch: 10 step: 241, loss is 0.000184536402230151\n",
      "epoch: 10 step: 242, loss is 0.01646602153778076\n",
      "epoch: 10 step: 243, loss is 0.022398922592401505\n",
      "epoch: 10 step: 244, loss is 0.11623622477054596\n",
      "epoch: 10 step: 245, loss is 0.0018962920876219869\n",
      "epoch: 10 step: 246, loss is 0.0004590881580952555\n",
      "epoch: 10 step: 247, loss is 0.005733794532716274\n",
      "epoch: 10 step: 248, loss is 0.012492830865085125\n",
      "epoch: 10 step: 249, loss is 0.00030306639382615685\n",
      "epoch: 10 step: 250, loss is 0.0004263872397132218\n",
      "epoch: 10 step: 251, loss is 0.0012856507673859596\n",
      "epoch: 10 step: 252, loss is 0.002632188145071268\n",
      "epoch: 10 step: 253, loss is 0.00034654425689950585\n",
      "epoch: 10 step: 254, loss is 0.001838818658143282\n",
      "epoch: 10 step: 255, loss is 0.03471582010388374\n",
      "epoch: 10 step: 256, loss is 0.0013375793350860476\n",
      "epoch: 10 step: 257, loss is 0.0033904092852026224\n",
      "epoch: 10 step: 258, loss is 0.0032394665759056807\n",
      "epoch: 10 step: 259, loss is 0.020529285073280334\n",
      "epoch: 10 step: 260, loss is 0.20854514837265015\n",
      "epoch: 10 step: 261, loss is 0.008641366846859455\n",
      "epoch: 10 step: 262, loss is 0.002242610789835453\n",
      "epoch: 10 step: 263, loss is 0.016162164509296417\n",
      "epoch: 10 step: 264, loss is 0.0030718916095793247\n",
      "epoch: 10 step: 265, loss is 0.0007318176212720573\n",
      "epoch: 10 step: 266, loss is 0.0010777032002806664\n",
      "epoch: 10 step: 267, loss is 0.0014482138212770224\n",
      "epoch: 10 step: 268, loss is 0.0005207462818361819\n",
      "epoch: 10 step: 269, loss is 0.0014325607335194945\n",
      "epoch: 10 step: 270, loss is 0.00017383633530698717\n",
      "epoch: 10 step: 271, loss is 0.0005263688508421183\n",
      "epoch: 10 step: 272, loss is 0.01630786433815956\n",
      "epoch: 10 step: 273, loss is 0.03050639107823372\n",
      "epoch: 10 step: 274, loss is 5.279454489937052e-05\n",
      "epoch: 10 step: 275, loss is 0.00035092252073809505\n",
      "epoch: 10 step: 276, loss is 7.570491288788617e-05\n",
      "epoch: 10 step: 277, loss is 0.04449714347720146\n",
      "epoch: 10 step: 278, loss is 0.0007955708424560726\n",
      "epoch: 10 step: 279, loss is 0.004081985913217068\n",
      "epoch: 10 step: 280, loss is 0.0006285978015512228\n",
      "epoch: 10 step: 281, loss is 0.004441004246473312\n",
      "epoch: 10 step: 282, loss is 2.369681533309631e-05\n",
      "epoch: 10 step: 283, loss is 0.000734139874111861\n",
      "epoch: 10 step: 284, loss is 0.011641065590083599\n",
      "epoch: 10 step: 285, loss is 0.000912714225705713\n",
      "epoch: 10 step: 286, loss is 5.762282307841815e-05\n",
      "epoch: 10 step: 287, loss is 0.004219286609441042\n",
      "epoch: 10 step: 288, loss is 0.057758629322052\n",
      "epoch: 10 step: 289, loss is 0.006881938315927982\n",
      "epoch: 10 step: 290, loss is 0.003290388500317931\n",
      "epoch: 10 step: 291, loss is 0.0007920858333818614\n",
      "epoch: 10 step: 292, loss is 4.398621604195796e-05\n",
      "epoch: 10 step: 293, loss is 0.001223336555995047\n",
      "epoch: 10 step: 294, loss is 0.0012388612376525998\n",
      "epoch: 10 step: 295, loss is 0.047000378370285034\n",
      "epoch: 10 step: 296, loss is 0.0005677810404449701\n",
      "epoch: 10 step: 297, loss is 0.004945661872625351\n",
      "epoch: 10 step: 298, loss is 0.00013706466415897012\n",
      "epoch: 10 step: 299, loss is 0.0002855575585272163\n",
      "epoch: 10 step: 300, loss is 2.988623054989148e-05\n",
      "epoch: 10 step: 301, loss is 2.8665024728979915e-05\n",
      "epoch: 10 step: 302, loss is 0.0015381058910861611\n",
      "epoch: 10 step: 303, loss is 0.011207245290279388\n",
      "epoch: 10 step: 304, loss is 0.0002001406392082572\n",
      "epoch: 10 step: 305, loss is 0.0006116966833360493\n",
      "epoch: 10 step: 306, loss is 0.0008486479637213051\n",
      "epoch: 10 step: 307, loss is 0.0010757328709587455\n",
      "epoch: 10 step: 308, loss is 0.00022286150488071144\n",
      "epoch: 10 step: 309, loss is 7.966847624629736e-05\n",
      "epoch: 10 step: 310, loss is 0.00019187951693311334\n",
      "epoch: 10 step: 311, loss is 1.351040100416867e-05\n",
      "epoch: 10 step: 312, loss is 5.389546640799381e-05\n",
      "epoch: 10 step: 313, loss is 0.0002920772531069815\n",
      "epoch: 10 step: 314, loss is 0.0009105867939069867\n",
      "epoch: 10 step: 315, loss is 0.00029014761094003916\n",
      "epoch: 10 step: 316, loss is 0.003435458056628704\n",
      "epoch: 10 step: 317, loss is 1.4156158840705757e-06\n",
      "epoch: 10 step: 318, loss is 0.09552372992038727\n",
      "epoch: 10 step: 319, loss is 0.0010955114848911762\n",
      "epoch: 10 step: 320, loss is 0.0027457333635538816\n",
      "epoch: 10 step: 321, loss is 0.0027493315283209085\n",
      "epoch: 10 step: 322, loss is 0.0055123078636825085\n",
      "epoch: 10 step: 323, loss is 0.0012098097940906882\n",
      "epoch: 10 step: 324, loss is 0.025086713954806328\n",
      "epoch: 10 step: 325, loss is 0.0007457358296960592\n",
      "epoch: 10 step: 326, loss is 0.0076060909777879715\n",
      "epoch: 10 step: 327, loss is 0.00010089735587825999\n",
      "epoch: 10 step: 328, loss is 0.0019470714032649994\n",
      "epoch: 10 step: 329, loss is 0.0013255957746878266\n",
      "epoch: 10 step: 330, loss is 0.0007353401160798967\n",
      "epoch: 10 step: 331, loss is 3.362058487255126e-05\n",
      "epoch: 10 step: 332, loss is 0.14282870292663574\n",
      "epoch: 10 step: 333, loss is 0.003921113442629576\n",
      "epoch: 10 step: 334, loss is 2.485139157215599e-05\n",
      "epoch: 10 step: 335, loss is 0.0002704155049286783\n",
      "epoch: 10 step: 336, loss is 0.0008292899001389742\n",
      "epoch: 10 step: 337, loss is 0.12489087134599686\n",
      "epoch: 10 step: 338, loss is 0.0030749966390430927\n",
      "epoch: 10 step: 339, loss is 0.0038507007993757725\n",
      "epoch: 10 step: 340, loss is 0.00015968744992278516\n",
      "epoch: 10 step: 341, loss is 0.049017660319805145\n",
      "epoch: 10 step: 342, loss is 1.5203620023385156e-05\n",
      "epoch: 10 step: 343, loss is 0.0006193867884576321\n",
      "epoch: 10 step: 344, loss is 0.0003073413099627942\n",
      "epoch: 10 step: 345, loss is 0.0004145948914811015\n",
      "epoch: 10 step: 346, loss is 0.00024179345928132534\n",
      "epoch: 10 step: 347, loss is 8.44211972435005e-05\n",
      "epoch: 10 step: 348, loss is 0.0025379578582942486\n",
      "epoch: 10 step: 349, loss is 0.0010489390697330236\n",
      "epoch: 10 step: 350, loss is 0.11049020290374756\n",
      "epoch: 10 step: 351, loss is 0.0016724775778129697\n",
      "epoch: 10 step: 352, loss is 0.01259161438792944\n",
      "epoch: 10 step: 353, loss is 0.026508614420890808\n",
      "epoch: 10 step: 354, loss is 0.002550323260948062\n",
      "epoch: 10 step: 355, loss is 0.004728465806692839\n",
      "epoch: 10 step: 356, loss is 0.000448799371952191\n",
      "epoch: 10 step: 357, loss is 0.017789987847208977\n",
      "epoch: 10 step: 358, loss is 0.00013727591431234032\n",
      "epoch: 10 step: 359, loss is 0.00016870175022631884\n",
      "epoch: 10 step: 360, loss is 5.86039423069451e-05\n",
      "epoch: 10 step: 361, loss is 0.00017523273709230125\n",
      "epoch: 10 step: 362, loss is 0.0005047487211413682\n",
      "epoch: 10 step: 363, loss is 0.0006065757479518652\n",
      "epoch: 10 step: 364, loss is 0.008699881844222546\n",
      "epoch: 10 step: 365, loss is 0.0011636540293693542\n",
      "epoch: 10 step: 366, loss is 0.0007716813124716282\n",
      "epoch: 10 step: 367, loss is 0.008027895353734493\n",
      "epoch: 10 step: 368, loss is 0.003964822739362717\n",
      "epoch: 10 step: 369, loss is 0.000546519469935447\n",
      "epoch: 10 step: 370, loss is 2.5518547772662714e-06\n",
      "epoch: 10 step: 371, loss is 0.021342944353818893\n",
      "epoch: 10 step: 372, loss is 5.513625183084514e-06\n",
      "epoch: 10 step: 373, loss is 0.002856246894225478\n",
      "epoch: 10 step: 374, loss is 0.00031782506266608834\n",
      "epoch: 10 step: 375, loss is 6.872670201119035e-05\n",
      "epoch: 10 step: 376, loss is 0.03538111224770546\n",
      "epoch: 10 step: 377, loss is 8.033253106987104e-05\n",
      "epoch: 10 step: 378, loss is 0.059969089925289154\n",
      "epoch: 10 step: 379, loss is 3.470814772299491e-05\n",
      "epoch: 10 step: 380, loss is 0.00024022355501074344\n",
      "epoch: 10 step: 381, loss is 0.0009442270384170115\n",
      "epoch: 10 step: 382, loss is 0.0013832590775564313\n",
      "epoch: 10 step: 383, loss is 0.0007949272403493524\n",
      "epoch: 10 step: 384, loss is 0.001146788476034999\n",
      "epoch: 10 step: 385, loss is 0.0011215268168598413\n",
      "epoch: 10 step: 386, loss is 0.02616507187485695\n",
      "epoch: 10 step: 387, loss is 0.004921089857816696\n",
      "epoch: 10 step: 388, loss is 0.0010778602445498109\n",
      "epoch: 10 step: 389, loss is 0.000441103707998991\n",
      "epoch: 10 step: 390, loss is 0.0013992942404001951\n",
      "epoch: 10 step: 391, loss is 0.00042837479850277305\n",
      "epoch: 10 step: 392, loss is 0.0001291046937694773\n",
      "epoch: 10 step: 393, loss is 0.05635762959718704\n",
      "epoch: 10 step: 394, loss is 0.0020181527361273766\n",
      "epoch: 10 step: 395, loss is 0.025289379060268402\n",
      "epoch: 10 step: 396, loss is 0.03184019401669502\n",
      "epoch: 10 step: 397, loss is 0.0034311919007450342\n",
      "epoch: 10 step: 398, loss is 0.001085998141206801\n",
      "epoch: 10 step: 399, loss is 0.0035266675986349583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 400, loss is 0.0021611619740724564\n",
      "epoch: 10 step: 401, loss is 0.006968501023948193\n",
      "epoch: 10 step: 402, loss is 0.024306364357471466\n",
      "epoch: 10 step: 403, loss is 0.00020083390700165182\n",
      "epoch: 10 step: 404, loss is 0.003080538474023342\n",
      "epoch: 10 step: 405, loss is 1.5149067621678114e-05\n",
      "epoch: 10 step: 406, loss is 0.0030738902278244495\n",
      "epoch: 10 step: 407, loss is 0.0019207772566005588\n",
      "epoch: 10 step: 408, loss is 0.0016931261634454131\n",
      "epoch: 10 step: 409, loss is 0.019402608275413513\n",
      "epoch: 10 step: 410, loss is 0.0007881702622398734\n",
      "epoch: 10 step: 411, loss is 0.0003232194285374135\n",
      "epoch: 10 step: 412, loss is 0.0014515361981466413\n",
      "epoch: 10 step: 413, loss is 0.1307631880044937\n",
      "epoch: 10 step: 414, loss is 0.00015944868209771812\n",
      "epoch: 10 step: 415, loss is 0.00015249958960339427\n",
      "epoch: 10 step: 416, loss is 0.007605869323015213\n",
      "epoch: 10 step: 417, loss is 0.0020430241711437702\n",
      "epoch: 10 step: 418, loss is 0.00011107415048172697\n",
      "epoch: 10 step: 419, loss is 0.011242492124438286\n",
      "epoch: 10 step: 420, loss is 0.00035526842111721635\n",
      "epoch: 10 step: 421, loss is 1.9273422367405146e-05\n",
      "epoch: 10 step: 422, loss is 6.815782398916781e-05\n",
      "epoch: 10 step: 423, loss is 0.00016380543820559978\n",
      "epoch: 10 step: 424, loss is 0.007505632005631924\n",
      "epoch: 10 step: 425, loss is 0.0002929308684542775\n",
      "epoch: 10 step: 426, loss is 0.07733724266290665\n",
      "epoch: 10 step: 427, loss is 0.005362355150282383\n",
      "epoch: 10 step: 428, loss is 0.0008145833853632212\n",
      "epoch: 10 step: 429, loss is 0.015788758173584938\n",
      "epoch: 10 step: 430, loss is 0.00014327437384054065\n",
      "epoch: 10 step: 431, loss is 0.0001758222933858633\n",
      "epoch: 10 step: 432, loss is 0.0014534270158037543\n",
      "epoch: 10 step: 433, loss is 0.05867480859160423\n",
      "epoch: 10 step: 434, loss is 0.12386917322874069\n",
      "epoch: 10 step: 435, loss is 0.0019989539869129658\n",
      "epoch: 10 step: 436, loss is 2.5415050913579762e-05\n",
      "epoch: 10 step: 437, loss is 0.0002937761601060629\n",
      "epoch: 10 step: 438, loss is 9.096128633245826e-05\n",
      "epoch: 10 step: 439, loss is 0.003876836970448494\n",
      "epoch: 10 step: 440, loss is 0.006157032214105129\n",
      "epoch: 10 step: 441, loss is 0.03066875785589218\n",
      "epoch: 10 step: 442, loss is 0.00019130577857140452\n",
      "epoch: 10 step: 443, loss is 5.848594446433708e-05\n",
      "epoch: 10 step: 444, loss is 2.422764737275429e-05\n",
      "epoch: 10 step: 445, loss is 0.0001927663543028757\n",
      "epoch: 10 step: 446, loss is 0.03441965579986572\n",
      "epoch: 10 step: 447, loss is 0.0016654256032779813\n",
      "epoch: 10 step: 448, loss is 0.0014131556963548064\n",
      "epoch: 10 step: 449, loss is 0.00011818826897069812\n",
      "epoch: 10 step: 450, loss is 0.06726386398077011\n",
      "epoch: 10 step: 451, loss is 5.032082481193356e-05\n",
      "epoch: 10 step: 452, loss is 0.008381536230444908\n",
      "epoch: 10 step: 453, loss is 0.0012725223787128925\n",
      "epoch: 10 step: 454, loss is 0.00025056026061065495\n",
      "epoch: 10 step: 455, loss is 0.02617732249200344\n",
      "epoch: 10 step: 456, loss is 4.563070251606405e-05\n",
      "epoch: 10 step: 457, loss is 0.0011752223363146186\n",
      "epoch: 10 step: 458, loss is 0.000661910860799253\n",
      "epoch: 10 step: 459, loss is 0.013735936023294926\n",
      "epoch: 10 step: 460, loss is 0.05832432210445404\n",
      "epoch: 10 step: 461, loss is 0.005564376711845398\n",
      "epoch: 10 step: 462, loss is 5.446480372484075e-06\n",
      "epoch: 10 step: 463, loss is 0.0005365556571632624\n",
      "epoch: 10 step: 464, loss is 0.003791204420849681\n",
      "epoch: 10 step: 465, loss is 2.3208788206829922e-06\n",
      "epoch: 10 step: 466, loss is 0.034573182463645935\n",
      "epoch: 10 step: 467, loss is 0.0046349442563951015\n",
      "epoch: 10 step: 468, loss is 0.0020792558789253235\n",
      "epoch: 10 step: 469, loss is 0.00011375835310900584\n",
      "epoch: 10 step: 470, loss is 0.00053312728414312\n",
      "epoch: 10 step: 471, loss is 0.0015311097959056497\n",
      "epoch: 10 step: 472, loss is 0.0004889292176812887\n",
      "epoch: 10 step: 473, loss is 0.034553930163383484\n",
      "epoch: 10 step: 474, loss is 0.1332097053527832\n",
      "epoch: 10 step: 475, loss is 1.531545422039926e-05\n",
      "epoch: 10 step: 476, loss is 8.233776316046715e-05\n",
      "epoch: 10 step: 477, loss is 0.00019469451217446476\n",
      "epoch: 10 step: 478, loss is 0.07431425899267197\n",
      "epoch: 10 step: 479, loss is 0.0002222961193183437\n",
      "epoch: 10 step: 480, loss is 0.0014771175337955356\n",
      "epoch: 10 step: 481, loss is 0.0028299703262746334\n",
      "epoch: 10 step: 482, loss is 0.00010824725177371874\n",
      "epoch: 10 step: 483, loss is 0.0019330526702106\n",
      "epoch: 10 step: 484, loss is 0.0029808180406689644\n",
      "epoch: 10 step: 485, loss is 9.314969065599144e-05\n",
      "epoch: 10 step: 486, loss is 0.01992505043745041\n",
      "epoch: 10 step: 487, loss is 0.0018021261785179377\n",
      "epoch: 10 step: 488, loss is 0.0014784988015890121\n",
      "epoch: 10 step: 489, loss is 0.00045583079918287694\n",
      "epoch: 10 step: 490, loss is 5.351642903406173e-05\n",
      "epoch: 10 step: 491, loss is 9.245696128346026e-05\n",
      "epoch: 10 step: 492, loss is 0.05725079029798508\n",
      "epoch: 10 step: 493, loss is 0.0037633967585861683\n",
      "epoch: 10 step: 494, loss is 0.0250686127692461\n",
      "epoch: 10 step: 495, loss is 0.0006566279917024076\n",
      "epoch: 10 step: 496, loss is 9.84199286904186e-05\n",
      "epoch: 10 step: 497, loss is 0.00016327646153513342\n",
      "epoch: 10 step: 498, loss is 0.008919570595026016\n",
      "epoch: 10 step: 499, loss is 2.2947826437302865e-05\n",
      "epoch: 10 step: 500, loss is 0.005245615262538195\n",
      "epoch: 10 step: 501, loss is 0.0007858488825149834\n",
      "epoch: 10 step: 502, loss is 0.00996309332549572\n",
      "epoch: 10 step: 503, loss is 0.00040201935917139053\n",
      "epoch: 10 step: 504, loss is 0.0012824557488784194\n",
      "epoch: 10 step: 505, loss is 0.0007363869226537645\n",
      "epoch: 10 step: 506, loss is 0.015457944013178349\n",
      "epoch: 10 step: 507, loss is 0.0004875481827184558\n",
      "epoch: 10 step: 508, loss is 4.489565981202759e-05\n",
      "epoch: 10 step: 509, loss is 0.0003284515405539423\n",
      "epoch: 10 step: 510, loss is 0.00015236074978020042\n",
      "epoch: 10 step: 511, loss is 0.003485148074105382\n",
      "epoch: 10 step: 512, loss is 0.03663570061326027\n",
      "epoch: 10 step: 513, loss is 0.001289117499254644\n",
      "epoch: 10 step: 514, loss is 1.7301763364230283e-05\n",
      "epoch: 10 step: 515, loss is 0.029596300795674324\n",
      "epoch: 10 step: 516, loss is 0.018515516072511673\n",
      "epoch: 10 step: 517, loss is 2.489211328793317e-05\n",
      "epoch: 10 step: 518, loss is 0.00034099468030035496\n",
      "epoch: 10 step: 519, loss is 0.0001663715811446309\n",
      "epoch: 10 step: 520, loss is 0.003827567445114255\n",
      "epoch: 10 step: 521, loss is 2.6621666620485485e-05\n",
      "epoch: 10 step: 522, loss is 0.03463131934404373\n",
      "epoch: 10 step: 523, loss is 0.007880747318267822\n",
      "epoch: 10 step: 524, loss is 0.0003011610242538154\n",
      "epoch: 10 step: 525, loss is 3.3238844480365515e-05\n",
      "epoch: 10 step: 526, loss is 0.016774486750364304\n",
      "epoch: 10 step: 527, loss is 0.011279680766165257\n",
      "epoch: 10 step: 528, loss is 0.00025779809220694005\n",
      "epoch: 10 step: 529, loss is 0.0009541918989270926\n",
      "epoch: 10 step: 530, loss is 0.0023199652787297964\n",
      "epoch: 10 step: 531, loss is 0.0005275725852698088\n",
      "epoch: 10 step: 532, loss is 0.0873553454875946\n",
      "epoch: 10 step: 533, loss is 0.003585709957405925\n",
      "epoch: 10 step: 534, loss is 0.039685193449258804\n",
      "epoch: 10 step: 535, loss is 0.033114369958639145\n",
      "epoch: 10 step: 536, loss is 0.0016860138857737184\n",
      "epoch: 10 step: 537, loss is 0.004796199034899473\n",
      "epoch: 10 step: 538, loss is 0.0720914900302887\n",
      "epoch: 10 step: 539, loss is 0.00028066319646313787\n",
      "epoch: 10 step: 540, loss is 3.294836642453447e-05\n",
      "epoch: 10 step: 541, loss is 0.000756550463847816\n",
      "epoch: 10 step: 542, loss is 0.028982490301132202\n",
      "epoch: 10 step: 543, loss is 0.0013066428946331143\n",
      "epoch: 10 step: 544, loss is 0.01314254105091095\n",
      "epoch: 10 step: 545, loss is 0.014491325244307518\n",
      "epoch: 10 step: 546, loss is 0.0002446019498165697\n",
      "epoch: 10 step: 547, loss is 0.0003321776748634875\n",
      "epoch: 10 step: 548, loss is 0.007653234526515007\n",
      "epoch: 10 step: 549, loss is 0.0006438224809244275\n",
      "epoch: 10 step: 550, loss is 0.0037318409886211157\n",
      "epoch: 10 step: 551, loss is 0.008054572157561779\n",
      "epoch: 10 step: 552, loss is 2.4037941329879686e-05\n",
      "epoch: 10 step: 553, loss is 0.0001268439955310896\n",
      "epoch: 10 step: 554, loss is 0.0026935888454318047\n",
      "epoch: 10 step: 555, loss is 0.005161892157047987\n",
      "epoch: 10 step: 556, loss is 0.009786893613636494\n",
      "epoch: 10 step: 557, loss is 0.20649904012680054\n",
      "epoch: 10 step: 558, loss is 0.005323668941855431\n",
      "epoch: 10 step: 559, loss is 0.0031311328057199717\n",
      "epoch: 10 step: 560, loss is 0.0015207250835373998\n",
      "epoch: 10 step: 561, loss is 0.010274040512740612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 562, loss is 0.00019329409406054765\n",
      "epoch: 10 step: 563, loss is 0.05007479339838028\n",
      "epoch: 10 step: 564, loss is 0.058661919087171555\n",
      "epoch: 10 step: 565, loss is 0.004887115675956011\n",
      "epoch: 10 step: 566, loss is 0.027034185826778412\n",
      "epoch: 10 step: 567, loss is 8.399533544434234e-05\n",
      "epoch: 10 step: 568, loss is 0.2162785828113556\n",
      "epoch: 10 step: 569, loss is 0.05158565565943718\n",
      "epoch: 10 step: 570, loss is 2.9837372494512238e-05\n",
      "epoch: 10 step: 571, loss is 3.777051097131334e-05\n",
      "epoch: 10 step: 572, loss is 0.1855432391166687\n",
      "epoch: 10 step: 573, loss is 0.0002072857751045376\n",
      "epoch: 10 step: 574, loss is 0.01349946204572916\n",
      "epoch: 10 step: 575, loss is 0.007571069989353418\n",
      "epoch: 10 step: 576, loss is 0.0005147424526512623\n",
      "epoch: 10 step: 577, loss is 0.04107479378581047\n",
      "epoch: 10 step: 578, loss is 0.000986979459412396\n",
      "epoch: 10 step: 579, loss is 3.121847157672164e-06\n",
      "epoch: 10 step: 580, loss is 0.0004793912812601775\n",
      "epoch: 10 step: 581, loss is 0.006414744071662426\n",
      "epoch: 10 step: 582, loss is 2.8312565518717747e-06\n",
      "epoch: 10 step: 583, loss is 0.034140605479478836\n",
      "epoch: 10 step: 584, loss is 0.0002557341067586094\n",
      "epoch: 10 step: 585, loss is 0.014668511226773262\n",
      "epoch: 10 step: 586, loss is 0.21138624846935272\n",
      "epoch: 10 step: 587, loss is 0.003663860261440277\n",
      "epoch: 10 step: 588, loss is 0.0006502450560219586\n",
      "epoch: 10 step: 589, loss is 0.00015109177911654115\n",
      "epoch: 10 step: 590, loss is 0.002928324742242694\n",
      "epoch: 10 step: 591, loss is 0.04236616566777229\n",
      "epoch: 10 step: 592, loss is 0.012934142723679543\n",
      "epoch: 10 step: 593, loss is 0.014575163833796978\n",
      "epoch: 10 step: 594, loss is 0.0045847115106880665\n",
      "epoch: 10 step: 595, loss is 0.0015325072454288602\n",
      "epoch: 10 step: 596, loss is 0.008092372678220272\n",
      "epoch: 10 step: 597, loss is 0.025471100583672523\n",
      "epoch: 10 step: 598, loss is 0.0022353478707373142\n",
      "epoch: 10 step: 599, loss is 0.03675375506281853\n",
      "epoch: 10 step: 600, loss is 0.09197338670492172\n",
      "epoch: 10 step: 601, loss is 0.00047711952356621623\n",
      "epoch: 10 step: 602, loss is 0.002176257548853755\n",
      "epoch: 10 step: 603, loss is 0.009793953038752079\n",
      "epoch: 10 step: 604, loss is 5.460477768792771e-05\n",
      "epoch: 10 step: 605, loss is 0.0006489696679636836\n",
      "epoch: 10 step: 606, loss is 0.09223141521215439\n",
      "epoch: 10 step: 607, loss is 0.0002393600152572617\n",
      "epoch: 10 step: 608, loss is 0.004069077782332897\n",
      "epoch: 10 step: 609, loss is 0.0016012239502742887\n",
      "epoch: 10 step: 610, loss is 0.0010927969124168158\n",
      "epoch: 10 step: 611, loss is 4.8921840061666444e-05\n",
      "epoch: 10 step: 612, loss is 0.0006898571737110615\n",
      "epoch: 10 step: 613, loss is 0.0006819010013714433\n",
      "epoch: 10 step: 614, loss is 0.0003854873648378998\n",
      "epoch: 10 step: 615, loss is 0.015012245625257492\n",
      "epoch: 10 step: 616, loss is 0.002468288177624345\n",
      "epoch: 10 step: 617, loss is 7.512023148592561e-05\n",
      "epoch: 10 step: 618, loss is 0.0001757846330292523\n",
      "epoch: 10 step: 619, loss is 0.002282633911818266\n",
      "epoch: 10 step: 620, loss is 0.00010322711750632152\n",
      "epoch: 10 step: 621, loss is 0.020347105339169502\n",
      "epoch: 10 step: 622, loss is 0.004031808115541935\n",
      "epoch: 10 step: 623, loss is 0.0019919690676033497\n",
      "epoch: 10 step: 624, loss is 0.0746864378452301\n",
      "epoch: 10 step: 625, loss is 5.2043205869267695e-06\n",
      "epoch: 10 step: 626, loss is 3.96374125557486e-05\n",
      "epoch: 10 step: 627, loss is 0.16530847549438477\n",
      "epoch: 10 step: 628, loss is 0.00039970752550289035\n",
      "epoch: 10 step: 629, loss is 8.70597068569623e-05\n",
      "epoch: 10 step: 630, loss is 2.2022419216227718e-05\n",
      "epoch: 10 step: 631, loss is 0.0003082574112340808\n",
      "epoch: 10 step: 632, loss is 0.0005259888712316751\n",
      "epoch: 10 step: 633, loss is 0.0008880952373147011\n",
      "epoch: 10 step: 634, loss is 0.0003559697070159018\n",
      "epoch: 10 step: 635, loss is 0.0013169525191187859\n",
      "epoch: 10 step: 636, loss is 0.0071968683041632175\n",
      "epoch: 10 step: 637, loss is 0.0007539585349150002\n",
      "epoch: 10 step: 638, loss is 0.00052271579625085\n",
      "epoch: 10 step: 639, loss is 0.00020124194270465523\n",
      "epoch: 10 step: 640, loss is 0.028469344601035118\n",
      "epoch: 10 step: 641, loss is 0.09779120236635208\n",
      "epoch: 10 step: 642, loss is 0.0006645335233770311\n",
      "epoch: 10 step: 643, loss is 0.07912569493055344\n",
      "epoch: 10 step: 644, loss is 6.60610239719972e-05\n",
      "epoch: 10 step: 645, loss is 0.03630048781633377\n",
      "epoch: 10 step: 646, loss is 0.0012785298749804497\n",
      "epoch: 10 step: 647, loss is 0.00030571239767596126\n",
      "epoch: 10 step: 648, loss is 0.005152683239430189\n",
      "epoch: 10 step: 649, loss is 0.00256527541205287\n",
      "epoch: 10 step: 650, loss is 0.0007272453512996435\n",
      "epoch: 10 step: 651, loss is 0.03682611510157585\n",
      "epoch: 10 step: 652, loss is 0.003113376908004284\n",
      "epoch: 10 step: 653, loss is 0.0011408246355131269\n",
      "epoch: 10 step: 654, loss is 0.004682830534875393\n",
      "epoch: 10 step: 655, loss is 0.012098057195544243\n",
      "epoch: 10 step: 656, loss is 0.011553015559911728\n",
      "epoch: 10 step: 657, loss is 0.0009443581220693886\n",
      "epoch: 10 step: 658, loss is 0.004787737503647804\n",
      "epoch: 10 step: 659, loss is 7.511118019465357e-05\n",
      "epoch: 10 step: 660, loss is 0.0013606606516987085\n",
      "epoch: 10 step: 661, loss is 0.00044902783702127635\n",
      "epoch: 10 step: 662, loss is 0.014965008944272995\n",
      "epoch: 10 step: 663, loss is 0.0004950835718773305\n",
      "epoch: 10 step: 664, loss is 0.004891876131296158\n",
      "epoch: 10 step: 665, loss is 0.0005226403009146452\n",
      "epoch: 10 step: 666, loss is 9.316462819697335e-05\n",
      "epoch: 10 step: 667, loss is 0.0026601506397128105\n",
      "epoch: 10 step: 668, loss is 0.0002908830938395113\n",
      "epoch: 10 step: 669, loss is 0.0043295579962432384\n",
      "epoch: 10 step: 670, loss is 0.007995618507266045\n",
      "epoch: 10 step: 671, loss is 0.0007135967025533319\n",
      "epoch: 10 step: 672, loss is 0.0006140118930488825\n",
      "epoch: 10 step: 673, loss is 0.0010099667124450207\n",
      "epoch: 10 step: 674, loss is 0.00023432474699802697\n",
      "epoch: 10 step: 675, loss is 0.01787228137254715\n",
      "epoch: 10 step: 676, loss is 0.010850833728909492\n",
      "epoch: 10 step: 677, loss is 0.0030839622486382723\n",
      "epoch: 10 step: 678, loss is 0.002610832452774048\n",
      "epoch: 10 step: 679, loss is 0.001057418528944254\n",
      "epoch: 10 step: 680, loss is 0.011961041018366814\n",
      "epoch: 10 step: 681, loss is 0.008754042908549309\n",
      "epoch: 10 step: 682, loss is 0.06492220610380173\n",
      "epoch: 10 step: 683, loss is 4.319459912949242e-05\n",
      "epoch: 10 step: 684, loss is 0.00021070601360406727\n",
      "epoch: 10 step: 685, loss is 0.005996999330818653\n",
      "epoch: 10 step: 686, loss is 0.009545731358230114\n",
      "epoch: 10 step: 687, loss is 7.00222808518447e-05\n",
      "epoch: 10 step: 688, loss is 0.0001887281541712582\n",
      "epoch: 10 step: 689, loss is 0.0003248102148063481\n",
      "epoch: 10 step: 690, loss is 0.0001091102312784642\n",
      "epoch: 10 step: 691, loss is 0.001104785013012588\n",
      "epoch: 10 step: 692, loss is 0.0005949260084889829\n",
      "epoch: 10 step: 693, loss is 0.0019362346502020955\n",
      "epoch: 10 step: 694, loss is 0.013354313559830189\n",
      "epoch: 10 step: 695, loss is 0.000534556049387902\n",
      "epoch: 10 step: 696, loss is 0.00878809206187725\n",
      "epoch: 10 step: 697, loss is 0.02505853772163391\n",
      "epoch: 10 step: 698, loss is 0.0014625157928094268\n",
      "epoch: 10 step: 699, loss is 0.0006796304951421916\n",
      "epoch: 10 step: 700, loss is 0.018733186647295952\n",
      "epoch: 10 step: 701, loss is 0.08148111402988434\n",
      "epoch: 10 step: 702, loss is 6.51381051284261e-05\n",
      "epoch: 10 step: 703, loss is 0.004316824022680521\n",
      "epoch: 10 step: 704, loss is 0.028772268444299698\n",
      "epoch: 10 step: 705, loss is 0.00013000731996726245\n",
      "epoch: 10 step: 706, loss is 0.0439114049077034\n",
      "epoch: 10 step: 707, loss is 0.021291207522153854\n",
      "epoch: 10 step: 708, loss is 0.04087267071008682\n",
      "epoch: 10 step: 709, loss is 0.006343663204461336\n",
      "epoch: 10 step: 710, loss is 0.00862069521099329\n",
      "epoch: 10 step: 711, loss is 0.0013420332688838243\n",
      "epoch: 10 step: 712, loss is 0.22597365081310272\n",
      "epoch: 10 step: 713, loss is 0.0006307319272309542\n",
      "epoch: 10 step: 714, loss is 0.00011814686877187341\n",
      "epoch: 10 step: 715, loss is 0.008473553694784641\n",
      "epoch: 10 step: 716, loss is 0.02906581573188305\n",
      "epoch: 10 step: 717, loss is 0.0018554870039224625\n",
      "epoch: 10 step: 718, loss is 0.008432145230472088\n",
      "epoch: 10 step: 719, loss is 0.00767340324819088\n",
      "epoch: 10 step: 720, loss is 0.0055862655863165855\n",
      "epoch: 10 step: 721, loss is 0.0008438713266514242\n",
      "epoch: 10 step: 722, loss is 5.826786218676716e-05\n",
      "epoch: 10 step: 723, loss is 0.15987497568130493\n",
      "epoch: 10 step: 724, loss is 0.0013053907314315438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 725, loss is 0.00023704035265836865\n",
      "epoch: 10 step: 726, loss is 0.004626729059964418\n",
      "epoch: 10 step: 727, loss is 0.029097318649291992\n",
      "epoch: 10 step: 728, loss is 0.00033965331385843456\n",
      "epoch: 10 step: 729, loss is 0.00154190044850111\n",
      "epoch: 10 step: 730, loss is 0.0005003585247322917\n",
      "epoch: 10 step: 731, loss is 0.00045045133447274566\n",
      "epoch: 10 step: 732, loss is 0.004997937940061092\n",
      "epoch: 10 step: 733, loss is 7.37610321266402e-07\n",
      "epoch: 10 step: 734, loss is 0.000830686476547271\n",
      "epoch: 10 step: 735, loss is 2.9960723622934893e-05\n",
      "epoch: 10 step: 736, loss is 0.04169031232595444\n",
      "epoch: 10 step: 737, loss is 0.06905725598335266\n",
      "epoch: 10 step: 738, loss is 1.1049757631553803e-05\n",
      "epoch: 10 step: 739, loss is 0.0058323233388364315\n",
      "epoch: 10 step: 740, loss is 0.004178911447525024\n",
      "epoch: 10 step: 741, loss is 0.0011940195690840483\n",
      "epoch: 10 step: 742, loss is 0.00495224678888917\n",
      "epoch: 10 step: 743, loss is 0.00031074354774318635\n",
      "epoch: 10 step: 744, loss is 7.869444380048662e-05\n",
      "epoch: 10 step: 745, loss is 0.0075203124433755875\n",
      "epoch: 10 step: 746, loss is 0.00033094690297730267\n",
      "epoch: 10 step: 747, loss is 6.24654785497114e-05\n",
      "epoch: 10 step: 748, loss is 0.0001014697045320645\n",
      "epoch: 10 step: 749, loss is 3.998868851340376e-05\n",
      "epoch: 10 step: 750, loss is 0.0034328990150243044\n",
      "epoch: 10 step: 751, loss is 2.8196576749905944e-05\n",
      "epoch: 10 step: 752, loss is 0.002891821786761284\n",
      "epoch: 10 step: 753, loss is 0.00026747575611807406\n",
      "epoch: 10 step: 754, loss is 0.021521542221307755\n",
      "epoch: 10 step: 755, loss is 0.0015398698160424829\n",
      "epoch: 10 step: 756, loss is 0.00041249918285757303\n",
      "epoch: 10 step: 757, loss is 0.0027135859709233046\n",
      "epoch: 10 step: 758, loss is 0.04375968500971794\n",
      "epoch: 10 step: 759, loss is 0.00020289470558054745\n",
      "epoch: 10 step: 760, loss is 0.018659064546227455\n",
      "epoch: 10 step: 761, loss is 0.0010493325535207987\n",
      "epoch: 10 step: 762, loss is 0.00012189875269541517\n",
      "epoch: 10 step: 763, loss is 4.049340350320563e-05\n",
      "epoch: 10 step: 764, loss is 0.005768905393779278\n",
      "epoch: 10 step: 765, loss is 0.0008323843940161169\n",
      "epoch: 10 step: 766, loss is 4.4205004087416455e-05\n",
      "epoch: 10 step: 767, loss is 2.808903218465275e-06\n",
      "epoch: 10 step: 768, loss is 0.039911411702632904\n",
      "epoch: 10 step: 769, loss is 0.0005582344601862133\n",
      "epoch: 10 step: 770, loss is 0.0005406341515481472\n",
      "epoch: 10 step: 771, loss is 3.0554547265637666e-05\n",
      "epoch: 10 step: 772, loss is 0.010707968845963478\n",
      "epoch: 10 step: 773, loss is 0.005489180330187082\n",
      "epoch: 10 step: 774, loss is 0.00014493928756564856\n",
      "epoch: 10 step: 775, loss is 4.3133459257660434e-05\n",
      "epoch: 10 step: 776, loss is 1.3723596566705965e-05\n",
      "epoch: 10 step: 777, loss is 0.0734374076128006\n",
      "epoch: 10 step: 778, loss is 6.233232124941424e-05\n",
      "epoch: 10 step: 779, loss is 0.0035730109084397554\n",
      "epoch: 10 step: 780, loss is 6.966663204366341e-05\n",
      "epoch: 10 step: 781, loss is 0.00011985459423158318\n",
      "epoch: 10 step: 782, loss is 0.009062620811164379\n",
      "epoch: 10 step: 783, loss is 4.456112947082147e-05\n",
      "epoch: 10 step: 784, loss is 0.03526021167635918\n",
      "epoch: 10 step: 785, loss is 0.0010141520760953426\n",
      "epoch: 10 step: 786, loss is 0.0018031859071925282\n",
      "epoch: 10 step: 787, loss is 0.0002390617592027411\n",
      "epoch: 10 step: 788, loss is 0.28800976276397705\n",
      "epoch: 10 step: 789, loss is 0.01693214662373066\n",
      "epoch: 10 step: 790, loss is 0.0008450045133940876\n",
      "epoch: 10 step: 791, loss is 0.0012213591253384948\n",
      "epoch: 10 step: 792, loss is 3.514160925988108e-05\n",
      "epoch: 10 step: 793, loss is 0.011180390603840351\n",
      "epoch: 10 step: 794, loss is 0.12497088313102722\n",
      "epoch: 10 step: 795, loss is 0.11868976801633835\n",
      "epoch: 10 step: 796, loss is 0.0007078083581291139\n",
      "epoch: 10 step: 797, loss is 0.0004216124361846596\n",
      "epoch: 10 step: 798, loss is 1.2651616088987794e-05\n",
      "epoch: 10 step: 799, loss is 0.000583746237680316\n",
      "epoch: 10 step: 800, loss is 0.0015954701229929924\n",
      "epoch: 10 step: 801, loss is 0.0024333568289875984\n",
      "epoch: 10 step: 802, loss is 0.0014960413100197911\n",
      "epoch: 10 step: 803, loss is 0.0019380593439564109\n",
      "epoch: 10 step: 804, loss is 0.011806418187916279\n",
      "epoch: 10 step: 805, loss is 0.027161145582795143\n",
      "epoch: 10 step: 806, loss is 0.0005634241970255971\n",
      "epoch: 10 step: 807, loss is 0.008954906836152077\n",
      "epoch: 10 step: 808, loss is 0.001015521353110671\n",
      "epoch: 10 step: 809, loss is 0.003412160323932767\n",
      "epoch: 10 step: 810, loss is 0.0016440480249002576\n",
      "epoch: 10 step: 811, loss is 0.0008327302057296038\n",
      "epoch: 10 step: 812, loss is 0.00017735594883561134\n",
      "epoch: 10 step: 813, loss is 0.008506957441568375\n",
      "epoch: 10 step: 814, loss is 0.006326932460069656\n",
      "epoch: 10 step: 815, loss is 0.009363922290503979\n",
      "epoch: 10 step: 816, loss is 0.0012398881372064352\n",
      "epoch: 10 step: 817, loss is 0.0012016111286357045\n",
      "epoch: 10 step: 818, loss is 0.00016522528312634677\n",
      "epoch: 10 step: 819, loss is 0.0027372792828828096\n",
      "epoch: 10 step: 820, loss is 9.773082274477929e-05\n",
      "epoch: 10 step: 821, loss is 0.0031834044493734837\n",
      "epoch: 10 step: 822, loss is 0.008065890520811081\n",
      "epoch: 10 step: 823, loss is 0.0008896783110685647\n",
      "epoch: 10 step: 824, loss is 0.033392030745744705\n",
      "epoch: 10 step: 825, loss is 0.000610693241469562\n",
      "epoch: 10 step: 826, loss is 0.0021792794577777386\n",
      "epoch: 10 step: 827, loss is 0.018574949353933334\n",
      "epoch: 10 step: 828, loss is 0.0016142386011779308\n",
      "epoch: 10 step: 829, loss is 0.05679081380367279\n",
      "epoch: 10 step: 830, loss is 0.0664227157831192\n",
      "epoch: 10 step: 831, loss is 0.022602954879403114\n",
      "epoch: 10 step: 832, loss is 0.0006014924729242921\n",
      "epoch: 10 step: 833, loss is 0.0009000131394714117\n",
      "epoch: 10 step: 834, loss is 0.002534742932766676\n",
      "epoch: 10 step: 835, loss is 0.004579166881740093\n",
      "epoch: 10 step: 836, loss is 0.00033091730438172817\n",
      "epoch: 10 step: 837, loss is 0.00013735749234911054\n",
      "epoch: 10 step: 838, loss is 0.0002438338124193251\n",
      "epoch: 10 step: 839, loss is 0.00014779878256376833\n",
      "epoch: 10 step: 840, loss is 6.936623321962543e-06\n",
      "epoch: 10 step: 841, loss is 0.027005977928638458\n",
      "epoch: 10 step: 842, loss is 0.0031578929629176855\n",
      "epoch: 10 step: 843, loss is 0.0001248895569005981\n",
      "epoch: 10 step: 844, loss is 0.0019695465452969074\n",
      "epoch: 10 step: 845, loss is 0.00254057627171278\n",
      "epoch: 10 step: 846, loss is 0.020584063604474068\n",
      "epoch: 10 step: 847, loss is 6.71223970130086e-05\n",
      "epoch: 10 step: 848, loss is 0.01420594658702612\n",
      "epoch: 10 step: 849, loss is 0.0008800682262517512\n",
      "epoch: 10 step: 850, loss is 0.0017174056265503168\n",
      "epoch: 10 step: 851, loss is 0.00010038680920843035\n",
      "epoch: 10 step: 852, loss is 0.011342914775013924\n",
      "epoch: 10 step: 853, loss is 0.0001893606677185744\n",
      "epoch: 10 step: 854, loss is 0.00010702303552534431\n",
      "epoch: 10 step: 855, loss is 0.00020803369989152998\n",
      "epoch: 10 step: 856, loss is 0.04207028076052666\n",
      "epoch: 10 step: 857, loss is 0.0016478222096338868\n",
      "epoch: 10 step: 858, loss is 0.0017568240873515606\n",
      "epoch: 10 step: 859, loss is 0.0006156826857477427\n",
      "epoch: 10 step: 860, loss is 0.0026693730615079403\n",
      "epoch: 10 step: 861, loss is 0.0001408834068570286\n",
      "epoch: 10 step: 862, loss is 0.00019235990475863218\n",
      "epoch: 10 step: 863, loss is 1.1537632417457644e-05\n",
      "epoch: 10 step: 864, loss is 4.4318825530353934e-05\n",
      "epoch: 10 step: 865, loss is 0.0002316161699127406\n",
      "epoch: 10 step: 866, loss is 0.0013464103685691953\n",
      "epoch: 10 step: 867, loss is 0.003161034779623151\n",
      "epoch: 10 step: 868, loss is 0.0006582837086170912\n",
      "epoch: 10 step: 869, loss is 0.00018671684665605426\n",
      "epoch: 10 step: 870, loss is 0.0001792802504496649\n",
      "epoch: 10 step: 871, loss is 1.672451980994083e-05\n",
      "epoch: 10 step: 872, loss is 3.3253556466661394e-05\n",
      "epoch: 10 step: 873, loss is 1.7860431398730725e-05\n",
      "epoch: 10 step: 874, loss is 6.819255213486031e-05\n",
      "epoch: 10 step: 875, loss is 0.00013580867380369455\n",
      "epoch: 10 step: 876, loss is 2.258228232676629e-05\n",
      "epoch: 10 step: 877, loss is 0.00040219942457042634\n",
      "epoch: 10 step: 878, loss is 1.0168846529268194e-05\n",
      "epoch: 10 step: 879, loss is 0.0008947243914008141\n",
      "epoch: 10 step: 880, loss is 0.0007110479637049139\n",
      "epoch: 10 step: 881, loss is 0.0004731629742309451\n",
      "epoch: 10 step: 882, loss is 0.0031241709366440773\n",
      "epoch: 10 step: 883, loss is 8.188530046027154e-06\n",
      "epoch: 10 step: 884, loss is 0.0005047338781878352\n",
      "epoch: 10 step: 885, loss is 0.021545996889472008\n",
      "epoch: 10 step: 886, loss is 3.9787332752894145e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 887, loss is 0.0005680133472196758\n",
      "epoch: 10 step: 888, loss is 0.00791159737855196\n",
      "epoch: 10 step: 889, loss is 0.0005517435492947698\n",
      "epoch: 10 step: 890, loss is 9.24880150705576e-05\n",
      "epoch: 10 step: 891, loss is 3.259043296566233e-05\n",
      "epoch: 10 step: 892, loss is 0.01368920598179102\n",
      "epoch: 10 step: 893, loss is 0.03886112943291664\n",
      "epoch: 10 step: 894, loss is 0.0003903293691109866\n",
      "epoch: 10 step: 895, loss is 0.0003646719560492784\n",
      "epoch: 10 step: 896, loss is 0.04293235018849373\n",
      "epoch: 10 step: 897, loss is 0.12642179429531097\n",
      "epoch: 10 step: 898, loss is 0.00015999781317077577\n",
      "epoch: 10 step: 899, loss is 0.0026662324089556932\n",
      "epoch: 10 step: 900, loss is 0.1130453422665596\n",
      "epoch: 10 step: 901, loss is 0.0012577521847561002\n",
      "epoch: 10 step: 902, loss is 0.013373611494898796\n",
      "epoch: 10 step: 903, loss is 0.0003335645596962422\n",
      "epoch: 10 step: 904, loss is 0.0004620364052243531\n",
      "epoch: 10 step: 905, loss is 6.931556526978966e-06\n",
      "epoch: 10 step: 906, loss is 0.004665517248213291\n",
      "epoch: 10 step: 907, loss is 3.7529960536630824e-05\n",
      "epoch: 10 step: 908, loss is 0.00011498927051434293\n",
      "epoch: 10 step: 909, loss is 0.01833566091954708\n",
      "epoch: 10 step: 910, loss is 0.00010219544492429122\n",
      "epoch: 10 step: 911, loss is 5.184857582207769e-05\n",
      "epoch: 10 step: 912, loss is 0.0017794232117012143\n",
      "epoch: 10 step: 913, loss is 5.113910083309747e-05\n",
      "epoch: 10 step: 914, loss is 0.05670371279120445\n",
      "epoch: 10 step: 915, loss is 0.0180494487285614\n",
      "epoch: 10 step: 916, loss is 0.006266003008931875\n",
      "epoch: 10 step: 917, loss is 1.1116864698124118e-05\n",
      "epoch: 10 step: 918, loss is 0.004022093024104834\n",
      "epoch: 10 step: 919, loss is 0.0005892665940336883\n",
      "epoch: 10 step: 920, loss is 0.10049653798341751\n",
      "epoch: 10 step: 921, loss is 0.00020672398386523128\n",
      "epoch: 10 step: 922, loss is 0.062158603221178055\n",
      "epoch: 10 step: 923, loss is 0.19064849615097046\n",
      "epoch: 10 step: 924, loss is 0.004810164216905832\n",
      "epoch: 10 step: 925, loss is 3.705434573930688e-05\n",
      "epoch: 10 step: 926, loss is 0.00015226658433675766\n",
      "epoch: 10 step: 927, loss is 0.03344453498721123\n",
      "epoch: 10 step: 928, loss is 0.00047153502237051725\n",
      "epoch: 10 step: 929, loss is 0.0562073215842247\n",
      "epoch: 10 step: 930, loss is 0.0008838517242111266\n",
      "epoch: 10 step: 931, loss is 0.00586693175137043\n",
      "epoch: 10 step: 932, loss is 0.01431478001177311\n",
      "epoch: 10 step: 933, loss is 0.00022823316976428032\n",
      "epoch: 10 step: 934, loss is 0.0002855375059880316\n",
      "epoch: 10 step: 935, loss is 0.00014709732204210013\n",
      "epoch: 10 step: 936, loss is 0.0013664484722539783\n",
      "epoch: 10 step: 937, loss is 0.07451459020376205\n",
      "epoch: 10 step: 938, loss is 0.0016442399937659502\n",
      "epoch: 10 step: 939, loss is 0.005458774510771036\n",
      "epoch: 10 step: 940, loss is 0.05216037482023239\n",
      "epoch: 10 step: 941, loss is 0.03601691126823425\n",
      "epoch: 10 step: 942, loss is 0.03927979618310928\n",
      "epoch: 10 step: 943, loss is 5.986091127851978e-05\n",
      "epoch: 10 step: 944, loss is 0.0013707155594602227\n",
      "epoch: 10 step: 945, loss is 0.00388595019467175\n",
      "epoch: 10 step: 946, loss is 0.00520770950242877\n",
      "epoch: 10 step: 947, loss is 0.000560976390261203\n",
      "epoch: 10 step: 948, loss is 0.000302873901091516\n",
      "epoch: 10 step: 949, loss is 0.0006608837284147739\n",
      "epoch: 10 step: 950, loss is 9.457483429287095e-06\n",
      "epoch: 10 step: 951, loss is 0.000376182229956612\n",
      "epoch: 10 step: 952, loss is 0.0025814492255449295\n",
      "epoch: 10 step: 953, loss is 2.417744553895318e-06\n",
      "epoch: 10 step: 954, loss is 0.00011249975068494678\n",
      "epoch: 10 step: 955, loss is 6.196996400831267e-05\n",
      "epoch: 10 step: 956, loss is 8.308557153213769e-05\n",
      "epoch: 10 step: 957, loss is 1.8016053218161687e-05\n",
      "epoch: 10 step: 958, loss is 0.001567150349728763\n",
      "epoch: 10 step: 959, loss is 0.024358857423067093\n",
      "epoch: 10 step: 960, loss is 0.003623092779889703\n",
      "epoch: 10 step: 961, loss is 0.010103676468133926\n",
      "epoch: 10 step: 962, loss is 1.5199268545984523e-06\n",
      "epoch: 10 step: 963, loss is 3.2588875910732895e-05\n",
      "epoch: 10 step: 964, loss is 0.023018978536128998\n",
      "epoch: 10 step: 965, loss is 0.00045375715126283467\n",
      "epoch: 10 step: 966, loss is 0.0001316484558628872\n",
      "epoch: 10 step: 967, loss is 0.0005006538121961057\n",
      "epoch: 10 step: 968, loss is 8.827743295114487e-05\n",
      "epoch: 10 step: 969, loss is 0.00048063715803436935\n",
      "epoch: 10 step: 970, loss is 8.776675531407818e-05\n",
      "epoch: 10 step: 971, loss is 0.0010721777798607945\n",
      "epoch: 10 step: 972, loss is 0.01211280282586813\n",
      "epoch: 10 step: 973, loss is 2.35879015235696e-05\n",
      "epoch: 10 step: 974, loss is 0.0028756787069141865\n",
      "epoch: 10 step: 975, loss is 0.12211868911981583\n",
      "epoch: 10 step: 976, loss is 4.621431071427651e-05\n",
      "epoch: 10 step: 977, loss is 8.409073780057952e-05\n",
      "epoch: 10 step: 978, loss is 0.02661067247390747\n",
      "epoch: 10 step: 979, loss is 1.5045474356156774e-05\n",
      "epoch: 10 step: 980, loss is 1.0009351171902381e-05\n",
      "epoch: 10 step: 981, loss is 0.017793411388993263\n",
      "epoch: 10 step: 982, loss is 0.004762440919876099\n",
      "epoch: 10 step: 983, loss is 0.0001867965329438448\n",
      "epoch: 10 step: 984, loss is 0.00023407000117003918\n",
      "epoch: 10 step: 985, loss is 0.00028413013205863535\n",
      "epoch: 10 step: 986, loss is 0.0028182046953588724\n",
      "epoch: 10 step: 987, loss is 0.05483643338084221\n",
      "epoch: 10 step: 988, loss is 2.9802749850205146e-06\n",
      "epoch: 10 step: 989, loss is 3.550780093064532e-05\n",
      "epoch: 10 step: 990, loss is 0.013707014732062817\n",
      "epoch: 10 step: 991, loss is 0.012548086233437061\n",
      "epoch: 10 step: 992, loss is 0.0011912626214325428\n",
      "epoch: 10 step: 993, loss is 0.024025827646255493\n",
      "epoch: 10 step: 994, loss is 0.00011202444147784263\n",
      "epoch: 10 step: 995, loss is 0.001723618246614933\n",
      "epoch: 10 step: 996, loss is 0.0152336610481143\n",
      "epoch: 10 step: 997, loss is 0.09815289080142975\n",
      "epoch: 10 step: 998, loss is 0.0009700896916911006\n",
      "epoch: 10 step: 999, loss is 0.004945291671901941\n",
      "epoch: 10 step: 1000, loss is 8.20790883153677e-05\n",
      "epoch: 10 step: 1001, loss is 1.4894774722051807e-05\n",
      "epoch: 10 step: 1002, loss is 0.0003399053239263594\n",
      "epoch: 10 step: 1003, loss is 0.0005461527034640312\n",
      "epoch: 10 step: 1004, loss is 0.0013686779420822859\n",
      "epoch: 10 step: 1005, loss is 0.0023002622183412313\n",
      "epoch: 10 step: 1006, loss is 0.003220345126464963\n",
      "epoch: 10 step: 1007, loss is 0.1570938676595688\n",
      "epoch: 10 step: 1008, loss is 0.037483394145965576\n",
      "epoch: 10 step: 1009, loss is 0.0010179639793932438\n",
      "epoch: 10 step: 1010, loss is 0.10824514180421829\n",
      "epoch: 10 step: 1011, loss is 5.450236130855046e-06\n",
      "epoch: 10 step: 1012, loss is 0.07105785608291626\n",
      "epoch: 10 step: 1013, loss is 0.0016975286416709423\n",
      "epoch: 10 step: 1014, loss is 0.0005584295722655952\n",
      "epoch: 10 step: 1015, loss is 0.0008148974739015102\n",
      "epoch: 10 step: 1016, loss is 1.5707160855527036e-05\n",
      "epoch: 10 step: 1017, loss is 6.391446368070319e-05\n",
      "epoch: 10 step: 1018, loss is 9.398612746736035e-05\n",
      "epoch: 10 step: 1019, loss is 0.0001364864583592862\n",
      "epoch: 10 step: 1020, loss is 0.07786556333303452\n",
      "epoch: 10 step: 1021, loss is 0.0017764228396117687\n",
      "epoch: 10 step: 1022, loss is 0.03990626707673073\n",
      "epoch: 10 step: 1023, loss is 2.3372505893348716e-05\n",
      "epoch: 10 step: 1024, loss is 0.00046902697067707777\n",
      "epoch: 10 step: 1025, loss is 0.10167843103408813\n",
      "epoch: 10 step: 1026, loss is 2.6430381694808602e-05\n",
      "epoch: 10 step: 1027, loss is 0.0007064082310535014\n",
      "epoch: 10 step: 1028, loss is 0.0004781642637681216\n",
      "epoch: 10 step: 1029, loss is 0.0015113957924768329\n",
      "epoch: 10 step: 1030, loss is 0.00496888579800725\n",
      "epoch: 10 step: 1031, loss is 0.0029688943177461624\n",
      "epoch: 10 step: 1032, loss is 0.19328679144382477\n",
      "epoch: 10 step: 1033, loss is 1.875155976449605e-05\n",
      "epoch: 10 step: 1034, loss is 8.022162364795804e-05\n",
      "epoch: 10 step: 1035, loss is 0.0002717664756346494\n",
      "epoch: 10 step: 1036, loss is 0.010495330207049847\n",
      "epoch: 10 step: 1037, loss is 0.0014547428581863642\n",
      "epoch: 10 step: 1038, loss is 0.02862977609038353\n",
      "epoch: 10 step: 1039, loss is 0.03480125591158867\n",
      "epoch: 10 step: 1040, loss is 1.9070688722422346e-05\n",
      "epoch: 10 step: 1041, loss is 0.006607959046959877\n",
      "epoch: 10 step: 1042, loss is 0.011089613661170006\n",
      "epoch: 10 step: 1043, loss is 0.0647154450416565\n",
      "epoch: 10 step: 1044, loss is 0.0008131162030622363\n",
      "epoch: 10 step: 1045, loss is 0.0022748929914087057\n",
      "epoch: 10 step: 1046, loss is 0.0001766821078490466\n",
      "epoch: 10 step: 1047, loss is 0.000377264223061502\n",
      "epoch: 10 step: 1048, loss is 0.0010010343976318836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1049, loss is 0.10969392210245132\n",
      "epoch: 10 step: 1050, loss is 0.0007235197117552161\n",
      "epoch: 10 step: 1051, loss is 0.0005572580266743898\n",
      "epoch: 10 step: 1052, loss is 0.01153044868260622\n",
      "epoch: 10 step: 1053, loss is 0.0680682584643364\n",
      "epoch: 10 step: 1054, loss is 0.004924796521663666\n",
      "epoch: 10 step: 1055, loss is 0.022043976932764053\n",
      "epoch: 10 step: 1056, loss is 0.03468145802617073\n",
      "epoch: 10 step: 1057, loss is 0.02840454690158367\n",
      "epoch: 10 step: 1058, loss is 0.02420753799378872\n",
      "epoch: 10 step: 1059, loss is 0.0002879386011045426\n",
      "epoch: 10 step: 1060, loss is 0.21812160313129425\n",
      "epoch: 10 step: 1061, loss is 8.855434316501487e-06\n",
      "epoch: 10 step: 1062, loss is 0.011088079772889614\n",
      "epoch: 10 step: 1063, loss is 0.0006230014842003584\n",
      "epoch: 10 step: 1064, loss is 0.0004975590854883194\n",
      "epoch: 10 step: 1065, loss is 0.02391458861529827\n",
      "epoch: 10 step: 1066, loss is 0.0027042091824114323\n",
      "epoch: 10 step: 1067, loss is 0.002325627254322171\n",
      "epoch: 10 step: 1068, loss is 0.06197189912199974\n",
      "epoch: 10 step: 1069, loss is 0.06168191879987717\n",
      "epoch: 10 step: 1070, loss is 0.0011431029997766018\n",
      "epoch: 10 step: 1071, loss is 0.08060596883296967\n",
      "epoch: 10 step: 1072, loss is 0.03633034974336624\n",
      "epoch: 10 step: 1073, loss is 0.0063506243750452995\n",
      "epoch: 10 step: 1074, loss is 0.0014135631499812007\n",
      "epoch: 10 step: 1075, loss is 0.004754981957376003\n",
      "epoch: 10 step: 1076, loss is 0.005443425849080086\n",
      "epoch: 10 step: 1077, loss is 0.00019435871217865497\n",
      "epoch: 10 step: 1078, loss is 0.00028753135120496154\n",
      "epoch: 10 step: 1079, loss is 6.346695590764284e-05\n",
      "epoch: 10 step: 1080, loss is 0.0008258933085016906\n",
      "epoch: 10 step: 1081, loss is 0.00010727976768976077\n",
      "epoch: 10 step: 1082, loss is 0.01226518303155899\n",
      "epoch: 10 step: 1083, loss is 0.016902072355151176\n",
      "epoch: 10 step: 1084, loss is 0.22677971422672272\n",
      "epoch: 10 step: 1085, loss is 0.0004934176104143262\n",
      "epoch: 10 step: 1086, loss is 7.407514203805476e-05\n",
      "epoch: 10 step: 1087, loss is 0.0040947855450212955\n",
      "epoch: 10 step: 1088, loss is 0.0003572024579625577\n",
      "epoch: 10 step: 1089, loss is 0.002687104046344757\n",
      "epoch: 10 step: 1090, loss is 0.051525410264730453\n",
      "epoch: 10 step: 1091, loss is 0.00039301946526393294\n",
      "epoch: 10 step: 1092, loss is 0.0031942485366016626\n",
      "epoch: 10 step: 1093, loss is 0.0004883522051386535\n",
      "epoch: 10 step: 1094, loss is 0.0002032379270531237\n",
      "epoch: 10 step: 1095, loss is 0.0031059239991009235\n",
      "epoch: 10 step: 1096, loss is 0.007532364688813686\n",
      "epoch: 10 step: 1097, loss is 0.017640771344304085\n",
      "epoch: 10 step: 1098, loss is 0.013904466293752193\n",
      "epoch: 10 step: 1099, loss is 0.014309200458228588\n",
      "epoch: 10 step: 1100, loss is 0.0005839779623784125\n",
      "epoch: 10 step: 1101, loss is 0.00010462837235536426\n",
      "epoch: 10 step: 1102, loss is 0.018581535667181015\n",
      "epoch: 10 step: 1103, loss is 0.0027084876783192158\n",
      "epoch: 10 step: 1104, loss is 0.00010748295608209446\n",
      "epoch: 10 step: 1105, loss is 0.013106973841786385\n",
      "epoch: 10 step: 1106, loss is 8.378548045584466e-06\n",
      "epoch: 10 step: 1107, loss is 0.0005488556926138699\n",
      "epoch: 10 step: 1108, loss is 0.00015941853052936494\n",
      "epoch: 10 step: 1109, loss is 0.007230232935398817\n",
      "epoch: 10 step: 1110, loss is 4.688032640842721e-05\n",
      "epoch: 10 step: 1111, loss is 2.657551522133872e-05\n",
      "epoch: 10 step: 1112, loss is 0.013657988049089909\n",
      "epoch: 10 step: 1113, loss is 0.0016422206535935402\n",
      "epoch: 10 step: 1114, loss is 0.0005299224285408854\n",
      "epoch: 10 step: 1115, loss is 0.051838044077157974\n",
      "epoch: 10 step: 1116, loss is 0.017925212159752846\n",
      "epoch: 10 step: 1117, loss is 0.015165436081588268\n",
      "epoch: 10 step: 1118, loss is 0.0005999548593536019\n",
      "epoch: 10 step: 1119, loss is 0.004895630292594433\n",
      "epoch: 10 step: 1120, loss is 0.013057507574558258\n",
      "epoch: 10 step: 1121, loss is 2.3328788302023895e-05\n",
      "epoch: 10 step: 1122, loss is 0.0014926977455615997\n",
      "epoch: 10 step: 1123, loss is 0.02978554554283619\n",
      "epoch: 10 step: 1124, loss is 5.8592653658706695e-05\n",
      "epoch: 10 step: 1125, loss is 0.0001944040704984218\n",
      "epoch: 10 step: 1126, loss is 0.0006473196553997695\n",
      "epoch: 10 step: 1127, loss is 0.004021218977868557\n",
      "epoch: 10 step: 1128, loss is 7.546997221652418e-05\n",
      "epoch: 10 step: 1129, loss is 0.004936781246215105\n",
      "epoch: 10 step: 1130, loss is 0.005973829887807369\n",
      "epoch: 10 step: 1131, loss is 0.0002413188194623217\n",
      "epoch: 10 step: 1132, loss is 0.00047121598618105054\n",
      "epoch: 10 step: 1133, loss is 0.0013658079551532865\n",
      "epoch: 10 step: 1134, loss is 0.0002255777653772384\n",
      "epoch: 10 step: 1135, loss is 0.00035053250030614436\n",
      "epoch: 10 step: 1136, loss is 9.591019625077024e-05\n",
      "epoch: 10 step: 1137, loss is 0.000208631856366992\n",
      "epoch: 10 step: 1138, loss is 0.0009430642821826041\n",
      "epoch: 10 step: 1139, loss is 0.00019249218166805804\n",
      "epoch: 10 step: 1140, loss is 0.0790531188249588\n",
      "epoch: 10 step: 1141, loss is 0.030247148126363754\n",
      "epoch: 10 step: 1142, loss is 0.0012757796794176102\n",
      "epoch: 10 step: 1143, loss is 0.016417186707258224\n",
      "epoch: 10 step: 1144, loss is 0.00044949937728233635\n",
      "epoch: 10 step: 1145, loss is 0.00016694405348971486\n",
      "epoch: 10 step: 1146, loss is 0.013183465227484703\n",
      "epoch: 10 step: 1147, loss is 7.1266367740463465e-06\n",
      "epoch: 10 step: 1148, loss is 0.11379393935203552\n",
      "epoch: 10 step: 1149, loss is 0.005937774665653706\n",
      "epoch: 10 step: 1150, loss is 0.0029750228859484196\n",
      "epoch: 10 step: 1151, loss is 0.02019045688211918\n",
      "epoch: 10 step: 1152, loss is 0.00013619023957289755\n",
      "epoch: 10 step: 1153, loss is 0.0002521146088838577\n",
      "epoch: 10 step: 1154, loss is 1.0449904948472977e-05\n",
      "epoch: 10 step: 1155, loss is 0.0021903221495449543\n",
      "epoch: 10 step: 1156, loss is 0.0019558838102966547\n",
      "epoch: 10 step: 1157, loss is 0.00011758889013435692\n",
      "epoch: 10 step: 1158, loss is 0.12144786864519119\n",
      "epoch: 10 step: 1159, loss is 5.430742749013007e-05\n",
      "epoch: 10 step: 1160, loss is 0.043845802545547485\n",
      "epoch: 10 step: 1161, loss is 0.0016726866597309709\n",
      "epoch: 10 step: 1162, loss is 0.006070660427212715\n",
      "epoch: 10 step: 1163, loss is 0.0006424775347113609\n",
      "epoch: 10 step: 1164, loss is 0.002401202218607068\n",
      "epoch: 10 step: 1165, loss is 5.544393934542313e-05\n",
      "epoch: 10 step: 1166, loss is 0.00011446897406131029\n",
      "epoch: 10 step: 1167, loss is 0.009667610749602318\n",
      "epoch: 10 step: 1168, loss is 0.0001021005300572142\n",
      "epoch: 10 step: 1169, loss is 0.005514376796782017\n",
      "epoch: 10 step: 1170, loss is 0.0007736116531305015\n",
      "epoch: 10 step: 1171, loss is 0.01450332161039114\n",
      "epoch: 10 step: 1172, loss is 3.571168417693116e-05\n",
      "epoch: 10 step: 1173, loss is 0.0004761441086884588\n",
      "epoch: 10 step: 1174, loss is 0.03970637544989586\n",
      "epoch: 10 step: 1175, loss is 0.003908404149115086\n",
      "epoch: 10 step: 1176, loss is 0.00255223480053246\n",
      "epoch: 10 step: 1177, loss is 0.00011519029794726521\n",
      "epoch: 10 step: 1178, loss is 7.1515234594699e-05\n",
      "epoch: 10 step: 1179, loss is 0.007485221605747938\n",
      "epoch: 10 step: 1180, loss is 0.002509176265448332\n",
      "epoch: 10 step: 1181, loss is 0.0006141571793705225\n",
      "epoch: 10 step: 1182, loss is 0.019691547378897667\n",
      "epoch: 10 step: 1183, loss is 8.491403423249722e-05\n",
      "epoch: 10 step: 1184, loss is 0.0005974494270049036\n",
      "epoch: 10 step: 1185, loss is 0.0003776188241317868\n",
      "epoch: 10 step: 1186, loss is 0.0002500051923561841\n",
      "epoch: 10 step: 1187, loss is 0.00037662251270376146\n",
      "epoch: 10 step: 1188, loss is 0.034736718982458115\n",
      "epoch: 10 step: 1189, loss is 0.0013643632410094142\n",
      "epoch: 10 step: 1190, loss is 0.0015474045649170876\n",
      "epoch: 10 step: 1191, loss is 7.04050762578845e-05\n",
      "epoch: 10 step: 1192, loss is 0.0037189151626080275\n",
      "epoch: 10 step: 1193, loss is 0.00010110539733432233\n",
      "epoch: 10 step: 1194, loss is 0.0028805197216570377\n",
      "epoch: 10 step: 1195, loss is 3.5655320971272886e-05\n",
      "epoch: 10 step: 1196, loss is 0.00011734729196177796\n",
      "epoch: 10 step: 1197, loss is 0.001858821022324264\n",
      "epoch: 10 step: 1198, loss is 0.03160787746310234\n",
      "epoch: 10 step: 1199, loss is 6.357301026582718e-05\n",
      "epoch: 10 step: 1200, loss is 7.258768891915679e-05\n",
      "epoch: 10 step: 1201, loss is 0.029820235446095467\n",
      "epoch: 10 step: 1202, loss is 0.0006639872444793582\n",
      "epoch: 10 step: 1203, loss is 0.0033787309657782316\n",
      "epoch: 10 step: 1204, loss is 4.313996214477811e-06\n",
      "epoch: 10 step: 1205, loss is 9.615599265089259e-05\n",
      "epoch: 10 step: 1206, loss is 0.0017669547814875841\n",
      "epoch: 10 step: 1207, loss is 7.385200296994299e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1208, loss is 6.6225795308128e-05\n",
      "epoch: 10 step: 1209, loss is 0.00491706607863307\n",
      "epoch: 10 step: 1210, loss is 0.003535084193572402\n",
      "epoch: 10 step: 1211, loss is 0.0011875084601342678\n",
      "epoch: 10 step: 1212, loss is 0.015207411721348763\n",
      "epoch: 10 step: 1213, loss is 0.0027520067524164915\n",
      "epoch: 10 step: 1214, loss is 2.331384166609496e-05\n",
      "epoch: 10 step: 1215, loss is 0.024176474660634995\n",
      "epoch: 10 step: 1216, loss is 0.011123891919851303\n",
      "epoch: 10 step: 1217, loss is 0.019116198644042015\n",
      "epoch: 10 step: 1218, loss is 0.003445891197770834\n",
      "epoch: 10 step: 1219, loss is 0.008663669228553772\n",
      "epoch: 10 step: 1220, loss is 0.007500713225454092\n",
      "epoch: 10 step: 1221, loss is 0.012926178053021431\n",
      "epoch: 10 step: 1222, loss is 7.735580584267154e-05\n",
      "epoch: 10 step: 1223, loss is 0.0009412862709723413\n",
      "epoch: 10 step: 1224, loss is 1.3324181963980664e-05\n",
      "epoch: 10 step: 1225, loss is 2.8743839720846154e-05\n",
      "epoch: 10 step: 1226, loss is 0.050329916179180145\n",
      "epoch: 10 step: 1227, loss is 0.007513826712965965\n",
      "epoch: 10 step: 1228, loss is 6.741394827258773e-06\n",
      "epoch: 10 step: 1229, loss is 2.0340237369964598e-06\n",
      "epoch: 10 step: 1230, loss is 0.0008176035480573773\n",
      "epoch: 10 step: 1231, loss is 0.00026691326638683677\n",
      "epoch: 10 step: 1232, loss is 0.0008785813115537167\n",
      "epoch: 10 step: 1233, loss is 0.00014908348384778947\n",
      "epoch: 10 step: 1234, loss is 0.009895379655063152\n",
      "epoch: 10 step: 1235, loss is 0.00013255540397949517\n",
      "epoch: 10 step: 1236, loss is 0.0001532723690615967\n",
      "epoch: 10 step: 1237, loss is 0.025875717401504517\n",
      "epoch: 10 step: 1238, loss is 6.890390795888379e-05\n",
      "epoch: 10 step: 1239, loss is 0.0009218741906806827\n",
      "epoch: 10 step: 1240, loss is 0.0001678246189840138\n",
      "epoch: 10 step: 1241, loss is 2.5101693609030917e-05\n",
      "epoch: 10 step: 1242, loss is 0.0005663480842486024\n",
      "epoch: 10 step: 1243, loss is 0.00028809005743823946\n",
      "epoch: 10 step: 1244, loss is 0.00014496674702968448\n",
      "epoch: 10 step: 1245, loss is 0.03409566730260849\n",
      "epoch: 10 step: 1246, loss is 0.0832175686955452\n",
      "epoch: 10 step: 1247, loss is 8.99906808626838e-06\n",
      "epoch: 10 step: 1248, loss is 1.6093433714559069e-06\n",
      "epoch: 10 step: 1249, loss is 0.00011194733087904751\n",
      "epoch: 10 step: 1250, loss is 0.08255007863044739\n",
      "epoch: 10 step: 1251, loss is 7.387561709037982e-06\n",
      "epoch: 10 step: 1252, loss is 0.00010107438720297068\n",
      "epoch: 10 step: 1253, loss is 7.665316843485925e-06\n",
      "epoch: 10 step: 1254, loss is 0.007884264923632145\n",
      "epoch: 10 step: 1255, loss is 0.00799578707665205\n",
      "epoch: 10 step: 1256, loss is 0.0007160863024182618\n",
      "epoch: 10 step: 1257, loss is 0.1567590981721878\n",
      "epoch: 10 step: 1258, loss is 7.244209700729698e-05\n",
      "epoch: 10 step: 1259, loss is 0.13602498173713684\n",
      "epoch: 10 step: 1260, loss is 0.0007743420428596437\n",
      "epoch: 10 step: 1261, loss is 0.0038883250672370195\n",
      "epoch: 10 step: 1262, loss is 0.008050267584621906\n",
      "epoch: 10 step: 1263, loss is 0.0008364699315279722\n",
      "epoch: 10 step: 1264, loss is 0.003152853576466441\n",
      "epoch: 10 step: 1265, loss is 4.8259160394081846e-05\n",
      "epoch: 10 step: 1266, loss is 0.0010157416108995676\n",
      "epoch: 10 step: 1267, loss is 0.0007277987897396088\n",
      "epoch: 10 step: 1268, loss is 4.190137406112626e-05\n",
      "epoch: 10 step: 1269, loss is 0.0005597815033979714\n",
      "epoch: 10 step: 1270, loss is 0.003569019492715597\n",
      "epoch: 10 step: 1271, loss is 0.0016819508746266365\n",
      "epoch: 10 step: 1272, loss is 0.28095743060112\n",
      "epoch: 10 step: 1273, loss is 0.0025764501187950373\n",
      "epoch: 10 step: 1274, loss is 0.0018408478936180472\n",
      "epoch: 10 step: 1275, loss is 0.07504037767648697\n",
      "epoch: 10 step: 1276, loss is 9.720722300698981e-05\n",
      "epoch: 10 step: 1277, loss is 0.00023731229885015637\n",
      "epoch: 10 step: 1278, loss is 0.0013503460213541985\n",
      "epoch: 10 step: 1279, loss is 0.001179325394332409\n",
      "epoch: 10 step: 1280, loss is 0.008501187898218632\n",
      "epoch: 10 step: 1281, loss is 1.9422168406890705e-05\n",
      "epoch: 10 step: 1282, loss is 0.00038190363557077944\n",
      "epoch: 10 step: 1283, loss is 4.0322443965123966e-05\n",
      "epoch: 10 step: 1284, loss is 0.001752148033119738\n",
      "epoch: 10 step: 1285, loss is 4.3096504668937996e-05\n",
      "epoch: 10 step: 1286, loss is 0.013762760907411575\n",
      "epoch: 10 step: 1287, loss is 0.0019205338321626186\n",
      "epoch: 10 step: 1288, loss is 0.0008897773222997785\n",
      "epoch: 10 step: 1289, loss is 0.0014214377151802182\n",
      "epoch: 10 step: 1290, loss is 0.005012382287532091\n",
      "epoch: 10 step: 1291, loss is 5.721033085137606e-05\n",
      "epoch: 10 step: 1292, loss is 0.0006272458704188466\n",
      "epoch: 10 step: 1293, loss is 0.0018910829676315188\n",
      "epoch: 10 step: 1294, loss is 0.002866622991859913\n",
      "epoch: 10 step: 1295, loss is 0.0005222390755079687\n",
      "epoch: 10 step: 1296, loss is 0.00019602464453782886\n",
      "epoch: 10 step: 1297, loss is 0.0032776270527392626\n",
      "epoch: 10 step: 1298, loss is 0.02888006903231144\n",
      "epoch: 10 step: 1299, loss is 0.0024830601178109646\n",
      "epoch: 10 step: 1300, loss is 0.00859204400330782\n",
      "epoch: 10 step: 1301, loss is 0.005594860762357712\n",
      "epoch: 10 step: 1302, loss is 0.0027454884257167578\n",
      "epoch: 10 step: 1303, loss is 7.044161611702293e-05\n",
      "epoch: 10 step: 1304, loss is 0.0002705650113057345\n",
      "epoch: 10 step: 1305, loss is 4.642163548851386e-05\n",
      "epoch: 10 step: 1306, loss is 0.018262920901179314\n",
      "epoch: 10 step: 1307, loss is 0.02207723632454872\n",
      "epoch: 10 step: 1308, loss is 0.00031205109553411603\n",
      "epoch: 10 step: 1309, loss is 0.0013677437091246247\n",
      "epoch: 10 step: 1310, loss is 0.0002591513912193477\n",
      "epoch: 10 step: 1311, loss is 0.011157050728797913\n",
      "epoch: 10 step: 1312, loss is 0.00013522592780645937\n",
      "epoch: 10 step: 1313, loss is 2.2579453798243776e-05\n",
      "epoch: 10 step: 1314, loss is 9.423879237147048e-05\n",
      "epoch: 10 step: 1315, loss is 0.017848916351795197\n",
      "epoch: 10 step: 1316, loss is 0.004874501843005419\n",
      "epoch: 10 step: 1317, loss is 0.0008351041469722986\n",
      "epoch: 10 step: 1318, loss is 6.651593139395118e-05\n",
      "epoch: 10 step: 1319, loss is 2.608683644211851e-05\n",
      "epoch: 10 step: 1320, loss is 0.0001805715583031997\n",
      "epoch: 10 step: 1321, loss is 0.0003158437320962548\n",
      "epoch: 10 step: 1322, loss is 0.00027327839052304626\n",
      "epoch: 10 step: 1323, loss is 0.00012894503015559167\n",
      "epoch: 10 step: 1324, loss is 2.5740750061231665e-05\n",
      "epoch: 10 step: 1325, loss is 0.024693796411156654\n",
      "epoch: 10 step: 1326, loss is 0.0017810227582231164\n",
      "epoch: 10 step: 1327, loss is 0.000792773615103215\n",
      "epoch: 10 step: 1328, loss is 2.9613009246531874e-05\n",
      "epoch: 10 step: 1329, loss is 1.5270943549694493e-05\n",
      "epoch: 10 step: 1330, loss is 0.0013045505620539188\n",
      "epoch: 10 step: 1331, loss is 0.00015840354899410158\n",
      "epoch: 10 step: 1332, loss is 0.0031996467150747776\n",
      "epoch: 10 step: 1333, loss is 0.000692053057719022\n",
      "epoch: 10 step: 1334, loss is 0.0019247772870585322\n",
      "epoch: 10 step: 1335, loss is 0.0004912381991744041\n",
      "epoch: 10 step: 1336, loss is 0.0021448677871376276\n",
      "epoch: 10 step: 1337, loss is 0.006643026601523161\n",
      "epoch: 10 step: 1338, loss is 0.12901140749454498\n",
      "epoch: 10 step: 1339, loss is 0.004735929425805807\n",
      "epoch: 10 step: 1340, loss is 0.0023748839739710093\n",
      "epoch: 10 step: 1341, loss is 0.008814235217869282\n",
      "epoch: 10 step: 1342, loss is 0.0025819202419370413\n",
      "epoch: 10 step: 1343, loss is 0.0011354215675964952\n",
      "epoch: 10 step: 1344, loss is 0.0005976626998744905\n",
      "epoch: 10 step: 1345, loss is 0.002214249921962619\n",
      "epoch: 10 step: 1346, loss is 0.01810692809522152\n",
      "epoch: 10 step: 1347, loss is 0.0008490084437653422\n",
      "epoch: 10 step: 1348, loss is 0.007572379894554615\n",
      "epoch: 10 step: 1349, loss is 8.762334618950263e-05\n",
      "epoch: 10 step: 1350, loss is 0.0016409722156822681\n",
      "epoch: 10 step: 1351, loss is 0.0010041426867246628\n",
      "epoch: 10 step: 1352, loss is 0.0005221884930506349\n",
      "epoch: 10 step: 1353, loss is 6.512483378173783e-05\n",
      "epoch: 10 step: 1354, loss is 0.008886704221367836\n",
      "epoch: 10 step: 1355, loss is 0.0006924016634002328\n",
      "epoch: 10 step: 1356, loss is 0.0018012977670878172\n",
      "epoch: 10 step: 1357, loss is 0.0002759911585599184\n",
      "epoch: 10 step: 1358, loss is 0.00032709940569475293\n",
      "epoch: 10 step: 1359, loss is 0.022604167461395264\n",
      "epoch: 10 step: 1360, loss is 0.0069855279289186\n",
      "epoch: 10 step: 1361, loss is 0.001050640014000237\n",
      "epoch: 10 step: 1362, loss is 1.2839203918701969e-05\n",
      "epoch: 10 step: 1363, loss is 0.010378565639257431\n",
      "epoch: 10 step: 1364, loss is 0.00011880796955665573\n",
      "epoch: 10 step: 1365, loss is 0.019590415060520172\n",
      "epoch: 10 step: 1366, loss is 0.057403214275836945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1367, loss is 4.9702390242600814e-05\n",
      "epoch: 10 step: 1368, loss is 1.5690504369558766e-05\n",
      "epoch: 10 step: 1369, loss is 0.0009788982570171356\n",
      "epoch: 10 step: 1370, loss is 6.788974133087322e-05\n",
      "epoch: 10 step: 1371, loss is 6.6535326368466485e-06\n",
      "epoch: 10 step: 1372, loss is 0.0004239005211275071\n",
      "epoch: 10 step: 1373, loss is 8.62666274770163e-06\n",
      "epoch: 10 step: 1374, loss is 0.00019878278544638306\n",
      "epoch: 10 step: 1375, loss is 0.00020712851255666465\n",
      "epoch: 10 step: 1376, loss is 0.0002265425428049639\n",
      "epoch: 10 step: 1377, loss is 0.0529501810669899\n",
      "epoch: 10 step: 1378, loss is 3.479249789961614e-05\n",
      "epoch: 10 step: 1379, loss is 0.0015939070144668221\n",
      "epoch: 10 step: 1380, loss is 1.3430188118945807e-05\n",
      "epoch: 10 step: 1381, loss is 0.0003208088455721736\n",
      "epoch: 10 step: 1382, loss is 2.0681132809841074e-05\n",
      "epoch: 10 step: 1383, loss is 0.00023803900694474578\n",
      "epoch: 10 step: 1384, loss is 0.0007078100461512804\n",
      "epoch: 10 step: 1385, loss is 0.00016332608356606215\n",
      "epoch: 10 step: 1386, loss is 0.005051241721957922\n",
      "epoch: 10 step: 1387, loss is 0.03401385247707367\n",
      "epoch: 10 step: 1388, loss is 0.009207085706293583\n",
      "epoch: 10 step: 1389, loss is 0.0015570319956168532\n",
      "epoch: 10 step: 1390, loss is 0.003431136254221201\n",
      "epoch: 10 step: 1391, loss is 0.00361144682392478\n",
      "epoch: 10 step: 1392, loss is 6.314546226349194e-06\n",
      "epoch: 10 step: 1393, loss is 0.00015810009790584445\n",
      "epoch: 10 step: 1394, loss is 0.0016188231529667974\n",
      "epoch: 10 step: 1395, loss is 0.0007432708516716957\n",
      "epoch: 10 step: 1396, loss is 0.00014446025306824595\n",
      "epoch: 10 step: 1397, loss is 0.0003542961203493178\n",
      "epoch: 10 step: 1398, loss is 0.04705182835459709\n",
      "epoch: 10 step: 1399, loss is 0.08034399151802063\n",
      "epoch: 10 step: 1400, loss is 0.0027808123268187046\n",
      "epoch: 10 step: 1401, loss is 0.006634783465415239\n",
      "epoch: 10 step: 1402, loss is 7.082028332661139e-06\n",
      "epoch: 10 step: 1403, loss is 0.014699991792440414\n",
      "epoch: 10 step: 1404, loss is 0.004096871241927147\n",
      "epoch: 10 step: 1405, loss is 0.003050665371119976\n",
      "epoch: 10 step: 1406, loss is 2.7723675884772092e-05\n",
      "epoch: 10 step: 1407, loss is 0.0002505438751541078\n",
      "epoch: 10 step: 1408, loss is 0.001883133314549923\n",
      "epoch: 10 step: 1409, loss is 0.00013257133832667023\n",
      "epoch: 10 step: 1410, loss is 0.09875089675188065\n",
      "epoch: 10 step: 1411, loss is 0.004785039462149143\n",
      "epoch: 10 step: 1412, loss is 0.010605956427752972\n",
      "epoch: 10 step: 1413, loss is 0.008729130029678345\n",
      "epoch: 10 step: 1414, loss is 0.01571262814104557\n",
      "epoch: 10 step: 1415, loss is 0.002071811817586422\n",
      "epoch: 10 step: 1416, loss is 0.0001732692908262834\n",
      "epoch: 10 step: 1417, loss is 0.0006255778134800494\n",
      "epoch: 10 step: 1418, loss is 4.218639514874667e-05\n",
      "epoch: 10 step: 1419, loss is 0.00010132860188605264\n",
      "epoch: 10 step: 1420, loss is 7.478461338905618e-05\n",
      "epoch: 10 step: 1421, loss is 0.003521307371556759\n",
      "epoch: 10 step: 1422, loss is 0.07100223004817963\n",
      "epoch: 10 step: 1423, loss is 4.1501207306282595e-06\n",
      "epoch: 10 step: 1424, loss is 0.00010508575360290706\n",
      "epoch: 10 step: 1425, loss is 0.0013566665584221482\n",
      "epoch: 10 step: 1426, loss is 7.904678204795346e-05\n",
      "epoch: 10 step: 1427, loss is 8.519332186551765e-05\n",
      "epoch: 10 step: 1428, loss is 0.0014104024739935994\n",
      "epoch: 10 step: 1429, loss is 0.023559458553791046\n",
      "epoch: 10 step: 1430, loss is 4.659637852455489e-05\n",
      "epoch: 10 step: 1431, loss is 0.07884698361158371\n",
      "epoch: 10 step: 1432, loss is 0.007915861904621124\n",
      "epoch: 10 step: 1433, loss is 0.029515929520130157\n",
      "epoch: 10 step: 1434, loss is 0.0004157188523095101\n",
      "epoch: 10 step: 1435, loss is 0.0008105478482320905\n",
      "epoch: 10 step: 1436, loss is 6.994587602093816e-05\n",
      "epoch: 10 step: 1437, loss is 0.0009383535943925381\n",
      "epoch: 10 step: 1438, loss is 0.03759974241256714\n",
      "epoch: 10 step: 1439, loss is 4.699097917182371e-05\n",
      "epoch: 10 step: 1440, loss is 0.003523849416524172\n",
      "epoch: 10 step: 1441, loss is 0.0008331267163157463\n",
      "epoch: 10 step: 1442, loss is 2.1346204448491335e-06\n",
      "epoch: 10 step: 1443, loss is 5.7259449022240005e-06\n",
      "epoch: 10 step: 1444, loss is 0.00023226179473567754\n",
      "epoch: 10 step: 1445, loss is 7.146662392187864e-05\n",
      "epoch: 10 step: 1446, loss is 0.0018384017748758197\n",
      "epoch: 10 step: 1447, loss is 0.004965055268257856\n",
      "epoch: 10 step: 1448, loss is 0.010257352143526077\n",
      "epoch: 10 step: 1449, loss is 0.020469117909669876\n",
      "epoch: 10 step: 1450, loss is 9.193192090606317e-05\n",
      "epoch: 10 step: 1451, loss is 2.5863631890388206e-05\n",
      "epoch: 10 step: 1452, loss is 0.011376198381185532\n",
      "epoch: 10 step: 1453, loss is 8.103789150482044e-05\n",
      "epoch: 10 step: 1454, loss is 0.00023583599249832332\n",
      "epoch: 10 step: 1455, loss is 0.18450742959976196\n",
      "epoch: 10 step: 1456, loss is 6.542021765199024e-06\n",
      "epoch: 10 step: 1457, loss is 1.613355561858043e-05\n",
      "epoch: 10 step: 1458, loss is 0.000311731273541227\n",
      "epoch: 10 step: 1459, loss is 0.001141812070272863\n",
      "epoch: 10 step: 1460, loss is 6.593943453481188e-06\n",
      "epoch: 10 step: 1461, loss is 0.0016331890365108848\n",
      "epoch: 10 step: 1462, loss is 0.01989789679646492\n",
      "epoch: 10 step: 1463, loss is 0.00018472844385541975\n",
      "epoch: 10 step: 1464, loss is 0.0023524214047938585\n",
      "epoch: 10 step: 1465, loss is 0.00734091317281127\n",
      "epoch: 10 step: 1466, loss is 0.0014685670612379909\n",
      "epoch: 10 step: 1467, loss is 0.03754013776779175\n",
      "epoch: 10 step: 1468, loss is 0.025841882452368736\n",
      "epoch: 10 step: 1469, loss is 0.00018460875435266644\n",
      "epoch: 10 step: 1470, loss is 0.055757295340299606\n",
      "epoch: 10 step: 1471, loss is 0.0001476225588703528\n",
      "epoch: 10 step: 1472, loss is 0.06097061559557915\n",
      "epoch: 10 step: 1473, loss is 0.00045704757212661207\n",
      "epoch: 10 step: 1474, loss is 0.00026227813214063644\n",
      "epoch: 10 step: 1475, loss is 0.0013185564894229174\n",
      "epoch: 10 step: 1476, loss is 8.131394861266017e-05\n",
      "epoch: 10 step: 1477, loss is 0.002158745424821973\n",
      "epoch: 10 step: 1478, loss is 0.04641349986195564\n",
      "epoch: 10 step: 1479, loss is 0.0016884950455278158\n",
      "epoch: 10 step: 1480, loss is 0.0004543208924587816\n",
      "epoch: 10 step: 1481, loss is 0.00011328692198731005\n",
      "epoch: 10 step: 1482, loss is 0.0002344988752156496\n",
      "epoch: 10 step: 1483, loss is 0.0011365738464519382\n",
      "epoch: 10 step: 1484, loss is 0.11998098343610764\n",
      "epoch: 10 step: 1485, loss is 0.000842006818857044\n",
      "epoch: 10 step: 1486, loss is 1.079100911738351e-05\n",
      "epoch: 10 step: 1487, loss is 0.00015455632819794118\n",
      "epoch: 10 step: 1488, loss is 0.035641781985759735\n",
      "epoch: 10 step: 1489, loss is 0.15288986265659332\n",
      "epoch: 10 step: 1490, loss is 0.0008924009744077921\n",
      "epoch: 10 step: 1491, loss is 0.034922029823064804\n",
      "epoch: 10 step: 1492, loss is 0.000837935833260417\n",
      "epoch: 10 step: 1493, loss is 0.0058540282770991325\n",
      "epoch: 10 step: 1494, loss is 1.5250399883370847e-05\n",
      "epoch: 10 step: 1495, loss is 0.0027099577710032463\n",
      "epoch: 10 step: 1496, loss is 0.0017367781838402152\n",
      "epoch: 10 step: 1497, loss is 0.06297298520803452\n",
      "epoch: 10 step: 1498, loss is 0.010710259899497032\n",
      "epoch: 10 step: 1499, loss is 0.004064925014972687\n",
      "epoch: 10 step: 1500, loss is 0.012599188834428787\n",
      "epoch: 10 step: 1501, loss is 0.00048036916996352375\n",
      "epoch: 10 step: 1502, loss is 0.0016301836585626006\n",
      "epoch: 10 step: 1503, loss is 0.002512401668354869\n",
      "epoch: 10 step: 1504, loss is 0.04087107256054878\n",
      "epoch: 10 step: 1505, loss is 0.034019529819488525\n",
      "epoch: 10 step: 1506, loss is 0.0027459135744720697\n",
      "epoch: 10 step: 1507, loss is 0.015495102852582932\n",
      "epoch: 10 step: 1508, loss is 0.05650779977440834\n",
      "epoch: 10 step: 1509, loss is 0.00035142325214110315\n",
      "epoch: 10 step: 1510, loss is 0.014424820430576801\n",
      "epoch: 10 step: 1511, loss is 0.14499078691005707\n",
      "epoch: 10 step: 1512, loss is 0.0016408722149208188\n",
      "epoch: 10 step: 1513, loss is 0.0002782998781185597\n",
      "epoch: 10 step: 1514, loss is 0.0006297786603681743\n",
      "epoch: 10 step: 1515, loss is 0.00038674252573400736\n",
      "epoch: 10 step: 1516, loss is 0.00035338615998625755\n",
      "epoch: 10 step: 1517, loss is 0.03021307848393917\n",
      "epoch: 10 step: 1518, loss is 0.0035776756703853607\n",
      "epoch: 10 step: 1519, loss is 0.039793387055397034\n",
      "epoch: 10 step: 1520, loss is 1.543462167319376e-05\n",
      "epoch: 10 step: 1521, loss is 0.10961845517158508\n",
      "epoch: 10 step: 1522, loss is 0.0029177723918110132\n",
      "epoch: 10 step: 1523, loss is 0.007720936555415392\n",
      "epoch: 10 step: 1524, loss is 7.03366913512582e-06\n",
      "epoch: 10 step: 1525, loss is 0.026664117351174355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1526, loss is 0.0018480997532606125\n",
      "epoch: 10 step: 1527, loss is 0.0005540209240280092\n",
      "epoch: 10 step: 1528, loss is 7.551021553808823e-05\n",
      "epoch: 10 step: 1529, loss is 0.000921394384931773\n",
      "epoch: 10 step: 1530, loss is 0.0006311989272944629\n",
      "epoch: 10 step: 1531, loss is 0.006380179896950722\n",
      "epoch: 10 step: 1532, loss is 4.1798602978815325e-06\n",
      "epoch: 10 step: 1533, loss is 0.0011186552001163363\n",
      "epoch: 10 step: 1534, loss is 0.004282171837985516\n",
      "epoch: 10 step: 1535, loss is 0.0040906872600317\n",
      "epoch: 10 step: 1536, loss is 0.002552263904362917\n",
      "epoch: 10 step: 1537, loss is 3.29432004946284e-05\n",
      "epoch: 10 step: 1538, loss is 0.03056732378900051\n",
      "epoch: 10 step: 1539, loss is 0.0002201333554694429\n",
      "epoch: 10 step: 1540, loss is 0.03582657128572464\n",
      "epoch: 10 step: 1541, loss is 0.0013007521629333496\n",
      "epoch: 10 step: 1542, loss is 0.04475570097565651\n",
      "epoch: 10 step: 1543, loss is 0.003977889660745859\n",
      "epoch: 10 step: 1544, loss is 0.023372262716293335\n",
      "epoch: 10 step: 1545, loss is 0.006757483817636967\n",
      "epoch: 10 step: 1546, loss is 0.040218520909547806\n",
      "epoch: 10 step: 1547, loss is 0.0039553348906338215\n",
      "epoch: 10 step: 1548, loss is 0.0046033114194869995\n",
      "epoch: 10 step: 1549, loss is 0.0006183604709804058\n",
      "epoch: 10 step: 1550, loss is 0.10073135048151016\n",
      "epoch: 10 step: 1551, loss is 0.03255255147814751\n",
      "epoch: 10 step: 1552, loss is 0.00018203046056441963\n",
      "epoch: 10 step: 1553, loss is 1.9616807549027726e-05\n",
      "epoch: 10 step: 1554, loss is 0.003492372576147318\n",
      "epoch: 10 step: 1555, loss is 0.11585050821304321\n",
      "epoch: 10 step: 1556, loss is 5.0940467190230265e-05\n",
      "epoch: 10 step: 1557, loss is 0.0029556495137512684\n",
      "epoch: 10 step: 1558, loss is 0.0023019949439913034\n",
      "epoch: 10 step: 1559, loss is 0.00644377525895834\n",
      "epoch: 10 step: 1560, loss is 0.007257993333041668\n",
      "epoch: 10 step: 1561, loss is 0.0031902086921036243\n",
      "epoch: 10 step: 1562, loss is 0.000986319500952959\n",
      "epoch: 10 step: 1563, loss is 0.02136087976396084\n",
      "epoch: 10 step: 1564, loss is 0.00010032821592176333\n",
      "epoch: 10 step: 1565, loss is 0.003837097901850939\n",
      "epoch: 10 step: 1566, loss is 0.011956922709941864\n",
      "epoch: 10 step: 1567, loss is 0.001073057996109128\n",
      "epoch: 10 step: 1568, loss is 0.00022669996542390436\n",
      "epoch: 10 step: 1569, loss is 0.004632414318621159\n",
      "epoch: 10 step: 1570, loss is 0.00041797099402174354\n",
      "epoch: 10 step: 1571, loss is 0.007494810037314892\n",
      "epoch: 10 step: 1572, loss is 0.004371172282844782\n",
      "epoch: 10 step: 1573, loss is 0.0006391375791281462\n",
      "epoch: 10 step: 1574, loss is 0.00010597556683933362\n",
      "epoch: 10 step: 1575, loss is 0.0002992142690345645\n",
      "epoch: 10 step: 1576, loss is 0.001028887927532196\n",
      "epoch: 10 step: 1577, loss is 0.0025925685185939074\n",
      "epoch: 10 step: 1578, loss is 0.001209898036904633\n",
      "epoch: 10 step: 1579, loss is 1.7716656657285057e-05\n",
      "epoch: 10 step: 1580, loss is 0.006092978175729513\n",
      "epoch: 10 step: 1581, loss is 0.0031543495133519173\n",
      "epoch: 10 step: 1582, loss is 0.009900608099997044\n",
      "epoch: 10 step: 1583, loss is 4.938760685035959e-05\n",
      "epoch: 10 step: 1584, loss is 0.0002175608678953722\n",
      "epoch: 10 step: 1585, loss is 0.00040573306614533067\n",
      "epoch: 10 step: 1586, loss is 0.0002765588869806379\n",
      "epoch: 10 step: 1587, loss is 0.00022209624876268208\n",
      "epoch: 10 step: 1588, loss is 0.0005817816127091646\n",
      "epoch: 10 step: 1589, loss is 0.00035394064616411924\n",
      "epoch: 10 step: 1590, loss is 0.00017572674551047385\n",
      "epoch: 10 step: 1591, loss is 0.0001709020434645936\n",
      "epoch: 10 step: 1592, loss is 0.00042098393896594644\n",
      "epoch: 10 step: 1593, loss is 0.0015005494933575392\n",
      "epoch: 10 step: 1594, loss is 0.001455441932193935\n",
      "epoch: 10 step: 1595, loss is 1.0645748261595145e-05\n",
      "epoch: 10 step: 1596, loss is 0.000251665071118623\n",
      "epoch: 10 step: 1597, loss is 0.0017049935413524508\n",
      "epoch: 10 step: 1598, loss is 0.05066201463341713\n",
      "epoch: 10 step: 1599, loss is 0.0007293125381693244\n",
      "epoch: 10 step: 1600, loss is 0.021859921514987946\n",
      "epoch: 10 step: 1601, loss is 7.422637281706557e-05\n",
      "epoch: 10 step: 1602, loss is 0.002006607363000512\n",
      "epoch: 10 step: 1603, loss is 0.00016350855003111064\n",
      "epoch: 10 step: 1604, loss is 7.504771929234266e-05\n",
      "epoch: 10 step: 1605, loss is 0.00024080293951556087\n",
      "epoch: 10 step: 1606, loss is 0.006316084414720535\n",
      "epoch: 10 step: 1607, loss is 0.01438396330922842\n",
      "epoch: 10 step: 1608, loss is 9.812720236368477e-06\n",
      "epoch: 10 step: 1609, loss is 0.01470098551362753\n",
      "epoch: 10 step: 1610, loss is 0.004941792692989111\n",
      "epoch: 10 step: 1611, loss is 0.0025789018254727125\n",
      "epoch: 10 step: 1612, loss is 0.0019237780943512917\n",
      "epoch: 10 step: 1613, loss is 0.005423588678240776\n",
      "epoch: 10 step: 1614, loss is 0.05169173330068588\n",
      "epoch: 10 step: 1615, loss is 0.0014167539775371552\n",
      "epoch: 10 step: 1616, loss is 0.0002936176024377346\n",
      "epoch: 10 step: 1617, loss is 0.00010998499055858701\n",
      "epoch: 10 step: 1618, loss is 0.012856096029281616\n",
      "epoch: 10 step: 1619, loss is 0.004937135614454746\n",
      "epoch: 10 step: 1620, loss is 4.1590908949729055e-05\n",
      "epoch: 10 step: 1621, loss is 0.00010073345038108528\n",
      "epoch: 10 step: 1622, loss is 0.0008950430201366544\n",
      "epoch: 10 step: 1623, loss is 0.00015986200014594942\n",
      "epoch: 10 step: 1624, loss is 0.003858026349917054\n",
      "epoch: 10 step: 1625, loss is 5.39402462891303e-05\n",
      "epoch: 10 step: 1626, loss is 0.00023064242850523442\n",
      "epoch: 10 step: 1627, loss is 3.824667146545835e-05\n",
      "epoch: 10 step: 1628, loss is 0.0020242840982973576\n",
      "epoch: 10 step: 1629, loss is 0.00086375413229689\n",
      "epoch: 10 step: 1630, loss is 0.00014594077947549522\n",
      "epoch: 10 step: 1631, loss is 2.858841253328137e-05\n",
      "epoch: 10 step: 1632, loss is 0.011323751881718636\n",
      "epoch: 10 step: 1633, loss is 0.002707972889766097\n",
      "epoch: 10 step: 1634, loss is 0.028520172461867332\n",
      "epoch: 10 step: 1635, loss is 0.00040841291774995625\n",
      "epoch: 10 step: 1636, loss is 0.0005291952402330935\n",
      "epoch: 10 step: 1637, loss is 0.0010730233043432236\n",
      "epoch: 10 step: 1638, loss is 0.00027392510673962533\n",
      "epoch: 10 step: 1639, loss is 0.015372312627732754\n",
      "epoch: 10 step: 1640, loss is 0.00041935849003493786\n",
      "epoch: 10 step: 1641, loss is 0.00011606010957621038\n",
      "epoch: 10 step: 1642, loss is 0.009104009717702866\n",
      "epoch: 10 step: 1643, loss is 0.0004511081497184932\n",
      "epoch: 10 step: 1644, loss is 1.4617700799135491e-05\n",
      "epoch: 10 step: 1645, loss is 0.03607998788356781\n",
      "epoch: 10 step: 1646, loss is 0.0005958664696663618\n",
      "epoch: 10 step: 1647, loss is 7.080852810759097e-05\n",
      "epoch: 10 step: 1648, loss is 0.030340252444148064\n",
      "epoch: 10 step: 1649, loss is 0.0007096193148754537\n",
      "epoch: 10 step: 1650, loss is 0.0001611046609468758\n",
      "epoch: 10 step: 1651, loss is 0.005704479292035103\n",
      "epoch: 10 step: 1652, loss is 0.0072428034618496895\n",
      "epoch: 10 step: 1653, loss is 0.023697640746831894\n",
      "epoch: 10 step: 1654, loss is 1.7807849872042425e-05\n",
      "epoch: 10 step: 1655, loss is 2.4017677787924185e-05\n",
      "epoch: 10 step: 1656, loss is 0.00749698793515563\n",
      "epoch: 10 step: 1657, loss is 0.002227215562015772\n",
      "epoch: 10 step: 1658, loss is 0.007620641496032476\n",
      "epoch: 10 step: 1659, loss is 0.0016833876725286245\n",
      "epoch: 10 step: 1660, loss is 0.022326122969388962\n",
      "epoch: 10 step: 1661, loss is 0.002566513605415821\n",
      "epoch: 10 step: 1662, loss is 0.0090352026745677\n",
      "epoch: 10 step: 1663, loss is 0.00011788988194894046\n",
      "epoch: 10 step: 1664, loss is 0.0009414395317435265\n",
      "epoch: 10 step: 1665, loss is 0.03647357225418091\n",
      "epoch: 10 step: 1666, loss is 0.007307836320251226\n",
      "epoch: 10 step: 1667, loss is 0.002174453344196081\n",
      "epoch: 10 step: 1668, loss is 0.003405025927349925\n",
      "epoch: 10 step: 1669, loss is 0.008915579877793789\n",
      "epoch: 10 step: 1670, loss is 0.0018346280558034778\n",
      "epoch: 10 step: 1671, loss is 0.0003459181752987206\n",
      "epoch: 10 step: 1672, loss is 0.0024947593919932842\n",
      "epoch: 10 step: 1673, loss is 6.175191811053082e-05\n",
      "epoch: 10 step: 1674, loss is 0.0036383469123393297\n",
      "epoch: 10 step: 1675, loss is 0.006349740084260702\n",
      "epoch: 10 step: 1676, loss is 0.0002886597940232605\n",
      "epoch: 10 step: 1677, loss is 1.4009316146257333e-05\n",
      "epoch: 10 step: 1678, loss is 0.001114912680350244\n",
      "epoch: 10 step: 1679, loss is 0.0002722772187553346\n",
      "epoch: 10 step: 1680, loss is 0.00012994026474189013\n",
      "epoch: 10 step: 1681, loss is 0.00013147115532774478\n",
      "epoch: 10 step: 1682, loss is 1.1836813428089954e-05\n",
      "epoch: 10 step: 1683, loss is 0.00013814556587021798\n",
      "epoch: 10 step: 1684, loss is 0.00010496743198018521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1685, loss is 0.009120328351855278\n",
      "epoch: 10 step: 1686, loss is 0.005044459365308285\n",
      "epoch: 10 step: 1687, loss is 0.0010453993454575539\n",
      "epoch: 10 step: 1688, loss is 0.004105791449546814\n",
      "epoch: 10 step: 1689, loss is 0.00882199127227068\n",
      "epoch: 10 step: 1690, loss is 0.017083484679460526\n",
      "epoch: 10 step: 1691, loss is 0.0033216685988008976\n",
      "epoch: 10 step: 1692, loss is 5.947398312855512e-05\n",
      "epoch: 10 step: 1693, loss is 0.0006241402588784695\n",
      "epoch: 10 step: 1694, loss is 0.05653172358870506\n",
      "epoch: 10 step: 1695, loss is 0.0017816709587350488\n",
      "epoch: 10 step: 1696, loss is 3.236042175558396e-05\n",
      "epoch: 10 step: 1697, loss is 0.00017570974887348711\n",
      "epoch: 10 step: 1698, loss is 0.0011032960610464215\n",
      "epoch: 10 step: 1699, loss is 0.002448810264468193\n",
      "epoch: 10 step: 1700, loss is 0.00032032912713475525\n",
      "epoch: 10 step: 1701, loss is 0.050008077174425125\n",
      "epoch: 10 step: 1702, loss is 8.862834874889813e-06\n",
      "epoch: 10 step: 1703, loss is 0.0015646148240193725\n",
      "epoch: 10 step: 1704, loss is 0.005367508623749018\n",
      "epoch: 10 step: 1705, loss is 0.04373764246702194\n",
      "epoch: 10 step: 1706, loss is 0.001970346551388502\n",
      "epoch: 10 step: 1707, loss is 2.1986579668009654e-05\n",
      "epoch: 10 step: 1708, loss is 0.001430694479495287\n",
      "epoch: 10 step: 1709, loss is 0.00023638841230422258\n",
      "epoch: 10 step: 1710, loss is 0.04711531475186348\n",
      "epoch: 10 step: 1711, loss is 0.047315746545791626\n",
      "epoch: 10 step: 1712, loss is 0.00011177018313901499\n",
      "epoch: 10 step: 1713, loss is 8.919715764932334e-05\n",
      "epoch: 10 step: 1714, loss is 0.002132898662239313\n",
      "epoch: 10 step: 1715, loss is 0.0018075136467814445\n",
      "epoch: 10 step: 1716, loss is 0.002221806440502405\n",
      "epoch: 10 step: 1717, loss is 3.1147552363108844e-05\n",
      "epoch: 10 step: 1718, loss is 0.14894837141036987\n",
      "epoch: 10 step: 1719, loss is 0.0005673121777363122\n",
      "epoch: 10 step: 1720, loss is 0.0023325677029788494\n",
      "epoch: 10 step: 1721, loss is 0.00255820294842124\n",
      "epoch: 10 step: 1722, loss is 0.004499036818742752\n",
      "epoch: 10 step: 1723, loss is 0.001620705472305417\n",
      "epoch: 10 step: 1724, loss is 0.0011787170078605413\n",
      "epoch: 10 step: 1725, loss is 0.0002505119191482663\n",
      "epoch: 10 step: 1726, loss is 0.008047524839639664\n",
      "epoch: 10 step: 1727, loss is 0.00014953987556509674\n",
      "epoch: 10 step: 1728, loss is 0.00019301573047414422\n",
      "epoch: 10 step: 1729, loss is 0.00010408223897684366\n",
      "epoch: 10 step: 1730, loss is 0.11764681339263916\n",
      "epoch: 10 step: 1731, loss is 0.004038563929498196\n",
      "epoch: 10 step: 1732, loss is 0.008476120419800282\n",
      "epoch: 10 step: 1733, loss is 5.9335226978873834e-05\n",
      "epoch: 10 step: 1734, loss is 0.0034044065978378057\n",
      "epoch: 10 step: 1735, loss is 0.030948791652917862\n",
      "epoch: 10 step: 1736, loss is 2.5785877369344234e-05\n",
      "epoch: 10 step: 1737, loss is 0.001148938899859786\n",
      "epoch: 10 step: 1738, loss is 0.0018120213644579053\n",
      "epoch: 10 step: 1739, loss is 0.06670992821455002\n",
      "epoch: 10 step: 1740, loss is 7.103241659933701e-05\n",
      "epoch: 10 step: 1741, loss is 0.0004599102248903364\n",
      "epoch: 10 step: 1742, loss is 0.0002644567284733057\n",
      "epoch: 10 step: 1743, loss is 3.123663191217929e-05\n",
      "epoch: 10 step: 1744, loss is 0.0033019818365573883\n",
      "epoch: 10 step: 1745, loss is 7.525358796556247e-06\n",
      "epoch: 10 step: 1746, loss is 0.0002199511945946142\n",
      "epoch: 10 step: 1747, loss is 0.000264255068032071\n",
      "epoch: 10 step: 1748, loss is 0.00014874213957227767\n",
      "epoch: 10 step: 1749, loss is 0.002613415475934744\n",
      "epoch: 10 step: 1750, loss is 9.490557567914948e-05\n",
      "epoch: 10 step: 1751, loss is 0.00999237596988678\n",
      "epoch: 10 step: 1752, loss is 0.00039889771142043173\n",
      "epoch: 10 step: 1753, loss is 7.416391599690542e-05\n",
      "epoch: 10 step: 1754, loss is 0.2228410840034485\n",
      "epoch: 10 step: 1755, loss is 2.7369964300305583e-05\n",
      "epoch: 10 step: 1756, loss is 0.0019243640126660466\n",
      "epoch: 10 step: 1757, loss is 0.060054026544094086\n",
      "epoch: 10 step: 1758, loss is 0.013112422078847885\n",
      "epoch: 10 step: 1759, loss is 0.0035966774448752403\n",
      "epoch: 10 step: 1760, loss is 0.001794918323867023\n",
      "epoch: 10 step: 1761, loss is 0.02825959213078022\n",
      "epoch: 10 step: 1762, loss is 0.010226428508758545\n",
      "epoch: 10 step: 1763, loss is 0.014988155104219913\n",
      "epoch: 10 step: 1764, loss is 1.3638983546115924e-05\n",
      "epoch: 10 step: 1765, loss is 0.0017657794523984194\n",
      "epoch: 10 step: 1766, loss is 0.00010592644684948027\n",
      "epoch: 10 step: 1767, loss is 1.699057793302927e-05\n",
      "epoch: 10 step: 1768, loss is 0.001921791466884315\n",
      "epoch: 10 step: 1769, loss is 0.048741091042757034\n",
      "epoch: 10 step: 1770, loss is 0.00013239149120636284\n",
      "epoch: 10 step: 1771, loss is 0.00041147993761114776\n",
      "epoch: 10 step: 1772, loss is 0.03612210974097252\n",
      "epoch: 10 step: 1773, loss is 1.2270122169866227e-05\n",
      "epoch: 10 step: 1774, loss is 0.0697050616145134\n",
      "epoch: 10 step: 1775, loss is 3.073035986744799e-05\n",
      "epoch: 10 step: 1776, loss is 0.02132182940840721\n",
      "epoch: 10 step: 1777, loss is 0.0026936077047139406\n",
      "epoch: 10 step: 1778, loss is 0.003969546407461166\n",
      "epoch: 10 step: 1779, loss is 0.07436195760965347\n",
      "epoch: 10 step: 1780, loss is 0.031574562191963196\n",
      "epoch: 10 step: 1781, loss is 0.004158230498433113\n",
      "epoch: 10 step: 1782, loss is 0.0004987316788174212\n",
      "epoch: 10 step: 1783, loss is 0.002322911284863949\n",
      "epoch: 10 step: 1784, loss is 0.00018623197684064507\n",
      "epoch: 10 step: 1785, loss is 0.001134050777181983\n",
      "epoch: 10 step: 1786, loss is 0.001955656800419092\n",
      "epoch: 10 step: 1787, loss is 0.0075027355924248695\n",
      "epoch: 10 step: 1788, loss is 0.000452600623248145\n",
      "epoch: 10 step: 1789, loss is 0.016454070806503296\n",
      "epoch: 10 step: 1790, loss is 0.0002678466262295842\n",
      "epoch: 10 step: 1791, loss is 0.05758398398756981\n",
      "epoch: 10 step: 1792, loss is 0.019106552004814148\n",
      "epoch: 10 step: 1793, loss is 0.0004900384228676558\n",
      "epoch: 10 step: 1794, loss is 0.0006472320528700948\n",
      "epoch: 10 step: 1795, loss is 0.0005444895359687507\n",
      "epoch: 10 step: 1796, loss is 0.0001990802848013118\n",
      "epoch: 10 step: 1797, loss is 8.98001526365988e-05\n",
      "epoch: 10 step: 1798, loss is 2.880985448427964e-05\n",
      "epoch: 10 step: 1799, loss is 0.0068733952939510345\n",
      "epoch: 10 step: 1800, loss is 0.18588851392269135\n",
      "epoch: 10 step: 1801, loss is 0.0024973852559924126\n",
      "epoch: 10 step: 1802, loss is 0.0006300503155216575\n",
      "epoch: 10 step: 1803, loss is 8.291310223285109e-06\n",
      "epoch: 10 step: 1804, loss is 0.0001633233914617449\n",
      "epoch: 10 step: 1805, loss is 1.3199540262576193e-05\n",
      "epoch: 10 step: 1806, loss is 0.12254674732685089\n",
      "epoch: 10 step: 1807, loss is 0.0010519891511648893\n",
      "epoch: 10 step: 1808, loss is 0.08311179280281067\n",
      "epoch: 10 step: 1809, loss is 0.002225233009085059\n",
      "epoch: 10 step: 1810, loss is 2.568235322542023e-05\n",
      "epoch: 10 step: 1811, loss is 0.10971798747777939\n",
      "epoch: 10 step: 1812, loss is 0.020130861550569534\n",
      "epoch: 10 step: 1813, loss is 0.003354328917339444\n",
      "epoch: 10 step: 1814, loss is 0.0002498065878171474\n",
      "epoch: 10 step: 1815, loss is 6.506699719466269e-06\n",
      "epoch: 10 step: 1816, loss is 0.006020093336701393\n",
      "epoch: 10 step: 1817, loss is 6.296458013821393e-05\n",
      "epoch: 10 step: 1818, loss is 9.068539657164365e-05\n",
      "epoch: 10 step: 1819, loss is 0.05818328261375427\n",
      "epoch: 10 step: 1820, loss is 0.0031153918243944645\n",
      "epoch: 10 step: 1821, loss is 1.7388922060490586e-05\n",
      "epoch: 10 step: 1822, loss is 0.07383361458778381\n",
      "epoch: 10 step: 1823, loss is 0.0003680386289488524\n",
      "epoch: 10 step: 1824, loss is 0.0027773845940828323\n",
      "epoch: 10 step: 1825, loss is 0.00023301118926610798\n",
      "epoch: 10 step: 1826, loss is 0.0010223457356914878\n",
      "epoch: 10 step: 1827, loss is 9.004274033941329e-06\n",
      "epoch: 10 step: 1828, loss is 0.0212889164686203\n",
      "epoch: 10 step: 1829, loss is 0.03089732863008976\n",
      "epoch: 10 step: 1830, loss is 0.0005408969009295106\n",
      "epoch: 10 step: 1831, loss is 0.000279245461570099\n",
      "epoch: 10 step: 1832, loss is 0.002515576547011733\n",
      "epoch: 10 step: 1833, loss is 0.00013714988017454743\n",
      "epoch: 10 step: 1834, loss is 0.12046415358781815\n",
      "epoch: 10 step: 1835, loss is 6.19118072791025e-05\n",
      "epoch: 10 step: 1836, loss is 0.015340087004005909\n",
      "epoch: 10 step: 1837, loss is 0.0009087859070859849\n",
      "epoch: 10 step: 1838, loss is 0.013947143219411373\n",
      "epoch: 10 step: 1839, loss is 0.0005103521980345249\n",
      "epoch: 10 step: 1840, loss is 6.0116912209196016e-05\n",
      "epoch: 10 step: 1841, loss is 0.015128130093216896\n",
      "epoch: 10 step: 1842, loss is 0.000100353492598515\n",
      "epoch: 10 step: 1843, loss is 0.016122322529554367\n",
      "epoch: 10 step: 1844, loss is 0.0016629495657980442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 1845, loss is 0.0002996671828441322\n",
      "epoch: 10 step: 1846, loss is 0.001362378941848874\n",
      "epoch: 10 step: 1847, loss is 0.0001354935229755938\n",
      "epoch: 10 step: 1848, loss is 1.1171152436872944e-05\n",
      "epoch: 10 step: 1849, loss is 0.001734251040033996\n",
      "epoch: 10 step: 1850, loss is 0.04663177207112312\n",
      "epoch: 10 step: 1851, loss is 5.8216555771650746e-05\n",
      "epoch: 10 step: 1852, loss is 0.0006516302819363773\n",
      "epoch: 10 step: 1853, loss is 0.012148904614150524\n",
      "epoch: 10 step: 1854, loss is 0.00013349131040740758\n",
      "epoch: 10 step: 1855, loss is 5.040556516178185e-06\n",
      "epoch: 10 step: 1856, loss is 5.8021490985993296e-05\n",
      "epoch: 10 step: 1857, loss is 0.012768133543431759\n",
      "epoch: 10 step: 1858, loss is 0.005631063133478165\n",
      "epoch: 10 step: 1859, loss is 0.0028326266910880804\n",
      "epoch: 10 step: 1860, loss is 0.0004013504658360034\n",
      "epoch: 10 step: 1861, loss is 2.4815186407067813e-05\n",
      "epoch: 10 step: 1862, loss is 9.660967043600976e-05\n",
      "epoch: 10 step: 1863, loss is 0.002901215571910143\n",
      "epoch: 10 step: 1864, loss is 0.046314630657434464\n",
      "epoch: 10 step: 1865, loss is 0.14229385554790497\n",
      "epoch: 10 step: 1866, loss is 0.001392036909237504\n",
      "epoch: 10 step: 1867, loss is 0.01280962023884058\n",
      "epoch: 10 step: 1868, loss is 0.008373366668820381\n",
      "epoch: 10 step: 1869, loss is 0.00010718893463490531\n",
      "epoch: 10 step: 1870, loss is 0.0012863256270065904\n",
      "epoch: 10 step: 1871, loss is 6.411372851289343e-06\n",
      "epoch: 10 step: 1872, loss is 0.0005342239164747298\n",
      "epoch: 10 step: 1873, loss is 0.0013203779235482216\n",
      "epoch: 10 step: 1874, loss is 0.002128059044480324\n",
      "epoch: 10 step: 1875, loss is 0.0014955524820834398\n",
      "epoch: 10 step: 1876, loss is 0.07224030792713165\n",
      "epoch: 10 step: 1877, loss is 0.00038151844637468457\n",
      "epoch: 10 step: 1878, loss is 0.002033919095993042\n",
      "epoch: 10 step: 1879, loss is 0.014038542285561562\n",
      "epoch: 10 step: 1880, loss is 5.332672662916593e-05\n",
      "epoch: 10 step: 1881, loss is 0.4643544852733612\n",
      "epoch: 10 step: 1882, loss is 0.00010172452311962843\n",
      "epoch: 10 step: 1883, loss is 0.002585842739790678\n",
      "epoch: 10 step: 1884, loss is 0.20194591581821442\n",
      "epoch: 10 step: 1885, loss is 0.0003953524283133447\n",
      "epoch: 10 step: 1886, loss is 0.025826867669820786\n",
      "epoch: 10 step: 1887, loss is 8.386163972318172e-05\n",
      "epoch: 10 step: 1888, loss is 0.001873165019787848\n",
      "epoch: 10 step: 1889, loss is 0.00534145487472415\n",
      "epoch: 10 step: 1890, loss is 0.14889581501483917\n",
      "epoch: 10 step: 1891, loss is 0.016620833426713943\n",
      "epoch: 10 step: 1892, loss is 0.0027347069699317217\n",
      "epoch: 10 step: 1893, loss is 0.0020600035786628723\n",
      "epoch: 10 step: 1894, loss is 0.0005134335951879621\n",
      "epoch: 10 step: 1895, loss is 0.00023018455249257386\n",
      "epoch: 10 step: 1896, loss is 0.014154452830553055\n",
      "epoch: 10 step: 1897, loss is 0.02558033913373947\n",
      "epoch: 10 step: 1898, loss is 0.0022350787185132504\n",
      "epoch: 10 step: 1899, loss is 0.0007988247671164572\n",
      "epoch: 10 step: 1900, loss is 0.0017713301349431276\n",
      "epoch: 10 step: 1901, loss is 0.008586391806602478\n",
      "epoch: 10 step: 1902, loss is 0.007909668609499931\n",
      "epoch: 10 step: 1903, loss is 0.0038335598073899746\n",
      "epoch: 10 step: 1904, loss is 0.1570492833852768\n",
      "epoch: 10 step: 1905, loss is 0.012934889644384384\n",
      "epoch: 10 step: 1906, loss is 0.0014011411694809794\n",
      "epoch: 10 step: 1907, loss is 0.0002689399116206914\n",
      "epoch: 10 step: 1908, loss is 0.004746878985315561\n",
      "epoch: 10 step: 1909, loss is 0.0009816529927775264\n",
      "epoch: 10 step: 1910, loss is 0.008687576279044151\n",
      "epoch: 10 step: 1911, loss is 0.004118246957659721\n",
      "epoch: 10 step: 1912, loss is 0.00041186914313584566\n",
      "epoch: 10 step: 1913, loss is 0.0074370866641402245\n",
      "epoch: 10 step: 1914, loss is 1.2763289305439685e-05\n",
      "epoch: 10 step: 1915, loss is 0.07554028928279877\n",
      "epoch: 10 step: 1916, loss is 0.0007650325424037874\n",
      "epoch: 10 step: 1917, loss is 0.004516057204455137\n",
      "epoch: 10 step: 1918, loss is 4.520948641584255e-05\n",
      "epoch: 10 step: 1919, loss is 0.00033787242136895657\n",
      "epoch: 10 step: 1920, loss is 0.03820362314581871\n",
      "epoch: 10 step: 1921, loss is 0.0016557361232116818\n",
      "epoch: 10 step: 1922, loss is 0.0010924855014309287\n",
      "epoch: 10 step: 1923, loss is 0.00017196079716086388\n",
      "epoch: 10 step: 1924, loss is 0.0008498838287778199\n",
      "epoch: 10 step: 1925, loss is 0.08887534588575363\n",
      "epoch: 10 step: 1926, loss is 0.001253509079106152\n",
      "epoch: 10 step: 1927, loss is 1.4138780898065306e-05\n",
      "epoch: 10 step: 1928, loss is 0.07209816575050354\n",
      "epoch: 10 step: 1929, loss is 0.018461402505636215\n",
      "epoch: 10 step: 1930, loss is 8.24306407594122e-05\n",
      "epoch: 10 step: 1931, loss is 9.343713463749737e-05\n",
      "epoch: 10 step: 1932, loss is 0.0009386718738824129\n",
      "epoch: 10 step: 1933, loss is 0.0002647260553203523\n",
      "epoch: 10 step: 1934, loss is 6.797764945076779e-05\n",
      "epoch: 10 step: 1935, loss is 0.00010793039837153628\n",
      "epoch: 10 step: 1936, loss is 0.0003445875772740692\n",
      "epoch: 10 step: 1937, loss is 0.1027923971414566\n",
      "epoch: 10 step: 1938, loss is 0.027640631422400475\n",
      "epoch: 10 step: 1939, loss is 0.0005029125604778528\n",
      "epoch: 10 step: 1940, loss is 0.006460000295192003\n",
      "epoch: 10 step: 1941, loss is 0.006822190247476101\n",
      "epoch: 10 step: 1942, loss is 0.0033743258100003004\n",
      "epoch: 10 step: 1943, loss is 0.007310907356441021\n",
      "epoch: 10 step: 1944, loss is 0.003155055455863476\n",
      "epoch: 10 step: 1945, loss is 0.19024710357189178\n",
      "epoch: 10 step: 1946, loss is 0.0025150696747004986\n",
      "epoch: 10 step: 1947, loss is 0.01280420646071434\n",
      "epoch: 10 step: 1948, loss is 0.04952318221330643\n",
      "epoch: 10 step: 1949, loss is 0.008461041375994682\n",
      "epoch: 10 step: 1950, loss is 0.0002094857773045078\n",
      "epoch: 10 step: 1951, loss is 0.0004510478174779564\n",
      "epoch: 10 step: 1952, loss is 0.011320576071739197\n",
      "epoch: 10 step: 1953, loss is 7.321656448766589e-05\n",
      "epoch: 10 step: 1954, loss is 0.00025913139688782394\n",
      "epoch: 10 step: 1955, loss is 0.00022688877652399242\n",
      "epoch: 10 step: 1956, loss is 0.0011825098190456629\n",
      "epoch: 10 step: 1957, loss is 0.00010552075400482863\n",
      "epoch: 10 step: 1958, loss is 3.2207601179834455e-05\n",
      "epoch: 10 step: 1959, loss is 2.256307561765425e-05\n",
      "epoch: 10 step: 1960, loss is 0.00012451416114345193\n",
      "epoch: 10 step: 1961, loss is 0.005275178235024214\n",
      "epoch: 10 step: 1962, loss is 8.519049151800573e-05\n",
      "epoch: 10 step: 1963, loss is 0.000945163716096431\n",
      "epoch: 10 step: 1964, loss is 0.006772611290216446\n",
      "epoch: 10 step: 1965, loss is 0.011484886519610882\n",
      "epoch: 10 step: 1966, loss is 0.020615359768271446\n",
      "epoch: 10 step: 1967, loss is 0.0005282667698338628\n",
      "epoch: 10 step: 1968, loss is 2.7812013286165893e-05\n",
      "epoch: 10 step: 1969, loss is 8.135442476486787e-05\n",
      "epoch: 10 step: 1970, loss is 0.00038691976806148887\n",
      "epoch: 10 step: 1971, loss is 0.015321492217481136\n",
      "epoch: 10 step: 1972, loss is 0.0012997547164559364\n",
      "epoch: 10 step: 1973, loss is 0.0013251121854409575\n",
      "epoch: 10 step: 1974, loss is 0.009060136042535305\n",
      "epoch: 10 step: 1975, loss is 0.012655002065002918\n",
      "epoch: 10 step: 1976, loss is 0.00011006852582795545\n",
      "epoch: 10 step: 1977, loss is 0.009294332936406136\n",
      "epoch: 10 step: 1978, loss is 0.0212706308811903\n",
      "epoch: 10 step: 1979, loss is 0.040378253906965256\n",
      "epoch: 10 step: 1980, loss is 0.00031359324930235744\n",
      "epoch: 10 step: 1981, loss is 0.0018850123742595315\n",
      "epoch: 10 step: 1982, loss is 0.011138666421175003\n",
      "epoch: 10 step: 1983, loss is 0.09205891937017441\n",
      "epoch: 10 step: 1984, loss is 0.05369763448834419\n",
      "epoch: 10 step: 1985, loss is 0.0003369851619936526\n",
      "epoch: 10 step: 1986, loss is 0.008204575628042221\n",
      "epoch: 10 step: 1987, loss is 0.0005392216262407601\n",
      "epoch: 10 step: 1988, loss is 0.011902950704097748\n",
      "epoch: 10 step: 1989, loss is 5.984751260257326e-05\n",
      "epoch: 10 step: 1990, loss is 0.00034520335611887276\n",
      "epoch: 10 step: 1991, loss is 9.042616875376552e-05\n",
      "epoch: 10 step: 1992, loss is 0.021472930908203125\n",
      "epoch: 10 step: 1993, loss is 0.006470193155109882\n",
      "epoch: 10 step: 1994, loss is 7.82601855462417e-05\n",
      "epoch: 10 step: 1995, loss is 0.03657433018088341\n",
      "epoch: 10 step: 1996, loss is 0.06738216429948807\n",
      "epoch: 10 step: 1997, loss is 0.022312909364700317\n",
      "epoch: 10 step: 1998, loss is 0.026127373799681664\n",
      "epoch: 10 step: 1999, loss is 0.000835902348626405\n",
      "epoch: 10 step: 2000, loss is 0.00046737759839743376\n",
      "epoch: 10 step: 2001, loss is 4.6605105126218405e-06\n",
      "epoch: 10 step: 2002, loss is 6.0814978496637195e-05\n",
      "epoch: 10 step: 2003, loss is 2.7248048354522325e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 2004, loss is 0.0003181733482051641\n",
      "epoch: 10 step: 2005, loss is 0.00035207034670747817\n",
      "epoch: 10 step: 2006, loss is 0.08288626372814178\n",
      "epoch: 10 step: 2007, loss is 0.00021208511316217482\n",
      "epoch: 10 step: 2008, loss is 0.03773059323430061\n",
      "epoch: 10 step: 2009, loss is 0.03539890795946121\n",
      "epoch: 10 step: 2010, loss is 0.015195262618362904\n",
      "epoch: 10 step: 2011, loss is 0.025606906041502953\n",
      "epoch: 10 step: 2012, loss is 0.0003784235450439155\n",
      "epoch: 10 step: 2013, loss is 0.007725963369011879\n",
      "epoch: 10 step: 2014, loss is 0.002565056085586548\n",
      "epoch: 10 step: 2015, loss is 0.0006357438396662474\n",
      "epoch: 10 step: 2016, loss is 2.2073774744058028e-05\n",
      "epoch: 10 step: 2017, loss is 0.00022947763500269502\n",
      "epoch: 10 step: 2018, loss is 0.0002825249102897942\n",
      "epoch: 10 step: 2019, loss is 0.010376743040978909\n",
      "epoch: 10 step: 2020, loss is 0.015934713184833527\n",
      "epoch: 10 step: 2021, loss is 0.00010700973507482558\n",
      "epoch: 10 step: 2022, loss is 3.717890876941965e-06\n",
      "epoch: 10 step: 2023, loss is 0.0013375654816627502\n",
      "epoch: 10 step: 2024, loss is 0.0013779568253085017\n",
      "epoch: 10 step: 2025, loss is 0.0009836556855589151\n",
      "epoch: 10 step: 2026, loss is 0.00352643639780581\n",
      "epoch: 10 step: 2027, loss is 0.0009981399634853005\n",
      "epoch: 10 step: 2028, loss is 0.00013800674059893936\n",
      "epoch: 10 step: 2029, loss is 0.028201814740896225\n",
      "epoch: 10 step: 2030, loss is 0.0009976014262065291\n",
      "epoch: 10 step: 2031, loss is 0.001592022366821766\n",
      "epoch: 10 step: 2032, loss is 2.2537624317919835e-05\n",
      "epoch: 10 step: 2033, loss is 0.0008445192943327129\n",
      "epoch: 10 step: 2034, loss is 0.0008128234185278416\n",
      "epoch: 10 step: 2035, loss is 0.0001752391690388322\n",
      "epoch: 10 step: 2036, loss is 0.00040855485713109374\n",
      "epoch: 10 step: 2037, loss is 0.00025414457195438445\n",
      "epoch: 10 step: 2038, loss is 2.6531473849900067e-05\n",
      "epoch: 10 step: 2039, loss is 0.0003331365587655455\n",
      "epoch: 10 step: 2040, loss is 0.0004977192147634923\n",
      "epoch: 10 step: 2041, loss is 0.0005525777814909816\n",
      "epoch: 10 step: 2042, loss is 9.551720722811297e-05\n",
      "epoch: 10 step: 2043, loss is 0.18925711512565613\n",
      "epoch: 10 step: 2044, loss is 1.8764341803034768e-05\n",
      "epoch: 10 step: 2045, loss is 0.0005838787765242159\n",
      "epoch: 10 step: 2046, loss is 0.030874282121658325\n",
      "epoch: 10 step: 2047, loss is 0.0011382935335859656\n",
      "epoch: 10 step: 2048, loss is 9.743518603499979e-05\n",
      "epoch: 10 step: 2049, loss is 0.0007152364123612642\n",
      "epoch: 10 step: 2050, loss is 0.08061444014310837\n",
      "epoch: 10 step: 2051, loss is 1.3118490642227698e-05\n",
      "epoch: 10 step: 2052, loss is 0.00014426490815822035\n",
      "epoch: 10 step: 2053, loss is 0.05640898644924164\n",
      "epoch: 10 step: 2054, loss is 0.001845862832851708\n",
      "epoch: 10 step: 2055, loss is 0.0417824313044548\n",
      "epoch: 10 step: 2056, loss is 0.011584937572479248\n",
      "epoch: 10 step: 2057, loss is 0.0009332108893431723\n",
      "epoch: 10 step: 2058, loss is 0.1576053500175476\n",
      "epoch: 10 step: 2059, loss is 0.0008855417836457491\n",
      "epoch: 10 step: 2060, loss is 0.07629125565290451\n",
      "epoch: 10 step: 2061, loss is 2.6248326321365312e-05\n",
      "epoch: 10 step: 2062, loss is 0.0001018261827994138\n",
      "epoch: 10 step: 2063, loss is 0.010265706107020378\n",
      "epoch: 10 step: 2064, loss is 0.028410106897354126\n",
      "epoch: 10 step: 2065, loss is 0.0013590881135314703\n",
      "epoch: 10 step: 2066, loss is 0.0003957529552280903\n",
      "epoch: 10 step: 2067, loss is 0.001992997946217656\n",
      "epoch: 10 step: 2068, loss is 0.05639161169528961\n",
      "epoch: 10 step: 2069, loss is 0.0006126989610493183\n",
      "epoch: 10 step: 2070, loss is 5.1451097533572465e-05\n",
      "epoch: 10 step: 2071, loss is 0.002109876135364175\n",
      "epoch: 10 step: 2072, loss is 0.17663855850696564\n",
      "epoch: 10 step: 2073, loss is 0.02672194130718708\n",
      "epoch: 10 step: 2074, loss is 6.93801703164354e-05\n",
      "epoch: 10 step: 2075, loss is 0.0001028401602525264\n",
      "epoch: 10 step: 2076, loss is 0.02730502188205719\n",
      "epoch: 10 step: 2077, loss is 0.002635946264490485\n",
      "epoch: 10 step: 2078, loss is 0.003707082476466894\n",
      "epoch: 10 step: 2079, loss is 0.001924070413224399\n",
      "epoch: 10 step: 2080, loss is 0.0002518762485124171\n",
      "epoch: 10 step: 2081, loss is 0.02383764274418354\n",
      "epoch: 10 step: 2082, loss is 0.00026468641590327024\n",
      "epoch: 10 step: 2083, loss is 0.24099315702915192\n",
      "epoch: 10 step: 2084, loss is 0.0009554015123285353\n",
      "epoch: 10 step: 2085, loss is 0.12511859834194183\n",
      "epoch: 10 step: 2086, loss is 0.00029117241501808167\n",
      "epoch: 10 step: 2087, loss is 0.0008845697739161551\n",
      "epoch: 10 step: 2088, loss is 0.0004380595055408776\n",
      "epoch: 10 step: 2089, loss is 0.0679357722401619\n",
      "epoch: 10 step: 2090, loss is 0.07165314257144928\n",
      "epoch: 10 step: 2091, loss is 0.0026691884268075228\n",
      "epoch: 10 step: 2092, loss is 0.0015082376776263118\n",
      "epoch: 10 step: 2093, loss is 0.0013154023326933384\n",
      "epoch: 10 step: 2094, loss is 0.001999820815399289\n",
      "epoch: 10 step: 2095, loss is 0.01111510954797268\n",
      "epoch: 10 step: 2096, loss is 0.0013032048009335995\n",
      "epoch: 10 step: 2097, loss is 0.14166954159736633\n",
      "epoch: 10 step: 2098, loss is 0.0004443209618330002\n",
      "epoch: 10 step: 2099, loss is 0.009025024250149727\n",
      "epoch: 10 step: 2100, loss is 0.013064763508737087\n",
      "epoch: 10 step: 2101, loss is 0.0005425668205134571\n",
      "epoch: 10 step: 2102, loss is 0.0009000819991342723\n",
      "epoch: 10 step: 2103, loss is 0.00013158904039300978\n",
      "epoch: 10 step: 2104, loss is 0.002517204498872161\n",
      "epoch: 10 step: 2105, loss is 0.00032925570849329233\n",
      "epoch: 10 step: 2106, loss is 6.41395672573708e-05\n",
      "epoch: 10 step: 2107, loss is 0.06030923128128052\n",
      "epoch: 10 step: 2108, loss is 0.012280451133847237\n",
      "epoch: 10 step: 2109, loss is 0.013715803623199463\n",
      "epoch: 10 step: 2110, loss is 0.0008158193086273968\n",
      "epoch: 10 step: 2111, loss is 0.0002486657176632434\n",
      "epoch: 10 step: 2112, loss is 0.0009569711401127279\n",
      "epoch: 10 step: 2113, loss is 0.0019707572646439075\n",
      "epoch: 10 step: 2114, loss is 0.0003790851915255189\n",
      "epoch: 10 step: 2115, loss is 0.0013985438272356987\n",
      "epoch: 10 step: 2116, loss is 0.010075329802930355\n",
      "epoch: 10 step: 2117, loss is 0.02750970609486103\n",
      "epoch: 10 step: 2118, loss is 0.006801297422498465\n",
      "epoch: 10 step: 2119, loss is 0.012354022823274136\n",
      "epoch: 10 step: 2120, loss is 0.0071815005503594875\n",
      "epoch: 10 step: 2121, loss is 0.0015335300704464316\n",
      "epoch: 10 step: 2122, loss is 0.0002894634671974927\n",
      "epoch: 10 step: 2123, loss is 0.00833249744027853\n",
      "epoch: 10 step: 2124, loss is 5.220413004280999e-05\n",
      "epoch: 10 step: 2125, loss is 0.00022990943398326635\n",
      "epoch: 10 step: 2126, loss is 0.0028857006691396236\n",
      "epoch: 10 step: 2127, loss is 0.0029048388823866844\n",
      "epoch: 10 step: 2128, loss is 0.0013594278134405613\n",
      "epoch: 10 step: 2129, loss is 0.000347067165421322\n",
      "epoch: 10 step: 2130, loss is 0.0008425773703493178\n",
      "epoch: 10 step: 2131, loss is 0.010854269377887249\n",
      "epoch: 10 step: 2132, loss is 0.007120082620531321\n",
      "epoch: 10 step: 2133, loss is 4.429717591847293e-05\n",
      "epoch: 10 step: 2134, loss is 2.4853379727574065e-05\n",
      "epoch: 10 step: 2135, loss is 0.2601608633995056\n",
      "epoch: 10 step: 2136, loss is 0.0010388443479314446\n",
      "epoch: 10 step: 2137, loss is 0.011814423836767673\n",
      "epoch: 10 step: 2138, loss is 0.0001664827432250604\n",
      "epoch: 10 step: 2139, loss is 0.1245480328798294\n",
      "epoch: 10 step: 2140, loss is 0.0001533956383354962\n",
      "epoch: 10 step: 2141, loss is 0.001892377040348947\n",
      "epoch: 10 step: 2142, loss is 0.004735284484922886\n",
      "epoch: 10 step: 2143, loss is 0.0011995293898507953\n",
      "epoch: 10 step: 2144, loss is 0.00183863693382591\n",
      "epoch: 10 step: 2145, loss is 0.0007119731744751334\n",
      "epoch: 10 step: 2146, loss is 0.060941074043512344\n",
      "epoch: 10 step: 2147, loss is 0.008944624103605747\n",
      "epoch: 10 step: 2148, loss is 0.0017159524140879512\n",
      "epoch: 10 step: 2149, loss is 0.031408026814460754\n",
      "epoch: 10 step: 2150, loss is 0.002560763154178858\n",
      "epoch: 10 step: 2151, loss is 0.0008958517573773861\n",
      "epoch: 10 step: 2152, loss is 0.0005701259360648692\n",
      "epoch: 10 step: 2153, loss is 0.0005291707930155098\n",
      "epoch: 10 step: 2154, loss is 0.001457385253161192\n",
      "epoch: 10 step: 2155, loss is 2.1875277525396086e-05\n",
      "epoch: 10 step: 2156, loss is 0.00141355418600142\n",
      "epoch: 10 step: 2157, loss is 0.00041982397669926286\n",
      "epoch: 10 step: 2158, loss is 0.0009869285859167576\n",
      "epoch: 10 step: 2159, loss is 2.754655542958062e-05\n",
      "epoch: 10 step: 2160, loss is 6.26559994998388e-05\n",
      "epoch: 10 step: 2161, loss is 0.00011673333210637793\n",
      "epoch: 10 step: 2162, loss is 6.835716339992359e-05\n",
      "epoch: 10 step: 2163, loss is 0.001432515331543982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 2164, loss is 0.021363671869039536\n",
      "epoch: 10 step: 2165, loss is 0.01330494973808527\n",
      "epoch: 10 step: 2166, loss is 0.0015751547180116177\n",
      "epoch: 10 step: 2167, loss is 0.0019786525517702103\n",
      "epoch: 10 step: 2168, loss is 7.132025348255411e-05\n",
      "epoch: 10 step: 2169, loss is 0.00016240455443039536\n",
      "epoch: 10 step: 2170, loss is 3.628649938036688e-05\n",
      "epoch: 10 step: 2171, loss is 0.000890028546564281\n",
      "epoch: 10 step: 2172, loss is 0.006955612916499376\n",
      "epoch: 10 step: 2173, loss is 0.0758945420384407\n",
      "epoch: 10 step: 2174, loss is 0.06425654143095016\n",
      "epoch: 10 step: 2175, loss is 3.543455750332214e-05\n",
      "epoch: 10 step: 2176, loss is 0.0024920639116317034\n",
      "epoch: 10 step: 2177, loss is 0.004027483053505421\n",
      "epoch: 10 step: 2178, loss is 0.00011091174383182079\n",
      "epoch: 10 step: 2179, loss is 0.0005765431560575962\n",
      "epoch: 10 step: 2180, loss is 0.013204016722738743\n",
      "epoch: 10 step: 2181, loss is 0.000304813904222101\n",
      "epoch: 10 step: 2182, loss is 0.00025844646734185517\n",
      "epoch: 10 step: 2183, loss is 0.00010813850531121716\n",
      "epoch: 10 step: 2184, loss is 0.0004201069241389632\n",
      "epoch: 10 step: 2185, loss is 8.789659477770329e-05\n",
      "epoch: 10 step: 2186, loss is 0.002085041254758835\n",
      "epoch: 10 step: 2187, loss is 0.00046521032345481217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.529.225 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.530.223 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.531.220 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.531.220 [mindspore\\dataset\\core\\validator_helpers.py:744] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:25.532.217 [mindspore\\dataset\\core\\validator_helpers.py:744] 'TypeCast' from mindspore.dataset.transforms.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'TypeCast' from mindspore.dataset.transforms instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting Testing ==========\n",
      "Test Accuracy: 0.9975851623228167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:37.154.346 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:37.155.365 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:37.157.318 [mindspore\\dataset\\core\\validator_helpers.py:744] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(364:18336,MainProcess):2024-04-29-20:52:37.158.336 [mindspore\\dataset\\core\\validator_helpers.py:744] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAGhCAYAAACJXHZ9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABFQ0lEQVR4nO3dfVTVVboH8EccOPjCi4pABEctX7BMMxJE8qVEbczraNRqXrqVOToauK4560651r1159Yaprl3xrk3ye6aCqt7vZQ1ZlqahYpZoIHpiC9UloIimC8c8A1IfvcPL0/P3gIdXg7n99vn+1nrrPUc9vawOTyc7W/v3967h2VZFgEAAICRgvzdAAAAAPAddPQAAAAGQ0cPAABgMHT0AAAABkNHDwAAYDB09AAAAAZDRw8AAGAwdPQAAAAGQ0cPAABgMHT0AAAABvNZR5+Tk0ODBw+m0NBQSklJod27d/vqWwF0KeQuOBVyF1rik47+jTfeoGXLltHTTz9Ne/bsoTFjxtCMGTPo1KlTvvh2AF0GuQtOhdyF1vTwxaE2KSkpNG7cOFq5ciURETU1NVFCQgItWbKEnnzyyTb/bVNTE1VWVlJYWBj16NGjq5sGPmBZFtXV1VFcXBwFBTl7Ngi5G1iQu8R1kbvO0p7c/VFXf/OGhgYqKSmh5cuX89eCgoIoPT2dCgsLr6lfX19P9fX1/PzEiRN00003dXWzoBtUVFRQfHy8v5vRYcjdwIXcRe46lTe52+X/hT19+jRduXKFYmJilK/HxMRQVVXVNfWzs7MpIiKCH0g25woLC/N3EzoFuRu4kLvIXafyJnf9Pla1fPly8ng8/KioqPB3k6CDAm3ID7lrDuQuctepvMndLh+6j4qKop49e1J1dbXy9erqaoqNjb2mvsvlIpfL1dXNAGg35C44FXIX2tLlV/QhISGUlJRE+fn5/LWmpibKz8+n1NTUrv52AF0GuQtOhdyFNlk+kJeXZ7lcLmv16tXWwYMHrYULF1qRkZFWVVXVD/5bj8djEREeDnx4PB5fpFO3Qu4G5gO5i9x16sOb3PVJR29ZlvX8889bbrfbCgkJsZKTk62ioiKv/h0SzrkPEz4sLQu5G4gP5C5y16kPb3LXJ+voO6O2tpYiIiL83QzoAI/HQ+Hh4f5uht8gd50LuYvcdSpvctfvd90DAACA76CjBwAAMBg6egAAAIOhowcAADAYOnoAAACDdfnOeOC9kJAQjseOHauUjRw5kuOLFy8qZXv27OH4q6++8lHrADpv1KhRynO5ecv58+c53rRpk1LP4/FwbLOFQdBB8vPulltuUcpGjx7NsbyDvK3tXWX+EBEdOXKE42+++Ybj8vJypV5TU5OXLTYHrugBAAAMho4eAADAYBi696OoqCiOH3zwQaXsvvvu4/jrr79WylasWMExhu6hveRwaK9evZQyOWza0NDA8blz55R6bQ2nDxw4kOM5c+YoZQsWLOC4qKiI4+3btyv15NA9OFPfvn2V5xMnTuT4gQceUMruuecejuUQvz5t+aMffd9lNTY2KmX79u3j+NNPP+X4gw8+UOrt37+f40uXLrX+AxgEV/QAAAAGQ0cPAABgMAzd+5G8IzklJUUpi4mJ4VgfnsddyNAZvXv35liu7iAiSktL41ieba7fFV9bW8uxno/yDmo9r+V0wO7duzluz9QA2FdwcDDHiYmJStkf/vAHjgcNGqSUnT17luOdO3dyrE9bhoWFcazfuT9u3DiO5eqO8ePHK/Wys7M5/vzzz5WyCxcukIlwRQ8AAGAwdPQAAAAGQ0cPAABgMMzRdyO5bIRIXWIyZMiQ7m4OBCiZa/Pnz1fKfvnLX3JcUVHB8ZkzZ5R6n3zyCcf6Eqjo6OgWYyKiG2+8keNHH32UY30J1KFDhzi+cuVKCz8F2JG8t2jatGlK2YgRIzj++OOPlbKVK1e2WKbnnVwaqu+6uHjxYo7nzp3L8d13363UCw0N5fjZZ59VyuSyvPr6ejIFrugBAAAMho4eAADAYBi69zE5XD9v3jylLD09neP+/fu3+hr6IQxyiRJAew0bNoxjuQyJSN15LDY2luOpU6cq9eTuYvrQfVvk0Kv829B3UQNnkr/foCD1OlIuodSHzIuLizmWh9Xoyyzl8wMHDihlTz31FMdbt27l+D/+4z+UenIJ6a9+9SulTO6UJ3dudDpc0QMAABgMHT0AAIDB0NEDAAAYDHP0PibnIfUTm+QpX/p8lpz33Lt3r1Iml4AAtNepU6c4PnLkiFI2ZswYjuWyNn2r0PbMy0s1NTUc79mzh+PDhw8r9fT7UsAZZG698cYbSpnczlbOyRO1PS/fGn3ZpVyKJ+foV61apdTLzMzkWF8CWFBQwLHMTyJn3xuFK3oAAACDoaMHAAAwGIbuu5E+9NPWjl9ymEtfRiJPegJoL7nMqbKyUilrbGzk+MSJExzLneqIiC5fvtzq6yckJLQYExEdP36c440bN3IsT8Mjwul1TiV3kzt27JhSJofW5VA9Udf8vuV0T11dHcdyh0ciNcf1nRvDw8M51qdTncycnwQAAACugY4eAADAYBi69wG5u9iAAQM4bs9wlRzKlEOtP/TvAH6IHJ7Uhy7l3fTyrmM5jE+kDn/KHfSIiIYOHcqxzH8idQrgs88+4xh32ZtH5gjRtZ9jXa1nz54cR0VFcXzHHXco9eQujHqb5OeuSTmJK3oAAACDoaMHAAAwGDp6AAAAg2GO3gfkbng33HADx4MGDVLqBQcHt/oachmSPj8K0B7yRDEiovj4eI5vuukmpUwuAT169CjHFy5cUOrJ+0TknDyRuqROn+esrq7mWF/2BNAeLpdLeT5kyBCO586dy/H06dOVenIuXy7xJFJ3gPzuu++6pJ12gCt6AAAAg6GjBwAAMBiG7n1ALq+TS48SExOVeqGhoRzru93JpU1lZWVd3UQIIHI5HZE6xOl2u5UyuQRU7prX1pJOffg/Li6O46qqKqVMLq/TpwMAdPq0U0REBMd63t1zzz0c//KXv+S4V69eSj05PL969WqlTH7uYnkdAAAAOAI6egAAAIOhowcAADAY5uj9SM57fvrpp0qZnEfST/YCaA/9BDl5r4jcDpSIqLy8nOPt27dzrG9nKpeQ3nrrra1+v7179yplxcXFHMv5V2zrHNjkkje5bG7gwIFKvZSUFI4zMjKUMrmMTuZnYWGhUu8vf/kLx/v27VPK9BNGTYEregAAAIOhowcAADAYhu67gBwmIlKXgPTp06fVfyeXF+k7NMkhTn3YFKA9YmJilOfyxLrLly8rZXI3vNLSUo71ZU5yx8fhw4crZTL/9d3L+vfvz7Eclq2rq1Pq1dfXc2zSMie4Sv/MlDl64403cvzAAw8o9WbNmsWx3OGRSP2cPHLkCMfPP/+8Uu+TTz7h2Ncn6tkFrugBAAAMho4eAADAYBi676DevXtzLA9QICLKycnhWB5cI/8NEdHJkyc5PnbsmFIWKENK4Bty18VJkyYpZePHj+f4zJkzSpm8S14O18vhfiKi2bNnc6wf1hQU9P31Q3JyslI2bNgwjr/88kuOd+3apdT7z//8T47lAU9EZh02EkjkcP3Pf/5zpeyRRx7hePDgwRzLqR6ia1eJSPLOfbk74xNPPKHUk9OieXl5Splc7XTp0qVWv5fT4IoeAADAYOjoAQAADIaOHgAAwGCYo++gyZMnc7xo0SKlTC4vasu3337L8cWLF5Uy7BQGnTFixAiO9VO++vXrx7E8aZFInc9/4YUXOB4zZoxST87LR0VFtdoO/fUHDBjAcVhYGMfyRD0idenpypUrlbLq6upWvx/Y15UrVzjWd0yUyyvlkk/5GUmk3sukLw2VSznl/VDXX3+9Uk8u35sxY4ZSVlNTw3FJSYlStmHDBo7ljnrylEe7whU9AACAwdDRAwAAGAxD9x0UGxvLsb4zmLfD7u+//z7H8jARgM4aO3Ysx3IXOyJ1GZK+XEkeUDNy5EiOIyMjlXpy2Wh7eDwejg8cOMCx3JGPiGjTpk0c41AnM8ihe7m0kojomWee4VjuJiqXahKpSyv1ZZYyr+VSPjldRKROa8m/EyI1//Vl0+PGjeP48OHDHL/88stKvZ07d7baRn/BFT0AAIDB0NEDAAAYDB09AACAwTBH30FyjlI/octbBQUFHGPJEHTW0KFDOZ46dSrH+tI1eTJcVVWVUiaXL8nlb6dPn1bqyXl/Pf/Pnj3LsdxSlIgoPz+fY7nEqq2teBsaGgjMIpdPEhHt3r3bZ9+rV69eynN5auLWrVuVMrkU9c4771TKpkyZwrH8m5L3HhCp9x/of1963e7Sriv67OxsGjduHIWFhVF0dDTNmTOHysrKlDqXL1+mzMxMGjBgAPXt25cyMjLQiYHfIXfBqZC70Fnt6ugLCgooMzOTioqK6MMPP6TGxkaaPn268r+zxx9/nDZs2EBr166lgoICqqyspHvvvbfLGw7QHshdcCrkLnRWD6sTW7B9++23FB0dTQUFBTRp0iTyeDw0cOBAWrNmDd13331EdHUZwsiRI6mwsFA5Nas1tbW1Xu8s508LFy7k+A9/+INSFh4ezrF8e+WQJpE6FCSXGjmVx+NRfnY7MyF35TIkIqJly5Zx/Oijj3IsTwMjUnfy2rJli1L27rvvciyX1KWkpCj17r//fo71E8bkDmKvvPKKUvbpp59yfOrUKbIL5K4zPnd9TZ76KJfaEak5P3PmTI71902evKgvvdN3+usK3uRup27Ga14T2/yHXlJSQo2NjZSens51EhMTye12U2FhYYuvUV9fT7W1tcoDwNeQu+BUyF1orw539E1NTbR06VJKS0ujUaNGEdHVGw9CQkKu2VwjJibmmpsSmmVnZ1NERAQ/EhISOtokAK8gd8GpkLvQER3u6DMzM6m0tJTy8vI61YDly5eTx+PhR0VFRadeD+CHIHfBqZC70BEdWl6XlZVFGzdupB07dlB8fDx/PTY2lhoaGqimpkb532V1dbWyZazkcrk6vDzNruS8vDyVad26dUo9eVISdA+n526PHj041ucG58yZw7G8Qrt06ZJSTy5de/PNN5UyufWs/Nn0eXi5RE/mOBHRRx99xLHc5pkIS+U6w+m56wTyRLyioiKlTC4xlacyLlmyRKmXmZnJsbznhcg3c/TeaNcVvWVZlJWVRevWraOtW7desz43KSmJgoODlbWyZWVlVF5eTqmpqV3TYoAOQO6CUyF3obPadUWfmZlJa9asofXr11NYWBjP/0RERFCvXr0oIiKC5s+fT8uWLaP+/ftTeHg4LVmyhFJTU7268xPAV5C74FTIXeisdnX0q1atIiJ1WRgRUW5uLj3yyCNERLRixQoKCgqijIwMqq+vpxkzZtALL7zQJY21EznEow9d9u7dm2M5VPPSSy8p9fTdwMB3TMzdpqYm5bnMJzlcf+LECaXexo0bOd68eXOrry+nCfSlfPKkMH3zFnkSY2NjY6uvD94xMXedSP59FRcXcyz/TojU0/LkEL8/tasV3iy5Dw0NpZycHMrJyelwowC6GnIXnAq5C52FQ20AAAAMZo9xBQc6evQox3v27FHKZs2axXFMTAzHzcNszZ599lmO5W5lAK2RV3f6GunmIV4i9dAlvd7hw4dbfD0idRhSDjvefvvtSj05PSXv4idS/zY6sfEmgM8FBanXunJKSh92HzRoEMeTJ09u9TXlwTX69Jq/4IoeAADAYOjoAQAADIaOHgAAwGCYo++gYcOGcZyWlqaUyXnOvn37cjxv3jyl3osvvsgx5uihsz744AOOP//8c44vXryo1JOnKMq5fCJ17l3OUUZHRyv17LJsCKCZ/Nxta65dzsvreS1PrNM/1+WeBImJiRzLOXkiooMHD3Isl2H7E67oAQAADIaOHgAAwGAYf+sgORzafD50M3kAyHfffcexfkjChQsXfNQ6CERyN7zjx49zrC/xkc+HDh2qlD300EMcjx49muObb75ZqScPRNF33pNTAwDeiIqKajF2u91KPTllqh/YExoa2mKZfgSvPAxKP9hHTl3pu0HKMjkk/9577yn1fve733Es/w79CVf0AAAABkNHDwAAYDB09AAAAAbDHH0HFRYWcvz73/9eKUtPT+d44MCBHOunScmT7QA6S243K+8NaUt8fLzy/Cc/+QnH8txzuUxUV11drTyvra316nsDNLvvvvs4njZtGsf6HH1ISAjH586dU8qOHDnCsVw2GhYWptQbMWIEx7169VLKvvjiC471rZ2PHTvWYtm+ffuUegcOHOC4vr6e7ABX9AAAAAZDRw8AAGAwDN13UEVFBcfvvPOOUrZ//36O5VKOzz77TKl3/vx53zQOwEvypDkiUs4zl8Oactcx3Y4dO5TnWDYK7VVaWsqxnHbSp4waGxs51pdxylMa5e53kZGRSj25G56cCtBfQ182evr0aY5PnjzJsb682o5wRQ8AAGAwdPQAAAAG62HJW3VtoLa2VhnuBufweDwUHh7u72b4DXLXuZC7yF2n8iZ3cUUPAABgMHT0AAAABkNHDwAAYDB09AAAAAZDRw8AAGAwdPQAAAAGQ0cPAABgMHT0AAAABkNHDwAAYDB09AAAAAZDRw8AAGAwdPQAAAAGs11Hb7MzdqAdAv13F+g/v5MF+u8u0H9+J/Pmd2e7jr6urs7fTYAOCvTfXaD//E4W6L+7QP/5ncyb353tjqltamqiyspKsiyL3G43VVRUBPTxkc1qa2spISHBlu+HZVlUV1dHcXFxFBRku/87dhvkbsuQu/aH3G2ZKbn7o25qk9eCgoIoPj6eamtriYgoPDzcdm+wP9n1/cBZ1sjdH2LX9wO5i9z9IXZ9P7zN3cD9LywAAEAAQEcPAABgMNt29C6Xi55++mlyuVz+boot4P1wDvyuVHg/nAO/K5Up74ftbsYDAACArmPbK3oAAADoPHT0AAAABkNHDwAAYDB09AAAAAazZUefk5NDgwcPptDQUEpJSaHdu3f7u0ndIjs7m8aNG0dhYWEUHR1Nc+bMobKyMqXO5cuXKTMzkwYMGEB9+/aljIwMqq6u9lOLQYfcRe46WSDmb0DkrmUzeXl5VkhIiPXKK69YBw4csBYsWGBFRkZa1dXV/m6az82YMcPKzc21SktLrb1791ozZ8603G63df78ea6zaNEiKyEhwcrPz7eKi4ut8ePHWxMmTPBjq6EZche562SBmr+BkLu26+iTk5OtzMxMfn7lyhUrLi7Oys7O9mOr/OPUqVMWEVkFBQWWZVlWTU2NFRwcbK1du5brHDp0yCIiq7Cw0F/NhP+H3P0ectd5kL9XmZi7thq6b2hooJKSEkpPT+evBQUFUXp6OhUWFvqxZf7h8XiIiKh///5ERFRSUkKNjY3K+5OYmEhutzsg3x87Qe6qkLvOgvz9nom5a6uO/vTp03TlyhWKiYlRvh4TE0NVVVV+apV/NDU10dKlSyktLY1GjRpFRERVVVUUEhJCkZGRSt1AfH/sBrn7PeSu8yB/rzI1d213eh1clZmZSaWlpbRz505/NwWgXZC74FSm5q6truijoqKoZ8+e19zNWF1dTbGxsX5qVffLysqijRs30rZt2yg+Pp6/HhsbSw0NDVRTU6PUD7T3x46Qu1chd50J+Wt27tqqow8JCaGkpCTKz8/nrzU1NVF+fj6lpqb6sWXdw7IsysrKonXr1tHWrVtpyJAhSnlSUhIFBwcr709ZWRmVl5cHxPtjZ8hd5K6TBXL+BkTu+uouv5UrV1qDBg2yXC6XlZycbO3atcurf5eXl2e5XC5r9erV1sGDB62FCxdakZGRVlVVla+aahuLFy+2IiIirO3bt1snT57kx8WLF7nOokWLLLfbbW3dutUqLi62UlNTrdTUVD+22jzI3fZD7tpDR3PXsgI3fwMhd33S0Xd2Pebzzz9vud1uKyQkxEpOTraKiop80UzbIaIWH7m5uVzn0qVL1mOPPWb169fP6t27tzV37lzr5MmT/mu0YZC7HYPc9b+uWAcfiPkbCLnrk2NqU1JSaNy4cbRy5UoiujoElJCQQEuWLKEnn3yyzX/b1NRElZWVFBYWRj169OjqpoEPWJZFdXV1FBcXR0FBtpoNajfkbmBB7hLXRe46S3tyt8vvum9ej7l8+XL+WnvWY1ZWVlJCQkJXNwu6QUVFhXITi9MgdwMXche561Te5G6Xd/Rtrcc8fPjwNfXr6+upvr6en/tggAG6SVhYmL+b0CnI3cCF3EXuOpU3uev3sars7GyKiIjgh9vt9neToIMCbcgPuWsO5C5y16m8yd0u7+jbux5z+fLl5PF4+FFRUdHVTQLwCnIXnAq5C23p8o6+vesxXS4XhYeHKw8Af0DuglMhd6FNvriVvzPrMT0eT6vLHfCw98Pj8fginboVcjcwH8hd5K5TH97krs82zOnoekwknHMfJnxYWhZyNxAfyF3krlMf3uSuT9bRd0ZtbS1FRET4uxnQAR6PJ6CHAJG7zoXcRe46lTe56/e77gEAAMB30NEDAAAYDOfRA0C7TZgwgePJkycrZfqmLdLXX3/N8bp16zjG8i4A38EVPQAAgMHQ0QMAABgMHT0AAIDBMEcPAC2Se2hfd911Stm8efM4nj17tlLmcrlafc2vvvqK4yNHjnCMOXoA38EVPQAAgMHQ0QMAABgMQ/cAwHr27MmxXCb3i1/8Qqk3a9YsjhsaGpSybdu2cXzu3LlWX9/pZ8ADOAWu6AEAAAyGjh4AAMBgGLr3o+DgYI71YczQ0FCOe/furZT16dOH4ytXrnB88eJFpV55eTnH3333XecaCwFB5uGMGTM4/pd/+RelnszJF198USnLycnhuLS0VCmLjIzkOC4urjNNBUPJ6R35WUdEysE7ellrqz3k6hEiotOnT3Pc2NiolMkz3pqampSyS5cucXzhwoUWv5dd4YoeAADAYOjoAQAADIaOHgAAwGCYo/exH/3o+7dYzrsTEcXHx3M8depUpSwxMZHj5ORkpUw+P3/+PMe7d+9W6j3yyCMcV1ZWKmVybh8Clz5/KZfULVy4kGN9/lPOV7733ntKmT4vL9XU1LQYQ2CTn5MyBydNmqTUmzlzJsdpaWlK2eDBg1t8bT3Hc3NzOT5x4oRSJufl6+rqlLIDBw5wvHPnTo7l3wKRPe+HwhU9AACAwdDRAwAAGAxD9z4glx7ddtttHN91111KvYceeohjOVxFpA5lyeUmROoSEPm9kpKSlHpymOvNN99UyvQdyyAw9evXT3memprK8bhx4zjWc/CJJ57g+LPPPvNR6yBQTJw4keOHH36Y4ylTpij15Oek/IwkUj8X2/Kzn/2MY30JnaRPb9bX13P8xRdfcPzUU08p9QoKCji2yzA+rugBAAAMho4eAADAYOjoAQAADIY5+jY8+OCDHI8YMUIpq6qq4ljfRnHChAkcy6Vw/fv3V+rJ5/p8k7fk0pGQkBClTLZZX9oHQKTeQ0JE9K//+q8t1tu7d6/y/OOPP+ZYbikK0Br5+fTAAw8oZXIp58iRIznWtwY/e/Ysx1999ZVSdubMmRa/r768rq25/PDwcI6HDBmilCUkJHAsP1vlMmYiosLCQo4xRw8AAAA+h44eAADAYBi619x4440cz5o1i+Px48cr9S5fvsyxvkRj4MCBHMvlS/oSJTmsc/ToUaWsrKyMY31I/uabb+Y4Ojq61dcfNWoUx7169SIAIqIBAwZwfNNNNyllcnhS7vj12muvKfUqKio4xi6L0BL91E05jbl48WKl7JZbbuH4m2++4Tg/P1+pJ3f/PHnypFLWFTstyhPx5Oc/EdG8efM4ljtF6tOu+lSBHeCKHgAAwGDo6AEAAAwW8EP3QUHq/3V+/OMfczxmzBiO5ZAmkffDM3JY88svv1TK5MEIRUVFStmRI0c41u+Mjo2N5VgO3etTCPKuVDnVAIFNTkP99Kc/VcrkQR4fffQRxxs2bFDq1dbW+qh1YAp9KlFOY+rTkXIqSB6S9Pbbbyv1Dh8+zLH+mdaRO9z1HUlvv/12juXnLJH6mS9XmujTC/oqLDvAFT0AAIDB0NEDAAAYDB09AACAwQJyjl7OtVx33XVK2YwZMzi+/vrrW/w3P+TChQsc79mzh+O33npLqSd3F9Pn7+V8lr60T+7eJOlzQ7t27WqxTRBYBg0apDxPT0/nWJ5WR0RUXV3NsVzKdPz4caWezDW5XI9IndvUdzaTS/bk8qhTp061/gOAIzU0NCjP5YlvL774olIml6jJ0xDlMmMiovPnz3e6XcOHD+dYnvBJRDRt2jSO5TJmIvW+lE2bNnG8ZcsWpZ5ddsOTcEUPAABgMHT0AAAABgvIoXu5q9HcuXOVsltvvZXjvn37tvoacnhGDncSqUvl8vLyOH733XeVem0tw5gyZQrHkydPVsrklIJshz78KYe96uvrW/1eYDa5ZEh/rg+vysOaZP7ou9/JvxN9aknucqYP68vhTzmt9eabbyr1zp07x3Fbh5CAfemfOQcOHGgx7qjg4GDluZzuHDx4cKv/bs6cORzrn/8yX0+cOKGUFRQUcLx69WqOy8vLvWmuX+GKHgAAwGDo6AEAAAyGjh4AAMBgATFHr2+3mJiYyPFvfvMbpUzf9rCZPk8o5zLXrVunlK1YsYJjOX+jb1Er6Sc9yaUdw4YNa/XfyS1Lt2/frpT97W9/4xhb4AYut9utPJfL7fQTwN555x2O5Ra4+hbQ//RP/8RxWlqaUqb/vUkyz+UyP3liGZG6ragdlytB+8kldG0tV5Ynbeq5FBoayrG+fa08HS8jI6PV7zV27NhWy+SSUvm3QET04Ycfciy3KHcCXNEDAAAYDB09AACAwQJi6F7f/e7pp5/mWB/+kScuyeF6fehbnrD0+9//XinTh0NbI4eN9CVQEydO5FgfNpXtkkv7XnrpJaUeltQFLrn06IYbblDKZD6tX79eKfvTn/7E8fTp0zlesGCBUm/06NEc68PuxcXFrbZL7sQnpxT0JXpyKROG7p1Dfn726dNHKZPTovqpoZI8NVRfJhcfH8+x/pkph+4lfXhefn7qS5Ll0L3coY9IzUO546O+66i+FNUOcEUPAABgMHT0AAAABguIoXt5pyYR0dChQzluawhJ7s6l39Eud7mTd+C3R0REBMcPPvigUjZhwoRW23jmzBmO5S58+/btU+rZcQgJusesWbM4lrvY/RA5nP7yyy9zvH//fqWePAxEvwO5raH2n/zkJxyvWbOG48WLFyv1/vznP3OMFSP2Jj+fRo4cyfFjjz2m1JO/e3lnPZE6vC6H//Vhd1km446KiopSni9btozjrKwspUx+zm/evJnjV199Val36NAhju0yfYoregAAAIOhowcAADAYOnoAAACDBcQc/bfffqs8f/HFFzn+3e9+p5TJE+t27NjBsZyvJCL6+OOPOfb2dC19uckTTzzBsdwljIgoPDyc40uXLillcvmSXFKHuUxoNnv2bI5vu+02pUwuKfrqq6+UssrKSo6XLl3KcWFhoVJPLqnTT8CToqOjlefy5EU5/6rfR9PWzmlgL/379+dY7pKonwwn58PbujeqK8i58ddee00pa+tzMikpiWP93pYhQ4Zw/Itf/IJj/bN706ZNHMvlqkQdv5+rs3BFDwAAYDB09AAAAAYLiKH72tpa5bk8hEYOVRIRDRw4kOPS0lKODx48qNQ7f/68V99bHuSg7/41Y8YMjuWQJpG6dKSiokIp27ZtG8dySZ23Uwhgvn79+nGsH5j05ZdfclxWVqaUeTwejuUSUrnUlMj7XJs8ebLyfP78+RzLIVT97wtLQ51DHqx1+PBhjt9//32l3tGjRzm+6aablDL5OSk/0/SlmxcvXvSqTTJ/9OmptpZ/yukF/TAoueRZLoeWh6QREblcLo7lQThE6nul76jnS7iiBwAAMBg6egAAAIOhowcAADBYu+bos7Oz6a9//SsdPnyYevXqRRMmTKDnnnuORowYwXUuX75Mv/71rykvL4/q6+tpxowZ9MILL1xzSlx30udk5Lz8hg0blDI5nymXtTU2Nnr9/eRSoZtvvpljfZtbeTKTPG2MSL2vQJ6oRESUn5/PcXfO8ziZU3PXF+TcuJwzJFLnNs+ePduh15fznPKUOyL15Dx5Oti///u/t9rGQGf33JVL2f72t79xnJOTo9STy5z1e5Lkcrvy8nKO9dPl2lrK2RXkfP6ePXuUMnm/gOwn5H0nRGqOy62oiYiOHTvG8RdffNG5xrZDu67oCwoKKDMzk4qKiujDDz+kxsZGmj59utLZPP7447RhwwZau3YtFRQUUGVlJd17771d3nCA9kDuglMhd6Gz2nVFLzfyJyJavXo1RUdHU0lJCU2aNIk8Hg+9/PLLtGbNGrrrrruIiCg3N5dGjhxJRUVF19x1DtBdkLvgVMhd6KxOLa9rXorTvDNSSUkJNTY2KjsFJSYmktvtpsLCQlsmnD6sry/F84ZcGkJEFB8fz/Hf//3fcyyX0xGpu/DpDhw4wPGWLVuUMnk6EnSMCblrFwMGDFCe33PPPRxPmTJFKTt58iTHb731FsdyKR+0zc65K5dh6ksyJX3JsB3p0wRy6eDbb7/N8bRp05R68vNfLtcmIgoJCenKJnqtwx19U1MTLV26lNLS0mjUqFFEdHV7v5CQEIqMjFTqxsTEtLr1X319vTLH05GOFqA9kLvgVMhd6IgO33WfmZlJpaWllJeX16kGZGdnU0REBD/kjQwAvoDcBadC7kJHdKijz8rKoo0bN9K2bduUYYrY2FhqaGigmpoapX51dTXFxsa2+FrLly8nj8fDDycM6YBzIXfBqZC70FHtGrq3LIuWLFlC69ato+3btyun+RBdPfknODiY8vPzKSMjg4iubrFZXl5OqampLb6my+VStgx0Iv2Errvvvpvj+++/n2N9qYs8oUueBkakLvuTp+gReb8NJHwPudu15NLQ22+/XSl76KGHOL7hhhuUsr/+9a8cv/fee75pnGGQu/bQ1NTEsVz+efr0aaWeXF6qn/qo1+0u7eroMzMzac2aNbR+/XoKCwvj+Z+IiAjq1asXRURE0Pz582nZsmXUv39/Cg8PpyVLllBqaipuZgK/Qu6CUyF3obPa1dGvWrWKiK69kzY3N5ceeeQRIiJasWIFBQUFUUZGhrJxA4A/IXfBqZC70FntHrr/IaGhoZSTk3PNrkimCQsL41gfHvvVr37F8XXXXcexHKonUk/A02+ukUuP5E5R0DHI3e/JXb30O7XlDmV9+vThWF8m1NzBEF2b//LUr40bNyplf/7znznWTyaDliF3/UOf2hg+fDjHf/d3f9fi14nUU/o++eQTpcxfQ/fY6x4AAMBg6OgBAAAM1qmd8QJJz549lefJyckcy2FMIvUgG0netUmkHurx4YcfKmUYrofOaOtApltuuYVjOQRJpK72kDdyLV68WKmXkpLCsb4z5KZNmzh+8803lTIM14OdyKkqIvVwsZEjRyplcjWJfpCNtGbNGo71ZYv6TqzdBVf0AAAABkNHDwAAYDB09AAAAAbDHL2X9F3tpk6dyvH06dNb/XdyXl5fWvHMM89wvGvXLqVMPzkJoD3++Mc/ciyX0xERzZ49m2M9d+WpifK+lNDQUKWenJd/9tlnlbJXX32VY7nUCMBu9D3+5T0rc+bMUcpuvfVWjuVS6d27dyv11q1bx7G+LbG/4IoeAADAYOjoAQAADIah+zbIk58WLFiglP3sZz/jWC7JaMuFCxeU56dOneJYHpIA0FmlpaUc60vc5KEbEyZMUMoiIiI4vnLlCsf79+9X6j311FMc60OXZ8+e5dhfy4nATHLIvG/fvkrZgAEDOJZTTQ8//LBSLyQkhOPRo0crZcOGDeNY/i0QqUvl5N/U5s2blXrygDJ9aau/4IoeAADAYOjoAQAADIaOHgAAwGCYo29DWloax3feeadSdv3117f67+Tc5pkzZzj+05/+pNQ7efIkx96cUAXgLXnPh769styGVt6HopNLQ+W8OxHR559/zrF+7wlAS+R2s4mJiUqZ3FJZngyqk0s+4+LilLIxY8a0WE/OuxOp943o91d98cUXHO/bt08pk8+3bdvGcXV1tVKvvr6+1fb7C67oAQAADIaOHgAAwGAYum+DPL3I7XYrZXJnMH0JkTx5bvXq1RzLHZOIiDweT1c0E6BNchlnS88BuoPL5eJ43rx5StnEiRM57tOnT6uvIac49R0f+/Xrx/HXX3/NsTwllIjoxIkTHOunKR4+fJjjY8eOKWVyZ1N9l1O7wxU9AACAwdDRAwAAGAxD922QQzz6UI2841M/uOONN97gODc3l2N5lz0R7rQHgMAh77ofPHiwUibvwj937hzHx48fV+rJz1q5Ux2Rere7HJKXU6lE6l3y+mtcvHixteY7Gq7oAQAADIaOHgAAwGDo6AEAAAyGOfo25OfncxwZGamUffnllxzLk8KIiF5//XWO5Tw/AECgkie5vfPOO0rZ+fPnOZbz8AcPHlTqyd3p5C520DZc0QMAABgMHT0AAIDBelg2W+NVW1tLERER/m4GdIDH46Hw8HB/N8NvkLvOhdxF7jqVN7mLK3oAAACDoaMHAAAwGDp6AAAAg6GjBwAAMBg6egAAAIPZrqO32SIAaIdA/90F+s/vZIH+uwv0n9/JvPnd2a6jr6ur83cToIMC/XcX6D+/kwX67y7Qf34n8+Z3Z7t19E1NTVRZWUmWZZHb7aaKioqAXt/arLa2lhISEmz5fliWRXV1dRQXF6ccRRlokLstQ+7aH3K3Zabkru32ug8KCqL4+Hiqra0lIqLw8HDbvcH+ZNf3A5ttIHd/iF3fD+QucveH2PX98DZ3A/e/sAAAAAEAHT0AAIDBbNvRu1wuevrpp8nlcvm7KbaA98M58LtS4f1wDvyuVKa8H7a7GQ8AAAC6jm2v6AEAAKDz0NEDAAAYDB09AACAwdDRAwAAGMyWHX1OTg4NHjyYQkNDKSUlhXbv3u3vJnWL7OxsGjduHIWFhVF0dDTNmTOHysrKlDqXL1+mzMxMGjBgAPXt25cyMjKourraTy0GHXIXuetkgZi/AZG7ls3k5eVZISEh1iuvvGIdOHDAWrBggRUZGWlVV1f7u2k+N2PGDCs3N9cqLS219u7da82cOdNyu93W+fPnuc6iRYushIQEKz8/3youLrbGjx9vTZgwwY+thmbIXeSukwVq/gZC7tquo09OTrYyMzP5+ZUrV6y4uDgrOzvbj63yj1OnTllEZBUUFFiWZVk1NTVWcHCwtXbtWq5z6NAhi4iswsJCfzUT/h9y93vIXedB/l5lYu7aaui+oaGBSkpKKD09nb8WFBRE6enpVFhY6MeW+YfH4yEiov79+xMRUUlJCTU2NirvT2JiIrnd7oB8f+wEuatC7joL8vd7JuaurTr606dP05UrVygmJkb5ekxMDFVVVfmpVf7R1NRES5cupbS0NBo1ahQREVVVVVFISAhFRkYqdQPx/bEb5O73kLvOg/y9ytTctd3pdXBVZmYmlZaW0s6dO/3dFIB2Qe6CU5mau7a6oo+KiqKePXteczdjdXU1xcbG+qlV3S8rK4s2btxI27Zto/j4eP56bGwsNTQ0UE1NjVI/0N4fO0LuXoXcdSbkr9m5a6uOPiQkhJKSkig/P5+/1tTURPn5+ZSamurHlnUPy7IoKyuL1q1bR1u3bqUhQ4Yo5UlJSRQcHKy8P2VlZVReXh4Q74+dIXeRu04WyPkbELnrq7v8Vq5caQ0aNMhyuVxWcnKytWvXLq/+XV5enuVyuazVq1dbBw8etBYuXGhFRkZaVVVVvmqqbSxevNiKiIiwtm/fbp08eZIfFy9e5DqLFi2y3G63tXXrVqu4uNhKTU21UlNT/dhq8yB32w+5aw8dzV3LCtz8DYTc9UlH39n1mM8//7zldrutkJAQKzk52SoqKvJFM22HiFp85Obmcp1Lly5Zjz32mNWvXz+rd+/e1ty5c62TJ0/6r9GGQe52DHLX/7piHXwg5m8g5K5PjqlNSUmhcePG0cqVK4no6hBQQkICLVmyhJ588sk2/21TUxNVVlZSWFgY9ejRo6ubBj5gWRbV1dVRXFwcBQXZajao3ZC7gQW5S1wXuess7cndLr/rvnk95vLly/lrba3HrK+vp/r6en5+4sQJuummm7q6WdANKioqlJtYnAa5G7iQu8hdp/Imd7v8v7DtXY+ZnZ1NERER/ECyOVdYWJi/m9ApyN3AhdxF7jqVN7nr97Gq5cuXk8fj4UdFRYW/mwQdFGhDfshdcyB3kbtO5U3udvnQfXvXY7pcLnK5XF3dDIB2Q+6CUyF3oS1dfkUfyOsxwdmQu+BUyF1oky9u5e/MekyPx9Pqcgc87P3weDy+SKduhdwNzAdyF7nr1Ic3ueuzDXM6uh4TCefchwkflpaF3A3EB3IXuevUhze565N19J1RW1tLERER/m4GdIDH46Hw8HB/N8NvkLvOhdxF7jqVN7nr97vuAQAAwHfQ0QMAABgMHT0AAIDB0NEDAAAYDB09AACAwdDRAwAAGAwdPQAAgMHQ0QMAABgMHT0AAIDB0NEDAAAYDB09AACAwbr8PHoAMF9ISAjHP/pR6x8j+pnnffr04Tgo6PvrjHPnzin16urqOttEcCiZM6GhoUrZlStXOL506VKrZb7Ws2dPjiMjI5WyqKgojvX8r6+v57iqqopjj8fTxS1U4YoeAADAYOjoAQAADIaOHgAAwGCYo/cjOc8j5yv1Mn0OVJZJPXr0UJ5bltViTER0+fJljhsbG1utB9CS4cOHczxw4EClTObr4MGDlbLx48dzLOfr16xZo9TbvHkzxw0NDZ1qK9if/Ey7+eabOR4xYoRS7+zZsxx/9tlnrZb5gmxjTEwMxw888IBSb968eRwPHTpUKTt48CDHzzzzDMfr16/vsna2BFf0AAAABkNHDwAAYDAM3fvRLbfcwvHIkSOVMjnkk5aWppQlJydzLIfr9aH7pqYmjmtqapQyOWz07rvvcnzmzBlvmg4BRl/m9Otf/5rjqVOnKmUREREc61NSclhfTh/pS5QOHDjA8bFjx5Sy7777zstWg1OMHTuW49/85jccT548Wam3ZcsWjvW86Oqhezm1RKR+Xv/85z/neP78+Uq94OBgji9evKiUySH6ffv2dUk7vYEregAAAIOhowcAADAYOnoAAACDYY6+C/Tv3195fscdd3B83333cRweHq7Ui42N5Vhum0ikzg/pc0Xyubdz9H379lXKxowZw/GuXbs4xhw9NJPz6ampqUrZ7bffzrHMYyJ1GZKek629vlx2R0T0l7/8heMFCxYoZUeOHGmr2eBAixcv5njixIkc6/djVFZWcuyLbWMTEhI41pfNPfjggxzHxcVxrN+/Irdvfu6555Syt99+m+MTJ050rrHtgCt6AAAAg6GjBwAAMJhRQ/dyKFAOb/fu3btDrzdgwACOb7vtNqVs0KBBHEdHRytlEyZMaLGePPGLSF2GIWMidVlSW7vVebuTnb6bnnxP9O8NQKSeBnb48GGl7J133uFY7pJHpJ7YpU8FyV0Yk5KSONb/vlJSUjjOyspSynJycjj+6quvWm0/+Jc+bSM/c+69916lTE4NyanQV199Vaknd1DsimnGsLAw5bls18MPP6yUyTyXfY08kY6I6L/+6784XrdunVJ29OhRjuXfgq/hih4AAMBg6OgBAAAMZtTQvbwT8q677uJY313JW/JOdTkET6TeJa9PDcihfG+H1vVhLjlUqu8AJV//1ltv9er1AdpL5u7JkyeVsv/+7//muF+/fkqZHNY8f/68Uib/puSQpxzGJyLq1asXx3IVC5F65zKG7u1LHxafMWMGx4sWLVLK4uPjOZbTjGVlZUo9uWNiV+yQOHr0aOX5nXfeybE+JdXaYWJyiouIqKioiGP9znp/HdCEK3oAAACDoaMHAAAwGDp6AAAAgxk1Ry9PF1q4cCHHcqmOL+jzLnJe5tSpUxzL07qIiPbv38/xpUuXlDI5Ry/nPImIZs2a1e426ruJyZOTvv3223a/HgQ2fe60Nfr8vTx5US6j0u9lkfOeckkS0bXz/mBP8hRDIqLZs2dzrC+n1JceN5NLnImunTfviIEDB3Isdy4lUncM1T93W6MvT7777rs5HjZsmFL2/vvvcyz/hny91A5X9AAAAAZDRw8AAGAwo4bu5aExctjo9OnTrdZrbciISB1215e4yQMVLly4oJTJYfKDBw9yrA85btmypcXXI1J39tN3kbruuutabK8+/Hn27FmO33jjDaVs06ZNHMuDIgCayaHL9ixlksOtcqieiOj+++/neNq0aRzruVtbW8vx+vXrlbLy8nKv2wL+I3dIJCIaPHgwx/pStdYOP0pLS1Oe6wd8dcQNN9zAsZ6fcljfW/rPKQ9h0v9u5DSp7FMwdA8AAAAdho4eAADAYOjoAQAADGbUHP3u3bs5XrFiBcfjx49X6t18880c68s35FzR1q1bOX7rrbeUeocOHeJYn4eRc/Z1dXVetV1uDUqkLj/R55H0JUvN9FOUduzYwfHrr7+ulOlLlsBc+rymzDV9rlQuFZJ5pi/BlHPq+jIkOa86d+5cpUyeUia3kdaXl+7atYvjnTt3KmXy3hOwL/1zUd53oW8bK0/rlPTtj+Vzb7cX17V1MmhTU1Or/07+PPJ+K315tXxN/e9GnrjXFVv4egtX9AAAAAZDRw8AAGAwo4bu5bI2Gf/P//yPUm/EiBEc68PgclhH7k5XXV2t1OuKYRc55DllyhSlbMmSJRzrp+/J4VW5LKOiokKpt3r1ao71JXRtDVGBfcmpJX1HLplPMtaXKE2YMIHjyMhIpUwO648aNYrj4uJipZ7Mf3nSHJG6E6WcJtPJ4Xp5KhkR0RNPPMExln86kz5t+dFHH3E8duxYpSw0NJRjmdd6jsv814fdZVlrJ839EJnXbe14+vHHH3Pc1gmKe/fuVZ7LvyN9usqXcEUPAABgMHT0AAAAButhdfTWRR+pra295jCEriaHdVrbkYlIvTPUF2+THK7/7W9/q5TJlQJtHa7w9ddfc/zYY48pZXJ4ST9Qxxc8Ho+y62Cg8UXu6ncjy6F2fcdEuTpj0qRJHMfFxSn1ZD7p+d/a1IA+jNnavyFS/77ayl055Dl//nylrKioyKvv3VWQu77P3d69e3PsdrtbrSs/FydOnKjUi42NbfX7ydeXU0b67qdt3XUvV3joU75yFda5c+c4buuQJX11gS/6FG9yF1f0AAAABkNHDwAAYDB09AAAAAYzanmdt/R5k+6i7343e/ZsjocNG6aUyXklfS7nyy+/5HjVqlUcf/LJJ0q97piXh64h5xfl8rRHH31UqRcfH8+xPIWLSM0vGbc1T66T8+0ybuuUx7a0NQ8p51ufeeYZpSwvL49j/eRF7IznDPoSXrljqPwM08nllO+++65Spi+3k4YOHcrxSy+9xHFb8/r6yaNyd9WCggKlTO4m6uv7t7oarugBAAAMho4eAADAYAE5dN+dXC4Xx/PmzVPKpk2bxnH//v2VMjkcpO+uJA+o2bhxI8cXL17sVFuh+8iheiJ198OFCxdyrC8vkkvXqqqqlLL//d//5Vjmgv4achmePp3k7TCkHF6VB9AQqQc+hYWFKWVyVz55cJOMidS/GzmcSqTuuCZ3hgR7k7nV1u9NTs20NU1z/fXXK89Hjx7Nsfw81Zf5yYNlXn31VaVMThkdO3ZMKevOQ2i6Gq7oAQAADIaOHgAAwGDo6AEAAAyGOXofkPOL8gSwjIwMpd7gwYM51pcvyfnX7du3K2Xvvfcex/o8EjiDvpxy5syZHOtz6pLchlPGROq8eWJiIsf6/QBtLVGS86hy6dGWLVuUenIpZ0lJiVJWXl7OsX7viVxWJevpP7PcwlTeU0BEdPz4cY71UyXBbDJ3hw8frpTJ5cryNDydzMEPPvhAKSstLeW4vr6+w+20m3Zd0WdnZ9O4ceMoLCyMoqOjac6cOVRWVqbUuXz5MmVmZtKAAQOob9++lJGRgT9G8DvkLjgVchc6q10dfUFBAWVmZlJRURF9+OGH1NjYSNOnT1f+5//444/Thg0baO3atVRQUECVlZXXHL4B0N2Qu+BUyF3orHYN3W/evFl5vnr1aoqOjqaSkhKaNGkSeTweevnll2nNmjV01113ERFRbm4ujRw5koqKipQT2UwmhysffPBBjuVwJJE6vCSXfBCpQ6UbNmxQyuRwPZYXecduuau/3tSpUzmWS9Lk8DaROuw4cOBApWzs2LEcjxkzhmO5YxiROrWk7wwmT0MsLi7m+LXXXlPqHThwgOOamhqlTO4apl9VfvvttxzLn23EiBFKPfm8rR0AA+Gq1W65608yd/XldfLzta1lonKqSZ/6NGm4XurUzXgej4eIvu/YSkpKqLGxkdLT07lOYmIiud1uKiwsbPE16uvrqba2VnkA+BpyF5wKuQvt1eGOvqmpiZYuXUppaWl8w1lVVRWFhIQoZ2YTEcXExFyzuUez7OxsioiI4EdCQkJHmwTgFeQuOBVyFzqiwx19ZmYmlZaWKjsJdcTy5cvJ4/Hwo6KiolOvB/BDkLvgVMhd6IgOLa/LysqijRs30o4dO5TTtGJjY6mhoYFqamqU/11WV1e3eoKQy+VS5l2cQs6vu91upWz69Okc//SnP+W4X79+Sj05XKbPw+Xm5nL86aefKmWYl+84u+SuXP6mP29oaOBYXyY0btw4ju+44w6lrLUTD/U5dDm/LmMioh07dnC8bds2jr/44gulnn4yWWsuXbqkPJcdinyNnTt3KvXkzyLfj0Bml9z1p6ioKI71+zrCw8M5bm2ZKJH6eSrvGTFZu67oLcuirKwsWrduHW3dupWGDBmilCclJVFwcDDl5+fz18rKyqi8vJxSU1O7psUAHYDcBadC7kJnteuKPjMzk9asWUPr16+nsLAwnv+JiIigXr16UUREBM2fP5+WLVtG/fv3p/DwcFqyZAmlpqYadecnOA9yF5wKuQud1a6OftWqVURENGXKFOXrubm59MgjjxAR0YoVKygoKIgyMjKovr6eZsyYQS+88EKXNNaf9N3E5JKf5p+92T/+4z9yLIcnz58/r9STO9798Y9/VMr0E+ugc+yWu/IENiI1N+TyMX0JkRyK1fNJLtGUr6/nkjzxUF4FEqm76/maXBr33HPPKWVHjx7l+PTp00pZoA3l2y13u5O+Y6jcJfHHP/6xUiaH6+XpjfrKA/n83LlzXdJOu2tXR+/NEZahoaGUk5NDOTk5HW4UQFdD7oJTIXehs3CoDQAAgMFwqE0bevbsybF+A4wcNmrejaqZHK6XQ0j6IST//M//zLG+dzWYTd7dTqQefiR3ydPvbpdD8vphR3InO/n6crc7IvUuZLmLXXf77rvvOJZD9URE//Zv/8axfnd4oA3dBzJ9ff9tt93Gsf6ZLPPi4MGDHMupVKLunZ6yC1zRAwAAGAwdPQAAgMHQ0QMAABgMc/RtkPOmWVlZStns2bM51ne8k8ue5Lz8k08+qdT75ptvOJbzlWA+eYIWEdFvf/tbjuWd0/ocvTxda//+/UqZnKOU+eTPefiOkj+3vrseBA79s1UuN9X39pf3nsglmfoJkIF4jweu6AEAAAyGjh4AAMBgGLrXyMNF/uEf/oFjfRem5rOgia7d5Uwue5JL6ORQPVFgDiHBVc1nijc7fPgwx3JZp04OaV++fLnrGwZgI3369FGe9+7du9W6cmMh+XfixKmrroYregAAAIOhowcAADAYOnoAAACDBeQcfVDQ9/+/GT58uFL21FNPcSy3to2KilLqyVOPNm/erJTJk+jk1rZYQgfN2lo2BwBXpaSkKM/lsbv6YT/eHP4TqHBFDwAAYDB09AAAAAYLiKF7fQelWbNmcXznnXcqZdOnT+dYLqGrqqpS6m3ZsoXj3NxcpWzv3r0dbSoAAPy/vn37tvkcvIMregAAAIOhowcAADBYQAzdR0REKM/nzJnDcXp6ulImh4aqq6s51u+sf/311zn+9NNPu6KZAAAg7N69W3m+bt06jpOSkpSyhISEbmmTE+GKHgAAwGDo6AEAAAyGjh4AAMBgATFHr+9CdvHiRY5dLpdSJk8Vk0voXnvtNaVeYWEhx42NjV3STgAA+N6OHTuU58ePH+f4jjvuUMpSU1M5Li0t5Rin1+GKHgAAwGjo6AEAAAwWEEP3tbW1yvP333+f46FDhyplR44c4XjVqlUcl5SUKPUwXA8A4Fv6Z7fcdVTfgXTlypXd0CJnwhU9AACAwdDRAwAAGAwdPQAAgMF6WJZl+bsRUm1t7TVb1oIzeDweCg8P93cz/Aa561zIXeSuU3mTu7iiBwAAMJjtOnqbDTBAOwT67y7Qf34nC/TfXaD//E7mze/Odh19XV2dv5sAHRTov7tA//mdLNB/d4H+8zuZN787283RNzU1UWVlJVmWRW63myoqKgJ67qxZbW0tJSQk2PL9sCyL6urqKC4ujoKCbPd/x26D3G0Zctf+kLstMyV3bbdhTlBQEMXHx/NGCeHh4bZ7g/3Jru8HbuRB7v4Qu74fyF3k7g+x6/vhbe4G7n9hAQAAAgA6egAAAIPZtqN3uVz09NNPX3OMbKDC++Ec+F2p8H44B35XKlPeD9vdjAcAAABdx7ZX9AAAANB56OgBAAAMho4eAADAYOjoAQAADGbLjj4nJ4cGDx5MoaGhlJKSQrt37/Z3k7pFdnY2jRs3jsLCwig6OprmzJlDZWVlSp3Lly9TZmYmDRgwgPr27UsZGRlUXV3tpxaDDrmL3HWyQMzfgMhdy2by8vKskJAQ65VXXrEOHDhgLViwwIqMjLSqq6v93TSfmzFjhpWbm2uVlpZae/futWbOnGm53W7r/PnzXGfRokVWQkKClZ+fbxUXF1vjx4+3JkyY4MdWQzPkLnLXyQI1fwMhd23X0ScnJ1uZmZn8/MqVK1ZcXJyVnZ3tx1b5x6lTpywisgoKCizLsqyamhorODjYWrt2Ldc5dOiQRURWYWGhv5oJ/w+5+z3krvMgf68yMXdtNXTf0NBAJSUllJ6ezl8LCgqi9PR0Kiws9GPL/MPj8RARUf/+/YmIqKSkhBobG5X3JzExkdxud0C+P3aC3FUhd50F+fs9E3PXVh396dOn6cqVKxQTE6N8PSYmhqqqqvzUKv9oamqipUuXUlpaGo0aNYqIiKqqqigkJIQiIyOVuoH4/tgNcvd7yF3nQf5eZWru2u70OrgqMzOTSktLaefOnf5uCkC7IHfBqUzNXVtd0UdFRVHPnj2vuZuxurqaYmNj/dSq7peVlUUbN26kbdu2UXx8PH89NjaWGhoaqKamRqkfaO+PHSF3r0LuOhPy1+zctVVHHxISQklJSZSfn89fa2pqovz8fEpNTfVjy7qHZVmUlZVF69ato61bt9KQIUOU8qSkJAoODlben7KyMiovLw+I98fOkLvIXScL5PwNiNz1882A18jLy7NcLpe1evVq6+DBg9bChQutyMhIq6qqyt9N87nFixdbERER1vbt262TJ0/y4+LFi1xn0aJFltvttrZu3WoVFxdbqampVmpqqh9bDc2Qu8hdJwvU/A2E3LVdR29ZlvX8889bbrfbCgkJsZKTk62ioiJ/N6lbEFGLj9zcXK5z6dIl67HHHrP69etn9e7d25o7d6518uRJ/zUaFMhd5K6TBWL+BkLu4phaAAAAg9lqjh4AAAC6Fjp6AAAAg6GjBwAAMBg6egAAAIOhowcAADAYOnoAAACDoaMHAAAwGDp6AAAAg6GjBwAAMBg6egAAAIOhowcAADAYOnoAAACD/R/elA1wV4fg/gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting Predicting ==========\n",
      "Predicted: \"[1 4 3 7 6 3 7 2 4]\", Actual: \"[1 4 3 7 6 3 7 2 4]\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.ops import operations as ops\n",
    "from mindspore import dataset as ds\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "from mindspore.dataset.vision import Inter\n",
    "from mindspore import nn, context\n",
    "from mindspore.train import Model\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.common.initializer import initializer\n",
    "from mindspore.nn.loss import SoftmaxCrossEntropyWithLogits\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "import matplotlib.pyplot as plt\n",
    "from mindvision.dataset import Mnist\n",
    "\n",
    "# 设置数据集路径\n",
    "data_path = \"mnist\"\n",
    "train_path = os.path.join(data_path, \"train\")\n",
    "test_path = os.path.join(data_path, \"test\")\n",
    "\n",
    "# 设置使用GPU或CPU进行训练\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n",
    "\n",
    "# 定义LeNet5模型\n",
    "class LeNet5(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        self.fc1 = nn.Dense(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Dense(120, 84)\n",
    "        self.fc3 = nn.Dense(84, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.max_pool2d(self.relu(self.conv1(x)))\n",
    "        x = self.max_pool2d(self.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 数据预处理\n",
    "def create_dataset(data_path, batch_size=32, repeat_size=1,\n",
    "                   num_parallel_workers=1):\n",
    "    # 读取数据集\n",
    "    mnist_ds = ds.MnistDataset(data_path)\n",
    "\n",
    "    # 对数据进行预处理\n",
    "    resize_height, resize_width = 32, 32\n",
    "    rescale = 1.0 / 255.0\n",
    "    shift = 0.0\n",
    "    rescale_nml = 1 / 0.3081\n",
    "    shift_nml = -1 * 0.1307 / 0.3081\n",
    "    resize_op = CV.Resize((resize_height, resize_width), interpolation=Inter.LINEAR)  \n",
    "    rescale_nml_op = CV.Rescale(rescale_nml, shift_nml)\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "    type_cast_op = C.TypeCast(mstype.int32)\n",
    "\n",
    "    # 数据集增强\n",
    "    mnist_ds = mnist_ds.map(operations=type_cast_op, input_columns=\"label\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=resize_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=rescale_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=rescale_nml_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=hwc2chw_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "\n",
    "    # 对数据集进行shuffle和batch处理\n",
    "    buffer_size = 10000\n",
    "    mnist_ds = mnist_ds.shuffle(buffer_size=buffer_size)\n",
    "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
    "    mnist_ds = mnist_ds.repeat(repeat_size)\n",
    "\n",
    "    return mnist_ds\n",
    "\n",
    "# 定义训练和测试函数\n",
    "def train_and_test(network, data_path, num_epochs=10, batch_size=32, lr=0.01,\n",
    "                   momentum=0.9, weight_decay=0.0):\n",
    "    # 创建数据集\n",
    "    dataset = create_dataset(data_path=data_path, batch_size=batch_size)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    net_loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    net_opt = nn.Momentum(network.trainable_params(), lr, momentum)\n",
    "\n",
    "    # 定义模型\n",
    "    model = Model(network, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()})\n",
    "\n",
    "    # 定义回调函数\n",
    "    ckpt_save_dir = \"./ckpt_lenet/\"\n",
    "    ckpt_config = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)\n",
    "    ckpt_cb = ModelCheckpoint(prefix=\"checkpoint_lenet\", directory=ckpt_save_dir, config=ckpt_config)\n",
    "\n",
    "    # 开始训练\n",
    "    print(\"========== Starting Training ==========\")\n",
    "    model.train(num_epochs, dataset, callbacks=[LossMonitor(), ckpt_cb], dataset_sink_mode=False)\n",
    "\n",
    "    # 开始测试\n",
    "    print(\"========== Starting Testing ==========\")\n",
    "    res = model.eval(create_dataset(data_path=data_path, batch_size=batch_size, repeat_size=1))\n",
    "    print(\"Test Accuracy:\", res[\"Accuracy\"])\n",
    "\n",
    "# 创建LeNet5模型并进行训练和测试\n",
    "if __name__ == \"__main__\":\n",
    "    net = LeNet5()\n",
    "    train_and_test(net, data_path, num_epochs=10, batch_size=32, lr=0.01, momentum=0.9, weight_decay=0.0)\n",
    "net = LeNet5()\n",
    "# 加载已经保存的用于测试的模型\n",
    "param_dict = load_checkpoint(\"./ckpt_lenet/checkpoint_lenet-10_2187.ckpt\")\n",
    "# 加载参数到网络中\n",
    "load_param_into_net(net, param_dict)\n",
    "            \n",
    "mnist = Mnist(\"./mnist\", split=\"train\", batch_size=9, resize=32)\n",
    "dataset_infer = mnist.run()\n",
    "ds_test = dataset_infer.create_dict_iterator()\n",
    "data = next(ds_test)\n",
    "images = data[\"image\"].asnumpy()\n",
    "labels = data[\"label\"].asnumpy()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(1, 10):\n",
    "    plt.subplot(3, 3, i)\n",
    "    plt.imshow(images[i-1][0], interpolation=\"None\", cmap=\"gray\")\n",
    "plt.show()\n",
    "lr=0.01\n",
    "momentum=0.9\n",
    "# 使用函数model.predict预测image对应分类\n",
    "net_loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "net_opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "# 定义模型\n",
    "model = Model(net, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()})\n",
    "output = model.predict(Tensor(data['image']))\n",
    "predicted = np.argmax(output.asnumpy(), axis=1)\n",
    "# 输出预测分类与实际分类\n",
    "print(\"========== Starting Predicting ==========\")\n",
    "print(f'Predicted: \"{predicted}\", Actual: \"{labels}\"')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
